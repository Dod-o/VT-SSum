{
    "id": "gn3yfild7nmglk2bofhxzhxujzosd7zj",
    "title": "Data Mining in the Life Sciences: The Path to Personalized Medicine",
    "info": {
        "author": [
            "Karsten Michael Borgwardt, Max Planck Institute for Biological Cybernetics, Max Planck Institute"
        ],
        "published": "May 13, 2014",
        "recorded": "April 2014",
        "category": [
            "Top->Computer Science->Machine Learning",
            "Top->Medicine"
        ]
    },
    "url": "http://videolectures.net/mlpmsummerschool2013_borgwardt_data_mining/",
    "segmentation": [
        [
            "Welcome to you all to our first ITN Summer School and welcome to also the kickoff meeting for Marie Curie initial training network.",
            "I'm happy to see you all here in tubing and and I'm happy that after more than three years of planning we now have reached a point at which we can officially declare this network founded.",
            "I'll take.",
            "The first 10 minutes of my time to give you a bit of background about the network, and then, as Chloe mentioned, I will present the first lecture.",
            "Of this summer school."
        ],
        [
            "Our network is a so-called FP 7.",
            "Marie Curie initial training network.",
            "FP7 is the framework program of European Union, the 7th of its kind to foster research and international collaborations in Europe.",
            "In particular, the initial training networks the Itins are supposed to educate experts at the interface of different disciplines, so it's it's a program for educating the interdisciplinary experts of the future.",
            "In our case, these two fields are machine learning and personalized medicine, or more specifically, if you look at the background of our ITN principle investigators interface of machine learning and statistical genetics.",
            "I will come to the to the principle investigators who they are and also today ITN students in a minute here on this first slide you can see the logo of this summer school.",
            "It's not yet the official logo of the 10 although we are going to have a vote on this in the Supervisory Board later on today and it's nicely showing this connection between machine learning and personalized medicine.",
            "If your data matrix to represent machine learning, and here this well known symbol of medicine and both comes together in our ITN network."
        ],
        [
            "Now I'm going to present this network in different ways.",
            "First of all, in numbers, so six countries are involved in this network.",
            "Belgium, France, Germany, Spain, United Kingdom and the United States.",
            "14 positions are funded by this network.",
            "13 Early stage researcher positions.",
            "These are PhD positions, so still official term for PhD position.",
            "The European Union and one experienced researcher postdoc position at Formatics in Edinburgh.",
            "The network right now includes twelve labs at 10 partner nodes, out of which eight are University or Research Institute nodes and two are industrial nodes.",
            "Siemens infomatics.",
            "The network runs officially for four years, so the official start date was first of January 2013.",
            "The actual start date as it is today.",
            "Our funding will run until December 2016.",
            "We have in total up to 3.75 million euro of funding for the network as a whole per student.",
            "We have three years of funding.",
            "So the network is running a bit longer than each single PhD scholarship, such that we can accommodate different starting times after different students.",
            "We promise to have two three month internships at other nodes per student.",
            "So in the general rule is that we have these three columns, or in our network machine learning statistical genetics and their industrial applications and every each Esri.",
            "So each student should be exposed to these three columns either by the PhD host or by the hosts by doing a second internship.",
            "At two nodes of the other two from the other two columns.",
            "There will be 4 summer schools, one per year, the first one as you can see, is in Tubingen in 2013.",
            "In the next year we'll have summer school in the UK in the year after that in France and in the year after that, we'll have a summer school combined with the closing conference in Spain.",
            "These are the numbers on our network."
        ],
        [
            "Now here's a different way of representing network as a map.",
            "That's a good way to show you.",
            "Who is involved in this network?",
            "So let's start here from the top.",
            "So the company Formatics from Edinburgh.",
            "Is part of the network the University of Sheffield.",
            "University of Liege.",
            "In them, and are mean.",
            "So I mean is mean Paristech in Paris.",
            "Then the MPI is in Tuebingen.",
            "It is to be precise, the MPI for intelligent systems into being that is involved the MPI for psychiatry in Munich and also in Munich.",
            "Siemens Research and technology.",
            "And from Spain.",
            "University Carlos Press the Madrid and Research Center in Valencia and our intercontinental partner.",
            "The Memorial Sloan Kettering Cancer Center in New York."
        ],
        [
            "So who is involved in this network?",
            "First of all, who are the principle investigators and I just I not only want to read out the names now, I would also like these persons to stand up such that we get to know each other.",
            "That's one of the main purposes of this meeting, not only to give lectures but also to get to know each other.",
            "And I think it's now the perfect time to start introducing.",
            "Ourselves to each other, so from Belgium, from the University of Liege Professor, Crystal Feinstein.",
            "They come, they come crystal.",
            "From Paris, from in Paris Tech professor show Philly player.",
            "And also from from Paris.",
            "Florence temini.",
            "From Spain we have from Madrid Fernando Palace goose.",
            "You're kinda puzzle is not here from the United Kingdom University of Sheffield.",
            "Neil Lawrence is not here yet, but he will give a course on Wednesday, Mac noses or it's not here yet, but Felix Arco from Formatics is here.",
            "Welcome, Felix.",
            "From the US gonna, but I haven't seen him yet, but maybe I missed him.",
            "No?",
            "Not yet.",
            "From Germany from Munich, Siemens focus crisp.",
            "Like in FOCA from the Max Planck Society from the Munich site for psychiatry.",
            "Better Miller moosach.",
            "From Tubingen banner chirkov.",
            "And me."
        ],
        [
            "And who are they?",
            "ESRI's that we have recruited so far so it's if I didn't miscount 12 out of which eleven are here.",
            "And they are now ordered in the same order in which we presented them.",
            "To the European Union.",
            "So from my lab Filippelli novice Lopez.",
            "And Carl Johann Szymon Gabriel.",
            "Come from the show cops Department.",
            "Mr James Mick Murray.",
            "From bathroom music, slap my venga.",
            "I will learn how to pronounce your name correctly, hopefully in the course of the four years, so forgive me if I mispronounced him this time from Siemens Cristobal Esteban.",
            "We come from the University of Sheffield Max Twizzlers.",
            "From the University of Liege, Miss Carmona fouladi.",
            "From and now it gets difficult from paradigm in Paris, Mr June Long Chau.",
            "They come and also from bears Mr Dragon Longzhu Lu Lu.",
            "Welcome.",
            "From Madrid, Miss Melanie Fernandez Pradier.",
            "From Valencia, who hasn't started yet conclude cubuk so he will join us at a later summer school.",
            "Ann from New York.",
            "E song he's not here yet, either you see, oh, you are here.",
            "Oh sorry, welcome.",
            "Become so these are all depends on the investigators and all the students that have joined the network so far are very important.",
            "Person is Matthias who is still not.",
            "He was still.",
            "Taking care of the late registrations.",
            "He has disappeared, but I will take another opportunity to introduce him.",
            "Matias Friendly is the administrative coordinator of the network, and he's doing a wonderful job at this and he also works with Chloe, one of the main organizers of this summer school.",
            "But I will come to the to the thank yous in my closing remarks on Friday.",
            "When they come to next is the 1st."
        ],
        [
            "Overview of our research topics.",
            "So we have defined.",
            "Four SAP research programs.",
            "As part of this network, the first one being biomarker discovery, the second one being data integration, the third one being causal mechanisms of disease.",
            "And 4th one being gene environment interactions.",
            "All of our research topics which I'll come to at the end of my 4 hour course can be connected to at least one, often several, of these research goals."
        ],
        [
            "Which leads me to the scientific presentations, so I'm going to present.",
            "4 hours of lectures on data mining in the life Sciences and the subtitle is so you can see on my first."
        ],
        [
            "Slide here the path to personalized medicine.",
            "I have three goals in these four hours of lectures.",
            "The first one.",
            "Being to describe this path to personalized medicine, how?",
            "Bioinformatics is moving more and more towards this direction of exploring the opportunities for personalized medicine.",
            "It's called one of my talk going to is.",
            "To show you some data mining problems that arise in this context such that you have an idea of which data mining problems we are facing on the path to personalized medicine.",
            "The third goal is that you get to know the research of my own research group, abit such that you have an idea of which topics we are working on and I try to reach these three goals in two hours of lecturing today and another two tomorrow morning."
        ],
        [
            "In our network we are combining machine learning with bio medicine.",
            "So the first important question is why is there a need for machine learning in bio medicine?",
            "This need has been created by the high throughput technologies that have been developed over the last decades, including genome and RNA sequencing, compound screening, genotyping, chips, bioimaging only to name a few.",
            "These technologies produce vast amounts of data.",
            "We are now collecting whole genomes of hundreds of or even thousands of individuals.",
            "We can screen 10s of thousands of compounds for their functional activity.",
            "We can determine representative markers in genomes efficiently and at a low cost, and we can take high resolution images of cellular cellular processes in bioimaging.",
            "All of these.",
            "Molecular databases are growing at a much faster pace than our knowledge of biological processes, so we are more collecting more data than could ever be analyzed by manual annotation.",
            "Therefore, we need machine learning methods to help us make sense to help us extract information from these large volumes of biological data.",
            "And by the way, this picture here is showing BGI Hong Kong's or one side, at which this PGI Hong Kong is sequencing genomes with dozens and hundreds of machines in China put billions of dollars into this infrastructure."
        ],
        [
            "I will describe how this field of applying computer science to biology evolved in three steps, and I'd chose some.",
            "Titles which are a bit provocative for this, I called them classic bioinformatics, modern bioinformatics and future bioinformatics.",
            "Classic bioinformatics is how the field started.",
            "It started with a strong focus on molecular properties."
        ],
        [
            "For instance.",
            "Studying the properties of gene and protein sequences of whole genome sequences of protein structures or of chemical compounds.",
            "As I've described before, for all of these, we can now collect large molecular databases of their properties.",
            "And one of the main topics of bound for medics in the beginning was to infer properties of these molecules to give you a few concrete examples.",
            "Very common topic in what I call a classic bound for mattix is to predict the function of a gene given its sequence.",
            "Or the structure of a protein.",
            "Given its sequence.",
            "Or you are given a genome segment and you want to predict the exact boundaries of a gene given this genome sequence or within this genome segment.",
            "And another classic topic which has been studied in chemoinformatics for decades, is to predict the function of a chemical compound given its molecular structure.",
            "So we not only want to collect these these large databases of gene and protein sequences, structures and molecular compounds, we also want to understand.",
            "The function, the biological role that these molecules play.",
            "And machine learning has to play a role in this."
        ],
        [
            "In particular, by establishing similarities between sequences, structures, molecules with known function, and those with unknown function so very common, and in my talk representative.",
            "Example is that you are given a database of molecular compounds with known function and known structure and you are also given an user of compounds.",
            "For which you know the the structure, but you don't know their function.",
            "Now the idea is by finding.",
            "The most similar or similar molecules in your database with known functions.",
            "You will then infer the function of a new molecule.",
            "So fundamental idea is that similarity in structure implies similarity in function.",
            "This research topic is called exploring the structure, activity relationship and the example here shows three molecules that were examined whether they have an anti anthrax activity.",
            "In this study from 2006, so that would be a typical example for research question."
        ],
        [
            "From classic bound formatics Now how do you answer such a question where you are given a molecular graph descriptor of the molecular structure of these molecules?",
            "For each of the molecules in your database, and for each of the molecules for which you want to do function prediction.",
            "And the algorithmic problem that you have to solve now is to.",
            "Measure similarity between these molecular graphs and this includes two components, namely 2.",
            "Quantify the structural similarity between these molecules and also to measure how similar the node, and if given the edge labels are between these graphs, so it's both topological similarity and attribute similarity that we care about."
        ],
        [
            "Many different approaches have been proposed for comparing graphs to each other, so one large family is the family of methods that.",
            "Perform graph isomorphism checking in subgraph isomorphism checking.",
            "These methods either check whether two graphs are completely identical, whether they match exactly, or whether one of the graphs is an exact subgraph of the other graph.",
            "No polynomial runtime algorithm is known for either of the two problems, so provides a morphism is checking.",
            "Is even known to be NP hard.",
            "In applications, these methods are a bit or not.",
            "Only a bit are rather limited in that they don't allow for any mismatches between the two molecules, and we hardly observe exact matches.",
            "Between entire molecules.",
            "So this and the exponential runtime are severe limitation.",
            "In practice, the second family of methods for comparing graphs to each other, also called graph edit distances.",
            "The key idea here is that you are given two graphs as shown on the previous slide.",
            "And now you want to transform the first graph into the second graph by a series of steps, and these steps include.",
            "Adding or removing edges.",
            "Adding or removing nodes and changing node and edge attributes.",
            "And you define a cost function which assigns a cost to each of these transformation steps.",
            "And the idea is that the two graphs are the more similar the cheaper it is.",
            "To transform the first graph into the second graph.",
            "So this approach.",
            "His two important features first of all.",
            "This cost function is both flexible.",
            "And.",
            "Also difficult to set, so some.",
            "Users of graph edit distance is present.",
            "This user for cost function is a key feature as a key advantage.",
            "Of course, elf graph edit distance is because you can adapt your cost function to your particular problem at hand and those who criticize graph edit distances say it's very hard to come up with the right cost function for your problem at hand, so it's an advantage and a disadvantage at the same time, what is.",
            "In general, a disadvantage of graph, edited, edited, since this is the second point that it typically involves subgraph isomorphism checking as an intermediate step, so it has a very expensive substep.",
            "This graph edit distance approach because you have to determine, given the two graphs, which parts which subparts of the two graphs are identical, such that you know which parts of the graphs don't have to be changed.",
            "And this involves up graph, an isomorphism checking and isomorphism checking.",
            "The third family are so called topological descriptors.",
            "Very popular in Chemoinformatics, here the idea is you are given a graph and you map this graph to a feature vector, so rather than working on the graphs directly, you try to come up with the feature vector representation.",
            "Off the graph.",
            "This is a very popular approach.",
            "Still it's it has some disadvantages.",
            "If you transform a graph into a vector then you either lose some of this actually information represented by the graph, or you again suffer from exponential runtime effort.",
            "For example, if you start in subgraphs of a given graph.",
            "And the fourth family, which I'm going to talk about.",
            "Alright, so called graph kernels that became popular in machine learning 10 years ago.",
            "Two of the Seminole Papers were the ones by Kashima ET al and Gardner ET al, and this graph counts.",
            "I connect three goals in which we want to contribute to the family of graph comparison methods.",
            "The first one being we want to come up with methods that whose which can be computed in a polynomial runtime in the number of nodes in the graph.",
            "The second goal being they are applicable to large graphs.",
            "I'll talk about this in more detail in the following.",
            "And the third goal being.",
            "That they are applicable to graphs with attributes.",
            "We're still working on this third goal, but we have some recent new results that I will at least touch in the later course of my lecture."
        ],
        [
            "Now what are kernels?",
            "Some of you might be very familiar with kernels.",
            "Some of you may never have heard of kernel functions, so I'll try to.",
            "To summarize, the definition of kernels in ovated, neither both one nor ask too much of the other part of the audience so.",
            "Kernel functions can be thought of as similarity measures between objects, and they derive from this up.",
            "Direction is up field of machine learning in which we try to solve learning problems by moving points from their original space from the original data space to a feature space.",
            "To give you a concrete example.",
            "Look at this toy problem here.",
            "This is a classification problem.",
            "We have a class of green points in a class of red points.",
            "And now for a new point for which we don't know whether it is red or green.",
            "We want to be able to predict, but at this point belongs to red or to the green glass.",
            "This could be done by introducing.",
            "A bound between the region of the space in which red points are located in an image to green points are located.",
            "And machinery exists for computing such boundaries.",
            "If those are linear.",
            "So either align in 2D or plane in 3D, or a hyperplane in higher dimensional spaces.",
            "However, it's very hard to find like a separating circle, as it is shown here.",
            "In fact, you cannot find the separating line here between the red and the green class.",
            "So what this field of kernel machine learning does is that it moves the whole problem to to a feature space, so it Maps the points from the original space to feature space in which the two classes become linearly separable.",
            "So now in this new space here you can find a separating line between the red and the green class, and then your classification algorithm will predict and you point to be a member of the green class if it is in the half in the right half space.",
            "And to be a red point if it is in the left half space.",
            "Colonels are nothing but.",
            "Inner products in this feature space to which we map our original data points.",
            "End.",
            "What I just described is mapping to a feature space.",
            "This could naively be done in 2 steps by first mapping each of the points from the original space through feature space and then measuring the similarity in this feature space and computing a classifier based on this similarity.",
            "But in practice, we don't use this naive approach.",
            "We rather do both steps in one single step by evaluating a kernel function on the on the data points in the original space.",
            "So the kernel between objects in the original space corresponds to an inner product between the same objects in the feature space, which means we can solve.",
            "This classification problem by performing operations in the original space.",
            "Although we are actually solving the classification problem in the feature space, so we do, we solve the problem in the feature space implicitly without explicitly mapping the points to this feature space.",
            "So now you know both the intuitive definition of a kernel.",
            "It is a similarity measure between objects and the mathematical definition is an inner product between objects in this feature space."
        ],
        [
            "Now when I.",
            "Talk about graph kernels.",
            "I mean kernels on pairs of graphs, so I give I'm given two graphs.",
            "As we said before and I want to measure the similarity between these two graphs.",
            "There's also work by assuming Armani and others.",
            "The term graph kernel refers to comparing two nodes within one single graph, but we compare objects that are one full graph each.",
            "There are instance of a larger framework of so called our convolution kernels by haeussler.",
            "The idea here is if you are given two such as objects, you decompose these objects into their substructures and then you compare these substructures pairwise a very simple graph corner.",
            "Could be defined by decomposing two graphs into their set of nodes, so just counting.",
            "For instance, the node attributes.",
            "So making a histogram over node label frequencies and then comparing these histograms to each other, these node labels pairwise to each other.",
            "That would be a very simple instance of the our convolution framework.",
            "Once we have defined such a kernel between graphs, a graph, can we?",
            "Have made the whole family of kernel methods applicable to graphs, and that's something special because this kernel is family of kernel methods includes methods for classification, regression, clustering to sample testing, principle, component analysis and many more."
        ],
        [
            "In chemoinformatics hundreds of molecular descriptors have been defined which map a graph.",
            "2A feature vector and you could argue that.",
            "In order to define a graph kernel, we just have to use."
        ],
        [
            "One of these.",
            "Molecular scripts descriptors.",
            "As our mapping function FI and this is correct, so you could just apply.",
            "One or several of these topological script descriptors from Chemoinformatics map a graph.",
            "To a feature space and then compute some inner product between these feature vector representation of the graphs.",
            "However, what we noticed over the years when trying to do function prediction using graph currents defined in this way is that these topological descriptor."
        ],
        [
            "As I mentioned in my overview here, they scale poorly to very large graphs.",
            "If you want to.",
            "Look at non trivial subgraphs of these graphs.",
            "Of course you can make a note label histogram over a large graph, but as soon as you move to more complex substructures of a graph then you ran into serious runtime problems and you could easily bring down."
        ],
        [
            "A computing cluster by performing more complex comparisons between graphs or by computing a more complex feature vector representation between graphs.",
            "So I end my lap and my first piece PhD student University work."
        ],
        [
            "For a number of years on this question, how can we speed up these?"
        ],
        [
            "Graph kernels dissimilarity measures.",
            "Between graphs, two large graphs.",
            "By large I mean not dozens of nodes but hundreds, thousands, millions of nodes, and in 2009 we came up with the following approach, which are which I'm going to describe in detail, which for large graphs.",
            "Is Siri the state of the art method for computing similarity between them?",
            "So how does this kernel work?",
            "We call it device fellow Lemon Corner because it is based on ideas from a test of of graph isomorphism originally defined by the Russian researchers, vice fella and lemon in 1968.",
            "And a funny anecdote is that the original paper is only published in Russian.",
            "A summary is later on published in English.",
            "But Nino knows Russian and she reads the original paper from 1968, so she wrapped the paper.",
            "I only knew the result of the paper.",
            "I tried to reconstruct the result that I knew was in the paper from the summary, but I couldn't and I haven't read the paper to this to this state, so we're given two graphs.",
            "G&G prime to networks.",
            "And they are not labeled these numbers here.",
            "And the colors represent node attributes.",
            "And now we want to measure similarity between these two graphs.",
            "And now how can you do this in an efficient way?",
            "They're all the approaches that I described before computing edit distances, deriving feature vector representations.",
            "Computing topological descriptors.",
            "We went for a different approach.",
            "We followed the same procedures that Vice Felimon used in their test of isomorphism and.",
            "What they did is the following for each.",
            "Note in our original graph we.",
            "Record the set of its neighbors.",
            "So 45 we recorded it has a neighbor labeled 2, three and four.",
            "In this repeat for every single node, so one has enabled 4 for example.",
            "And now.",
            "In the second step, we sort these sets so we define an order over these node attributes.",
            "Here it's a numerical order over these numbers and sort these neighbors in ascending order 05.",
            "The neighbors of five are two 3, four in ascending order.",
            "This will repeat for every node in our two graphs.",
            "Now in this step see here in this.",
            "Step three, we hash.",
            "These mighty sets, or as we call them these neighborhood strings that represent the label of a note and the label of its neighbors in the following way.",
            "If two nodes have exactly the same neighborhood string.",
            "Such as these two notes here.",
            "Then they are mapped to the same number.",
            "So one in four is mapped to 623, which is.",
            "Which note here this note here is mapped to 7 and so on and so forth, so this is called in computer science, a hashing operation.",
            "So we hash this neighborhood strings into integers and then in the fourth step we use these hash values.",
            "S knew note attributes in our graphs.",
            "So if 1 four is hash 26, then the node that previously was labeled one is now labeled 6.",
            "And the testifies Amorphism Bivi Spelemann relied on the fact that if the set of GNU labels that you generate at the end of 1 iteration in the two graphs, PNG prime is not the same, then they cannot be isomorphic.",
            "Which is correct.",
            "However, there are some pathological cases in which even after many iterations, the two graphs have the same multi set of labels, but they're still not isomorphic and therefore this approach didn't solve the graph isomorphism problem but.",
            "As it turns out, for us it can still be used to define a very efficient to compute similarity measure between graphs.",
            "Because all you have to do is.",
            "You represent the graph as a histogram over these know knew node label frequencies after each iteration.",
            "And this is."
        ],
        [
            "Shown on the following slide so you can start.",
            "By just counting the frequency of each label in the."
        ],
        [
            "In the graph, so you go to these graphs.",
            "Here you make a histogram over the node label frequencies.",
            "Here these frequency."
        ],
        [
            "These are the first part of your feature vector representation of your graphs, and then you repeat this histogram construction, sorry."
        ],
        [
            "At the end of such an iteration of device Felimon algorithm, so you count the frequencies of these labels after the graphs have been re labeled.",
            "And of course you can repeat this whole procedure over and over again, so once you've reached this step here you can go back, compute enabled strings, hash them and Re label the graph again.",
            "Now what are you doing by constructing?"
        ],
        [
            "Such a feature vector representation of a graph well?"
        ],
        [
            "You're looking at what we call subtree like patterns.",
            "They are not subtrees of the original graphs in the strict sense, because there may be repetitions of nodes, but still the data structure that we look at.",
            "Resembles a tree because we start at one node at one for example, and then visit the neighbors of that node 123 and six, and then we visit their neighbors.",
            "So by iteratively repeating the virtual lemonade with them, we can V compare larger and larger neighborhoods in the two graphs, which are, which can be represented.",
            "As a tree structure, but which are not strict upgrade subtrees of the original graph because we may repeat some nodes in here.",
            "So that's what we do.",
            "We look at larger and larger subtree like patterns in the two graphs and we just."
        ],
        [
            "Count them so we get a concatenation of many different histograms over node label frequencies.",
            "At the end of each iteration of the West Valley Mall algorithm, and then in the end all that we have to do is we have to compare these feature vectors for the two graphs that we want to compare."
        ],
        [
            "Now, how expensive is it to compute such a kernel?",
            "It's amazingly cheap.",
            "And for us this was really a breakthrough because before we didn't know how to compute these kernels in around time, which is less than quadratic in the number of nodes in the two graphs.",
            "So as I said, there are three steps in this procedure.",
            "The first one being.",
            "That we represent each node as a sorted list of its neighbors.",
            "This requires a runtime of all of M. The Ms number of edges in the graph I just have to run through all edges and can thereby record enables over note.",
            "Then we hash these.",
            "Neighborhood strings we map identical neighborhood strings to the same integer.",
            "This can also be done in a runtime which is linear in the number of edges.",
            "And then once we have computed the hash values, we re label the nodes in the graph.",
            "This is only linear in the number of nodes N in the graph.",
            "What often provokes questions is the second step.",
            "How can the second step here?",
            "Be performed in linear runtime and I want to give a few hints and details on how this is done, because this is the most complex step in here, so we have all of these neighborhood strings."
        ],
        [
            "In our example.",
            "And the first question is, can we really sort each neighborhood string in linear time?",
            "In the number of edges and the answer is yes, we can do that by by using bucket sort because our graphs are of finite size.",
            "There's only a finite alphabet from which our discrete, no no distributes come.",
            "So the number of buckets for bucket sort is limited.",
            "By at most the number of nodes in the graphs.",
            "So what we do is we create a bucket for all letters in our alphabet.",
            "In this example, here we would create a bucket for one 234 up to five.",
            "So we have 5 packets and then.",
            "We go to each neighborhood string and start throwing.",
            "The letters into these buckets while recording for each letter that we throw into a bucket which string it came from.",
            "Once we have done that, we have distributed all the nodes over these buckets.",
            "We go through the buckets in ascending order, so from one to six and we start reassembling the neighborhood strings.",
            "By construction, now all enabled strings are sorted.",
            "And this is all linear time because I have to perform.",
            "One step per note in so once for throwing him into the bucket and one step for going through the bucket so it's 2 steps to be precise per note.",
            "So now I have these sorted neighborhood strings.",
            "How can I efficiently find out if two neighborhood strings are the same?",
            "That's the next puzzling question.",
            "And here again, you need.",
            "A special kind of sorting algorithm.",
            "You need radix sort.",
            "Radix sort allows you to sort a set of strings in a runtime, which is linear in the total length of these strings, and the trick is that you start.",
            "Sorting the strings as you can see here the strings here are sorted.",
            "And how do you achieve this?",
            "Using Radix sort, you start by sorting these strings according to their last.",
            "Number according to their last letter.",
            "To be precise.",
            "And then.",
            "You proceed.",
            "To the first part, last second but last letter, and so on and so forth, thereby slowly bringing the strings into the correct order, and it can be shown that this is also an effort which is done, which is a linear in the number of strings.",
            "The question to ask is how can can I guarantee that this operation is really only linear in the number of edges in the graph?",
            "If these neighborhoods can be of different size?",
            "Well, this can be achieved by running through all of the strings once and recording how long they are.",
            "So you make a histogram over the length of the strings and you only and then you have the information of how long a string is an in which steps of radix sort.",
            "You have to consider a certain string depending on its total length, so thereby you avoid that the algorithm scales in the number of nodes times the number.",
            "Of maximum neighbors over of a node.",
            "Thereby you achieve that it is only really only linear in the number of edges, so there are a lot of sorting tricks in here which make it possible that this is really oh of M in its overall runtime."
        ],
        [
            "We can repeat this this whole procedure age times.",
            "And therefore the overall runtime is O of M * H for capital N graph.",
            "So if you want to compute this for whole collection of capital N graphs, we can easily compute the kernel pair pair capital N ^2 * M * H would be the runtime.",
            "What is faster in practice is to compute the feature vector representation for all for all graphs explicitly, and then to compute the kernel matrix from this explicit representation of.",
            "Of each graph as a feature vector.",
            "So in our experiments this part here number of graphs, times number of edges, times, sum of iterations absolutely dominates.",
            "The runtime."
        ],
        [
            "And this is also shown here on the next slide, on which you can see.",
            "That computing this feature vector representation of the graphs explicitly.",
            "Is just called global.",
            "Here is much faster than a knife approach which computer just iterates through all pairs of graphs and computes their similarity.",
            "So here global scale is linear in the number of graphs N in the number of iterations H. In the graph density, which is the number of edges per node and quadratically in the number of nodes N depending on the number of edges.",
            "Of course in the graph."
        ],
        [
            "And we also showed.",
            "That this type of graph kernel is absolutely competitive with other graph coins that have been defined.",
            "It is on small graphs as good on classification benchmarks and larger graphs which have hundreds of nodes.",
            "It is the best performing method both in terms of accuracy and in terms of runtime."
        ],
        [
            "So now you have an idea of what a typical question in what I call classic band formatics is.",
            "Another example would be sequence alignment finding.",
            "Similar subsequences, similar substrings in two given DNA or protein sequences, and they are very famous methods like Blast for.",
            "For answering this question and there are even string kernels that try to find matching substrings.",
            "In biological sequences.",
            "Now the next step in bound for Matics in modern bioinformatics, which is now probably at least 15 years old.",
            "Is to move away from the focus on molecules and their properties and to focus on individuals and the.",
            "Key technology which has been."
        ],
        [
            "Used for this were microarrays.",
            "In the beginning, microarrays allow you to measure the all gene expression levels in a given sample.",
            "This technology has been out for a while.",
            "It has been complemented by other properties that allow you to measure the the characteristics, the molecular characteristics of an individual.",
            "So-called genotyping chips allow you to determine the Geno type of an individual, so they allow you to measure representative markers representative positions in the genome of an individual which capture the genetic properties of this individual and even.",
            "More.",
            "Yep, demanding is the next large scale technology which is genome sequencing.",
            "It allows you to determine the genome sequence of an individual or or also recently via RNA sequencing to generate a transcriptomic profile of an individual.",
            "So in summary, it is as it is stated on this slide here.",
            "High throughput technologies now enable to collection of molecular information on individuals.",
            "As you can see here, the cost for these technologies is dropping dramatically.",
            "Even faster than most law would imply as a genome sequencing is becoming cheaper and cheaper and collecting large collections of data now on individuals not only on molecules is becoming more and more affordable.",
            "And an option."
        ],
        [
            "Then machine learning was interested.",
            "In this type of modern bound formatics, from the very very beginning, because there are some obvious questions to ask.",
            "For instance, if I jump back several slides to my toy."
        ],
        [
            "Example here.",
            "One question is.",
            "If I have gene expression levels for a large collection of patients.",
            "Which star who suffer from different diseases?",
            "Can I then diagnose which disease a particular patient suffers from by using such machine learning techniques?",
            "Or can I detect clusters of patients that are similar on there on the molecular level and which forms up types of the disease?",
            "It would be a clustering question.",
            "Or can I detect genes that are highly active or deactivated, inactive in in sick individuals?",
            "All of these classification, clustering and feature selection problems have been studied in much detail on these gene expression data.",
            "However."
        ],
        [
            "It is fair to admit that very often, and I also include worked on this domain, so I'm not excluding myself very often in this domain.",
            "The results were not that satisfying to put its diplomatic.",
            "2011 there was even an article in PLOS Computational Biology saying that most random gene expression signatures are significantly associated with breast cancer outcome.",
            "Sounds a bit strange to someone with a statistics background how.",
            "A random gene expression signature can be statistically significantly associated, and how most random gene expression signatures can be significantly associated.",
            "Becausw significant is usually defined on being unlike most random.",
            "The instances of the data better what they mean in this article is that if you use a published cancer signature also a list of genes that are known to be involved or speculated to be involved in cancer and predict breast cancer outcome using this published list of genes.",
            "And you compare this to a randomly drawn set of genes in their experiments.",
            "Then there's no significant difference between the results that you obtain.",
            "End.",
            "One major reason for this, for the problems that we encounter here, is that the number of dimensions that we're dealing with this so much larger the number of samples.",
            "That that we work with in most of these datasets.",
            "So usually we are looking at thousands of genes, but only on a large datasets hundreds of gene expression profiles, so there's a lot of room for.",
            "For overfitting, and it's very hard to solve this feature selection problem."
        ],
        [
            "On the gene expression data still.",
            "I don't want to make a general statement about the field as a whole.",
            "There are some examples of success.",
            "There are some examples where gene expression levels have been even approved for.",
            "For personalized medicine.",
            "For checking whether a certain person should receive a certain treatment.",
            "And there were even other.",
            "Examples of success in which phenotype prediction worked really well, and one of these I noticed when after moving to tubing only a few months after I arrived in Tubingen, I read in current biology about a genetic test that predicts eye color in Dutch men with 90% accuracy and I wasn't a statistical geneticist at the time.",
            "My background was mainly machine learning, so I wondered by is this example so different from the gene expression from many gene expression studies, and why?",
            "If this works for eye color in Dutch men, can't we predict other phenotypes?",
            "Complex phenotypes with the same accuracy?",
            "And for the statistical analysis among you, this may all sound trivial, but this is how I experienced this or or got to learn this as a machine learner and this is maybe interesting to some of our students who have a technical background.",
            "So why can't we predict other complex diseases or phenotypes such as diabetes, autism, depression, track response, or plant growth?",
            "To name an example from genetics with the same accuracy as.",
            "These researchers from the Netherlands were able to predict eye color in Dutch men well.",
            "The differences in this study value at all the jeans that are involved in eye color pigmentation are already known.",
            "It is 8 genes which they used and in these jeans they just counted the number of mutations or do or to be more precise, number of deviations from the reference genome in these eight jeans.",
            "Just the total count of these deviations was enough.",
            "To get a very good predictor of eye color in in Dutch men.",
            "So this particular aspect distinguishes this application from.",
            "The phenotype prediction problem for all of these other complex phenotypes and diseases for diseases such as diabetes, depression or autism we don't know.",
            "Many genes that may be involved in these diseases we know a few candidate genes, but there's still a lot to explore and we still don't know all the.",
            "Ordenes, let alone the genetic mechanisms involved in these diseases, and therefore."
        ],
        [
            "The genetics community and this is now we're moving from research topics in machine learning to research base in statistical genetics.",
            "Therefore the statistical genetics community tries to find these jeans that are involved in complex phenotypes in large international genetics consortia via so-called genome wide Association studies.",
            "And I'll summarize what these are for those of you who don't have a statistical genetics background.",
            "Very broadly speaking, in a genome wide Association study, we want to compute.",
            "Correlations between phenotypic variation and genotypic variation.",
            "I've shown a toy example here.",
            "We are given a group of plants that differ in a particular phenotype.",
            "Some of them are high at all.",
            "Some of them are short, so this is the phenotype and the phenotypic variation that we're looking at.",
            "Height in plants and for each of these plants we are given a number of.",
            "Genetic markers shown here as these little dots and they are given in two colors.",
            "Let us define orange to be.",
            "In agreement with the reference genome.",
            "And blue.",
            "As a deviation from the reference genome and each.",
            "Horizontal line is one of these genetic markers and now in genome wide Association size we want to compute which of these markers.",
            "Correlate most with variation in the phenotype.",
            "These markets, and it's very important to know, are usually single nucleotide polymorphism's, the so called snips.",
            "So single basis that may differ between individuals and you'll hear a lot more about this in our talks.",
            "And when you read papers and so on.",
            "So this term should be known to everyone, so may also be called genetic locus or genomic variant.",
            "If you want to use a more broad.",
            "Term the problems did the typical problems I have to give you an idea of this that we work with in in such genome wide Association studies?",
            "Is that we have somewhere between 100,000 and 10,000,000 snips per genome, and today is at least the ones that we we look at.",
            "The range from 100 individuals to 200,000 at most.",
            "So for instance, for human height and for clinical migraine, 200,000 patients have now been collected by different hospital, so it's not that that everyone in these consortia has access to 200,000.",
            "And patient genotypes.",
            "But the total collection of patients would be 200,000."
        ],
        [
            "Now, how are the results from such a genome wide Association study reported?",
            "They are reported using a so called Manhattan Plot.",
            "One of which is shown here for phenotype from a plant model Organism.",
            "The X axis are positions on the genomes or each point of the axis represents snip.",
            "the Y axis is representing minus log 10 of the P value of the strength of Association between this snip and the phenotype.",
            "So the higher point on this Y axis, the stronger the Association between this snip and the phenotype.",
            "This is called a Manhattan plot because if you have a lot of strong associations between the phenotype and Geno type, then you have peaks here which look like the skyscrapers.",
            "In in Manhattan, this plot looks more like Tubingen and.",
            "There is very only isolated larger buildings.",
            "And the Bonferroni threshold here.",
            "This is the threshold that you have to pass in order for your strength of Association being significant.",
            "We're performing a lot of statistical tests here.",
            "Just this.",
            "As a side remark, and therefore we have to correct for this multiple hypothesis testing.",
            "And so we have to avoid that we get positive results just by random chance.",
            "So on and the point that would be above this line would be a would be a statistically significant observation or correlation between genotype and phenotype."
        ],
        [
            "Now using this approach.",
            "More.",
            "Then 1200 new disease loci were detected over the last decade.",
            "However, and there are even numbers that are there, some even cite higher numbers.",
            "This is from Eric Lenders 10 year anniversary paper for the sequencing of the human genome.",
            "At the same time, it's disappointing that the phenotypic variance explained by these loci.",
            "Is disappointingly low.",
            "For hardly any disease, it's it's more than 20% will have some examples on the following slide and and statistical genetics.",
            "Even coined a term for this phenomenon is the phenomenon of missing heritability, so we may find snips that are correlated with phenotypic variation, but these statistically significantly associated snips only explain a small fraction of the phenotypic variance that we observe, and even of the heritable.",
            "Yeah, component of these traits which we observe in twin studies or in family pedigrees."
        ],
        [
            "To give you an idea of dismissing heritability are here side a few numbers from this paper by Eric Lander an for very few common traits is too.",
            "Is the explained heritable component larger than 50% type one diabetes and fetal hemoglobin levels are some examples for this.",
            "For some trades it is between 20 and 30%.",
            "For example, Crohn's disease and lipid levels.",
            "For most diseases this explained heritability and explained variance is less than 20%.",
            "For instance, autism height and schitzophrenia belong to this class.",
            "Explained heritability is in this context the phenotypic variance explained by known variants over the variance explained by all variants.",
            "So if we know that a certain trait is heritable.",
            "By 80% for example, and we notice from a pedigree or from a twin study, and then we determine snips that are associated with this variation in the phenotype, and then we divide the variance that can be explained.",
            "By these nips by the variance which can be explained from the heritable component of this disease, and that's the explained heritability of disease over disease.",
            "In two papers which appeared over last two years, lender and colleagues speculate that there may be reasons for this missing heritability.",
            "For, for instance, what they claim or speculate, and it's just speculation, is that maybe our estimates of overall heritability.",
            "So the denominator of this formula here may be too large because they ignore gene gene interactions and gene environment interactions.",
            "So that's a hypothesis which they brought forward a year ago."
        ],
        [
            "Well, this was your question no?",
            "It's true OK?",
            "So we'll come exactly to this debate.",
            "What is the reason now?",
            "There are many other potential reasons for missing heritability, and this is heavily debated.",
            "The statistical genetics community, and a lot of different opinions on this and you just heard that bedroom and Florence agree with Eric Lander and.",
            "And Crystal also so all.",
            "General agreement, that's that's nice.",
            "That Eric Lander is right."
        ],
        [
            "So that these heritability estimates may be inflated, that we may overestimate how heritable certain traits and complex diseases are."
        ],
        [
            "So when you look at the debate.",
            "In statistical genetics about the potential reasons for missing heritability.",
            "Then from my perspective, as a former almost pure machine learner, three points tend to reoccur in this debate.",
            "First of all, one point is most current analysis neglect the additive or multiplicative effects between loci.",
            "So as I showed you as I showed you in the Manhattan lots, we compute correlations between a single snip and a phenotype.",
            "However, it's biologically very possible that many loci many genes are involved in a complex trait.",
            "And it may be more realistic to move from the single locus perspective to a systems biology perspective and to study the polygenic rather than the monogenic architecture of complex traits.",
            "So that's one point moving to polygenic architectures.",
            "The second point is that.",
            "The effect size.",
            "Off single snips of single loci is maybe smaller than one first had hoped for, or had speculated.",
            "So these small effect sizes are not detectable with small sample sizes, so we really need these 10s of thousands or hundreds of thousands of patients to detect the snips with a small effect size.",
            "The other point, which is a very broad one or the other potential reason for missing heritability, is that they feel that we may underestimate the phenotypic effect of other genetic, epigenetic or non genetic factors.",
            "So there may be genetic properties that we've ignored, ignored so far.",
            "For instance, real snips that play an important role in disease.",
            "There may be chemical modifications of the genome such as demethylation state.",
            "Of bases in the genome that may be involved in phenotypic variation.",
            "And of course there may be important environmental effects on the phenotype which may also play a phenotypic role."
        ],
        [
            "Now, how can machine learning help here?",
            "I see three directions how machine learning can contribute to genetics at the moment.",
            "You could summarize them by saying machine learning can support genetics to move to a systems biology perspective.",
            "First of all, by developing efficient to compute multilocus models by developing algorithms that allow to discover trade related systems of genetic loci.",
            "The second one.",
            "Being machine learning can some can support increasing the sample size in genetic studies, not by generating new samples, but by making it cheaper to Geno type and phenotype.",
            "Individuals give you a few concrete examples of this at the latest tomorrow.",
            "And machine learning has also a role to play in developing statistical tests which allow you to decide better additional types of molecular information.",
            "Can improve your prediction of the phenotype.",
            "These genetic, epigenetic or environmental effects that we talked that I talked about on the previous slide and to which decree they improve our ability to predict the phenotype."
        ],
        [
            "And I.",
            "Said in the beginning that I also want to give you an idea of what my group is working on, so I will show a number of different projects of ours which are located exactly in this domain at this interface between machine learning and genetics in the following.",
            "And I'll start with the multilocus models because this is 1 area where there's a lot of room for new algorithm."
        ],
        [
            "Development.",
            "So.",
            "The epistaxis.",
            "Is if defined statistically?",
            "The interaction between two snips.",
            "Which contributes to phenotypic variation, and it's conjectured to be one source of missing heritability that we.",
            "Do in many studies ignore this contribution of snip, snip interactions.",
            "There are large scale studies in model organisms, for instance by Boone ET al, which showed it a lot of genetic interactions.",
            "Also, interaction effects between genes exist and they are one indicator that appetite is maybe a major factor in the Geno type phenotype relationship.",
            "And there are also a number.",
            "Of examples in the literature which showed that only certain modifications in pairs of genes lead to a particular phenotype or that a second mutation masks the effect of the first mutation.",
            "For instance, here, the loss of either BRCA one or BAC A2 tumor suppressor function in cells triggers a cell cycle arrest at G2 M checkpoint that can be suppressed by the inactivation.",
            "Of P53.",
            "So P 53 is a component that is involved in a lot of interactions in cancer, and another example is to loss of the fund.",
            "Hippel Lindau tumor suppressor function normally causes cellular center St.",
            "But inactivation of a second tumor suppressor RB retinoblastoma can suppress this process, so these are two examples from cancer.",
            "That show how interactions between genes may affect disease status or complex phenotype."
        ],
        [
            "Now, why can't we easily check for all of these epistatic snip snip interactions?",
            "We have two big problems.",
            "One is a combination of 1 and the other is statistical one.",
            "They both derive from the same fact the number of potential candidate snip peers is huge.",
            "As I said before, we typically deal with between 10,000 and 10,000,000 snips, and exhaustive search through all of.",
            "These potential snippers would therefore have to consider tend to attend to 10 to 14.",
            "Snippers tend to the 10, maybe handebol, or one can deal with 10 to 14.",
            "Can even keep a large computing cluster busy for awhile.",
            "In short, what we are suffering from in epistasis detection is that it is an enormous computational runtime problem, and of course hand in hand with this computational runtime problem goes also an enormous multiple hypothesis testing problem, because in the most extreme case, we're testing 10 to 14 hypothesis and we have to make sure that we don't get order 10 to the 12 false positives by ignoring the multiple hypothesis testing problem.",
            "Here."
        ],
        [
            "A lot of paramedics groups have looked at this problem, in fact, and one can.",
            "Even make a taxonomy of different approaches that have been defined in order to deal with this problem of epistasis detection.",
            "So the first family is the family of exhaustive enumeration methods, an.",
            "Which is applicable only to small sets of snips.",
            "If you use standard hardware or can be extended to a genome wide scale by using special hardware such as cloud computing or GPU implementations, and there's actually a field in which bathroom and I've worked over the last few years together, and I think also crystal worked in this domain of epistasis detection.",
            "So with special hardware you can perform such an exhaustive enumeration.",
            "The second family are so called filtering approaches where you try to narrow down the search space to reduce the computational effort.",
            "Either you narrow it down by a statistical statistical criterion, for instance only considering snips that have a large main effect.",
            "So large effect on their own, and then you only construct pairs of chips.",
            "We're both snips have a large effect, or you use a biological criterion.",
            "For instance, you only look at Snips that are near.",
            "Genes whose proteins are known to interact.",
            "So you use biological networks to narrow down the search space.",
            "In data mining, some index structure approaches were proposed.",
            "The most famous one being faster Nova.",
            "It's a planned branch and bound algorithm.",
            "On step step interaction in numeration so you.",
            "Use this principle from optimization theory branch and bound to avoid to compute the statistics for parts of the search space of snip.",
            "Snip interactions team is the successor method of Faster Nova, which makes it more efficient to compute P values by storing intermediate terms that have to be computed again and again in random permutations of the data which are needed to compute the P values.",
            "So these are three.",
            "Types of approaches.",
            "They all have in common that in the worst case you still suffer from a runtime which is quadratic in the number of snips.",
            "Sometimes the these pruning filtering criteria here may reduce your search space.",
            "Sometimes they may not, or they may.",
            "Make you lose a lot of interesting candidate pairs.",
            "In the other case, for instance, here in the branch and bound approach, you may have datasets in which this branch and bound approach doesn't work that well where you can only prune 1% of the entire search space, and you still have to commute 99% of these 10 to 14 snippers."
        ],
        [
            "So to summarize it in short.",
            "These methods.",
            "Tend to either.",
            "Suffer from averse case runtime of N square or often from a low recoil.",
            "So a more theoretical question.",
            "That I am.",
            "Better soon of mine and I ask is can you can you can we come up with a principle method that we can show to require sub quadratic runtime in epistaxis detection."
        ],
        [
            "And this work.",
            "I would like to present to you in a bit more detail.",
            "So first of all, we had to settle on a particular type of definition of how to measure epistaxis, and we defined it as.",
            "A difference in correlation.",
            "This also criterion that better I had used in one of the GPU implementations.",
            "Called a plaster, so it is the difference in correlation between 2 steps between cases and controls between in in the group of individuals that suffer from the disease and the group of individuals that doesn't suffer from the disease.",
            "The biological interpretation is that we have a different degree of linkage disequilibrium, so a different degree of correlation between the two loci in these two phenotypic classes.",
            "And now a datamining question to ask.",
            "Boss, can we?"
        ],
        [
            "Solve this problem in a runtime which is provability less than quadratic in the number of snips, N and.",
            "We checked the literature in theoretical computer science and found one related piece of work by Pertouli ET al from called 1989.",
            "In which paturia doll.",
            "Tackle the so-called maximum correlation problem or.",
            "To use the more illustrative fame, this so called light bulb problem.",
            "What is the light by problem?",
            "You're observing a set of light bulbs which can be on or off.",
            "Individually and you are observing them across different points in time.",
            "And now.",
            "After observing all these light bulbs, you want to find out which pair of light bulbs was most often in the same state.",
            "You could also say you want to find the pair of light bulbs with the minimum Hamming distance.",
            "Ideally, two laptops would be in the same state all the time.",
            "Of course the naive approach is you.",
            "Compute all pairwise Hamming distances between the light bulbs and pick the pair with the minimum distance."
        ],
        [
            "However, in this type of approach for 1989 by Patriot Al.",
            "But we I presented an approach which can do better.",
            "And it works as follows.",
            "We are given a binary matrix A with M rows and N columns, Mr.",
            "The number of time points in the light bulb.",
            "Example N is the number of light bulbs.",
            "In our.",
            "Case in our application, M is the number of patients.",
            "In is the number of snips.",
            "And now the algorithm repeats the following steps L times it samples K rose.",
            "From the matrix.",
            "So K timepoints or K patients if you want.",
            "And it increases a counter for all pairs of columns for all pairs of light bulbs or for all pairs of snips that match exactly on these K rose.",
            "You can again use techniques sorting techniques that I described on the graphs for doing this efficiently.",
            "In this procedure we repeat edit times, always increasing count the counters for those pairs of columns that match exactly on our subset of rows.",
            "And then in the end we divide all these counters by adding the number of iterations to get an estimate of.",
            "This probability of being in the same state, which is which is the opposite of the of the Hamming distance.",
            "To get an estimate of the Hamming distance.",
            "And now what Patriot I'll show in their paper is that with the probability close to one, this light by procedure retrieves the most correlated pair.",
            "So they call this correlated.",
            "I called it minimum Hamming distance in a runtime.",
            "Which, ignoring this logarithmic part here is M to the one plus logarithm of C1 over logarithm of C2.",
            "So what else you wanted to see?",
            "One is the highest.",
            "NC 2 is the second highest correlation score in our data set.",
            "If they are identical, if the top here and the second pair.",
            "Have the same level of correlation, then this runtime here is a quadratic again.",
            "As soon as there is a gap in correlation between the top here and the second most correlated pair, this runtime becomes sub quadratic in a number of snips."
        ],
        [
            "However, this old algorithm from 1989 did not solve our apostata search problem directly.",
            "There are three points in which it differs from what we were planning to do.",
            "First of all, we were interested in this difference in correlation between cases and controls.",
            "Second, our snips are not binary in general in.",
            "In the light bulb case, the variables are binary.",
            "Snips tend to be triple, state or even when they are imputed, they can be have continuous values.",
            "So having this only for binary variables, for the restriction and.",
            "Via this lab approach, dealt with Hamming distance and the probability of being in the same state for binary variables.",
            "We wanted to compute Pearson's correlation coefficient.",
            "And in three steps we could overcome these."
        ],
        [
            "The three discrepancies.",
            "So first of all.",
            "We could overcome the problem that we don't want to maximize correlation.",
            "Want to maximize difference in correlation?",
            "We can do so by manipulating the original data matrix a bit.",
            "Original datamatrix is the concatenation of the matrices.",
            "A&BA is the matrix of cases.",
            "B is the matrix of controls.",
            "The roles are the patients again, so the case and control it's the columns are the snips.",
            "So this concatenation of A of A&B is our original data matrix.",
            "Now what we do is we copy this matrix.",
            "And we invert B.",
            "By inverting BI mean computing 1 -- B so far I still assume that all our variables are binary.",
            "I'll only overcome this problem later on.",
            "So far we can still assume that they are binary, so 1 -- B flips exactly the entries of B.",
            "And we do the same manipulation again.",
            "We copy AB, invert this time a.",
            "And now we compute.",
            "The light by the algorithm on these extended matrices, shown here in line three and four.",
            "And we can show and I only state the result here.",
            "The proof is in the paper that the maximally correlated pair.",
            "Of columns in these extended matrices.",
            "Is.",
            "Also, the pair of columns, the pair of variables which maximizes the difference in correlation between cases and controls.",
            "This is just a matrix.",
            "Transformation which allows to solve this."
        ],
        [
            "Problem.",
            "We can still use on the extended transform matrix the original algorithm, but as I said before, our snips are still binary, so we have to.",
            "Make it more general in that we can deal with non binary snips as well.",
            "Well, one way to make our algorithm applicable to snips is that we binarize the snips before we put them into our algorithm.",
            "And we do so by a technique called locality sensitive hashing by Charikar from 2002, and the idea here is.",
            "That we are given vectors in an M dimensional space.",
            "These are our snips, so if you have EM patients.",
            "Then each step can be represented as an M dimensional vector and now we want to binarize these vectors.",
            "And in order to do so, we draw a random vector from an M dimensional Gaussian distribution.",
            "This our vector R and then we compute the inner product between R and.",
            "Our snip vector XI.",
            "If this inner product is positive or zero, then we map the vector to one.",
            "If it is negative, we map it to 0.",
            "This is the binarization scheme that we apply to our snip data.",
            "You may have noticed this chance snip.",
            "Which is represented as an M dimensional vector in a single bit.",
            "Of course, it's very caused, kind of binarization, or of the information stored in the richness of vectors.",
            "So we do this again and again.",
            "So we we transform the original snip vector into a sequence of bits which are determined by different random vectors are.",
            "What is known from locality sensitive hashing?",
            "Is.",
            "That the probability that two different vectors will be hashed to the same bit.",
            "So both to 0 or both to one.",
            "Depends on the angle between these vectors.",
            "The smaller the angle.",
            "Between the two step vectors in our M dimensional space, the larger the probability that they will be.",
            "Mapped to the same bit both one above 2 zero.",
            "There's a geometric interpretation of what is happening here, and that is by drawing a random vector.",
            "You define a hyperplane.",
            "Which is orthogonal to this random vector and which goes through the origin of your M dimensional space.",
            "End.",
            "Two vectors are.",
            "Both hash to one or both has to 0 if they are on the same side of this hyperplane.",
            "If there are different sides of the hyperbole, if they point to different sides of the hyperplane, they will be hashed to different bit values, and the probability that the hyperplane will separate the two vectors from each other of course depends on the angle between the two vectors.",
            "That's the geometric interpretation illustration of what is going on here.",
            "The closer together the vectors are, the less likely it is that by drawing a random hyperplane you will separate them into different half spaces.",
            "This property is very important to us."
        ],
        [
            "Overcome the the third problem that we face to the third discrepancy between our setting and the one from the lightbulb algorithm.",
            "Which is that we want to compute Pearson correlation coefficient and not the Hamming distance.",
            "And in order to show that we can also maximize.",
            "The piece is called correlation coefficient.",
            "Using our lab algorithm.",
            "We have to recall that Pearson's correlation coefficient has a geometric interpretation as well.",
            "We all know it as the covariance between 2 random variables divided by their standard deviations.",
            "However.",
            "After centering the two vectors XI and XJ.",
            "The PSPS correlation coefficient is also.",
            "An equivalent to the cosine between these two center vectors XI and XJ.",
            "So now we have a link between everything that we want to compute.",
            "We know that Pearson's correlation coefficient.",
            "Is linked to the cosine of the angle between.",
            "The two vectors we know."
        ],
        [
            "At the angle.",
            "Is connected to the Hamming distance between our binarized vectors and we know that the lightbulb algorithm can compute the pair of vectors with the minimum Hamming distance with high probability.",
            "So we have the full path from.",
            "From Pearson correlation coefficient to hamming distance and we have the method to.",
            "To minimize to having this."
        ],
        [
            "It's."
        ],
        [
            "This gives rise to the following algorithm which we published in KDD.",
            "We binarize the original matrices which we call a zero and B0 in this pseudocode into A&B by locality sensitive hashing.",
            "We run the library algorithm on.",
            "The extended matrix, the first extended matrix that I described.",
            "We run it on the second extended matrix that I described.",
            "We record the maximally correlated pair on each of these extended matrices and the maximum of the two is the outcome.",
            "The output of our algorithm."
        ],
        [
            "We ran this algorithm on several datasets.",
            "To find out what the empirical runtime is, so we observe this empirically.",
            "This algorithm converges after runtime, which is proportional to end to the 1.5.",
            "And we measured this as being able to detect.",
            "At least 95% of the top 1000 snipped pairs in a given data set, which we had computed using our cluster or using our GPU, approaches to system interaction detection.",
            "So using this algorithm we can compute.",
            "Epistasis detection on a single computer rather than using our cluster here, our cluster with 1000 cores."
        ],
        [
            "And just to show the results.",
            "From the paper in the graphic.",
            "Let us have a look at this figure here.",
            "So the access is we have to recall among the top 1000 snippers as computed by an exhaustive enumeration and the exponent of the runtime to the base N, and you can see here that for an exponent of around 1.5 we reach.",
            "95% recall or more on these three different datasets.",
            "Is the ability to detect at least 950 out of the top 1000 Snip appears from Dicks source of enumeration, so 95% would be 950 after 1000.",
            "How many of these we found?"
        ],
        [
            "That's the.",
            "Point the alternative approach using GPU's with bathroom and Tony come tongue.",
            "Amuz is.",
            "Deficiency of graphical processing units to perform basic mathematical operations in parallel.",
            "These are heavily optimized for rendering, rendering graphics on your computer screen for updating the state of the pixels on your computer screen and these basic mathematical operations is also what we need in order to do epistasis detection, so we can use.",
            "This power of GPU's to perform a lot of basic mathematical operations in parallel, and to compute a lot of emphasizes test statistics in parallel.",
            "Still, what we're doing here is an exhaustive enumeration, and the speedup that we achieved using these GPU implementations is similar to the one that we achieved using the lightbulb algorithm and in a.",
            "International Genetics Consortium on headache diseases.",
            "We are now exploring with bedroom matters.",
            "The application of these methods to disable interaction.",
            "Alesis in clinical My Crane, another disease genetics consortia using our our software and our methods.",
            "In order to do some sleep interaction detection on diseases such as autism, schizophrenia, or depression."
        ],
        [
            "Other important aspects.",
            "In this field of developing multilocus models for genetics.",
            "By machine learning.",
            "Include.",
            "Prior knowledge, including prior knowledge on the relevance of snips into our models, we have one support vector machine approach from 2011 which can.",
            "Deal with prior knowledge about Snips.",
            "Another important aspect is that one has to account for the relatedness of individuals in these studies.",
            "For instance, Baraki worked on this in my lab measuring statistical significance of more complex multi locus models, also very.",
            "Difficult problem because once we move to these higher order combinations of snips.",
            "The space of potential solutions become so large that it is very hard to correctly quantify statistical significance and to also correctly account for multiple hypothesis testing.",
            "And the fourth problem that is now drawing a lot of attention is that one would like to predict multiple correlated phenotypes jointly.",
            "There's for instance work by Eric Singh and his Leopard County men on on this topic.",
            "How one can exploit correlations between phenotypes to get two more accurate predictions?",
            "There's older work on this in statistical genetics or synergetics has a lot of rich work on the statistical aspects of studying genetics data.",
            "What machine learning can contribute here is to scale these up to the large genome datasets that we have now.",
            "This is in fact a very good moment for me to stop today and tomorrow I'll continue further and explain to you what the future of barometric says.",
            "Thank you for today."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Welcome to you all to our first ITN Summer School and welcome to also the kickoff meeting for Marie Curie initial training network.",
                    "label": 0
                },
                {
                    "sent": "I'm happy to see you all here in tubing and and I'm happy that after more than three years of planning we now have reached a point at which we can officially declare this network founded.",
                    "label": 0
                },
                {
                    "sent": "I'll take.",
                    "label": 0
                },
                {
                    "sent": "The first 10 minutes of my time to give you a bit of background about the network, and then, as Chloe mentioned, I will present the first lecture.",
                    "label": 0
                },
                {
                    "sent": "Of this summer school.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Our network is a so-called FP 7.",
                    "label": 0
                },
                {
                    "sent": "Marie Curie initial training network.",
                    "label": 1
                },
                {
                    "sent": "FP7 is the framework program of European Union, the 7th of its kind to foster research and international collaborations in Europe.",
                    "label": 0
                },
                {
                    "sent": "In particular, the initial training networks the Itins are supposed to educate experts at the interface of different disciplines, so it's it's a program for educating the interdisciplinary experts of the future.",
                    "label": 0
                },
                {
                    "sent": "In our case, these two fields are machine learning and personalized medicine, or more specifically, if you look at the background of our ITN principle investigators interface of machine learning and statistical genetics.",
                    "label": 0
                },
                {
                    "sent": "I will come to the to the principle investigators who they are and also today ITN students in a minute here on this first slide you can see the logo of this summer school.",
                    "label": 0
                },
                {
                    "sent": "It's not yet the official logo of the 10 although we are going to have a vote on this in the Supervisory Board later on today and it's nicely showing this connection between machine learning and personalized medicine.",
                    "label": 0
                },
                {
                    "sent": "If your data matrix to represent machine learning, and here this well known symbol of medicine and both comes together in our ITN network.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now I'm going to present this network in different ways.",
                    "label": 0
                },
                {
                    "sent": "First of all, in numbers, so six countries are involved in this network.",
                    "label": 0
                },
                {
                    "sent": "Belgium, France, Germany, Spain, United Kingdom and the United States.",
                    "label": 1
                },
                {
                    "sent": "14 positions are funded by this network.",
                    "label": 0
                },
                {
                    "sent": "13 Early stage researcher positions.",
                    "label": 0
                },
                {
                    "sent": "These are PhD positions, so still official term for PhD position.",
                    "label": 0
                },
                {
                    "sent": "The European Union and one experienced researcher postdoc position at Formatics in Edinburgh.",
                    "label": 0
                },
                {
                    "sent": "The network right now includes twelve labs at 10 partner nodes, out of which eight are University or Research Institute nodes and two are industrial nodes.",
                    "label": 0
                },
                {
                    "sent": "Siemens infomatics.",
                    "label": 0
                },
                {
                    "sent": "The network runs officially for four years, so the official start date was first of January 2013.",
                    "label": 0
                },
                {
                    "sent": "The actual start date as it is today.",
                    "label": 0
                },
                {
                    "sent": "Our funding will run until December 2016.",
                    "label": 0
                },
                {
                    "sent": "We have in total up to 3.75 million euro of funding for the network as a whole per student.",
                    "label": 0
                },
                {
                    "sent": "We have three years of funding.",
                    "label": 0
                },
                {
                    "sent": "So the network is running a bit longer than each single PhD scholarship, such that we can accommodate different starting times after different students.",
                    "label": 0
                },
                {
                    "sent": "We promise to have two three month internships at other nodes per student.",
                    "label": 0
                },
                {
                    "sent": "So in the general rule is that we have these three columns, or in our network machine learning statistical genetics and their industrial applications and every each Esri.",
                    "label": 0
                },
                {
                    "sent": "So each student should be exposed to these three columns either by the PhD host or by the hosts by doing a second internship.",
                    "label": 0
                },
                {
                    "sent": "At two nodes of the other two from the other two columns.",
                    "label": 0
                },
                {
                    "sent": "There will be 4 summer schools, one per year, the first one as you can see, is in Tubingen in 2013.",
                    "label": 0
                },
                {
                    "sent": "In the next year we'll have summer school in the UK in the year after that in France and in the year after that, we'll have a summer school combined with the closing conference in Spain.",
                    "label": 0
                },
                {
                    "sent": "These are the numbers on our network.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now here's a different way of representing network as a map.",
                    "label": 1
                },
                {
                    "sent": "That's a good way to show you.",
                    "label": 0
                },
                {
                    "sent": "Who is involved in this network?",
                    "label": 0
                },
                {
                    "sent": "So let's start here from the top.",
                    "label": 0
                },
                {
                    "sent": "So the company Formatics from Edinburgh.",
                    "label": 1
                },
                {
                    "sent": "Is part of the network the University of Sheffield.",
                    "label": 0
                },
                {
                    "sent": "University of Liege.",
                    "label": 0
                },
                {
                    "sent": "In them, and are mean.",
                    "label": 0
                },
                {
                    "sent": "So I mean is mean Paristech in Paris.",
                    "label": 0
                },
                {
                    "sent": "Then the MPI is in Tuebingen.",
                    "label": 0
                },
                {
                    "sent": "It is to be precise, the MPI for intelligent systems into being that is involved the MPI for psychiatry in Munich and also in Munich.",
                    "label": 1
                },
                {
                    "sent": "Siemens Research and technology.",
                    "label": 0
                },
                {
                    "sent": "And from Spain.",
                    "label": 0
                },
                {
                    "sent": "University Carlos Press the Madrid and Research Center in Valencia and our intercontinental partner.",
                    "label": 0
                },
                {
                    "sent": "The Memorial Sloan Kettering Cancer Center in New York.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So who is involved in this network?",
                    "label": 0
                },
                {
                    "sent": "First of all, who are the principle investigators and I just I not only want to read out the names now, I would also like these persons to stand up such that we get to know each other.",
                    "label": 0
                },
                {
                    "sent": "That's one of the main purposes of this meeting, not only to give lectures but also to get to know each other.",
                    "label": 0
                },
                {
                    "sent": "And I think it's now the perfect time to start introducing.",
                    "label": 0
                },
                {
                    "sent": "Ourselves to each other, so from Belgium, from the University of Liege Professor, Crystal Feinstein.",
                    "label": 0
                },
                {
                    "sent": "They come, they come crystal.",
                    "label": 0
                },
                {
                    "sent": "From Paris, from in Paris Tech professor show Philly player.",
                    "label": 0
                },
                {
                    "sent": "And also from from Paris.",
                    "label": 0
                },
                {
                    "sent": "Florence temini.",
                    "label": 0
                },
                {
                    "sent": "From Spain we have from Madrid Fernando Palace goose.",
                    "label": 0
                },
                {
                    "sent": "You're kinda puzzle is not here from the United Kingdom University of Sheffield.",
                    "label": 1
                },
                {
                    "sent": "Neil Lawrence is not here yet, but he will give a course on Wednesday, Mac noses or it's not here yet, but Felix Arco from Formatics is here.",
                    "label": 0
                },
                {
                    "sent": "Welcome, Felix.",
                    "label": 0
                },
                {
                    "sent": "From the US gonna, but I haven't seen him yet, but maybe I missed him.",
                    "label": 0
                },
                {
                    "sent": "No?",
                    "label": 0
                },
                {
                    "sent": "Not yet.",
                    "label": 0
                },
                {
                    "sent": "From Germany from Munich, Siemens focus crisp.",
                    "label": 0
                },
                {
                    "sent": "Like in FOCA from the Max Planck Society from the Munich site for psychiatry.",
                    "label": 0
                },
                {
                    "sent": "Better Miller moosach.",
                    "label": 0
                },
                {
                    "sent": "From Tubingen banner chirkov.",
                    "label": 0
                },
                {
                    "sent": "And me.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And who are they?",
                    "label": 0
                },
                {
                    "sent": "ESRI's that we have recruited so far so it's if I didn't miscount 12 out of which eleven are here.",
                    "label": 0
                },
                {
                    "sent": "And they are now ordered in the same order in which we presented them.",
                    "label": 0
                },
                {
                    "sent": "To the European Union.",
                    "label": 0
                },
                {
                    "sent": "So from my lab Filippelli novice Lopez.",
                    "label": 0
                },
                {
                    "sent": "And Carl Johann Szymon Gabriel.",
                    "label": 0
                },
                {
                    "sent": "Come from the show cops Department.",
                    "label": 0
                },
                {
                    "sent": "Mr James Mick Murray.",
                    "label": 0
                },
                {
                    "sent": "From bathroom music, slap my venga.",
                    "label": 0
                },
                {
                    "sent": "I will learn how to pronounce your name correctly, hopefully in the course of the four years, so forgive me if I mispronounced him this time from Siemens Cristobal Esteban.",
                    "label": 0
                },
                {
                    "sent": "We come from the University of Sheffield Max Twizzlers.",
                    "label": 0
                },
                {
                    "sent": "From the University of Liege, Miss Carmona fouladi.",
                    "label": 0
                },
                {
                    "sent": "From and now it gets difficult from paradigm in Paris, Mr June Long Chau.",
                    "label": 0
                },
                {
                    "sent": "They come and also from bears Mr Dragon Longzhu Lu Lu.",
                    "label": 0
                },
                {
                    "sent": "Welcome.",
                    "label": 0
                },
                {
                    "sent": "From Madrid, Miss Melanie Fernandez Pradier.",
                    "label": 0
                },
                {
                    "sent": "From Valencia, who hasn't started yet conclude cubuk so he will join us at a later summer school.",
                    "label": 0
                },
                {
                    "sent": "Ann from New York.",
                    "label": 0
                },
                {
                    "sent": "E song he's not here yet, either you see, oh, you are here.",
                    "label": 0
                },
                {
                    "sent": "Oh sorry, welcome.",
                    "label": 0
                },
                {
                    "sent": "Become so these are all depends on the investigators and all the students that have joined the network so far are very important.",
                    "label": 0
                },
                {
                    "sent": "Person is Matthias who is still not.",
                    "label": 0
                },
                {
                    "sent": "He was still.",
                    "label": 0
                },
                {
                    "sent": "Taking care of the late registrations.",
                    "label": 0
                },
                {
                    "sent": "He has disappeared, but I will take another opportunity to introduce him.",
                    "label": 0
                },
                {
                    "sent": "Matias Friendly is the administrative coordinator of the network, and he's doing a wonderful job at this and he also works with Chloe, one of the main organizers of this summer school.",
                    "label": 0
                },
                {
                    "sent": "But I will come to the to the thank yous in my closing remarks on Friday.",
                    "label": 0
                },
                {
                    "sent": "When they come to next is the 1st.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Overview of our research topics.",
                    "label": 0
                },
                {
                    "sent": "So we have defined.",
                    "label": 0
                },
                {
                    "sent": "Four SAP research programs.",
                    "label": 0
                },
                {
                    "sent": "As part of this network, the first one being biomarker discovery, the second one being data integration, the third one being causal mechanisms of disease.",
                    "label": 1
                },
                {
                    "sent": "And 4th one being gene environment interactions.",
                    "label": 0
                },
                {
                    "sent": "All of our research topics which I'll come to at the end of my 4 hour course can be connected to at least one, often several, of these research goals.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which leads me to the scientific presentations, so I'm going to present.",
                    "label": 0
                },
                {
                    "sent": "4 hours of lectures on data mining in the life Sciences and the subtitle is so you can see on my first.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Slide here the path to personalized medicine.",
                    "label": 0
                },
                {
                    "sent": "I have three goals in these four hours of lectures.",
                    "label": 0
                },
                {
                    "sent": "The first one.",
                    "label": 0
                },
                {
                    "sent": "Being to describe this path to personalized medicine, how?",
                    "label": 0
                },
                {
                    "sent": "Bioinformatics is moving more and more towards this direction of exploring the opportunities for personalized medicine.",
                    "label": 1
                },
                {
                    "sent": "It's called one of my talk going to is.",
                    "label": 0
                },
                {
                    "sent": "To show you some data mining problems that arise in this context such that you have an idea of which data mining problems we are facing on the path to personalized medicine.",
                    "label": 1
                },
                {
                    "sent": "The third goal is that you get to know the research of my own research group, abit such that you have an idea of which topics we are working on and I try to reach these three goals in two hours of lecturing today and another two tomorrow morning.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In our network we are combining machine learning with bio medicine.",
                    "label": 0
                },
                {
                    "sent": "So the first important question is why is there a need for machine learning in bio medicine?",
                    "label": 0
                },
                {
                    "sent": "This need has been created by the high throughput technologies that have been developed over the last decades, including genome and RNA sequencing, compound screening, genotyping, chips, bioimaging only to name a few.",
                    "label": 1
                },
                {
                    "sent": "These technologies produce vast amounts of data.",
                    "label": 0
                },
                {
                    "sent": "We are now collecting whole genomes of hundreds of or even thousands of individuals.",
                    "label": 0
                },
                {
                    "sent": "We can screen 10s of thousands of compounds for their functional activity.",
                    "label": 0
                },
                {
                    "sent": "We can determine representative markers in genomes efficiently and at a low cost, and we can take high resolution images of cellular cellular processes in bioimaging.",
                    "label": 0
                },
                {
                    "sent": "All of these.",
                    "label": 0
                },
                {
                    "sent": "Molecular databases are growing at a much faster pace than our knowledge of biological processes, so we are more collecting more data than could ever be analyzed by manual annotation.",
                    "label": 1
                },
                {
                    "sent": "Therefore, we need machine learning methods to help us make sense to help us extract information from these large volumes of biological data.",
                    "label": 0
                },
                {
                    "sent": "And by the way, this picture here is showing BGI Hong Kong's or one side, at which this PGI Hong Kong is sequencing genomes with dozens and hundreds of machines in China put billions of dollars into this infrastructure.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I will describe how this field of applying computer science to biology evolved in three steps, and I'd chose some.",
                    "label": 0
                },
                {
                    "sent": "Titles which are a bit provocative for this, I called them classic bioinformatics, modern bioinformatics and future bioinformatics.",
                    "label": 0
                },
                {
                    "sent": "Classic bioinformatics is how the field started.",
                    "label": 0
                },
                {
                    "sent": "It started with a strong focus on molecular properties.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For instance.",
                    "label": 0
                },
                {
                    "sent": "Studying the properties of gene and protein sequences of whole genome sequences of protein structures or of chemical compounds.",
                    "label": 1
                },
                {
                    "sent": "As I've described before, for all of these, we can now collect large molecular databases of their properties.",
                    "label": 0
                },
                {
                    "sent": "And one of the main topics of bound for medics in the beginning was to infer properties of these molecules to give you a few concrete examples.",
                    "label": 0
                },
                {
                    "sent": "Very common topic in what I call a classic bound for mattix is to predict the function of a gene given its sequence.",
                    "label": 1
                },
                {
                    "sent": "Or the structure of a protein.",
                    "label": 0
                },
                {
                    "sent": "Given its sequence.",
                    "label": 0
                },
                {
                    "sent": "Or you are given a genome segment and you want to predict the exact boundaries of a gene given this genome sequence or within this genome segment.",
                    "label": 1
                },
                {
                    "sent": "And another classic topic which has been studied in chemoinformatics for decades, is to predict the function of a chemical compound given its molecular structure.",
                    "label": 1
                },
                {
                    "sent": "So we not only want to collect these these large databases of gene and protein sequences, structures and molecular compounds, we also want to understand.",
                    "label": 0
                },
                {
                    "sent": "The function, the biological role that these molecules play.",
                    "label": 0
                },
                {
                    "sent": "And machine learning has to play a role in this.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In particular, by establishing similarities between sequences, structures, molecules with known function, and those with unknown function so very common, and in my talk representative.",
                    "label": 0
                },
                {
                    "sent": "Example is that you are given a database of molecular compounds with known function and known structure and you are also given an user of compounds.",
                    "label": 0
                },
                {
                    "sent": "For which you know the the structure, but you don't know their function.",
                    "label": 0
                },
                {
                    "sent": "Now the idea is by finding.",
                    "label": 0
                },
                {
                    "sent": "The most similar or similar molecules in your database with known functions.",
                    "label": 0
                },
                {
                    "sent": "You will then infer the function of a new molecule.",
                    "label": 0
                },
                {
                    "sent": "So fundamental idea is that similarity in structure implies similarity in function.",
                    "label": 1
                },
                {
                    "sent": "This research topic is called exploring the structure, activity relationship and the example here shows three molecules that were examined whether they have an anti anthrax activity.",
                    "label": 0
                },
                {
                    "sent": "In this study from 2006, so that would be a typical example for research question.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "From classic bound formatics Now how do you answer such a question where you are given a molecular graph descriptor of the molecular structure of these molecules?",
                    "label": 0
                },
                {
                    "sent": "For each of the molecules in your database, and for each of the molecules for which you want to do function prediction.",
                    "label": 0
                },
                {
                    "sent": "And the algorithmic problem that you have to solve now is to.",
                    "label": 0
                },
                {
                    "sent": "Measure similarity between these molecular graphs and this includes two components, namely 2.",
                    "label": 0
                },
                {
                    "sent": "Quantify the structural similarity between these molecules and also to measure how similar the node, and if given the edge labels are between these graphs, so it's both topological similarity and attribute similarity that we care about.",
                    "label": 1
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Many different approaches have been proposed for comparing graphs to each other, so one large family is the family of methods that.",
                    "label": 0
                },
                {
                    "sent": "Perform graph isomorphism checking in subgraph isomorphism checking.",
                    "label": 1
                },
                {
                    "sent": "These methods either check whether two graphs are completely identical, whether they match exactly, or whether one of the graphs is an exact subgraph of the other graph.",
                    "label": 0
                },
                {
                    "sent": "No polynomial runtime algorithm is known for either of the two problems, so provides a morphism is checking.",
                    "label": 0
                },
                {
                    "sent": "Is even known to be NP hard.",
                    "label": 0
                },
                {
                    "sent": "In applications, these methods are a bit or not.",
                    "label": 0
                },
                {
                    "sent": "Only a bit are rather limited in that they don't allow for any mismatches between the two molecules, and we hardly observe exact matches.",
                    "label": 0
                },
                {
                    "sent": "Between entire molecules.",
                    "label": 0
                },
                {
                    "sent": "So this and the exponential runtime are severe limitation.",
                    "label": 0
                },
                {
                    "sent": "In practice, the second family of methods for comparing graphs to each other, also called graph edit distances.",
                    "label": 0
                },
                {
                    "sent": "The key idea here is that you are given two graphs as shown on the previous slide.",
                    "label": 0
                },
                {
                    "sent": "And now you want to transform the first graph into the second graph by a series of steps, and these steps include.",
                    "label": 0
                },
                {
                    "sent": "Adding or removing edges.",
                    "label": 0
                },
                {
                    "sent": "Adding or removing nodes and changing node and edge attributes.",
                    "label": 0
                },
                {
                    "sent": "And you define a cost function which assigns a cost to each of these transformation steps.",
                    "label": 0
                },
                {
                    "sent": "And the idea is that the two graphs are the more similar the cheaper it is.",
                    "label": 0
                },
                {
                    "sent": "To transform the first graph into the second graph.",
                    "label": 0
                },
                {
                    "sent": "So this approach.",
                    "label": 0
                },
                {
                    "sent": "His two important features first of all.",
                    "label": 0
                },
                {
                    "sent": "This cost function is both flexible.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Also difficult to set, so some.",
                    "label": 0
                },
                {
                    "sent": "Users of graph edit distance is present.",
                    "label": 0
                },
                {
                    "sent": "This user for cost function is a key feature as a key advantage.",
                    "label": 0
                },
                {
                    "sent": "Of course, elf graph edit distance is because you can adapt your cost function to your particular problem at hand and those who criticize graph edit distances say it's very hard to come up with the right cost function for your problem at hand, so it's an advantage and a disadvantage at the same time, what is.",
                    "label": 0
                },
                {
                    "sent": "In general, a disadvantage of graph, edited, edited, since this is the second point that it typically involves subgraph isomorphism checking as an intermediate step, so it has a very expensive substep.",
                    "label": 0
                },
                {
                    "sent": "This graph edit distance approach because you have to determine, given the two graphs, which parts which subparts of the two graphs are identical, such that you know which parts of the graphs don't have to be changed.",
                    "label": 0
                },
                {
                    "sent": "And this involves up graph, an isomorphism checking and isomorphism checking.",
                    "label": 0
                },
                {
                    "sent": "The third family are so called topological descriptors.",
                    "label": 0
                },
                {
                    "sent": "Very popular in Chemoinformatics, here the idea is you are given a graph and you map this graph to a feature vector, so rather than working on the graphs directly, you try to come up with the feature vector representation.",
                    "label": 0
                },
                {
                    "sent": "Off the graph.",
                    "label": 0
                },
                {
                    "sent": "This is a very popular approach.",
                    "label": 0
                },
                {
                    "sent": "Still it's it has some disadvantages.",
                    "label": 0
                },
                {
                    "sent": "If you transform a graph into a vector then you either lose some of this actually information represented by the graph, or you again suffer from exponential runtime effort.",
                    "label": 1
                },
                {
                    "sent": "For example, if you start in subgraphs of a given graph.",
                    "label": 0
                },
                {
                    "sent": "And the fourth family, which I'm going to talk about.",
                    "label": 1
                },
                {
                    "sent": "Alright, so called graph kernels that became popular in machine learning 10 years ago.",
                    "label": 0
                },
                {
                    "sent": "Two of the Seminole Papers were the ones by Kashima ET al and Gardner ET al, and this graph counts.",
                    "label": 1
                },
                {
                    "sent": "I connect three goals in which we want to contribute to the family of graph comparison methods.",
                    "label": 1
                },
                {
                    "sent": "The first one being we want to come up with methods that whose which can be computed in a polynomial runtime in the number of nodes in the graph.",
                    "label": 0
                },
                {
                    "sent": "The second goal being they are applicable to large graphs.",
                    "label": 0
                },
                {
                    "sent": "I'll talk about this in more detail in the following.",
                    "label": 1
                },
                {
                    "sent": "And the third goal being.",
                    "label": 0
                },
                {
                    "sent": "That they are applicable to graphs with attributes.",
                    "label": 0
                },
                {
                    "sent": "We're still working on this third goal, but we have some recent new results that I will at least touch in the later course of my lecture.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now what are kernels?",
                    "label": 0
                },
                {
                    "sent": "Some of you might be very familiar with kernels.",
                    "label": 0
                },
                {
                    "sent": "Some of you may never have heard of kernel functions, so I'll try to.",
                    "label": 0
                },
                {
                    "sent": "To summarize, the definition of kernels in ovated, neither both one nor ask too much of the other part of the audience so.",
                    "label": 0
                },
                {
                    "sent": "Kernel functions can be thought of as similarity measures between objects, and they derive from this up.",
                    "label": 0
                },
                {
                    "sent": "Direction is up field of machine learning in which we try to solve learning problems by moving points from their original space from the original data space to a feature space.",
                    "label": 0
                },
                {
                    "sent": "To give you a concrete example.",
                    "label": 0
                },
                {
                    "sent": "Look at this toy problem here.",
                    "label": 0
                },
                {
                    "sent": "This is a classification problem.",
                    "label": 0
                },
                {
                    "sent": "We have a class of green points in a class of red points.",
                    "label": 0
                },
                {
                    "sent": "And now for a new point for which we don't know whether it is red or green.",
                    "label": 0
                },
                {
                    "sent": "We want to be able to predict, but at this point belongs to red or to the green glass.",
                    "label": 0
                },
                {
                    "sent": "This could be done by introducing.",
                    "label": 0
                },
                {
                    "sent": "A bound between the region of the space in which red points are located in an image to green points are located.",
                    "label": 0
                },
                {
                    "sent": "And machinery exists for computing such boundaries.",
                    "label": 0
                },
                {
                    "sent": "If those are linear.",
                    "label": 0
                },
                {
                    "sent": "So either align in 2D or plane in 3D, or a hyperplane in higher dimensional spaces.",
                    "label": 0
                },
                {
                    "sent": "However, it's very hard to find like a separating circle, as it is shown here.",
                    "label": 0
                },
                {
                    "sent": "In fact, you cannot find the separating line here between the red and the green class.",
                    "label": 0
                },
                {
                    "sent": "So what this field of kernel machine learning does is that it moves the whole problem to to a feature space, so it Maps the points from the original space to feature space in which the two classes become linearly separable.",
                    "label": 1
                },
                {
                    "sent": "So now in this new space here you can find a separating line between the red and the green class, and then your classification algorithm will predict and you point to be a member of the green class if it is in the half in the right half space.",
                    "label": 0
                },
                {
                    "sent": "And to be a red point if it is in the left half space.",
                    "label": 0
                },
                {
                    "sent": "Colonels are nothing but.",
                    "label": 0
                },
                {
                    "sent": "Inner products in this feature space to which we map our original data points.",
                    "label": 0
                },
                {
                    "sent": "End.",
                    "label": 0
                },
                {
                    "sent": "What I just described is mapping to a feature space.",
                    "label": 0
                },
                {
                    "sent": "This could naively be done in 2 steps by first mapping each of the points from the original space through feature space and then measuring the similarity in this feature space and computing a classifier based on this similarity.",
                    "label": 0
                },
                {
                    "sent": "But in practice, we don't use this naive approach.",
                    "label": 0
                },
                {
                    "sent": "We rather do both steps in one single step by evaluating a kernel function on the on the data points in the original space.",
                    "label": 0
                },
                {
                    "sent": "So the kernel between objects in the original space corresponds to an inner product between the same objects in the feature space, which means we can solve.",
                    "label": 1
                },
                {
                    "sent": "This classification problem by performing operations in the original space.",
                    "label": 0
                },
                {
                    "sent": "Although we are actually solving the classification problem in the feature space, so we do, we solve the problem in the feature space implicitly without explicitly mapping the points to this feature space.",
                    "label": 0
                },
                {
                    "sent": "So now you know both the intuitive definition of a kernel.",
                    "label": 0
                },
                {
                    "sent": "It is a similarity measure between objects and the mathematical definition is an inner product between objects in this feature space.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now when I.",
                    "label": 0
                },
                {
                    "sent": "Talk about graph kernels.",
                    "label": 0
                },
                {
                    "sent": "I mean kernels on pairs of graphs, so I give I'm given two graphs.",
                    "label": 1
                },
                {
                    "sent": "As we said before and I want to measure the similarity between these two graphs.",
                    "label": 0
                },
                {
                    "sent": "There's also work by assuming Armani and others.",
                    "label": 0
                },
                {
                    "sent": "The term graph kernel refers to comparing two nodes within one single graph, but we compare objects that are one full graph each.",
                    "label": 0
                },
                {
                    "sent": "There are instance of a larger framework of so called our convolution kernels by haeussler.",
                    "label": 0
                },
                {
                    "sent": "The idea here is if you are given two such as objects, you decompose these objects into their substructures and then you compare these substructures pairwise a very simple graph corner.",
                    "label": 0
                },
                {
                    "sent": "Could be defined by decomposing two graphs into their set of nodes, so just counting.",
                    "label": 0
                },
                {
                    "sent": "For instance, the node attributes.",
                    "label": 0
                },
                {
                    "sent": "So making a histogram over node label frequencies and then comparing these histograms to each other, these node labels pairwise to each other.",
                    "label": 0
                },
                {
                    "sent": "That would be a very simple instance of the our convolution framework.",
                    "label": 0
                },
                {
                    "sent": "Once we have defined such a kernel between graphs, a graph, can we?",
                    "label": 0
                },
                {
                    "sent": "Have made the whole family of kernel methods applicable to graphs, and that's something special because this kernel is family of kernel methods includes methods for classification, regression, clustering to sample testing, principle, component analysis and many more.",
                    "label": 1
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In chemoinformatics hundreds of molecular descriptors have been defined which map a graph.",
                    "label": 0
                },
                {
                    "sent": "2A feature vector and you could argue that.",
                    "label": 0
                },
                {
                    "sent": "In order to define a graph kernel, we just have to use.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "One of these.",
                    "label": 0
                },
                {
                    "sent": "Molecular scripts descriptors.",
                    "label": 0
                },
                {
                    "sent": "As our mapping function FI and this is correct, so you could just apply.",
                    "label": 0
                },
                {
                    "sent": "One or several of these topological script descriptors from Chemoinformatics map a graph.",
                    "label": 0
                },
                {
                    "sent": "To a feature space and then compute some inner product between these feature vector representation of the graphs.",
                    "label": 1
                },
                {
                    "sent": "However, what we noticed over the years when trying to do function prediction using graph currents defined in this way is that these topological descriptor.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As I mentioned in my overview here, they scale poorly to very large graphs.",
                    "label": 0
                },
                {
                    "sent": "If you want to.",
                    "label": 0
                },
                {
                    "sent": "Look at non trivial subgraphs of these graphs.",
                    "label": 0
                },
                {
                    "sent": "Of course you can make a note label histogram over a large graph, but as soon as you move to more complex substructures of a graph then you ran into serious runtime problems and you could easily bring down.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A computing cluster by performing more complex comparisons between graphs or by computing a more complex feature vector representation between graphs.",
                    "label": 0
                },
                {
                    "sent": "So I end my lap and my first piece PhD student University work.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For a number of years on this question, how can we speed up these?",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Graph kernels dissimilarity measures.",
                    "label": 0
                },
                {
                    "sent": "Between graphs, two large graphs.",
                    "label": 0
                },
                {
                    "sent": "By large I mean not dozens of nodes but hundreds, thousands, millions of nodes, and in 2009 we came up with the following approach, which are which I'm going to describe in detail, which for large graphs.",
                    "label": 0
                },
                {
                    "sent": "Is Siri the state of the art method for computing similarity between them?",
                    "label": 0
                },
                {
                    "sent": "So how does this kernel work?",
                    "label": 0
                },
                {
                    "sent": "We call it device fellow Lemon Corner because it is based on ideas from a test of of graph isomorphism originally defined by the Russian researchers, vice fella and lemon in 1968.",
                    "label": 0
                },
                {
                    "sent": "And a funny anecdote is that the original paper is only published in Russian.",
                    "label": 0
                },
                {
                    "sent": "A summary is later on published in English.",
                    "label": 0
                },
                {
                    "sent": "But Nino knows Russian and she reads the original paper from 1968, so she wrapped the paper.",
                    "label": 0
                },
                {
                    "sent": "I only knew the result of the paper.",
                    "label": 1
                },
                {
                    "sent": "I tried to reconstruct the result that I knew was in the paper from the summary, but I couldn't and I haven't read the paper to this to this state, so we're given two graphs.",
                    "label": 0
                },
                {
                    "sent": "G&G prime to networks.",
                    "label": 0
                },
                {
                    "sent": "And they are not labeled these numbers here.",
                    "label": 0
                },
                {
                    "sent": "And the colors represent node attributes.",
                    "label": 0
                },
                {
                    "sent": "And now we want to measure similarity between these two graphs.",
                    "label": 0
                },
                {
                    "sent": "And now how can you do this in an efficient way?",
                    "label": 1
                },
                {
                    "sent": "They're all the approaches that I described before computing edit distances, deriving feature vector representations.",
                    "label": 0
                },
                {
                    "sent": "Computing topological descriptors.",
                    "label": 0
                },
                {
                    "sent": "We went for a different approach.",
                    "label": 0
                },
                {
                    "sent": "We followed the same procedures that Vice Felimon used in their test of isomorphism and.",
                    "label": 0
                },
                {
                    "sent": "What they did is the following for each.",
                    "label": 0
                },
                {
                    "sent": "Note in our original graph we.",
                    "label": 0
                },
                {
                    "sent": "Record the set of its neighbors.",
                    "label": 0
                },
                {
                    "sent": "So 45 we recorded it has a neighbor labeled 2, three and four.",
                    "label": 0
                },
                {
                    "sent": "In this repeat for every single node, so one has enabled 4 for example.",
                    "label": 0
                },
                {
                    "sent": "And now.",
                    "label": 0
                },
                {
                    "sent": "In the second step, we sort these sets so we define an order over these node attributes.",
                    "label": 0
                },
                {
                    "sent": "Here it's a numerical order over these numbers and sort these neighbors in ascending order 05.",
                    "label": 0
                },
                {
                    "sent": "The neighbors of five are two 3, four in ascending order.",
                    "label": 0
                },
                {
                    "sent": "This will repeat for every node in our two graphs.",
                    "label": 0
                },
                {
                    "sent": "Now in this step see here in this.",
                    "label": 0
                },
                {
                    "sent": "Step three, we hash.",
                    "label": 0
                },
                {
                    "sent": "These mighty sets, or as we call them these neighborhood strings that represent the label of a note and the label of its neighbors in the following way.",
                    "label": 0
                },
                {
                    "sent": "If two nodes have exactly the same neighborhood string.",
                    "label": 0
                },
                {
                    "sent": "Such as these two notes here.",
                    "label": 0
                },
                {
                    "sent": "Then they are mapped to the same number.",
                    "label": 0
                },
                {
                    "sent": "So one in four is mapped to 623, which is.",
                    "label": 0
                },
                {
                    "sent": "Which note here this note here is mapped to 7 and so on and so forth, so this is called in computer science, a hashing operation.",
                    "label": 0
                },
                {
                    "sent": "So we hash this neighborhood strings into integers and then in the fourth step we use these hash values.",
                    "label": 0
                },
                {
                    "sent": "S knew note attributes in our graphs.",
                    "label": 1
                },
                {
                    "sent": "So if 1 four is hash 26, then the node that previously was labeled one is now labeled 6.",
                    "label": 0
                },
                {
                    "sent": "And the testifies Amorphism Bivi Spelemann relied on the fact that if the set of GNU labels that you generate at the end of 1 iteration in the two graphs, PNG prime is not the same, then they cannot be isomorphic.",
                    "label": 0
                },
                {
                    "sent": "Which is correct.",
                    "label": 0
                },
                {
                    "sent": "However, there are some pathological cases in which even after many iterations, the two graphs have the same multi set of labels, but they're still not isomorphic and therefore this approach didn't solve the graph isomorphism problem but.",
                    "label": 0
                },
                {
                    "sent": "As it turns out, for us it can still be used to define a very efficient to compute similarity measure between graphs.",
                    "label": 0
                },
                {
                    "sent": "Because all you have to do is.",
                    "label": 0
                },
                {
                    "sent": "You represent the graph as a histogram over these know knew node label frequencies after each iteration.",
                    "label": 0
                },
                {
                    "sent": "And this is.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Shown on the following slide so you can start.",
                    "label": 0
                },
                {
                    "sent": "By just counting the frequency of each label in the.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the graph, so you go to these graphs.",
                    "label": 0
                },
                {
                    "sent": "Here you make a histogram over the node label frequencies.",
                    "label": 0
                },
                {
                    "sent": "Here these frequency.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "These are the first part of your feature vector representation of your graphs, and then you repeat this histogram construction, sorry.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At the end of such an iteration of device Felimon algorithm, so you count the frequencies of these labels after the graphs have been re labeled.",
                    "label": 0
                },
                {
                    "sent": "And of course you can repeat this whole procedure over and over again, so once you've reached this step here you can go back, compute enabled strings, hash them and Re label the graph again.",
                    "label": 0
                },
                {
                    "sent": "Now what are you doing by constructing?",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Such a feature vector representation of a graph well?",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You're looking at what we call subtree like patterns.",
                    "label": 0
                },
                {
                    "sent": "They are not subtrees of the original graphs in the strict sense, because there may be repetitions of nodes, but still the data structure that we look at.",
                    "label": 0
                },
                {
                    "sent": "Resembles a tree because we start at one node at one for example, and then visit the neighbors of that node 123 and six, and then we visit their neighbors.",
                    "label": 0
                },
                {
                    "sent": "So by iteratively repeating the virtual lemonade with them, we can V compare larger and larger neighborhoods in the two graphs, which are, which can be represented.",
                    "label": 0
                },
                {
                    "sent": "As a tree structure, but which are not strict upgrade subtrees of the original graph because we may repeat some nodes in here.",
                    "label": 0
                },
                {
                    "sent": "So that's what we do.",
                    "label": 0
                },
                {
                    "sent": "We look at larger and larger subtree like patterns in the two graphs and we just.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Count them so we get a concatenation of many different histograms over node label frequencies.",
                    "label": 0
                },
                {
                    "sent": "At the end of each iteration of the West Valley Mall algorithm, and then in the end all that we have to do is we have to compare these feature vectors for the two graphs that we want to compare.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now, how expensive is it to compute such a kernel?",
                    "label": 0
                },
                {
                    "sent": "It's amazingly cheap.",
                    "label": 0
                },
                {
                    "sent": "And for us this was really a breakthrough because before we didn't know how to compute these kernels in around time, which is less than quadratic in the number of nodes in the two graphs.",
                    "label": 0
                },
                {
                    "sent": "So as I said, there are three steps in this procedure.",
                    "label": 0
                },
                {
                    "sent": "The first one being.",
                    "label": 0
                },
                {
                    "sent": "That we represent each node as a sorted list of its neighbors.",
                    "label": 1
                },
                {
                    "sent": "This requires a runtime of all of M. The Ms number of edges in the graph I just have to run through all edges and can thereby record enables over note.",
                    "label": 0
                },
                {
                    "sent": "Then we hash these.",
                    "label": 0
                },
                {
                    "sent": "Neighborhood strings we map identical neighborhood strings to the same integer.",
                    "label": 0
                },
                {
                    "sent": "This can also be done in a runtime which is linear in the number of edges.",
                    "label": 1
                },
                {
                    "sent": "And then once we have computed the hash values, we re label the nodes in the graph.",
                    "label": 0
                },
                {
                    "sent": "This is only linear in the number of nodes N in the graph.",
                    "label": 0
                },
                {
                    "sent": "What often provokes questions is the second step.",
                    "label": 0
                },
                {
                    "sent": "How can the second step here?",
                    "label": 0
                },
                {
                    "sent": "Be performed in linear runtime and I want to give a few hints and details on how this is done, because this is the most complex step in here, so we have all of these neighborhood strings.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In our example.",
                    "label": 0
                },
                {
                    "sent": "And the first question is, can we really sort each neighborhood string in linear time?",
                    "label": 0
                },
                {
                    "sent": "In the number of edges and the answer is yes, we can do that by by using bucket sort because our graphs are of finite size.",
                    "label": 0
                },
                {
                    "sent": "There's only a finite alphabet from which our discrete, no no distributes come.",
                    "label": 0
                },
                {
                    "sent": "So the number of buckets for bucket sort is limited.",
                    "label": 0
                },
                {
                    "sent": "By at most the number of nodes in the graphs.",
                    "label": 0
                },
                {
                    "sent": "So what we do is we create a bucket for all letters in our alphabet.",
                    "label": 0
                },
                {
                    "sent": "In this example, here we would create a bucket for one 234 up to five.",
                    "label": 0
                },
                {
                    "sent": "So we have 5 packets and then.",
                    "label": 0
                },
                {
                    "sent": "We go to each neighborhood string and start throwing.",
                    "label": 0
                },
                {
                    "sent": "The letters into these buckets while recording for each letter that we throw into a bucket which string it came from.",
                    "label": 0
                },
                {
                    "sent": "Once we have done that, we have distributed all the nodes over these buckets.",
                    "label": 0
                },
                {
                    "sent": "We go through the buckets in ascending order, so from one to six and we start reassembling the neighborhood strings.",
                    "label": 0
                },
                {
                    "sent": "By construction, now all enabled strings are sorted.",
                    "label": 0
                },
                {
                    "sent": "And this is all linear time because I have to perform.",
                    "label": 0
                },
                {
                    "sent": "One step per note in so once for throwing him into the bucket and one step for going through the bucket so it's 2 steps to be precise per note.",
                    "label": 0
                },
                {
                    "sent": "So now I have these sorted neighborhood strings.",
                    "label": 0
                },
                {
                    "sent": "How can I efficiently find out if two neighborhood strings are the same?",
                    "label": 0
                },
                {
                    "sent": "That's the next puzzling question.",
                    "label": 0
                },
                {
                    "sent": "And here again, you need.",
                    "label": 0
                },
                {
                    "sent": "A special kind of sorting algorithm.",
                    "label": 0
                },
                {
                    "sent": "You need radix sort.",
                    "label": 0
                },
                {
                    "sent": "Radix sort allows you to sort a set of strings in a runtime, which is linear in the total length of these strings, and the trick is that you start.",
                    "label": 0
                },
                {
                    "sent": "Sorting the strings as you can see here the strings here are sorted.",
                    "label": 0
                },
                {
                    "sent": "And how do you achieve this?",
                    "label": 0
                },
                {
                    "sent": "Using Radix sort, you start by sorting these strings according to their last.",
                    "label": 0
                },
                {
                    "sent": "Number according to their last letter.",
                    "label": 0
                },
                {
                    "sent": "To be precise.",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 0
                },
                {
                    "sent": "You proceed.",
                    "label": 0
                },
                {
                    "sent": "To the first part, last second but last letter, and so on and so forth, thereby slowly bringing the strings into the correct order, and it can be shown that this is also an effort which is done, which is a linear in the number of strings.",
                    "label": 0
                },
                {
                    "sent": "The question to ask is how can can I guarantee that this operation is really only linear in the number of edges in the graph?",
                    "label": 0
                },
                {
                    "sent": "If these neighborhoods can be of different size?",
                    "label": 0
                },
                {
                    "sent": "Well, this can be achieved by running through all of the strings once and recording how long they are.",
                    "label": 0
                },
                {
                    "sent": "So you make a histogram over the length of the strings and you only and then you have the information of how long a string is an in which steps of radix sort.",
                    "label": 0
                },
                {
                    "sent": "You have to consider a certain string depending on its total length, so thereby you avoid that the algorithm scales in the number of nodes times the number.",
                    "label": 0
                },
                {
                    "sent": "Of maximum neighbors over of a node.",
                    "label": 0
                },
                {
                    "sent": "Thereby you achieve that it is only really only linear in the number of edges, so there are a lot of sorting tricks in here which make it possible that this is really oh of M in its overall runtime.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We can repeat this this whole procedure age times.",
                    "label": 0
                },
                {
                    "sent": "And therefore the overall runtime is O of M * H for capital N graph.",
                    "label": 0
                },
                {
                    "sent": "So if you want to compute this for whole collection of capital N graphs, we can easily compute the kernel pair pair capital N ^2 * M * H would be the runtime.",
                    "label": 1
                },
                {
                    "sent": "What is faster in practice is to compute the feature vector representation for all for all graphs explicitly, and then to compute the kernel matrix from this explicit representation of.",
                    "label": 0
                },
                {
                    "sent": "Of each graph as a feature vector.",
                    "label": 0
                },
                {
                    "sent": "So in our experiments this part here number of graphs, times number of edges, times, sum of iterations absolutely dominates.",
                    "label": 0
                },
                {
                    "sent": "The runtime.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And this is also shown here on the next slide, on which you can see.",
                    "label": 0
                },
                {
                    "sent": "That computing this feature vector representation of the graphs explicitly.",
                    "label": 0
                },
                {
                    "sent": "Is just called global.",
                    "label": 0
                },
                {
                    "sent": "Here is much faster than a knife approach which computer just iterates through all pairs of graphs and computes their similarity.",
                    "label": 0
                },
                {
                    "sent": "So here global scale is linear in the number of graphs N in the number of iterations H. In the graph density, which is the number of edges per node and quadratically in the number of nodes N depending on the number of edges.",
                    "label": 1
                },
                {
                    "sent": "Of course in the graph.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we also showed.",
                    "label": 0
                },
                {
                    "sent": "That this type of graph kernel is absolutely competitive with other graph coins that have been defined.",
                    "label": 0
                },
                {
                    "sent": "It is on small graphs as good on classification benchmarks and larger graphs which have hundreds of nodes.",
                    "label": 0
                },
                {
                    "sent": "It is the best performing method both in terms of accuracy and in terms of runtime.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now you have an idea of what a typical question in what I call classic band formatics is.",
                    "label": 0
                },
                {
                    "sent": "Another example would be sequence alignment finding.",
                    "label": 0
                },
                {
                    "sent": "Similar subsequences, similar substrings in two given DNA or protein sequences, and they are very famous methods like Blast for.",
                    "label": 0
                },
                {
                    "sent": "For answering this question and there are even string kernels that try to find matching substrings.",
                    "label": 0
                },
                {
                    "sent": "In biological sequences.",
                    "label": 0
                },
                {
                    "sent": "Now the next step in bound for Matics in modern bioinformatics, which is now probably at least 15 years old.",
                    "label": 0
                },
                {
                    "sent": "Is to move away from the focus on molecules and their properties and to focus on individuals and the.",
                    "label": 0
                },
                {
                    "sent": "Key technology which has been.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Used for this were microarrays.",
                    "label": 0
                },
                {
                    "sent": "In the beginning, microarrays allow you to measure the all gene expression levels in a given sample.",
                    "label": 1
                },
                {
                    "sent": "This technology has been out for a while.",
                    "label": 0
                },
                {
                    "sent": "It has been complemented by other properties that allow you to measure the the characteristics, the molecular characteristics of an individual.",
                    "label": 0
                },
                {
                    "sent": "So-called genotyping chips allow you to determine the Geno type of an individual, so they allow you to measure representative markers representative positions in the genome of an individual which capture the genetic properties of this individual and even.",
                    "label": 0
                },
                {
                    "sent": "More.",
                    "label": 0
                },
                {
                    "sent": "Yep, demanding is the next large scale technology which is genome sequencing.",
                    "label": 0
                },
                {
                    "sent": "It allows you to determine the genome sequence of an individual or or also recently via RNA sequencing to generate a transcriptomic profile of an individual.",
                    "label": 1
                },
                {
                    "sent": "So in summary, it is as it is stated on this slide here.",
                    "label": 1
                },
                {
                    "sent": "High throughput technologies now enable to collection of molecular information on individuals.",
                    "label": 0
                },
                {
                    "sent": "As you can see here, the cost for these technologies is dropping dramatically.",
                    "label": 0
                },
                {
                    "sent": "Even faster than most law would imply as a genome sequencing is becoming cheaper and cheaper and collecting large collections of data now on individuals not only on molecules is becoming more and more affordable.",
                    "label": 0
                },
                {
                    "sent": "And an option.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then machine learning was interested.",
                    "label": 0
                },
                {
                    "sent": "In this type of modern bound formatics, from the very very beginning, because there are some obvious questions to ask.",
                    "label": 0
                },
                {
                    "sent": "For instance, if I jump back several slides to my toy.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Example here.",
                    "label": 0
                },
                {
                    "sent": "One question is.",
                    "label": 0
                },
                {
                    "sent": "If I have gene expression levels for a large collection of patients.",
                    "label": 0
                },
                {
                    "sent": "Which star who suffer from different diseases?",
                    "label": 0
                },
                {
                    "sent": "Can I then diagnose which disease a particular patient suffers from by using such machine learning techniques?",
                    "label": 0
                },
                {
                    "sent": "Or can I detect clusters of patients that are similar on there on the molecular level and which forms up types of the disease?",
                    "label": 0
                },
                {
                    "sent": "It would be a clustering question.",
                    "label": 0
                },
                {
                    "sent": "Or can I detect genes that are highly active or deactivated, inactive in in sick individuals?",
                    "label": 0
                },
                {
                    "sent": "All of these classification, clustering and feature selection problems have been studied in much detail on these gene expression data.",
                    "label": 0
                },
                {
                    "sent": "However.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It is fair to admit that very often, and I also include worked on this domain, so I'm not excluding myself very often in this domain.",
                    "label": 0
                },
                {
                    "sent": "The results were not that satisfying to put its diplomatic.",
                    "label": 0
                },
                {
                    "sent": "2011 there was even an article in PLOS Computational Biology saying that most random gene expression signatures are significantly associated with breast cancer outcome.",
                    "label": 1
                },
                {
                    "sent": "Sounds a bit strange to someone with a statistics background how.",
                    "label": 0
                },
                {
                    "sent": "A random gene expression signature can be statistically significantly associated, and how most random gene expression signatures can be significantly associated.",
                    "label": 0
                },
                {
                    "sent": "Becausw significant is usually defined on being unlike most random.",
                    "label": 0
                },
                {
                    "sent": "The instances of the data better what they mean in this article is that if you use a published cancer signature also a list of genes that are known to be involved or speculated to be involved in cancer and predict breast cancer outcome using this published list of genes.",
                    "label": 0
                },
                {
                    "sent": "And you compare this to a randomly drawn set of genes in their experiments.",
                    "label": 0
                },
                {
                    "sent": "Then there's no significant difference between the results that you obtain.",
                    "label": 0
                },
                {
                    "sent": "End.",
                    "label": 0
                },
                {
                    "sent": "One major reason for this, for the problems that we encounter here, is that the number of dimensions that we're dealing with this so much larger the number of samples.",
                    "label": 0
                },
                {
                    "sent": "That that we work with in most of these datasets.",
                    "label": 0
                },
                {
                    "sent": "So usually we are looking at thousands of genes, but only on a large datasets hundreds of gene expression profiles, so there's a lot of room for.",
                    "label": 0
                },
                {
                    "sent": "For overfitting, and it's very hard to solve this feature selection problem.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "On the gene expression data still.",
                    "label": 0
                },
                {
                    "sent": "I don't want to make a general statement about the field as a whole.",
                    "label": 0
                },
                {
                    "sent": "There are some examples of success.",
                    "label": 0
                },
                {
                    "sent": "There are some examples where gene expression levels have been even approved for.",
                    "label": 0
                },
                {
                    "sent": "For personalized medicine.",
                    "label": 0
                },
                {
                    "sent": "For checking whether a certain person should receive a certain treatment.",
                    "label": 0
                },
                {
                    "sent": "And there were even other.",
                    "label": 0
                },
                {
                    "sent": "Examples of success in which phenotype prediction worked really well, and one of these I noticed when after moving to tubing only a few months after I arrived in Tubingen, I read in current biology about a genetic test that predicts eye color in Dutch men with 90% accuracy and I wasn't a statistical geneticist at the time.",
                    "label": 1
                },
                {
                    "sent": "My background was mainly machine learning, so I wondered by is this example so different from the gene expression from many gene expression studies, and why?",
                    "label": 0
                },
                {
                    "sent": "If this works for eye color in Dutch men, can't we predict other phenotypes?",
                    "label": 0
                },
                {
                    "sent": "Complex phenotypes with the same accuracy?",
                    "label": 0
                },
                {
                    "sent": "And for the statistical analysis among you, this may all sound trivial, but this is how I experienced this or or got to learn this as a machine learner and this is maybe interesting to some of our students who have a technical background.",
                    "label": 0
                },
                {
                    "sent": "So why can't we predict other complex diseases or phenotypes such as diabetes, autism, depression, track response, or plant growth?",
                    "label": 0
                },
                {
                    "sent": "To name an example from genetics with the same accuracy as.",
                    "label": 0
                },
                {
                    "sent": "These researchers from the Netherlands were able to predict eye color in Dutch men well.",
                    "label": 0
                },
                {
                    "sent": "The differences in this study value at all the jeans that are involved in eye color pigmentation are already known.",
                    "label": 0
                },
                {
                    "sent": "It is 8 genes which they used and in these jeans they just counted the number of mutations or do or to be more precise, number of deviations from the reference genome in these eight jeans.",
                    "label": 0
                },
                {
                    "sent": "Just the total count of these deviations was enough.",
                    "label": 0
                },
                {
                    "sent": "To get a very good predictor of eye color in in Dutch men.",
                    "label": 0
                },
                {
                    "sent": "So this particular aspect distinguishes this application from.",
                    "label": 0
                },
                {
                    "sent": "The phenotype prediction problem for all of these other complex phenotypes and diseases for diseases such as diabetes, depression or autism we don't know.",
                    "label": 0
                },
                {
                    "sent": "Many genes that may be involved in these diseases we know a few candidate genes, but there's still a lot to explore and we still don't know all the.",
                    "label": 0
                },
                {
                    "sent": "Ordenes, let alone the genetic mechanisms involved in these diseases, and therefore.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The genetics community and this is now we're moving from research topics in machine learning to research base in statistical genetics.",
                    "label": 0
                },
                {
                    "sent": "Therefore the statistical genetics community tries to find these jeans that are involved in complex phenotypes in large international genetics consortia via so-called genome wide Association studies.",
                    "label": 0
                },
                {
                    "sent": "And I'll summarize what these are for those of you who don't have a statistical genetics background.",
                    "label": 0
                },
                {
                    "sent": "Very broadly speaking, in a genome wide Association study, we want to compute.",
                    "label": 0
                },
                {
                    "sent": "Correlations between phenotypic variation and genotypic variation.",
                    "label": 0
                },
                {
                    "sent": "I've shown a toy example here.",
                    "label": 0
                },
                {
                    "sent": "We are given a group of plants that differ in a particular phenotype.",
                    "label": 0
                },
                {
                    "sent": "Some of them are high at all.",
                    "label": 0
                },
                {
                    "sent": "Some of them are short, so this is the phenotype and the phenotypic variation that we're looking at.",
                    "label": 0
                },
                {
                    "sent": "Height in plants and for each of these plants we are given a number of.",
                    "label": 0
                },
                {
                    "sent": "Genetic markers shown here as these little dots and they are given in two colors.",
                    "label": 0
                },
                {
                    "sent": "Let us define orange to be.",
                    "label": 0
                },
                {
                    "sent": "In agreement with the reference genome.",
                    "label": 0
                },
                {
                    "sent": "And blue.",
                    "label": 0
                },
                {
                    "sent": "As a deviation from the reference genome and each.",
                    "label": 0
                },
                {
                    "sent": "Horizontal line is one of these genetic markers and now in genome wide Association size we want to compute which of these markers.",
                    "label": 0
                },
                {
                    "sent": "Correlate most with variation in the phenotype.",
                    "label": 1
                },
                {
                    "sent": "These markets, and it's very important to know, are usually single nucleotide polymorphism's, the so called snips.",
                    "label": 1
                },
                {
                    "sent": "So single basis that may differ between individuals and you'll hear a lot more about this in our talks.",
                    "label": 0
                },
                {
                    "sent": "And when you read papers and so on.",
                    "label": 0
                },
                {
                    "sent": "So this term should be known to everyone, so may also be called genetic locus or genomic variant.",
                    "label": 1
                },
                {
                    "sent": "If you want to use a more broad.",
                    "label": 0
                },
                {
                    "sent": "Term the problems did the typical problems I have to give you an idea of this that we work with in in such genome wide Association studies?",
                    "label": 0
                },
                {
                    "sent": "Is that we have somewhere between 100,000 and 10,000,000 snips per genome, and today is at least the ones that we we look at.",
                    "label": 0
                },
                {
                    "sent": "The range from 100 individuals to 200,000 at most.",
                    "label": 0
                },
                {
                    "sent": "So for instance, for human height and for clinical migraine, 200,000 patients have now been collected by different hospital, so it's not that that everyone in these consortia has access to 200,000.",
                    "label": 0
                },
                {
                    "sent": "And patient genotypes.",
                    "label": 0
                },
                {
                    "sent": "But the total collection of patients would be 200,000.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now, how are the results from such a genome wide Association study reported?",
                    "label": 0
                },
                {
                    "sent": "They are reported using a so called Manhattan Plot.",
                    "label": 0
                },
                {
                    "sent": "One of which is shown here for phenotype from a plant model Organism.",
                    "label": 0
                },
                {
                    "sent": "The X axis are positions on the genomes or each point of the axis represents snip.",
                    "label": 0
                },
                {
                    "sent": "the Y axis is representing minus log 10 of the P value of the strength of Association between this snip and the phenotype.",
                    "label": 0
                },
                {
                    "sent": "So the higher point on this Y axis, the stronger the Association between this snip and the phenotype.",
                    "label": 0
                },
                {
                    "sent": "This is called a Manhattan plot because if you have a lot of strong associations between the phenotype and Geno type, then you have peaks here which look like the skyscrapers.",
                    "label": 0
                },
                {
                    "sent": "In in Manhattan, this plot looks more like Tubingen and.",
                    "label": 0
                },
                {
                    "sent": "There is very only isolated larger buildings.",
                    "label": 0
                },
                {
                    "sent": "And the Bonferroni threshold here.",
                    "label": 0
                },
                {
                    "sent": "This is the threshold that you have to pass in order for your strength of Association being significant.",
                    "label": 0
                },
                {
                    "sent": "We're performing a lot of statistical tests here.",
                    "label": 0
                },
                {
                    "sent": "Just this.",
                    "label": 0
                },
                {
                    "sent": "As a side remark, and therefore we have to correct for this multiple hypothesis testing.",
                    "label": 0
                },
                {
                    "sent": "And so we have to avoid that we get positive results just by random chance.",
                    "label": 0
                },
                {
                    "sent": "So on and the point that would be above this line would be a would be a statistically significant observation or correlation between genotype and phenotype.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now using this approach.",
                    "label": 0
                },
                {
                    "sent": "More.",
                    "label": 0
                },
                {
                    "sent": "Then 1200 new disease loci were detected over the last decade.",
                    "label": 1
                },
                {
                    "sent": "However, and there are even numbers that are there, some even cite higher numbers.",
                    "label": 0
                },
                {
                    "sent": "This is from Eric Lenders 10 year anniversary paper for the sequencing of the human genome.",
                    "label": 1
                },
                {
                    "sent": "At the same time, it's disappointing that the phenotypic variance explained by these loci.",
                    "label": 0
                },
                {
                    "sent": "Is disappointingly low.",
                    "label": 1
                },
                {
                    "sent": "For hardly any disease, it's it's more than 20% will have some examples on the following slide and and statistical genetics.",
                    "label": 0
                },
                {
                    "sent": "Even coined a term for this phenomenon is the phenomenon of missing heritability, so we may find snips that are correlated with phenotypic variation, but these statistically significantly associated snips only explain a small fraction of the phenotypic variance that we observe, and even of the heritable.",
                    "label": 0
                },
                {
                    "sent": "Yeah, component of these traits which we observe in twin studies or in family pedigrees.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To give you an idea of dismissing heritability are here side a few numbers from this paper by Eric Lander an for very few common traits is too.",
                    "label": 0
                },
                {
                    "sent": "Is the explained heritable component larger than 50% type one diabetes and fetal hemoglobin levels are some examples for this.",
                    "label": 0
                },
                {
                    "sent": "For some trades it is between 20 and 30%.",
                    "label": 0
                },
                {
                    "sent": "For example, Crohn's disease and lipid levels.",
                    "label": 1
                },
                {
                    "sent": "For most diseases this explained heritability and explained variance is less than 20%.",
                    "label": 0
                },
                {
                    "sent": "For instance, autism height and schitzophrenia belong to this class.",
                    "label": 0
                },
                {
                    "sent": "Explained heritability is in this context the phenotypic variance explained by known variants over the variance explained by all variants.",
                    "label": 1
                },
                {
                    "sent": "So if we know that a certain trait is heritable.",
                    "label": 0
                },
                {
                    "sent": "By 80% for example, and we notice from a pedigree or from a twin study, and then we determine snips that are associated with this variation in the phenotype, and then we divide the variance that can be explained.",
                    "label": 0
                },
                {
                    "sent": "By these nips by the variance which can be explained from the heritable component of this disease, and that's the explained heritability of disease over disease.",
                    "label": 0
                },
                {
                    "sent": "In two papers which appeared over last two years, lender and colleagues speculate that there may be reasons for this missing heritability.",
                    "label": 0
                },
                {
                    "sent": "For, for instance, what they claim or speculate, and it's just speculation, is that maybe our estimates of overall heritability.",
                    "label": 0
                },
                {
                    "sent": "So the denominator of this formula here may be too large because they ignore gene gene interactions and gene environment interactions.",
                    "label": 0
                },
                {
                    "sent": "So that's a hypothesis which they brought forward a year ago.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well, this was your question no?",
                    "label": 0
                },
                {
                    "sent": "It's true OK?",
                    "label": 0
                },
                {
                    "sent": "So we'll come exactly to this debate.",
                    "label": 0
                },
                {
                    "sent": "What is the reason now?",
                    "label": 0
                },
                {
                    "sent": "There are many other potential reasons for missing heritability, and this is heavily debated.",
                    "label": 1
                },
                {
                    "sent": "The statistical genetics community, and a lot of different opinions on this and you just heard that bedroom and Florence agree with Eric Lander and.",
                    "label": 0
                },
                {
                    "sent": "And Crystal also so all.",
                    "label": 0
                },
                {
                    "sent": "General agreement, that's that's nice.",
                    "label": 0
                },
                {
                    "sent": "That Eric Lander is right.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that these heritability estimates may be inflated, that we may overestimate how heritable certain traits and complex diseases are.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So when you look at the debate.",
                    "label": 0
                },
                {
                    "sent": "In statistical genetics about the potential reasons for missing heritability.",
                    "label": 1
                },
                {
                    "sent": "Then from my perspective, as a former almost pure machine learner, three points tend to reoccur in this debate.",
                    "label": 0
                },
                {
                    "sent": "First of all, one point is most current analysis neglect the additive or multiplicative effects between loci.",
                    "label": 1
                },
                {
                    "sent": "So as I showed you as I showed you in the Manhattan lots, we compute correlations between a single snip and a phenotype.",
                    "label": 0
                },
                {
                    "sent": "However, it's biologically very possible that many loci many genes are involved in a complex trait.",
                    "label": 0
                },
                {
                    "sent": "And it may be more realistic to move from the single locus perspective to a systems biology perspective and to study the polygenic rather than the monogenic architecture of complex traits.",
                    "label": 0
                },
                {
                    "sent": "So that's one point moving to polygenic architectures.",
                    "label": 0
                },
                {
                    "sent": "The second point is that.",
                    "label": 0
                },
                {
                    "sent": "The effect size.",
                    "label": 0
                },
                {
                    "sent": "Off single snips of single loci is maybe smaller than one first had hoped for, or had speculated.",
                    "label": 1
                },
                {
                    "sent": "So these small effect sizes are not detectable with small sample sizes, so we really need these 10s of thousands or hundreds of thousands of patients to detect the snips with a small effect size.",
                    "label": 0
                },
                {
                    "sent": "The other point, which is a very broad one or the other potential reason for missing heritability, is that they feel that we may underestimate the phenotypic effect of other genetic, epigenetic or non genetic factors.",
                    "label": 1
                },
                {
                    "sent": "So there may be genetic properties that we've ignored, ignored so far.",
                    "label": 1
                },
                {
                    "sent": "For instance, real snips that play an important role in disease.",
                    "label": 0
                },
                {
                    "sent": "There may be chemical modifications of the genome such as demethylation state.",
                    "label": 0
                },
                {
                    "sent": "Of bases in the genome that may be involved in phenotypic variation.",
                    "label": 0
                },
                {
                    "sent": "And of course there may be important environmental effects on the phenotype which may also play a phenotypic role.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now, how can machine learning help here?",
                    "label": 0
                },
                {
                    "sent": "I see three directions how machine learning can contribute to genetics at the moment.",
                    "label": 0
                },
                {
                    "sent": "You could summarize them by saying machine learning can support genetics to move to a systems biology perspective.",
                    "label": 1
                },
                {
                    "sent": "First of all, by developing efficient to compute multilocus models by developing algorithms that allow to discover trade related systems of genetic loci.",
                    "label": 1
                },
                {
                    "sent": "The second one.",
                    "label": 0
                },
                {
                    "sent": "Being machine learning can some can support increasing the sample size in genetic studies, not by generating new samples, but by making it cheaper to Geno type and phenotype.",
                    "label": 0
                },
                {
                    "sent": "Individuals give you a few concrete examples of this at the latest tomorrow.",
                    "label": 0
                },
                {
                    "sent": "And machine learning has also a role to play in developing statistical tests which allow you to decide better additional types of molecular information.",
                    "label": 0
                },
                {
                    "sent": "Can improve your prediction of the phenotype.",
                    "label": 0
                },
                {
                    "sent": "These genetic, epigenetic or environmental effects that we talked that I talked about on the previous slide and to which decree they improve our ability to predict the phenotype.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And I.",
                    "label": 0
                },
                {
                    "sent": "Said in the beginning that I also want to give you an idea of what my group is working on, so I will show a number of different projects of ours which are located exactly in this domain at this interface between machine learning and genetics in the following.",
                    "label": 0
                },
                {
                    "sent": "And I'll start with the multilocus models because this is 1 area where there's a lot of room for new algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Development.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The epistaxis.",
                    "label": 0
                },
                {
                    "sent": "Is if defined statistically?",
                    "label": 0
                },
                {
                    "sent": "The interaction between two snips.",
                    "label": 0
                },
                {
                    "sent": "Which contributes to phenotypic variation, and it's conjectured to be one source of missing heritability that we.",
                    "label": 1
                },
                {
                    "sent": "Do in many studies ignore this contribution of snip, snip interactions.",
                    "label": 0
                },
                {
                    "sent": "There are large scale studies in model organisms, for instance by Boone ET al, which showed it a lot of genetic interactions.",
                    "label": 1
                },
                {
                    "sent": "Also, interaction effects between genes exist and they are one indicator that appetite is maybe a major factor in the Geno type phenotype relationship.",
                    "label": 0
                },
                {
                    "sent": "And there are also a number.",
                    "label": 0
                },
                {
                    "sent": "Of examples in the literature which showed that only certain modifications in pairs of genes lead to a particular phenotype or that a second mutation masks the effect of the first mutation.",
                    "label": 0
                },
                {
                    "sent": "For instance, here, the loss of either BRCA one or BAC A2 tumor suppressor function in cells triggers a cell cycle arrest at G2 M checkpoint that can be suppressed by the inactivation.",
                    "label": 1
                },
                {
                    "sent": "Of P53.",
                    "label": 0
                },
                {
                    "sent": "So P 53 is a component that is involved in a lot of interactions in cancer, and another example is to loss of the fund.",
                    "label": 0
                },
                {
                    "sent": "Hippel Lindau tumor suppressor function normally causes cellular center St.",
                    "label": 1
                },
                {
                    "sent": "But inactivation of a second tumor suppressor RB retinoblastoma can suppress this process, so these are two examples from cancer.",
                    "label": 0
                },
                {
                    "sent": "That show how interactions between genes may affect disease status or complex phenotype.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now, why can't we easily check for all of these epistatic snip snip interactions?",
                    "label": 0
                },
                {
                    "sent": "We have two big problems.",
                    "label": 0
                },
                {
                    "sent": "One is a combination of 1 and the other is statistical one.",
                    "label": 0
                },
                {
                    "sent": "They both derive from the same fact the number of potential candidate snip peers is huge.",
                    "label": 0
                },
                {
                    "sent": "As I said before, we typically deal with between 10,000 and 10,000,000 snips, and exhaustive search through all of.",
                    "label": 0
                },
                {
                    "sent": "These potential snippers would therefore have to consider tend to attend to 10 to 14.",
                    "label": 0
                },
                {
                    "sent": "Snippers tend to the 10, maybe handebol, or one can deal with 10 to 14.",
                    "label": 0
                },
                {
                    "sent": "Can even keep a large computing cluster busy for awhile.",
                    "label": 0
                },
                {
                    "sent": "In short, what we are suffering from in epistasis detection is that it is an enormous computational runtime problem, and of course hand in hand with this computational runtime problem goes also an enormous multiple hypothesis testing problem, because in the most extreme case, we're testing 10 to 14 hypothesis and we have to make sure that we don't get order 10 to the 12 false positives by ignoring the multiple hypothesis testing problem.",
                    "label": 1
                },
                {
                    "sent": "Here.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A lot of paramedics groups have looked at this problem, in fact, and one can.",
                    "label": 0
                },
                {
                    "sent": "Even make a taxonomy of different approaches that have been defined in order to deal with this problem of epistasis detection.",
                    "label": 0
                },
                {
                    "sent": "So the first family is the family of exhaustive enumeration methods, an.",
                    "label": 0
                },
                {
                    "sent": "Which is applicable only to small sets of snips.",
                    "label": 0
                },
                {
                    "sent": "If you use standard hardware or can be extended to a genome wide scale by using special hardware such as cloud computing or GPU implementations, and there's actually a field in which bathroom and I've worked over the last few years together, and I think also crystal worked in this domain of epistasis detection.",
                    "label": 1
                },
                {
                    "sent": "So with special hardware you can perform such an exhaustive enumeration.",
                    "label": 0
                },
                {
                    "sent": "The second family are so called filtering approaches where you try to narrow down the search space to reduce the computational effort.",
                    "label": 1
                },
                {
                    "sent": "Either you narrow it down by a statistical statistical criterion, for instance only considering snips that have a large main effect.",
                    "label": 0
                },
                {
                    "sent": "So large effect on their own, and then you only construct pairs of chips.",
                    "label": 0
                },
                {
                    "sent": "We're both snips have a large effect, or you use a biological criterion.",
                    "label": 0
                },
                {
                    "sent": "For instance, you only look at Snips that are near.",
                    "label": 0
                },
                {
                    "sent": "Genes whose proteins are known to interact.",
                    "label": 0
                },
                {
                    "sent": "So you use biological networks to narrow down the search space.",
                    "label": 1
                },
                {
                    "sent": "In data mining, some index structure approaches were proposed.",
                    "label": 0
                },
                {
                    "sent": "The most famous one being faster Nova.",
                    "label": 0
                },
                {
                    "sent": "It's a planned branch and bound algorithm.",
                    "label": 0
                },
                {
                    "sent": "On step step interaction in numeration so you.",
                    "label": 0
                },
                {
                    "sent": "Use this principle from optimization theory branch and bound to avoid to compute the statistics for parts of the search space of snip.",
                    "label": 1
                },
                {
                    "sent": "Snip interactions team is the successor method of Faster Nova, which makes it more efficient to compute P values by storing intermediate terms that have to be computed again and again in random permutations of the data which are needed to compute the P values.",
                    "label": 0
                },
                {
                    "sent": "So these are three.",
                    "label": 0
                },
                {
                    "sent": "Types of approaches.",
                    "label": 0
                },
                {
                    "sent": "They all have in common that in the worst case you still suffer from a runtime which is quadratic in the number of snips.",
                    "label": 0
                },
                {
                    "sent": "Sometimes the these pruning filtering criteria here may reduce your search space.",
                    "label": 0
                },
                {
                    "sent": "Sometimes they may not, or they may.",
                    "label": 0
                },
                {
                    "sent": "Make you lose a lot of interesting candidate pairs.",
                    "label": 0
                },
                {
                    "sent": "In the other case, for instance, here in the branch and bound approach, you may have datasets in which this branch and bound approach doesn't work that well where you can only prune 1% of the entire search space, and you still have to commute 99% of these 10 to 14 snippers.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So to summarize it in short.",
                    "label": 0
                },
                {
                    "sent": "These methods.",
                    "label": 0
                },
                {
                    "sent": "Tend to either.",
                    "label": 0
                },
                {
                    "sent": "Suffer from averse case runtime of N square or often from a low recoil.",
                    "label": 0
                },
                {
                    "sent": "So a more theoretical question.",
                    "label": 0
                },
                {
                    "sent": "That I am.",
                    "label": 0
                },
                {
                    "sent": "Better soon of mine and I ask is can you can you can we come up with a principle method that we can show to require sub quadratic runtime in epistaxis detection.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And this work.",
                    "label": 0
                },
                {
                    "sent": "I would like to present to you in a bit more detail.",
                    "label": 0
                },
                {
                    "sent": "So first of all, we had to settle on a particular type of definition of how to measure epistaxis, and we defined it as.",
                    "label": 0
                },
                {
                    "sent": "A difference in correlation.",
                    "label": 0
                },
                {
                    "sent": "This also criterion that better I had used in one of the GPU implementations.",
                    "label": 0
                },
                {
                    "sent": "Called a plaster, so it is the difference in correlation between 2 steps between cases and controls between in in the group of individuals that suffer from the disease and the group of individuals that doesn't suffer from the disease.",
                    "label": 1
                },
                {
                    "sent": "The biological interpretation is that we have a different degree of linkage disequilibrium, so a different degree of correlation between the two loci in these two phenotypic classes.",
                    "label": 1
                },
                {
                    "sent": "And now a datamining question to ask.",
                    "label": 0
                },
                {
                    "sent": "Boss, can we?",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Solve this problem in a runtime which is provability less than quadratic in the number of snips, N and.",
                    "label": 0
                },
                {
                    "sent": "We checked the literature in theoretical computer science and found one related piece of work by Pertouli ET al from called 1989.",
                    "label": 1
                },
                {
                    "sent": "In which paturia doll.",
                    "label": 0
                },
                {
                    "sent": "Tackle the so-called maximum correlation problem or.",
                    "label": 1
                },
                {
                    "sent": "To use the more illustrative fame, this so called light bulb problem.",
                    "label": 0
                },
                {
                    "sent": "What is the light by problem?",
                    "label": 1
                },
                {
                    "sent": "You're observing a set of light bulbs which can be on or off.",
                    "label": 0
                },
                {
                    "sent": "Individually and you are observing them across different points in time.",
                    "label": 0
                },
                {
                    "sent": "And now.",
                    "label": 0
                },
                {
                    "sent": "After observing all these light bulbs, you want to find out which pair of light bulbs was most often in the same state.",
                    "label": 0
                },
                {
                    "sent": "You could also say you want to find the pair of light bulbs with the minimum Hamming distance.",
                    "label": 1
                },
                {
                    "sent": "Ideally, two laptops would be in the same state all the time.",
                    "label": 0
                },
                {
                    "sent": "Of course the naive approach is you.",
                    "label": 0
                },
                {
                    "sent": "Compute all pairwise Hamming distances between the light bulbs and pick the pair with the minimum distance.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "However, in this type of approach for 1989 by Patriot Al.",
                    "label": 0
                },
                {
                    "sent": "But we I presented an approach which can do better.",
                    "label": 0
                },
                {
                    "sent": "And it works as follows.",
                    "label": 0
                },
                {
                    "sent": "We are given a binary matrix A with M rows and N columns, Mr.",
                    "label": 1
                },
                {
                    "sent": "The number of time points in the light bulb.",
                    "label": 0
                },
                {
                    "sent": "Example N is the number of light bulbs.",
                    "label": 0
                },
                {
                    "sent": "In our.",
                    "label": 0
                },
                {
                    "sent": "Case in our application, M is the number of patients.",
                    "label": 1
                },
                {
                    "sent": "In is the number of snips.",
                    "label": 0
                },
                {
                    "sent": "And now the algorithm repeats the following steps L times it samples K rose.",
                    "label": 0
                },
                {
                    "sent": "From the matrix.",
                    "label": 0
                },
                {
                    "sent": "So K timepoints or K patients if you want.",
                    "label": 1
                },
                {
                    "sent": "And it increases a counter for all pairs of columns for all pairs of light bulbs or for all pairs of snips that match exactly on these K rose.",
                    "label": 0
                },
                {
                    "sent": "You can again use techniques sorting techniques that I described on the graphs for doing this efficiently.",
                    "label": 0
                },
                {
                    "sent": "In this procedure we repeat edit times, always increasing count the counters for those pairs of columns that match exactly on our subset of rows.",
                    "label": 0
                },
                {
                    "sent": "And then in the end we divide all these counters by adding the number of iterations to get an estimate of.",
                    "label": 0
                },
                {
                    "sent": "This probability of being in the same state, which is which is the opposite of the of the Hamming distance.",
                    "label": 1
                },
                {
                    "sent": "To get an estimate of the Hamming distance.",
                    "label": 0
                },
                {
                    "sent": "And now what Patriot I'll show in their paper is that with the probability close to one, this light by procedure retrieves the most correlated pair.",
                    "label": 0
                },
                {
                    "sent": "So they call this correlated.",
                    "label": 0
                },
                {
                    "sent": "I called it minimum Hamming distance in a runtime.",
                    "label": 0
                },
                {
                    "sent": "Which, ignoring this logarithmic part here is M to the one plus logarithm of C1 over logarithm of C2.",
                    "label": 0
                },
                {
                    "sent": "So what else you wanted to see?",
                    "label": 1
                },
                {
                    "sent": "One is the highest.",
                    "label": 0
                },
                {
                    "sent": "NC 2 is the second highest correlation score in our data set.",
                    "label": 0
                },
                {
                    "sent": "If they are identical, if the top here and the second pair.",
                    "label": 0
                },
                {
                    "sent": "Have the same level of correlation, then this runtime here is a quadratic again.",
                    "label": 0
                },
                {
                    "sent": "As soon as there is a gap in correlation between the top here and the second most correlated pair, this runtime becomes sub quadratic in a number of snips.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "However, this old algorithm from 1989 did not solve our apostata search problem directly.",
                    "label": 0
                },
                {
                    "sent": "There are three points in which it differs from what we were planning to do.",
                    "label": 0
                },
                {
                    "sent": "First of all, we were interested in this difference in correlation between cases and controls.",
                    "label": 1
                },
                {
                    "sent": "Second, our snips are not binary in general in.",
                    "label": 0
                },
                {
                    "sent": "In the light bulb case, the variables are binary.",
                    "label": 0
                },
                {
                    "sent": "Snips tend to be triple, state or even when they are imputed, they can be have continuous values.",
                    "label": 0
                },
                {
                    "sent": "So having this only for binary variables, for the restriction and.",
                    "label": 0
                },
                {
                    "sent": "Via this lab approach, dealt with Hamming distance and the probability of being in the same state for binary variables.",
                    "label": 0
                },
                {
                    "sent": "We wanted to compute Pearson's correlation coefficient.",
                    "label": 1
                },
                {
                    "sent": "And in three steps we could overcome these.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The three discrepancies.",
                    "label": 0
                },
                {
                    "sent": "So first of all.",
                    "label": 0
                },
                {
                    "sent": "We could overcome the problem that we don't want to maximize correlation.",
                    "label": 0
                },
                {
                    "sent": "Want to maximize difference in correlation?",
                    "label": 1
                },
                {
                    "sent": "We can do so by manipulating the original data matrix a bit.",
                    "label": 0
                },
                {
                    "sent": "Original datamatrix is the concatenation of the matrices.",
                    "label": 1
                },
                {
                    "sent": "A&BA is the matrix of cases.",
                    "label": 0
                },
                {
                    "sent": "B is the matrix of controls.",
                    "label": 0
                },
                {
                    "sent": "The roles are the patients again, so the case and control it's the columns are the snips.",
                    "label": 0
                },
                {
                    "sent": "So this concatenation of A of A&B is our original data matrix.",
                    "label": 0
                },
                {
                    "sent": "Now what we do is we copy this matrix.",
                    "label": 0
                },
                {
                    "sent": "And we invert B.",
                    "label": 0
                },
                {
                    "sent": "By inverting BI mean computing 1 -- B so far I still assume that all our variables are binary.",
                    "label": 0
                },
                {
                    "sent": "I'll only overcome this problem later on.",
                    "label": 0
                },
                {
                    "sent": "So far we can still assume that they are binary, so 1 -- B flips exactly the entries of B.",
                    "label": 0
                },
                {
                    "sent": "And we do the same manipulation again.",
                    "label": 0
                },
                {
                    "sent": "We copy AB, invert this time a.",
                    "label": 0
                },
                {
                    "sent": "And now we compute.",
                    "label": 0
                },
                {
                    "sent": "The light by the algorithm on these extended matrices, shown here in line three and four.",
                    "label": 0
                },
                {
                    "sent": "And we can show and I only state the result here.",
                    "label": 0
                },
                {
                    "sent": "The proof is in the paper that the maximally correlated pair.",
                    "label": 1
                },
                {
                    "sent": "Of columns in these extended matrices.",
                    "label": 0
                },
                {
                    "sent": "Is.",
                    "label": 0
                },
                {
                    "sent": "Also, the pair of columns, the pair of variables which maximizes the difference in correlation between cases and controls.",
                    "label": 0
                },
                {
                    "sent": "This is just a matrix.",
                    "label": 0
                },
                {
                    "sent": "Transformation which allows to solve this.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Problem.",
                    "label": 0
                },
                {
                    "sent": "We can still use on the extended transform matrix the original algorithm, but as I said before, our snips are still binary, so we have to.",
                    "label": 0
                },
                {
                    "sent": "Make it more general in that we can deal with non binary snips as well.",
                    "label": 0
                },
                {
                    "sent": "Well, one way to make our algorithm applicable to snips is that we binarize the snips before we put them into our algorithm.",
                    "label": 0
                },
                {
                    "sent": "And we do so by a technique called locality sensitive hashing by Charikar from 2002, and the idea here is.",
                    "label": 0
                },
                {
                    "sent": "That we are given vectors in an M dimensional space.",
                    "label": 1
                },
                {
                    "sent": "These are our snips, so if you have EM patients.",
                    "label": 0
                },
                {
                    "sent": "Then each step can be represented as an M dimensional vector and now we want to binarize these vectors.",
                    "label": 1
                },
                {
                    "sent": "And in order to do so, we draw a random vector from an M dimensional Gaussian distribution.",
                    "label": 1
                },
                {
                    "sent": "This our vector R and then we compute the inner product between R and.",
                    "label": 0
                },
                {
                    "sent": "Our snip vector XI.",
                    "label": 0
                },
                {
                    "sent": "If this inner product is positive or zero, then we map the vector to one.",
                    "label": 1
                },
                {
                    "sent": "If it is negative, we map it to 0.",
                    "label": 0
                },
                {
                    "sent": "This is the binarization scheme that we apply to our snip data.",
                    "label": 0
                },
                {
                    "sent": "You may have noticed this chance snip.",
                    "label": 0
                },
                {
                    "sent": "Which is represented as an M dimensional vector in a single bit.",
                    "label": 1
                },
                {
                    "sent": "Of course, it's very caused, kind of binarization, or of the information stored in the richness of vectors.",
                    "label": 0
                },
                {
                    "sent": "So we do this again and again.",
                    "label": 0
                },
                {
                    "sent": "So we we transform the original snip vector into a sequence of bits which are determined by different random vectors are.",
                    "label": 1
                },
                {
                    "sent": "What is known from locality sensitive hashing?",
                    "label": 0
                },
                {
                    "sent": "Is.",
                    "label": 0
                },
                {
                    "sent": "That the probability that two different vectors will be hashed to the same bit.",
                    "label": 0
                },
                {
                    "sent": "So both to 0 or both to one.",
                    "label": 0
                },
                {
                    "sent": "Depends on the angle between these vectors.",
                    "label": 0
                },
                {
                    "sent": "The smaller the angle.",
                    "label": 0
                },
                {
                    "sent": "Between the two step vectors in our M dimensional space, the larger the probability that they will be.",
                    "label": 0
                },
                {
                    "sent": "Mapped to the same bit both one above 2 zero.",
                    "label": 0
                },
                {
                    "sent": "There's a geometric interpretation of what is happening here, and that is by drawing a random vector.",
                    "label": 0
                },
                {
                    "sent": "You define a hyperplane.",
                    "label": 0
                },
                {
                    "sent": "Which is orthogonal to this random vector and which goes through the origin of your M dimensional space.",
                    "label": 0
                },
                {
                    "sent": "End.",
                    "label": 0
                },
                {
                    "sent": "Two vectors are.",
                    "label": 0
                },
                {
                    "sent": "Both hash to one or both has to 0 if they are on the same side of this hyperplane.",
                    "label": 0
                },
                {
                    "sent": "If there are different sides of the hyperbole, if they point to different sides of the hyperplane, they will be hashed to different bit values, and the probability that the hyperplane will separate the two vectors from each other of course depends on the angle between the two vectors.",
                    "label": 1
                },
                {
                    "sent": "That's the geometric interpretation illustration of what is going on here.",
                    "label": 0
                },
                {
                    "sent": "The closer together the vectors are, the less likely it is that by drawing a random hyperplane you will separate them into different half spaces.",
                    "label": 0
                },
                {
                    "sent": "This property is very important to us.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Overcome the the third problem that we face to the third discrepancy between our setting and the one from the lightbulb algorithm.",
                    "label": 0
                },
                {
                    "sent": "Which is that we want to compute Pearson correlation coefficient and not the Hamming distance.",
                    "label": 0
                },
                {
                    "sent": "And in order to show that we can also maximize.",
                    "label": 0
                },
                {
                    "sent": "The piece is called correlation coefficient.",
                    "label": 0
                },
                {
                    "sent": "Using our lab algorithm.",
                    "label": 0
                },
                {
                    "sent": "We have to recall that Pearson's correlation coefficient has a geometric interpretation as well.",
                    "label": 0
                },
                {
                    "sent": "We all know it as the covariance between 2 random variables divided by their standard deviations.",
                    "label": 1
                },
                {
                    "sent": "However.",
                    "label": 0
                },
                {
                    "sent": "After centering the two vectors XI and XJ.",
                    "label": 1
                },
                {
                    "sent": "The PSPS correlation coefficient is also.",
                    "label": 0
                },
                {
                    "sent": "An equivalent to the cosine between these two center vectors XI and XJ.",
                    "label": 0
                },
                {
                    "sent": "So now we have a link between everything that we want to compute.",
                    "label": 0
                },
                {
                    "sent": "We know that Pearson's correlation coefficient.",
                    "label": 0
                },
                {
                    "sent": "Is linked to the cosine of the angle between.",
                    "label": 0
                },
                {
                    "sent": "The two vectors we know.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At the angle.",
                    "label": 0
                },
                {
                    "sent": "Is connected to the Hamming distance between our binarized vectors and we know that the lightbulb algorithm can compute the pair of vectors with the minimum Hamming distance with high probability.",
                    "label": 0
                },
                {
                    "sent": "So we have the full path from.",
                    "label": 0
                },
                {
                    "sent": "From Pearson correlation coefficient to hamming distance and we have the method to.",
                    "label": 0
                },
                {
                    "sent": "To minimize to having this.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This gives rise to the following algorithm which we published in KDD.",
                    "label": 0
                },
                {
                    "sent": "We binarize the original matrices which we call a zero and B0 in this pseudocode into A&B by locality sensitive hashing.",
                    "label": 1
                },
                {
                    "sent": "We run the library algorithm on.",
                    "label": 0
                },
                {
                    "sent": "The extended matrix, the first extended matrix that I described.",
                    "label": 0
                },
                {
                    "sent": "We run it on the second extended matrix that I described.",
                    "label": 1
                },
                {
                    "sent": "We record the maximally correlated pair on each of these extended matrices and the maximum of the two is the outcome.",
                    "label": 0
                },
                {
                    "sent": "The output of our algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We ran this algorithm on several datasets.",
                    "label": 0
                },
                {
                    "sent": "To find out what the empirical runtime is, so we observe this empirically.",
                    "label": 0
                },
                {
                    "sent": "This algorithm converges after runtime, which is proportional to end to the 1.5.",
                    "label": 0
                },
                {
                    "sent": "And we measured this as being able to detect.",
                    "label": 0
                },
                {
                    "sent": "At least 95% of the top 1000 snipped pairs in a given data set, which we had computed using our cluster or using our GPU, approaches to system interaction detection.",
                    "label": 0
                },
                {
                    "sent": "So using this algorithm we can compute.",
                    "label": 0
                },
                {
                    "sent": "Epistasis detection on a single computer rather than using our cluster here, our cluster with 1000 cores.",
                    "label": 1
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And just to show the results.",
                    "label": 0
                },
                {
                    "sent": "From the paper in the graphic.",
                    "label": 0
                },
                {
                    "sent": "Let us have a look at this figure here.",
                    "label": 0
                },
                {
                    "sent": "So the access is we have to recall among the top 1000 snippers as computed by an exhaustive enumeration and the exponent of the runtime to the base N, and you can see here that for an exponent of around 1.5 we reach.",
                    "label": 1
                },
                {
                    "sent": "95% recall or more on these three different datasets.",
                    "label": 0
                },
                {
                    "sent": "Is the ability to detect at least 950 out of the top 1000 Snip appears from Dicks source of enumeration, so 95% would be 950 after 1000.",
                    "label": 0
                },
                {
                    "sent": "How many of these we found?",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That's the.",
                    "label": 0
                },
                {
                    "sent": "Point the alternative approach using GPU's with bathroom and Tony come tongue.",
                    "label": 0
                },
                {
                    "sent": "Amuz is.",
                    "label": 0
                },
                {
                    "sent": "Deficiency of graphical processing units to perform basic mathematical operations in parallel.",
                    "label": 1
                },
                {
                    "sent": "These are heavily optimized for rendering, rendering graphics on your computer screen for updating the state of the pixels on your computer screen and these basic mathematical operations is also what we need in order to do epistasis detection, so we can use.",
                    "label": 0
                },
                {
                    "sent": "This power of GPU's to perform a lot of basic mathematical operations in parallel, and to compute a lot of emphasizes test statistics in parallel.",
                    "label": 0
                },
                {
                    "sent": "Still, what we're doing here is an exhaustive enumeration, and the speedup that we achieved using these GPU implementations is similar to the one that we achieved using the lightbulb algorithm and in a.",
                    "label": 1
                },
                {
                    "sent": "International Genetics Consortium on headache diseases.",
                    "label": 0
                },
                {
                    "sent": "We are now exploring with bedroom matters.",
                    "label": 0
                },
                {
                    "sent": "The application of these methods to disable interaction.",
                    "label": 0
                },
                {
                    "sent": "Alesis in clinical My Crane, another disease genetics consortia using our our software and our methods.",
                    "label": 0
                },
                {
                    "sent": "In order to do some sleep interaction detection on diseases such as autism, schizophrenia, or depression.",
                    "label": 1
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Other important aspects.",
                    "label": 0
                },
                {
                    "sent": "In this field of developing multilocus models for genetics.",
                    "label": 1
                },
                {
                    "sent": "By machine learning.",
                    "label": 0
                },
                {
                    "sent": "Include.",
                    "label": 0
                },
                {
                    "sent": "Prior knowledge, including prior knowledge on the relevance of snips into our models, we have one support vector machine approach from 2011 which can.",
                    "label": 1
                },
                {
                    "sent": "Deal with prior knowledge about Snips.",
                    "label": 1
                },
                {
                    "sent": "Another important aspect is that one has to account for the relatedness of individuals in these studies.",
                    "label": 0
                },
                {
                    "sent": "For instance, Baraki worked on this in my lab measuring statistical significance of more complex multi locus models, also very.",
                    "label": 0
                },
                {
                    "sent": "Difficult problem because once we move to these higher order combinations of snips.",
                    "label": 0
                },
                {
                    "sent": "The space of potential solutions become so large that it is very hard to correctly quantify statistical significance and to also correctly account for multiple hypothesis testing.",
                    "label": 1
                },
                {
                    "sent": "And the fourth problem that is now drawing a lot of attention is that one would like to predict multiple correlated phenotypes jointly.",
                    "label": 0
                },
                {
                    "sent": "There's for instance work by Eric Singh and his Leopard County men on on this topic.",
                    "label": 0
                },
                {
                    "sent": "How one can exploit correlations between phenotypes to get two more accurate predictions?",
                    "label": 0
                },
                {
                    "sent": "There's older work on this in statistical genetics or synergetics has a lot of rich work on the statistical aspects of studying genetics data.",
                    "label": 0
                },
                {
                    "sent": "What machine learning can contribute here is to scale these up to the large genome datasets that we have now.",
                    "label": 0
                },
                {
                    "sent": "This is in fact a very good moment for me to stop today and tomorrow I'll continue further and explain to you what the future of barometric says.",
                    "label": 0
                },
                {
                    "sent": "Thank you for today.",
                    "label": 0
                }
            ]
        }
    }
}