{
    "id": "kgooj63grdilksbymmb5lpbscpngqvlk",
    "title": "Visual Event Recognition in Videos by Learning from Web Data",
    "info": {
        "author": [
            "Lixin Duan, School of Computer Science and Engineering, Nanyang Technological University"
        ],
        "published": "July 19, 2010",
        "recorded": "June 2010",
        "category": [
            "Top->Computer Science->Computer Vision->Video Analysis"
        ]
    },
    "url": "http://videolectures.net/cvpr2010_duan_verv/",
    "segmentation": [
        [
            "So good afternoon everyone.",
            "My name is Lisa and one I'm going to talk about video event recognition in videos by learning from web data.",
            "This is joint work with my professor, professor, don't shoot Professor Everton from that young technological University in Singapore and Doctor J Bull from Kodak Research Labs in Rochester, US.",
            "So this is our life of mine."
        ],
        [
            "Plantation, first I will give you our view of the event recognition system and in the system there are two issues.",
            "The first issue is how to measure the similarity between videos.",
            "To address this issue we propose Alliance which time period matching and the second issue is crushed.",
            "Miller is chrestman problem and we propose adaptive multiple current learning.",
            "To solve this problem I will give you more details on these two issues later.",
            "After that I will show you the."
        ],
        [
            "Perimental results followed by conclusion.",
            "So first let us look into the overview of the system.",
            "The goal of our system is to recognize consumer videos.",
            "The consumer videos are usually taken by consumers during some events such as wedding, sports, picnic and so on.",
            "So consumer videos usually have large interclass variabilities and also their outing a limited number of consumer videos, because the consumers may not be willing to label lots of videos.",
            "So as known to us, using a limited number of.",
            "Training samples cannot learn good classifier, so we had to make use of the auxiliary data.",
            "So thanks to the Internet we can download."
        ],
        [
            "Videos from web.",
            "For example, we can download web videos from YouTube so we can leverage a large number of loosely labeled web videos to learn a good classifier for the consumer videos.",
            "And this is a flow chart of our system."
        ],
        [
            "The system is designed in a traditional way that given a video database, we first train a classifier and for adding test video we use a classifier to predict its label as output.",
            "So just as I said."
        ],
        [
            "There are two issues in the system.",
            "The first one is how to measure the similarity between videos.",
            "Several procurement matching methods have been proposed to address this issue, and this methods.",
            "Each video is divided into multiple volumes along the time Axis, space, axis, and both space and time axis.",
            "And this method you'll have two steps in the first step, the volume to volume distances are computed in the.",
            "In the second step, the distance between 2 videos is computed based on the volume to volume distances.",
            "So in the unaligned space pure matching method proposed by Doctor Elective, the volume one video can only be matched to the video in the same position of another video."
        ],
        [
            "So following the existing work in our alliance with tamper matching, we divide each video into multiple.",
            "Now overlapped spacetime values.",
            "Here is the level number and in the experiments we set L equal to zero and one.",
            "And in our method one video when volume new video can be matched to avoid doing in a different position of another video.",
            "So our method has a greater variability than the online space temper matching.",
            "For example, one object may move around in two videos, so it may appear in different positions of the two videos.",
            "So in this case our method can match the two volumes both containing the object by the online space tempier matching cannot.",
            "And our method is also a two step approach.",
            "In the first step, we directly followed the Doctor electives work to compute the volume to volume distances.",
            "So in the second step, to compute the distance between 2 videos at level 0, each video is directly considered as space, time, volume.",
            "So the distance between 2 videos can be directly obtained.",
            "At level one, we divide each."
        ],
        [
            "Video in two 8 down overlapped spacetime volumes with the same size."
        ],
        [
            "And we adopt integer phloem D. Arthur's distance."
        ],
        [
            "To compute the distance between the two videos, so after performing integer flow earthmovers distance, we can find the best matching between the volumes.",
            "So for example, in this figure, the two volumes in red color are matched and the two volumes in green color matched and so are the rest rest photos.",
            "So with the after finding the matched values we can compute the distance between 2 videos without based on the distance between the master volumes."
        ],
        [
            "So here comes the second issue that that is customer problem.",
            "So as we know the consumer videos are naturally captured by consumers and the web videos may may be edited and they are usually selected before uploading until the Internet.",
            "So the data distribution of this of the consumer videos and web videos may be different.",
            "So let us consider the consumer video consumer videos as the target domain and web videos as a source domain.",
            "So to measure the.",
            "Data distribution mismatch between the two domains.",
            "We adopt A criteria called.",
            "Maximum means discrepancy MMD in this criteria.",
            "Thus, each sample X is mapped into a higher dimensional space 5X and Edward MD computes the distance between the means of the two distributions and also MD preserves some higher order statistics and with some simple mathematical operations we can simplify the square of the MMD distance at the trace of matrix K times.",
            "A matrix is here the metrics K is Colonel metrics it is.",
            "Deduced from the feature mapping Phi and the metrics S is coefficient matrix.",
            "So suppose."
        ],
        [
            "There are people in the class, Paris, FP and actually FP can be learned by adding technique using the training type from either the observed a man or the target domain, or from both domains.",
            "So in the experiments we left P is learned by SVM with the label train data from both domains.",
            "And we propose the targeted design function like this.",
            "In this equation, beta P is linear combination coefficient and Delta effects is called the partition function and in the target is in function.",
            "The first term can be considered as a prior information and because of the good the interpretability of the multiple current learning we model the partition function Delta if by."
        ],
        [
            "Using multiple current kernel learning, so in my in my table color kernel learning MCL, the kernel is assumed to be a linear combination of multiple based based kernels.",
            "Ken and Kim is deduced from the feature mapping file and so with MCL we can we can rewrite the MMD distance as a function or mega D which equals to the transpose of vector H times the vector D. So here the letter D is composed of the linear combination coefficient of the base kernels.",
            "So finally we propose our adaptive multiple current learning as the following optimization problem.",
            "So in the objective function there are two terms.",
            "The first term is the MD term.",
            "It minimizes the mismatch between the two domains and the second term is the structural risk."
        ],
        [
            "Functional and in the traditional MCL, the training data assumed to be from the same domain.",
            "However, in our method, the train data are from different domains and our method is actually adapted adapted from one domain to the other.",
            "And to solve this optimization problem, the structure risk functional JD is usually written in its dual form and after that we can we get."
        ],
        [
            "Adaptive multiple kernel algorithm iteratively solves the linear combination coefficient D and the dual variable Alpha in the dual form of JD.",
            "So here at least several existing customer learning methods, the first one is the feature application.",
            "If are either simply augments the features and the second method called domain transfers, Venditti SVM, and this is our previous work, but in this method there's no prior information used.",
            "And."
        ],
        [
            "The third method is adaptive is when and this method is similar to ours except for two major differences and the first one that the linear combination coefficient gamma P is predefined in adaptive SVM and the partition function that F is modeled by a simple MCL.",
            "Simple is why I'm sorry."
        ],
        [
            "So here comes the experimental parts for the data set we use 195 consumer videos and 906 web videos collected by ourselves and also from Codex Umar Video benchmark data set.",
            "There are six events.",
            "There are wedding, birthday, picnic, parade, show and sports an for the training data, we randomly sample 3 videos, prevent from consumer videos and all.",
            "The web videos are also considered as the training data and the rest consumer videos are considered as the test data.",
            "And in the."
        ],
        [
            "Experiments will use two types of features that spacetime feature and the same feature, and we also use four types of base kernels that Gaussian, Laplace and inverse square distance and the inverse distance.",
            "And we compare."
        ],
        [
            "Our line is spacetime pyramid matching with the Alliance whisper matching these two table tables show the results for some features and spacetime features respectively, and from the table will observe that the lattice based empire matching is better than the online like this whisper matching at level one for every case is."
        ],
        [
            "So recall that this is our proposed target.",
            "The same function, and in our experiments we use 80 based kernels.",
            "In total there from 2 pyramid levels.",
            "Two types of features, 5 kernels parameters and four types of kernels.",
            "And the way we Train 80 base classifiers based on this database kernels and for each level and each type of feature will have 20 base classifiers learned by SVN and then we average this 20 based classifiers to get one average classifier and in total there are four average classifiers and then we use this average classifier to construct the preload classifiers FP."
        ],
        [
            "Now here we compared our method with other question.",
            "Many methods in three sittings.",
            "In setting a we only use safety features and still be.",
            "We only use spacetime features and since they both both features are used.",
            "And this figure shows the average precision of all methods for each for each event.",
            "And in an instant and see which uses both features and our method outperforms the other methods in four out of six events.",
            "And for example, taking parade for example, our method, which is 75.7% average precision compared with the second best result 62.650 application, which is 1313.5% improvement."
        ],
        [
            "And we use mean average precision in the final evaluation we observe that in the multiple kernel learning based methods that performance performance of Sitting C is much better than than those of sitting and B.",
            "So this might have occurred in kernel learning based methods can actually better fuse the safety features and spacetime features, and they can also handle the noise in the loose labels to some extent.",
            "And for each method we find the best result among all the three settings and based on the best results, we compared our method with all other methods.",
            "And here are the relative improvements of our method over the other methods.",
            "We can see that our method significantly outperforms the other method."
        ],
        [
            "So in conclusion, we propose a new event recognition framework for consumer videos by leveraging a large number of loosely labeled web videos.",
            "And we develop a new alliance first time period matching method.",
            "And also we present a new quest, minority method, adaptive multiple kernel learning which handles the mismatch between the data distributions of the consumer radio domain and the web video domain."
        ],
        [
            "That's all for my."
        ],
        [
            "Presentation thank you."
        ],
        [
            "Are there questions?",
            "Yes, please go to the mic if you can.",
            "So it seems to me that your approach have two components.",
            "The first component is a kind of pyramid matching and the second component is multi kernel learning.",
            "So how do you connect these two components?",
            "I mean in the first component we have imagined score or something like that right?",
            "And then what features do you use for this multiple kernel learning?",
            "And actually we just use the per match method to compute the distance between the video VI and VJ as illustrated."
        ],
        [
            "This slide.",
            "So after that after we got the distances between the videos we use our adaptive multiple kernel learning to do the learning job.",
            "So actually this is.",
            "This is a two step approach.",
            "Other questions.",
            "I actually had one question.",
            "I was wondering if the approach can be extended to the case where you have consumer videos that are unlabeled, entirely unlabeled.",
            "Um, Nope, actually this is a supervised method, so you need labeled consumer videos.",
            "Yeah, we, we can extend it to the supervised learning method.",
            "Yes, I want question if your first step you compare color tool video volumes right?",
            "Intuitively that actually because of the forests because of the variability in the pixel values when you compare those two columns seems to me the distance in some sense does not make intuitively basically make much sense big quickly please.",
            "Clarify this little bit.",
            "I mean you compare it to volumes.",
            "How do you basically deal with the variability in the pixel changes?",
            "Or actually we do not consider the pics level because we direct for each volume what directly use some extractors to extract features such as the space, time, features and some features.",
            "And to get a feature.",
            "Any other questions?",
            "OK, thank you very much.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So good afternoon everyone.",
                    "label": 0
                },
                {
                    "sent": "My name is Lisa and one I'm going to talk about video event recognition in videos by learning from web data.",
                    "label": 1
                },
                {
                    "sent": "This is joint work with my professor, professor, don't shoot Professor Everton from that young technological University in Singapore and Doctor J Bull from Kodak Research Labs in Rochester, US.",
                    "label": 0
                },
                {
                    "sent": "So this is our life of mine.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Plantation, first I will give you our view of the event recognition system and in the system there are two issues.",
                    "label": 1
                },
                {
                    "sent": "The first issue is how to measure the similarity between videos.",
                    "label": 0
                },
                {
                    "sent": "To address this issue we propose Alliance which time period matching and the second issue is crushed.",
                    "label": 0
                },
                {
                    "sent": "Miller is chrestman problem and we propose adaptive multiple current learning.",
                    "label": 0
                },
                {
                    "sent": "To solve this problem I will give you more details on these two issues later.",
                    "label": 0
                },
                {
                    "sent": "After that I will show you the.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Perimental results followed by conclusion.",
                    "label": 0
                },
                {
                    "sent": "So first let us look into the overview of the system.",
                    "label": 0
                },
                {
                    "sent": "The goal of our system is to recognize consumer videos.",
                    "label": 1
                },
                {
                    "sent": "The consumer videos are usually taken by consumers during some events such as wedding, sports, picnic and so on.",
                    "label": 1
                },
                {
                    "sent": "So consumer videos usually have large interclass variabilities and also their outing a limited number of consumer videos, because the consumers may not be willing to label lots of videos.",
                    "label": 0
                },
                {
                    "sent": "So as known to us, using a limited number of.",
                    "label": 0
                },
                {
                    "sent": "Training samples cannot learn good classifier, so we had to make use of the auxiliary data.",
                    "label": 0
                },
                {
                    "sent": "So thanks to the Internet we can download.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Videos from web.",
                    "label": 0
                },
                {
                    "sent": "For example, we can download web videos from YouTube so we can leverage a large number of loosely labeled web videos to learn a good classifier for the consumer videos.",
                    "label": 1
                },
                {
                    "sent": "And this is a flow chart of our system.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The system is designed in a traditional way that given a video database, we first train a classifier and for adding test video we use a classifier to predict its label as output.",
                    "label": 0
                },
                {
                    "sent": "So just as I said.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There are two issues in the system.",
                    "label": 0
                },
                {
                    "sent": "The first one is how to measure the similarity between videos.",
                    "label": 1
                },
                {
                    "sent": "Several procurement matching methods have been proposed to address this issue, and this methods.",
                    "label": 1
                },
                {
                    "sent": "Each video is divided into multiple volumes along the time Axis, space, axis, and both space and time axis.",
                    "label": 0
                },
                {
                    "sent": "And this method you'll have two steps in the first step, the volume to volume distances are computed in the.",
                    "label": 0
                },
                {
                    "sent": "In the second step, the distance between 2 videos is computed based on the volume to volume distances.",
                    "label": 0
                },
                {
                    "sent": "So in the unaligned space pure matching method proposed by Doctor Elective, the volume one video can only be matched to the video in the same position of another video.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So following the existing work in our alliance with tamper matching, we divide each video into multiple.",
                    "label": 0
                },
                {
                    "sent": "Now overlapped spacetime values.",
                    "label": 0
                },
                {
                    "sent": "Here is the level number and in the experiments we set L equal to zero and one.",
                    "label": 0
                },
                {
                    "sent": "And in our method one video when volume new video can be matched to avoid doing in a different position of another video.",
                    "label": 0
                },
                {
                    "sent": "So our method has a greater variability than the online space temper matching.",
                    "label": 0
                },
                {
                    "sent": "For example, one object may move around in two videos, so it may appear in different positions of the two videos.",
                    "label": 0
                },
                {
                    "sent": "So in this case our method can match the two volumes both containing the object by the online space tempier matching cannot.",
                    "label": 0
                },
                {
                    "sent": "And our method is also a two step approach.",
                    "label": 0
                },
                {
                    "sent": "In the first step, we directly followed the Doctor electives work to compute the volume to volume distances.",
                    "label": 0
                },
                {
                    "sent": "So in the second step, to compute the distance between 2 videos at level 0, each video is directly considered as space, time, volume.",
                    "label": 0
                },
                {
                    "sent": "So the distance between 2 videos can be directly obtained.",
                    "label": 0
                },
                {
                    "sent": "At level one, we divide each.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Video in two 8 down overlapped spacetime volumes with the same size.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we adopt integer phloem D. Arthur's distance.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To compute the distance between the two videos, so after performing integer flow earthmovers distance, we can find the best matching between the volumes.",
                    "label": 0
                },
                {
                    "sent": "So for example, in this figure, the two volumes in red color are matched and the two volumes in green color matched and so are the rest rest photos.",
                    "label": 0
                },
                {
                    "sent": "So with the after finding the matched values we can compute the distance between 2 videos without based on the distance between the master volumes.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here comes the second issue that that is customer problem.",
                    "label": 0
                },
                {
                    "sent": "So as we know the consumer videos are naturally captured by consumers and the web videos may may be edited and they are usually selected before uploading until the Internet.",
                    "label": 0
                },
                {
                    "sent": "So the data distribution of this of the consumer videos and web videos may be different.",
                    "label": 1
                },
                {
                    "sent": "So let us consider the consumer video consumer videos as the target domain and web videos as a source domain.",
                    "label": 0
                },
                {
                    "sent": "So to measure the.",
                    "label": 1
                },
                {
                    "sent": "Data distribution mismatch between the two domains.",
                    "label": 0
                },
                {
                    "sent": "We adopt A criteria called.",
                    "label": 0
                },
                {
                    "sent": "Maximum means discrepancy MMD in this criteria.",
                    "label": 0
                },
                {
                    "sent": "Thus, each sample X is mapped into a higher dimensional space 5X and Edward MD computes the distance between the means of the two distributions and also MD preserves some higher order statistics and with some simple mathematical operations we can simplify the square of the MMD distance at the trace of matrix K times.",
                    "label": 0
                },
                {
                    "sent": "A matrix is here the metrics K is Colonel metrics it is.",
                    "label": 0
                },
                {
                    "sent": "Deduced from the feature mapping Phi and the metrics S is coefficient matrix.",
                    "label": 0
                },
                {
                    "sent": "So suppose.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There are people in the class, Paris, FP and actually FP can be learned by adding technique using the training type from either the observed a man or the target domain, or from both domains.",
                    "label": 0
                },
                {
                    "sent": "So in the experiments we left P is learned by SVM with the label train data from both domains.",
                    "label": 0
                },
                {
                    "sent": "And we propose the targeted design function like this.",
                    "label": 0
                },
                {
                    "sent": "In this equation, beta P is linear combination coefficient and Delta effects is called the partition function and in the target is in function.",
                    "label": 0
                },
                {
                    "sent": "The first term can be considered as a prior information and because of the good the interpretability of the multiple current learning we model the partition function Delta if by.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Using multiple current kernel learning, so in my in my table color kernel learning MCL, the kernel is assumed to be a linear combination of multiple based based kernels.",
                    "label": 0
                },
                {
                    "sent": "Ken and Kim is deduced from the feature mapping file and so with MCL we can we can rewrite the MMD distance as a function or mega D which equals to the transpose of vector H times the vector D. So here the letter D is composed of the linear combination coefficient of the base kernels.",
                    "label": 0
                },
                {
                    "sent": "So finally we propose our adaptive multiple current learning as the following optimization problem.",
                    "label": 0
                },
                {
                    "sent": "So in the objective function there are two terms.",
                    "label": 0
                },
                {
                    "sent": "The first term is the MD term.",
                    "label": 0
                },
                {
                    "sent": "It minimizes the mismatch between the two domains and the second term is the structural risk.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Functional and in the traditional MCL, the training data assumed to be from the same domain.",
                    "label": 0
                },
                {
                    "sent": "However, in our method, the train data are from different domains and our method is actually adapted adapted from one domain to the other.",
                    "label": 0
                },
                {
                    "sent": "And to solve this optimization problem, the structure risk functional JD is usually written in its dual form and after that we can we get.",
                    "label": 1
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Adaptive multiple kernel algorithm iteratively solves the linear combination coefficient D and the dual variable Alpha in the dual form of JD.",
                    "label": 0
                },
                {
                    "sent": "So here at least several existing customer learning methods, the first one is the feature application.",
                    "label": 0
                },
                {
                    "sent": "If are either simply augments the features and the second method called domain transfers, Venditti SVM, and this is our previous work, but in this method there's no prior information used.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The third method is adaptive is when and this method is similar to ours except for two major differences and the first one that the linear combination coefficient gamma P is predefined in adaptive SVM and the partition function that F is modeled by a simple MCL.",
                    "label": 0
                },
                {
                    "sent": "Simple is why I'm sorry.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here comes the experimental parts for the data set we use 195 consumer videos and 906 web videos collected by ourselves and also from Codex Umar Video benchmark data set.",
                    "label": 1
                },
                {
                    "sent": "There are six events.",
                    "label": 1
                },
                {
                    "sent": "There are wedding, birthday, picnic, parade, show and sports an for the training data, we randomly sample 3 videos, prevent from consumer videos and all.",
                    "label": 0
                },
                {
                    "sent": "The web videos are also considered as the training data and the rest consumer videos are considered as the test data.",
                    "label": 0
                },
                {
                    "sent": "And in the.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Experiments will use two types of features that spacetime feature and the same feature, and we also use four types of base kernels that Gaussian, Laplace and inverse square distance and the inverse distance.",
                    "label": 0
                },
                {
                    "sent": "And we compare.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Our line is spacetime pyramid matching with the Alliance whisper matching these two table tables show the results for some features and spacetime features respectively, and from the table will observe that the lattice based empire matching is better than the online like this whisper matching at level one for every case is.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So recall that this is our proposed target.",
                    "label": 0
                },
                {
                    "sent": "The same function, and in our experiments we use 80 based kernels.",
                    "label": 0
                },
                {
                    "sent": "In total there from 2 pyramid levels.",
                    "label": 0
                },
                {
                    "sent": "Two types of features, 5 kernels parameters and four types of kernels.",
                    "label": 0
                },
                {
                    "sent": "And the way we Train 80 base classifiers based on this database kernels and for each level and each type of feature will have 20 base classifiers learned by SVN and then we average this 20 based classifiers to get one average classifier and in total there are four average classifiers and then we use this average classifier to construct the preload classifiers FP.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now here we compared our method with other question.",
                    "label": 0
                },
                {
                    "sent": "Many methods in three sittings.",
                    "label": 0
                },
                {
                    "sent": "In setting a we only use safety features and still be.",
                    "label": 1
                },
                {
                    "sent": "We only use spacetime features and since they both both features are used.",
                    "label": 0
                },
                {
                    "sent": "And this figure shows the average precision of all methods for each for each event.",
                    "label": 0
                },
                {
                    "sent": "And in an instant and see which uses both features and our method outperforms the other methods in four out of six events.",
                    "label": 0
                },
                {
                    "sent": "And for example, taking parade for example, our method, which is 75.7% average precision compared with the second best result 62.650 application, which is 1313.5% improvement.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we use mean average precision in the final evaluation we observe that in the multiple kernel learning based methods that performance performance of Sitting C is much better than than those of sitting and B.",
                    "label": 0
                },
                {
                    "sent": "So this might have occurred in kernel learning based methods can actually better fuse the safety features and spacetime features, and they can also handle the noise in the loose labels to some extent.",
                    "label": 1
                },
                {
                    "sent": "And for each method we find the best result among all the three settings and based on the best results, we compared our method with all other methods.",
                    "label": 0
                },
                {
                    "sent": "And here are the relative improvements of our method over the other methods.",
                    "label": 0
                },
                {
                    "sent": "We can see that our method significantly outperforms the other method.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in conclusion, we propose a new event recognition framework for consumer videos by leveraging a large number of loosely labeled web videos.",
                    "label": 1
                },
                {
                    "sent": "And we develop a new alliance first time period matching method.",
                    "label": 1
                },
                {
                    "sent": "And also we present a new quest, minority method, adaptive multiple kernel learning which handles the mismatch between the data distributions of the consumer radio domain and the web video domain.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's all for my.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Presentation thank you.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Are there questions?",
                    "label": 0
                },
                {
                    "sent": "Yes, please go to the mic if you can.",
                    "label": 0
                },
                {
                    "sent": "So it seems to me that your approach have two components.",
                    "label": 0
                },
                {
                    "sent": "The first component is a kind of pyramid matching and the second component is multi kernel learning.",
                    "label": 0
                },
                {
                    "sent": "So how do you connect these two components?",
                    "label": 0
                },
                {
                    "sent": "I mean in the first component we have imagined score or something like that right?",
                    "label": 0
                },
                {
                    "sent": "And then what features do you use for this multiple kernel learning?",
                    "label": 0
                },
                {
                    "sent": "And actually we just use the per match method to compute the distance between the video VI and VJ as illustrated.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This slide.",
                    "label": 0
                },
                {
                    "sent": "So after that after we got the distances between the videos we use our adaptive multiple kernel learning to do the learning job.",
                    "label": 0
                },
                {
                    "sent": "So actually this is.",
                    "label": 0
                },
                {
                    "sent": "This is a two step approach.",
                    "label": 0
                },
                {
                    "sent": "Other questions.",
                    "label": 0
                },
                {
                    "sent": "I actually had one question.",
                    "label": 0
                },
                {
                    "sent": "I was wondering if the approach can be extended to the case where you have consumer videos that are unlabeled, entirely unlabeled.",
                    "label": 0
                },
                {
                    "sent": "Um, Nope, actually this is a supervised method, so you need labeled consumer videos.",
                    "label": 0
                },
                {
                    "sent": "Yeah, we, we can extend it to the supervised learning method.",
                    "label": 0
                },
                {
                    "sent": "Yes, I want question if your first step you compare color tool video volumes right?",
                    "label": 0
                },
                {
                    "sent": "Intuitively that actually because of the forests because of the variability in the pixel values when you compare those two columns seems to me the distance in some sense does not make intuitively basically make much sense big quickly please.",
                    "label": 0
                },
                {
                    "sent": "Clarify this little bit.",
                    "label": 0
                },
                {
                    "sent": "I mean you compare it to volumes.",
                    "label": 0
                },
                {
                    "sent": "How do you basically deal with the variability in the pixel changes?",
                    "label": 0
                },
                {
                    "sent": "Or actually we do not consider the pics level because we direct for each volume what directly use some extractors to extract features such as the space, time, features and some features.",
                    "label": 0
                },
                {
                    "sent": "And to get a feature.",
                    "label": 0
                },
                {
                    "sent": "Any other questions?",
                    "label": 0
                },
                {
                    "sent": "OK, thank you very much.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}