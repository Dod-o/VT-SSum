{
    "id": "ztjb67hrjuqqnvh2txzuhqjqz4okjghh",
    "title": "The statistical physics of optimal control theory",
    "info": {
        "author": [
            "Bert Kappen, Department of Medical Physics and Biophysics, Radboud University Nijmegen"
        ],
        "published": "Oct. 16, 2012",
        "recorded": "September 2012",
        "category": [
            "Top->Physics->Statistical Physics",
            "Top->Mathematics->Control Theory"
        ]
    },
    "url": "http://videolectures.net/cyberstat2012_kappen_statistical_physics/",
    "segmentation": [
        [
            "So I come from a field where I've been working in what is called machine learning and machine learning.",
            "They use Bayesian methods and Bayesian methods are about inference.",
            "An inference is computing things with probabilities, so computing marginals, computing correlations in any big probability model and what has been my story in the machine learning is is with other people is trying to use statistical physics methods.",
            "To to help the inference computation to speed up.",
            "So, as you may know, it is just these computations are intractable.",
            "They scale exponential with the size of the problem and using mean field methods or using belief propagation or using even multi color sampling methods.",
            "All methods that originated from statistical physics have been very helpful to make the inference computation tractable with many many applications in machine learning ranging from robotics to computer vision to expert systems.",
            "Anything so I've been doing that for awhile and I thought at some point."
        ],
        [
            "That is, these interact abilities that are also interact abilities encountered in control theory, particularly stochastic control theory, where you also have probabilities, but now overtime and wouldn't it be nice to sort of connect these interact abilities to the intractability is observed in the machine learning and graphical models, so I was looking into that.",
            "I found the connection."
        ],
        [
            "Some connection between control.",
            "I was intrigued with that.",
            "The connection between control and quantum mechanics, first based on the on the work of Francesco Guerra here in the audience, but then also digging down to the work of Ed Nelson etc.",
            "And I was intrigued by that because that is a work where you get a control problem, which is a nonlinear problem with diffusions and the quantum mechanics is basically a linearisation of that, making it making it sort of.",
            "I thought it was an interesting connection, so I've really been chewing on that for awhile to see whether there is a connection.",
            "I'm going to tell you a little bit about it, but at some point I had to give up on that and I actually found a more direct."
        ],
        [
            "Link between the control theory and the statistical physics.",
            "Any inference, which is also what I'm going to be talking about.",
            "So then when that was established.",
            "Other people got interested, Ann."
        ],
        [
            "And so people were telling me that basically these control messages that have been talking about using path integrals, they are have to do with large deviations.",
            "They have to lose with martingales theory, so there's a whole bunch of mathematicians that now link into all these kind of things, and some of them are here and then.",
            "In the end there is also of course people in robotic."
        ],
        [
            "It's interested is Yvonne Gallo sitting here using these control methods in robotics and also people using that too."
        ],
        [
            "Duke Neuroscience and use these methods there, so this is a very the short story how this came about and from my perspective and.",
            "And this part of the story that I want to get together here."
        ],
        [
            "So my my talk will consist of three parts.",
            "The first part is is trying to give this this quantum mechanical link with control theory and sort of explain to you where I think it fails and I'm not.",
            "This may not be I. Hopefully that's not the end of it, but as far as I'm understanding it, this connection is not so useful.",
            "Maybe for control, but it's intriguing.",
            "It."
        ],
        [
            "Is it is based on these people and then the second part is on the personal control theory which developed which is was originally.",
            "The idea goes back maybe two half in the 50s even 2 Schrader Rim himself flaming a meter meter was coming.",
            "This afternoon is not yet here.",
            "Have made important have made these connections before."
        ],
        [
            "And the third part is a little is my understanding of the link between control theory and large deviations using an old paper of Schrodinger from 1919 thirty two.",
            "I have to apologize in the sense that in a bit because I wanted to give an overview, so as a necessity the talk will be somewhat superficial, but that's how it.",
            "That's how it is so controlling quantum mechanics."
        ],
        [
            "So if we take the Schrodinger equation which was flies away function size away function, sorry, so complex valued object and it's it's a linear equation, sorry.",
            "Absolute brackets missing, missing here around.",
            "Then we can write it right in equation by writing it as a as a as a as a norm as the norm times times in the face.",
            "If we write it that with Rowan as both being functions of space and time and we plug it in the Schrodinger equation, we get two coupled equations.",
            "One is sort of diffusion type of equation where rho is a function of space and time where the diffusion has a drift term, which is a gradient of a scalar.",
            "Which is this S&S itself is a is satisfying dizzy equation, which is looks a little bit for like a like a bellman equation.",
            "But it has this funny potential term which involves the density of States and of course the potential itself.",
            "This potential here and so this.",
            "This was all very well known.",
            "So you see that these two equations being equivalent to the Schrodinger equation."
        ],
        [
            "So this can be seen sort of as a control problem if we if we go back to if I remind you of the Pontryagin minimum principle.",
            "So suppose so this is a little bit and interlude, so consider deterministic control problem X dot is some function of X and you use the control.",
            "I have a cost which is an end cost which is an inner product with some scalar and I have a path cost an I want to find the trajectory U.",
            "In this finite horizon control that minimizes this, this cost, and we can do that by constraint optimization.",
            "It's a well known argument you define Lagrangian with with LaGrange multiplier, Lambda, which is also a function of time.",
            "And you write down the Lagrangian, which is the LaGrange multiplier term which is constraining the dynamics.",
            "And this is done the cost and you are you going to minimize this?",
            "This discussed and integrated overtime and if you use a variational argument and you set the derivative with respect to you an X in Lambda, set it equal to 0.",
            "You will find 3 equations.",
            "One is that that you have to minimize with respect to you this L. Which gives you what is called the Hamiltonian, which is a function of the state and the Co state and these two remaining variables.",
            "They satisfy these coupled equations, which are some very I like identical to the to the Hamilton equations of motions, where X is the can be interpreted as a state, and Lambda can be interpreted as the as the momentum variable, so they have they have this disjoint dynamics and X of course is initialized at initial time, which was the.",
            "The origonal control problem an Lambda is because of the variation argument gets boundary condition at at the end time.",
            "So you get this mixed boundary value problem to solve.",
            "So that is 1 slide the poultry organ.",
            "Minimum principle.",
            "Now if we go back to the quantum mechanics."
        ],
        [
            "If we define this Hamiltonian here this way."
        ],
        [
            "If we define that."
        ],
        [
            "In this way, where we identify row with the state an S as the Co state, then we will find indeed that this H is such that that it satisfies these Hamilton equations.",
            "For this for this system as satisfying it for the for the Schrodinger equation.",
            "So in other words we."
        ],
        [
            "We can find that the quantum mechanics satisfies the Hamilton dynamics with position Rowen with Momentum S. But now we have also the boundary."
        ],
        [
            "Patience so we have to if we want to now make the link with the point with the control in the Pontryagin principle we have to initialize the density at initial time so that's that's fine and we have to get this boundary condition for the Co state at the at the end time which was the gradient.",
            "This gradient which becomes noticed dysfunction five that we had and so.",
            "We get that the quantum mechanics satisfies the Pontryagin equations for optimal control.",
            "And so that's sort of the can."
        ],
        [
            "The problem is that this is the dynamics F is, so this is this gradient.",
            "This sort of density flow and the cost is this term here and this end cost that we have here.",
            "Of course we could consider end cosio where this whole term is absence.",
            "So this is the formulation of quantum mechanics as a control of distributions.",
            "And it was pointed out by by, by Guerra and by Nelson that that you can make a stochastic."
        ],
        [
            "Interpretation of this where you say OK if a dynamics evolve Ng with some drift in some stochastic process with Brownian noise, and then I distinguish between a mean forward velocity and amine backward velocity which are which.",
            "Then together give the mean velocity and the difference between them is quality osmotic velocity which is the gradient of the log of the density.",
            "So this if you make this interpretation.",
            "Then the control problem becomes a stochastic control problem where this equation is of course nothing else then the governed by the focal Planck equation, which can be written as the gradient of this mean velocity and the cost now becomes in terms of this can be written this custom.",
            "This custom V. Can now be written in terms of."
        ],
        [
            "V Plus and V minus and it becomes."
        ],
        [
            "Of this term, and this is what was pointed out by by Guerra as being the generalization of acceleration to the stochastic case.",
            "So."
        ],
        [
            "In this.",
            "So there's a famous quote of Nelson saying that stochastic mechanics, as this is called is quantum mechanics make difficult, and the reason why is that in order to make this system to run this system, you have to compute AV Plus and V plus means that you have to get the solution of S and computers gradient and at the end of the day what you really have to run is a shorter equation itself before you can actually simulate this dynamics.",
            "He used an example for the quantum harmonic oscillator, where the this is the.",
            "This is the mean velocity and these are stochastic trajectories around it.",
            "This is a plot of the fluctuations around the mean AUC to sort of beats overtime.",
            "So this is the funny kind of dynamics that you can get from this system, so I've been staring for this at this for for some time.",
            "And I thought, what about?"
        ],
        [
            "If quantum mechanics is stochastic, optimal control made easy, you know if you could do could reverse the arrow somehow.",
            "But the problem I'm stuck with and still stuck with this is that the control formulation has the mixed boundary conditions and this is not so easy to relate to the boundary conditions on the sharing equation.",
            "And the control cost this term fee plus B minus is in fact is not linear function of the density and how to interpret that as a custom?",
            "I am at a loss, so I had to give up.",
            "I gave up on that."
        ],
        [
            "And I moved to a simpler case, which is the case discussed by also by Fleming and Meter, which"
        ],
        [
            "Chiz"
        ],
        [
            "Skip this."
        ],
        [
            "If you have time."
        ],
        [
            "So is the idea to express the control problem as an inference problem and try to use ideas from statistical physics to make that inference computation tractable?",
            "Sure, sure, sure, yeah, yeah.",
            "When you say that quantum mechanics miss boundary conditions running question, I mean so this one case should be easy which is.",
            "Gaussian linear.",
            "The common equations control the common filter, especially where you can separate the two problems.",
            "So is that analogy Phantom account for this?",
            "I don't think so.",
            "So the if you if.",
            "Yeah, but so.",
            "But that's so in this in this class that I'm talking about his personal methods.",
            "There it is easy because there you get the linear quadratic control you get to carbon filter and you get the separation.",
            "But in the quantum mechanical case.",
            "So in the quantum harmonic oscillator, I don't think you get it separation, but I'm looking at.",
            "An infinite interval and assuming Gaussian complex Gaussian, then it's exactly.",
            "So so it becomes a. I wonder whether.",
            "Yeah, I'm not sure.",
            "Is that the solution of Sherry questions the exponential?",
            "Type is fails.",
            "Phil's wedding density of the.",
            "Solution Schrodinger equation and do something with it nice in the case where you assume this Gaussian, yeah.",
            "Just by chance.",
            "Is there is the same problem in the classical mechanics that position initial time and velocity at final time is bigger engine principle, yeah?",
            "Only when you integrate the buybacks then they will appear in the usual sense.",
            "But the the very short principle over classical mechanics, it is exactly all this shape, yes.",
            "Yes.",
            "We built the concept of state.",
            "Position with logic which have all been times according to English.",
            "Yes, yes yes yeah.",
            "Yeah, it's like saying also that classical mechanics is a special case of control theories that like if yes, exactly, that is that.",
            "The same structure.",
            "Could you show your conditional time exactly?",
            "And velocity is the control exactly exactly.",
            "Yeah, that works perfectly if final state is not constrained.",
            "It is.",
            "I don't wanna screw up.",
            "Yeah.",
            "So the problem you mentioned on the exponential form of the Phantom account.",
            "This is not specific one connection.",
            "Whenever I try to go over your beyond Gaussian linear Mr. Costa control like this actually seems like.",
            "So it's again not quantum mechanics.",
            "Exponential answers.",
            "OK.",
            "So this is another tack to the to this.",
            "Trying to make something linear out of nonlinear problems, and this is using the.",
            "A simpler approach in the sense so the class of control problems.",
            "The."
        ],
        [
            "One considers is is this class where you have a state variable which has a nonlinear dynamics and where the control acts linearly multiplied by some arbitrary nonlinear function of the state, and where there is some Gaussian noise which act in the same in the same subspace as the control and the control cost is an expectation value involving an arbitrary end state and cost arbitrary state costs, but is quadratic in the control variable itself.",
            "So it is like an arbitrary dynamical system where you allow an easy control mechanism which is linear with quadratic costs, right?",
            "And if I now assumes that there is a relation between there's noise covariance matrix of PSI and the R matrix here, in the sense that they are related by a scalar value Lambda which is positive so that ours is equal to some constant times the inverse covariance matrix.",
            "Of the noise.",
            "Then well, even before that, but if so, this is 1 makes and then the the Hamilton Jacobi equation becomes becomes this one which is linear quadratic and it has the boundary conditions and then you can."
        ],
        [
            "Can minimize disrespect to you and substitute that solution back in.",
            "You get a nonlinear equation and now if this funding relation between the noise and our holds and you make this log transform of the cost to go, then with this with this parameter Lambda appearing here, then this Hamilton Jacobi equation reduces to this linear equation.",
            "And and where is this one had boundary conditions on the on J being equal to five, then this one has boundary conditions on side being equal to the exponent of five over Lambda.",
            "Because of this of this log transform.",
            "So there is a class of control problems for which the Bellman equation is linear and that is this class of control problems.",
            "The.",
            "So did in order to solve this.",
            "So since it's a linear, the great advantage of it is that you can use the Feynman cuts.",
            "The message is integral to solve it and you can show work to following reconsider."
        ],
        [
            "QA distribution of the trajectories that govern the uncontrolled dynamics that is in other words, that is the system that we started out with."
        ],
        [
            "With control 0.",
            "So that is what is called the uncontrolled dynamics."
        ],
        [
            "And so this this."
        ],
        [
            "So in Q is the distribution over the trajectories under that uncontrolled dynamics?",
            "So then you can show that this that that the PSI on the previous slide which was which was linearized Bellman equation is now the solution of Q multiplied by exponent of X where X is is an action which counts the path costs and the end cost.",
            "And so it is like a.",
            "You can interpret this that that the optimal cost to go, or the exponent of it, is given by an integral of trajectories, where each trajectory is penalized by the cost of that particular trajectory.",
            "And of course, the nice thing is that it's I can now be estimated sampled by this from this uncontrolled dynamics you sampled at this uncontrolled dynamics.",
            "You don't know the control you sample this, you discount the the trajectories with this with this term and you get the optimal cost to go, and in this way you also get the control.",
            "So the the the Q can be seen as sort of a prior in the Bayesian sense.",
            "It's a distribution over trajectory."
        ],
        [
            "And one can ask, one can see here that is Q.",
            "That is that This site is."
        ],
        [
            "All of it is sort of a partition sum.",
            "One could think well if queue times.",
            "This is the the the normalizer of some distribution that where this is the normalizes the partition sum then what is the underlying distribution?",
            "Well of course it's simply the numerator divided by the normalization.",
            "So in other words."
        ],
        [
            "This is the.",
            "This is the distribution that this Psy is the partition sum of right?",
            "So we have Q times.",
            "This is discounted thing and we normalize it and if we can identify this distribution, so Q is the distribution of uncontrolled dynamics, uncontrolled trajectories and P is the distribution over optimally controlled trajectory's is the posterior distribution.",
            "And so sign was the was related to the cost to go by this log transform.",
            "So we find out the cost ago is minus Lambda log off site, which was this expression.",
            "So we see this.",
            "We clearly find here an interpretation as a free energy where J is the free energy, the cost to go is a free energy where Lambda plays the role of the temperature.",
            "And finally, one can go back to the fact that the control is the gradient of the cost to go by, and we know if we take gradients of free energies we get expectation values.",
            "So you could take the gradient of the cost to go to compute the optimal control you find after some calculus that it's basically the expectation value of the first noise direction under this posterior distribution.",
            "So we have a distribution over trajectories which are penalized.",
            "Some are good, some are bad, and we take for every first direction of the path.",
            "We weigh them and that gives us exactly our optimal control for this class of problems."
        ],
        [
            "So this is a recap.",
            "The.",
            "So this is the dynamics we have this funny relation that means basically that this means that that control that in directions where you have high noise.",
            "This term the R has to be small, which means that control is cheap, so you can do have large control in direction of large noise.",
            "An interactions of very low noise the vice versa.",
            "Also if you have no noise, this term goes to Infinity or becomes Infinity and basically penalizing the control to zero.",
            "No controls allowed, right?",
            "So there's no control in the deterministic directions and the control has to be somehow proportional in that sense.",
            "The HB equation is linear.",
            "It has this kind of funny Schrodinger local like form, but of course This site is a real valued function, is not complex.",
            "The solution is given by final cuts formula.",
            "the Q is the distribution of the uncontrolled dynamics.",
            "There's a posterior distribution and the optimal control is expectation value of that under that distribution.",
            "Lambda here is some sort of temperature, yeah?",
            "So, at least in one limit would love those.",
            "There's one other no one Misty.",
            "Infinity 2 zero.",
            "You should get back.",
            "The deterministic control.",
            "Yeah, you do so.",
            "I think that so here if you if you take Lambda equal to 0."
        ],
        [
            "This distribution peaks on the maximum, and so you get JS.",
            "Basically S, which is just the cost of the path.",
            "But again, the entropy here is the standard entropy.",
            "Battery which is conjugated to this temperature.",
            "Is that the other posterior?",
            "It's not cross entropy between P&Q, no no.",
            "In the in the, so there's not a formulation that will come to at the end of this talk where where I relate this to do a cross entropy.",
            "OK, all the virgins between P&Q.",
            "Product of.",
            "Cute, yeah, so there is so that is hidden in this formulation.",
            "We will find it.",
            "Yes, OK. Any other?"
        ],
        [
            "OK.",
            "So here's an example of so many."
        ],
        [
            "People may have seen this before, so if I have a 1 dimensional X an I've you an excited so we want to mention of course is relation between R and new is is is trivial is always true.",
            "So if no state dependent pass costs and I have just have you squared of the control costs and I have two goals at plus or minus one and I start here somewhere at X and here is T if you then solve the control problem in this case for this class of problems you find that optimal cost to go is convex.",
            "If you very far away and if you move closer to the entire it, you'll get a symmetry breaking where it has the Brownian particle has to make a choice, but it's optimal for far away to actually steer towards the middle.",
            "And the reason is that if you far away your forward cone of diffusion is so wide that it will incompass both targets and there is no need to make a choice.",
            "Only later your forward cone is actually going to hide between these two.",
            "And of course you have to make choices so you get this out and you get.",
            "So when the future is uncertain, your deley your decisions.",
            "This is take home message for management course maybe.",
            "Of course, the more uncertain, the wider your forward cone and the later you will make that decision, and it domestication will make it infinitely far back in time.",
            "OK.",
            "So."
        ],
        [
            "Using this formula for the optimal control, this formula they said that the optimal control is the expectation failure under the posterior of these first noise direction.",
            "You can of course make a sample estimate by using getting some samples mu and penalising them with the costs, and then taking the first noise direction and getting optimal control in this way.",
            "And here's a little cartoon of how that will work, so here is a state here is time there is.",
            "Initial state is in this case this, and there is.",
            "There's a.",
            "There's two holes here, and there's an infinite potential here.",
            "So here all the this cost will be infinite, so this will put these past that will hit here will put him to zero.",
            "Only the few lucky path that goes through that will actually do that.",
            "So although this is an unbiased, good solid scheme to compute this optimal control, you can clearly see that it's very inefficient depending on where you are.",
            "If you are in front of one of the holes, you may be lucky, but in general you may be unlucky.",
            "And so here you see.",
            "In green, the optimal cost to go calculated analytically for all positions, and the blue ones are the sample estimates, and you see that the sample estimates they get very bad if you.",
            "So it's inefficient.",
            "So the idea one can use is to use."
        ],
        [
            "Important sampling to improve the sampling in the idea of important sampling is simply sad.",
            "You sample from the wrong distribution and you're correct for it.",
            "So in this way we have for instance, for the optimal cost to go, we have to sample.",
            "We have to do this computation, but we can write it as cute rhyme price times Q / Q time, Q prime and so we get this expression.",
            "So now we sample not interpretation is that we sample from this distribution and we discount the instead of only for this term we discount for this whole product in this way.",
            "And so how do we accuse chooses Q prime so Q prime?",
            "Maybe some stochastic process where we put in some probing control which is not zero in this case and which will steer is already towards the best places that we should go and then correct for that.",
            "So if you do that for this example."
        ],
        [
            "Where you hear the plot was 100,000 samples per per X.",
            "Here I have only 100 samples per action.",
            "You see that it's it goes.",
            "It goes very well.",
            "It's obvious that you can improve that this way.",
            "Of course, you have to know how to choose these important directions, and this is.",
            "This is something you can do maybe in iteratively you get first.",
            "You do U zero and then with that you get an idea of where the good use are.",
            "With that you use to improve your sampler and so in this way you can get.",
            "A better result.",
            "So we apply."
        ],
        [
            "That to the idea of motor babbling.",
            "So this is the idea that in biology, if you don't know how the problem of the brain is that the brain doesn't know how the limbs are, they only you know there's no, there's only some sensory input.",
            "There's no hardwired plan of how to control, so the idea that the way infants seem to learn control is just to do random things and see what happens, and so you can also do this in this control setting where you say OK. Now, let's say I have this deterministic.",
            "Plans and I'm now going to choose as controls.",
            "I'm going to choose these these control.",
            "I take noise where the size of the noise is some constant times inverse cost matrix that I have here and so this is originally a domestic control problem, but I make it a stochastic control problem by having this.",
            "By having this exploration with noisy controls and so I have a plant, I have a state I can observe.",
            "I can observe the new state, I can observe the controls, which is our noise, which I do myself, and then I can.",
            "Then, because of the path integral formalism, it turns out that by just observing that you can compute because you get samples from this plant, you never need to know the plant itself.",
            "You never need to know F&G and just from the samples itself you can compute the optimal control.",
            "So this is a model free.",
            "Way to do optimal control.",
            "And so."
        ],
        [
            "This is.",
            "Let me see.",
            "Something.",
            "This is some some little fucker."
        ],
        [
            "Single is 2 degrees of Freedom 2 joint system that is doing is learning to control.",
            "In in these iterations of where you use important sampling to improve the control over various trials, this is maybe 100 to trials, so this.",
            "Is very simple and it's somehow also related to the ideas of of Teodoro.",
            "What he implanted in his algorithms for robotics, and so this is something that is seems to work quite well.",
            "And let me see where's my talk now.",
            "Yeah.",
            "So I come now to the to the third."
        ],
        [
            "Art.",
            "That's the link between control theory and large deviations, and it goes back to an old paper of Schrodinger, which I thought I found very, very interesting, and it's about something called the Schrodinger Bridge for those."
        ],
        [
            "So I don't know it it is a generalization of the Brownian Bridge, so these so consider a system initial distribution S of X and we have a market dynamics which connects which gives the distribution over X at the time T2 as a function of state, given that it was at time T1 at another state for all times between A and T1 and T2.",
            "NBA is here at the is there.",
            "And we are given begin an end distributions PA of X&PB of Z.",
            "So they live here and they live there.",
            "And now we want to compute the marginal distribution for each intermediate time of the most likely trajectories from A to B for entering any intermediate time.",
            "So this is the the vertical destroying the bridge."
        ],
        [
            "So let's first consider the simpler case in the Brownian Bridge, then these these these PA&PB there Delta distributions just for centered on a on X&Z.",
            "And of course the probability to be at state Y at an intermediate time T given that at time a I was a state X and at time BI was in state.",
            "Z is just simply given by Bayes rule.",
            "So this is this.",
            "We have this dynamic so we have the forward numbers to go from Y to Z and we have the forward.",
            "To go from X to Y, we multiply that and we normalize and the normalization.",
            "What is normalization was just the integral overall Y of this product.",
            "So that's the normalization constant over there.",
            "And so now the question is, if X&Z are now from a distribution with these given marginals, then of course we get for the probability to observe Y at T given out these distributions.",
            "Being the integral of all X&Z of this posterior that we had here multiplied by the P of X&Z and integrating over all XZ.",
            "So this is then the solution.",
            "But clearly there are many distributions that have these marginals, and so the question now becomes which distribution do we need to have the which?",
            "Which one do we choose?"
        ],
        [
            "An insured.",
            "In this paper he imagined clouds of particles and they have distribution Essex at the time A and then move according to the Markov process and we discretize the the initial state and the final state, and we denote by gamma.",
            "KL is the number of particles that leave cell Delta XK and they arrive itself Delta ZL and so the probability of an individual particle trajectory is then.",
            "Of K, which is the S of XK times QKL, which is the.",
            "This distribution dial Delta X DD Z and so since that is the probability of an individual distribution, we get all these individual particles that just satisfy a multinomial distribution, where this is the base distribution based probability to the power.",
            "The number of particles that are there normalized.",
            "So this is a standard binomial distribution.",
            "So if we now take the limit.",
            "A van to Infinity, then an we define DKL as basically being this this sort of continuous limit of this gamma.",
            "Then we find that this distribution of this multinomial becomes dominated by by this term, where N is the number of particles and the KL is the KL divergent's global divergent between P, which is this, say posterior over particles.",
            "An S times Q which is the was the prior.",
            "So we see here very naturally that the large deviation argument comes comes here.",
            "And So what we need to do in a large particle limit is to minimize this KL to find the most likely solution and that will set us give us the solution for P. So the KL."
        ],
        [
            "Almost we minimize subject to these constraints that they are at the boundaries.",
            "To have these distributions and the solution can be found by LaGrange multipliers, you will find that P is proportional to two Q.",
            "Damn times two or LaGrange functions and these LaGrange functions they they have to be be found somehow, but if we take this solution and we put it now in in here we have a solution for P we."
        ],
        [
            "But in here we see that P is now proportional to this term, so that will drop out and so the product will now be a function of X * A function of Z.",
            "If I see."
        ],
        [
            "Received so here look."
        ],
        [
            "So P is proportional to this Q and so and the rest is X function to X * Y.",
            "So in other words, if you take the integral over Q / P divided by sorry.",
            "And it is a bit fast.",
            "If we put disease."
        ],
        [
            "Equation in here is dividing by Q and we multiply by P which is proportional to cues that that term drops out and the remaining terms are a function of Z * A function of X.",
            "So we can do this integral separates into integrals."
        ],
        [
            "Anne."
        ],
        [
            "The result is that the optimal solution of the density at an intermediate time, given these initial density and a final density, is a product of two functions where one is moving forward in time, which is his initial conditions at at initial time and then moving with the density forward and the other one has initial conditions at final time moving backward in time, and so we have here again a mixed boundary value condition.",
            "System where these two functions now have to be satisfied to be solved such that their product at initial time is this marginal density and their product at the end time is that marginal density, yeah?",
            "Use the optimal density optimal most sense optimal in the sense of this KL minimization.",
            "Essentially brings back the exponential form."
        ],
        [
            "Assumption.",
            "So the way it is optimal in the following way.",
            "So if you give the initial distribution and you give the market dynamics, the final distribution is given right?",
            "So now you ask yourself, OK, I give the initial distribution.",
            "I give the dynamics, but I also give two other distributions, IPA and a PB, and I want to know how to sort of squeeze the system most likely into that.",
            "And then you get a large deviation argument and there is one solution that dominates that and that's.",
            "The one that minimizes this scale.",
            "And in that sense, it's optimal.",
            "It's the most likely.",
            "So so that the only the only thing in the larger yeah.",
            "In case of course, that would be Gaussian.",
            "Yeah.",
            "In this case, we will be asking yes.",
            "So.",
            "The story is that the salute."
        ],
        [
            "Ocean is a product of 2."
        ],
        [
            "Functions and those who are in are familiar with inference in time series model.",
            "They know of course is.",
            "You have a common filter where you have forward path messages and backward messages and any any posterior distribution is a product of the forward message in the backward message, like here and so it is if you want to compute the distribution of the immediate time, you have some something moving forward, something moving backwards, you multiply it and that is your solution.",
            "Incidentally, the interest of certain ranges was that he was very much intrigued.",
            "By identifying these two with Siam Sidebar being and so you get, the density is the product of the of the wavefunction, and so he thought this was the reason why Schrodinger equation.",
            "His is a quantity is a wave function.",
            "That is it.",
            "This could be an explanation for why probability is the square of the wavefunction that was his argument, but he didn't really pursue it.",
            "Further, as far as I know.",
            "OK, so that's that.",
            "So once we have that, we can take this descaled."
        ],
        [
            "Our version is more seriously and say OK, let's define control problems with this KL divergent.",
            "So let's say that we have a state space and we have we define something.",
            "The uncontrolled dynamics is given some Q trajectory's over overtime.",
            "Maybe first order Markov process and we have some costs and are the probability is to find a posterior distribution P that minimizes akl in the sense that so that we want a distribution that is somehow close to the.",
            "Uncontrolled dynamics that we have here, but at the same time we want to minimize an expected cost term.",
            "And if you if you minimize this, this equation is of course you can do it quite easily."
        ],
        [
            "Because this is just, you know, if you minimize it stands right that you the optimal solution of this minimization problem.",
            "You can write it in close form, P is proportional to Q * E to the into the R and normalized, and if you put that solution, if you put it back into here and look at the optimal cost, then you get ultimate costs minus the log of Z and so in other words we have here that day Z is the side that we had before, which is this, which is this this?",
            "We got from this final cuts formula where we have an integral over trajectories.",
            "Dizzy is nothing else than the normalizer of this distribution is a distribution of trajectory.",
            "So we get a normalizer which is a sum over distributed over trajectories of the uncontrolled dynamics waited by the path costs and the optimal cost to go is the log partition sum.",
            "And here we have the prior distribution and the posterior distribution, so we're getting one slide back.",
            "But we already knew before.",
            "And we can we can do the control."
        ],
        [
            "Population now as an inference computation, which is say OK, we have a time here and we just have to do backwards message passing.",
            "So if we want to compute, for instance, the optimal control where to move from state X0 to X1, we have this whole distribution of trajectories we have to marginalized out state X2, T, do that some and you can push this some through the time series and basically collect these in terms where you get sort of recurrent message passing equations that do the sum 1 by 1.",
            "Until you are at a time XX, one and these are these recurrent equations.",
            "They're basically these backward message passing, so the whole control computation becomes an inference,"
        ],
        [
            "Jason so this is the overall picture, so if you have normally a dynamics and you set up your Bellman equation through dynamic programming arguments, and then maybe do some approximation to get to some optimal control in this picture, we look at the restricted class of control problems and we have a date for this class.",
            "We can do the solution we have in closed form, but of course it's intractable and we can use approximate inference to then do the computation.",
            "Officient and so OK.",
            "So what is that?",
            "So how does that relate to the previous story?",
            "If we now set the."
        ],
        [
            "Dynamics is just being over small time intervals as being just a Gaussian with this nonlinear drift term in it, and we have the control dynamics as being adding this this control term.",
            "If we now look at the KL term for this, this cost for this term, we will find that if you put it in that this will automatically reduce to this term that we had before where we have explicitly now the relation between this R and this new minus one.",
            "So it is an incense is an explanation why this funny relation between R and new must hold because it is related to this class of of KL divergent problems.",
            "More general than the government."
        ],
        [
            "It is, yeah, so you can do through all the models also.",
            "So, um.",
            "Just a few remarks on this on this system, so we have studied.",
            "For instance, the the average cost case of this of this problem.",
            "So in the limit the time goes to Infinity.",
            "These these message passage equation.",
            "They become time independent and basically you get an eigenvalue equation where beta is a vector with indexed by the states of the system and H is a matrix which consists of the uncontrolled dynamics.",
            "Multiply it on the right with the exponentiated costs and so we have to find.",
            "You can show that the optimal control is given by the parameter benyus eigen pair of this of this system, basically the largest Eigen eigen value, the optimal cost average cost is becomes the log of the largest eigenvalue which gives the minimal cost and the cost to go is the log of the eigen eigenvector and the optimal Markov process is given by the uncontrolled Markov process.",
            "Times the cost times the ratio of these of these components in the in the eigenvector, and so this is something that you can then compute by using linear algebra."
        ],
        [
            "One more thing, so another funny thing is that in the case that the uncontrolled dynamics satisfy detailed balance, which means that detailed balance means that.",
            "QY given X times QX is QX given y * Q Y, so these dynamics this these two terms are given, but detailed balance means that there exists such a Q which which satisfies this which is not true for all dynamical systems.",
            "But if it satisfies and it's called detailed balance if such a Q exist then one can show that the control system also satisfies detailed balance.",
            "And the relation is that the optimal stationary distribution over the over the controlled a system is the stationary distribution of the uncontrolled system multiplied by this first eigenvalue squared.",
            "So there's this funny square coming back again in the probability."
        ],
        [
            "So he is here example.",
            "I let me not go over this.",
            "So we have done a."
        ],
        [
            "So one of the things is that we have looked at stochastic implementation of this of this rule.",
            "So for systems where which are small, you can just compute such a program vainius eigenvector by by just by the power method.",
            "You just take an arbitrary vector and you multiply.",
            "You get the extreme eigenvalue and eigenvector.",
            "How this algorithm describes how you can do that in a stochastic way without ever having to store the whole vector.",
            "So for state spaces, which are very large where you cannot store the whole vector, we can use this uncontrolled dynamics to basically sample do a sampling procedure, and under some conditions we can prove that is this converges to that system that."
        ],
        [
            "Solution.",
            "Easy example for a small maze.",
            "I'm sorry for the graphics, they are something went wrong.",
            "This is this is a maze with with the goal here and you start anywhere and here you see the solution for the optimal cost to go, which is nicely gradient and here you see the behavior of the algorithm.",
            "He uses the eigenvalue going to one which is a scaled version.",
            "In this case is by construction has to go to one and you see convergence of the algorithm.",
            "The stochastic method.",
            "So I've come to the end of my talk."
        ],
        [
            "I've I think I've touched on many things and only lightly, but that was the idea.",
            "As far as I understand, quantum mechanics does not seem to correspond to a useful class of control poles, but this is for me.",
            "It's part of the this week's discussion."
        ],
        [
            "I have looked at another class of control problems that links inference to statistical physics and to the machine learning methodology.",
            "I've already told you much about that.",
            "We have done several studies here.",
            "You see, for instance multi agent systems that is being controlled and if you increase the number of agents.",
            "Of course the exact computation of the control scales exponentially with the system size we have used here, belief propagation and mean field methods to get to get polynomial time behavior.",
            "I've shown that battery.",
            "That's it for."
        ],
        [
            "Stochastic control problems that there is for this class of problems.",
            "We have got some insight in the role of noise and particularly this kind of phase transitions that occur for particular noise levels in the problem."
        ],
        [
            "I.",
            "There has been a lot of work on comparison with state of the art reinforcement learning methods compared this these possible methods, but definitely my group of Steven Sjolund.",
            "Pedal steel door was here.",
            "We'll talk about that and also more recently in the Group of Young Boy Moto who's also here will also be talking about some of that work."
        ],
        [
            "Um?",
            "So then there's and I've tried to point out the link between large deviations and KO control theory and that will is also leads to possible generalization by considering other distributions as you as you pointed out."
        ],
        [
            "I've some papers on the website.",
            "If you want to read more on that.",
            "And I have some questions for this for this for this conference, but one is this quantum mechanical question, which is basically the."
        ],
        [
            "Following so.",
            "So this control that I've considered is all fully observable if you talk about partial observable problems, you're not.",
            "You have to deal with uncertainty over these unobserved things, so these uncertainties captured in terms of distributions and these distributions were now being controlled by your actions.",
            "So you get you get nonlinear control diffusion.",
            "So my question is, does there exist a class of partial observed control problems that can be linearized in the sense that that I was looking for in the quantum mechanical case, but that I've failed to find and this is something that is still very much on?",
            "On my mind.",
            "There's another open question a little bit more practical.",
            "In a possible control theory, the optimal cost to go is a free energy."
        ],
        [
            "As I explained this way, it's an integral of a path.",
            "There's another body of work which is related to the Jasinski equation, and it relates to free energy difference of two states to the path and roll over the work.",
            "It's some expression of this.",
            "Now these expressions they look very similar because if you interpret the free energy as the free energy difference is the cost to go, you get basically also integral over path.",
            "So are these two statements related?",
            "I don't know.",
            "I've been trying to work it out, but I have no answers.",
            "Maybe some of you know that."
        ],
        [
            "So this is the initial science, like I started with an here I have put some of the names of the people that contribute to the different parts of far as I understand it, so at least there's some work on statistical physics relating to inference and algorithms, and that is work that will be presented by Mark, Massabesic, INA and these people here with following.",
            "Basically this this kind of line here."
        ],
        [
            "Dender is some people talking about quantum mechanics and control.",
            "I'm not sure where to grab, will talk about quantum mechanics, but so that's so that's that link there.",
            "Then the."
        ],
        [
            "Will be quite a few people talk about control, statistical physics and large deviations, so that's going in this direction.",
            "And then."
        ],
        [
            "There will be some people looking at the relation between control and inference.",
            "This link here.",
            "And then there will be."
        ],
        [
            "Some people looking at the relation to the brain to biology.",
            "And there will be some people looking at the."
        ],
        [
            "Relation to control.",
            "And that's the end of my talk.",
            "Thank you very much.",
            "So since that day finally.",
            "It's very important to know what.",
            "To make connections from PBS to specifications.",
            "And so far all these frameworks.",
            "Here's one with continuous state continuous time problems.",
            "Deal with the email Gmail deletes, so there is a real version of the final cut you Mother.",
            "You can find actually the equivalent to financial equation, an expectation that if you have something forward in time, we can actually approach my English Wikipedia, but in fact it is the normal the normal version of this, so difficult.",
            "Problems you can actually live account.",
            "There's a problem and equation.",
            "Anne.",
            "But so how would it work?",
            "Because the assault of Feynman cuts lemma is is intimately related to the linearity that you have a.",
            "You have a sort of a Green's function, and you use a solution as a linear superposition.",
            "How about this?",
            "No, no, no.",
            "I don't know about it now.",
            "Well, I would like to learn about it.",
            "Two soundlink with forward and backward stochastic differential equation.",
            "So something is not going forward.",
            "You have to back or stochastic presentation and now you have to ask how I'm going to medically indicated this problem so I don't know if that is medically physically like.",
            "I'm aware there's a book by Baiza and Lean, and now we don't.",
            "Stochastic difference.",
            "Yeah, and they have also these backwards equations and stochastic equations.",
            "But the link that they are making there is more.",
            "In order to find a stochastic custom variation of the yeah, yes, exactly exactly.",
            "Yeah.",
            "So weird.",
            "No, I don't know.",
            "I should talk about it in here.",
            "So why is the standard to Goshen observation, Gaussian noise and linear dynamics?",
            "With simple example, you're partially observed.",
            "Linearizations for instance, if you have, if you have if you have something like DX is Alpha U DT plus noise something like this and if you don't observe Alpha.",
            "You get distribution of Alpha and is this if you know Alpha this is linear predictor control problem.",
            "If you don't observe, our file becomes a nonlinear problem problem.",
            "Because you have to parameterise the uncertainty in Alpha in a distribution with certain parameters and these parameters will also evolve overtime, so they are coupled with these dynamics in the control computation.",
            "But there is 1 case of course, which is his point and and leaves with partial observer comes from additive Gaussian noise.",
            "Yeah, which is OK, OK?",
            "So there is an example to question may be trivial, but yeah, so that's sort of the equivalent case in which the optimal control does not depend on the noise.",
            "Yeah yeah.",
            "Is actually formulated as a.",
            "Send please system identification and yes, state identification problem.",
            "There's effective discretion caitians of that.",
            "Yeah, we do run a battery of common filters and then you compute conditional density in both the signal space and the model space.",
            "Can be done tomorrow.",
            "But these common filters are the nonlinear no.",
            "The beauty of, well, if you assume that your model is linear but you don't know what it is, yeah, so you postulate a grid of models, then you run the common set while you run the common folder.",
            "Assuming each of those models in known is known battery I see.",
            "And if you run them as solutions of the conditional density equation and you also at the same time get the conditional density joint conditional density for Alpha and this state, yeah.",
            "Maximum is a good idea I guess, but I guess you have to sort of the discretization of your Alpha.",
            "A very difficult limit.",
            "Yeah, Alpha, go to Infinity.",
            "Computational effectiveness yeah OK?",
            "So no free lunch.",
            "So far maybe here maybe here OK?",
            "Any other questions?",
            "If not, Oh yeah.",
            "And maybe that relates to longer between controller installation and maybe we're going to see that.",
            "But since we have people from information sharing, typically 11 takes classes in state, destination and detection theory.",
            "If you are told about the camera roll bound, and we know that for the general case when you have a comma, prepare for linear case active noise that the computer is actually very optimal estimator.",
            "Because he treated the camera logo, so I was wondering what is really the equivalent of this.",
            "Principle to control because if I mean there is value, at least for the guitar cases when we have only added noise and Gaussian noise, and So what is really they do a concept of grammar out lower bound?",
            "But the come over this is also about I thought about sampling, right?",
            "I mean how much how many samples you have.",
            "It bonds their variance.",
            "Basically yeah, but it's a statement in how much samples.",
            "Estimate.",
            "Yeah, so it will be.",
            "It will come in probably if you do.",
            "If your estimate to pass through with the final number of samples somehow.",
            "Oh no, you know what you?",
            "OK, so I'm right now I'm sure I'm just guessing.",
            "When we come around, robots take says that if you have enough samples, the violence at some point, if any, is the number of samples.",
            "Yeah yeah.",
            "Or if you set up from the information.",
            "Patient is going to have basically been maximized.",
            "Hey Bob.",
            "So we speak about violence here, right here is the nation.",
            "What's wrong with connection to form?",
            "The only connection I see is, you know, if you have a sample estimate of this bathroom rule.",
            "With the number of samples you get an estimate with which has a variance.",
            "Isn't that the connection?",
            "I was thinking that the the the draw concept will be required functions.",
            "I don't know.",
            "I'm sorry I don't know.",
            "Any other questions before?",
            "OK, thank you very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I come from a field where I've been working in what is called machine learning and machine learning.",
                    "label": 0
                },
                {
                    "sent": "They use Bayesian methods and Bayesian methods are about inference.",
                    "label": 0
                },
                {
                    "sent": "An inference is computing things with probabilities, so computing marginals, computing correlations in any big probability model and what has been my story in the machine learning is is with other people is trying to use statistical physics methods.",
                    "label": 0
                },
                {
                    "sent": "To to help the inference computation to speed up.",
                    "label": 0
                },
                {
                    "sent": "So, as you may know, it is just these computations are intractable.",
                    "label": 0
                },
                {
                    "sent": "They scale exponential with the size of the problem and using mean field methods or using belief propagation or using even multi color sampling methods.",
                    "label": 0
                },
                {
                    "sent": "All methods that originated from statistical physics have been very helpful to make the inference computation tractable with many many applications in machine learning ranging from robotics to computer vision to expert systems.",
                    "label": 0
                },
                {
                    "sent": "Anything so I've been doing that for awhile and I thought at some point.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That is, these interact abilities that are also interact abilities encountered in control theory, particularly stochastic control theory, where you also have probabilities, but now overtime and wouldn't it be nice to sort of connect these interact abilities to the intractability is observed in the machine learning and graphical models, so I was looking into that.",
                    "label": 0
                },
                {
                    "sent": "I found the connection.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Some connection between control.",
                    "label": 0
                },
                {
                    "sent": "I was intrigued with that.",
                    "label": 0
                },
                {
                    "sent": "The connection between control and quantum mechanics, first based on the on the work of Francesco Guerra here in the audience, but then also digging down to the work of Ed Nelson etc.",
                    "label": 1
                },
                {
                    "sent": "And I was intrigued by that because that is a work where you get a control problem, which is a nonlinear problem with diffusions and the quantum mechanics is basically a linearisation of that, making it making it sort of.",
                    "label": 0
                },
                {
                    "sent": "I thought it was an interesting connection, so I've really been chewing on that for awhile to see whether there is a connection.",
                    "label": 0
                },
                {
                    "sent": "I'm going to tell you a little bit about it, but at some point I had to give up on that and I actually found a more direct.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Link between the control theory and the statistical physics.",
                    "label": 1
                },
                {
                    "sent": "Any inference, which is also what I'm going to be talking about.",
                    "label": 0
                },
                {
                    "sent": "So then when that was established.",
                    "label": 0
                },
                {
                    "sent": "Other people got interested, Ann.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so people were telling me that basically these control messages that have been talking about using path integrals, they are have to do with large deviations.",
                    "label": 0
                },
                {
                    "sent": "They have to lose with martingales theory, so there's a whole bunch of mathematicians that now link into all these kind of things, and some of them are here and then.",
                    "label": 0
                },
                {
                    "sent": "In the end there is also of course people in robotic.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's interested is Yvonne Gallo sitting here using these control methods in robotics and also people using that too.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Duke Neuroscience and use these methods there, so this is a very the short story how this came about and from my perspective and.",
                    "label": 0
                },
                {
                    "sent": "And this part of the story that I want to get together here.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So my my talk will consist of three parts.",
                    "label": 0
                },
                {
                    "sent": "The first part is is trying to give this this quantum mechanical link with control theory and sort of explain to you where I think it fails and I'm not.",
                    "label": 1
                },
                {
                    "sent": "This may not be I. Hopefully that's not the end of it, but as far as I'm understanding it, this connection is not so useful.",
                    "label": 0
                },
                {
                    "sent": "Maybe for control, but it's intriguing.",
                    "label": 0
                },
                {
                    "sent": "It.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is it is based on these people and then the second part is on the personal control theory which developed which is was originally.",
                    "label": 0
                },
                {
                    "sent": "The idea goes back maybe two half in the 50s even 2 Schrader Rim himself flaming a meter meter was coming.",
                    "label": 0
                },
                {
                    "sent": "This afternoon is not yet here.",
                    "label": 0
                },
                {
                    "sent": "Have made important have made these connections before.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the third part is a little is my understanding of the link between control theory and large deviations using an old paper of Schrodinger from 1919 thirty two.",
                    "label": 1
                },
                {
                    "sent": "I have to apologize in the sense that in a bit because I wanted to give an overview, so as a necessity the talk will be somewhat superficial, but that's how it.",
                    "label": 1
                },
                {
                    "sent": "That's how it is so controlling quantum mechanics.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if we take the Schrodinger equation which was flies away function size away function, sorry, so complex valued object and it's it's a linear equation, sorry.",
                    "label": 0
                },
                {
                    "sent": "Absolute brackets missing, missing here around.",
                    "label": 0
                },
                {
                    "sent": "Then we can write it right in equation by writing it as a as a as a as a norm as the norm times times in the face.",
                    "label": 0
                },
                {
                    "sent": "If we write it that with Rowan as both being functions of space and time and we plug it in the Schrodinger equation, we get two coupled equations.",
                    "label": 0
                },
                {
                    "sent": "One is sort of diffusion type of equation where rho is a function of space and time where the diffusion has a drift term, which is a gradient of a scalar.",
                    "label": 0
                },
                {
                    "sent": "Which is this S&S itself is a is satisfying dizzy equation, which is looks a little bit for like a like a bellman equation.",
                    "label": 0
                },
                {
                    "sent": "But it has this funny potential term which involves the density of States and of course the potential itself.",
                    "label": 0
                },
                {
                    "sent": "This potential here and so this.",
                    "label": 0
                },
                {
                    "sent": "This was all very well known.",
                    "label": 0
                },
                {
                    "sent": "So you see that these two equations being equivalent to the Schrodinger equation.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this can be seen sort of as a control problem if we if we go back to if I remind you of the Pontryagin minimum principle.",
                    "label": 1
                },
                {
                    "sent": "So suppose so this is a little bit and interlude, so consider deterministic control problem X dot is some function of X and you use the control.",
                    "label": 0
                },
                {
                    "sent": "I have a cost which is an end cost which is an inner product with some scalar and I have a path cost an I want to find the trajectory U.",
                    "label": 0
                },
                {
                    "sent": "In this finite horizon control that minimizes this, this cost, and we can do that by constraint optimization.",
                    "label": 0
                },
                {
                    "sent": "It's a well known argument you define Lagrangian with with LaGrange multiplier, Lambda, which is also a function of time.",
                    "label": 0
                },
                {
                    "sent": "And you write down the Lagrangian, which is the LaGrange multiplier term which is constraining the dynamics.",
                    "label": 0
                },
                {
                    "sent": "And this is done the cost and you are you going to minimize this?",
                    "label": 0
                },
                {
                    "sent": "This discussed and integrated overtime and if you use a variational argument and you set the derivative with respect to you an X in Lambda, set it equal to 0.",
                    "label": 0
                },
                {
                    "sent": "You will find 3 equations.",
                    "label": 0
                },
                {
                    "sent": "One is that that you have to minimize with respect to you this L. Which gives you what is called the Hamiltonian, which is a function of the state and the Co state and these two remaining variables.",
                    "label": 0
                },
                {
                    "sent": "They satisfy these coupled equations, which are some very I like identical to the to the Hamilton equations of motions, where X is the can be interpreted as a state, and Lambda can be interpreted as the as the momentum variable, so they have they have this disjoint dynamics and X of course is initialized at initial time, which was the.",
                    "label": 0
                },
                {
                    "sent": "The origonal control problem an Lambda is because of the variation argument gets boundary condition at at the end time.",
                    "label": 0
                },
                {
                    "sent": "So you get this mixed boundary value problem to solve.",
                    "label": 0
                },
                {
                    "sent": "So that is 1 slide the poultry organ.",
                    "label": 0
                },
                {
                    "sent": "Minimum principle.",
                    "label": 0
                },
                {
                    "sent": "Now if we go back to the quantum mechanics.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If we define this Hamiltonian here this way.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If we define that.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In this way, where we identify row with the state an S as the Co state, then we will find indeed that this H is such that that it satisfies these Hamilton equations.",
                    "label": 0
                },
                {
                    "sent": "For this for this system as satisfying it for the for the Schrodinger equation.",
                    "label": 0
                },
                {
                    "sent": "So in other words we.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We can find that the quantum mechanics satisfies the Hamilton dynamics with position Rowen with Momentum S. But now we have also the boundary.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Patience so we have to if we want to now make the link with the point with the control in the Pontryagin principle we have to initialize the density at initial time so that's that's fine and we have to get this boundary condition for the Co state at the at the end time which was the gradient.",
                    "label": 0
                },
                {
                    "sent": "This gradient which becomes noticed dysfunction five that we had and so.",
                    "label": 0
                },
                {
                    "sent": "We get that the quantum mechanics satisfies the Pontryagin equations for optimal control.",
                    "label": 0
                },
                {
                    "sent": "And so that's sort of the can.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The problem is that this is the dynamics F is, so this is this gradient.",
                    "label": 0
                },
                {
                    "sent": "This sort of density flow and the cost is this term here and this end cost that we have here.",
                    "label": 0
                },
                {
                    "sent": "Of course we could consider end cosio where this whole term is absence.",
                    "label": 0
                },
                {
                    "sent": "So this is the formulation of quantum mechanics as a control of distributions.",
                    "label": 0
                },
                {
                    "sent": "And it was pointed out by by, by Guerra and by Nelson that that you can make a stochastic.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Interpretation of this where you say OK if a dynamics evolve Ng with some drift in some stochastic process with Brownian noise, and then I distinguish between a mean forward velocity and amine backward velocity which are which.",
                    "label": 0
                },
                {
                    "sent": "Then together give the mean velocity and the difference between them is quality osmotic velocity which is the gradient of the log of the density.",
                    "label": 0
                },
                {
                    "sent": "So this if you make this interpretation.",
                    "label": 0
                },
                {
                    "sent": "Then the control problem becomes a stochastic control problem where this equation is of course nothing else then the governed by the focal Planck equation, which can be written as the gradient of this mean velocity and the cost now becomes in terms of this can be written this custom.",
                    "label": 0
                },
                {
                    "sent": "This custom V. Can now be written in terms of.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "V Plus and V minus and it becomes.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of this term, and this is what was pointed out by by Guerra as being the generalization of acceleration to the stochastic case.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In this.",
                    "label": 0
                },
                {
                    "sent": "So there's a famous quote of Nelson saying that stochastic mechanics, as this is called is quantum mechanics make difficult, and the reason why is that in order to make this system to run this system, you have to compute AV Plus and V plus means that you have to get the solution of S and computers gradient and at the end of the day what you really have to run is a shorter equation itself before you can actually simulate this dynamics.",
                    "label": 0
                },
                {
                    "sent": "He used an example for the quantum harmonic oscillator, where the this is the.",
                    "label": 0
                },
                {
                    "sent": "This is the mean velocity and these are stochastic trajectories around it.",
                    "label": 0
                },
                {
                    "sent": "This is a plot of the fluctuations around the mean AUC to sort of beats overtime.",
                    "label": 0
                },
                {
                    "sent": "So this is the funny kind of dynamics that you can get from this system, so I've been staring for this at this for for some time.",
                    "label": 0
                },
                {
                    "sent": "And I thought, what about?",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If quantum mechanics is stochastic, optimal control made easy, you know if you could do could reverse the arrow somehow.",
                    "label": 1
                },
                {
                    "sent": "But the problem I'm stuck with and still stuck with this is that the control formulation has the mixed boundary conditions and this is not so easy to relate to the boundary conditions on the sharing equation.",
                    "label": 0
                },
                {
                    "sent": "And the control cost this term fee plus B minus is in fact is not linear function of the density and how to interpret that as a custom?",
                    "label": 0
                },
                {
                    "sent": "I am at a loss, so I had to give up.",
                    "label": 0
                },
                {
                    "sent": "I gave up on that.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And I moved to a simpler case, which is the case discussed by also by Fleming and Meter, which",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Chiz",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Skip this.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you have time.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So is the idea to express the control problem as an inference problem and try to use ideas from statistical physics to make that inference computation tractable?",
                    "label": 1
                },
                {
                    "sent": "Sure, sure, sure, yeah, yeah.",
                    "label": 0
                },
                {
                    "sent": "When you say that quantum mechanics miss boundary conditions running question, I mean so this one case should be easy which is.",
                    "label": 0
                },
                {
                    "sent": "Gaussian linear.",
                    "label": 0
                },
                {
                    "sent": "The common equations control the common filter, especially where you can separate the two problems.",
                    "label": 0
                },
                {
                    "sent": "So is that analogy Phantom account for this?",
                    "label": 0
                },
                {
                    "sent": "I don't think so.",
                    "label": 0
                },
                {
                    "sent": "So the if you if.",
                    "label": 0
                },
                {
                    "sent": "Yeah, but so.",
                    "label": 0
                },
                {
                    "sent": "But that's so in this in this class that I'm talking about his personal methods.",
                    "label": 0
                },
                {
                    "sent": "There it is easy because there you get the linear quadratic control you get to carbon filter and you get the separation.",
                    "label": 0
                },
                {
                    "sent": "But in the quantum mechanical case.",
                    "label": 0
                },
                {
                    "sent": "So in the quantum harmonic oscillator, I don't think you get it separation, but I'm looking at.",
                    "label": 0
                },
                {
                    "sent": "An infinite interval and assuming Gaussian complex Gaussian, then it's exactly.",
                    "label": 0
                },
                {
                    "sent": "So so it becomes a. I wonder whether.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I'm not sure.",
                    "label": 0
                },
                {
                    "sent": "Is that the solution of Sherry questions the exponential?",
                    "label": 0
                },
                {
                    "sent": "Type is fails.",
                    "label": 0
                },
                {
                    "sent": "Phil's wedding density of the.",
                    "label": 0
                },
                {
                    "sent": "Solution Schrodinger equation and do something with it nice in the case where you assume this Gaussian, yeah.",
                    "label": 0
                },
                {
                    "sent": "Just by chance.",
                    "label": 0
                },
                {
                    "sent": "Is there is the same problem in the classical mechanics that position initial time and velocity at final time is bigger engine principle, yeah?",
                    "label": 0
                },
                {
                    "sent": "Only when you integrate the buybacks then they will appear in the usual sense.",
                    "label": 0
                },
                {
                    "sent": "But the the very short principle over classical mechanics, it is exactly all this shape, yes.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "We built the concept of state.",
                    "label": 0
                },
                {
                    "sent": "Position with logic which have all been times according to English.",
                    "label": 0
                },
                {
                    "sent": "Yes, yes yes yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah, it's like saying also that classical mechanics is a special case of control theories that like if yes, exactly, that is that.",
                    "label": 0
                },
                {
                    "sent": "The same structure.",
                    "label": 0
                },
                {
                    "sent": "Could you show your conditional time exactly?",
                    "label": 0
                },
                {
                    "sent": "And velocity is the control exactly exactly.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that works perfectly if final state is not constrained.",
                    "label": 0
                },
                {
                    "sent": "It is.",
                    "label": 0
                },
                {
                    "sent": "I don't wanna screw up.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "So the problem you mentioned on the exponential form of the Phantom account.",
                    "label": 0
                },
                {
                    "sent": "This is not specific one connection.",
                    "label": 0
                },
                {
                    "sent": "Whenever I try to go over your beyond Gaussian linear Mr. Costa control like this actually seems like.",
                    "label": 0
                },
                {
                    "sent": "So it's again not quantum mechanics.",
                    "label": 0
                },
                {
                    "sent": "Exponential answers.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So this is another tack to the to this.",
                    "label": 0
                },
                {
                    "sent": "Trying to make something linear out of nonlinear problems, and this is using the.",
                    "label": 1
                },
                {
                    "sent": "A simpler approach in the sense so the class of control problems.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One considers is is this class where you have a state variable which has a nonlinear dynamics and where the control acts linearly multiplied by some arbitrary nonlinear function of the state, and where there is some Gaussian noise which act in the same in the same subspace as the control and the control cost is an expectation value involving an arbitrary end state and cost arbitrary state costs, but is quadratic in the control variable itself.",
                    "label": 0
                },
                {
                    "sent": "So it is like an arbitrary dynamical system where you allow an easy control mechanism which is linear with quadratic costs, right?",
                    "label": 0
                },
                {
                    "sent": "And if I now assumes that there is a relation between there's noise covariance matrix of PSI and the R matrix here, in the sense that they are related by a scalar value Lambda which is positive so that ours is equal to some constant times the inverse covariance matrix.",
                    "label": 0
                },
                {
                    "sent": "Of the noise.",
                    "label": 0
                },
                {
                    "sent": "Then well, even before that, but if so, this is 1 makes and then the the Hamilton Jacobi equation becomes becomes this one which is linear quadratic and it has the boundary conditions and then you can.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Can minimize disrespect to you and substitute that solution back in.",
                    "label": 0
                },
                {
                    "sent": "You get a nonlinear equation and now if this funding relation between the noise and our holds and you make this log transform of the cost to go, then with this with this parameter Lambda appearing here, then this Hamilton Jacobi equation reduces to this linear equation.",
                    "label": 0
                },
                {
                    "sent": "And and where is this one had boundary conditions on the on J being equal to five, then this one has boundary conditions on side being equal to the exponent of five over Lambda.",
                    "label": 0
                },
                {
                    "sent": "Because of this of this log transform.",
                    "label": 0
                },
                {
                    "sent": "So there is a class of control problems for which the Bellman equation is linear and that is this class of control problems.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "So did in order to solve this.",
                    "label": 0
                },
                {
                    "sent": "So since it's a linear, the great advantage of it is that you can use the Feynman cuts.",
                    "label": 0
                },
                {
                    "sent": "The message is integral to solve it and you can show work to following reconsider.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "QA distribution of the trajectories that govern the uncontrolled dynamics that is in other words, that is the system that we started out with.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With control 0.",
                    "label": 0
                },
                {
                    "sent": "So that is what is called the uncontrolled dynamics.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so this this.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in Q is the distribution over the trajectories under that uncontrolled dynamics?",
                    "label": 1
                },
                {
                    "sent": "So then you can show that this that that the PSI on the previous slide which was which was linearized Bellman equation is now the solution of Q multiplied by exponent of X where X is is an action which counts the path costs and the end cost.",
                    "label": 0
                },
                {
                    "sent": "And so it is like a.",
                    "label": 0
                },
                {
                    "sent": "You can interpret this that that the optimal cost to go, or the exponent of it, is given by an integral of trajectories, where each trajectory is penalized by the cost of that particular trajectory.",
                    "label": 0
                },
                {
                    "sent": "And of course, the nice thing is that it's I can now be estimated sampled by this from this uncontrolled dynamics you sampled at this uncontrolled dynamics.",
                    "label": 0
                },
                {
                    "sent": "You don't know the control you sample this, you discount the the trajectories with this with this term and you get the optimal cost to go, and in this way you also get the control.",
                    "label": 1
                },
                {
                    "sent": "So the the the Q can be seen as sort of a prior in the Bayesian sense.",
                    "label": 0
                },
                {
                    "sent": "It's a distribution over trajectory.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And one can ask, one can see here that is Q.",
                    "label": 0
                },
                {
                    "sent": "That is that This site is.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "All of it is sort of a partition sum.",
                    "label": 0
                },
                {
                    "sent": "One could think well if queue times.",
                    "label": 0
                },
                {
                    "sent": "This is the the the normalizer of some distribution that where this is the normalizes the partition sum then what is the underlying distribution?",
                    "label": 0
                },
                {
                    "sent": "Well of course it's simply the numerator divided by the normalization.",
                    "label": 0
                },
                {
                    "sent": "So in other words.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is the.",
                    "label": 0
                },
                {
                    "sent": "This is the distribution that this Psy is the partition sum of right?",
                    "label": 1
                },
                {
                    "sent": "So we have Q times.",
                    "label": 0
                },
                {
                    "sent": "This is discounted thing and we normalize it and if we can identify this distribution, so Q is the distribution of uncontrolled dynamics, uncontrolled trajectories and P is the distribution over optimally controlled trajectory's is the posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "And so sign was the was related to the cost to go by this log transform.",
                    "label": 0
                },
                {
                    "sent": "So we find out the cost ago is minus Lambda log off site, which was this expression.",
                    "label": 0
                },
                {
                    "sent": "So we see this.",
                    "label": 0
                },
                {
                    "sent": "We clearly find here an interpretation as a free energy where J is the free energy, the cost to go is a free energy where Lambda plays the role of the temperature.",
                    "label": 1
                },
                {
                    "sent": "And finally, one can go back to the fact that the control is the gradient of the cost to go by, and we know if we take gradients of free energies we get expectation values.",
                    "label": 0
                },
                {
                    "sent": "So you could take the gradient of the cost to go to compute the optimal control you find after some calculus that it's basically the expectation value of the first noise direction under this posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "So we have a distribution over trajectories which are penalized.",
                    "label": 0
                },
                {
                    "sent": "Some are good, some are bad, and we take for every first direction of the path.",
                    "label": 0
                },
                {
                    "sent": "We weigh them and that gives us exactly our optimal control for this class of problems.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is a recap.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "So this is the dynamics we have this funny relation that means basically that this means that that control that in directions where you have high noise.",
                    "label": 0
                },
                {
                    "sent": "This term the R has to be small, which means that control is cheap, so you can do have large control in direction of large noise.",
                    "label": 0
                },
                {
                    "sent": "An interactions of very low noise the vice versa.",
                    "label": 0
                },
                {
                    "sent": "Also if you have no noise, this term goes to Infinity or becomes Infinity and basically penalizing the control to zero.",
                    "label": 0
                },
                {
                    "sent": "No controls allowed, right?",
                    "label": 0
                },
                {
                    "sent": "So there's no control in the deterministic directions and the control has to be somehow proportional in that sense.",
                    "label": 0
                },
                {
                    "sent": "The HB equation is linear.",
                    "label": 1
                },
                {
                    "sent": "It has this kind of funny Schrodinger local like form, but of course This site is a real valued function, is not complex.",
                    "label": 1
                },
                {
                    "sent": "The solution is given by final cuts formula.",
                    "label": 1
                },
                {
                    "sent": "the Q is the distribution of the uncontrolled dynamics.",
                    "label": 0
                },
                {
                    "sent": "There's a posterior distribution and the optimal control is expectation value of that under that distribution.",
                    "label": 1
                },
                {
                    "sent": "Lambda here is some sort of temperature, yeah?",
                    "label": 0
                },
                {
                    "sent": "So, at least in one limit would love those.",
                    "label": 0
                },
                {
                    "sent": "There's one other no one Misty.",
                    "label": 0
                },
                {
                    "sent": "Infinity 2 zero.",
                    "label": 0
                },
                {
                    "sent": "You should get back.",
                    "label": 0
                },
                {
                    "sent": "The deterministic control.",
                    "label": 0
                },
                {
                    "sent": "Yeah, you do so.",
                    "label": 0
                },
                {
                    "sent": "I think that so here if you if you take Lambda equal to 0.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This distribution peaks on the maximum, and so you get JS.",
                    "label": 0
                },
                {
                    "sent": "Basically S, which is just the cost of the path.",
                    "label": 0
                },
                {
                    "sent": "But again, the entropy here is the standard entropy.",
                    "label": 0
                },
                {
                    "sent": "Battery which is conjugated to this temperature.",
                    "label": 0
                },
                {
                    "sent": "Is that the other posterior?",
                    "label": 0
                },
                {
                    "sent": "It's not cross entropy between P&Q, no no.",
                    "label": 0
                },
                {
                    "sent": "In the in the, so there's not a formulation that will come to at the end of this talk where where I relate this to do a cross entropy.",
                    "label": 0
                },
                {
                    "sent": "OK, all the virgins between P&Q.",
                    "label": 0
                },
                {
                    "sent": "Product of.",
                    "label": 0
                },
                {
                    "sent": "Cute, yeah, so there is so that is hidden in this formulation.",
                    "label": 0
                },
                {
                    "sent": "We will find it.",
                    "label": 0
                },
                {
                    "sent": "Yes, OK. Any other?",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So here's an example of so many.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "People may have seen this before, so if I have a 1 dimensional X an I've you an excited so we want to mention of course is relation between R and new is is is trivial is always true.",
                    "label": 0
                },
                {
                    "sent": "So if no state dependent pass costs and I have just have you squared of the control costs and I have two goals at plus or minus one and I start here somewhere at X and here is T if you then solve the control problem in this case for this class of problems you find that optimal cost to go is convex.",
                    "label": 0
                },
                {
                    "sent": "If you very far away and if you move closer to the entire it, you'll get a symmetry breaking where it has the Brownian particle has to make a choice, but it's optimal for far away to actually steer towards the middle.",
                    "label": 0
                },
                {
                    "sent": "And the reason is that if you far away your forward cone of diffusion is so wide that it will incompass both targets and there is no need to make a choice.",
                    "label": 0
                },
                {
                    "sent": "Only later your forward cone is actually going to hide between these two.",
                    "label": 0
                },
                {
                    "sent": "And of course you have to make choices so you get this out and you get.",
                    "label": 0
                },
                {
                    "sent": "So when the future is uncertain, your deley your decisions.",
                    "label": 1
                },
                {
                    "sent": "This is take home message for management course maybe.",
                    "label": 0
                },
                {
                    "sent": "Of course, the more uncertain, the wider your forward cone and the later you will make that decision, and it domestication will make it infinitely far back in time.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Using this formula for the optimal control, this formula they said that the optimal control is the expectation failure under the posterior of these first noise direction.",
                    "label": 1
                },
                {
                    "sent": "You can of course make a sample estimate by using getting some samples mu and penalising them with the costs, and then taking the first noise direction and getting optimal control in this way.",
                    "label": 0
                },
                {
                    "sent": "And here's a little cartoon of how that will work, so here is a state here is time there is.",
                    "label": 0
                },
                {
                    "sent": "Initial state is in this case this, and there is.",
                    "label": 0
                },
                {
                    "sent": "There's a.",
                    "label": 0
                },
                {
                    "sent": "There's two holes here, and there's an infinite potential here.",
                    "label": 0
                },
                {
                    "sent": "So here all the this cost will be infinite, so this will put these past that will hit here will put him to zero.",
                    "label": 0
                },
                {
                    "sent": "Only the few lucky path that goes through that will actually do that.",
                    "label": 0
                },
                {
                    "sent": "So although this is an unbiased, good solid scheme to compute this optimal control, you can clearly see that it's very inefficient depending on where you are.",
                    "label": 0
                },
                {
                    "sent": "If you are in front of one of the holes, you may be lucky, but in general you may be unlucky.",
                    "label": 0
                },
                {
                    "sent": "And so here you see.",
                    "label": 0
                },
                {
                    "sent": "In green, the optimal cost to go calculated analytically for all positions, and the blue ones are the sample estimates, and you see that the sample estimates they get very bad if you.",
                    "label": 0
                },
                {
                    "sent": "So it's inefficient.",
                    "label": 0
                },
                {
                    "sent": "So the idea one can use is to use.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Important sampling to improve the sampling in the idea of important sampling is simply sad.",
                    "label": 0
                },
                {
                    "sent": "You sample from the wrong distribution and you're correct for it.",
                    "label": 0
                },
                {
                    "sent": "So in this way we have for instance, for the optimal cost to go, we have to sample.",
                    "label": 0
                },
                {
                    "sent": "We have to do this computation, but we can write it as cute rhyme price times Q / Q time, Q prime and so we get this expression.",
                    "label": 0
                },
                {
                    "sent": "So now we sample not interpretation is that we sample from this distribution and we discount the instead of only for this term we discount for this whole product in this way.",
                    "label": 0
                },
                {
                    "sent": "And so how do we accuse chooses Q prime so Q prime?",
                    "label": 0
                },
                {
                    "sent": "Maybe some stochastic process where we put in some probing control which is not zero in this case and which will steer is already towards the best places that we should go and then correct for that.",
                    "label": 0
                },
                {
                    "sent": "So if you do that for this example.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Where you hear the plot was 100,000 samples per per X.",
                    "label": 0
                },
                {
                    "sent": "Here I have only 100 samples per action.",
                    "label": 0
                },
                {
                    "sent": "You see that it's it goes.",
                    "label": 0
                },
                {
                    "sent": "It goes very well.",
                    "label": 0
                },
                {
                    "sent": "It's obvious that you can improve that this way.",
                    "label": 0
                },
                {
                    "sent": "Of course, you have to know how to choose these important directions, and this is.",
                    "label": 0
                },
                {
                    "sent": "This is something you can do maybe in iteratively you get first.",
                    "label": 0
                },
                {
                    "sent": "You do U zero and then with that you get an idea of where the good use are.",
                    "label": 0
                },
                {
                    "sent": "With that you use to improve your sampler and so in this way you can get.",
                    "label": 0
                },
                {
                    "sent": "A better result.",
                    "label": 0
                },
                {
                    "sent": "So we apply.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That to the idea of motor babbling.",
                    "label": 1
                },
                {
                    "sent": "So this is the idea that in biology, if you don't know how the problem of the brain is that the brain doesn't know how the limbs are, they only you know there's no, there's only some sensory input.",
                    "label": 0
                },
                {
                    "sent": "There's no hardwired plan of how to control, so the idea that the way infants seem to learn control is just to do random things and see what happens, and so you can also do this in this control setting where you say OK. Now, let's say I have this deterministic.",
                    "label": 1
                },
                {
                    "sent": "Plans and I'm now going to choose as controls.",
                    "label": 0
                },
                {
                    "sent": "I'm going to choose these these control.",
                    "label": 0
                },
                {
                    "sent": "I take noise where the size of the noise is some constant times inverse cost matrix that I have here and so this is originally a domestic control problem, but I make it a stochastic control problem by having this.",
                    "label": 0
                },
                {
                    "sent": "By having this exploration with noisy controls and so I have a plant, I have a state I can observe.",
                    "label": 0
                },
                {
                    "sent": "I can observe the new state, I can observe the controls, which is our noise, which I do myself, and then I can.",
                    "label": 0
                },
                {
                    "sent": "Then, because of the path integral formalism, it turns out that by just observing that you can compute because you get samples from this plant, you never need to know the plant itself.",
                    "label": 0
                },
                {
                    "sent": "You never need to know F&G and just from the samples itself you can compute the optimal control.",
                    "label": 0
                },
                {
                    "sent": "So this is a model free.",
                    "label": 0
                },
                {
                    "sent": "Way to do optimal control.",
                    "label": 0
                },
                {
                    "sent": "And so.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is.",
                    "label": 0
                },
                {
                    "sent": "Let me see.",
                    "label": 0
                },
                {
                    "sent": "Something.",
                    "label": 0
                },
                {
                    "sent": "This is some some little fucker.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Single is 2 degrees of Freedom 2 joint system that is doing is learning to control.",
                    "label": 0
                },
                {
                    "sent": "In in these iterations of where you use important sampling to improve the control over various trials, this is maybe 100 to trials, so this.",
                    "label": 0
                },
                {
                    "sent": "Is very simple and it's somehow also related to the ideas of of Teodoro.",
                    "label": 0
                },
                {
                    "sent": "What he implanted in his algorithms for robotics, and so this is something that is seems to work quite well.",
                    "label": 0
                },
                {
                    "sent": "And let me see where's my talk now.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "So I come now to the to the third.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Art.",
                    "label": 0
                },
                {
                    "sent": "That's the link between control theory and large deviations, and it goes back to an old paper of Schrodinger, which I thought I found very, very interesting, and it's about something called the Schrodinger Bridge for those.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I don't know it it is a generalization of the Brownian Bridge, so these so consider a system initial distribution S of X and we have a market dynamics which connects which gives the distribution over X at the time T2 as a function of state, given that it was at time T1 at another state for all times between A and T1 and T2.",
                    "label": 0
                },
                {
                    "sent": "NBA is here at the is there.",
                    "label": 0
                },
                {
                    "sent": "And we are given begin an end distributions PA of X&PB of Z.",
                    "label": 0
                },
                {
                    "sent": "So they live here and they live there.",
                    "label": 0
                },
                {
                    "sent": "And now we want to compute the marginal distribution for each intermediate time of the most likely trajectories from A to B for entering any intermediate time.",
                    "label": 1
                },
                {
                    "sent": "So this is the the vertical destroying the bridge.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's first consider the simpler case in the Brownian Bridge, then these these these PA&PB there Delta distributions just for centered on a on X&Z.",
                    "label": 0
                },
                {
                    "sent": "And of course the probability to be at state Y at an intermediate time T given that at time a I was a state X and at time BI was in state.",
                    "label": 1
                },
                {
                    "sent": "Z is just simply given by Bayes rule.",
                    "label": 0
                },
                {
                    "sent": "So this is this.",
                    "label": 0
                },
                {
                    "sent": "We have this dynamic so we have the forward numbers to go from Y to Z and we have the forward.",
                    "label": 0
                },
                {
                    "sent": "To go from X to Y, we multiply that and we normalize and the normalization.",
                    "label": 0
                },
                {
                    "sent": "What is normalization was just the integral overall Y of this product.",
                    "label": 0
                },
                {
                    "sent": "So that's the normalization constant over there.",
                    "label": 0
                },
                {
                    "sent": "And so now the question is, if X&Z are now from a distribution with these given marginals, then of course we get for the probability to observe Y at T given out these distributions.",
                    "label": 0
                },
                {
                    "sent": "Being the integral of all X&Z of this posterior that we had here multiplied by the P of X&Z and integrating over all XZ.",
                    "label": 0
                },
                {
                    "sent": "So this is then the solution.",
                    "label": 0
                },
                {
                    "sent": "But clearly there are many distributions that have these marginals, and so the question now becomes which distribution do we need to have the which?",
                    "label": 0
                },
                {
                    "sent": "Which one do we choose?",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "An insured.",
                    "label": 0
                },
                {
                    "sent": "In this paper he imagined clouds of particles and they have distribution Essex at the time A and then move according to the Markov process and we discretize the the initial state and the final state, and we denote by gamma.",
                    "label": 1
                },
                {
                    "sent": "KL is the number of particles that leave cell Delta XK and they arrive itself Delta ZL and so the probability of an individual particle trajectory is then.",
                    "label": 1
                },
                {
                    "sent": "Of K, which is the S of XK times QKL, which is the.",
                    "label": 0
                },
                {
                    "sent": "This distribution dial Delta X DD Z and so since that is the probability of an individual distribution, we get all these individual particles that just satisfy a multinomial distribution, where this is the base distribution based probability to the power.",
                    "label": 0
                },
                {
                    "sent": "The number of particles that are there normalized.",
                    "label": 0
                },
                {
                    "sent": "So this is a standard binomial distribution.",
                    "label": 0
                },
                {
                    "sent": "So if we now take the limit.",
                    "label": 0
                },
                {
                    "sent": "A van to Infinity, then an we define DKL as basically being this this sort of continuous limit of this gamma.",
                    "label": 0
                },
                {
                    "sent": "Then we find that this distribution of this multinomial becomes dominated by by this term, where N is the number of particles and the KL is the KL divergent's global divergent between P, which is this, say posterior over particles.",
                    "label": 0
                },
                {
                    "sent": "An S times Q which is the was the prior.",
                    "label": 0
                },
                {
                    "sent": "So we see here very naturally that the large deviation argument comes comes here.",
                    "label": 0
                },
                {
                    "sent": "And So what we need to do in a large particle limit is to minimize this KL to find the most likely solution and that will set us give us the solution for P. So the KL.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Almost we minimize subject to these constraints that they are at the boundaries.",
                    "label": 0
                },
                {
                    "sent": "To have these distributions and the solution can be found by LaGrange multipliers, you will find that P is proportional to two Q.",
                    "label": 0
                },
                {
                    "sent": "Damn times two or LaGrange functions and these LaGrange functions they they have to be be found somehow, but if we take this solution and we put it now in in here we have a solution for P we.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But in here we see that P is now proportional to this term, so that will drop out and so the product will now be a function of X * A function of Z.",
                    "label": 0
                },
                {
                    "sent": "If I see.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Received so here look.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So P is proportional to this Q and so and the rest is X function to X * Y.",
                    "label": 0
                },
                {
                    "sent": "So in other words, if you take the integral over Q / P divided by sorry.",
                    "label": 0
                },
                {
                    "sent": "And it is a bit fast.",
                    "label": 0
                },
                {
                    "sent": "If we put disease.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Equation in here is dividing by Q and we multiply by P which is proportional to cues that that term drops out and the remaining terms are a function of Z * A function of X.",
                    "label": 0
                },
                {
                    "sent": "So we can do this integral separates into integrals.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The result is that the optimal solution of the density at an intermediate time, given these initial density and a final density, is a product of two functions where one is moving forward in time, which is his initial conditions at at initial time and then moving with the density forward and the other one has initial conditions at final time moving backward in time, and so we have here again a mixed boundary value condition.",
                    "label": 0
                },
                {
                    "sent": "System where these two functions now have to be satisfied to be solved such that their product at initial time is this marginal density and their product at the end time is that marginal density, yeah?",
                    "label": 0
                },
                {
                    "sent": "Use the optimal density optimal most sense optimal in the sense of this KL minimization.",
                    "label": 0
                },
                {
                    "sent": "Essentially brings back the exponential form.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Assumption.",
                    "label": 0
                },
                {
                    "sent": "So the way it is optimal in the following way.",
                    "label": 0
                },
                {
                    "sent": "So if you give the initial distribution and you give the market dynamics, the final distribution is given right?",
                    "label": 0
                },
                {
                    "sent": "So now you ask yourself, OK, I give the initial distribution.",
                    "label": 0
                },
                {
                    "sent": "I give the dynamics, but I also give two other distributions, IPA and a PB, and I want to know how to sort of squeeze the system most likely into that.",
                    "label": 0
                },
                {
                    "sent": "And then you get a large deviation argument and there is one solution that dominates that and that's.",
                    "label": 0
                },
                {
                    "sent": "The one that minimizes this scale.",
                    "label": 0
                },
                {
                    "sent": "And in that sense, it's optimal.",
                    "label": 0
                },
                {
                    "sent": "It's the most likely.",
                    "label": 0
                },
                {
                    "sent": "So so that the only the only thing in the larger yeah.",
                    "label": 0
                },
                {
                    "sent": "In case of course, that would be Gaussian.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "In this case, we will be asking yes.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The story is that the salute.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Ocean is a product of 2.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Functions and those who are in are familiar with inference in time series model.",
                    "label": 0
                },
                {
                    "sent": "They know of course is.",
                    "label": 0
                },
                {
                    "sent": "You have a common filter where you have forward path messages and backward messages and any any posterior distribution is a product of the forward message in the backward message, like here and so it is if you want to compute the distribution of the immediate time, you have some something moving forward, something moving backwards, you multiply it and that is your solution.",
                    "label": 0
                },
                {
                    "sent": "Incidentally, the interest of certain ranges was that he was very much intrigued.",
                    "label": 0
                },
                {
                    "sent": "By identifying these two with Siam Sidebar being and so you get, the density is the product of the of the wavefunction, and so he thought this was the reason why Schrodinger equation.",
                    "label": 0
                },
                {
                    "sent": "His is a quantity is a wave function.",
                    "label": 0
                },
                {
                    "sent": "That is it.",
                    "label": 0
                },
                {
                    "sent": "This could be an explanation for why probability is the square of the wavefunction that was his argument, but he didn't really pursue it.",
                    "label": 0
                },
                {
                    "sent": "Further, as far as I know.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's that.",
                    "label": 0
                },
                {
                    "sent": "So once we have that, we can take this descaled.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Our version is more seriously and say OK, let's define control problems with this KL divergent.",
                    "label": 0
                },
                {
                    "sent": "So let's say that we have a state space and we have we define something.",
                    "label": 1
                },
                {
                    "sent": "The uncontrolled dynamics is given some Q trajectory's over overtime.",
                    "label": 0
                },
                {
                    "sent": "Maybe first order Markov process and we have some costs and are the probability is to find a posterior distribution P that minimizes akl in the sense that so that we want a distribution that is somehow close to the.",
                    "label": 1
                },
                {
                    "sent": "Uncontrolled dynamics that we have here, but at the same time we want to minimize an expected cost term.",
                    "label": 0
                },
                {
                    "sent": "And if you if you minimize this, this equation is of course you can do it quite easily.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Because this is just, you know, if you minimize it stands right that you the optimal solution of this minimization problem.",
                    "label": 0
                },
                {
                    "sent": "You can write it in close form, P is proportional to Q * E to the into the R and normalized, and if you put that solution, if you put it back into here and look at the optimal cost, then you get ultimate costs minus the log of Z and so in other words we have here that day Z is the side that we had before, which is this, which is this this?",
                    "label": 0
                },
                {
                    "sent": "We got from this final cuts formula where we have an integral over trajectories.",
                    "label": 1
                },
                {
                    "sent": "Dizzy is nothing else than the normalizer of this distribution is a distribution of trajectory.",
                    "label": 1
                },
                {
                    "sent": "So we get a normalizer which is a sum over distributed over trajectories of the uncontrolled dynamics waited by the path costs and the optimal cost to go is the log partition sum.",
                    "label": 0
                },
                {
                    "sent": "And here we have the prior distribution and the posterior distribution, so we're getting one slide back.",
                    "label": 0
                },
                {
                    "sent": "But we already knew before.",
                    "label": 0
                },
                {
                    "sent": "And we can we can do the control.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Population now as an inference computation, which is say OK, we have a time here and we just have to do backwards message passing.",
                    "label": 0
                },
                {
                    "sent": "So if we want to compute, for instance, the optimal control where to move from state X0 to X1, we have this whole distribution of trajectories we have to marginalized out state X2, T, do that some and you can push this some through the time series and basically collect these in terms where you get sort of recurrent message passing equations that do the sum 1 by 1.",
                    "label": 0
                },
                {
                    "sent": "Until you are at a time XX, one and these are these recurrent equations.",
                    "label": 0
                },
                {
                    "sent": "They're basically these backward message passing, so the whole control computation becomes an inference,",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Jason so this is the overall picture, so if you have normally a dynamics and you set up your Bellman equation through dynamic programming arguments, and then maybe do some approximation to get to some optimal control in this picture, we look at the restricted class of control problems and we have a date for this class.",
                    "label": 0
                },
                {
                    "sent": "We can do the solution we have in closed form, but of course it's intractable and we can use approximate inference to then do the computation.",
                    "label": 0
                },
                {
                    "sent": "Officient and so OK.",
                    "label": 0
                },
                {
                    "sent": "So what is that?",
                    "label": 0
                },
                {
                    "sent": "So how does that relate to the previous story?",
                    "label": 0
                },
                {
                    "sent": "If we now set the.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Dynamics is just being over small time intervals as being just a Gaussian with this nonlinear drift term in it, and we have the control dynamics as being adding this this control term.",
                    "label": 0
                },
                {
                    "sent": "If we now look at the KL term for this, this cost for this term, we will find that if you put it in that this will automatically reduce to this term that we had before where we have explicitly now the relation between this R and this new minus one.",
                    "label": 0
                },
                {
                    "sent": "So it is an incense is an explanation why this funny relation between R and new must hold because it is related to this class of of KL divergent problems.",
                    "label": 0
                },
                {
                    "sent": "More general than the government.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It is, yeah, so you can do through all the models also.",
                    "label": 0
                },
                {
                    "sent": "So, um.",
                    "label": 0
                },
                {
                    "sent": "Just a few remarks on this on this system, so we have studied.",
                    "label": 0
                },
                {
                    "sent": "For instance, the the average cost case of this of this problem.",
                    "label": 0
                },
                {
                    "sent": "So in the limit the time goes to Infinity.",
                    "label": 0
                },
                {
                    "sent": "These these message passage equation.",
                    "label": 0
                },
                {
                    "sent": "They become time independent and basically you get an eigenvalue equation where beta is a vector with indexed by the states of the system and H is a matrix which consists of the uncontrolled dynamics.",
                    "label": 0
                },
                {
                    "sent": "Multiply it on the right with the exponentiated costs and so we have to find.",
                    "label": 0
                },
                {
                    "sent": "You can show that the optimal control is given by the parameter benyus eigen pair of this of this system, basically the largest Eigen eigen value, the optimal cost average cost is becomes the log of the largest eigenvalue which gives the minimal cost and the cost to go is the log of the eigen eigenvector and the optimal Markov process is given by the uncontrolled Markov process.",
                    "label": 1
                },
                {
                    "sent": "Times the cost times the ratio of these of these components in the in the eigenvector, and so this is something that you can then compute by using linear algebra.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "One more thing, so another funny thing is that in the case that the uncontrolled dynamics satisfy detailed balance, which means that detailed balance means that.",
                    "label": 1
                },
                {
                    "sent": "QY given X times QX is QX given y * Q Y, so these dynamics this these two terms are given, but detailed balance means that there exists such a Q which which satisfies this which is not true for all dynamical systems.",
                    "label": 0
                },
                {
                    "sent": "But if it satisfies and it's called detailed balance if such a Q exist then one can show that the control system also satisfies detailed balance.",
                    "label": 0
                },
                {
                    "sent": "And the relation is that the optimal stationary distribution over the over the controlled a system is the stationary distribution of the uncontrolled system multiplied by this first eigenvalue squared.",
                    "label": 0
                },
                {
                    "sent": "So there's this funny square coming back again in the probability.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So he is here example.",
                    "label": 0
                },
                {
                    "sent": "I let me not go over this.",
                    "label": 0
                },
                {
                    "sent": "So we have done a.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So one of the things is that we have looked at stochastic implementation of this of this rule.",
                    "label": 0
                },
                {
                    "sent": "So for systems where which are small, you can just compute such a program vainius eigenvector by by just by the power method.",
                    "label": 0
                },
                {
                    "sent": "You just take an arbitrary vector and you multiply.",
                    "label": 0
                },
                {
                    "sent": "You get the extreme eigenvalue and eigenvector.",
                    "label": 0
                },
                {
                    "sent": "How this algorithm describes how you can do that in a stochastic way without ever having to store the whole vector.",
                    "label": 0
                },
                {
                    "sent": "So for state spaces, which are very large where you cannot store the whole vector, we can use this uncontrolled dynamics to basically sample do a sampling procedure, and under some conditions we can prove that is this converges to that system that.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Solution.",
                    "label": 0
                },
                {
                    "sent": "Easy example for a small maze.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry for the graphics, they are something went wrong.",
                    "label": 0
                },
                {
                    "sent": "This is this is a maze with with the goal here and you start anywhere and here you see the solution for the optimal cost to go, which is nicely gradient and here you see the behavior of the algorithm.",
                    "label": 0
                },
                {
                    "sent": "He uses the eigenvalue going to one which is a scaled version.",
                    "label": 0
                },
                {
                    "sent": "In this case is by construction has to go to one and you see convergence of the algorithm.",
                    "label": 0
                },
                {
                    "sent": "The stochastic method.",
                    "label": 0
                },
                {
                    "sent": "So I've come to the end of my talk.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I've I think I've touched on many things and only lightly, but that was the idea.",
                    "label": 0
                },
                {
                    "sent": "As far as I understand, quantum mechanics does not seem to correspond to a useful class of control poles, but this is for me.",
                    "label": 1
                },
                {
                    "sent": "It's part of the this week's discussion.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I have looked at another class of control problems that links inference to statistical physics and to the machine learning methodology.",
                    "label": 1
                },
                {
                    "sent": "I've already told you much about that.",
                    "label": 0
                },
                {
                    "sent": "We have done several studies here.",
                    "label": 0
                },
                {
                    "sent": "You see, for instance multi agent systems that is being controlled and if you increase the number of agents.",
                    "label": 0
                },
                {
                    "sent": "Of course the exact computation of the control scales exponentially with the system size we have used here, belief propagation and mean field methods to get to get polynomial time behavior.",
                    "label": 0
                },
                {
                    "sent": "I've shown that battery.",
                    "label": 0
                },
                {
                    "sent": "That's it for.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Stochastic control problems that there is for this class of problems.",
                    "label": 0
                },
                {
                    "sent": "We have got some insight in the role of noise and particularly this kind of phase transitions that occur for particular noise levels in the problem.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I.",
                    "label": 0
                },
                {
                    "sent": "There has been a lot of work on comparison with state of the art reinforcement learning methods compared this these possible methods, but definitely my group of Steven Sjolund.",
                    "label": 0
                },
                {
                    "sent": "Pedal steel door was here.",
                    "label": 0
                },
                {
                    "sent": "We'll talk about that and also more recently in the Group of Young Boy Moto who's also here will also be talking about some of that work.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So then there's and I've tried to point out the link between large deviations and KO control theory and that will is also leads to possible generalization by considering other distributions as you as you pointed out.",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I've some papers on the website.",
                    "label": 0
                },
                {
                    "sent": "If you want to read more on that.",
                    "label": 0
                },
                {
                    "sent": "And I have some questions for this for this for this conference, but one is this quantum mechanical question, which is basically the.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Following so.",
                    "label": 0
                },
                {
                    "sent": "So this control that I've considered is all fully observable if you talk about partial observable problems, you're not.",
                    "label": 0
                },
                {
                    "sent": "You have to deal with uncertainty over these unobserved things, so these uncertainties captured in terms of distributions and these distributions were now being controlled by your actions.",
                    "label": 0
                },
                {
                    "sent": "So you get you get nonlinear control diffusion.",
                    "label": 0
                },
                {
                    "sent": "So my question is, does there exist a class of partial observed control problems that can be linearized in the sense that that I was looking for in the quantum mechanical case, but that I've failed to find and this is something that is still very much on?",
                    "label": 1
                },
                {
                    "sent": "On my mind.",
                    "label": 0
                },
                {
                    "sent": "There's another open question a little bit more practical.",
                    "label": 0
                },
                {
                    "sent": "In a possible control theory, the optimal cost to go is a free energy.",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As I explained this way, it's an integral of a path.",
                    "label": 0
                },
                {
                    "sent": "There's another body of work which is related to the Jasinski equation, and it relates to free energy difference of two states to the path and roll over the work.",
                    "label": 1
                },
                {
                    "sent": "It's some expression of this.",
                    "label": 1
                },
                {
                    "sent": "Now these expressions they look very similar because if you interpret the free energy as the free energy difference is the cost to go, you get basically also integral over path.",
                    "label": 1
                },
                {
                    "sent": "So are these two statements related?",
                    "label": 0
                },
                {
                    "sent": "I don't know.",
                    "label": 0
                },
                {
                    "sent": "I've been trying to work it out, but I have no answers.",
                    "label": 0
                },
                {
                    "sent": "Maybe some of you know that.",
                    "label": 0
                }
            ]
        },
        "clip_80": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is the initial science, like I started with an here I have put some of the names of the people that contribute to the different parts of far as I understand it, so at least there's some work on statistical physics relating to inference and algorithms, and that is work that will be presented by Mark, Massabesic, INA and these people here with following.",
                    "label": 0
                },
                {
                    "sent": "Basically this this kind of line here.",
                    "label": 0
                }
            ]
        },
        "clip_81": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Dender is some people talking about quantum mechanics and control.",
                    "label": 1
                },
                {
                    "sent": "I'm not sure where to grab, will talk about quantum mechanics, but so that's so that's that link there.",
                    "label": 0
                },
                {
                    "sent": "Then the.",
                    "label": 0
                }
            ]
        },
        "clip_82": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Will be quite a few people talk about control, statistical physics and large deviations, so that's going in this direction.",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 0
                }
            ]
        },
        "clip_83": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There will be some people looking at the relation between control and inference.",
                    "label": 1
                },
                {
                    "sent": "This link here.",
                    "label": 0
                },
                {
                    "sent": "And then there will be.",
                    "label": 0
                }
            ]
        },
        "clip_84": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some people looking at the relation to the brain to biology.",
                    "label": 0
                },
                {
                    "sent": "And there will be some people looking at the.",
                    "label": 0
                }
            ]
        },
        "clip_85": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Relation to control.",
                    "label": 0
                },
                {
                    "sent": "And that's the end of my talk.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                },
                {
                    "sent": "So since that day finally.",
                    "label": 0
                },
                {
                    "sent": "It's very important to know what.",
                    "label": 0
                },
                {
                    "sent": "To make connections from PBS to specifications.",
                    "label": 0
                },
                {
                    "sent": "And so far all these frameworks.",
                    "label": 0
                },
                {
                    "sent": "Here's one with continuous state continuous time problems.",
                    "label": 0
                },
                {
                    "sent": "Deal with the email Gmail deletes, so there is a real version of the final cut you Mother.",
                    "label": 0
                },
                {
                    "sent": "You can find actually the equivalent to financial equation, an expectation that if you have something forward in time, we can actually approach my English Wikipedia, but in fact it is the normal the normal version of this, so difficult.",
                    "label": 0
                },
                {
                    "sent": "Problems you can actually live account.",
                    "label": 0
                },
                {
                    "sent": "There's a problem and equation.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "But so how would it work?",
                    "label": 0
                },
                {
                    "sent": "Because the assault of Feynman cuts lemma is is intimately related to the linearity that you have a.",
                    "label": 0
                },
                {
                    "sent": "You have a sort of a Green's function, and you use a solution as a linear superposition.",
                    "label": 0
                },
                {
                    "sent": "How about this?",
                    "label": 0
                },
                {
                    "sent": "No, no, no.",
                    "label": 0
                },
                {
                    "sent": "I don't know about it now.",
                    "label": 0
                },
                {
                    "sent": "Well, I would like to learn about it.",
                    "label": 0
                },
                {
                    "sent": "Two soundlink with forward and backward stochastic differential equation.",
                    "label": 0
                },
                {
                    "sent": "So something is not going forward.",
                    "label": 0
                },
                {
                    "sent": "You have to back or stochastic presentation and now you have to ask how I'm going to medically indicated this problem so I don't know if that is medically physically like.",
                    "label": 0
                },
                {
                    "sent": "I'm aware there's a book by Baiza and Lean, and now we don't.",
                    "label": 0
                },
                {
                    "sent": "Stochastic difference.",
                    "label": 0
                },
                {
                    "sent": "Yeah, and they have also these backwards equations and stochastic equations.",
                    "label": 0
                },
                {
                    "sent": "But the link that they are making there is more.",
                    "label": 0
                },
                {
                    "sent": "In order to find a stochastic custom variation of the yeah, yes, exactly exactly.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "So weird.",
                    "label": 0
                },
                {
                    "sent": "No, I don't know.",
                    "label": 0
                },
                {
                    "sent": "I should talk about it in here.",
                    "label": 0
                },
                {
                    "sent": "So why is the standard to Goshen observation, Gaussian noise and linear dynamics?",
                    "label": 0
                },
                {
                    "sent": "With simple example, you're partially observed.",
                    "label": 0
                },
                {
                    "sent": "Linearizations for instance, if you have, if you have if you have something like DX is Alpha U DT plus noise something like this and if you don't observe Alpha.",
                    "label": 0
                },
                {
                    "sent": "You get distribution of Alpha and is this if you know Alpha this is linear predictor control problem.",
                    "label": 0
                },
                {
                    "sent": "If you don't observe, our file becomes a nonlinear problem problem.",
                    "label": 0
                },
                {
                    "sent": "Because you have to parameterise the uncertainty in Alpha in a distribution with certain parameters and these parameters will also evolve overtime, so they are coupled with these dynamics in the control computation.",
                    "label": 0
                },
                {
                    "sent": "But there is 1 case of course, which is his point and and leaves with partial observer comes from additive Gaussian noise.",
                    "label": 0
                },
                {
                    "sent": "Yeah, which is OK, OK?",
                    "label": 0
                },
                {
                    "sent": "So there is an example to question may be trivial, but yeah, so that's sort of the equivalent case in which the optimal control does not depend on the noise.",
                    "label": 0
                },
                {
                    "sent": "Yeah yeah.",
                    "label": 0
                },
                {
                    "sent": "Is actually formulated as a.",
                    "label": 0
                },
                {
                    "sent": "Send please system identification and yes, state identification problem.",
                    "label": 0
                },
                {
                    "sent": "There's effective discretion caitians of that.",
                    "label": 0
                },
                {
                    "sent": "Yeah, we do run a battery of common filters and then you compute conditional density in both the signal space and the model space.",
                    "label": 0
                },
                {
                    "sent": "Can be done tomorrow.",
                    "label": 0
                },
                {
                    "sent": "But these common filters are the nonlinear no.",
                    "label": 0
                },
                {
                    "sent": "The beauty of, well, if you assume that your model is linear but you don't know what it is, yeah, so you postulate a grid of models, then you run the common set while you run the common folder.",
                    "label": 0
                },
                {
                    "sent": "Assuming each of those models in known is known battery I see.",
                    "label": 0
                },
                {
                    "sent": "And if you run them as solutions of the conditional density equation and you also at the same time get the conditional density joint conditional density for Alpha and this state, yeah.",
                    "label": 0
                },
                {
                    "sent": "Maximum is a good idea I guess, but I guess you have to sort of the discretization of your Alpha.",
                    "label": 0
                },
                {
                    "sent": "A very difficult limit.",
                    "label": 0
                },
                {
                    "sent": "Yeah, Alpha, go to Infinity.",
                    "label": 0
                },
                {
                    "sent": "Computational effectiveness yeah OK?",
                    "label": 0
                },
                {
                    "sent": "So no free lunch.",
                    "label": 0
                },
                {
                    "sent": "So far maybe here maybe here OK?",
                    "label": 0
                },
                {
                    "sent": "Any other questions?",
                    "label": 0
                },
                {
                    "sent": "If not, Oh yeah.",
                    "label": 0
                },
                {
                    "sent": "And maybe that relates to longer between controller installation and maybe we're going to see that.",
                    "label": 0
                },
                {
                    "sent": "But since we have people from information sharing, typically 11 takes classes in state, destination and detection theory.",
                    "label": 0
                },
                {
                    "sent": "If you are told about the camera roll bound, and we know that for the general case when you have a comma, prepare for linear case active noise that the computer is actually very optimal estimator.",
                    "label": 0
                },
                {
                    "sent": "Because he treated the camera logo, so I was wondering what is really the equivalent of this.",
                    "label": 0
                },
                {
                    "sent": "Principle to control because if I mean there is value, at least for the guitar cases when we have only added noise and Gaussian noise, and So what is really they do a concept of grammar out lower bound?",
                    "label": 0
                },
                {
                    "sent": "But the come over this is also about I thought about sampling, right?",
                    "label": 0
                },
                {
                    "sent": "I mean how much how many samples you have.",
                    "label": 0
                },
                {
                    "sent": "It bonds their variance.",
                    "label": 0
                },
                {
                    "sent": "Basically yeah, but it's a statement in how much samples.",
                    "label": 0
                },
                {
                    "sent": "Estimate.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so it will be.",
                    "label": 0
                },
                {
                    "sent": "It will come in probably if you do.",
                    "label": 0
                },
                {
                    "sent": "If your estimate to pass through with the final number of samples somehow.",
                    "label": 0
                },
                {
                    "sent": "Oh no, you know what you?",
                    "label": 0
                },
                {
                    "sent": "OK, so I'm right now I'm sure I'm just guessing.",
                    "label": 0
                },
                {
                    "sent": "When we come around, robots take says that if you have enough samples, the violence at some point, if any, is the number of samples.",
                    "label": 0
                },
                {
                    "sent": "Yeah yeah.",
                    "label": 0
                },
                {
                    "sent": "Or if you set up from the information.",
                    "label": 0
                },
                {
                    "sent": "Patient is going to have basically been maximized.",
                    "label": 0
                },
                {
                    "sent": "Hey Bob.",
                    "label": 0
                },
                {
                    "sent": "So we speak about violence here, right here is the nation.",
                    "label": 0
                },
                {
                    "sent": "What's wrong with connection to form?",
                    "label": 0
                },
                {
                    "sent": "The only connection I see is, you know, if you have a sample estimate of this bathroom rule.",
                    "label": 0
                },
                {
                    "sent": "With the number of samples you get an estimate with which has a variance.",
                    "label": 0
                },
                {
                    "sent": "Isn't that the connection?",
                    "label": 0
                },
                {
                    "sent": "I was thinking that the the the draw concept will be required functions.",
                    "label": 0
                },
                {
                    "sent": "I don't know.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry I don't know.",
                    "label": 0
                },
                {
                    "sent": "Any other questions before?",
                    "label": 0
                },
                {
                    "sent": "OK, thank you very much.",
                    "label": 0
                }
            ]
        }
    }
}