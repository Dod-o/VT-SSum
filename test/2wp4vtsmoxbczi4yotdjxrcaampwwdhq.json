{
    "id": "2wp4vtsmoxbczi4yotdjxrcaampwwdhq",
    "title": "Rich Probabilistic Models for Holistic Scene Understanding",
    "info": {
        "author": [
            "Daphne Koller, Stanford University"
        ],
        "published": "Aug. 23, 2011",
        "recorded": "July 2011",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/ijcai2011_koller_scene/",
    "segmentation": [
        [
            "Thank you to the organizers, organizers for inviting me to be here 10 years almost to the day from the time that I gave my computers and thought award talk, and in fact, the."
        ],
        [
            "Our slide that I'm going to present.",
            "Is.",
            "Actually, the last slide that I used in my computers in thought talk 10 years ago, which was a slide where I talked about the importance of bridging different things, bridging logic and probability.",
            "Using that as the basis for bridging between reasoning and learning, and ultimately using that.",
            "Looking forward as bridging between low level perception and high level understanding, and much of the work that I've done since that talk in the last decade has focused.",
            "Certainly the computer vision part has focused on trying to bridge this gap between perception and understanding."
        ],
        [
            "That's what I hope to tell you about today, so let's talk about what it means to go from perception to understand that if this is an image that we hope to, we hope to interpret what we would like to do is we would like to move beyond just labeling pieces of the image in isolation, but rather to come up with a holistic interpretation in the same way that a person might use so to come up with an interpretation that says a man wearing a backpack smoking a cigarette, walking a dog.",
            "Now, for those of you who haven't done computer vision, this might seem fairly trivial.",
            "I mean, it's obvious that that's what's going on here.",
            "But if you actually start thinking about what computer vision does and how it might be applied to this image, you realize that the cigarette is about 3 pixels wide and 10 pixels long.",
            "Is a white stick, and the only way to possibly infer that it's a cigarette is by realizing that it's part of a man's mouth that is at the man's mouth, and that means it could either be a cigarette or lollipop, and given that it's a grown up, it's probably a cigarette, and that's not the kind of reasoning that a computer naturally doesn't.",
            "Certainly, computer vision algorithms today are not capable of doing that kind of influence in general.",
            "The same issues come up with the backpack, which is an undifferentiated black blob, and backpacks come in many shapes and many colors.",
            "The leash is almost invisible, so how could you possibly infer that the man is walking the dog if you weren't using context?",
            "So what I'd like to tell you about today is some of the work that we've done to take a few steps.",
            "Certainly not the."
        ],
        [
            "Away in this direction.",
            "Again, clarify the difficulty of the problem.",
            "Let me talk about how object detection is done today.",
            "This is a caricature, but it's not that far off from the truth, so we want to detect cars in an image.",
            "So we give the algorithm A.",
            "We give a machine learning algorithm.",
            "This is better.",
            "OK, sorry, so we give a machine learning algorithm.",
            "A bunch of examples of bounding boxes that contain cars and a bunch of examples of bounding boxes that don't contain cards and it learns to distinguish cars from non car bounding boxes and then given the new image like this we take each bounding box and we place it on the image and we ask is this a car yes or no?",
            "Does it pass our threshold?",
            "Well, what about this one and this one and this one and this one and that one and not look now one?",
            "Now the problem of course is that we don't know the scale of the car because it's a 2 dimensional projection of a 3D World.",
            "So we.",
            "To run this at different scales as well, and so if you do that with the best sophisticated machine learning algorithms and run this on this image, trying to detect three object classes, a car, a Moat."
        ],
        [
            "Cycle and a person.",
            "This is what you get so.",
            "There's a person right there.",
            "That's a motorcycle.",
            "It did detect this car.",
            "Correct weakness these other two, but on the other hand found one there and one there.",
            "This is fairly typical of computer vision algorithms, and it's not because there stupid.",
            "The people who build these machine learning up based algorithms for computer vision are very smart and they put a lot of thought into constructing the best learning algorithms that they can.",
            "It's because they don't see the whole."
        ],
        [
            "Picture.",
            "And So what I'd like to tell you about is 2 things.",
            "The first is the work that we've done in holistic scene models, and that's going to have two parts.",
            "And then the second half is going to be focused primarily on machine learning and develop some new machine learning techniques that we've developed that are instrumental in trying to do better understanding of semantically complicated objects, and I hope that the second part of the talk will be of relevance even to those of you who don't specifically care bout compute."
        ],
        [
            "Vision, so the first part of the talk is work primarily by my student YN Lang.",
            "Together with Stephen Gould and that's it."
        ],
        [
            "Understanding of indoor scenes.",
            "So here are the goals that they can.",
            "Image of the scenes such as this and indoor image and to recover what the global scene geometry which gives us a notion of scale and where the floor and walls are so that we can better detect and identify objects as well as what are the furnitures that the Occupy the seats are.",
            "Target output is a box that identifies the boundaries between the major faces and the furniture layout.",
            "The problem is this is not an easy problem because these clutters these furnitures.",
            "Occlude boundaries and obscure the appearance of major faces and so it's very hard for computer vision style algorithm to know that behind this bed and this cabinet there's actually a wall, and that this is where the wall is, so this is not."
        ],
        [
            "Trivial problem, so we were not the first identify this problem year before we wrote our paper.",
            "A very nice paper by head out all came out and they said well since these two problems are difficult and interrelated, we're going to basically try and train algorithm to solve each of them.",
            "So we're going to train an algorithm that labels the box.",
            "We're also going to try and label an algorithm that identifies the clutter, the furniture, and then we're going to iterate by long over these two different stages, estimating the box and labeling.",
            "The the the the labels of the of the pixels in the image as to whether they are cut or not.",
            "Now this is the paper that we started out from.",
            "Only decided to take a different approach which as you'll see is a running theme throughout this talk which is to try and let the algorithm figure things out for itself.",
            "So rather than labeling the rather than giving it a training set with labeled clutter, we're going to only label the boxes and we're going to let the algorithm figure out for itself what.",
            "What is the clutter now that has?",
            "The obvious advantage of requiring a lot less labeling effort, but as you see it also has other advantages that I'll get to that I'll get to at the end of this segment.",
            "So here we're going to model the clutter layout as latent variables.",
            "Latent means that they run observed at training time, not just the test time.",
            "So the algorithm has to train inferring what the where the clutter is, and then we're going to employ Max margin learning for joint model of the clutter and the box, and I'll talk about Mega Max margin learning in the second half."
        ],
        [
            "So what is So what is the overall formulation of the model that we used here and that we're going to use elsewhere in the talk is is what's called an energy function, or also known as a log probability.",
            "So this, so this is what it would look like, and so here X is the input.",
            "In this case it's the image.",
            "Why is the target output, which is the observed output?",
            "Is the box parameters, age is the set of latent variables, which in our case is a binary mask for each pixel, or each super pixel in the image.",
            "Specifying whether it's clutter or part of the box, this is a large feature vector that basically says forgiven configuration of imagebox parameters and latent variables.",
            "Does this make what are some features of that configuration jointly?",
            "So, for example, how uniform are the walls?",
            "Or how even is the box and things like that?",
            "So these are this is a large feature vector from which we hope to use to identify how good different configurations are, and this is the learned weights that we're going to have our model learn.",
            "And then given this energy function which which we learned, we're going to label the overall scene by finding the optimal the highest scoring configuration of both the box emulator very."
        ],
        [
            "OK, so this is great and we did maximum large margin learning using state of the art method that I'll talk about later.",
            "And this is the output that we got.",
            "This is the inferred box.",
            "In some of those scenes you can see that it's not that great.",
            "And what's more important, this is the inferred clutter, and you'll notice that in all of these images, half the room is labeled as clutter.",
            "Basically, in some images, everything but the clutter is labeled as clutter.",
            "Which basically gives the come brings us to the conclusion that latent variables, although very powerful modeling tool or actually a tricky thing to work with, because often they end up taking in directions that you don't want to and will come back to that."
        ],
        [
            "Um?",
            "So how do you ground the latent variables?",
            "So here we chose this approach that basically introduces an informed prior about what latent variables with the latent variables ought to look like.",
            "So in particular, we added another term to the energy function, and we said for this energy there's these two terms.",
            "First part is that major faces, like the walls or the floor should have pretty much consistent appearance.",
            "If you take out the clutter.",
            "So everything but the clutter should be pretty uniform.",
            "Now that by itself is not enough, because one way to achieve uniformity of the faces is to have just a single pixel in each.",
            "It's not going to be really uniform, so you don't want that.",
            "So the other thing is the penalty on the total amount of clutter, so you don't want to get to a degenerate solution where everything is cluttered.",
            "Everything is labeled with butter, so it turns out that if you add this very small amount of prior knowledge, each of these is a very simple term.",
            "You end up with an informed fire about latent variables that guides the process towards a non degenerate."
        ],
        [
            "Solution.",
            "And so going back to this example here we have the learning without prior terms which we saw in the previous slide.",
            "And here we have learning with prior terms and you can see that was identified as clutter.",
            "Now is effectively only the clutter, and so this drove the latent variables towards a much more reasonable solution in this space."
        ],
        [
            "So does that help?",
            "Let's look at some quantitative results.",
            "So this is the pixelwise classification error in terms of the major faces.",
            "And this is the paper by hydel at all, and they achieved a 3026% misclassification rate using their previous unsupervised scheme, where they didn't label the clutter.",
            "And then they managed to bring it down to about 20 with labeled quarter we got.",
            "A very significant reduction in the error.",
            "Even though we had unsupervised clutter, that is the comparison point for this is the first bar, not the second bar, because this used the same amount of annotation as this.",
            "Without the prior, as you saw, as you would expect, the results are not quite as good, but here is the most interesting bar in this whole chart.",
            "If you give the algorithm the ground truth clutter at Test time, and the training time, it performs considerably worse.",
            "Huawei."
        ],
        [
            "Look at that.",
            "So here is the hand labeled clutter by human experts who labeled the clutter, and you can see that lots of things is that our algorithm chose to label is clutter.",
            "The human didn't choose to label as clutter the entire cabinet.",
            "Everything that's on the walls."
        ],
        [
            "And in some examples, including this one, nothing was labeled as clutter, even though there's two or three distinct pieces of furniture in the room.",
            "Which basically indicates the human labeling for these latent variables aren't necessarily the thing that the algorithm performs best with, and that's something that will come back to.",
            "It's a running theme of this."
        ],
        [
            "OK, so that was the first thing yet.",
            "Moving to the second vignette, let's talk about outdoor scenes and this is work by primarily by my PhD student Steven Golden.",
            "Like postpone Kumar together with."
        ],
        [
            "And she go.",
            "So here are goals that they can outdoor scene like this and basically to construct again a pixelized scene segmentation that identify specific objects as well as the classes to which they belong.",
            "But at the level not have bounding boxes with absolute pixel by pixel, assign each pixel to a particular object and object class.",
            "So here we're going to use the same idea.",
            "We're going to define this energy function and notice at the moment there are."
        ],
        [
            "Latent variables will."
        ],
        [
            "After that, and so we're going to define this energy function with."
        ],
        [
            "So on the next slide and what this energy function does is it introduces these variables that assign each pixel to a region, so we're region is something that is semantically and geometrically coherent, and so variables that we have in the model are the pixel to region assignments as well as various characteristics of the different regions, like their semantic label with, whether it's a car ground or or water, whatever the geometry, whether it's vertical, horizontal or Sky.",
            "And then various other things, including the location of the horizon, which is also inferred in the image.",
            "So this is the model and basically models.",
            "Try the model tries to assign each pixel to a region while respecting the global coherence of the scene.",
            "And I'll show that in."
        ],
        [
            "The structure of the energy function in the next slide.",
            "So this is my energy function.",
            "Initially the basic model just had these three terms.",
            "First tried to use image features to identify the location of the horizon.",
            "Things like vanishing points.",
            "It also had a bunch of terms that related each region between the semantic label, the geometry in the horizon.",
            "So for example, it says first of all that if you're labeling this region as a tree then it should be kind of.",
            "Green and free.",
            "It should be vertical and most likely it's going to be above the horizon.",
            "Now know that none of these were imposed on the on the energy function.",
            "This was all learned from data, so this was just we incorporated the term into the energy function that allowed the model to learn this characteristic of natural scenes.",
            "And then finally we had a contrast term that tried to encourage the model not to fragment the scene into tiny little pieces, but rather to merge together adjacent regions that had similar color and texture, and so that gave rise to these large coherent regions that provided a much more robust model.",
            "So this."
        ],
        [
            "The region they small let me show you some results, so this is what you see here.",
            "Or is the class labels what you see here is the geometry including the inferred horizon and you can see that by and large it actually gets pretty good segmentation, so not perfect.",
            "Oranges is foreground object, blue is water Gray Sky and by and large you see purple is Rd.",
            "You can see that it works pretty well.",
            "Green is grass and so on, so it actually it actually works pretty well in segmenting out even fairly fine boundaries, although there are some failure modes, like here for."
        ],
        [
            "So what can you do with this?",
            "Well, one thing you can do with this, which is kind of a cool demo that I that is very visually appealing is if you partition the scene into these geometrically coherent regions.",
            "You could actually now do a 3D reconstruction from a single monocular image, so you can by identifying the horizon by assuming that the camera is about 1.8 meters off the ground.",
            "You can estimate the camera tilt and buy from that.",
            "You can basically.",
            "Figure out how the camera is looking and then predict the the region 3D position using Ray projection.",
            "So what does that mean for the object for the red object here, whose bottom is not included?",
            "We can figure out where how far it is from the camera.",
            "Approximately the green object has its bottom included, so we can't know exactly where it is on the ground plane, but we know that it can't be in front of the red object and it can't be so far back that it would be visible above the top of the red object, which actually gives you a little fairly small range of options as to where it might be.",
            "And so we picked the midpoint."
        ],
        [
            "So here are some examples of 3D reconstructions of very different images.",
            "And you can see that it actually does pretty well at figuring out what's in front of what, and that's from a single monocular image based purely on a semantic reconstruction.",
            "OK."
        ],
        [
            "The next thing you can do with this is go back to the object detection problem, which is the one that I highlighted the very beginning of the talk, and for that we augmented the model in addition to having pixels and regions.",
            "We also had objects and we could have objects that are comprised of multiple regions.",
            "So for example, here is a car that's comprised of several different regions, and so we have an additional set of variables that represent regions object assignments.",
            "We also commensurately extended the energy function, so here is the object model that basically says if this is a region or a bunch of regions that are.",
            "Together, form an object and they were expecting it to have a certain appearance.",
            "So for example, we're expecting a wheel in the bottom corner and various other image features that people typically use for identifying objects, so that's one term, and notice that it also relates the horizon because we also expect certain objects to be above the horizon and others to be below the horizon, and then the final, and perhaps the most interesting term in this whole energy function is the context term that relates objects to adjacent regions.",
            "So here, for example, the model learns again this none of this is pre imposed.",
            "It learns of cars are typically found on roads.",
            "Cows are typically found on grass, and vaults are typically found on water, and this is actually really significant because distinguishing, for example, Rd from water using image features alone is very, very difficult.",
            "They're both often grayish and have a certain amount of texture, but if you find the car on top of it, it's very unlikely to be water, and if you find the boat on it is very unlikely to be road, and so the object model can inform the regions and vice versa, and you get from this holistic model much better results than you get.",
            "By thinking about each piece of the image."
        ],
        [
            "Isolation.",
            "Phone is showing again some examples.",
            "This is a typical sliding window detector results and I'm showing you the talk to detections per image.",
            "So here are the top two highest confidence people in this image.",
            "One is indeed over there, but the other ones over there.",
            "These are the top two car detections.",
            "It's missed the real car entirely and put both cars over there.",
            "Now to be fair, the third detection really is that car but still and for some reason that's a cow.",
            "OK, our model which has a much deeper knowledge of context, understanding of contexts not only correctly outlined the one and only person in the scene and correctly more or less outline the only car visible in the scene, but also missed the cow that doesn't exist.",
            "That's good."
        ],
        [
            "Now again coming up with more quantitative results, here are several different graphs.",
            "This is the baseline object detection.",
            "This is precision.",
            "This is recall, so standard curves the baseline sliding window detector for all three of these object classes.",
            "The blue is a region based model and the red is what we would do.",
            "How well we could perform if we had perfect segmentation of the image into regions, which of course we don't.",
            "But it kind of gives you a sense of how well we could perform.",
            "So what we can see is that we get significant improvements in precision by considering regions and contexts.",
            "And if we have.",
            "OK, I'm going to have to never mind.",
            "But if we had, we could get near perfect detection, but but we don't, and so there's still obviously a way to go between."
        ],
        [
            "The red line.",
            "So now getting back to latent variables.",
            "Here we basically didn't, didn't assume latent variables.",
            "We assume that our training data was fully supervised.",
            "But now let's think about what that means.",
            "What is a person give us when labeling regions in an image which we did by obviously by Amazon Mechanical Turk?",
            "So this would be the ground truth label for the car object.",
            "And here is another ground truth label for this car.",
            "And for this tree, and so on.",
            "And then when you think about it, you realize that you know cars.",
            "A car isn't a single homogeneous region in terms of appearance, or for that matter, neither is it.",
            "Tree nor person, and so that the fact is that human specified regions are not the most discriminative necessarily from the perspective of computer vision algorithm.",
            "So what would happen if instead of having giving it ground from labels, we will let the human who would let the computer rather pick for itself?",
            "What are the late?",
            "What are the regions the pixel to region assignments that are most discriminative for its own purposes?"
        ],
        [
            "So here we learn, we train the model again with latent variables in coding these correspondences and what you get is a consistent improvement across all object classes with the most or almost all of the classes with the single most significant improvement being on the foreground class, which is the one we would expect there to be a biggest room for improvement.",
            "So that's kind of so.",
            "That's kind of a pleasing result that again choose letting the algorithm to this only thing variables is a good thing, which of course let us to be much more ambitious if we can do."
        ],
        [
            "That let's really tackle multiclass segmentation in the broadest sense of the word.",
            "So now let's have not five or six or ten object classes, but let's have 30 object classes that really pretty, much ultimately 100 or 1000 object classes, but not yet, but really basically label each pixel in the scene is corresponding to real semantic class.",
            "So here we would like from this input to basically label this entire set of pixels as an airplane.",
            "This is a person ground, Rd, and so on.",
            "Sky so great, but do we have?"
        ],
        [
            "Label training data for this.",
            "Well, we don't.",
            "We have various bits and pieces, so we have fully supervised foreground data from something like Pascal VOC, which is a standard computer vision data set were they have kindly labeled for us the labels for all foreground regions, but the background is left as generic background and we saw how important it is to have labeled background in terms of the interplay between background and foreground."
        ],
        [
            "The data set that we constructed, now known as the Stanford background data set has fully specified background classes, but the foreground are labeled as generic foreground, so we don't have a data set that has both at the moment.",
            "Now.",
            "Certainly we could construct one.",
            "We could put this all on Amazon Mechanical Turk and get that amount of fully supervised label training data, but that would be kind of mean missing the point, because in a day."
        ],
        [
            "And to all these datasets, we also have thousands of images that are labeled at the level of bounding boxes.",
            "Um, we're somebody only tells us that this is.",
            "This box contains a bus, and this one contains a car, but it doesn't give us a pixel level annotation, and it would be fairly expensive and time consuming to label all of these thousands of the level of the individual pixels."
        ],
        [
            "Not to mention the millions of images that exist on Flickr image net, Google images and so on, where we're the only label this given is car and you don't even know the bounding box of the car in the image.",
            "Certainly we don't want to label those at the level of individual pixels."
        ],
        [
            "So that again calls out for, so we'd like to use all of these images in training the kinds of models that we're talking about, and that immediately calls out again."
        ],
        [
            "The use of latent variables.",
            "So how would we formulate this as a latent variable model?",
            "Well, some of this is fairly straightforward.",
            "So for example, if we have a an image that's only labeled correctly at the label at the level of foreground, so we know the annotation of the foreground object.",
            "But we don't know the class label of the of the background classes and so.",
            "And so.",
            "My computer is stuck.",
            "OK, and so we have now a latent variable that actually has two components.",
            "First, as the assignment of region pixels to regions, which is, which is the one we had previously.",
            "But we also have latent variables that tell us how the background is assigned to appropriate classes, and that's something that we need the algorithm to infer during training, because that's not labeled your own training.",
            "But we so we think we have a labeling that says it's specific classes in the background must agree with the fact that is."
        ],
        [
            "And similarly.",
            "Similarly for the other.",
            "For the background case, what about bounding boxes?",
            "Say we only have we have an image accent Ry says.",
            "Here is a cow somewhere within this bounding box.",
            "Again, the latent variables tell us the partition into regions as well as the detailed segmentation of the image, and we have a constraint now on the bounding box assignment that says every row and every column in the bounding box must contain a pixel labeled with the bounding box class, because otherwise they would have made the bounding box maybe smaller.",
            "So this is a constraint on latent variables.",
            "That we need in order to make use of these very weakly labeled."
        ],
        [
            "And then finally going towards the most weakly labeled instances that you might find on on Flickr image net.",
            "Here the images is XY, just says cow somewhere in there and again the latent variables are the same and we have a constraint that somewhere in the image there needs to be a region that's labeled with cow in this case.",
            "So great, we now have a latent variable formulation.",
            "We applied our greatest and best latent variable."
        ],
        [
            "Learning method and.",
            "Basically we got a zero point 7% improvement by including all of those images in the data.",
            "Well, OK, that's on the background data set.",
            "Maybe on Pascal, which is a foreground data set.",
            "We're going to do better.",
            "Well, no, actually not.",
            "We did worse.",
            "In fact, here there's absolutely no improvement by using all of these weakly labeled images in in our current classification problem.",
            "And the problem is so basically using this large amount of weakly labeled data provides only marginal improvement, if any.",
            "And the reason for that is that inputing latent variables is hard, that is, to come up with this with what these latent variables ought to be is a challenging problem, and can introduce enough noise that it outweighs the benefit of having so."
        ],
        [
            "Much more data.",
            "Which brings me to the second part of my talk, which talks about learning latent variable models and the specific idea of self paced learning or having the algorithm pace itself in computing latent variables.",
            "And I'm going to talk about two different examples of this, one at the level of instances and one at the level of model.",
            "And this is work that was really led by my post doctoral on Kumar in my PC."
        ],
        [
            "So let me take a short digression into Max margin training, which is a topic that I'm sure many of you are familiar with.",
            "So go through it fairly quickly, so this is the the grammar and finger extension of binary support vector machines to the multiclass setting.",
            "So just as a reminder, we are still in the case where we're trying to find we're labeling.",
            "Why by optimizing an energy function which is a dot product of weights and the feature vector and the Max margin.",
            "Formulation which is a straight generalization of the standard SVM criterion, basically has the following pieces.",
            "We're trying to minimize the norm of the weights, and I'm hoping this is familiar to most people here, which is why it's going to be pretty quick.",
            "Some of the weights plus a weighted sum of the of the slacks and so subject to the constraint that the weight of the ground truth label, while I for the I TH instance is not only greater than the than the score of any other label for that instance, but also greater by a certain margins.",
            "This is why it's called Max margin classification and the slap basically is my ability to say, well, I can't label this instance correctly within the margin, so I'm going to allow myself not to do that correctly, but I'm going to have to pay for it.",
            "Objective function, so this is exactly the same as the two class formulation, except that I have for all Y here for all of the other possible labels for the for the instance X."
        ],
        [
            "Now in 2000 and three 2004, this framework of multi class SVM was extended first by my student Ben Tasker and Carlos Guestrin and subsequently by by forcing welcomes group to the notion of structured outputs.",
            "Where why isn't just a set of labels 1234, but rather an entire multi dimensional vector giving rise to potentially exponentially many labels.",
            "So why for example can be the entire segmentation?",
            "Avacyn, assigning each pixel to a class, in which case we have number which is exponential in number of number of labels, which is exponential number of pixels in the scene.",
            "So other than that, the formulation is actually fairly similar other than turning why from a from just an ordinal to a vector, we now have exactly the same formulation.",
            "The only other changes that the margin now can depend is not just the 01 loss given.",
            "Did you label this as the correct class or not?",
            "But then actually depend on some notion of distance between the ground truth in the alternative labeling so that you might choose, for example, to penalize Lessa segmentation that.",
            "Just a couple of pixels oph relative to penalising a segmentation that's you know has half the image labeled incorrectly, so you can have a loss dependent margin that allows different instances to requite allows you to require different levels of margin from different instances.",
            "Depending on just how wrong they are.",
            "So this was a nice nice formulation.",
            "It by itself is not is not a huge leap because you just basically changed the space of lies.",
            "The real issue of course is that this has exponentially many constraints because we have a constraint that specifies the margin for every single possible labeling wine.",
            "As I just told you, there's exponentially many of those.",
            "So how does one deal with that?",
            "Well, these two papers presented two different methods are."
        ],
        [
            "Paper in 2003 basically made the observation that for models that are tractable in a certain sense, basically ones that look like a tractable graphical model, admit a polynomial size formulation that is exact as a quadratic program.",
            "So you could actually solve it using exactly the same kinds of techniques that you would solve any other support vector machine.",
            "In the subsequent paper, by forcing your Kings group, they came up with a more general approach that also is in easier to implement, which uses cutting planes so that instead of constructing a single QP, basically add constraints one at a time and that has a lot of elegant properties.",
            "Specifically, it often requires only map inference relative to this graphical model so that it admits algorithms that are much more tractable and don't require that we compute the partition function or run full scale probabilistic inference.",
            "And they actually showed using very nice proof that for many models only polynomial number of cutting planes is required for close to optimal learning, which means that by generating enough bad solutions in this problem, if you generate a polynomial number of those you've converged to something that is actually correct.",
            "Are close to correct, so that was a big development in this whole technology is now used really ubiquitously in computer vision as well as in other areas, including natural language and others.",
            "For learning structured models using a Max margin form."
        ],
        [
            "In 2008, 2009, this framework was first extended to the case of latent variables.",
            "So the latent SVM model, which was first proposed by Felzenszwalb, McAllister and Ramanan, basically the energy function, just like in the first few slides that I showed, was extended by introducing a latent variable, and that gave rise to the following formulation.",
            "That looks exactly like the previous one that we showed before, except that these additional latent variables are entered into the into the energy function.",
            "And what basically gets what basically happens is that these have to be imputed in the case of the ground truth annotation.",
            "So the best imputation of H, which is this Max over the hi.",
            "So the best imputation of the best completion of the hidden variables that's consistent with my ground truth label needs to be better by the margin than any other imputation.",
            "For any other label.",
            "So this is sort of the thing that I would most pick this consistent with my ground truth.",
            "Has to be better than anything else."
        ],
        [
            "OK, and so, um, these two papers came up with an algorithm called SCCP which has the following structure.",
            "It starts with an initial estimate of the parameters and then it imputes the latent variables using those current parameters.",
            "And that's again, then using map inference, whilst the latent variables are imputed, this turns back into a standard.",
            "Under Dassem and that you can solve using your standard techniques and then the process repeats.",
            "Because you now have better parameters, so you can think of it as kind of like expectation maximization or kind of like or variant of coordinate descent.",
            "So fairly straightforward method for dealing with latent variables, which I'm sure all of you have seen before in different contexts.",
            "And you can prove that this converges to a local optimum of this objective function.",
            "But the critical question is how well can you impute."
        ],
        [
            "Hi.",
            "So let's look at some examples in the context that I showed before.",
            "So here is 1 example.",
            "Remember, we don't have the background information here, so let's see how we can compute it.",
            "Well, here the Sky is white, the grass is green, the road is Gray.",
            "Basically any half Lane algorithm can impute those pretty correctly, and the answer is it does, so this isn't."
        ],
        [
            "Easy example.",
            "Here's another good one.",
            "The Sky is white or kind of grayish.",
            "The grass is green, the water is blue.",
            "Imputation works great.",
            "Unfortunately, not all images are create."
        ],
        [
            "Equal here is a different one.",
            "Here you're trying to impute the foreground, which is immediately much harder.",
            "Problem is this a cow.",
            "A horse.",
            "Cat.",
            "Remember, the algorithm doesn't hasn't been trained yet.",
            "It doesn't really know What Car what cows look like and how they differ from horses.",
            "And sure enough, if you try and impute this, you get this unholy mess that I think is half sheep.",
            "Half something half how I think it's some."
        ],
        [
            "So our mix.",
            "Here's another one.",
            "Well, this one is a pretty nasty one.",
            "The Sky is red.",
            "The mountains black and sure enough, if you try and impute this you basically end up with some completely ridiculous imputation once again.",
            "So not only."
        ],
        [
            "This is are the same.",
            "So now we were inspired by going back to human learning, and let's imagine that we were trying to teach this kid math and we said all of what we know into one in one session.",
            "It's not going to go over really well.",
            "So what happens if rather we teach them?"
        ],
        [
            "He should the way we teach, or ought to be, teaching children by doing things one stage at a time.",
            "That works a little bit better, so why don't we try?"
        ],
        [
            "You do the same with our algorithm.",
            "Start with easy examples and then consider hard ones.",
            "And this is an actually an idea that was proposed contemporaneously with our work by Yoshua Bengio at all I see Mail 2009 and.",
            "It says let's label some images is easy, others are hard, and then trying train the model on the easy examples first, then only then start to impute the hard work.",
            "The problem is that easy for humans is not the same as easy for computers and this is the case that I've been making throughout this talk."
        ],
        [
            "So we have easiness is not some objective thing that you can determine in advance the property of datasets and it's a property with classifier you're using.",
            "You can't look at an instance and in isolation say whether it's easy or hard and that the computer who has a much better sense of what's easy and hard for it should figure out for itself.",
            "With instances are hard for it right now in the current stage of the algorithm.",
            "So with this intuition in mind, we came up with an algorithm called self paced learning, which this is the original.",
            "The original SCCP algorithm."
        ],
        [
            "We basically we now all.",
            "We now add a set of variables VI which are 01 labels and we only count and basically VI means if you guys want it says the instance is included in the current learning iteration.",
            "VI Zero, it says that it's not included and you can see that by the fact that VI multiplies the stock.",
            "So you don't pay any penalty for getting unincluded instances wrong.",
            "So so basically the example is easy.",
            "I should include it, and if it's hard then I should know that by itself you know gives the algorithm all the incentives just label everything is hard and say my work is done so obviously want to penalize it for choosing not to label instances and so we add an additional penalty term for all of the instances that it chose not to label.",
            "And then that forces it, or to choose some of the hard examples to label eventually and we're going to anneal this factor K. To eventually force it to label all of the examples.",
            "Now, in order to solve this, we relax this to A to a set of continuous variables, another in the interval 01, and then it turns out that it's a BI convex optimization, which can be solved efficiently using alternate convex search, and I'm not going to."
        ],
        [
            "Other details, so now the algorithm says start with an initial estimate W 0.",
            "Impute the latent variables.",
            "Update WT plus one by solving this biconvex problem and then having done that, I'm going to hopefully have a better model, so I'm going to decrease going to new my penalty so that I'm forcing the algorithm to include more instances."
        ],
        [
            "So let's look at what that does.",
            "This isn't a simple illustration of a 01 of a binary classification problem.",
            "Initially at the early stages, K is large.",
            "I don't really care if I use, don't use so many instances so it's only going to choose to label instances that are far from the decision boundary.",
            "As the algorithm progresses, the penalty becomes larger and so eventually I'm going to move to the regime where I have to label everything, including if it's confusing, but hopefully by this point my parameters are good enough that my imputation for the latent variables."
        ],
        [
            "Pretty reliable, so let me demonstrate this on an example because I think visually is going to become very clear and I'm going to use a much simpler example.",
            "The one of you so far.",
            "This is a standard example of object detection.",
            "The input X is an image, the output wise.",
            "A class label, which in this case is one of six mammal groups, were doing a simple 01 loss, and the latent variable is the bounding box where the object is going to be found.",
            "Given a bounding box, I can now apply any of my favorite learning algorithms that do bounding box detection.",
            "So for example, we could use a standard so-called hog detector.",
            "For those of you have heard the term, but any any algorithm that detects the classified bounding boxes can be used in this setting.",
            "The problem, of course, is that we don't know rhat is latent using the training."
        ],
        [
            "So let's look at some examples.",
            "This is the iterations of the algorithm of blue on the left of the CCP algorithm, which is the one that that was there before.",
            "And this is the self paced learning variance.",
            "And what you see here is blue if the if the example is used in training in red.",
            "If it's not, and remember whether it's used or not as the decision of the algorithm makes, so CCP doesn't get a choice, it has to use all of the all of the images, which is why the bounding boxes here all blue.",
            "But you'll notice that an iteration one the inferred bounding boxes.",
            "That the algorithm chose not to use are almost invariably wrong.",
            "Where is the one that it shows yes to use are almost invariably."
        ],
        [
            "This is iteration 5.",
            "The bounding box is changed a little bit, but it's still not sufficiently confident about these, even though this one's pretty cool."
        ],
        [
            "Right, but by iteration mine it nailed both of these mounting boxes and in fact chose to use them, whereas this one is still not sufficiently confident.",
            "And in fact it's still a little bit."
        ],
        [
            "But by iteration 13, it's basically imputed the hidden variables correctly and chosen to use."
        ],
        [
            "All the examples.",
            "So quantitatively, this is my object detection baseline task.",
            "What we see here is the test error for SCCP versus self paced learning and we see a healthy improvement in of 1.5% in in the test error.",
            "We applied this to actually four different very very distinct problems that involve latent variables.",
            "I'm not going to show you all four of them just going to show you one more to demonstrate the generality of this of this algorithm.",
            "So this is finding DNA motifs where you know that a protein bound to a particular region of the DNA but don't know exactly.",
            "Word bound and you'd like to identify the motif that allowed the protein to bind to the DNA.",
            "So here X is the sequence Y is bind Ng bind and H is the multi position.",
            "And again we see a very healthy improvement of about 5% in test area."
        ],
        [
            "And then finally, these are results that arrive yesterday.",
            "This is of some initial results on the Pascal VLC challenge and this is accuracy as opposed to error, so higher is better.",
            "And again we can see healthy improvements both in test accuracy and an average precision, which is a metric that's often used in computer vision."
        ],
        [
            "OK, so now let's go back to our diverse data learning and the whole image segmentation thing that started out this this whole discussion.",
            "So here's an example.",
            "Input image.",
            "Here is the in Ferd labels from the from the original algorithm that we started out with and here and notice that it's labeled.",
            "All of this I think is grass and that's role and hear the inferred labels are considerably better.",
            "And again that translates to significant improvements in performance.",
            "Across all different classes for both the Stanford background data set and for the Pascal DLC data set.",
            "So some classes are a little bit worse, but almost all classes are considerably better.",
            "Which shows that if you train your algorithm correctly.",
            "Computing the hidden variables carefully, then you can make good use even a very weakly annotated data."
        ],
        [
            "The final piece of this is a very new work.",
            "It's actually still under review, which tries to take this intuition as in."
        ],
        [
            "Get a different, slightly different direction, which is the question of model selection, which is one that I'm sure that all of you have ever applied machine learning have faced of OK.",
            "Which classifier should I use?",
            "And specifically, for example, which kernels should I use that he's a linear kernel?",
            "A cubic kernel quit the kernel?"
        ],
        [
            "So let's go back to the human learning motivation and let's again take some do this kind of as a simple example, imagine when somebody asks you to teach them physics.",
            "You start out with a very complicated model.",
            "The general theory of relativity."
        ],
        [
            "Rob."
        ],
        [
            "Very successful.",
            "But what about if we start with a?"
        ],
        [
            "Simple model."
        ],
        [
            "And then a slightly more complicated."
        ],
        [
            "1.",
            "And then the most complicated one.",
            "Maybe that's going to work better so."
        ],
        [
            "Let's see if that applies to computers, so here are our three, three kernels of increasing complexity, and we're going to rely on the theory of multiple kernel learning, which was proposed by Bocklin creator Jordan in 2004, and what that says is we're going to use a weighted average of different kernels.",
            "So here we have the different kernels side one side 2 and so on, and there's a bunch of coefficients that wait with.",
            "What way do you want to include each of them?",
            "And So what we have is actually, like, really, really, really long kernel.",
            "That is, the aggregate of all of these different pieces of kernels.",
            "And so you can think of the kernel as a weighted combination was called the conic combination of the different of the diff."
        ],
        [
            "Sub kernels, and then how does one do multiple kernel learning?",
            "Well, you basically put this big big kernel into the matrix and you optimize simultaneously, not only over the weights of the learner and the slacks but also over the weights of the different kernels so that you try and pick the kernels.",
            "That gives you the best loss on your training set.",
            "Well, that's great, except that if you actually optimize this objective as written, it encourages the most complex kernel because the most complex kernel fits best to give me the lowest slacks it's going to.",
            "It's going to give the best classification performance on the training data, and so if I try and optimize two training performance, I'm going to."
        ],
        [
            "Profit.",
            "So.",
            "What we're going to do is we're going to introduce into this a penalty on model complexity and the specific model complexity that we're going to use is what's called the Rademacher complexity.",
            "It's a way of measuring the complexity of a kernel, and so we're going to learn in a way that encourages the algorithm to pick simpler models.",
            "And now let's think about what that does in the context of latent."
        ],
        [
            "Labeling.",
            "All.",
            "So we start with an initial estimate.",
            "And we're going to use that to impute.",
            "The um, latent variables, and then we're going to go and update both the weights and the kernel weights by solving this convex problem, and then we repeat."
        ],
        [
            "So let's see."
        ],
        [
            "Think about what this algorithm, which is we call self paced multiple kernel learning or known to its friends as spam."
        ],
        [
            "So here is the spam kill behavior.",
            "What happens in early iterations?",
            "In early iterations the hi's are almost invariably incorrectly imputed.",
            "Which means that the cyyz are going to be large even for complex kernels because even for complex kernels, if the bounding boxes right, you can't get things correct, because it's effectively a random prediction problem.",
            "And at that point the algorithm tries to optimize for this complexity term and therefore it's going to prefer simple kernels.",
            "Which are going to not overfit."
        ],
        [
            "Dana in later iterations the hi's are more likely to be correctly imputed, which means that society is going to be small for the correct kernel and then hopefully you're going to prefer the more complex kernels so that you can minimize the total sum of the slacks.",
            "So let me show you that that and know that this behavior happens without ever kneeling the term Lambda, which represents the strength of this term."
        ],
        [
            "So let me show you that this actually works in practice.",
            "This is exactly an example of the balance of the imputed bounding boxes relative to cubic kernel, which is the one that performs best on this data set.",
            "And so here is just a plain cubic kernel and the system fill.",
            "This is iteration one, it's the same, it's the same because they both start out in the same place."
        ],
        [
            "By iteration 3."
        ],
        [
            "Spam Kill has moved many of the bounding boxes to the correct place.",
            "We don't."
        ],
        [
            "If any improvements for the cubic kernel, because basically it's over fit to this particular set of incorrectly computed bounding boxes.",
            "Now stuck and can't."
        ],
        [
            "Iteration 6 we've now nailed.",
            "That one as well.",
            "This still doesn't know very."
        ],
        [
            "Not.",
            "Here, iterations and it moves that actually in the."
        ],
        [
            "Direction and basically have convergence Pamphile has nailed bounding boxes for all of these objects, whereas this one is still very far off because it overfit to the incurred."
        ],
        [
            "Tations so if you actually look at that quantitatively, what you see here is the behavior of linear, cubic, quintic, UU weighting of the kernels in spaniel, and we see that other than the linear kernel which performs pathetically all of them achieve affectively, 100% accuracy on the training data, and that's because they are over fitting.",
            "On the other hand, on the test data, the linear kernel still performs pathetically, but all of the other ones also performed not very well because they've overfit to the trading banophen incorrect imputations.",
            "So the stronger kernels overfit.",
            "The noise invitations get stuck at a local optimum where Spackle only uses the strong kernels.",
            "When the imputations are accurate."
        ],
        [
            "Waiting this local optimum and if you want to see this even more quantitatively, this is the score of the overlap of the bounding boxes between the imputed bounding box and the ground truth bounding box, and what you see here is over iterations.",
            "This score of how well these match up and you can see that the cubic kernel, which is the one that performed best, never achieves an average intersection of greater than 0.8, where Stanfield gets to 0.9, three or two or so."
        ],
        [
            "And again, to show you this is not a fluke for this data set, this is the DNA binding motif and you can see here the linear kernel actually performs better than these other guys, but spam kill performs significantly."
        ],
        [
            "So to summarize.",
            "The first conclusion is the pixel level scene.",
            "Understanding this is for the first part of the talk, enforces coherent coherence.",
            "In the scene interpretation and consistency of context, so you don't get, for example, that this is a cow.",
            "Which is what it was inferred to be.",
            "Um?",
            "But on the other hand, if we want pixel level scene understanding that we need a heck of a lot more training data than we currently have, because pixel annotations are still very laborious even with all of the Amazon Mechanical Turk, and so we only have those in limited amounts.",
            "And Furthermore, even if we can get somebody to label them the human annotations don't necessarily line up with what we do."
        ],
        [
            "Like to see.",
            "So the second conclusion and this, I think, is a broad conclusion for machine learning in general, not just for computer vision, is that we need to come up with ways of making better use of training data.",
            "We need to be able to use weekly label data.",
            "We need to use diverse data that has different levels of annotations, including unsupervised data and so on.",
            "But in order to do that, you need to be able to deal correctly with latent variables.",
            "Because as soon as you have weak labeling, it means that implicitly or explicitly, there's a bunch of variables."
        ],
        [
            "Unlabeled in your training data.",
            "And the third conclusion from the third part from the last part of the talk is that if you're training latent variable models, it's important not to jump too quickly.",
            "Don't immediately force your algorithm to solve the hardest instances, or to use the richest model.",
            "Rather, let the algorithm gradually adapt to increasing levels of complexity."
        ],
        [
            "So let me prove I found this looking around.",
            "I don't know how many of you are familiar with the Khan Academy, which is this really amazing resource on the web for teaching kids math.",
            "This is an article from KQED that talks about the future of the school day for teaching children math as well as other topics, and it talks about the importance of self paced learning where every student works at his or her own pace.",
            "Students, working groups and so on."
        ],
        [
            "So what about if we have the following every algorithm working at his or her own pace?",
            "Different kernels, working groups, and helping each other and the data set full of diverse weakly labeled instances that give algorithms practical knowledge and experience?"
        ],
        [
            "So let me conclude by thanking the people who did the work.",
            "I've already mentioned all their names.",
            "I won't read this again as well as my funding sources and thank you for your attention.",
            "And I'm happy to take questions.",
            "Well, Tom is getting a microphone so.",
            "So I love to talk.",
            "One question though is.",
            "You needed to have a data set where some of the instances were actually easy.",
            "Yes.",
            "DNA data that you might not have such things, although I've never given up.",
            "I guess that's a valid question.",
            "What makes some DNA instances easier than others?",
            "I think.",
            "That's a really good question.",
            "I think that's partially it's a question of how many almost motifs there are in the in the DNA surrounding the actual motif of whether it looks more like the random background distribution.",
            "But you're right that if I have a data set where all instances are equally hard, this is likely this at least the as the self paced learning.",
            "The first one is likely not to work.",
            "Intuition why you didn't have to.",
            "To the anneal the the Lambda parameter.",
            "Sure, because then go back because it's close."
        ],
        [
            "So in the early iterations, even with a fixed Lambda the hi's are going to be incorrectly imputed because the WS are just wrong and so the cyyz are going to be large no matter which currently used, because even the most complex curtain kernel can't fit the noise that well and so given that option of fairly large size, regardless of whether you use a simple kernel or complex kernel, the Rademacher complexity turn takes over and says well in that case, since I can't win on the.",
            "On the accuracy anyway, may as well at least win on model complexity, whereas in later iterations as the HI is become more correctly imputed than using the simple kernels doesn't fit to them quite as well, and I'm going to use the most complex kernel that fits well the imputed labels, but even then I'm not going to necessarily.",
            "We have graphs of that in the paper, even there it doesn't go all the way to quit the kernels.",
            "At that point, it sort of stops where CU has most of the mouse because.",
            "Because that's sort of the right tradeoff point where the size are about equally good and but you lose on the Rademacher complexity.",
            "I have a question about the first part of the talk and the notion of clutter and working more in natural language and speech in speech recognition.",
            "Actually, the lesson learned was the notion of culture is not good.",
            "I mean right now the best speech recognition algorithms for this so called garbage models.",
            "So they explicitly model every detail of the clutter in the sense that said nonspeech things like, you know, even cutting and so on on this explicitly model.",
            "Now my question is.",
            "Envision another expert.",
            "Whether it's a good idea to really start with running Club in general, because what is clutter for one task may be non clutter for another one.",
            "If you look at the picture from a different perspective, let's say you are looking at the traffic scene from Homeland Security perspective.",
            "Some things which may be clutter in the normal classification is a session is essentially no clutter for the purpose we are looking at this picture and so on so.",
            "That's my question.",
            "I need a job.",
            "The lesson from speech or about the notion of of you know, distinguishing clutter in one cluster is only another good boundaries between vision.",
            "It's another case.",
            "OK, so first I think the use of the word clutter, which we did not invent because we adopted it from the previous paper, was probably misleading in this regard.",
            "We have no intention of throwing out the clutter.",
            "In fact, the clutter is the furniture, and often some of the most interesting aspects of the scene are the are the so called clutter.",
            "The reason it's clutter is because it clutters up your ability to detect the box, which is why they originally used the word clutter for that particular thing.",
            "Now, the experience that people have in computer vision in general is very similar to what you're reporting from speech, which is the throwing away things that are not the thing that you're trying to detect is losing valuable information, which in this case would be contextual information about where the object is.",
            "So specifically when people have done, for example, detection.",
            "Sorry, object classification, you actually often do worse by focusing only on the bounding box of the object and removing any of the contextual information.",
            "Nevertheless, identifying what where the object is versus where it's not is very valuable information for guiding the features of the of the algorithms so that you know to wait those differently, perhaps, and so that's what the latent variables are doing is they think this is where I think the object is and I should treat the feature inside this box differently from the features.",
            "Outside this box, even if the ones outside this stuff are so informative, there informative in a different way.",
            "So the experience is very similar to what you described and the word clutter here was just chosen because of the specifics of the application that that that that the original construction of the worker.",
            "But it's a very good point, so thank you for asking them.",
            "Question.",
            "So let's take the speaker, yeah?"
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you to the organizers, organizers for inviting me to be here 10 years almost to the day from the time that I gave my computers and thought award talk, and in fact, the.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Our slide that I'm going to present.",
                    "label": 0
                },
                {
                    "sent": "Is.",
                    "label": 0
                },
                {
                    "sent": "Actually, the last slide that I used in my computers in thought talk 10 years ago, which was a slide where I talked about the importance of bridging different things, bridging logic and probability.",
                    "label": 0
                },
                {
                    "sent": "Using that as the basis for bridging between reasoning and learning, and ultimately using that.",
                    "label": 0
                },
                {
                    "sent": "Looking forward as bridging between low level perception and high level understanding, and much of the work that I've done since that talk in the last decade has focused.",
                    "label": 0
                },
                {
                    "sent": "Certainly the computer vision part has focused on trying to bridge this gap between perception and understanding.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That's what I hope to tell you about today, so let's talk about what it means to go from perception to understand that if this is an image that we hope to, we hope to interpret what we would like to do is we would like to move beyond just labeling pieces of the image in isolation, but rather to come up with a holistic interpretation in the same way that a person might use so to come up with an interpretation that says a man wearing a backpack smoking a cigarette, walking a dog.",
                    "label": 1
                },
                {
                    "sent": "Now, for those of you who haven't done computer vision, this might seem fairly trivial.",
                    "label": 0
                },
                {
                    "sent": "I mean, it's obvious that that's what's going on here.",
                    "label": 0
                },
                {
                    "sent": "But if you actually start thinking about what computer vision does and how it might be applied to this image, you realize that the cigarette is about 3 pixels wide and 10 pixels long.",
                    "label": 0
                },
                {
                    "sent": "Is a white stick, and the only way to possibly infer that it's a cigarette is by realizing that it's part of a man's mouth that is at the man's mouth, and that means it could either be a cigarette or lollipop, and given that it's a grown up, it's probably a cigarette, and that's not the kind of reasoning that a computer naturally doesn't.",
                    "label": 0
                },
                {
                    "sent": "Certainly, computer vision algorithms today are not capable of doing that kind of influence in general.",
                    "label": 0
                },
                {
                    "sent": "The same issues come up with the backpack, which is an undifferentiated black blob, and backpacks come in many shapes and many colors.",
                    "label": 0
                },
                {
                    "sent": "The leash is almost invisible, so how could you possibly infer that the man is walking the dog if you weren't using context?",
                    "label": 0
                },
                {
                    "sent": "So what I'd like to tell you about today is some of the work that we've done to take a few steps.",
                    "label": 0
                },
                {
                    "sent": "Certainly not the.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Away in this direction.",
                    "label": 0
                },
                {
                    "sent": "Again, clarify the difficulty of the problem.",
                    "label": 0
                },
                {
                    "sent": "Let me talk about how object detection is done today.",
                    "label": 0
                },
                {
                    "sent": "This is a caricature, but it's not that far off from the truth, so we want to detect cars in an image.",
                    "label": 0
                },
                {
                    "sent": "So we give the algorithm A.",
                    "label": 0
                },
                {
                    "sent": "We give a machine learning algorithm.",
                    "label": 0
                },
                {
                    "sent": "This is better.",
                    "label": 0
                },
                {
                    "sent": "OK, sorry, so we give a machine learning algorithm.",
                    "label": 0
                },
                {
                    "sent": "A bunch of examples of bounding boxes that contain cars and a bunch of examples of bounding boxes that don't contain cards and it learns to distinguish cars from non car bounding boxes and then given the new image like this we take each bounding box and we place it on the image and we ask is this a car yes or no?",
                    "label": 0
                },
                {
                    "sent": "Does it pass our threshold?",
                    "label": 0
                },
                {
                    "sent": "Well, what about this one and this one and this one and this one and that one and not look now one?",
                    "label": 0
                },
                {
                    "sent": "Now the problem of course is that we don't know the scale of the car because it's a 2 dimensional projection of a 3D World.",
                    "label": 0
                },
                {
                    "sent": "So we.",
                    "label": 0
                },
                {
                    "sent": "To run this at different scales as well, and so if you do that with the best sophisticated machine learning algorithms and run this on this image, trying to detect three object classes, a car, a Moat.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Cycle and a person.",
                    "label": 0
                },
                {
                    "sent": "This is what you get so.",
                    "label": 0
                },
                {
                    "sent": "There's a person right there.",
                    "label": 0
                },
                {
                    "sent": "That's a motorcycle.",
                    "label": 0
                },
                {
                    "sent": "It did detect this car.",
                    "label": 0
                },
                {
                    "sent": "Correct weakness these other two, but on the other hand found one there and one there.",
                    "label": 0
                },
                {
                    "sent": "This is fairly typical of computer vision algorithms, and it's not because there stupid.",
                    "label": 0
                },
                {
                    "sent": "The people who build these machine learning up based algorithms for computer vision are very smart and they put a lot of thought into constructing the best learning algorithms that they can.",
                    "label": 0
                },
                {
                    "sent": "It's because they don't see the whole.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Picture.",
                    "label": 0
                },
                {
                    "sent": "And So what I'd like to tell you about is 2 things.",
                    "label": 0
                },
                {
                    "sent": "The first is the work that we've done in holistic scene models, and that's going to have two parts.",
                    "label": 1
                },
                {
                    "sent": "And then the second half is going to be focused primarily on machine learning and develop some new machine learning techniques that we've developed that are instrumental in trying to do better understanding of semantically complicated objects, and I hope that the second part of the talk will be of relevance even to those of you who don't specifically care bout compute.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Vision, so the first part of the talk is work primarily by my student YN Lang.",
                    "label": 0
                },
                {
                    "sent": "Together with Stephen Gould and that's it.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Understanding of indoor scenes.",
                    "label": 0
                },
                {
                    "sent": "So here are the goals that they can.",
                    "label": 0
                },
                {
                    "sent": "Image of the scenes such as this and indoor image and to recover what the global scene geometry which gives us a notion of scale and where the floor and walls are so that we can better detect and identify objects as well as what are the furnitures that the Occupy the seats are.",
                    "label": 0
                },
                {
                    "sent": "Target output is a box that identifies the boundaries between the major faces and the furniture layout.",
                    "label": 0
                },
                {
                    "sent": "The problem is this is not an easy problem because these clutters these furnitures.",
                    "label": 0
                },
                {
                    "sent": "Occlude boundaries and obscure the appearance of major faces and so it's very hard for computer vision style algorithm to know that behind this bed and this cabinet there's actually a wall, and that this is where the wall is, so this is not.",
                    "label": 1
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Trivial problem, so we were not the first identify this problem year before we wrote our paper.",
                    "label": 0
                },
                {
                    "sent": "A very nice paper by head out all came out and they said well since these two problems are difficult and interrelated, we're going to basically try and train algorithm to solve each of them.",
                    "label": 0
                },
                {
                    "sent": "So we're going to train an algorithm that labels the box.",
                    "label": 0
                },
                {
                    "sent": "We're also going to try and label an algorithm that identifies the clutter, the furniture, and then we're going to iterate by long over these two different stages, estimating the box and labeling.",
                    "label": 0
                },
                {
                    "sent": "The the the the labels of the of the pixels in the image as to whether they are cut or not.",
                    "label": 0
                },
                {
                    "sent": "Now this is the paper that we started out from.",
                    "label": 0
                },
                {
                    "sent": "Only decided to take a different approach which as you'll see is a running theme throughout this talk which is to try and let the algorithm figure things out for itself.",
                    "label": 0
                },
                {
                    "sent": "So rather than labeling the rather than giving it a training set with labeled clutter, we're going to only label the boxes and we're going to let the algorithm figure out for itself what.",
                    "label": 0
                },
                {
                    "sent": "What is the clutter now that has?",
                    "label": 0
                },
                {
                    "sent": "The obvious advantage of requiring a lot less labeling effort, but as you see it also has other advantages that I'll get to that I'll get to at the end of this segment.",
                    "label": 0
                },
                {
                    "sent": "So here we're going to model the clutter layout as latent variables.",
                    "label": 1
                },
                {
                    "sent": "Latent means that they run observed at training time, not just the test time.",
                    "label": 1
                },
                {
                    "sent": "So the algorithm has to train inferring what the where the clutter is, and then we're going to employ Max margin learning for joint model of the clutter and the box, and I'll talk about Mega Max margin learning in the second half.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what is So what is the overall formulation of the model that we used here and that we're going to use elsewhere in the talk is is what's called an energy function, or also known as a log probability.",
                    "label": 0
                },
                {
                    "sent": "So this, so this is what it would look like, and so here X is the input.",
                    "label": 0
                },
                {
                    "sent": "In this case it's the image.",
                    "label": 0
                },
                {
                    "sent": "Why is the target output, which is the observed output?",
                    "label": 0
                },
                {
                    "sent": "Is the box parameters, age is the set of latent variables, which in our case is a binary mask for each pixel, or each super pixel in the image.",
                    "label": 1
                },
                {
                    "sent": "Specifying whether it's clutter or part of the box, this is a large feature vector that basically says forgiven configuration of imagebox parameters and latent variables.",
                    "label": 0
                },
                {
                    "sent": "Does this make what are some features of that configuration jointly?",
                    "label": 0
                },
                {
                    "sent": "So, for example, how uniform are the walls?",
                    "label": 0
                },
                {
                    "sent": "Or how even is the box and things like that?",
                    "label": 0
                },
                {
                    "sent": "So these are this is a large feature vector from which we hope to use to identify how good different configurations are, and this is the learned weights that we're going to have our model learn.",
                    "label": 0
                },
                {
                    "sent": "And then given this energy function which which we learned, we're going to label the overall scene by finding the optimal the highest scoring configuration of both the box emulator very.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so this is great and we did maximum large margin learning using state of the art method that I'll talk about later.",
                    "label": 0
                },
                {
                    "sent": "And this is the output that we got.",
                    "label": 0
                },
                {
                    "sent": "This is the inferred box.",
                    "label": 1
                },
                {
                    "sent": "In some of those scenes you can see that it's not that great.",
                    "label": 0
                },
                {
                    "sent": "And what's more important, this is the inferred clutter, and you'll notice that in all of these images, half the room is labeled as clutter.",
                    "label": 1
                },
                {
                    "sent": "Basically, in some images, everything but the clutter is labeled as clutter.",
                    "label": 0
                },
                {
                    "sent": "Which basically gives the come brings us to the conclusion that latent variables, although very powerful modeling tool or actually a tricky thing to work with, because often they end up taking in directions that you don't want to and will come back to that.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So how do you ground the latent variables?",
                    "label": 0
                },
                {
                    "sent": "So here we chose this approach that basically introduces an informed prior about what latent variables with the latent variables ought to look like.",
                    "label": 1
                },
                {
                    "sent": "So in particular, we added another term to the energy function, and we said for this energy there's these two terms.",
                    "label": 1
                },
                {
                    "sent": "First part is that major faces, like the walls or the floor should have pretty much consistent appearance.",
                    "label": 0
                },
                {
                    "sent": "If you take out the clutter.",
                    "label": 0
                },
                {
                    "sent": "So everything but the clutter should be pretty uniform.",
                    "label": 0
                },
                {
                    "sent": "Now that by itself is not enough, because one way to achieve uniformity of the faces is to have just a single pixel in each.",
                    "label": 0
                },
                {
                    "sent": "It's not going to be really uniform, so you don't want that.",
                    "label": 0
                },
                {
                    "sent": "So the other thing is the penalty on the total amount of clutter, so you don't want to get to a degenerate solution where everything is cluttered.",
                    "label": 0
                },
                {
                    "sent": "Everything is labeled with butter, so it turns out that if you add this very small amount of prior knowledge, each of these is a very simple term.",
                    "label": 0
                },
                {
                    "sent": "You end up with an informed fire about latent variables that guides the process towards a non degenerate.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Solution.",
                    "label": 0
                },
                {
                    "sent": "And so going back to this example here we have the learning without prior terms which we saw in the previous slide.",
                    "label": 0
                },
                {
                    "sent": "And here we have learning with prior terms and you can see that was identified as clutter.",
                    "label": 1
                },
                {
                    "sent": "Now is effectively only the clutter, and so this drove the latent variables towards a much more reasonable solution in this space.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So does that help?",
                    "label": 0
                },
                {
                    "sent": "Let's look at some quantitative results.",
                    "label": 0
                },
                {
                    "sent": "So this is the pixelwise classification error in terms of the major faces.",
                    "label": 1
                },
                {
                    "sent": "And this is the paper by hydel at all, and they achieved a 3026% misclassification rate using their previous unsupervised scheme, where they didn't label the clutter.",
                    "label": 0
                },
                {
                    "sent": "And then they managed to bring it down to about 20 with labeled quarter we got.",
                    "label": 0
                },
                {
                    "sent": "A very significant reduction in the error.",
                    "label": 0
                },
                {
                    "sent": "Even though we had unsupervised clutter, that is the comparison point for this is the first bar, not the second bar, because this used the same amount of annotation as this.",
                    "label": 0
                },
                {
                    "sent": "Without the prior, as you saw, as you would expect, the results are not quite as good, but here is the most interesting bar in this whole chart.",
                    "label": 0
                },
                {
                    "sent": "If you give the algorithm the ground truth clutter at Test time, and the training time, it performs considerably worse.",
                    "label": 0
                },
                {
                    "sent": "Huawei.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Look at that.",
                    "label": 0
                },
                {
                    "sent": "So here is the hand labeled clutter by human experts who labeled the clutter, and you can see that lots of things is that our algorithm chose to label is clutter.",
                    "label": 0
                },
                {
                    "sent": "The human didn't choose to label as clutter the entire cabinet.",
                    "label": 0
                },
                {
                    "sent": "Everything that's on the walls.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And in some examples, including this one, nothing was labeled as clutter, even though there's two or three distinct pieces of furniture in the room.",
                    "label": 0
                },
                {
                    "sent": "Which basically indicates the human labeling for these latent variables aren't necessarily the thing that the algorithm performs best with, and that's something that will come back to.",
                    "label": 1
                },
                {
                    "sent": "It's a running theme of this.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so that was the first thing yet.",
                    "label": 0
                },
                {
                    "sent": "Moving to the second vignette, let's talk about outdoor scenes and this is work by primarily by my PhD student Steven Golden.",
                    "label": 0
                },
                {
                    "sent": "Like postpone Kumar together with.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And she go.",
                    "label": 0
                },
                {
                    "sent": "So here are goals that they can outdoor scene like this and basically to construct again a pixelized scene segmentation that identify specific objects as well as the classes to which they belong.",
                    "label": 0
                },
                {
                    "sent": "But at the level not have bounding boxes with absolute pixel by pixel, assign each pixel to a particular object and object class.",
                    "label": 0
                },
                {
                    "sent": "So here we're going to use the same idea.",
                    "label": 0
                },
                {
                    "sent": "We're going to define this energy function and notice at the moment there are.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Latent variables will.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "After that, and so we're going to define this energy function with.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So on the next slide and what this energy function does is it introduces these variables that assign each pixel to a region, so we're region is something that is semantically and geometrically coherent, and so variables that we have in the model are the pixel to region assignments as well as various characteristics of the different regions, like their semantic label with, whether it's a car ground or or water, whatever the geometry, whether it's vertical, horizontal or Sky.",
                    "label": 0
                },
                {
                    "sent": "And then various other things, including the location of the horizon, which is also inferred in the image.",
                    "label": 0
                },
                {
                    "sent": "So this is the model and basically models.",
                    "label": 0
                },
                {
                    "sent": "Try the model tries to assign each pixel to a region while respecting the global coherence of the scene.",
                    "label": 1
                },
                {
                    "sent": "And I'll show that in.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The structure of the energy function in the next slide.",
                    "label": 0
                },
                {
                    "sent": "So this is my energy function.",
                    "label": 0
                },
                {
                    "sent": "Initially the basic model just had these three terms.",
                    "label": 0
                },
                {
                    "sent": "First tried to use image features to identify the location of the horizon.",
                    "label": 0
                },
                {
                    "sent": "Things like vanishing points.",
                    "label": 0
                },
                {
                    "sent": "It also had a bunch of terms that related each region between the semantic label, the geometry in the horizon.",
                    "label": 0
                },
                {
                    "sent": "So for example, it says first of all that if you're labeling this region as a tree then it should be kind of.",
                    "label": 0
                },
                {
                    "sent": "Green and free.",
                    "label": 0
                },
                {
                    "sent": "It should be vertical and most likely it's going to be above the horizon.",
                    "label": 0
                },
                {
                    "sent": "Now know that none of these were imposed on the on the energy function.",
                    "label": 0
                },
                {
                    "sent": "This was all learned from data, so this was just we incorporated the term into the energy function that allowed the model to learn this characteristic of natural scenes.",
                    "label": 0
                },
                {
                    "sent": "And then finally we had a contrast term that tried to encourage the model not to fragment the scene into tiny little pieces, but rather to merge together adjacent regions that had similar color and texture, and so that gave rise to these large coherent regions that provided a much more robust model.",
                    "label": 0
                },
                {
                    "sent": "So this.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The region they small let me show you some results, so this is what you see here.",
                    "label": 0
                },
                {
                    "sent": "Or is the class labels what you see here is the geometry including the inferred horizon and you can see that by and large it actually gets pretty good segmentation, so not perfect.",
                    "label": 0
                },
                {
                    "sent": "Oranges is foreground object, blue is water Gray Sky and by and large you see purple is Rd.",
                    "label": 0
                },
                {
                    "sent": "You can see that it works pretty well.",
                    "label": 0
                },
                {
                    "sent": "Green is grass and so on, so it actually it actually works pretty well in segmenting out even fairly fine boundaries, although there are some failure modes, like here for.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what can you do with this?",
                    "label": 0
                },
                {
                    "sent": "Well, one thing you can do with this, which is kind of a cool demo that I that is very visually appealing is if you partition the scene into these geometrically coherent regions.",
                    "label": 0
                },
                {
                    "sent": "You could actually now do a 3D reconstruction from a single monocular image, so you can by identifying the horizon by assuming that the camera is about 1.8 meters off the ground.",
                    "label": 0
                },
                {
                    "sent": "You can estimate the camera tilt and buy from that.",
                    "label": 0
                },
                {
                    "sent": "You can basically.",
                    "label": 0
                },
                {
                    "sent": "Figure out how the camera is looking and then predict the the region 3D position using Ray projection.",
                    "label": 1
                },
                {
                    "sent": "So what does that mean for the object for the red object here, whose bottom is not included?",
                    "label": 0
                },
                {
                    "sent": "We can figure out where how far it is from the camera.",
                    "label": 0
                },
                {
                    "sent": "Approximately the green object has its bottom included, so we can't know exactly where it is on the ground plane, but we know that it can't be in front of the red object and it can't be so far back that it would be visible above the top of the red object, which actually gives you a little fairly small range of options as to where it might be.",
                    "label": 0
                },
                {
                    "sent": "And so we picked the midpoint.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here are some examples of 3D reconstructions of very different images.",
                    "label": 1
                },
                {
                    "sent": "And you can see that it actually does pretty well at figuring out what's in front of what, and that's from a single monocular image based purely on a semantic reconstruction.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The next thing you can do with this is go back to the object detection problem, which is the one that I highlighted the very beginning of the talk, and for that we augmented the model in addition to having pixels and regions.",
                    "label": 0
                },
                {
                    "sent": "We also had objects and we could have objects that are comprised of multiple regions.",
                    "label": 0
                },
                {
                    "sent": "So for example, here is a car that's comprised of several different regions, and so we have an additional set of variables that represent regions object assignments.",
                    "label": 0
                },
                {
                    "sent": "We also commensurately extended the energy function, so here is the object model that basically says if this is a region or a bunch of regions that are.",
                    "label": 0
                },
                {
                    "sent": "Together, form an object and they were expecting it to have a certain appearance.",
                    "label": 0
                },
                {
                    "sent": "So for example, we're expecting a wheel in the bottom corner and various other image features that people typically use for identifying objects, so that's one term, and notice that it also relates the horizon because we also expect certain objects to be above the horizon and others to be below the horizon, and then the final, and perhaps the most interesting term in this whole energy function is the context term that relates objects to adjacent regions.",
                    "label": 0
                },
                {
                    "sent": "So here, for example, the model learns again this none of this is pre imposed.",
                    "label": 0
                },
                {
                    "sent": "It learns of cars are typically found on roads.",
                    "label": 0
                },
                {
                    "sent": "Cows are typically found on grass, and vaults are typically found on water, and this is actually really significant because distinguishing, for example, Rd from water using image features alone is very, very difficult.",
                    "label": 0
                },
                {
                    "sent": "They're both often grayish and have a certain amount of texture, but if you find the car on top of it, it's very unlikely to be water, and if you find the boat on it is very unlikely to be road, and so the object model can inform the regions and vice versa, and you get from this holistic model much better results than you get.",
                    "label": 0
                },
                {
                    "sent": "By thinking about each piece of the image.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Isolation.",
                    "label": 0
                },
                {
                    "sent": "Phone is showing again some examples.",
                    "label": 0
                },
                {
                    "sent": "This is a typical sliding window detector results and I'm showing you the talk to detections per image.",
                    "label": 1
                },
                {
                    "sent": "So here are the top two highest confidence people in this image.",
                    "label": 0
                },
                {
                    "sent": "One is indeed over there, but the other ones over there.",
                    "label": 1
                },
                {
                    "sent": "These are the top two car detections.",
                    "label": 0
                },
                {
                    "sent": "It's missed the real car entirely and put both cars over there.",
                    "label": 0
                },
                {
                    "sent": "Now to be fair, the third detection really is that car but still and for some reason that's a cow.",
                    "label": 0
                },
                {
                    "sent": "OK, our model which has a much deeper knowledge of context, understanding of contexts not only correctly outlined the one and only person in the scene and correctly more or less outline the only car visible in the scene, but also missed the cow that doesn't exist.",
                    "label": 0
                },
                {
                    "sent": "That's good.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now again coming up with more quantitative results, here are several different graphs.",
                    "label": 0
                },
                {
                    "sent": "This is the baseline object detection.",
                    "label": 0
                },
                {
                    "sent": "This is precision.",
                    "label": 0
                },
                {
                    "sent": "This is recall, so standard curves the baseline sliding window detector for all three of these object classes.",
                    "label": 0
                },
                {
                    "sent": "The blue is a region based model and the red is what we would do.",
                    "label": 0
                },
                {
                    "sent": "How well we could perform if we had perfect segmentation of the image into regions, which of course we don't.",
                    "label": 0
                },
                {
                    "sent": "But it kind of gives you a sense of how well we could perform.",
                    "label": 0
                },
                {
                    "sent": "So what we can see is that we get significant improvements in precision by considering regions and contexts.",
                    "label": 1
                },
                {
                    "sent": "And if we have.",
                    "label": 0
                },
                {
                    "sent": "OK, I'm going to have to never mind.",
                    "label": 0
                },
                {
                    "sent": "But if we had, we could get near perfect detection, but but we don't, and so there's still obviously a way to go between.",
                    "label": 1
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The red line.",
                    "label": 0
                },
                {
                    "sent": "So now getting back to latent variables.",
                    "label": 0
                },
                {
                    "sent": "Here we basically didn't, didn't assume latent variables.",
                    "label": 0
                },
                {
                    "sent": "We assume that our training data was fully supervised.",
                    "label": 0
                },
                {
                    "sent": "But now let's think about what that means.",
                    "label": 0
                },
                {
                    "sent": "What is a person give us when labeling regions in an image which we did by obviously by Amazon Mechanical Turk?",
                    "label": 0
                },
                {
                    "sent": "So this would be the ground truth label for the car object.",
                    "label": 0
                },
                {
                    "sent": "And here is another ground truth label for this car.",
                    "label": 0
                },
                {
                    "sent": "And for this tree, and so on.",
                    "label": 0
                },
                {
                    "sent": "And then when you think about it, you realize that you know cars.",
                    "label": 0
                },
                {
                    "sent": "A car isn't a single homogeneous region in terms of appearance, or for that matter, neither is it.",
                    "label": 0
                },
                {
                    "sent": "Tree nor person, and so that the fact is that human specified regions are not the most discriminative necessarily from the perspective of computer vision algorithm.",
                    "label": 1
                },
                {
                    "sent": "So what would happen if instead of having giving it ground from labels, we will let the human who would let the computer rather pick for itself?",
                    "label": 0
                },
                {
                    "sent": "What are the late?",
                    "label": 0
                },
                {
                    "sent": "What are the regions the pixel to region assignments that are most discriminative for its own purposes?",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here we learn, we train the model again with latent variables in coding these correspondences and what you get is a consistent improvement across all object classes with the most or almost all of the classes with the single most significant improvement being on the foreground class, which is the one we would expect there to be a biggest room for improvement.",
                    "label": 0
                },
                {
                    "sent": "So that's kind of so.",
                    "label": 0
                },
                {
                    "sent": "That's kind of a pleasing result that again choose letting the algorithm to this only thing variables is a good thing, which of course let us to be much more ambitious if we can do.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That let's really tackle multiclass segmentation in the broadest sense of the word.",
                    "label": 1
                },
                {
                    "sent": "So now let's have not five or six or ten object classes, but let's have 30 object classes that really pretty, much ultimately 100 or 1000 object classes, but not yet, but really basically label each pixel in the scene is corresponding to real semantic class.",
                    "label": 0
                },
                {
                    "sent": "So here we would like from this input to basically label this entire set of pixels as an airplane.",
                    "label": 0
                },
                {
                    "sent": "This is a person ground, Rd, and so on.",
                    "label": 0
                },
                {
                    "sent": "Sky so great, but do we have?",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Label training data for this.",
                    "label": 0
                },
                {
                    "sent": "Well, we don't.",
                    "label": 0
                },
                {
                    "sent": "We have various bits and pieces, so we have fully supervised foreground data from something like Pascal VOC, which is a standard computer vision data set were they have kindly labeled for us the labels for all foreground regions, but the background is left as generic background and we saw how important it is to have labeled background in terms of the interplay between background and foreground.",
                    "label": 1
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The data set that we constructed, now known as the Stanford background data set has fully specified background classes, but the foreground are labeled as generic foreground, so we don't have a data set that has both at the moment.",
                    "label": 1
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "Certainly we could construct one.",
                    "label": 0
                },
                {
                    "sent": "We could put this all on Amazon Mechanical Turk and get that amount of fully supervised label training data, but that would be kind of mean missing the point, because in a day.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And to all these datasets, we also have thousands of images that are labeled at the level of bounding boxes.",
                    "label": 1
                },
                {
                    "sent": "Um, we're somebody only tells us that this is.",
                    "label": 0
                },
                {
                    "sent": "This box contains a bus, and this one contains a car, but it doesn't give us a pixel level annotation, and it would be fairly expensive and time consuming to label all of these thousands of the level of the individual pixels.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Not to mention the millions of images that exist on Flickr image net, Google images and so on, where we're the only label this given is car and you don't even know the bounding box of the car in the image.",
                    "label": 0
                },
                {
                    "sent": "Certainly we don't want to label those at the level of individual pixels.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that again calls out for, so we'd like to use all of these images in training the kinds of models that we're talking about, and that immediately calls out again.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The use of latent variables.",
                    "label": 0
                },
                {
                    "sent": "So how would we formulate this as a latent variable model?",
                    "label": 1
                },
                {
                    "sent": "Well, some of this is fairly straightforward.",
                    "label": 0
                },
                {
                    "sent": "So for example, if we have a an image that's only labeled correctly at the label at the level of foreground, so we know the annotation of the foreground object.",
                    "label": 0
                },
                {
                    "sent": "But we don't know the class label of the of the background classes and so.",
                    "label": 0
                },
                {
                    "sent": "And so.",
                    "label": 0
                },
                {
                    "sent": "My computer is stuck.",
                    "label": 0
                },
                {
                    "sent": "OK, and so we have now a latent variable that actually has two components.",
                    "label": 0
                },
                {
                    "sent": "First, as the assignment of region pixels to regions, which is, which is the one we had previously.",
                    "label": 0
                },
                {
                    "sent": "But we also have latent variables that tell us how the background is assigned to appropriate classes, and that's something that we need the algorithm to infer during training, because that's not labeled your own training.",
                    "label": 0
                },
                {
                    "sent": "But we so we think we have a labeling that says it's specific classes in the background must agree with the fact that is.",
                    "label": 1
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And similarly.",
                    "label": 0
                },
                {
                    "sent": "Similarly for the other.",
                    "label": 0
                },
                {
                    "sent": "For the background case, what about bounding boxes?",
                    "label": 0
                },
                {
                    "sent": "Say we only have we have an image accent Ry says.",
                    "label": 0
                },
                {
                    "sent": "Here is a cow somewhere within this bounding box.",
                    "label": 0
                },
                {
                    "sent": "Again, the latent variables tell us the partition into regions as well as the detailed segmentation of the image, and we have a constraint now on the bounding box assignment that says every row and every column in the bounding box must contain a pixel labeled with the bounding box class, because otherwise they would have made the bounding box maybe smaller.",
                    "label": 1
                },
                {
                    "sent": "So this is a constraint on latent variables.",
                    "label": 0
                },
                {
                    "sent": "That we need in order to make use of these very weakly labeled.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then finally going towards the most weakly labeled instances that you might find on on Flickr image net.",
                    "label": 0
                },
                {
                    "sent": "Here the images is XY, just says cow somewhere in there and again the latent variables are the same and we have a constraint that somewhere in the image there needs to be a region that's labeled with cow in this case.",
                    "label": 0
                },
                {
                    "sent": "So great, we now have a latent variable formulation.",
                    "label": 1
                },
                {
                    "sent": "We applied our greatest and best latent variable.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Learning method and.",
                    "label": 0
                },
                {
                    "sent": "Basically we got a zero point 7% improvement by including all of those images in the data.",
                    "label": 0
                },
                {
                    "sent": "Well, OK, that's on the background data set.",
                    "label": 0
                },
                {
                    "sent": "Maybe on Pascal, which is a foreground data set.",
                    "label": 0
                },
                {
                    "sent": "We're going to do better.",
                    "label": 0
                },
                {
                    "sent": "Well, no, actually not.",
                    "label": 0
                },
                {
                    "sent": "We did worse.",
                    "label": 0
                },
                {
                    "sent": "In fact, here there's absolutely no improvement by using all of these weakly labeled images in in our current classification problem.",
                    "label": 0
                },
                {
                    "sent": "And the problem is so basically using this large amount of weakly labeled data provides only marginal improvement, if any.",
                    "label": 1
                },
                {
                    "sent": "And the reason for that is that inputing latent variables is hard, that is, to come up with this with what these latent variables ought to be is a challenging problem, and can introduce enough noise that it outweighs the benefit of having so.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Much more data.",
                    "label": 0
                },
                {
                    "sent": "Which brings me to the second part of my talk, which talks about learning latent variable models and the specific idea of self paced learning or having the algorithm pace itself in computing latent variables.",
                    "label": 0
                },
                {
                    "sent": "And I'm going to talk about two different examples of this, one at the level of instances and one at the level of model.",
                    "label": 0
                },
                {
                    "sent": "And this is work that was really led by my post doctoral on Kumar in my PC.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let me take a short digression into Max margin training, which is a topic that I'm sure many of you are familiar with.",
                    "label": 0
                },
                {
                    "sent": "So go through it fairly quickly, so this is the the grammar and finger extension of binary support vector machines to the multiclass setting.",
                    "label": 0
                },
                {
                    "sent": "So just as a reminder, we are still in the case where we're trying to find we're labeling.",
                    "label": 0
                },
                {
                    "sent": "Why by optimizing an energy function which is a dot product of weights and the feature vector and the Max margin.",
                    "label": 0
                },
                {
                    "sent": "Formulation which is a straight generalization of the standard SVM criterion, basically has the following pieces.",
                    "label": 0
                },
                {
                    "sent": "We're trying to minimize the norm of the weights, and I'm hoping this is familiar to most people here, which is why it's going to be pretty quick.",
                    "label": 0
                },
                {
                    "sent": "Some of the weights plus a weighted sum of the of the slacks and so subject to the constraint that the weight of the ground truth label, while I for the I TH instance is not only greater than the than the score of any other label for that instance, but also greater by a certain margins.",
                    "label": 0
                },
                {
                    "sent": "This is why it's called Max margin classification and the slap basically is my ability to say, well, I can't label this instance correctly within the margin, so I'm going to allow myself not to do that correctly, but I'm going to have to pay for it.",
                    "label": 0
                },
                {
                    "sent": "Objective function, so this is exactly the same as the two class formulation, except that I have for all Y here for all of the other possible labels for the for the instance X.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now in 2000 and three 2004, this framework of multi class SVM was extended first by my student Ben Tasker and Carlos Guestrin and subsequently by by forcing welcomes group to the notion of structured outputs.",
                    "label": 0
                },
                {
                    "sent": "Where why isn't just a set of labels 1234, but rather an entire multi dimensional vector giving rise to potentially exponentially many labels.",
                    "label": 0
                },
                {
                    "sent": "So why for example can be the entire segmentation?",
                    "label": 0
                },
                {
                    "sent": "Avacyn, assigning each pixel to a class, in which case we have number which is exponential in number of number of labels, which is exponential number of pixels in the scene.",
                    "label": 0
                },
                {
                    "sent": "So other than that, the formulation is actually fairly similar other than turning why from a from just an ordinal to a vector, we now have exactly the same formulation.",
                    "label": 0
                },
                {
                    "sent": "The only other changes that the margin now can depend is not just the 01 loss given.",
                    "label": 0
                },
                {
                    "sent": "Did you label this as the correct class or not?",
                    "label": 0
                },
                {
                    "sent": "But then actually depend on some notion of distance between the ground truth in the alternative labeling so that you might choose, for example, to penalize Lessa segmentation that.",
                    "label": 0
                },
                {
                    "sent": "Just a couple of pixels oph relative to penalising a segmentation that's you know has half the image labeled incorrectly, so you can have a loss dependent margin that allows different instances to requite allows you to require different levels of margin from different instances.",
                    "label": 0
                },
                {
                    "sent": "Depending on just how wrong they are.",
                    "label": 0
                },
                {
                    "sent": "So this was a nice nice formulation.",
                    "label": 0
                },
                {
                    "sent": "It by itself is not is not a huge leap because you just basically changed the space of lies.",
                    "label": 0
                },
                {
                    "sent": "The real issue of course is that this has exponentially many constraints because we have a constraint that specifies the margin for every single possible labeling wine.",
                    "label": 1
                },
                {
                    "sent": "As I just told you, there's exponentially many of those.",
                    "label": 0
                },
                {
                    "sent": "So how does one deal with that?",
                    "label": 0
                },
                {
                    "sent": "Well, these two papers presented two different methods are.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Paper in 2003 basically made the observation that for models that are tractable in a certain sense, basically ones that look like a tractable graphical model, admit a polynomial size formulation that is exact as a quadratic program.",
                    "label": 0
                },
                {
                    "sent": "So you could actually solve it using exactly the same kinds of techniques that you would solve any other support vector machine.",
                    "label": 0
                },
                {
                    "sent": "In the subsequent paper, by forcing your Kings group, they came up with a more general approach that also is in easier to implement, which uses cutting planes so that instead of constructing a single QP, basically add constraints one at a time and that has a lot of elegant properties.",
                    "label": 0
                },
                {
                    "sent": "Specifically, it often requires only map inference relative to this graphical model so that it admits algorithms that are much more tractable and don't require that we compute the partition function or run full scale probabilistic inference.",
                    "label": 1
                },
                {
                    "sent": "And they actually showed using very nice proof that for many models only polynomial number of cutting planes is required for close to optimal learning, which means that by generating enough bad solutions in this problem, if you generate a polynomial number of those you've converged to something that is actually correct.",
                    "label": 1
                },
                {
                    "sent": "Are close to correct, so that was a big development in this whole technology is now used really ubiquitously in computer vision as well as in other areas, including natural language and others.",
                    "label": 0
                },
                {
                    "sent": "For learning structured models using a Max margin form.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In 2008, 2009, this framework was first extended to the case of latent variables.",
                    "label": 0
                },
                {
                    "sent": "So the latent SVM model, which was first proposed by Felzenszwalb, McAllister and Ramanan, basically the energy function, just like in the first few slides that I showed, was extended by introducing a latent variable, and that gave rise to the following formulation.",
                    "label": 0
                },
                {
                    "sent": "That looks exactly like the previous one that we showed before, except that these additional latent variables are entered into the into the energy function.",
                    "label": 0
                },
                {
                    "sent": "And what basically gets what basically happens is that these have to be imputed in the case of the ground truth annotation.",
                    "label": 0
                },
                {
                    "sent": "So the best imputation of H, which is this Max over the hi.",
                    "label": 0
                },
                {
                    "sent": "So the best imputation of the best completion of the hidden variables that's consistent with my ground truth label needs to be better by the margin than any other imputation.",
                    "label": 1
                },
                {
                    "sent": "For any other label.",
                    "label": 0
                },
                {
                    "sent": "So this is sort of the thing that I would most pick this consistent with my ground truth.",
                    "label": 1
                },
                {
                    "sent": "Has to be better than anything else.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, and so, um, these two papers came up with an algorithm called SCCP which has the following structure.",
                    "label": 0
                },
                {
                    "sent": "It starts with an initial estimate of the parameters and then it imputes the latent variables using those current parameters.",
                    "label": 1
                },
                {
                    "sent": "And that's again, then using map inference, whilst the latent variables are imputed, this turns back into a standard.",
                    "label": 0
                },
                {
                    "sent": "Under Dassem and that you can solve using your standard techniques and then the process repeats.",
                    "label": 0
                },
                {
                    "sent": "Because you now have better parameters, so you can think of it as kind of like expectation maximization or kind of like or variant of coordinate descent.",
                    "label": 0
                },
                {
                    "sent": "So fairly straightforward method for dealing with latent variables, which I'm sure all of you have seen before in different contexts.",
                    "label": 0
                },
                {
                    "sent": "And you can prove that this converges to a local optimum of this objective function.",
                    "label": 1
                },
                {
                    "sent": "But the critical question is how well can you impute.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi.",
                    "label": 0
                },
                {
                    "sent": "So let's look at some examples in the context that I showed before.",
                    "label": 0
                },
                {
                    "sent": "So here is 1 example.",
                    "label": 0
                },
                {
                    "sent": "Remember, we don't have the background information here, so let's see how we can compute it.",
                    "label": 0
                },
                {
                    "sent": "Well, here the Sky is white, the grass is green, the road is Gray.",
                    "label": 0
                },
                {
                    "sent": "Basically any half Lane algorithm can impute those pretty correctly, and the answer is it does, so this isn't.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Easy example.",
                    "label": 0
                },
                {
                    "sent": "Here's another good one.",
                    "label": 0
                },
                {
                    "sent": "The Sky is white or kind of grayish.",
                    "label": 0
                },
                {
                    "sent": "The grass is green, the water is blue.",
                    "label": 0
                },
                {
                    "sent": "Imputation works great.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately, not all images are create.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Equal here is a different one.",
                    "label": 0
                },
                {
                    "sent": "Here you're trying to impute the foreground, which is immediately much harder.",
                    "label": 0
                },
                {
                    "sent": "Problem is this a cow.",
                    "label": 0
                },
                {
                    "sent": "A horse.",
                    "label": 0
                },
                {
                    "sent": "Cat.",
                    "label": 0
                },
                {
                    "sent": "Remember, the algorithm doesn't hasn't been trained yet.",
                    "label": 0
                },
                {
                    "sent": "It doesn't really know What Car what cows look like and how they differ from horses.",
                    "label": 0
                },
                {
                    "sent": "And sure enough, if you try and impute this, you get this unholy mess that I think is half sheep.",
                    "label": 0
                },
                {
                    "sent": "Half something half how I think it's some.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So our mix.",
                    "label": 0
                },
                {
                    "sent": "Here's another one.",
                    "label": 0
                },
                {
                    "sent": "Well, this one is a pretty nasty one.",
                    "label": 0
                },
                {
                    "sent": "The Sky is red.",
                    "label": 0
                },
                {
                    "sent": "The mountains black and sure enough, if you try and impute this you basically end up with some completely ridiculous imputation once again.",
                    "label": 0
                },
                {
                    "sent": "So not only.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is are the same.",
                    "label": 0
                },
                {
                    "sent": "So now we were inspired by going back to human learning, and let's imagine that we were trying to teach this kid math and we said all of what we know into one in one session.",
                    "label": 0
                },
                {
                    "sent": "It's not going to go over really well.",
                    "label": 0
                },
                {
                    "sent": "So what happens if rather we teach them?",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "He should the way we teach, or ought to be, teaching children by doing things one stage at a time.",
                    "label": 0
                },
                {
                    "sent": "That works a little bit better, so why don't we try?",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You do the same with our algorithm.",
                    "label": 0
                },
                {
                    "sent": "Start with easy examples and then consider hard ones.",
                    "label": 1
                },
                {
                    "sent": "And this is an actually an idea that was proposed contemporaneously with our work by Yoshua Bengio at all I see Mail 2009 and.",
                    "label": 0
                },
                {
                    "sent": "It says let's label some images is easy, others are hard, and then trying train the model on the easy examples first, then only then start to impute the hard work.",
                    "label": 0
                },
                {
                    "sent": "The problem is that easy for humans is not the same as easy for computers and this is the case that I've been making throughout this talk.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we have easiness is not some objective thing that you can determine in advance the property of datasets and it's a property with classifier you're using.",
                    "label": 0
                },
                {
                    "sent": "You can't look at an instance and in isolation say whether it's easy or hard and that the computer who has a much better sense of what's easy and hard for it should figure out for itself.",
                    "label": 0
                },
                {
                    "sent": "With instances are hard for it right now in the current stage of the algorithm.",
                    "label": 1
                },
                {
                    "sent": "So with this intuition in mind, we came up with an algorithm called self paced learning, which this is the original.",
                    "label": 0
                },
                {
                    "sent": "The original SCCP algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We basically we now all.",
                    "label": 0
                },
                {
                    "sent": "We now add a set of variables VI which are 01 labels and we only count and basically VI means if you guys want it says the instance is included in the current learning iteration.",
                    "label": 0
                },
                {
                    "sent": "VI Zero, it says that it's not included and you can see that by the fact that VI multiplies the stock.",
                    "label": 0
                },
                {
                    "sent": "So you don't pay any penalty for getting unincluded instances wrong.",
                    "label": 0
                },
                {
                    "sent": "So so basically the example is easy.",
                    "label": 0
                },
                {
                    "sent": "I should include it, and if it's hard then I should know that by itself you know gives the algorithm all the incentives just label everything is hard and say my work is done so obviously want to penalize it for choosing not to label instances and so we add an additional penalty term for all of the instances that it chose not to label.",
                    "label": 0
                },
                {
                    "sent": "And then that forces it, or to choose some of the hard examples to label eventually and we're going to anneal this factor K. To eventually force it to label all of the examples.",
                    "label": 0
                },
                {
                    "sent": "Now, in order to solve this, we relax this to A to a set of continuous variables, another in the interval 01, and then it turns out that it's a BI convex optimization, which can be solved efficiently using alternate convex search, and I'm not going to.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Other details, so now the algorithm says start with an initial estimate W 0.",
                    "label": 1
                },
                {
                    "sent": "Impute the latent variables.",
                    "label": 0
                },
                {
                    "sent": "Update WT plus one by solving this biconvex problem and then having done that, I'm going to hopefully have a better model, so I'm going to decrease going to new my penalty so that I'm forcing the algorithm to include more instances.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's look at what that does.",
                    "label": 0
                },
                {
                    "sent": "This isn't a simple illustration of a 01 of a binary classification problem.",
                    "label": 0
                },
                {
                    "sent": "Initially at the early stages, K is large.",
                    "label": 0
                },
                {
                    "sent": "I don't really care if I use, don't use so many instances so it's only going to choose to label instances that are far from the decision boundary.",
                    "label": 0
                },
                {
                    "sent": "As the algorithm progresses, the penalty becomes larger and so eventually I'm going to move to the regime where I have to label everything, including if it's confusing, but hopefully by this point my parameters are good enough that my imputation for the latent variables.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Pretty reliable, so let me demonstrate this on an example because I think visually is going to become very clear and I'm going to use a much simpler example.",
                    "label": 0
                },
                {
                    "sent": "The one of you so far.",
                    "label": 0
                },
                {
                    "sent": "This is a standard example of object detection.",
                    "label": 1
                },
                {
                    "sent": "The input X is an image, the output wise.",
                    "label": 0
                },
                {
                    "sent": "A class label, which in this case is one of six mammal groups, were doing a simple 01 loss, and the latent variable is the bounding box where the object is going to be found.",
                    "label": 0
                },
                {
                    "sent": "Given a bounding box, I can now apply any of my favorite learning algorithms that do bounding box detection.",
                    "label": 0
                },
                {
                    "sent": "So for example, we could use a standard so-called hog detector.",
                    "label": 0
                },
                {
                    "sent": "For those of you have heard the term, but any any algorithm that detects the classified bounding boxes can be used in this setting.",
                    "label": 0
                },
                {
                    "sent": "The problem, of course, is that we don't know rhat is latent using the training.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's look at some examples.",
                    "label": 0
                },
                {
                    "sent": "This is the iterations of the algorithm of blue on the left of the CCP algorithm, which is the one that that was there before.",
                    "label": 0
                },
                {
                    "sent": "And this is the self paced learning variance.",
                    "label": 0
                },
                {
                    "sent": "And what you see here is blue if the if the example is used in training in red.",
                    "label": 0
                },
                {
                    "sent": "If it's not, and remember whether it's used or not as the decision of the algorithm makes, so CCP doesn't get a choice, it has to use all of the all of the images, which is why the bounding boxes here all blue.",
                    "label": 0
                },
                {
                    "sent": "But you'll notice that an iteration one the inferred bounding boxes.",
                    "label": 0
                },
                {
                    "sent": "That the algorithm chose not to use are almost invariably wrong.",
                    "label": 0
                },
                {
                    "sent": "Where is the one that it shows yes to use are almost invariably.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is iteration 5.",
                    "label": 0
                },
                {
                    "sent": "The bounding box is changed a little bit, but it's still not sufficiently confident about these, even though this one's pretty cool.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right, but by iteration mine it nailed both of these mounting boxes and in fact chose to use them, whereas this one is still not sufficiently confident.",
                    "label": 0
                },
                {
                    "sent": "And in fact it's still a little bit.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But by iteration 13, it's basically imputed the hidden variables correctly and chosen to use.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "All the examples.",
                    "label": 0
                },
                {
                    "sent": "So quantitatively, this is my object detection baseline task.",
                    "label": 1
                },
                {
                    "sent": "What we see here is the test error for SCCP versus self paced learning and we see a healthy improvement in of 1.5% in in the test error.",
                    "label": 1
                },
                {
                    "sent": "We applied this to actually four different very very distinct problems that involve latent variables.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to show you all four of them just going to show you one more to demonstrate the generality of this of this algorithm.",
                    "label": 0
                },
                {
                    "sent": "So this is finding DNA motifs where you know that a protein bound to a particular region of the DNA but don't know exactly.",
                    "label": 0
                },
                {
                    "sent": "Word bound and you'd like to identify the motif that allowed the protein to bind to the DNA.",
                    "label": 0
                },
                {
                    "sent": "So here X is the sequence Y is bind Ng bind and H is the multi position.",
                    "label": 0
                },
                {
                    "sent": "And again we see a very healthy improvement of about 5% in test area.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then finally, these are results that arrive yesterday.",
                    "label": 0
                },
                {
                    "sent": "This is of some initial results on the Pascal VLC challenge and this is accuracy as opposed to error, so higher is better.",
                    "label": 0
                },
                {
                    "sent": "And again we can see healthy improvements both in test accuracy and an average precision, which is a metric that's often used in computer vision.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so now let's go back to our diverse data learning and the whole image segmentation thing that started out this this whole discussion.",
                    "label": 0
                },
                {
                    "sent": "So here's an example.",
                    "label": 0
                },
                {
                    "sent": "Input image.",
                    "label": 0
                },
                {
                    "sent": "Here is the in Ferd labels from the from the original algorithm that we started out with and here and notice that it's labeled.",
                    "label": 0
                },
                {
                    "sent": "All of this I think is grass and that's role and hear the inferred labels are considerably better.",
                    "label": 0
                },
                {
                    "sent": "And again that translates to significant improvements in performance.",
                    "label": 0
                },
                {
                    "sent": "Across all different classes for both the Stanford background data set and for the Pascal DLC data set.",
                    "label": 0
                },
                {
                    "sent": "So some classes are a little bit worse, but almost all classes are considerably better.",
                    "label": 0
                },
                {
                    "sent": "Which shows that if you train your algorithm correctly.",
                    "label": 0
                },
                {
                    "sent": "Computing the hidden variables carefully, then you can make good use even a very weakly annotated data.",
                    "label": 1
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The final piece of this is a very new work.",
                    "label": 0
                },
                {
                    "sent": "It's actually still under review, which tries to take this intuition as in.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Get a different, slightly different direction, which is the question of model selection, which is one that I'm sure that all of you have ever applied machine learning have faced of OK.",
                    "label": 0
                },
                {
                    "sent": "Which classifier should I use?",
                    "label": 1
                },
                {
                    "sent": "And specifically, for example, which kernels should I use that he's a linear kernel?",
                    "label": 0
                },
                {
                    "sent": "A cubic kernel quit the kernel?",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's go back to the human learning motivation and let's again take some do this kind of as a simple example, imagine when somebody asks you to teach them physics.",
                    "label": 0
                },
                {
                    "sent": "You start out with a very complicated model.",
                    "label": 0
                },
                {
                    "sent": "The general theory of relativity.",
                    "label": 1
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Rob.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Very successful.",
                    "label": 0
                },
                {
                    "sent": "But what about if we start with a?",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Simple model.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then a slightly more complicated.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "1.",
                    "label": 0
                },
                {
                    "sent": "And then the most complicated one.",
                    "label": 0
                },
                {
                    "sent": "Maybe that's going to work better so.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let's see if that applies to computers, so here are our three, three kernels of increasing complexity, and we're going to rely on the theory of multiple kernel learning, which was proposed by Bocklin creator Jordan in 2004, and what that says is we're going to use a weighted average of different kernels.",
                    "label": 1
                },
                {
                    "sent": "So here we have the different kernels side one side 2 and so on, and there's a bunch of coefficients that wait with.",
                    "label": 0
                },
                {
                    "sent": "What way do you want to include each of them?",
                    "label": 0
                },
                {
                    "sent": "And So what we have is actually, like, really, really, really long kernel.",
                    "label": 0
                },
                {
                    "sent": "That is, the aggregate of all of these different pieces of kernels.",
                    "label": 0
                },
                {
                    "sent": "And so you can think of the kernel as a weighted combination was called the conic combination of the different of the diff.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sub kernels, and then how does one do multiple kernel learning?",
                    "label": 1
                },
                {
                    "sent": "Well, you basically put this big big kernel into the matrix and you optimize simultaneously, not only over the weights of the learner and the slacks but also over the weights of the different kernels so that you try and pick the kernels.",
                    "label": 0
                },
                {
                    "sent": "That gives you the best loss on your training set.",
                    "label": 0
                },
                {
                    "sent": "Well, that's great, except that if you actually optimize this objective as written, it encourages the most complex kernel because the most complex kernel fits best to give me the lowest slacks it's going to.",
                    "label": 0
                },
                {
                    "sent": "It's going to give the best classification performance on the training data, and so if I try and optimize two training performance, I'm going to.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Profit.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "What we're going to do is we're going to introduce into this a penalty on model complexity and the specific model complexity that we're going to use is what's called the Rademacher complexity.",
                    "label": 0
                },
                {
                    "sent": "It's a way of measuring the complexity of a kernel, and so we're going to learn in a way that encourages the algorithm to pick simpler models.",
                    "label": 0
                },
                {
                    "sent": "And now let's think about what that does in the context of latent.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Labeling.",
                    "label": 0
                },
                {
                    "sent": "All.",
                    "label": 0
                },
                {
                    "sent": "So we start with an initial estimate.",
                    "label": 1
                },
                {
                    "sent": "And we're going to use that to impute.",
                    "label": 0
                },
                {
                    "sent": "The um, latent variables, and then we're going to go and update both the weights and the kernel weights by solving this convex problem, and then we repeat.",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's see.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Think about what this algorithm, which is we call self paced multiple kernel learning or known to its friends as spam.",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here is the spam kill behavior.",
                    "label": 0
                },
                {
                    "sent": "What happens in early iterations?",
                    "label": 0
                },
                {
                    "sent": "In early iterations the hi's are almost invariably incorrectly imputed.",
                    "label": 1
                },
                {
                    "sent": "Which means that the cyyz are going to be large even for complex kernels because even for complex kernels, if the bounding boxes right, you can't get things correct, because it's effectively a random prediction problem.",
                    "label": 1
                },
                {
                    "sent": "And at that point the algorithm tries to optimize for this complexity term and therefore it's going to prefer simple kernels.",
                    "label": 0
                },
                {
                    "sent": "Which are going to not overfit.",
                    "label": 0
                }
            ]
        },
        "clip_80": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Dana in later iterations the hi's are more likely to be correctly imputed, which means that society is going to be small for the correct kernel and then hopefully you're going to prefer the more complex kernels so that you can minimize the total sum of the slacks.",
                    "label": 0
                },
                {
                    "sent": "So let me show you that that and know that this behavior happens without ever kneeling the term Lambda, which represents the strength of this term.",
                    "label": 0
                }
            ]
        },
        "clip_81": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let me show you that this actually works in practice.",
                    "label": 0
                },
                {
                    "sent": "This is exactly an example of the balance of the imputed bounding boxes relative to cubic kernel, which is the one that performs best on this data set.",
                    "label": 0
                },
                {
                    "sent": "And so here is just a plain cubic kernel and the system fill.",
                    "label": 0
                },
                {
                    "sent": "This is iteration one, it's the same, it's the same because they both start out in the same place.",
                    "label": 0
                }
            ]
        },
        "clip_82": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "By iteration 3.",
                    "label": 0
                }
            ]
        },
        "clip_83": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Spam Kill has moved many of the bounding boxes to the correct place.",
                    "label": 0
                },
                {
                    "sent": "We don't.",
                    "label": 0
                }
            ]
        },
        "clip_84": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If any improvements for the cubic kernel, because basically it's over fit to this particular set of incorrectly computed bounding boxes.",
                    "label": 0
                },
                {
                    "sent": "Now stuck and can't.",
                    "label": 0
                }
            ]
        },
        "clip_85": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Iteration 6 we've now nailed.",
                    "label": 1
                },
                {
                    "sent": "That one as well.",
                    "label": 0
                },
                {
                    "sent": "This still doesn't know very.",
                    "label": 0
                }
            ]
        },
        "clip_86": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Not.",
                    "label": 0
                },
                {
                    "sent": "Here, iterations and it moves that actually in the.",
                    "label": 0
                }
            ]
        },
        "clip_87": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Direction and basically have convergence Pamphile has nailed bounding boxes for all of these objects, whereas this one is still very far off because it overfit to the incurred.",
                    "label": 0
                }
            ]
        },
        "clip_88": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Tations so if you actually look at that quantitatively, what you see here is the behavior of linear, cubic, quintic, UU weighting of the kernels in spaniel, and we see that other than the linear kernel which performs pathetically all of them achieve affectively, 100% accuracy on the training data, and that's because they are over fitting.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, on the test data, the linear kernel still performs pathetically, but all of the other ones also performed not very well because they've overfit to the trading banophen incorrect imputations.",
                    "label": 0
                },
                {
                    "sent": "So the stronger kernels overfit.",
                    "label": 0
                },
                {
                    "sent": "The noise invitations get stuck at a local optimum where Spackle only uses the strong kernels.",
                    "label": 0
                },
                {
                    "sent": "When the imputations are accurate.",
                    "label": 0
                }
            ]
        },
        "clip_89": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Waiting this local optimum and if you want to see this even more quantitatively, this is the score of the overlap of the bounding boxes between the imputed bounding box and the ground truth bounding box, and what you see here is over iterations.",
                    "label": 0
                },
                {
                    "sent": "This score of how well these match up and you can see that the cubic kernel, which is the one that performed best, never achieves an average intersection of greater than 0.8, where Stanfield gets to 0.9, three or two or so.",
                    "label": 0
                }
            ]
        },
        "clip_90": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And again, to show you this is not a fluke for this data set, this is the DNA binding motif and you can see here the linear kernel actually performs better than these other guys, but spam kill performs significantly.",
                    "label": 0
                }
            ]
        },
        "clip_91": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So to summarize.",
                    "label": 0
                },
                {
                    "sent": "The first conclusion is the pixel level scene.",
                    "label": 0
                },
                {
                    "sent": "Understanding this is for the first part of the talk, enforces coherent coherence.",
                    "label": 0
                },
                {
                    "sent": "In the scene interpretation and consistency of context, so you don't get, for example, that this is a cow.",
                    "label": 0
                },
                {
                    "sent": "Which is what it was inferred to be.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "But on the other hand, if we want pixel level scene understanding that we need a heck of a lot more training data than we currently have, because pixel annotations are still very laborious even with all of the Amazon Mechanical Turk, and so we only have those in limited amounts.",
                    "label": 0
                },
                {
                    "sent": "And Furthermore, even if we can get somebody to label them the human annotations don't necessarily line up with what we do.",
                    "label": 0
                }
            ]
        },
        "clip_92": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Like to see.",
                    "label": 0
                },
                {
                    "sent": "So the second conclusion and this, I think, is a broad conclusion for machine learning in general, not just for computer vision, is that we need to come up with ways of making better use of training data.",
                    "label": 0
                },
                {
                    "sent": "We need to be able to use weekly label data.",
                    "label": 0
                },
                {
                    "sent": "We need to use diverse data that has different levels of annotations, including unsupervised data and so on.",
                    "label": 0
                },
                {
                    "sent": "But in order to do that, you need to be able to deal correctly with latent variables.",
                    "label": 0
                },
                {
                    "sent": "Because as soon as you have weak labeling, it means that implicitly or explicitly, there's a bunch of variables.",
                    "label": 0
                }
            ]
        },
        "clip_93": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Unlabeled in your training data.",
                    "label": 0
                },
                {
                    "sent": "And the third conclusion from the third part from the last part of the talk is that if you're training latent variable models, it's important not to jump too quickly.",
                    "label": 0
                },
                {
                    "sent": "Don't immediately force your algorithm to solve the hardest instances, or to use the richest model.",
                    "label": 0
                },
                {
                    "sent": "Rather, let the algorithm gradually adapt to increasing levels of complexity.",
                    "label": 1
                }
            ]
        },
        "clip_94": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let me prove I found this looking around.",
                    "label": 0
                },
                {
                    "sent": "I don't know how many of you are familiar with the Khan Academy, which is this really amazing resource on the web for teaching kids math.",
                    "label": 0
                },
                {
                    "sent": "This is an article from KQED that talks about the future of the school day for teaching children math as well as other topics, and it talks about the importance of self paced learning where every student works at his or her own pace.",
                    "label": 0
                },
                {
                    "sent": "Students, working groups and so on.",
                    "label": 0
                }
            ]
        },
        "clip_95": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what about if we have the following every algorithm working at his or her own pace?",
                    "label": 0
                },
                {
                    "sent": "Different kernels, working groups, and helping each other and the data set full of diverse weakly labeled instances that give algorithms practical knowledge and experience?",
                    "label": 0
                }
            ]
        },
        "clip_96": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let me conclude by thanking the people who did the work.",
                    "label": 0
                },
                {
                    "sent": "I've already mentioned all their names.",
                    "label": 0
                },
                {
                    "sent": "I won't read this again as well as my funding sources and thank you for your attention.",
                    "label": 0
                },
                {
                    "sent": "And I'm happy to take questions.",
                    "label": 0
                },
                {
                    "sent": "Well, Tom is getting a microphone so.",
                    "label": 0
                },
                {
                    "sent": "So I love to talk.",
                    "label": 0
                },
                {
                    "sent": "One question though is.",
                    "label": 0
                },
                {
                    "sent": "You needed to have a data set where some of the instances were actually easy.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "DNA data that you might not have such things, although I've never given up.",
                    "label": 0
                },
                {
                    "sent": "I guess that's a valid question.",
                    "label": 0
                },
                {
                    "sent": "What makes some DNA instances easier than others?",
                    "label": 0
                },
                {
                    "sent": "I think.",
                    "label": 0
                },
                {
                    "sent": "That's a really good question.",
                    "label": 0
                },
                {
                    "sent": "I think that's partially it's a question of how many almost motifs there are in the in the DNA surrounding the actual motif of whether it looks more like the random background distribution.",
                    "label": 0
                },
                {
                    "sent": "But you're right that if I have a data set where all instances are equally hard, this is likely this at least the as the self paced learning.",
                    "label": 0
                },
                {
                    "sent": "The first one is likely not to work.",
                    "label": 0
                },
                {
                    "sent": "Intuition why you didn't have to.",
                    "label": 0
                },
                {
                    "sent": "To the anneal the the Lambda parameter.",
                    "label": 0
                },
                {
                    "sent": "Sure, because then go back because it's close.",
                    "label": 0
                }
            ]
        },
        "clip_97": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in the early iterations, even with a fixed Lambda the hi's are going to be incorrectly imputed because the WS are just wrong and so the cyyz are going to be large no matter which currently used, because even the most complex curtain kernel can't fit the noise that well and so given that option of fairly large size, regardless of whether you use a simple kernel or complex kernel, the Rademacher complexity turn takes over and says well in that case, since I can't win on the.",
                    "label": 0
                },
                {
                    "sent": "On the accuracy anyway, may as well at least win on model complexity, whereas in later iterations as the HI is become more correctly imputed than using the simple kernels doesn't fit to them quite as well, and I'm going to use the most complex kernel that fits well the imputed labels, but even then I'm not going to necessarily.",
                    "label": 0
                },
                {
                    "sent": "We have graphs of that in the paper, even there it doesn't go all the way to quit the kernels.",
                    "label": 0
                },
                {
                    "sent": "At that point, it sort of stops where CU has most of the mouse because.",
                    "label": 0
                },
                {
                    "sent": "Because that's sort of the right tradeoff point where the size are about equally good and but you lose on the Rademacher complexity.",
                    "label": 0
                },
                {
                    "sent": "I have a question about the first part of the talk and the notion of clutter and working more in natural language and speech in speech recognition.",
                    "label": 0
                },
                {
                    "sent": "Actually, the lesson learned was the notion of culture is not good.",
                    "label": 0
                },
                {
                    "sent": "I mean right now the best speech recognition algorithms for this so called garbage models.",
                    "label": 0
                },
                {
                    "sent": "So they explicitly model every detail of the clutter in the sense that said nonspeech things like, you know, even cutting and so on on this explicitly model.",
                    "label": 0
                },
                {
                    "sent": "Now my question is.",
                    "label": 0
                },
                {
                    "sent": "Envision another expert.",
                    "label": 0
                },
                {
                    "sent": "Whether it's a good idea to really start with running Club in general, because what is clutter for one task may be non clutter for another one.",
                    "label": 0
                },
                {
                    "sent": "If you look at the picture from a different perspective, let's say you are looking at the traffic scene from Homeland Security perspective.",
                    "label": 0
                },
                {
                    "sent": "Some things which may be clutter in the normal classification is a session is essentially no clutter for the purpose we are looking at this picture and so on so.",
                    "label": 0
                },
                {
                    "sent": "That's my question.",
                    "label": 0
                },
                {
                    "sent": "I need a job.",
                    "label": 0
                },
                {
                    "sent": "The lesson from speech or about the notion of of you know, distinguishing clutter in one cluster is only another good boundaries between vision.",
                    "label": 0
                },
                {
                    "sent": "It's another case.",
                    "label": 0
                },
                {
                    "sent": "OK, so first I think the use of the word clutter, which we did not invent because we adopted it from the previous paper, was probably misleading in this regard.",
                    "label": 0
                },
                {
                    "sent": "We have no intention of throwing out the clutter.",
                    "label": 0
                },
                {
                    "sent": "In fact, the clutter is the furniture, and often some of the most interesting aspects of the scene are the are the so called clutter.",
                    "label": 0
                },
                {
                    "sent": "The reason it's clutter is because it clutters up your ability to detect the box, which is why they originally used the word clutter for that particular thing.",
                    "label": 0
                },
                {
                    "sent": "Now, the experience that people have in computer vision in general is very similar to what you're reporting from speech, which is the throwing away things that are not the thing that you're trying to detect is losing valuable information, which in this case would be contextual information about where the object is.",
                    "label": 0
                },
                {
                    "sent": "So specifically when people have done, for example, detection.",
                    "label": 0
                },
                {
                    "sent": "Sorry, object classification, you actually often do worse by focusing only on the bounding box of the object and removing any of the contextual information.",
                    "label": 0
                },
                {
                    "sent": "Nevertheless, identifying what where the object is versus where it's not is very valuable information for guiding the features of the of the algorithms so that you know to wait those differently, perhaps, and so that's what the latent variables are doing is they think this is where I think the object is and I should treat the feature inside this box differently from the features.",
                    "label": 0
                },
                {
                    "sent": "Outside this box, even if the ones outside this stuff are so informative, there informative in a different way.",
                    "label": 0
                },
                {
                    "sent": "So the experience is very similar to what you described and the word clutter here was just chosen because of the specifics of the application that that that that the original construction of the worker.",
                    "label": 0
                },
                {
                    "sent": "But it's a very good point, so thank you for asking them.",
                    "label": 0
                },
                {
                    "sent": "Question.",
                    "label": 0
                },
                {
                    "sent": "So let's take the speaker, yeah?",
                    "label": 0
                }
            ]
        }
    }
}