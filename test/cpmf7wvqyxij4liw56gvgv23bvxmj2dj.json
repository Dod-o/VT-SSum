{
    "id": "cpmf7wvqyxij4liw56gvgv23bvxmj2dj",
    "title": "From Bandits to Experts: On the Value of Side-Observations",
    "info": {
        "author": [
            "Ohad Shamir, Faculty of Mathematics and Computer Science, Weizmann Institute of Science"
        ],
        "published": "Sept. 6, 2012",
        "recorded": "December 2011",
        "category": [
            "Top->Computer Science->Machine Learning->On-line Learning"
        ]
    },
    "url": "http://videolectures.net/nips2011_shamir_observations/",
    "segmentation": [
        [
            "So I will work deals with the sequential decision setting, which has been very well studied in on."
        ],
        [
            "I'm learning, namely the problem of repeatedly choosing among K actions where the awards might change in an arbitrary way now to specific settings which have been very, very well studied in this context, is the expert setting, where we assume that after each round the learner gets to see the rewards of all the actions in the current round and the bandits for multi arm bandit setting where the learner just gets to see its own reward and basically what we do is that we introduce a more.",
            "General in UA model, which captures a whole spectrum of realistic learning problems between these two extremes, and actually subsumes both of them, namely that by picking action, the learner gets to see, beside his own reward, some sort of site information on some subset of the other actions.",
            "So this captures both the expert setting where no matter which action learning picks, it gets to see all the rewards bad in setting with just sees himself, but also everything in between, with possibly some.",
            "A complicated information feedback structure."
        ],
        [
            "And the motivation is to try and capture a problems in which we have some sort of structure between the actions.",
            "So, for instance, web advertising, we might have a two ads for a related things, say for similar luxury cars and with replace one ad we in the user comes and clicks on it.",
            "We also get some sort of facade information.",
            "What would have happened if you would have placed the other ads that maybe the user it would have been likely to click on it as well.",
            "I, on the other hand, if we have two ads targeted at completely disjoint market segments, and the user that clicks and one of them is unlikely to click on the other and vice versa, different kind of set of examples come from sensor in communication networks where if we pick a certain sensor or pick a certain channel to broadcast in, we often get some citing relation on what happens in adjacent sensors or nearby channels.",
            "Now this notion of structure we prove the actions is also been explored in previous works.",
            "But none of them really capture the information feedback in the same way that we do.",
            "So either it focus just on affinity and doesn't capture this similarity between the actions, or they make stochastic assumptions which we don't need to make here.",
            "So in our work we have quite a few."
        ],
        [
            "The results we present a new and efficient algorithms for this kind of setting.",
            "We provide the regret analysis, both upper and lower bounds, which it really capture.",
            "What property of the information feedback a quantified, the regret that you can get in there.",
            "Such cases.",
            "We have experiments and there are also quite a few open questions that are still left.",
            "So if you're interested, comes here poster to W 81, thanks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I will work deals with the sequential decision setting, which has been very well studied in on.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm learning, namely the problem of repeatedly choosing among K actions where the awards might change in an arbitrary way now to specific settings which have been very, very well studied in this context, is the expert setting, where we assume that after each round the learner gets to see the rewards of all the actions in the current round and the bandits for multi arm bandit setting where the learner just gets to see its own reward and basically what we do is that we introduce a more.",
                    "label": 0
                },
                {
                    "sent": "General in UA model, which captures a whole spectrum of realistic learning problems between these two extremes, and actually subsumes both of them, namely that by picking action, the learner gets to see, beside his own reward, some sort of site information on some subset of the other actions.",
                    "label": 1
                },
                {
                    "sent": "So this captures both the expert setting where no matter which action learning picks, it gets to see all the rewards bad in setting with just sees himself, but also everything in between, with possibly some.",
                    "label": 0
                },
                {
                    "sent": "A complicated information feedback structure.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the motivation is to try and capture a problems in which we have some sort of structure between the actions.",
                    "label": 1
                },
                {
                    "sent": "So, for instance, web advertising, we might have a two ads for a related things, say for similar luxury cars and with replace one ad we in the user comes and clicks on it.",
                    "label": 0
                },
                {
                    "sent": "We also get some sort of facade information.",
                    "label": 0
                },
                {
                    "sent": "What would have happened if you would have placed the other ads that maybe the user it would have been likely to click on it as well.",
                    "label": 0
                },
                {
                    "sent": "I, on the other hand, if we have two ads targeted at completely disjoint market segments, and the user that clicks and one of them is unlikely to click on the other and vice versa, different kind of set of examples come from sensor in communication networks where if we pick a certain sensor or pick a certain channel to broadcast in, we often get some citing relation on what happens in adjacent sensors or nearby channels.",
                    "label": 0
                },
                {
                    "sent": "Now this notion of structure we prove the actions is also been explored in previous works.",
                    "label": 0
                },
                {
                    "sent": "But none of them really capture the information feedback in the same way that we do.",
                    "label": 0
                },
                {
                    "sent": "So either it focus just on affinity and doesn't capture this similarity between the actions, or they make stochastic assumptions which we don't need to make here.",
                    "label": 0
                },
                {
                    "sent": "So in our work we have quite a few.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The results we present a new and efficient algorithms for this kind of setting.",
                    "label": 1
                },
                {
                    "sent": "We provide the regret analysis, both upper and lower bounds, which it really capture.",
                    "label": 1
                },
                {
                    "sent": "What property of the information feedback a quantified, the regret that you can get in there.",
                    "label": 0
                },
                {
                    "sent": "Such cases.",
                    "label": 0
                },
                {
                    "sent": "We have experiments and there are also quite a few open questions that are still left.",
                    "label": 0
                },
                {
                    "sent": "So if you're interested, comes here poster to W 81, thanks.",
                    "label": 0
                }
            ]
        }
    }
}