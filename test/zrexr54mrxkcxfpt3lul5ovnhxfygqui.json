{
    "id": "zrexr54mrxkcxfpt3lul5ovnhxfygqui",
    "title": "Pattern Analysis with Graphs and Trees",
    "info": {
        "author": [
            "Edwin Hancock, Department of Computer Science, University of York"
        ],
        "published": "Feb. 25, 2007",
        "recorded": "November 2005",
        "category": [
            "Top->Computer Science->Machine Learning->Pattern Recognition"
        ]
    },
    "url": "http://videolectures.net/aop05_hancock_pagt/",
    "segmentation": [
        [
            "Memory about the straight line.",
            "One thing is is construct something called struggling translation.",
            "Here what you do is divide each straight line into a number of sub segments.",
            "Length of the subset need subsegment is the distance.",
            "Play supply.",
            "The.",
            "6.7 century should be some settings, but what happens is that they will expand and manner which reflects the shape in the straight line.",
            "And then we take the.",
            "Triangulation of the sort of takes the incentive points of the image Regents arises construction recurring Bill Grubbs remember this directionality?",
            "Straight lines in the image."
        ],
        [
            "I want to deal with the full graph.",
            "You gotta simplify it right to bring back some of their structure, because this might be regarded as redundant.",
            "The two graphs of which can be computed will make graph which simplified the structure.",
            "Most of these is a paper graph paper as we do is use construct a circle on edge on each edge of graph.",
            "Then what we do is we check to see whether that circle contains another node.",
            "Instead of opening up the road, then you delete the page itself.",
            "So this is prunes away redundant adjacency relationships.",
            "Starting with sophisticated version of this is the neighborhood graph that is relative neighborhood graph is probably constructing a circle from the issue.",
            "You construct a mood, so that means if you have two circles."
        ],
        [
            "They sent it to you.",
            "Find edge.",
            "Look at the intersection of those two circles.",
            "Just finds his shady Blue Ridge in here and it's blooming contains a.",
            "Additional node then what we do is, we believe corresponding age.",
            "So that's why you are pulling back the edge structure through labor after simplifying cross structure."
        ],
        [
            "Recommendation I will talk about it.",
            "Is a shocker of?",
            "Shut up arises in skeletal representation shape, so here's a giraffe or regardless, with computer vision axis.",
            "Skeleton so every point on that maybe access.",
            "We could construct a circle is by tangent to the boundary of the object.",
            "So we choose a point we could construct every point on the skeleton so it just touches in by fashion way the battery.",
            "Now that's what we do is we can.",
            "We can move it on the skeleton and recall what happens to the radius that circle.",
            "So you can imagine the circle behavior and other displays if the library is tapering, then what happens is that the circle increases or decreases on the Franklin radius.",
            "If we have a construction.",
            "Then so probably come back here then what happens is the circle has a radius, has a local minimum.",
            "If we have a boundary of a beautiful width, then the greatest service constant, then finally we can have a little bulge on the boundary, in which case the radius of circle is locally maximum.",
            "And So what we can do is we can fulfill sampling into the radius of 500 circle as we travel along different instead of branches and that allows sensitive tribute.",
            "The skeleton in a manner which tells us something about the geometry of the boundary difference.",
            "With Jonathan Foundry, I'll come back to this representation made wrong because I should use it, provide data for one of my one of my examples."
        ],
        [
            "OK, so.",
            "That really finishing my 2 pieces of that sort of motivational right first will probably work, and Secondly setting up the picture of how graphs come about in computer vision.",
            "Now I want to do is to get started stuff into more technical aspects and talk to you little bit about how we could try to measure the similarity of graphs, particular how we can capture that similarity in a probabilistic way.",
            "So why don't we do it in the next?",
            "I guess 40 minutes or so, but it's talking about array in which we can model types of errors occur or variations occur in the grass.",
            "To measure these in a probabilistic manner to get developer problems, distribution, little caption."
        ],
        [
            "OK, so the starting point for this work is a.",
            "Motion.",
            "And it was published in family back in 1997."
        ],
        [
            "And the idea is as follows.",
            "Let's suppose we're trying to match two brothers.",
            "And this growth potentially have different numbers of nodes and edges.",
            "What we're trying to do is to mark at each node in one graph.",
            "You know the demographics in correspondence with it.",
            "So what can go wrong if we were trying to form this process?",
            "Well, first of all I don't know how to make the initial tests.",
            "Probably correspondences are going to have to somehow initializes process assigning correspondences nodes, and so they're going to at the outset of the process are going to be assignment errors.",
            "I'm going to displace.",
            "No correspondence is and what I'm going to do is trying really freaking figure placement of those motocross policies so that they.",
            "They satisfy age constraints.",
            "In practice, this may sound like cloud problem, but it's it's relatively easy capturing a number of different ways.",
            "In a sense of chocolate, if I'm trying to match the paragraphs, a structural errors and so, for instance, graphs on matching, they have different numbers of nodes.",
            "So for instance there may be additional nodes due to the fact that my image segmentation segmenter is pulled out of fools, regions or fourth quarters or full sections of the shop graph.",
            "And then maybe missing nodes due to the fact that my image Segmenter hasn't been chewed up in numbers detected image structure.",
            "So the graphs are going to have different numbers of nodes due to.",
            "Addition or loss of nodes and this means the edge structure is also going to be different."
        ],
        [
            "So let's sum this practice of formalize this problem.",
            "What I'm doing with the script for simple graphs, undirected graphs, just nodes and edges.",
            "And let's assume that we don't have any attributes, either overloads or on the edges and the edges are waiting.",
            "Ronald, who is to find the function F which is going to map from the modes of unravel.",
            "Thankful photograph onto a second graph and which I'm going to Colorado.",
            "What I want to do is to try to find this function in a way that satisfies constraints provided by pages into drugs.",
            "So let's consider this right."
        ],
        [
            "Slightly.",
            "Brute force way doing this.",
            "Suppose that I have.",
            "These two.",
            "Personal browse here comes match.",
            "You might develop these numbers.",
            "Saturday is the same time for nothing to match.",
            "In fact, might develop.",
            "These doesn't discuss it will start components behavior growth.",
            "So I'm doing this.",
            "I'm taking units which consists of the node tool, those pages and all those limits are connected to that center mode by hedge.",
            "So I got.",
            "Here is I've got one graph, but the signal is a pretty speedy surrounding it.",
            "In order to conveniently over here what I have is I am rough journey has two nodes in it and drop it looks here at Lake in the bottom 23.",
            "So how my going to compare those two drugs?",
            "What am I going to regret this kind of brute force approach?",
            "What I can do is I can make these graphs in the same size by adding padding mode.",
            "Here is a dummy node for today.",
            "So let's assume that I have official guests of, let's call that gamma.",
            "Which is a set of correspondence is between the lobes of this graph here and padded bra over here.",
            "Suspected of.",
            "Correspondence is sent copies in pairs.",
            "Not going to take this.",
            "Simple graph here.",
            "ABC D Magic 123CO23D.",
            "Then the principle happens is that the.",
            "I can be sure about the identity of the center node here.",
            "Then the surrounding roads could obviously be computed in cycle Canada and that will also give me a consistent pattern.",
            "Correspondence is so mappings between ABCD 123 W. Even here you see, there's a little just cited presentations of 2 three dummy around data center node.",
            "So let me cool is set here this set of.",
            "I'm in full destruction.",
            "Between First off and second round theater here, what we see is there are there 123 and six of these.",
            "So I can do so much about the probability of my initial guess like correspondances between the nodes of these two graphs I may have.",
            "Cases which of these these nodes in correspondence with these over here?",
            "What I can do is I can justify the base formula.",
            "So the problem that you got my respect to somewhere over all these possible structures in that things.",
            "Gavin, this time to be best.",
            "And Furthermore that I can do is I can assume that the if I take out the best I can assume that they assignments in the different modes are independent.",
            "That means I can factor probably counting this as a probability of the map of McKay given the label on expected signing binding instructions only happening here.",
            "So this is just going to be some of product conditional probabilities.",
            "Find my project.",
            "This problem is distribution here.",
            "Alright, I can do is I can make the very very simple error model consumer to error process is operating one of those is an assignment error process which just says if I made an error in my initial guess as to which node corresponds in Minecraft correspondence which over another.",
            "Let me say that every process operates with probability P. And then the other error code says that operates is factor five quarter missing node in the second graph I have to insert a dummy to compensate for it so I can do is I can buy consume the probability of inserting the dummy is being fine.",
            "So everything is hungry and I successfully match or node to the sidelines is along demanded by the structure, reserving mapping.",
            "Then what happens is that neither of the process is assignment error process with the dummy insertion process of operators in that case.",
            "So the probability of its Avengers online supply comes online spel.",
            "OK, now let's assume that.",
            "Now this will take a case.",
            "Now, the mapping that I have and it's going to be equal to mapping multiple instruction survey map, including two to nose correspondence in public assistant, one for you to start reserving memory and that load is not a diary.",
            "This means what happens is I made an assignment error, but I haven't had to insert a Wii and had to make a structural modification to graph, so there's probably long lines P5.",
            "There's no dummy.",
            "Have made assignment error.",
            "Then now what happens if I try to match paper dummy node or elsewhere download is then what happens is I have forwarded by here because I need in the case of loving search dummy.",
            "What we can do is we can try to extend.",
            "This is simple model.",
            "The only thing is actually a three month graph too.",
            "Sorry for number 3 number as I've shown here and."
        ],
        [
            "Extend it to graphs, but their arbitrary number of nodes in regions.",
            "I'm considering an article numbers of dummies.",
            "So I can make three different measurements on the stage of the match.",
            "One of them is I can compute the Hamming distance between the my current assignment understructure deserving that day.",
            "That's the number of areas assignment errors that made you pull in H. I can compute number dummy nodes that I require that's different.",
            "The difference in the size of two graphs are matching.",
            "And then I'd like to do is I consider the other rule size of problem, that's a maximum of the science into crowds.",
            "Two structures I'm considering, so I do that.",
            "This probability distribution just simplifies down to long lines.",
            "Being high comes online speed to the size of there are plans having distance.",
            "Find some number of early.",
            "Dumb insertions then.",
            "Idaho lines keep items before having distance.",
            "Another assignment errors that may I have P5 the number of W nodes that is very simple.",
            "Probability distribution takes demencial depends on how many distance number dummy numbers in science graphs.",
            "But in principle right then average this like an intake.",
            "This measure if it's feasible to evaluate it.",
            "If the grasshopper can be what I can do is I can decompose the graphs I'm dealing with into something.",
            "Like this, an average is probability of inside the units and then try to somehow maximizing probability by reassigning the correspondences between pairs of graphs."
        ],
        [
            "No, I'm not playing with you before this optimization problem.",
            "That is great news sent by Greenfield Clinic search engineers, people, group search, whatever you want and result in Gainesville.",
            "Generally speaking, going to be kind of proportional image.",
            "Computational resource information problem.",
            "There's not one of the problems that underpins this.",
            "This kind of approach is it's this computational complexity and what happens if I start to want to take larger units here.",
            "I want to insert more than one dummy node, then the number of the structure preserving mappings pros exponentially for the number of number of dummy insertions.",
            "Also, the size of units only.",
            "So this problem is going to be played by.",
            "Computational complexity.",
            "One problem is to his packages from the complexity of the problem.",
            "Create these neighborhoods strings.",
            "With this work, we did this and like for example the trying to match neighborhoods of strings.",
            "Second approach is something that focus on more details this week off the ground spectral approach that will allow us to get."
        ],
        [
            "Rise the at the graph.",
            "Subpoena more local way and I'll show you how we can extend this.",
            "This publishes revolution into the spectral domain."
        ],
        [
            "Headaches."
        ],
        [
            "That shows a little example of how we can.",
            "Solve this problem for producing more computational texted by trying to reduce the neighborhood configurations to strings.",
            "And if you're interested in this, there's a paper that appeared in in Hamming in I think 2000 resource it by Richard Myers rituals and myself.",
            "OK, so that's."
        ],
        [
            "Some.",
            "Let's not start."
        ],
        [
            "Think about the how we might.",
            "Matches hope that this problem into a matrix setting and tried to.",
            "Make the recovery is that correspondence is a little bit more elegant.",
            "So this is special correspondence matching what I'm doing that if you want to have a picture of it is trying to extend well beyond this algorithm that finds the permutation that brings graphs and correspondence by taking out a product of the Cedar vectors and adjacency matrices.",
            "But it would be trying to do.",
            "In this part of the tool is extended database where we have different numbers of nodes.",
            "Right, I know to be doing this using an algorithm solve this problem, but I need to do something to treat the correspondences between the graphs, missing data, set up incomplete, unlikely function for the problem, and then I'm going to try to find a solution to that.",
            "Using an eigenvector method.",
            "So that is a quick hold hands.",
            "How many of you heard of EM algorithm?",
            "How many goals?",
            "OK."
        ],
        [
            "So it's located.",
            "So what we're doing here is kind of probabilistic approach from matching.",
            "Use matrix factorization.",
            "The idea is to use the eigenvectors of job from Jason Matrix.",
            "Trying to find a solution.",
            "Well, this is a sitting on top of the arms algorithm and really contribution here is put everything into a low brightness setting to use PM Alpha funding solution.",
            "Select some."
        ],
        [
            "Let's review.",
            "Only algorithm save more.",
            "It does.",
            "So let's suppose I put a few drops major Alpha blocker off.",
            "We're not going to do is.",
            "I'm going to float the adjacency matrix today, tomorrow, Friday and the adjacency matrix and walk around my head.",
            "World Series confrontation Matrix which minimize the previous goals between the data matrix and commuted.",
            "From Jason to Matrix, so other side I've written matrix transpose out painful because I'm using text mode in PowerPoint and I couldn't do equation.",
            "So that there will be on this album is that they.",
            "Matrix S minimizes comedias distance is found by performing, signifying the composition of the data graph model, rather basic matrix making schemes.",
            "So the singular value decomposition takes the.",
            "It doesn't look like I'm a competition.",
            "We have a matrix to direct you dial matrix, transpose to US intellectuals and worked on the RV show is that we can do to save your battery composition on model graph, adjacency matrix, and they'd rather basic matrix data.",
            "Setting simulated simulated view model from city elections be for the data graph.",
            "Thankfully of approximation to the permutation matrix is just becomes transpose of you.",
            "It's only going to work if we have the same number of nodes in data graph and look around, let's say matrices Dee Ann at the same number of rows and columns.",
            "So what we do is to show how people that try to develop an algorithm that will admit different size of the grass needs of this problem.",
            "So this is the."
        ],
        [
            "In the approach.",
            "We need to do is we're going to consider the number of nodes N broad node.",
            "And David will be assignments or perform some other rather than later uploads as sort of hidden variables and what we want to do is to try to find a likelihood of hidden variables and then try to recover the maximum likelihood set variables using VML.",
            "What are really going to be doing here is focusing on how this ranking function is exactly what we will see is strong parallels between this what I did in the example that discovered.",
            "We'll start to see how the exponential distribution enters into problem."
        ],
        [
            "So let's set up some matrix representation.",
            "What I want to do is to have a set of indicated variables that Tommy whether or not paraphrasing correspondence.",
            "So assume you've got an OK from the data graph, unknown Alpha from the model graph, and if those two nodes are in correspondence configuration, end of my algorithm essay Alpha team for one but not in correspondence, essay Alpha is equal 0.",
            "Now I have two Jason matrices.",
            "I have Big Brother Jason Matrix D and the elements of this one.",
            "If you notice a very connected by an edge, 0 otherwise and then we have similar matrix adjacency matrix multiply.",
            "So that's three matrices in my my problem.",
            "This is a.",
            "These two square matrices of different size, the number of rows and columns induced matrices are equal to the number of nodes in the later afternoon.",
            "Other modes of model graph.",
            "This matrix is rectangular and it's it has both.",
            "The problem is given by the number of nodes later after number of nodes in the whole graph.",
            "So this is the problem."
        ],
        [
            "Suppose that GD is.",
            "I hate Pearl Jam is my mobile graph.",
            "And this isn't correspondances.",
            "Between the loads of the photograph later on, or I want to do is right now, probability of observing the data growth given the world growth concession correspondence.",
            "Is it automatic?",
            "Loads of these drugs.",
            "So it is the as it was very discouraging.",
            "EM algorithm.",
            "These correspondences are going to be regarded as in variables, and they're going to be assumed to rise through a noisy observation process.",
            "So the idea here is to effectively to construct the mixture models over the possible correspondences between the data graph nodes and the models that do that.",
            "What I do is I factorize the.",
            "Drop everything, paper notes and I assumed each of the data graph nodes potentially actually truly programmable modes and then some other days.",
            "So the probability of observing the data graph even along Grafton said correspondence is the product over the Haven graph, knows some local the model graph nodes, probability of seeing node XA electoral given by offering model graph in the second correspondence is.",
            "So what we want to do is try to construct a model of this observation density which leaves the.",
            "In terms of performance indicators, thanks."
        ],
        [
            "So what we do is we can we can apply based here in the factorize the.",
            "Right over the performance indicators you do that or happens is distribution becomes product over the longer after numbers of product innovation, graph modes.",
            "Phoenix Alpha in.",
            "While I'm texting beta recipe Rita is the effectively correspondence inspector.",
            "So let's say we assume that they."
        ],
        [
            "Effectively, correspondence indicators what ended?",
            "They now want to do is to try to find the arrival.",
            "Which will make the performance indicators.",
            "So they built this patient with loads of different graph.",
            "So to do that we do in working terms of this.",
            "Yeah.",
            "And let me know which way today we consider JB M, Alpha, Beta, SV.",
            "So will put back on that's doing is asking is telling us whether the nodes XA and XB in the later afternoon correspondence with mobile offer might be the model graph and if when we test the pictures we multiply the later application, see.",
            "Maybe it will project 60 element and Alpha beta.",
            "The correspondence indicates 80 feature that's equal to 1.",
            "Then what we're seeing is a pair of nodes to consistently connected by edges with zero.",
            "Then this is this condition is not satisfied.",
            "Now I can do is I can turn to the.",
            "The idea of having an error process is used in Decatur variable.",
            "Trying to account for the observation of the correspondence indicators under the assumption that this is variable followed follows balloon distribution.",
            "Do I have is I have a opponent PC probability that the.",
            "Her blood great match.",
            "That's good buddy.",
            "ABDL computer SP feature and then probably very correctly match is just 1 -- 8 * 4 minus indicator.",
            "So this is now beginning to sort of playing the role that Hamming distance did when I was developing this model.",
            "In the discrete case they wrong.",
            "So if I could."
        ],
        [
            "Now substitute this back into the factorization."
        ],
        [
            "What happens is products database, I think effectively happens is this.",
            "Products here environmental distribution.",
            "So if I.",
            "Define take the probabilities inside the product inside the exponential.",
            "Then the probability that I see no a invasion graph given no doubt from the model profit center correspondence, is just K times.",
            "The sum is indicated.",
            "Variables over the center of loans which connected to the load.",
            "A photograph.",
            "Constantly review is just a lot of fun.",
            "Lightspeed, the divided by fear.",
            "It's the development here using the new model for the correspondence indicators, large write down exponential distribution from the observation density, you seem OK. Those are all people know about them over after second correspondence is.",
            "So what I want to do is to then take this this observation density and two computer log likelihood function for certain correspondences using the observation entity.",
            "So if I do that."
        ],
        [
            "Hey.",
            "I like your function is is just some of those in the face, Prof kinds of law of the sum of these probabilities here.",
            "That seems that we couldn't even write this down as a. Estimation problem, but of course these diseases are heading, so we need to approach it in slightly different way."
        ],
        [
            "So.",
            "Street correspondence in pages hidden instead of writing down credit card like a function, which I've done here, what we need to do is to write down the expected operator function under Friday.",
            "Apparatus of the DNR order.",
            "So what we want to do is take estimates of the correspondence implications for these matrices, correspondence, indicators.",
            "We what we want to do is to make a new estimate of correspondence indicators operation plus one even estimate at iteration pen.",
            "And so the algorithm says that we want to solve this problem that we need to write down the expected or lacking function that simply the probability posterior probability of Alpha given a correspondence in the pages times log of the observation density.",
            "So if we what we can do is we can now rewrite this.",
            "This expression, in terms of a set of correspondence probabilities and the logarithm of the of the observation density, so we go back."
        ],
        [
            "Observation density is exponential fold.",
            "It's some of these.",
            "The.",
            "Matrix matrix and the correspondence indicator.",
            "So if we substitute back in."
        ],
        [
            "This expression here, it turns out that the expected alright with function she says the sum over pairs of notes and later on as opposed to Model graph QL Alpha, which is just the posterior probability of no delpha, even though David correspondence in pages times the personal log of portion ality constant from the exponential distribution, and then the the argument that the exponential distribution here.",
            "So that's the that's putting the effectively problem now into the form of a expectable right through function.",
            "So probably an algorithm requires decimate is to.",
            "Just to confuse this equation, the first of the the correspondence indicating his answers were after the segment of the posterior probabilities, which we could in fact knowing distribution estimate from correspondence indications.",
            "Alexa's purpose will be further."
        ],
        [
            "So far the operating system VM algorithm you notice right two steps maximization step, which is to find maximum likelihood correspondence in the pages and expectations that produces workout posterior probabilities.",
            "So."
        ],
        [
            "The maximum likelihood correspondence indicators just going to maximize them through S have given the indicators we had in the previous iteration.",
            "We turn our attention to the expected alright in function."
        ],
        [
            "And it turns out that."
        ],
        [
            "This first part here will be influenced by a correspondence indicators, so it's just this term here which you don't have to turn our attention.",
            "And in particular, what we can do is we can replace these.",
            "Stations here.",
            "My matrix multiplications.",
            "What happens if you do this?"
        ],
        [
            "It turns out that the the components of the expectable platform function that determines the correspondence indicators is just minus the trace.",
            "The transpose of nature objects matrix times matrix of posterior probabilities, evaluation, iteration eight times the make the model graph adjacency matrix times I minus the correspondence indications.",
            "And this is Isaac really matter, so we can produce this.",
            "The task of finding problems in inventory is maximizing price of beauty and Q&A.",
            "And St. What is done?",
            "Is it stated we have by using the?",
            "Distribution policy pages because for maximum likelihood problem into trace maximization problem.",
            "So that's that's now reduced.",
            "The algorithm to function multiple editors statement in terms of matrices.",
            "And what I need to do now is to explain to you how the how we can find this maximum likelihood matrix correspondence indicators.",
            "So this maximizes trace function."
        ],
        [
            "So what we have to do is to borrow an idea from an algorithm developed by Christopher Longuet Higgins and I stop.",
            "What they show is that if you have a choice maximization.",
            "With his sword.",
            "First we trying to find matrix bar.",
            "It maximizes trace here.",
            "Then we can find the.",
            "Solution using singularity composition.",
            "What we do is find the solution is we take this matrix, the duty queue and we perform singular value composition onto it.",
            "So we like this is be deltas baggage for matrix beauty.",
            "And then the matrix R maximizes trace just becomes duty.",
            "So this will give us a matrix that maximizes grace and probably is the.",
            "This problem all I wanted was the matrix S we made up of several indicators and there's nothing about this matrix.",
            "Guarantees that the government is going to be very qualified and looking to guarantee anything positive.",
            "So what we do is we use simple you Ristic protect this matrix and we assign the proper formulas.",
            "Indicate if you want.",
            "If the element Alpha is wrong, maximum of our consumer otherwise.",
            "So if it's if the yellow is not going through important maximum, then we set the correspondence indication 10.",
            "That's not the case.",
            "And then."
        ],
        [
            "Now we have the new correspondence indicators.",
            "What we can do is we can just proximal to the distribution exponential distribution, and we can use the.",
            "Ian algorithm beautiful theory of abilities.",
            "So there's really steps in the algorithm.",
            "It's what we're doing is where we were taking this this price.",
            "Matrices with finding promising pages using this touristic.",
            "Really and then once we have the appropriate backpack into the expectations set with the algorithm update posterior probabilities.",
            "And then we're just iterating through these two steps.",
            "So this typing is interesting because it does."
        ],
        [
            "Number of entrances with the algorithm.",
            "First of all, using simulated composition, but importantly what we're doing is where we have.",
            "Taking the problem into the main, we have different numbers of nodes in the two graphs because what we're doing is we're performing senior value composition on this rectangular matrix here.",
            "So here it is."
        ],
        [
            "What I've done is I have taken through the translation somehow sequence.",
            "I showed you earlier and we find this number of pairs of use as the camera and."
        ],
        [
            "Here, here, the past abusive were taking and carrying firstview this with the subsequent viewer using that chain of superimposed images on top of each other here.",
            "So you get some appreciation of differences in the image as the camera pans Lotus.",
            "Initially there might be insignificant volume reached final image in sequence.",
            "They really are quite large.",
            "So that's.",
            "Show"
        ],
        [
            "Initial post compensates between first image on the second image in sequence.",
            "Very good what you see is the.",
            "For Xbox Correspondence, is is indicated by having parallel rides.",
            "Now what happens is that we're going to rotate the."
        ],
        [
            "Seconding Slightly Stoopid food package matches."
        ],
        [
            "Now we started flares creeping in.",
            "And."
        ],
        [
            "The."
        ],
        [
            "Sorry."
        ],
        [
            "Where is Idaho?",
            "This number, called his phone number, photographs.",
            "These are number of correct responses.",
            "These number full squad is holding season easily.",
            "Notice which we did not respond to exist because the Matrix arms to radius.",
            "So what we see here is that we don't really pick up a significant fraction of the various till we reach the cost efficiencies."
        ],
        [
            "This is what happens if we apply the elements.",
            "Obviously applying for Yama reciprocal because we have to find a pair of images where the number of nodes are the same.",
            "So you go back to my table here."
        ],
        [
            "How's two and how school?",
            "Coincidentally, both have 32 forms in terms that means we can apply for beyond algorithm."
        ],
        [
            "This is what you get, and it's quite a mess, so it seems that our algorithm is not only dealing with the.",
            "Size graphs match, it's also.",
            "Results.",
            "Structure.",
            "This is."
        ],
        [
            "The algorithm for the same image pad."
        ],
        [
            "And then we got up.",
            "This algorithm we've added additional nodes into the images.",
            "Increase.",
            "Here is Rich Wilson 97 album book who is the Spectral algorithm here and then down here is a money.",
            "Well there's money through algorithm.",
            "Here is a algorithm attempts made Kathleen feel powerful, robust.",
            "So they are going to be $35."
        ],
        [
            "The question is that iteration like done here, is shown in full, but we have another correct correspondence is first iteration number.",
            "You see, it goes up and reaches convergence around the 2015 and 20 iterations."
        ],
        [
            "This is called here show happens if you keep number no space.",
            "Very the age structure in graphs.",
            "And what we see here is the output from up here.",
            "Then we are rounding underneath is disappeared.",
            "So experience."
        ],
        [
            "OK, so is it summarizes."
        ],
        [
            "Hungry.",
            "What I've done is I've shown how you can use the amount of rhythm.",
            "Graph matching refers to transfer size, then structure and copes with Zach Braff action.",
            "Break.",
            "Especially after them which.",
            "Text approach to problem.",
            "Trying to convert frustrations using I think technique and then by spring that change to the screen is extracted from drugs using the activator technique.",
            "So backing up."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Memory about the straight line.",
                    "label": 0
                },
                {
                    "sent": "One thing is is construct something called struggling translation.",
                    "label": 0
                },
                {
                    "sent": "Here what you do is divide each straight line into a number of sub segments.",
                    "label": 0
                },
                {
                    "sent": "Length of the subset need subsegment is the distance.",
                    "label": 0
                },
                {
                    "sent": "Play supply.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "6.7 century should be some settings, but what happens is that they will expand and manner which reflects the shape in the straight line.",
                    "label": 0
                },
                {
                    "sent": "And then we take the.",
                    "label": 0
                },
                {
                    "sent": "Triangulation of the sort of takes the incentive points of the image Regents arises construction recurring Bill Grubbs remember this directionality?",
                    "label": 0
                },
                {
                    "sent": "Straight lines in the image.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I want to deal with the full graph.",
                    "label": 0
                },
                {
                    "sent": "You gotta simplify it right to bring back some of their structure, because this might be regarded as redundant.",
                    "label": 0
                },
                {
                    "sent": "The two graphs of which can be computed will make graph which simplified the structure.",
                    "label": 0
                },
                {
                    "sent": "Most of these is a paper graph paper as we do is use construct a circle on edge on each edge of graph.",
                    "label": 0
                },
                {
                    "sent": "Then what we do is we check to see whether that circle contains another node.",
                    "label": 0
                },
                {
                    "sent": "Instead of opening up the road, then you delete the page itself.",
                    "label": 0
                },
                {
                    "sent": "So this is prunes away redundant adjacency relationships.",
                    "label": 0
                },
                {
                    "sent": "Starting with sophisticated version of this is the neighborhood graph that is relative neighborhood graph is probably constructing a circle from the issue.",
                    "label": 0
                },
                {
                    "sent": "You construct a mood, so that means if you have two circles.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "They sent it to you.",
                    "label": 0
                },
                {
                    "sent": "Find edge.",
                    "label": 0
                },
                {
                    "sent": "Look at the intersection of those two circles.",
                    "label": 0
                },
                {
                    "sent": "Just finds his shady Blue Ridge in here and it's blooming contains a.",
                    "label": 0
                },
                {
                    "sent": "Additional node then what we do is, we believe corresponding age.",
                    "label": 0
                },
                {
                    "sent": "So that's why you are pulling back the edge structure through labor after simplifying cross structure.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Recommendation I will talk about it.",
                    "label": 0
                },
                {
                    "sent": "Is a shocker of?",
                    "label": 0
                },
                {
                    "sent": "Shut up arises in skeletal representation shape, so here's a giraffe or regardless, with computer vision axis.",
                    "label": 0
                },
                {
                    "sent": "Skeleton so every point on that maybe access.",
                    "label": 0
                },
                {
                    "sent": "We could construct a circle is by tangent to the boundary of the object.",
                    "label": 0
                },
                {
                    "sent": "So we choose a point we could construct every point on the skeleton so it just touches in by fashion way the battery.",
                    "label": 0
                },
                {
                    "sent": "Now that's what we do is we can.",
                    "label": 0
                },
                {
                    "sent": "We can move it on the skeleton and recall what happens to the radius that circle.",
                    "label": 0
                },
                {
                    "sent": "So you can imagine the circle behavior and other displays if the library is tapering, then what happens is that the circle increases or decreases on the Franklin radius.",
                    "label": 0
                },
                {
                    "sent": "If we have a construction.",
                    "label": 0
                },
                {
                    "sent": "Then so probably come back here then what happens is the circle has a radius, has a local minimum.",
                    "label": 0
                },
                {
                    "sent": "If we have a boundary of a beautiful width, then the greatest service constant, then finally we can have a little bulge on the boundary, in which case the radius of circle is locally maximum.",
                    "label": 0
                },
                {
                    "sent": "And So what we can do is we can fulfill sampling into the radius of 500 circle as we travel along different instead of branches and that allows sensitive tribute.",
                    "label": 0
                },
                {
                    "sent": "The skeleton in a manner which tells us something about the geometry of the boundary difference.",
                    "label": 0
                },
                {
                    "sent": "With Jonathan Foundry, I'll come back to this representation made wrong because I should use it, provide data for one of my one of my examples.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "That really finishing my 2 pieces of that sort of motivational right first will probably work, and Secondly setting up the picture of how graphs come about in computer vision.",
                    "label": 0
                },
                {
                    "sent": "Now I want to do is to get started stuff into more technical aspects and talk to you little bit about how we could try to measure the similarity of graphs, particular how we can capture that similarity in a probabilistic way.",
                    "label": 0
                },
                {
                    "sent": "So why don't we do it in the next?",
                    "label": 0
                },
                {
                    "sent": "I guess 40 minutes or so, but it's talking about array in which we can model types of errors occur or variations occur in the grass.",
                    "label": 0
                },
                {
                    "sent": "To measure these in a probabilistic manner to get developer problems, distribution, little caption.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so the starting point for this work is a.",
                    "label": 0
                },
                {
                    "sent": "Motion.",
                    "label": 0
                },
                {
                    "sent": "And it was published in family back in 1997.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the idea is as follows.",
                    "label": 0
                },
                {
                    "sent": "Let's suppose we're trying to match two brothers.",
                    "label": 0
                },
                {
                    "sent": "And this growth potentially have different numbers of nodes and edges.",
                    "label": 1
                },
                {
                    "sent": "What we're trying to do is to mark at each node in one graph.",
                    "label": 0
                },
                {
                    "sent": "You know the demographics in correspondence with it.",
                    "label": 0
                },
                {
                    "sent": "So what can go wrong if we were trying to form this process?",
                    "label": 0
                },
                {
                    "sent": "Well, first of all I don't know how to make the initial tests.",
                    "label": 0
                },
                {
                    "sent": "Probably correspondences are going to have to somehow initializes process assigning correspondences nodes, and so they're going to at the outset of the process are going to be assignment errors.",
                    "label": 0
                },
                {
                    "sent": "I'm going to displace.",
                    "label": 0
                },
                {
                    "sent": "No correspondence is and what I'm going to do is trying really freaking figure placement of those motocross policies so that they.",
                    "label": 0
                },
                {
                    "sent": "They satisfy age constraints.",
                    "label": 1
                },
                {
                    "sent": "In practice, this may sound like cloud problem, but it's it's relatively easy capturing a number of different ways.",
                    "label": 0
                },
                {
                    "sent": "In a sense of chocolate, if I'm trying to match the paragraphs, a structural errors and so, for instance, graphs on matching, they have different numbers of nodes.",
                    "label": 1
                },
                {
                    "sent": "So for instance there may be additional nodes due to the fact that my image segmentation segmenter is pulled out of fools, regions or fourth quarters or full sections of the shop graph.",
                    "label": 0
                },
                {
                    "sent": "And then maybe missing nodes due to the fact that my image Segmenter hasn't been chewed up in numbers detected image structure.",
                    "label": 0
                },
                {
                    "sent": "So the graphs are going to have different numbers of nodes due to.",
                    "label": 0
                },
                {
                    "sent": "Addition or loss of nodes and this means the edge structure is also going to be different.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's sum this practice of formalize this problem.",
                    "label": 0
                },
                {
                    "sent": "What I'm doing with the script for simple graphs, undirected graphs, just nodes and edges.",
                    "label": 1
                },
                {
                    "sent": "And let's assume that we don't have any attributes, either overloads or on the edges and the edges are waiting.",
                    "label": 0
                },
                {
                    "sent": "Ronald, who is to find the function F which is going to map from the modes of unravel.",
                    "label": 1
                },
                {
                    "sent": "Thankful photograph onto a second graph and which I'm going to Colorado.",
                    "label": 0
                },
                {
                    "sent": "What I want to do is to try to find this function in a way that satisfies constraints provided by pages into drugs.",
                    "label": 0
                },
                {
                    "sent": "So let's consider this right.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Slightly.",
                    "label": 0
                },
                {
                    "sent": "Brute force way doing this.",
                    "label": 0
                },
                {
                    "sent": "Suppose that I have.",
                    "label": 0
                },
                {
                    "sent": "These two.",
                    "label": 0
                },
                {
                    "sent": "Personal browse here comes match.",
                    "label": 0
                },
                {
                    "sent": "You might develop these numbers.",
                    "label": 0
                },
                {
                    "sent": "Saturday is the same time for nothing to match.",
                    "label": 0
                },
                {
                    "sent": "In fact, might develop.",
                    "label": 0
                },
                {
                    "sent": "These doesn't discuss it will start components behavior growth.",
                    "label": 0
                },
                {
                    "sent": "So I'm doing this.",
                    "label": 0
                },
                {
                    "sent": "I'm taking units which consists of the node tool, those pages and all those limits are connected to that center mode by hedge.",
                    "label": 0
                },
                {
                    "sent": "So I got.",
                    "label": 0
                },
                {
                    "sent": "Here is I've got one graph, but the signal is a pretty speedy surrounding it.",
                    "label": 0
                },
                {
                    "sent": "In order to conveniently over here what I have is I am rough journey has two nodes in it and drop it looks here at Lake in the bottom 23.",
                    "label": 0
                },
                {
                    "sent": "So how my going to compare those two drugs?",
                    "label": 0
                },
                {
                    "sent": "What am I going to regret this kind of brute force approach?",
                    "label": 0
                },
                {
                    "sent": "What I can do is I can make these graphs in the same size by adding padding mode.",
                    "label": 0
                },
                {
                    "sent": "Here is a dummy node for today.",
                    "label": 0
                },
                {
                    "sent": "So let's assume that I have official guests of, let's call that gamma.",
                    "label": 0
                },
                {
                    "sent": "Which is a set of correspondence is between the lobes of this graph here and padded bra over here.",
                    "label": 0
                },
                {
                    "sent": "Suspected of.",
                    "label": 0
                },
                {
                    "sent": "Correspondence is sent copies in pairs.",
                    "label": 0
                },
                {
                    "sent": "Not going to take this.",
                    "label": 0
                },
                {
                    "sent": "Simple graph here.",
                    "label": 0
                },
                {
                    "sent": "ABC D Magic 123CO23D.",
                    "label": 0
                },
                {
                    "sent": "Then the principle happens is that the.",
                    "label": 0
                },
                {
                    "sent": "I can be sure about the identity of the center node here.",
                    "label": 0
                },
                {
                    "sent": "Then the surrounding roads could obviously be computed in cycle Canada and that will also give me a consistent pattern.",
                    "label": 0
                },
                {
                    "sent": "Correspondence is so mappings between ABCD 123 W. Even here you see, there's a little just cited presentations of 2 three dummy around data center node.",
                    "label": 0
                },
                {
                    "sent": "So let me cool is set here this set of.",
                    "label": 0
                },
                {
                    "sent": "I'm in full destruction.",
                    "label": 0
                },
                {
                    "sent": "Between First off and second round theater here, what we see is there are there 123 and six of these.",
                    "label": 0
                },
                {
                    "sent": "So I can do so much about the probability of my initial guess like correspondances between the nodes of these two graphs I may have.",
                    "label": 0
                },
                {
                    "sent": "Cases which of these these nodes in correspondence with these over here?",
                    "label": 0
                },
                {
                    "sent": "What I can do is I can justify the base formula.",
                    "label": 0
                },
                {
                    "sent": "So the problem that you got my respect to somewhere over all these possible structures in that things.",
                    "label": 0
                },
                {
                    "sent": "Gavin, this time to be best.",
                    "label": 0
                },
                {
                    "sent": "And Furthermore that I can do is I can assume that the if I take out the best I can assume that they assignments in the different modes are independent.",
                    "label": 0
                },
                {
                    "sent": "That means I can factor probably counting this as a probability of the map of McKay given the label on expected signing binding instructions only happening here.",
                    "label": 0
                },
                {
                    "sent": "So this is just going to be some of product conditional probabilities.",
                    "label": 0
                },
                {
                    "sent": "Find my project.",
                    "label": 0
                },
                {
                    "sent": "This problem is distribution here.",
                    "label": 0
                },
                {
                    "sent": "Alright, I can do is I can make the very very simple error model consumer to error process is operating one of those is an assignment error process which just says if I made an error in my initial guess as to which node corresponds in Minecraft correspondence which over another.",
                    "label": 0
                },
                {
                    "sent": "Let me say that every process operates with probability P. And then the other error code says that operates is factor five quarter missing node in the second graph I have to insert a dummy to compensate for it so I can do is I can buy consume the probability of inserting the dummy is being fine.",
                    "label": 0
                },
                {
                    "sent": "So everything is hungry and I successfully match or node to the sidelines is along demanded by the structure, reserving mapping.",
                    "label": 0
                },
                {
                    "sent": "Then what happens is that neither of the process is assignment error process with the dummy insertion process of operators in that case.",
                    "label": 0
                },
                {
                    "sent": "So the probability of its Avengers online supply comes online spel.",
                    "label": 0
                },
                {
                    "sent": "OK, now let's assume that.",
                    "label": 0
                },
                {
                    "sent": "Now this will take a case.",
                    "label": 0
                },
                {
                    "sent": "Now, the mapping that I have and it's going to be equal to mapping multiple instruction survey map, including two to nose correspondence in public assistant, one for you to start reserving memory and that load is not a diary.",
                    "label": 0
                },
                {
                    "sent": "This means what happens is I made an assignment error, but I haven't had to insert a Wii and had to make a structural modification to graph, so there's probably long lines P5.",
                    "label": 0
                },
                {
                    "sent": "There's no dummy.",
                    "label": 0
                },
                {
                    "sent": "Have made assignment error.",
                    "label": 0
                },
                {
                    "sent": "Then now what happens if I try to match paper dummy node or elsewhere download is then what happens is I have forwarded by here because I need in the case of loving search dummy.",
                    "label": 0
                },
                {
                    "sent": "What we can do is we can try to extend.",
                    "label": 0
                },
                {
                    "sent": "This is simple model.",
                    "label": 0
                },
                {
                    "sent": "The only thing is actually a three month graph too.",
                    "label": 0
                },
                {
                    "sent": "Sorry for number 3 number as I've shown here and.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Extend it to graphs, but their arbitrary number of nodes in regions.",
                    "label": 0
                },
                {
                    "sent": "I'm considering an article numbers of dummies.",
                    "label": 0
                },
                {
                    "sent": "So I can make three different measurements on the stage of the match.",
                    "label": 1
                },
                {
                    "sent": "One of them is I can compute the Hamming distance between the my current assignment understructure deserving that day.",
                    "label": 0
                },
                {
                    "sent": "That's the number of areas assignment errors that made you pull in H. I can compute number dummy nodes that I require that's different.",
                    "label": 0
                },
                {
                    "sent": "The difference in the size of two graphs are matching.",
                    "label": 0
                },
                {
                    "sent": "And then I'd like to do is I consider the other rule size of problem, that's a maximum of the science into crowds.",
                    "label": 0
                },
                {
                    "sent": "Two structures I'm considering, so I do that.",
                    "label": 0
                },
                {
                    "sent": "This probability distribution just simplifies down to long lines.",
                    "label": 0
                },
                {
                    "sent": "Being high comes online speed to the size of there are plans having distance.",
                    "label": 0
                },
                {
                    "sent": "Find some number of early.",
                    "label": 0
                },
                {
                    "sent": "Dumb insertions then.",
                    "label": 0
                },
                {
                    "sent": "Idaho lines keep items before having distance.",
                    "label": 0
                },
                {
                    "sent": "Another assignment errors that may I have P5 the number of W nodes that is very simple.",
                    "label": 0
                },
                {
                    "sent": "Probability distribution takes demencial depends on how many distance number dummy numbers in science graphs.",
                    "label": 0
                },
                {
                    "sent": "But in principle right then average this like an intake.",
                    "label": 0
                },
                {
                    "sent": "This measure if it's feasible to evaluate it.",
                    "label": 0
                },
                {
                    "sent": "If the grasshopper can be what I can do is I can decompose the graphs I'm dealing with into something.",
                    "label": 0
                },
                {
                    "sent": "Like this, an average is probability of inside the units and then try to somehow maximizing probability by reassigning the correspondences between pairs of graphs.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "No, I'm not playing with you before this optimization problem.",
                    "label": 0
                },
                {
                    "sent": "That is great news sent by Greenfield Clinic search engineers, people, group search, whatever you want and result in Gainesville.",
                    "label": 0
                },
                {
                    "sent": "Generally speaking, going to be kind of proportional image.",
                    "label": 0
                },
                {
                    "sent": "Computational resource information problem.",
                    "label": 0
                },
                {
                    "sent": "There's not one of the problems that underpins this.",
                    "label": 0
                },
                {
                    "sent": "This kind of approach is it's this computational complexity and what happens if I start to want to take larger units here.",
                    "label": 0
                },
                {
                    "sent": "I want to insert more than one dummy node, then the number of the structure preserving mappings pros exponentially for the number of number of dummy insertions.",
                    "label": 0
                },
                {
                    "sent": "Also, the size of units only.",
                    "label": 0
                },
                {
                    "sent": "So this problem is going to be played by.",
                    "label": 0
                },
                {
                    "sent": "Computational complexity.",
                    "label": 0
                },
                {
                    "sent": "One problem is to his packages from the complexity of the problem.",
                    "label": 0
                },
                {
                    "sent": "Create these neighborhoods strings.",
                    "label": 0
                },
                {
                    "sent": "With this work, we did this and like for example the trying to match neighborhoods of strings.",
                    "label": 0
                },
                {
                    "sent": "Second approach is something that focus on more details this week off the ground spectral approach that will allow us to get.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Rise the at the graph.",
                    "label": 1
                },
                {
                    "sent": "Subpoena more local way and I'll show you how we can extend this.",
                    "label": 0
                },
                {
                    "sent": "This publishes revolution into the spectral domain.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Headaches.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That shows a little example of how we can.",
                    "label": 0
                },
                {
                    "sent": "Solve this problem for producing more computational texted by trying to reduce the neighborhood configurations to strings.",
                    "label": 0
                },
                {
                    "sent": "And if you're interested in this, there's a paper that appeared in in Hamming in I think 2000 resource it by Richard Myers rituals and myself.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some.",
                    "label": 0
                },
                {
                    "sent": "Let's not start.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Think about the how we might.",
                    "label": 0
                },
                {
                    "sent": "Matches hope that this problem into a matrix setting and tried to.",
                    "label": 0
                },
                {
                    "sent": "Make the recovery is that correspondence is a little bit more elegant.",
                    "label": 0
                },
                {
                    "sent": "So this is special correspondence matching what I'm doing that if you want to have a picture of it is trying to extend well beyond this algorithm that finds the permutation that brings graphs and correspondence by taking out a product of the Cedar vectors and adjacency matrices.",
                    "label": 0
                },
                {
                    "sent": "But it would be trying to do.",
                    "label": 0
                },
                {
                    "sent": "In this part of the tool is extended database where we have different numbers of nodes.",
                    "label": 0
                },
                {
                    "sent": "Right, I know to be doing this using an algorithm solve this problem, but I need to do something to treat the correspondences between the graphs, missing data, set up incomplete, unlikely function for the problem, and then I'm going to try to find a solution to that.",
                    "label": 0
                },
                {
                    "sent": "Using an eigenvector method.",
                    "label": 0
                },
                {
                    "sent": "So that is a quick hold hands.",
                    "label": 0
                },
                {
                    "sent": "How many of you heard of EM algorithm?",
                    "label": 0
                },
                {
                    "sent": "How many goals?",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So it's located.",
                    "label": 0
                },
                {
                    "sent": "So what we're doing here is kind of probabilistic approach from matching.",
                    "label": 0
                },
                {
                    "sent": "Use matrix factorization.",
                    "label": 0
                },
                {
                    "sent": "The idea is to use the eigenvectors of job from Jason Matrix.",
                    "label": 0
                },
                {
                    "sent": "Trying to find a solution.",
                    "label": 0
                },
                {
                    "sent": "Well, this is a sitting on top of the arms algorithm and really contribution here is put everything into a low brightness setting to use PM Alpha funding solution.",
                    "label": 0
                },
                {
                    "sent": "Select some.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's review.",
                    "label": 0
                },
                {
                    "sent": "Only algorithm save more.",
                    "label": 0
                },
                {
                    "sent": "It does.",
                    "label": 0
                },
                {
                    "sent": "So let's suppose I put a few drops major Alpha blocker off.",
                    "label": 0
                },
                {
                    "sent": "We're not going to do is.",
                    "label": 0
                },
                {
                    "sent": "I'm going to float the adjacency matrix today, tomorrow, Friday and the adjacency matrix and walk around my head.",
                    "label": 0
                },
                {
                    "sent": "World Series confrontation Matrix which minimize the previous goals between the data matrix and commuted.",
                    "label": 0
                },
                {
                    "sent": "From Jason to Matrix, so other side I've written matrix transpose out painful because I'm using text mode in PowerPoint and I couldn't do equation.",
                    "label": 0
                },
                {
                    "sent": "So that there will be on this album is that they.",
                    "label": 0
                },
                {
                    "sent": "Matrix S minimizes comedias distance is found by performing, signifying the composition of the data graph model, rather basic matrix making schemes.",
                    "label": 0
                },
                {
                    "sent": "So the singular value decomposition takes the.",
                    "label": 0
                },
                {
                    "sent": "It doesn't look like I'm a competition.",
                    "label": 0
                },
                {
                    "sent": "We have a matrix to direct you dial matrix, transpose to US intellectuals and worked on the RV show is that we can do to save your battery composition on model graph, adjacency matrix, and they'd rather basic matrix data.",
                    "label": 0
                },
                {
                    "sent": "Setting simulated simulated view model from city elections be for the data graph.",
                    "label": 0
                },
                {
                    "sent": "Thankfully of approximation to the permutation matrix is just becomes transpose of you.",
                    "label": 0
                },
                {
                    "sent": "It's only going to work if we have the same number of nodes in data graph and look around, let's say matrices Dee Ann at the same number of rows and columns.",
                    "label": 0
                },
                {
                    "sent": "So what we do is to show how people that try to develop an algorithm that will admit different size of the grass needs of this problem.",
                    "label": 0
                },
                {
                    "sent": "So this is the.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the approach.",
                    "label": 0
                },
                {
                    "sent": "We need to do is we're going to consider the number of nodes N broad node.",
                    "label": 0
                },
                {
                    "sent": "And David will be assignments or perform some other rather than later uploads as sort of hidden variables and what we want to do is to try to find a likelihood of hidden variables and then try to recover the maximum likelihood set variables using VML.",
                    "label": 0
                },
                {
                    "sent": "What are really going to be doing here is focusing on how this ranking function is exactly what we will see is strong parallels between this what I did in the example that discovered.",
                    "label": 0
                },
                {
                    "sent": "We'll start to see how the exponential distribution enters into problem.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's set up some matrix representation.",
                    "label": 0
                },
                {
                    "sent": "What I want to do is to have a set of indicated variables that Tommy whether or not paraphrasing correspondence.",
                    "label": 0
                },
                {
                    "sent": "So assume you've got an OK from the data graph, unknown Alpha from the model graph, and if those two nodes are in correspondence configuration, end of my algorithm essay Alpha team for one but not in correspondence, essay Alpha is equal 0.",
                    "label": 0
                },
                {
                    "sent": "Now I have two Jason matrices.",
                    "label": 0
                },
                {
                    "sent": "I have Big Brother Jason Matrix D and the elements of this one.",
                    "label": 0
                },
                {
                    "sent": "If you notice a very connected by an edge, 0 otherwise and then we have similar matrix adjacency matrix multiply.",
                    "label": 0
                },
                {
                    "sent": "So that's three matrices in my my problem.",
                    "label": 0
                },
                {
                    "sent": "This is a.",
                    "label": 0
                },
                {
                    "sent": "These two square matrices of different size, the number of rows and columns induced matrices are equal to the number of nodes in the later afternoon.",
                    "label": 0
                },
                {
                    "sent": "Other modes of model graph.",
                    "label": 0
                },
                {
                    "sent": "This matrix is rectangular and it's it has both.",
                    "label": 0
                },
                {
                    "sent": "The problem is given by the number of nodes later after number of nodes in the whole graph.",
                    "label": 0
                },
                {
                    "sent": "So this is the problem.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Suppose that GD is.",
                    "label": 0
                },
                {
                    "sent": "I hate Pearl Jam is my mobile graph.",
                    "label": 0
                },
                {
                    "sent": "And this isn't correspondances.",
                    "label": 0
                },
                {
                    "sent": "Between the loads of the photograph later on, or I want to do is right now, probability of observing the data growth given the world growth concession correspondence.",
                    "label": 0
                },
                {
                    "sent": "Is it automatic?",
                    "label": 0
                },
                {
                    "sent": "Loads of these drugs.",
                    "label": 0
                },
                {
                    "sent": "So it is the as it was very discouraging.",
                    "label": 0
                },
                {
                    "sent": "EM algorithm.",
                    "label": 0
                },
                {
                    "sent": "These correspondences are going to be regarded as in variables, and they're going to be assumed to rise through a noisy observation process.",
                    "label": 0
                },
                {
                    "sent": "So the idea here is to effectively to construct the mixture models over the possible correspondences between the data graph nodes and the models that do that.",
                    "label": 0
                },
                {
                    "sent": "What I do is I factorize the.",
                    "label": 0
                },
                {
                    "sent": "Drop everything, paper notes and I assumed each of the data graph nodes potentially actually truly programmable modes and then some other days.",
                    "label": 0
                },
                {
                    "sent": "So the probability of observing the data graph even along Grafton said correspondence is the product over the Haven graph, knows some local the model graph nodes, probability of seeing node XA electoral given by offering model graph in the second correspondence is.",
                    "label": 0
                },
                {
                    "sent": "So what we want to do is try to construct a model of this observation density which leaves the.",
                    "label": 0
                },
                {
                    "sent": "In terms of performance indicators, thanks.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what we do is we can we can apply based here in the factorize the.",
                    "label": 0
                },
                {
                    "sent": "Right over the performance indicators you do that or happens is distribution becomes product over the longer after numbers of product innovation, graph modes.",
                    "label": 0
                },
                {
                    "sent": "Phoenix Alpha in.",
                    "label": 0
                },
                {
                    "sent": "While I'm texting beta recipe Rita is the effectively correspondence inspector.",
                    "label": 0
                },
                {
                    "sent": "So let's say we assume that they.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Effectively, correspondence indicators what ended?",
                    "label": 0
                },
                {
                    "sent": "They now want to do is to try to find the arrival.",
                    "label": 0
                },
                {
                    "sent": "Which will make the performance indicators.",
                    "label": 0
                },
                {
                    "sent": "So they built this patient with loads of different graph.",
                    "label": 0
                },
                {
                    "sent": "So to do that we do in working terms of this.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "And let me know which way today we consider JB M, Alpha, Beta, SV.",
                    "label": 0
                },
                {
                    "sent": "So will put back on that's doing is asking is telling us whether the nodes XA and XB in the later afternoon correspondence with mobile offer might be the model graph and if when we test the pictures we multiply the later application, see.",
                    "label": 0
                },
                {
                    "sent": "Maybe it will project 60 element and Alpha beta.",
                    "label": 0
                },
                {
                    "sent": "The correspondence indicates 80 feature that's equal to 1.",
                    "label": 0
                },
                {
                    "sent": "Then what we're seeing is a pair of nodes to consistently connected by edges with zero.",
                    "label": 0
                },
                {
                    "sent": "Then this is this condition is not satisfied.",
                    "label": 0
                },
                {
                    "sent": "Now I can do is I can turn to the.",
                    "label": 0
                },
                {
                    "sent": "The idea of having an error process is used in Decatur variable.",
                    "label": 0
                },
                {
                    "sent": "Trying to account for the observation of the correspondence indicators under the assumption that this is variable followed follows balloon distribution.",
                    "label": 0
                },
                {
                    "sent": "Do I have is I have a opponent PC probability that the.",
                    "label": 0
                },
                {
                    "sent": "Her blood great match.",
                    "label": 0
                },
                {
                    "sent": "That's good buddy.",
                    "label": 0
                },
                {
                    "sent": "ABDL computer SP feature and then probably very correctly match is just 1 -- 8 * 4 minus indicator.",
                    "label": 0
                },
                {
                    "sent": "So this is now beginning to sort of playing the role that Hamming distance did when I was developing this model.",
                    "label": 0
                },
                {
                    "sent": "In the discrete case they wrong.",
                    "label": 0
                },
                {
                    "sent": "So if I could.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now substitute this back into the factorization.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What happens is products database, I think effectively happens is this.",
                    "label": 0
                },
                {
                    "sent": "Products here environmental distribution.",
                    "label": 0
                },
                {
                    "sent": "So if I.",
                    "label": 0
                },
                {
                    "sent": "Define take the probabilities inside the product inside the exponential.",
                    "label": 0
                },
                {
                    "sent": "Then the probability that I see no a invasion graph given no doubt from the model profit center correspondence, is just K times.",
                    "label": 0
                },
                {
                    "sent": "The sum is indicated.",
                    "label": 0
                },
                {
                    "sent": "Variables over the center of loans which connected to the load.",
                    "label": 0
                },
                {
                    "sent": "A photograph.",
                    "label": 0
                },
                {
                    "sent": "Constantly review is just a lot of fun.",
                    "label": 0
                },
                {
                    "sent": "Lightspeed, the divided by fear.",
                    "label": 0
                },
                {
                    "sent": "It's the development here using the new model for the correspondence indicators, large write down exponential distribution from the observation density, you seem OK. Those are all people know about them over after second correspondence is.",
                    "label": 0
                },
                {
                    "sent": "So what I want to do is to then take this this observation density and two computer log likelihood function for certain correspondences using the observation entity.",
                    "label": 0
                },
                {
                    "sent": "So if I do that.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hey.",
                    "label": 0
                },
                {
                    "sent": "I like your function is is just some of those in the face, Prof kinds of law of the sum of these probabilities here.",
                    "label": 0
                },
                {
                    "sent": "That seems that we couldn't even write this down as a. Estimation problem, but of course these diseases are heading, so we need to approach it in slightly different way.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Street correspondence in pages hidden instead of writing down credit card like a function, which I've done here, what we need to do is to write down the expected operator function under Friday.",
                    "label": 0
                },
                {
                    "sent": "Apparatus of the DNR order.",
                    "label": 0
                },
                {
                    "sent": "So what we want to do is take estimates of the correspondence implications for these matrices, correspondence, indicators.",
                    "label": 0
                },
                {
                    "sent": "We what we want to do is to make a new estimate of correspondence indicators operation plus one even estimate at iteration pen.",
                    "label": 0
                },
                {
                    "sent": "And so the algorithm says that we want to solve this problem that we need to write down the expected or lacking function that simply the probability posterior probability of Alpha given a correspondence in the pages times log of the observation density.",
                    "label": 0
                },
                {
                    "sent": "So if we what we can do is we can now rewrite this.",
                    "label": 0
                },
                {
                    "sent": "This expression, in terms of a set of correspondence probabilities and the logarithm of the of the observation density, so we go back.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Observation density is exponential fold.",
                    "label": 0
                },
                {
                    "sent": "It's some of these.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "Matrix matrix and the correspondence indicator.",
                    "label": 0
                },
                {
                    "sent": "So if we substitute back in.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This expression here, it turns out that the expected alright with function she says the sum over pairs of notes and later on as opposed to Model graph QL Alpha, which is just the posterior probability of no delpha, even though David correspondence in pages times the personal log of portion ality constant from the exponential distribution, and then the the argument that the exponential distribution here.",
                    "label": 0
                },
                {
                    "sent": "So that's the that's putting the effectively problem now into the form of a expectable right through function.",
                    "label": 0
                },
                {
                    "sent": "So probably an algorithm requires decimate is to.",
                    "label": 0
                },
                {
                    "sent": "Just to confuse this equation, the first of the the correspondence indicating his answers were after the segment of the posterior probabilities, which we could in fact knowing distribution estimate from correspondence indications.",
                    "label": 0
                },
                {
                    "sent": "Alexa's purpose will be further.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So far the operating system VM algorithm you notice right two steps maximization step, which is to find maximum likelihood correspondence in the pages and expectations that produces workout posterior probabilities.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The maximum likelihood correspondence indicators just going to maximize them through S have given the indicators we had in the previous iteration.",
                    "label": 0
                },
                {
                    "sent": "We turn our attention to the expected alright in function.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And it turns out that.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This first part here will be influenced by a correspondence indicators, so it's just this term here which you don't have to turn our attention.",
                    "label": 0
                },
                {
                    "sent": "And in particular, what we can do is we can replace these.",
                    "label": 0
                },
                {
                    "sent": "Stations here.",
                    "label": 0
                },
                {
                    "sent": "My matrix multiplications.",
                    "label": 0
                },
                {
                    "sent": "What happens if you do this?",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It turns out that the the components of the expectable platform function that determines the correspondence indicators is just minus the trace.",
                    "label": 0
                },
                {
                    "sent": "The transpose of nature objects matrix times matrix of posterior probabilities, evaluation, iteration eight times the make the model graph adjacency matrix times I minus the correspondence indications.",
                    "label": 0
                },
                {
                    "sent": "And this is Isaac really matter, so we can produce this.",
                    "label": 0
                },
                {
                    "sent": "The task of finding problems in inventory is maximizing price of beauty and Q&A.",
                    "label": 0
                },
                {
                    "sent": "And St. What is done?",
                    "label": 0
                },
                {
                    "sent": "Is it stated we have by using the?",
                    "label": 0
                },
                {
                    "sent": "Distribution policy pages because for maximum likelihood problem into trace maximization problem.",
                    "label": 0
                },
                {
                    "sent": "So that's that's now reduced.",
                    "label": 0
                },
                {
                    "sent": "The algorithm to function multiple editors statement in terms of matrices.",
                    "label": 0
                },
                {
                    "sent": "And what I need to do now is to explain to you how the how we can find this maximum likelihood matrix correspondence indicators.",
                    "label": 0
                },
                {
                    "sent": "So this maximizes trace function.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what we have to do is to borrow an idea from an algorithm developed by Christopher Longuet Higgins and I stop.",
                    "label": 0
                },
                {
                    "sent": "What they show is that if you have a choice maximization.",
                    "label": 0
                },
                {
                    "sent": "With his sword.",
                    "label": 0
                },
                {
                    "sent": "First we trying to find matrix bar.",
                    "label": 0
                },
                {
                    "sent": "It maximizes trace here.",
                    "label": 0
                },
                {
                    "sent": "Then we can find the.",
                    "label": 0
                },
                {
                    "sent": "Solution using singularity composition.",
                    "label": 0
                },
                {
                    "sent": "What we do is find the solution is we take this matrix, the duty queue and we perform singular value composition onto it.",
                    "label": 0
                },
                {
                    "sent": "So we like this is be deltas baggage for matrix beauty.",
                    "label": 0
                },
                {
                    "sent": "And then the matrix R maximizes trace just becomes duty.",
                    "label": 0
                },
                {
                    "sent": "So this will give us a matrix that maximizes grace and probably is the.",
                    "label": 0
                },
                {
                    "sent": "This problem all I wanted was the matrix S we made up of several indicators and there's nothing about this matrix.",
                    "label": 0
                },
                {
                    "sent": "Guarantees that the government is going to be very qualified and looking to guarantee anything positive.",
                    "label": 0
                },
                {
                    "sent": "So what we do is we use simple you Ristic protect this matrix and we assign the proper formulas.",
                    "label": 0
                },
                {
                    "sent": "Indicate if you want.",
                    "label": 0
                },
                {
                    "sent": "If the element Alpha is wrong, maximum of our consumer otherwise.",
                    "label": 0
                },
                {
                    "sent": "So if it's if the yellow is not going through important maximum, then we set the correspondence indication 10.",
                    "label": 0
                },
                {
                    "sent": "That's not the case.",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now we have the new correspondence indicators.",
                    "label": 0
                },
                {
                    "sent": "What we can do is we can just proximal to the distribution exponential distribution, and we can use the.",
                    "label": 0
                },
                {
                    "sent": "Ian algorithm beautiful theory of abilities.",
                    "label": 0
                },
                {
                    "sent": "So there's really steps in the algorithm.",
                    "label": 0
                },
                {
                    "sent": "It's what we're doing is where we were taking this this price.",
                    "label": 0
                },
                {
                    "sent": "Matrices with finding promising pages using this touristic.",
                    "label": 0
                },
                {
                    "sent": "Really and then once we have the appropriate backpack into the expectations set with the algorithm update posterior probabilities.",
                    "label": 0
                },
                {
                    "sent": "And then we're just iterating through these two steps.",
                    "label": 0
                },
                {
                    "sent": "So this typing is interesting because it does.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Number of entrances with the algorithm.",
                    "label": 0
                },
                {
                    "sent": "First of all, using simulated composition, but importantly what we're doing is where we have.",
                    "label": 0
                },
                {
                    "sent": "Taking the problem into the main, we have different numbers of nodes in the two graphs because what we're doing is we're performing senior value composition on this rectangular matrix here.",
                    "label": 0
                },
                {
                    "sent": "So here it is.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What I've done is I have taken through the translation somehow sequence.",
                    "label": 0
                },
                {
                    "sent": "I showed you earlier and we find this number of pairs of use as the camera and.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here, here, the past abusive were taking and carrying firstview this with the subsequent viewer using that chain of superimposed images on top of each other here.",
                    "label": 0
                },
                {
                    "sent": "So you get some appreciation of differences in the image as the camera pans Lotus.",
                    "label": 0
                },
                {
                    "sent": "Initially there might be insignificant volume reached final image in sequence.",
                    "label": 0
                },
                {
                    "sent": "They really are quite large.",
                    "label": 0
                },
                {
                    "sent": "So that's.",
                    "label": 0
                },
                {
                    "sent": "Show",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Initial post compensates between first image on the second image in sequence.",
                    "label": 0
                },
                {
                    "sent": "Very good what you see is the.",
                    "label": 0
                },
                {
                    "sent": "For Xbox Correspondence, is is indicated by having parallel rides.",
                    "label": 0
                },
                {
                    "sent": "Now what happens is that we're going to rotate the.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Seconding Slightly Stoopid food package matches.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now we started flares creeping in.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sorry.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Where is Idaho?",
                    "label": 0
                },
                {
                    "sent": "This number, called his phone number, photographs.",
                    "label": 0
                },
                {
                    "sent": "These are number of correct responses.",
                    "label": 0
                },
                {
                    "sent": "These number full squad is holding season easily.",
                    "label": 0
                },
                {
                    "sent": "Notice which we did not respond to exist because the Matrix arms to radius.",
                    "label": 0
                },
                {
                    "sent": "So what we see here is that we don't really pick up a significant fraction of the various till we reach the cost efficiencies.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is what happens if we apply the elements.",
                    "label": 0
                },
                {
                    "sent": "Obviously applying for Yama reciprocal because we have to find a pair of images where the number of nodes are the same.",
                    "label": 0
                },
                {
                    "sent": "So you go back to my table here.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How's two and how school?",
                    "label": 0
                },
                {
                    "sent": "Coincidentally, both have 32 forms in terms that means we can apply for beyond algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is what you get, and it's quite a mess, so it seems that our algorithm is not only dealing with the.",
                    "label": 0
                },
                {
                    "sent": "Size graphs match, it's also.",
                    "label": 0
                },
                {
                    "sent": "Results.",
                    "label": 0
                },
                {
                    "sent": "Structure.",
                    "label": 0
                },
                {
                    "sent": "This is.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The algorithm for the same image pad.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we got up.",
                    "label": 0
                },
                {
                    "sent": "This algorithm we've added additional nodes into the images.",
                    "label": 0
                },
                {
                    "sent": "Increase.",
                    "label": 0
                },
                {
                    "sent": "Here is Rich Wilson 97 album book who is the Spectral algorithm here and then down here is a money.",
                    "label": 0
                },
                {
                    "sent": "Well there's money through algorithm.",
                    "label": 0
                },
                {
                    "sent": "Here is a algorithm attempts made Kathleen feel powerful, robust.",
                    "label": 0
                },
                {
                    "sent": "So they are going to be $35.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The question is that iteration like done here, is shown in full, but we have another correct correspondence is first iteration number.",
                    "label": 0
                },
                {
                    "sent": "You see, it goes up and reaches convergence around the 2015 and 20 iterations.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is called here show happens if you keep number no space.",
                    "label": 0
                },
                {
                    "sent": "Very the age structure in graphs.",
                    "label": 0
                },
                {
                    "sent": "And what we see here is the output from up here.",
                    "label": 0
                },
                {
                    "sent": "Then we are rounding underneath is disappeared.",
                    "label": 0
                },
                {
                    "sent": "So experience.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so is it summarizes.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hungry.",
                    "label": 0
                },
                {
                    "sent": "What I've done is I've shown how you can use the amount of rhythm.",
                    "label": 0
                },
                {
                    "sent": "Graph matching refers to transfer size, then structure and copes with Zach Braff action.",
                    "label": 0
                },
                {
                    "sent": "Break.",
                    "label": 0
                },
                {
                    "sent": "Especially after them which.",
                    "label": 0
                },
                {
                    "sent": "Text approach to problem.",
                    "label": 0
                },
                {
                    "sent": "Trying to convert frustrations using I think technique and then by spring that change to the screen is extracted from drugs using the activator technique.",
                    "label": 0
                },
                {
                    "sent": "So backing up.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": []
        }
    }
}