{
    "id": "wxf56tsyr62cznkifkzbpzeaxm4dnezs",
    "title": "A Theory of Plenoptic Multiplexing",
    "info": {
        "author": [
            "Ivo Ihrke, Cluster of Excellence Multimodal Computing and Interaction, Saarland University",
            "Gordon Wetzstein, Department of Computer Science, University of British Columbia"
        ],
        "published": "July 19, 2010",
        "recorded": "June 2010",
        "category": [
            "Top->Computer Science->Computer Vision->Computational Photography"
        ]
    },
    "url": "http://videolectures.net/cvpr2010_ihrke_wetzstein_tpm/",
    "segmentation": [
        [
            "With that I'm just going to quickly introduce the speakers.",
            "The first speakers are on paper dieteria plenoptic multiplexing, and the authors are evil or K. Gordon Wetzstein and Balkan heidrick.",
            "OK, good morning and thank you for the introduction.",
            "Work."
        ],
        [
            "We are talking panoptic multiplexing.",
            "In the last couple of years we have seen tremendous progress in the area that is now called computational photography.",
            "We have seen how light fields can be acquired in digital cameras.",
            "How multispectral imaging can work, and of course, temporal light variation has been of interest for a long time.",
            "And the goal of all these works was basically to extend the capabilities of traditional film based cameras to be more flexible and in a way a perfect plenoptic imager that we're going to talk about.",
            "Would record each individual photon together with its plenoptic parameters.",
            "That means a direction, wavelength and time of arrival."
        ],
        [
            "And this paper is basically introducing a mathematical framework for such a device, and it is.",
            "This framework is general enough that it is describing the most plenoptic multiplexing algorithms that are around so far and devices, and by doing so, it basically enables comparative analysis of these different designs which we exemplify by performing noise analysis for color and light field multiplexing within a common framework.",
            "But maybe most interesting Lee.",
            "Our our theory allows us to enumerate a fixed number of design choices for plenoptic multiplexing algorithms.",
            "So in order to introduce our theory, I would like to reiterate how is sensor is actually recording light."
        ],
        [
            "For that, I'd like to employ the field of.",
            "Buckets analogy here.",
            "So we have a field filled with buckets and it's raining, and all those raindrops represent photons and buckets ours.",
            "Our sensor elements of course, because they are photons, they."
        ],
        [
            "Have a certain wavelength so there's a color variation.",
            "We also have temporal and direction of variation and the back of the bucket."
        ],
        [
            "Collecting all these raindrops that means."
        ],
        [
            "They're integrating all the photons.",
            "Regardless of incident, direction, time of arrival or wavelength, and the same."
        ],
        [
            "It's in a real scene as shown here on the right.",
            "We have light source emitting photons which hit some scene surface is they are being reflected, bounce around and.",
            "In the end, being focused onto the sensor where sensor element is collecting all these photons and integrating in the same way as with the buckets and this integration is very high dimensional, destroys information by averaging.",
            "It's present in the plenoptic function and the task of plenoptic multiplexing as we define it is to at least partially prevent this loss of information.",
            "For this we have basically three choices."
        ],
        [
            "We have multi sensor capture which means we split up the light and record with different sensors differently filtered versions of the light.",
            "This is usually expensive and bulky.",
            "We can do some time sequential capture.",
            "This limits US to static scenes and the third option is multiplexing which we're covering in this paper here and there.",
            "We are trading spatial resolution for plenoptic resolution.",
            "That means individual pixels are filtered differently to give us more information about the plenoptic function and in our opinion this is the most.",
            "Flexible approach in the most scalable approach that might eventually enable consumer products here.",
            "This is also motivated by the increase in pixels that can be produced economically.",
            "Which is increasing exponentially while the optics stays more or less fixed.",
            "That means we can use these additional pixels in some meaningful way by using the vocal and optic multiplexing.",
            "So for describing our model, basically let me first."
        ],
        [
            "Introduce the image formation model so we have the image intensity which is.",
            "Independent order continuous spatial variable X here and this is given in sensor space by an integral over the plenoptic function or Lambda here.",
            "And P is basically collecting all the plenoptic para meters.",
            "That means direction, wavelength and time, and this integral is happening on the sensor.",
            "Of course we have a plan optic integration domain.",
            "That means we have a restricted cone of race that are being integrated that pass through the aperture times some spectral region and temporal region of interest.",
            "Let me show you some example how we can modify this now with filters that picked."
        ],
        [
            "Certain values of this function so we have signal incident on the sensor here, and by putting different filters in front of the array we can for example sample different color values like shown here red, green and blue.",
            "This is familiar to everybody but also light fields by putting lens loads in the same pixels we could reckon.",
            "Put basically a directional filter that records different light directions in different pixels and a similar thing happens for so called mass based light fields where similar pixels are recording similar cone cones of race here.",
            "To accommodate for that in our framework, no.",
            "Sorry if we have those different filters before they are repeating.",
            "Basically we are using and repeating structure and one such.",
            "Thing is called a super pixel."
        ],
        [
            "To accommodate for this thing in our framework, we introduce something called a plenoptic modulator, which is a function that can attenuate race based on their plenoptic parameters.",
            "And as we show in our paper, we can actually separate this, usually for the Super pixel layout into a separable spatial basis and plenoptic basis.",
            "Let me show you one example here.",
            "Uh, 1D color filter array to give you some intuition.",
            "Basically, the spatial basis here.",
            "This is the first one is selecting a certain plenoptic basis, which is a spectral filter in this case, for each of the pixel values, and this is a Cartesian product.",
            "Here we can do the same thing for light field, so this is light field imaging."
        ],
        [
            "Through an array of pin holes and this time our plan optic basis is a rectangular function which is selecting certain cone of race for each of the pixels and our spatial basis is still picking a certain cone of race for each of them and we will see more general examples later.",
            "Why we actually call these function Sigma and Pi here basis can be immediately seen if we plug in this definition into our image formation model.",
            "It basically shows that the.",
            "The image formation is a projection into the plenoptic basis of the plenoptic function, so we have the plan optic function.",
            "Here it is being projected into the spaces and afterwards it's mixed on the sensor by the spatial basis.",
            "So this leads to."
        ],
        [
            "Main results of all paper which can be summarized in two theorems and the first is this plenoptic spatial multiplexing theorem, which states that the interpolated measurement channels are locally related to the plenoptic function, where measurement channel now is a collection of pixels with the same filter which is filled up by interpolation like these blue, green and red channels here and.",
            "Yes we can."
        ],
        [
            "Compute the plan or the projection of the panoptic function from that, and it's similar theorem is the plenoptic foreign multiplexing theorem which analyzes the same thing and through domain we see for transform here and it states that the full channels which are the red box here like one of those tiles, the different tiles are the food channels are locali related to the Fourier transform of the plug-in optic function.",
            "That means locality here means basically that the correlation this linear system that we see here.",
            "Is in dependently solvable for every of the spatial tire frequencies."
        ],
        [
            "Shown here, so together these two theorems basically form a unified view online optical reconstruction.",
            "First we have sampling process which generates a repeating pattern in spatial domain as shown here or or tiles in the full domain as shown here.",
            "Then reconstruction in a signal processing sense basically includes spatial interpolation or extraction of tiles using a weighting function followed by channel re correlation in any case.",
            "Have shown here which is local in either the spatial pixel position."
        ],
        [
            "Or the local frequency?",
            "This diagram shows that we can decompose any algorithm here into basically 3 design choices that we have, and the first one is the choice of the spatial and the plenoptic basis, particular their number in shape, where the spatial basis determining the sampling layout and the mixture properties.",
            "Where is the plan Optic base is determining the subspace of the plenoptic function that can be represented as the second choice.",
            "We have the interpolation scheme.",
            "We can use interpolation with priors, edge preserving, interpolation and so on and.",
            "The 3rd and maybe most interesting thing is that we can choose the decorrelation or reconstruction scheme.",
            "I mean, usually we employ linear reconstruction, but we can also go and take nonlinear reconstructions and enforce sparseness of the recovery treatment signal or a particular data dependent models and so on to fill our theory with some meaning.",
            "My colleague got in which time is now going to show you some examples of the application."
        ],
        [
            "Thank you Eva.",
            "Let me just say that I'm very excited to be here today, but we don't have much time left so."
        ],
        [
            "Jump right into an intuitive example for Thierry, which most of you should be familiar with, which is emerging with color filter arrays.",
            "So when you capture us 3 scene with a monochromatic sensor through a color filter array, every pixel it sends a single color channel only.",
            "Reconstruction in full resolution for an RGB image can be performed by interpolating all the color channels to every single pixel.",
            "Now, it's well known that periodic patterns such as the color filter array have it for you transform that consists of a sparse set of direct peaks.",
            "So the multiplication that the color filter array does on the incident light in the spatial domain becomes a convolution in the Fourier domain and the Fourier transform of the sensor image is basically a collection of 2D frequency tiles centered as those direct peaks.",
            "Reconstruction in the Fourier domain can be performed by decorrelating those tiles and transforming them back into the spatial domain.",
            "In this case the spatial reconstruction gives better result because we can use."
        ],
        [
            "More sophisticated interpolation schemes.",
            "Let me now show you how this can be extended to light fields and in the paper we also derive this for other plenoptic dimensions.",
            "Like fields that are captured with non refractive attenuation masks other than pinhole arrays have usually been reconstructed in the foyer in the Fourier domain, so we assume an attenuation Max to be placed at a distance set from the sensor plane and use the two plane parameterization of the light field where the two planes have a unit distance.",
            "Light Ray XV is then attenuated on the mask plane at the position X -- Z V. The sensor image is formed by integrating over the directional domain at every sensor pixel.",
            "If we replace the attenuation function M here by the inverse of its Fourier transform, we basically get a formulation that can be separated into a purely spatial and purely plenoptic or directional part.",
            "In this case, these are basically our spatial and our plenoptic basis functions.",
            "Although both the spatial and the plan optic basis are the Fourier transform and the inverse Fourier transform, respectively, this formulation actually allows a spatial per pixel reconstruction, just like in the case of color demosaicing.",
            "Using our theory in the."
        ],
        [
            "Paper in the supplemental material, we show how our theory applies to a variety of light field cameras, including those with non refractive estimation methods and those with refractive optical elements."
        ],
        [
            "Here's an example of Lightfield captured through a sum of sinusoids mask.",
            "The data set is taken from the depth photography paper and on the left and in the middle we see reconstructions in the Fourier domain and on the right is spatial reconstruction.",
            "Using our theory coming for your ringing artifacts in the Fourier domain can be avoided with the space."
        ],
        [
            "Reconstruction the same applies to data sets that are captured with alternative attenuation methods such as this mural pattern here.",
            "This is from the Shields paper and again, especially reconstruction can perform better than a full year reconstruction, although we only prove our theory for linear upsampling filters.",
            "In practice it works quite well with nonlinear filters such as the spatial joint bilateral filter as seen on the right here."
        ],
        [
            "Our theory also allows us to compare different plenoptic multiplexing schemes in terms of the signal to noise ratio in the reconstructed data.",
            "In order to do this, we need to propagate the sensor noise into the final reconstruction.",
            "We employ a standard computer vision noise model that describes it as the sum of an additive signal independent part and a signal dependent photo noise part.",
            "The signal can be approximated by the mean light transmission of the modulator itself, the signal to noise ratio in the final reconstruction.",
            "Is then given by the signal divided by the propagated or amplified noise where the noise amplification factor depends on the trace, or similarly on the singular values of the combined spatial in plenoptic multiplexing basis."
        ],
        [
            "Using this analysis, we can compare alternative multiplexing methods.",
            "For instance for color filter racing on the left, where the horizontal red line at zero, decibel is a reference, which in this case in RGB Bayer pattern we can see that alternative patterns can perform much better if the additive noise in the camera.",
            "It is dominating.",
            "I should say that the X axis in this case is a tradeoff between additive noise and photo noise, which depends on the sensor itself and also on the camera.",
            "Again, settings for lightfields assert lenslet arrays always perform best in terms of signal to noise ratio, whereas neural patterns can actually perform very well for a dominating additive noise term in the camera sum of sinusoids messed in.",
            "This case perform always worse, but we need to consider that this noise model does not consider.",
            "Sensor quantization, saturation, or motion blur in the scene.",
            "If these are desired properties for the light field to be captured, some of sinusoids and muromets may very well be better choices, as the pinhole camera."
        ],
        [
            "Here are four different simulated sensor images that show reconstruction with with a dominating additive noise part here.",
            "As expected, the neural mass and the Lenslet arrays perform very well.",
            "However, as the signal dependent photon noise term increases, even them your maths.",
            "Noise level."
        ],
        [
            "Is higher than that of a pinhole mask.",
            "So in summary.",
            "Will have to skip the summary and."
        ],
        [
            "Take questions now, thank you.",
            "Any questions can you please come up to the microphone to ask a question?",
            "I can't hear you.",
            "Come on, it's right there.",
            "Just briefly identify yourself and ask questions.",
            "Karepalli Nokia Research Center Palo Alto.",
            "I'd like to see the conclusion slide."
        ],
        [
            "Police do you wanna do it now?",
            "OK, so in summary, we have presented a theory of plenoptic multiplexing and demultiplexing.",
            "The theory allows us to identify design choices for plenoptic modulators and also to evaluate them.",
            "It enables a principled way of exploring the area of plenoptic multiplexing and also allows us to transfer knowledge from areas that are well explored such as color demosaicing to other dimensions of the plenoptic function, such as lightfields, temporal variation or spectral variation.",
            "We can compare existing designs and computationally optimize future designs of multiplexing schemes, for instance, based on the noise characteristics.",
            "Yes, curious, please come up.",
            "You didn't say much about aliasing and I was wondering if aliasing is the same in all of the multiplexing methods you presented.",
            "I was asked to repeat all questions.",
            "The question is about aliasing and the impact in this multiplexing architecture.",
            "Basically, we assume that the signal that is incident on the sensor is suitably bandlimited.",
            "That means basically for all these attenuation filters we assume.",
            "That that that bent limitation is this is the common notion of bent limitation.",
            "Basically that we have that the copies do not overlap, and in the free domain for the reflective elements it's a little bit different.",
            "In the supplemental material.",
            "So we show this.",
            "There we have to assume that the light field is constant over one single small reflective element.",
            "This is basically the notion of aliasing that we have in this case.",
            "Does this answer your question?",
            "Well, I guess so.",
            "So in that case I'm not sure how you compare the existing designs.",
            "If the sort of assumptions on aliasing are not quite exactly the same.",
            "Um?",
            "Yes so.",
            "Basically, we we assume that at this age using assumption is sort of a similar one in this case and we compare this, I think with that we're going to move to the next speaker.",
            "Let's thank the speakers.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With that I'm just going to quickly introduce the speakers.",
                    "label": 0
                },
                {
                    "sent": "The first speakers are on paper dieteria plenoptic multiplexing, and the authors are evil or K. Gordon Wetzstein and Balkan heidrick.",
                    "label": 0
                },
                {
                    "sent": "OK, good morning and thank you for the introduction.",
                    "label": 0
                },
                {
                    "sent": "Work.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We are talking panoptic multiplexing.",
                    "label": 0
                },
                {
                    "sent": "In the last couple of years we have seen tremendous progress in the area that is now called computational photography.",
                    "label": 0
                },
                {
                    "sent": "We have seen how light fields can be acquired in digital cameras.",
                    "label": 1
                },
                {
                    "sent": "How multispectral imaging can work, and of course, temporal light variation has been of interest for a long time.",
                    "label": 1
                },
                {
                    "sent": "And the goal of all these works was basically to extend the capabilities of traditional film based cameras to be more flexible and in a way a perfect plenoptic imager that we're going to talk about.",
                    "label": 0
                },
                {
                    "sent": "Would record each individual photon together with its plenoptic parameters.",
                    "label": 0
                },
                {
                    "sent": "That means a direction, wavelength and time of arrival.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And this paper is basically introducing a mathematical framework for such a device, and it is.",
                    "label": 0
                },
                {
                    "sent": "This framework is general enough that it is describing the most plenoptic multiplexing algorithms that are around so far and devices, and by doing so, it basically enables comparative analysis of these different designs which we exemplify by performing noise analysis for color and light field multiplexing within a common framework.",
                    "label": 1
                },
                {
                    "sent": "But maybe most interesting Lee.",
                    "label": 1
                },
                {
                    "sent": "Our our theory allows us to enumerate a fixed number of design choices for plenoptic multiplexing algorithms.",
                    "label": 0
                },
                {
                    "sent": "So in order to introduce our theory, I would like to reiterate how is sensor is actually recording light.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For that, I'd like to employ the field of.",
                    "label": 0
                },
                {
                    "sent": "Buckets analogy here.",
                    "label": 0
                },
                {
                    "sent": "So we have a field filled with buckets and it's raining, and all those raindrops represent photons and buckets ours.",
                    "label": 0
                },
                {
                    "sent": "Our sensor elements of course, because they are photons, they.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Have a certain wavelength so there's a color variation.",
                    "label": 0
                },
                {
                    "sent": "We also have temporal and direction of variation and the back of the bucket.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Collecting all these raindrops that means.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "They're integrating all the photons.",
                    "label": 0
                },
                {
                    "sent": "Regardless of incident, direction, time of arrival or wavelength, and the same.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It's in a real scene as shown here on the right.",
                    "label": 0
                },
                {
                    "sent": "We have light source emitting photons which hit some scene surface is they are being reflected, bounce around and.",
                    "label": 0
                },
                {
                    "sent": "In the end, being focused onto the sensor where sensor element is collecting all these photons and integrating in the same way as with the buckets and this integration is very high dimensional, destroys information by averaging.",
                    "label": 0
                },
                {
                    "sent": "It's present in the plenoptic function and the task of plenoptic multiplexing as we define it is to at least partially prevent this loss of information.",
                    "label": 1
                },
                {
                    "sent": "For this we have basically three choices.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We have multi sensor capture which means we split up the light and record with different sensors differently filtered versions of the light.",
                    "label": 0
                },
                {
                    "sent": "This is usually expensive and bulky.",
                    "label": 0
                },
                {
                    "sent": "We can do some time sequential capture.",
                    "label": 0
                },
                {
                    "sent": "This limits US to static scenes and the third option is multiplexing which we're covering in this paper here and there.",
                    "label": 0
                },
                {
                    "sent": "We are trading spatial resolution for plenoptic resolution.",
                    "label": 0
                },
                {
                    "sent": "That means individual pixels are filtered differently to give us more information about the plenoptic function and in our opinion this is the most.",
                    "label": 0
                },
                {
                    "sent": "Flexible approach in the most scalable approach that might eventually enable consumer products here.",
                    "label": 0
                },
                {
                    "sent": "This is also motivated by the increase in pixels that can be produced economically.",
                    "label": 0
                },
                {
                    "sent": "Which is increasing exponentially while the optics stays more or less fixed.",
                    "label": 0
                },
                {
                    "sent": "That means we can use these additional pixels in some meaningful way by using the vocal and optic multiplexing.",
                    "label": 0
                },
                {
                    "sent": "So for describing our model, basically let me first.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Introduce the image formation model so we have the image intensity which is.",
                    "label": 1
                },
                {
                    "sent": "Independent order continuous spatial variable X here and this is given in sensor space by an integral over the plenoptic function or Lambda here.",
                    "label": 0
                },
                {
                    "sent": "And P is basically collecting all the plenoptic para meters.",
                    "label": 0
                },
                {
                    "sent": "That means direction, wavelength and time, and this integral is happening on the sensor.",
                    "label": 1
                },
                {
                    "sent": "Of course we have a plan optic integration domain.",
                    "label": 0
                },
                {
                    "sent": "That means we have a restricted cone of race that are being integrated that pass through the aperture times some spectral region and temporal region of interest.",
                    "label": 1
                },
                {
                    "sent": "Let me show you some example how we can modify this now with filters that picked.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Certain values of this function so we have signal incident on the sensor here, and by putting different filters in front of the array we can for example sample different color values like shown here red, green and blue.",
                    "label": 0
                },
                {
                    "sent": "This is familiar to everybody but also light fields by putting lens loads in the same pixels we could reckon.",
                    "label": 0
                },
                {
                    "sent": "Put basically a directional filter that records different light directions in different pixels and a similar thing happens for so called mass based light fields where similar pixels are recording similar cone cones of race here.",
                    "label": 0
                },
                {
                    "sent": "To accommodate for that in our framework, no.",
                    "label": 0
                },
                {
                    "sent": "Sorry if we have those different filters before they are repeating.",
                    "label": 0
                },
                {
                    "sent": "Basically we are using and repeating structure and one such.",
                    "label": 0
                },
                {
                    "sent": "Thing is called a super pixel.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To accommodate for this thing in our framework, we introduce something called a plenoptic modulator, which is a function that can attenuate race based on their plenoptic parameters.",
                    "label": 0
                },
                {
                    "sent": "And as we show in our paper, we can actually separate this, usually for the Super pixel layout into a separable spatial basis and plenoptic basis.",
                    "label": 1
                },
                {
                    "sent": "Let me show you one example here.",
                    "label": 0
                },
                {
                    "sent": "Uh, 1D color filter array to give you some intuition.",
                    "label": 1
                },
                {
                    "sent": "Basically, the spatial basis here.",
                    "label": 0
                },
                {
                    "sent": "This is the first one is selecting a certain plenoptic basis, which is a spectral filter in this case, for each of the pixel values, and this is a Cartesian product.",
                    "label": 0
                },
                {
                    "sent": "Here we can do the same thing for light field, so this is light field imaging.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Through an array of pin holes and this time our plan optic basis is a rectangular function which is selecting certain cone of race for each of the pixels and our spatial basis is still picking a certain cone of race for each of them and we will see more general examples later.",
                    "label": 0
                },
                {
                    "sent": "Why we actually call these function Sigma and Pi here basis can be immediately seen if we plug in this definition into our image formation model.",
                    "label": 0
                },
                {
                    "sent": "It basically shows that the.",
                    "label": 0
                },
                {
                    "sent": "The image formation is a projection into the plenoptic basis of the plenoptic function, so we have the plan optic function.",
                    "label": 0
                },
                {
                    "sent": "Here it is being projected into the spaces and afterwards it's mixed on the sensor by the spatial basis.",
                    "label": 0
                },
                {
                    "sent": "So this leads to.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Main results of all paper which can be summarized in two theorems and the first is this plenoptic spatial multiplexing theorem, which states that the interpolated measurement channels are locally related to the plenoptic function, where measurement channel now is a collection of pixels with the same filter which is filled up by interpolation like these blue, green and red channels here and.",
                    "label": 0
                },
                {
                    "sent": "Yes we can.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Compute the plan or the projection of the panoptic function from that, and it's similar theorem is the plenoptic foreign multiplexing theorem which analyzes the same thing and through domain we see for transform here and it states that the full channels which are the red box here like one of those tiles, the different tiles are the food channels are locali related to the Fourier transform of the plug-in optic function.",
                    "label": 1
                },
                {
                    "sent": "That means locality here means basically that the correlation this linear system that we see here.",
                    "label": 0
                },
                {
                    "sent": "Is in dependently solvable for every of the spatial tire frequencies.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Shown here, so together these two theorems basically form a unified view online optical reconstruction.",
                    "label": 0
                },
                {
                    "sent": "First we have sampling process which generates a repeating pattern in spatial domain as shown here or or tiles in the full domain as shown here.",
                    "label": 0
                },
                {
                    "sent": "Then reconstruction in a signal processing sense basically includes spatial interpolation or extraction of tiles using a weighting function followed by channel re correlation in any case.",
                    "label": 0
                },
                {
                    "sent": "Have shown here which is local in either the spatial pixel position.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Or the local frequency?",
                    "label": 0
                },
                {
                    "sent": "This diagram shows that we can decompose any algorithm here into basically 3 design choices that we have, and the first one is the choice of the spatial and the plenoptic basis, particular their number in shape, where the spatial basis determining the sampling layout and the mixture properties.",
                    "label": 1
                },
                {
                    "sent": "Where is the plan Optic base is determining the subspace of the plenoptic function that can be represented as the second choice.",
                    "label": 1
                },
                {
                    "sent": "We have the interpolation scheme.",
                    "label": 0
                },
                {
                    "sent": "We can use interpolation with priors, edge preserving, interpolation and so on and.",
                    "label": 0
                },
                {
                    "sent": "The 3rd and maybe most interesting thing is that we can choose the decorrelation or reconstruction scheme.",
                    "label": 0
                },
                {
                    "sent": "I mean, usually we employ linear reconstruction, but we can also go and take nonlinear reconstructions and enforce sparseness of the recovery treatment signal or a particular data dependent models and so on to fill our theory with some meaning.",
                    "label": 0
                },
                {
                    "sent": "My colleague got in which time is now going to show you some examples of the application.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you Eva.",
                    "label": 0
                },
                {
                    "sent": "Let me just say that I'm very excited to be here today, but we don't have much time left so.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Jump right into an intuitive example for Thierry, which most of you should be familiar with, which is emerging with color filter arrays.",
                    "label": 1
                },
                {
                    "sent": "So when you capture us 3 scene with a monochromatic sensor through a color filter array, every pixel it sends a single color channel only.",
                    "label": 0
                },
                {
                    "sent": "Reconstruction in full resolution for an RGB image can be performed by interpolating all the color channels to every single pixel.",
                    "label": 0
                },
                {
                    "sent": "Now, it's well known that periodic patterns such as the color filter array have it for you transform that consists of a sparse set of direct peaks.",
                    "label": 0
                },
                {
                    "sent": "So the multiplication that the color filter array does on the incident light in the spatial domain becomes a convolution in the Fourier domain and the Fourier transform of the sensor image is basically a collection of 2D frequency tiles centered as those direct peaks.",
                    "label": 0
                },
                {
                    "sent": "Reconstruction in the Fourier domain can be performed by decorrelating those tiles and transforming them back into the spatial domain.",
                    "label": 0
                },
                {
                    "sent": "In this case the spatial reconstruction gives better result because we can use.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "More sophisticated interpolation schemes.",
                    "label": 0
                },
                {
                    "sent": "Let me now show you how this can be extended to light fields and in the paper we also derive this for other plenoptic dimensions.",
                    "label": 0
                },
                {
                    "sent": "Like fields that are captured with non refractive attenuation masks other than pinhole arrays have usually been reconstructed in the foyer in the Fourier domain, so we assume an attenuation Max to be placed at a distance set from the sensor plane and use the two plane parameterization of the light field where the two planes have a unit distance.",
                    "label": 0
                },
                {
                    "sent": "Light Ray XV is then attenuated on the mask plane at the position X -- Z V. The sensor image is formed by integrating over the directional domain at every sensor pixel.",
                    "label": 0
                },
                {
                    "sent": "If we replace the attenuation function M here by the inverse of its Fourier transform, we basically get a formulation that can be separated into a purely spatial and purely plenoptic or directional part.",
                    "label": 0
                },
                {
                    "sent": "In this case, these are basically our spatial and our plenoptic basis functions.",
                    "label": 0
                },
                {
                    "sent": "Although both the spatial and the plan optic basis are the Fourier transform and the inverse Fourier transform, respectively, this formulation actually allows a spatial per pixel reconstruction, just like in the case of color demosaicing.",
                    "label": 0
                },
                {
                    "sent": "Using our theory in the.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Paper in the supplemental material, we show how our theory applies to a variety of light field cameras, including those with non refractive estimation methods and those with refractive optical elements.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here's an example of Lightfield captured through a sum of sinusoids mask.",
                    "label": 0
                },
                {
                    "sent": "The data set is taken from the depth photography paper and on the left and in the middle we see reconstructions in the Fourier domain and on the right is spatial reconstruction.",
                    "label": 1
                },
                {
                    "sent": "Using our theory coming for your ringing artifacts in the Fourier domain can be avoided with the space.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Reconstruction the same applies to data sets that are captured with alternative attenuation methods such as this mural pattern here.",
                    "label": 0
                },
                {
                    "sent": "This is from the Shields paper and again, especially reconstruction can perform better than a full year reconstruction, although we only prove our theory for linear upsampling filters.",
                    "label": 0
                },
                {
                    "sent": "In practice it works quite well with nonlinear filters such as the spatial joint bilateral filter as seen on the right here.",
                    "label": 1
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Our theory also allows us to compare different plenoptic multiplexing schemes in terms of the signal to noise ratio in the reconstructed data.",
                    "label": 0
                },
                {
                    "sent": "In order to do this, we need to propagate the sensor noise into the final reconstruction.",
                    "label": 1
                },
                {
                    "sent": "We employ a standard computer vision noise model that describes it as the sum of an additive signal independent part and a signal dependent photo noise part.",
                    "label": 1
                },
                {
                    "sent": "The signal can be approximated by the mean light transmission of the modulator itself, the signal to noise ratio in the final reconstruction.",
                    "label": 0
                },
                {
                    "sent": "Is then given by the signal divided by the propagated or amplified noise where the noise amplification factor depends on the trace, or similarly on the singular values of the combined spatial in plenoptic multiplexing basis.",
                    "label": 1
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Using this analysis, we can compare alternative multiplexing methods.",
                    "label": 0
                },
                {
                    "sent": "For instance for color filter racing on the left, where the horizontal red line at zero, decibel is a reference, which in this case in RGB Bayer pattern we can see that alternative patterns can perform much better if the additive noise in the camera.",
                    "label": 0
                },
                {
                    "sent": "It is dominating.",
                    "label": 0
                },
                {
                    "sent": "I should say that the X axis in this case is a tradeoff between additive noise and photo noise, which depends on the sensor itself and also on the camera.",
                    "label": 0
                },
                {
                    "sent": "Again, settings for lightfields assert lenslet arrays always perform best in terms of signal to noise ratio, whereas neural patterns can actually perform very well for a dominating additive noise term in the camera sum of sinusoids messed in.",
                    "label": 0
                },
                {
                    "sent": "This case perform always worse, but we need to consider that this noise model does not consider.",
                    "label": 1
                },
                {
                    "sent": "Sensor quantization, saturation, or motion blur in the scene.",
                    "label": 0
                },
                {
                    "sent": "If these are desired properties for the light field to be captured, some of sinusoids and muromets may very well be better choices, as the pinhole camera.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here are four different simulated sensor images that show reconstruction with with a dominating additive noise part here.",
                    "label": 0
                },
                {
                    "sent": "As expected, the neural mass and the Lenslet arrays perform very well.",
                    "label": 0
                },
                {
                    "sent": "However, as the signal dependent photon noise term increases, even them your maths.",
                    "label": 0
                },
                {
                    "sent": "Noise level.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is higher than that of a pinhole mask.",
                    "label": 0
                },
                {
                    "sent": "So in summary.",
                    "label": 0
                },
                {
                    "sent": "Will have to skip the summary and.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Take questions now, thank you.",
                    "label": 1
                },
                {
                    "sent": "Any questions can you please come up to the microphone to ask a question?",
                    "label": 0
                },
                {
                    "sent": "I can't hear you.",
                    "label": 0
                },
                {
                    "sent": "Come on, it's right there.",
                    "label": 0
                },
                {
                    "sent": "Just briefly identify yourself and ask questions.",
                    "label": 0
                },
                {
                    "sent": "Karepalli Nokia Research Center Palo Alto.",
                    "label": 0
                },
                {
                    "sent": "I'd like to see the conclusion slide.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Police do you wanna do it now?",
                    "label": 0
                },
                {
                    "sent": "OK, so in summary, we have presented a theory of plenoptic multiplexing and demultiplexing.",
                    "label": 1
                },
                {
                    "sent": "The theory allows us to identify design choices for plenoptic modulators and also to evaluate them.",
                    "label": 1
                },
                {
                    "sent": "It enables a principled way of exploring the area of plenoptic multiplexing and also allows us to transfer knowledge from areas that are well explored such as color demosaicing to other dimensions of the plenoptic function, such as lightfields, temporal variation or spectral variation.",
                    "label": 1
                },
                {
                    "sent": "We can compare existing designs and computationally optimize future designs of multiplexing schemes, for instance, based on the noise characteristics.",
                    "label": 0
                },
                {
                    "sent": "Yes, curious, please come up.",
                    "label": 0
                },
                {
                    "sent": "You didn't say much about aliasing and I was wondering if aliasing is the same in all of the multiplexing methods you presented.",
                    "label": 0
                },
                {
                    "sent": "I was asked to repeat all questions.",
                    "label": 0
                },
                {
                    "sent": "The question is about aliasing and the impact in this multiplexing architecture.",
                    "label": 0
                },
                {
                    "sent": "Basically, we assume that the signal that is incident on the sensor is suitably bandlimited.",
                    "label": 0
                },
                {
                    "sent": "That means basically for all these attenuation filters we assume.",
                    "label": 0
                },
                {
                    "sent": "That that that bent limitation is this is the common notion of bent limitation.",
                    "label": 0
                },
                {
                    "sent": "Basically that we have that the copies do not overlap, and in the free domain for the reflective elements it's a little bit different.",
                    "label": 0
                },
                {
                    "sent": "In the supplemental material.",
                    "label": 0
                },
                {
                    "sent": "So we show this.",
                    "label": 0
                },
                {
                    "sent": "There we have to assume that the light field is constant over one single small reflective element.",
                    "label": 0
                },
                {
                    "sent": "This is basically the notion of aliasing that we have in this case.",
                    "label": 0
                },
                {
                    "sent": "Does this answer your question?",
                    "label": 0
                },
                {
                    "sent": "Well, I guess so.",
                    "label": 0
                },
                {
                    "sent": "So in that case I'm not sure how you compare the existing designs.",
                    "label": 0
                },
                {
                    "sent": "If the sort of assumptions on aliasing are not quite exactly the same.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Yes so.",
                    "label": 0
                },
                {
                    "sent": "Basically, we we assume that at this age using assumption is sort of a similar one in this case and we compare this, I think with that we're going to move to the next speaker.",
                    "label": 0
                },
                {
                    "sent": "Let's thank the speakers.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}