{
    "id": "txvpphvkca7z4rms3pjen6wpkpitn4wv",
    "title": "Collecting, Integrating, Enriching and Republishing Open City Data as Linked Data",
    "info": {
        "author": [
            "Stefan Bischof, Siemens AG \u00d6sterreich"
        ],
        "published": "Nov. 10, 2015",
        "recorded": "October 2015",
        "category": [
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/iswc2015_bischof_linked_data/",
    "segmentation": [
        [
            "So thank you for the possibility to present our work here today.",
            "This is joint work by Siemens, Austria and the economical University in Vienna.",
            "And in Simmons, we have a pact."
        ],
        [
            "Use case, which is to compare city data, different kinds of cities.",
            "So which city is the best?",
            "Depending on the use case of course."
        ],
        [
            "And the example that we have is the European Green City Index, which was published by Siemens a few years ago already, which compares different European cities on how green or how sustainable they are.",
            "And studies like this are usually created by manually collecting this data from the different statistical offices.",
            "And then computing these indicators.",
            "Like CO2 or energy or for buildings.",
            "And then ranking the cities in the end.",
            "But we said at least the quantitative indicators should also be available from open data sources."
        ],
        [
            "So we built city data pipeline.",
            "Which is a software.",
            "Package which uses standard semantic web technologies and we have three parts of this.",
            "The first one is data integration, where we first crawl different open data sources and integrate it with an ontology together in one big data set.",
            "We also have lightweight provenance information and put all the cities in a temporal and spatial context.",
            "The second part is the data refinement where we clean the data bit and doing the enrichment, which essentially means that we are approximating missing values.",
            "But I come to this on the next slide in a second.",
            "The last part then estate the publication where we publish all the data that we got and approximated values as linked open data and on a sparkle endpoint as well.",
            "So back to the."
        ],
        [
            "Missing values.",
            "So when you integrate this kind of statistical numerical data from open data sources, you will find out that's not specific to our use case, but you will find out that these datasets have lots of missing values.",
            "So for example, if we.",
            "If we organize our data in this kind of matrix where we have the cities as rows and we have the indicators as columns.",
            "We see that for years that for example, we have 51% missing values.",
            "And it's even worse for you in data where we have 97% with missing values, and this is actually not very surprising, because as usual for this kind of web data you have.",
            "For.",
            "For a few indicators, you have lots of values for many cities, but then you have lots of indicators.",
            "Very have very few values, so 97% is really not much.",
            "But then when you integrate these data sources, you also get this kind of rectangles like this one here or this one.",
            "And they're necessarily empty.",
            "And but if we want to.",
            "Compute indicators we need values for all the cities for one indicator to compute a new indicator, so we really have to somehow fill in these values."
        ],
        [
            "How can you do that?",
            "Well, there is of course several possibilities, and the first one is just to get more data from somewhere, but that's not so easy, because how do you get this data?",
            "You have to really measure the data and collected from somewhere.",
            "And eventually you will have the same problem again as."
        ],
        [
            "For if we have more data sources, we will get more of these.",
            "Empty spaces here and we will have even more missing values in the end."
        ],
        [
            "Other possibilities would be to use domain knowledge or some kind of automated automation to fill in the missing values and you come to this now."
        ],
        [
            "Domain knowledge would mean, for example in the urban audit data set of yours that we have 6262 equations for derived indicators like population density for example, and they can be computed from some base indicators, not a possibility.",
            "We would be to do unit conversions, for example using this Q DT ontology which contains all the factors for different unit conversions.",
            "We can use materialization or query writing.",
            "We also presented a paper at East WC two years ago which shows how you can compute these values with the ontology based method.",
            "But then again, we only really get very few indicators values or very few indicators, so that doesn't help us very much.",
            "The second."
        ],
        [
            "3rd possibility actually was to use some kind of automatic process.",
            "In our case it was different kinds of machine learning methods.",
            "What if we tried multiple linear regression, K nearest neighbor and random forest decision trees and we actually found that depending on the indicator, different methods work better or not so good.",
            "Validated this.",
            "Buy a tenfold cross validation and using as a quality measure the normalized root mean square error in percentage.",
            "But then again, if you want to apply this machine learning methods you already need kind of complete training sets.",
            "So how can you do that?",
            "We have two approaches."
        ],
        [
            "Or trying this.",
            "The first one is we called complete subset regression.",
            "So for each target indicator which is in the picture here in Orange.",
            "For example, this one.",
            "You try to you try to find the top K other indicators predictors based on a correlation matrix.",
            "And from this subset the green one here.",
            "So you take this green one subset as a training data set.",
            "And then try to predict the target indicator.",
            "The problem is here that finding these subsets is.",
            "This is a problem because we don't have that many values available, but we still can get some values, so let's look at."
        ],
        [
            "There are measures for this.",
            "So you see here on the vertical axis, the error measure, which is the RMS in percentage.",
            "And the number of predictors that we used.",
            "So if we go to the right from the left to the right to see here, we used two indicators to predict on target indicator and the error measures are around 2:00 or 3%.",
            "And when selecting the best method, this goes down to actually on average 0.25%.",
            "So this is very good.",
            "In this case, it actually nearly always coincides with using the KNN predictor, but that's not always the case, so here it's 4.",
            "Here you see a little difference, actually.",
            "And another interesting thing about this graph is that the models about random forest actually get worse the more indicators, the more predictors that we add.",
            "This seems very strange, but the more we go right?",
            "Actually the our complete subsets, so our training sets gets actually smaller, so we have kind of overfitting happening here.",
            "The second."
        ],
        [
            "Roach what to do some too.",
            "Extract new features by using some principle component analysis and there is a.",
            "A variant of this of principle component analysis and iterative very variant.",
            "Which first?",
            "So it takes the matrix that we have here.",
            "And fills in all the missing values by some neutral values which respect to the PCA.",
            "So the result of the PCA does not depend.",
            "Kind of on these neutral values.",
            "So this is a technique introduced by revised 97.",
            "When we have this, we we do the principle component analysis as usual and we get the principle components which is now.",
            "Our training set.",
            "And now we have a complete matrix and we can use our machine learning techniques as usual.",
            "To predict our target indicator.",
            "The advantage of this date now now we can really predict all the indicators and not only very few."
        ],
        [
            "But the error measures get worse, and that's what you see on the picture here again.",
            "Before we were around here somewhere and now we are up in the four to 8% range.",
            "But again, we see with more predictors it gets actually better.",
            "With very few predictors.",
            "The best method is usually again KNN, but then if we add more predictors up to 80 then for many indicators the linear regression is actually chosen as the best method.",
            "OK."
        ],
        [
            "Apart from that.",
            "Coming back to the to the motivation kind of to fill in these gaps.",
            "Here.",
            "That we need to make by integrating the datasets.",
            "So the idea a second idea was that we just try to fill in the values from the missing values from one data set.",
            "So the missing indicators from for UN data, for example based on the ones that we have from euro stats.",
            "So we have to have this kind of mapping from one data set to another data set.",
            "We did again this as before as approach to, so we have we filled in the missing values, but this time only for one data set and then use disorders training set to predict values from the other data set."
        ],
        [
            "So here here we see that two directions that are possible.",
            "So once from UN data to euros that.",
            "And once from yours that to you in data and we see here for the first case.",
            "The error measures are always around.",
            "You cannot see it, but it's about 14%.",
            "And it stays about the same, and even the more predictors that we have had and that is cause for you and date that we have.",
            "We have lots of cities, but most of them have nearly no indicators and the most prevalent indicator are populations or population, population, male or population female, and most of the other indicators are empty.",
            "As I said, we have 97% missing values here.",
            "So the more indicators that we add as predictors, it doesn't improve and it actually gets worse for linear regression in this case.",
            "From the other direction, from euros to U and data we have actually worse error measures for all of the methods and it gets even worse overtime.",
            "And this is because UN data.",
            "Has many more cities than yours, that of course because in euros that we have only European cities, but in UN date that we have worldwide cities and with this method we're kind of we have a European centric bias kind of so we are essentially saying that all the cities worldwide work like European cities and this is not working very well.",
            "The other this is not.",
            "No, it's not changing anymore, OK?"
        ],
        [
            "Yeah, as I said we have a.",
            "The the error is not very good and we have this kind of bias on it, but for some indicators this works quite well."
        ],
        [
            "The 2nd way to do this to to have this kind of cross data set mappings is to employ some kind of ontology learning.",
            "Actually.",
            "So we did this.",
            "To find equivalent indicators between indicate between datasets.",
            "So for example, you end date and yours that they both have indicators for population, but they're not called population.",
            "So we tried to automatically find this equivalent indicators in different datasets.",
            "And we do this by it's kind of standard.",
            "Instance instance based mapping generation.",
            "So we do this.",
            "We do linear regression on pairs of indicators.",
            "So we just take any pair of indicators from the two different sources and see if the values coincide.",
            "If there are the same values for the same cities, it's the same indicator.",
            "We can also find linear dependencies of pairs of indicators, so if one of them the area for example, would be in one data set in square kilometers.",
            "And the other one in square miles.",
            "We can find this linear dependency and and see that this is essentially the same indicator, but just a unit conversion."
        ],
        [
            "OK, to compare the different methods that we have.",
            "We had these two approaches.",
            "To fill in the missing values, one of them was this complete subsets which had actually very good results.",
            "0.25% are MSE, but covers only very few cities and indicators.",
            "Then we had the second approach of the principle component regression, which predicts more.",
            "Actually, nearly all missing values, but the quality was not as good anymore, so we were around 3% here.",
            "Then we tried this cross state to set prediction in general to fill in the missing the boxes that we created by integrating the data centers.",
            "This had very bad error rates and it depends on from which data set you predicted into which data set so.",
            "There are some problems there as well, but it would be very interesting to find these mappings between datasets.",
            "The last thing that I just presented was this ontology learning from instance data and we found there are several relationships, equivalent properties, mostly population.",
            "But also linear dependencies between.",
            "Indicators.",
            "But of course, to have this to do this kind of machine learning, this linear regression, we need data from overlapping cities from all of the data sources.",
            "So in the end.",
            "But then what do we want to do?",
            "We also want to not only have European cities, we also want to have US cities, but.",
            "As I said here, we need datasets from overlapping cities and European USA.",
            "There are distinct, so we need some kind of something in there between that is able to map between these datasets.",
            "And UN data is doing that partly as we have also seen with this bad error rates before.",
            "But it's it's possible, but it's not very well so far, so there's still optimization.",
            "Potential."
        ],
        [
            "So we have all these states that we have the predictions.",
            "Some of them are good, some of them are not so good.",
            "But we also left out the very bad ones.",
            "And all of this is available as linked open data.",
            "We have also has partial end point.",
            "Where we have the original data, we have the predicted values and all of the predicted values.",
            "Have there are measures.",
            "The error estimates connotated with it.",
            "So you can always see how good do we estimate this value to be.",
            "This is available online so everybody can use it."
        ],
        [
            "And this was what we're currently working on.",
            "There is lots of different ways where you can go to use standard vocabularies like prefer the RDF data cubes, and that's what we're doing now.",
            "Use other methods for this machine learning like SVM's or robust linear regression.",
            "And then we also found out that if we have time series because we have data from several years into this time series analysis, we could also get better values.",
            "Or add more data sources.",
            "Of course, as I said and integrate this data sources so.",
            "In the end, our assumption is still our predictions will get better and more data that we can integrate.",
            "Thanks for your attention.",
            "Hello, my question is in general what are the main benefits of replacing City data wrestling data?",
            "Well, in the end we can compute our indicators that we have.",
            "And you have.",
            "It's already open source.",
            "We just fill in the missing values so it's already open data.",
            "But now we have linked open data.",
            "So that you can use any kind of linked open data tool on top of it.",
            "Can do reasoning whatever whatever tool you have.",
            "OK, I have another question.",
            "How long it takes to compute the indicators you have so?",
            "To fill in the missing values you mean.",
            "The thing is we are doing nowadays 10 fold cross validation, so we it's always 10 models.",
            "So we trained 10 models or actually 10 models for each method, which means 30 models.",
            "For each of the target indicators.",
            "So we have around 200 indicators, so we have 200 indicators and 30 models for each of these indicators.",
            "So this takes maybe five hours I think, so it takes some time, yeah?",
            "OK, what about the updates?",
            "Updates, so this is mainly statistical data, so it doesn't change very often.",
            "We sometimes call the data again, but it's like yearly data usually, so we don't have to do it very often.",
            "Last question is what is the best city then?",
            "According to this, what is the best city?",
            "Well, in the Green City index?",
            "I can tell you about the Green City index.",
            "There it was Copenhagen, but it's already a few years old and it depends on how you compute your indicators, of course.",
            "OK."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So thank you for the possibility to present our work here today.",
                    "label": 0
                },
                {
                    "sent": "This is joint work by Siemens, Austria and the economical University in Vienna.",
                    "label": 0
                },
                {
                    "sent": "And in Simmons, we have a pact.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Use case, which is to compare city data, different kinds of cities.",
                    "label": 0
                },
                {
                    "sent": "So which city is the best?",
                    "label": 1
                },
                {
                    "sent": "Depending on the use case of course.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the example that we have is the European Green City Index, which was published by Siemens a few years ago already, which compares different European cities on how green or how sustainable they are.",
                    "label": 1
                },
                {
                    "sent": "And studies like this are usually created by manually collecting this data from the different statistical offices.",
                    "label": 0
                },
                {
                    "sent": "And then computing these indicators.",
                    "label": 0
                },
                {
                    "sent": "Like CO2 or energy or for buildings.",
                    "label": 0
                },
                {
                    "sent": "And then ranking the cities in the end.",
                    "label": 0
                },
                {
                    "sent": "But we said at least the quantitative indicators should also be available from open data sources.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we built city data pipeline.",
                    "label": 1
                },
                {
                    "sent": "Which is a software.",
                    "label": 0
                },
                {
                    "sent": "Package which uses standard semantic web technologies and we have three parts of this.",
                    "label": 1
                },
                {
                    "sent": "The first one is data integration, where we first crawl different open data sources and integrate it with an ontology together in one big data set.",
                    "label": 1
                },
                {
                    "sent": "We also have lightweight provenance information and put all the cities in a temporal and spatial context.",
                    "label": 0
                },
                {
                    "sent": "The second part is the data refinement where we clean the data bit and doing the enrichment, which essentially means that we are approximating missing values.",
                    "label": 0
                },
                {
                    "sent": "But I come to this on the next slide in a second.",
                    "label": 0
                },
                {
                    "sent": "The last part then estate the publication where we publish all the data that we got and approximated values as linked open data and on a sparkle endpoint as well.",
                    "label": 0
                },
                {
                    "sent": "So back to the.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Missing values.",
                    "label": 0
                },
                {
                    "sent": "So when you integrate this kind of statistical numerical data from open data sources, you will find out that's not specific to our use case, but you will find out that these datasets have lots of missing values.",
                    "label": 0
                },
                {
                    "sent": "So for example, if we.",
                    "label": 0
                },
                {
                    "sent": "If we organize our data in this kind of matrix where we have the cities as rows and we have the indicators as columns.",
                    "label": 0
                },
                {
                    "sent": "We see that for years that for example, we have 51% missing values.",
                    "label": 0
                },
                {
                    "sent": "And it's even worse for you in data where we have 97% with missing values, and this is actually not very surprising, because as usual for this kind of web data you have.",
                    "label": 0
                },
                {
                    "sent": "For.",
                    "label": 0
                },
                {
                    "sent": "For a few indicators, you have lots of values for many cities, but then you have lots of indicators.",
                    "label": 0
                },
                {
                    "sent": "Very have very few values, so 97% is really not much.",
                    "label": 0
                },
                {
                    "sent": "But then when you integrate these data sources, you also get this kind of rectangles like this one here or this one.",
                    "label": 0
                },
                {
                    "sent": "And they're necessarily empty.",
                    "label": 0
                },
                {
                    "sent": "And but if we want to.",
                    "label": 0
                },
                {
                    "sent": "Compute indicators we need values for all the cities for one indicator to compute a new indicator, so we really have to somehow fill in these values.",
                    "label": 1
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "How can you do that?",
                    "label": 1
                },
                {
                    "sent": "Well, there is of course several possibilities, and the first one is just to get more data from somewhere, but that's not so easy, because how do you get this data?",
                    "label": 1
                },
                {
                    "sent": "You have to really measure the data and collected from somewhere.",
                    "label": 0
                },
                {
                    "sent": "And eventually you will have the same problem again as.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For if we have more data sources, we will get more of these.",
                    "label": 0
                },
                {
                    "sent": "Empty spaces here and we will have even more missing values in the end.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Other possibilities would be to use domain knowledge or some kind of automated automation to fill in the missing values and you come to this now.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Domain knowledge would mean, for example in the urban audit data set of yours that we have 6262 equations for derived indicators like population density for example, and they can be computed from some base indicators, not a possibility.",
                    "label": 1
                },
                {
                    "sent": "We would be to do unit conversions, for example using this Q DT ontology which contains all the factors for different unit conversions.",
                    "label": 1
                },
                {
                    "sent": "We can use materialization or query writing.",
                    "label": 0
                },
                {
                    "sent": "We also presented a paper at East WC two years ago which shows how you can compute these values with the ontology based method.",
                    "label": 0
                },
                {
                    "sent": "But then again, we only really get very few indicators values or very few indicators, so that doesn't help us very much.",
                    "label": 0
                },
                {
                    "sent": "The second.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "3rd possibility actually was to use some kind of automatic process.",
                    "label": 0
                },
                {
                    "sent": "In our case it was different kinds of machine learning methods.",
                    "label": 0
                },
                {
                    "sent": "What if we tried multiple linear regression, K nearest neighbor and random forest decision trees and we actually found that depending on the indicator, different methods work better or not so good.",
                    "label": 1
                },
                {
                    "sent": "Validated this.",
                    "label": 0
                },
                {
                    "sent": "Buy a tenfold cross validation and using as a quality measure the normalized root mean square error in percentage.",
                    "label": 1
                },
                {
                    "sent": "But then again, if you want to apply this machine learning methods you already need kind of complete training sets.",
                    "label": 0
                },
                {
                    "sent": "So how can you do that?",
                    "label": 0
                },
                {
                    "sent": "We have two approaches.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Or trying this.",
                    "label": 0
                },
                {
                    "sent": "The first one is we called complete subset regression.",
                    "label": 1
                },
                {
                    "sent": "So for each target indicator which is in the picture here in Orange.",
                    "label": 1
                },
                {
                    "sent": "For example, this one.",
                    "label": 1
                },
                {
                    "sent": "You try to you try to find the top K other indicators predictors based on a correlation matrix.",
                    "label": 0
                },
                {
                    "sent": "And from this subset the green one here.",
                    "label": 0
                },
                {
                    "sent": "So you take this green one subset as a training data set.",
                    "label": 0
                },
                {
                    "sent": "And then try to predict the target indicator.",
                    "label": 0
                },
                {
                    "sent": "The problem is here that finding these subsets is.",
                    "label": 0
                },
                {
                    "sent": "This is a problem because we don't have that many values available, but we still can get some values, so let's look at.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There are measures for this.",
                    "label": 0
                },
                {
                    "sent": "So you see here on the vertical axis, the error measure, which is the RMS in percentage.",
                    "label": 0
                },
                {
                    "sent": "And the number of predictors that we used.",
                    "label": 0
                },
                {
                    "sent": "So if we go to the right from the left to the right to see here, we used two indicators to predict on target indicator and the error measures are around 2:00 or 3%.",
                    "label": 0
                },
                {
                    "sent": "And when selecting the best method, this goes down to actually on average 0.25%.",
                    "label": 0
                },
                {
                    "sent": "So this is very good.",
                    "label": 0
                },
                {
                    "sent": "In this case, it actually nearly always coincides with using the KNN predictor, but that's not always the case, so here it's 4.",
                    "label": 0
                },
                {
                    "sent": "Here you see a little difference, actually.",
                    "label": 0
                },
                {
                    "sent": "And another interesting thing about this graph is that the models about random forest actually get worse the more indicators, the more predictors that we add.",
                    "label": 0
                },
                {
                    "sent": "This seems very strange, but the more we go right?",
                    "label": 0
                },
                {
                    "sent": "Actually the our complete subsets, so our training sets gets actually smaller, so we have kind of overfitting happening here.",
                    "label": 0
                },
                {
                    "sent": "The second.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Roach what to do some too.",
                    "label": 0
                },
                {
                    "sent": "Extract new features by using some principle component analysis and there is a.",
                    "label": 0
                },
                {
                    "sent": "A variant of this of principle component analysis and iterative very variant.",
                    "label": 0
                },
                {
                    "sent": "Which first?",
                    "label": 0
                },
                {
                    "sent": "So it takes the matrix that we have here.",
                    "label": 0
                },
                {
                    "sent": "And fills in all the missing values by some neutral values which respect to the PCA.",
                    "label": 1
                },
                {
                    "sent": "So the result of the PCA does not depend.",
                    "label": 0
                },
                {
                    "sent": "Kind of on these neutral values.",
                    "label": 0
                },
                {
                    "sent": "So this is a technique introduced by revised 97.",
                    "label": 0
                },
                {
                    "sent": "When we have this, we we do the principle component analysis as usual and we get the principle components which is now.",
                    "label": 0
                },
                {
                    "sent": "Our training set.",
                    "label": 0
                },
                {
                    "sent": "And now we have a complete matrix and we can use our machine learning techniques as usual.",
                    "label": 1
                },
                {
                    "sent": "To predict our target indicator.",
                    "label": 0
                },
                {
                    "sent": "The advantage of this date now now we can really predict all the indicators and not only very few.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But the error measures get worse, and that's what you see on the picture here again.",
                    "label": 0
                },
                {
                    "sent": "Before we were around here somewhere and now we are up in the four to 8% range.",
                    "label": 0
                },
                {
                    "sent": "But again, we see with more predictors it gets actually better.",
                    "label": 0
                },
                {
                    "sent": "With very few predictors.",
                    "label": 0
                },
                {
                    "sent": "The best method is usually again KNN, but then if we add more predictors up to 80 then for many indicators the linear regression is actually chosen as the best method.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Apart from that.",
                    "label": 0
                },
                {
                    "sent": "Coming back to the to the motivation kind of to fill in these gaps.",
                    "label": 0
                },
                {
                    "sent": "Here.",
                    "label": 0
                },
                {
                    "sent": "That we need to make by integrating the datasets.",
                    "label": 0
                },
                {
                    "sent": "So the idea a second idea was that we just try to fill in the values from the missing values from one data set.",
                    "label": 0
                },
                {
                    "sent": "So the missing indicators from for UN data, for example based on the ones that we have from euro stats.",
                    "label": 0
                },
                {
                    "sent": "So we have to have this kind of mapping from one data set to another data set.",
                    "label": 0
                },
                {
                    "sent": "We did again this as before as approach to, so we have we filled in the missing values, but this time only for one data set and then use disorders training set to predict values from the other data set.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here here we see that two directions that are possible.",
                    "label": 0
                },
                {
                    "sent": "So once from UN data to euros that.",
                    "label": 0
                },
                {
                    "sent": "And once from yours that to you in data and we see here for the first case.",
                    "label": 0
                },
                {
                    "sent": "The error measures are always around.",
                    "label": 0
                },
                {
                    "sent": "You cannot see it, but it's about 14%.",
                    "label": 0
                },
                {
                    "sent": "And it stays about the same, and even the more predictors that we have had and that is cause for you and date that we have.",
                    "label": 0
                },
                {
                    "sent": "We have lots of cities, but most of them have nearly no indicators and the most prevalent indicator are populations or population, population, male or population female, and most of the other indicators are empty.",
                    "label": 0
                },
                {
                    "sent": "As I said, we have 97% missing values here.",
                    "label": 0
                },
                {
                    "sent": "So the more indicators that we add as predictors, it doesn't improve and it actually gets worse for linear regression in this case.",
                    "label": 0
                },
                {
                    "sent": "From the other direction, from euros to U and data we have actually worse error measures for all of the methods and it gets even worse overtime.",
                    "label": 0
                },
                {
                    "sent": "And this is because UN data.",
                    "label": 0
                },
                {
                    "sent": "Has many more cities than yours, that of course because in euros that we have only European cities, but in UN date that we have worldwide cities and with this method we're kind of we have a European centric bias kind of so we are essentially saying that all the cities worldwide work like European cities and this is not working very well.",
                    "label": 0
                },
                {
                    "sent": "The other this is not.",
                    "label": 0
                },
                {
                    "sent": "No, it's not changing anymore, OK?",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, as I said we have a.",
                    "label": 0
                },
                {
                    "sent": "The the error is not very good and we have this kind of bias on it, but for some indicators this works quite well.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The 2nd way to do this to to have this kind of cross data set mappings is to employ some kind of ontology learning.",
                    "label": 0
                },
                {
                    "sent": "Actually.",
                    "label": 0
                },
                {
                    "sent": "So we did this.",
                    "label": 0
                },
                {
                    "sent": "To find equivalent indicators between indicate between datasets.",
                    "label": 0
                },
                {
                    "sent": "So for example, you end date and yours that they both have indicators for population, but they're not called population.",
                    "label": 0
                },
                {
                    "sent": "So we tried to automatically find this equivalent indicators in different datasets.",
                    "label": 0
                },
                {
                    "sent": "And we do this by it's kind of standard.",
                    "label": 0
                },
                {
                    "sent": "Instance instance based mapping generation.",
                    "label": 0
                },
                {
                    "sent": "So we do this.",
                    "label": 0
                },
                {
                    "sent": "We do linear regression on pairs of indicators.",
                    "label": 1
                },
                {
                    "sent": "So we just take any pair of indicators from the two different sources and see if the values coincide.",
                    "label": 0
                },
                {
                    "sent": "If there are the same values for the same cities, it's the same indicator.",
                    "label": 0
                },
                {
                    "sent": "We can also find linear dependencies of pairs of indicators, so if one of them the area for example, would be in one data set in square kilometers.",
                    "label": 1
                },
                {
                    "sent": "And the other one in square miles.",
                    "label": 0
                },
                {
                    "sent": "We can find this linear dependency and and see that this is essentially the same indicator, but just a unit conversion.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, to compare the different methods that we have.",
                    "label": 0
                },
                {
                    "sent": "We had these two approaches.",
                    "label": 0
                },
                {
                    "sent": "To fill in the missing values, one of them was this complete subsets which had actually very good results.",
                    "label": 1
                },
                {
                    "sent": "0.25% are MSE, but covers only very few cities and indicators.",
                    "label": 1
                },
                {
                    "sent": "Then we had the second approach of the principle component regression, which predicts more.",
                    "label": 0
                },
                {
                    "sent": "Actually, nearly all missing values, but the quality was not as good anymore, so we were around 3% here.",
                    "label": 1
                },
                {
                    "sent": "Then we tried this cross state to set prediction in general to fill in the missing the boxes that we created by integrating the data centers.",
                    "label": 0
                },
                {
                    "sent": "This had very bad error rates and it depends on from which data set you predicted into which data set so.",
                    "label": 0
                },
                {
                    "sent": "There are some problems there as well, but it would be very interesting to find these mappings between datasets.",
                    "label": 0
                },
                {
                    "sent": "The last thing that I just presented was this ontology learning from instance data and we found there are several relationships, equivalent properties, mostly population.",
                    "label": 1
                },
                {
                    "sent": "But also linear dependencies between.",
                    "label": 0
                },
                {
                    "sent": "Indicators.",
                    "label": 0
                },
                {
                    "sent": "But of course, to have this to do this kind of machine learning, this linear regression, we need data from overlapping cities from all of the data sources.",
                    "label": 0
                },
                {
                    "sent": "So in the end.",
                    "label": 0
                },
                {
                    "sent": "But then what do we want to do?",
                    "label": 1
                },
                {
                    "sent": "We also want to not only have European cities, we also want to have US cities, but.",
                    "label": 0
                },
                {
                    "sent": "As I said here, we need datasets from overlapping cities and European USA.",
                    "label": 0
                },
                {
                    "sent": "There are distinct, so we need some kind of something in there between that is able to map between these datasets.",
                    "label": 0
                },
                {
                    "sent": "And UN data is doing that partly as we have also seen with this bad error rates before.",
                    "label": 0
                },
                {
                    "sent": "But it's it's possible, but it's not very well so far, so there's still optimization.",
                    "label": 0
                },
                {
                    "sent": "Potential.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we have all these states that we have the predictions.",
                    "label": 0
                },
                {
                    "sent": "Some of them are good, some of them are not so good.",
                    "label": 0
                },
                {
                    "sent": "But we also left out the very bad ones.",
                    "label": 0
                },
                {
                    "sent": "And all of this is available as linked open data.",
                    "label": 1
                },
                {
                    "sent": "We have also has partial end point.",
                    "label": 0
                },
                {
                    "sent": "Where we have the original data, we have the predicted values and all of the predicted values.",
                    "label": 0
                },
                {
                    "sent": "Have there are measures.",
                    "label": 1
                },
                {
                    "sent": "The error estimates connotated with it.",
                    "label": 0
                },
                {
                    "sent": "So you can always see how good do we estimate this value to be.",
                    "label": 0
                },
                {
                    "sent": "This is available online so everybody can use it.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And this was what we're currently working on.",
                    "label": 0
                },
                {
                    "sent": "There is lots of different ways where you can go to use standard vocabularies like prefer the RDF data cubes, and that's what we're doing now.",
                    "label": 0
                },
                {
                    "sent": "Use other methods for this machine learning like SVM's or robust linear regression.",
                    "label": 1
                },
                {
                    "sent": "And then we also found out that if we have time series because we have data from several years into this time series analysis, we could also get better values.",
                    "label": 1
                },
                {
                    "sent": "Or add more data sources.",
                    "label": 1
                },
                {
                    "sent": "Of course, as I said and integrate this data sources so.",
                    "label": 0
                },
                {
                    "sent": "In the end, our assumption is still our predictions will get better and more data that we can integrate.",
                    "label": 0
                },
                {
                    "sent": "Thanks for your attention.",
                    "label": 0
                },
                {
                    "sent": "Hello, my question is in general what are the main benefits of replacing City data wrestling data?",
                    "label": 0
                },
                {
                    "sent": "Well, in the end we can compute our indicators that we have.",
                    "label": 0
                },
                {
                    "sent": "And you have.",
                    "label": 0
                },
                {
                    "sent": "It's already open source.",
                    "label": 1
                },
                {
                    "sent": "We just fill in the missing values so it's already open data.",
                    "label": 0
                },
                {
                    "sent": "But now we have linked open data.",
                    "label": 0
                },
                {
                    "sent": "So that you can use any kind of linked open data tool on top of it.",
                    "label": 0
                },
                {
                    "sent": "Can do reasoning whatever whatever tool you have.",
                    "label": 0
                },
                {
                    "sent": "OK, I have another question.",
                    "label": 0
                },
                {
                    "sent": "How long it takes to compute the indicators you have so?",
                    "label": 0
                },
                {
                    "sent": "To fill in the missing values you mean.",
                    "label": 0
                },
                {
                    "sent": "The thing is we are doing nowadays 10 fold cross validation, so we it's always 10 models.",
                    "label": 0
                },
                {
                    "sent": "So we trained 10 models or actually 10 models for each method, which means 30 models.",
                    "label": 0
                },
                {
                    "sent": "For each of the target indicators.",
                    "label": 0
                },
                {
                    "sent": "So we have around 200 indicators, so we have 200 indicators and 30 models for each of these indicators.",
                    "label": 0
                },
                {
                    "sent": "So this takes maybe five hours I think, so it takes some time, yeah?",
                    "label": 0
                },
                {
                    "sent": "OK, what about the updates?",
                    "label": 0
                },
                {
                    "sent": "Updates, so this is mainly statistical data, so it doesn't change very often.",
                    "label": 0
                },
                {
                    "sent": "We sometimes call the data again, but it's like yearly data usually, so we don't have to do it very often.",
                    "label": 0
                },
                {
                    "sent": "Last question is what is the best city then?",
                    "label": 0
                },
                {
                    "sent": "According to this, what is the best city?",
                    "label": 0
                },
                {
                    "sent": "Well, in the Green City index?",
                    "label": 0
                },
                {
                    "sent": "I can tell you about the Green City index.",
                    "label": 0
                },
                {
                    "sent": "There it was Copenhagen, but it's already a few years old and it depends on how you compute your indicators, of course.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        }
    }
}