{
    "id": "jt7zoueffqblumu3jksjqmwr6z554ddv",
    "title": "Dyna(k): A Multi-Step Dyna Planning",
    "info": {
        "author": [
            "Hengshuai Yao, School of Creative Media, City University of Hong Kong"
        ],
        "published": "Aug. 26, 2009",
        "recorded": "June 2009",
        "category": [
            "Top->Computer Science->Artificial Intelligence->Planning and Scheduling"
        ]
    },
    "url": "http://videolectures.net/icml09_yao_dmsdp/",
    "segmentation": [
        [
            "I I'm going to talk about markets Epstein applying and it's extension of previous diner to multi step look ahead."
        ],
        [
            "So here is auto line and so we will have brief overview of planning and diner and show how to extend diner to multistep.",
            "Dine applying and the key of the merge step.",
            "Dina planning is linear multistep model and we will show how to use this linear multistep Model 2 Diner, Diner style planning and finally some experimental results."
        ],
        [
            "So planning is a model based reinforcement learning and actually the reinforcement learning book already defined this.",
            "This plan, planning and it's any computational process that takes in a model and produce policy for interacting with the model environment.",
            "So examples of multiplying include dynamic programming, heuristic touristic search and diner.",
            "So what Dina looks like?"
        ],
        [
            "So, so we are familiar with Model 3 frame model frame.",
            "Sorry model free learning like you learning Sarsa.",
            "So we have some observation and then we take action and then we have reward appearance.",
            "So we use this reward experience to learn value function and then we take action again.",
            "So Diana is special in that it's in addition there, in addition to learning step.",
            "There's also.",
            "Modeling step so it will use real world experience second time to build.",
            "Build a model of the world and then use this real world to simulate some experience and then and then use this simulated simulated experience to plan an improved value function.",
            "So different diner structure is different in the in the model part and how to simulate simulate experience?",
            "So."
        ],
        [
            "So what is my multi step diner planning look like?",
            "So multi step dining plan is very simple idea so it just replace the model part with the multi step model of the world and then simulate multi step transitioning appearance.",
            "So the model can be state state to state model and can be state state action, pair to state action pair.",
            "It depends on how you design the word model."
        ],
        [
            "So.",
            "Am artist and model is it's a key part of a multi step planning and multi step model tells user results of your current feature after many steps later and this multi symbol model can be tabular can be one step like bear my equation and can be multi step like the key step model by certain in 95 and can be linear which is proposed last year by.",
            "By starting at some coauthors so this work actually extend this, this this this tabular marks the model and linear single step model to linear multistep model."
        ],
        [
            "Anne.",
            "Here let's best look.",
            "Take a look at at the difference between single step model and multi step model.",
            "So single step model is.",
            "This case is a description of both tabular and linear function of submission of the one step linear model.",
            "Of the one step model, so just one step more ticks in a feature or state and output the expected net state or next feature and also approximately one step reward.",
            "So the key step linear model will take in a state or a feature and output.",
            "Extra expect feature after UN steps and also.",
            "A reward after N steps.",
            "So this is the key difference, and so mathematically, here's some notation."
        ],
        [
            "And single step model is described by transition matrix and one step reward vector and in the linear case is defined in this way.",
            "So here kept to fee is feature matrix and the pie is steady distribution following policy \u03c0.",
            "Here is the transition problem.",
            "Issues there, and basically you can imagine this is a normalization factor and this matrix actually mimics the.",
            "The transition probability, but you can show that I've \u03c0 is not, is not stochastic, so it's not a transition matrix, but you can imagine its function as a transition matrix in the feature space, and you can show that I've pie has a very interesting properties that is the spectral radius of a pie is smaller than one, so this is a casing we will take advantage."
        ],
        [
            "So.",
            "So we define multi step linear model in this way and if K equal to 1 we can show that it's just, it's just reduce it to single step linear model last page.",
            "And if if your linear function approximation reduces to tabular representation of the world so this will reduce to the original key step model by certain certain.",
            "95 so.",
            "So see the property and for bigger than one it is well defined because the spectral radius of \u03c0 is smaller than One South.",
            "Finally, if your key is going to Infinity, so this matrix actually going to zero, it shrinks step by step.",
            "And also your FKF key.",
            "We will be well defined.",
            "And you can show that this definition is beautiful becausw.",
            "In both linear and tabular case, this solution will give you the same solution with TD0."
        ],
        [
            "So this is how to use the key step linear model we just defined for plans for Dina planning.",
            "So planning always start from the latest value function you already learn and then.",
            "This is the planning step.",
            "After planning step you output the improved policy to your linking to your Twitter to your next step where you function.",
            "You can use that for learning.",
            "So in the planning step we sample according to some distribution.",
            "So we have imaginary feature vector and then we applied key step linear model to project step ahead to see the key step results and then.",
            "Also we project reward key step reward so finally we have imaginary key step transition experience.",
            "That is fine too dear and this and this.",
            "So you planning on this rather than the single step transition experience.",
            "And then you apply a generalized TD learning.",
            "So like this week.",
            "So."
        ],
        [
            "This is experimental results on by and change just a little bit about previous comparison of TD and Diner Linear Diner.",
            "So in last year paper.",
            "The show, I mean the paper that proposed linear Edina in UI by certain you tester and this girl is actually their terrorism which is a single step diner and their results.",
            "Actually you can see that their results suggest that in the beginning linear diner is faster than than TD but after some episodes there result suggests linear dynamic blowup error curve graph.",
            "That means their result.",
            "Suggest Dina may be poor in the long run, so this results actually is stronger than the result because we we found that.",
            "There is a three learning step size there, so which is learning with cooling step, which there's a also modeling step size and planning steps step size.",
            "So the you seem step size for the two for the three step size and the user seems scheduling for the three step size and we actually decoupling the three step size on you.",
            "Different scheduling, scheduling and so.",
            "This is a key thing that we achieve better results and also this results also suggests that multistep dynamics more advantage advantage than single Step diner.",
            "So."
        ],
        [
            "So some conclusion, sending your diner is constantly faster than TD.",
            "And multi Step Diner is still faster than linear diner.",
            "So planning for control we have some initial results.",
            "So we build a multi step linear state action to state action model and we also this model is also interesting in that it attracts the optimal tracks greedy policy and in the long run we hope that this tracking model we will model the optimum policy and we also have some experiment on mountain car and the result shows that.",
            "This tracking multistep model enables you to find the optimum policy faster than the ordinary model free.",
            "Learning algorithm such as source and cleaning.",
            "So if you're interested, we can discuss as a poster.",
            "Thank you.",
            "Question.",
            "Quickly, but I.",
            "Linear K step.",
            "Yeah.",
            "Basically saying there's a bunch of state features and we're getting going to approximate the true transition model with linear map.",
            "Yeah, and so if K was large enough that so it's sort of like extended common filter, right?",
            "It might be locally linear, but if you make a very big.",
            "Then the linear approximation will breakdown.",
            "So I think you are talking about you saying that if key big, maybe your model is not accurate.",
            "Is that what you mean, right?",
            "They don't on a large time scale.",
            "It might not be linear.",
            "That makes even make sense.",
            "Or I mean, misunderstanding.",
            "I think you are right.",
            "It's not linear, but it's a transition model can be shows that it is a power is the power is a USA.",
            "You apply linear step model multi times.",
            "So it's not linear, but it's the powers of linear.",
            "For the.",
            "For the transition proximation right?",
            "So the true transition model is indeed the power of the true transition model for one step, right?",
            "Yeah, and the linear line is the power of the linear model for one step, yeah, but while the linear model might be a good approximation for short time scales, yeah, you're right, it could be not good approximation.",
            "So in other words, there might be a good time scale.",
            "For the domain and it's going to interact with gamma, so if you make gamma, yeah, you're right, close to 1, right that you might need to control you.",
            "OK, very carefully so you don't get too much error.",
            "Does that make sense?",
            "Yeah, so my my experiment are mounting car shows that so more step you look into into the future so poor performance you get.",
            "Yeah, so some intermediate value of key.",
            "For example K equal to 5 or 10.",
            "You get best result and from 20 and later key from key equal to 20 and later your performance will degenerate.",
            "So I think it's interesting to see how much you can rely on your multi step projection and how much accuracy can you provide.",
            "But I think it's it's how program.",
            "Right, maybe there is a better way to find the market step model.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I I'm going to talk about markets Epstein applying and it's extension of previous diner to multi step look ahead.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here is auto line and so we will have brief overview of planning and diner and show how to extend diner to multistep.",
                    "label": 0
                },
                {
                    "sent": "Dine applying and the key of the merge step.",
                    "label": 0
                },
                {
                    "sent": "Dina planning is linear multistep model and we will show how to use this linear multistep Model 2 Diner, Diner style planning and finally some experimental results.",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So planning is a model based reinforcement learning and actually the reinforcement learning book already defined this.",
                    "label": 0
                },
                {
                    "sent": "This plan, planning and it's any computational process that takes in a model and produce policy for interacting with the model environment.",
                    "label": 1
                },
                {
                    "sent": "So examples of multiplying include dynamic programming, heuristic touristic search and diner.",
                    "label": 0
                },
                {
                    "sent": "So what Dina looks like?",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So, so we are familiar with Model 3 frame model frame.",
                    "label": 0
                },
                {
                    "sent": "Sorry model free learning like you learning Sarsa.",
                    "label": 0
                },
                {
                    "sent": "So we have some observation and then we take action and then we have reward appearance.",
                    "label": 0
                },
                {
                    "sent": "So we use this reward experience to learn value function and then we take action again.",
                    "label": 0
                },
                {
                    "sent": "So Diana is special in that it's in addition there, in addition to learning step.",
                    "label": 0
                },
                {
                    "sent": "There's also.",
                    "label": 0
                },
                {
                    "sent": "Modeling step so it will use real world experience second time to build.",
                    "label": 0
                },
                {
                    "sent": "Build a model of the world and then use this real world to simulate some experience and then and then use this simulated simulated experience to plan an improved value function.",
                    "label": 0
                },
                {
                    "sent": "So different diner structure is different in the in the model part and how to simulate simulate experience?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what is my multi step diner planning look like?",
                    "label": 0
                },
                {
                    "sent": "So multi step dining plan is very simple idea so it just replace the model part with the multi step model of the world and then simulate multi step transitioning appearance.",
                    "label": 1
                },
                {
                    "sent": "So the model can be state state to state model and can be state state action, pair to state action pair.",
                    "label": 0
                },
                {
                    "sent": "It depends on how you design the word model.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Am artist and model is it's a key part of a multi step planning and multi step model tells user results of your current feature after many steps later and this multi symbol model can be tabular can be one step like bear my equation and can be multi step like the key step model by certain in 95 and can be linear which is proposed last year by.",
                    "label": 1
                },
                {
                    "sent": "By starting at some coauthors so this work actually extend this, this this this tabular marks the model and linear single step model to linear multistep model.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "Here let's best look.",
                    "label": 0
                },
                {
                    "sent": "Take a look at at the difference between single step model and multi step model.",
                    "label": 0
                },
                {
                    "sent": "So single step model is.",
                    "label": 0
                },
                {
                    "sent": "This case is a description of both tabular and linear function of submission of the one step linear model.",
                    "label": 1
                },
                {
                    "sent": "Of the one step model, so just one step more ticks in a feature or state and output the expected net state or next feature and also approximately one step reward.",
                    "label": 0
                },
                {
                    "sent": "So the key step linear model will take in a state or a feature and output.",
                    "label": 1
                },
                {
                    "sent": "Extra expect feature after UN steps and also.",
                    "label": 0
                },
                {
                    "sent": "A reward after N steps.",
                    "label": 0
                },
                {
                    "sent": "So this is the key difference, and so mathematically, here's some notation.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And single step model is described by transition matrix and one step reward vector and in the linear case is defined in this way.",
                    "label": 1
                },
                {
                    "sent": "So here kept to fee is feature matrix and the pie is steady distribution following policy \u03c0.",
                    "label": 0
                },
                {
                    "sent": "Here is the transition problem.",
                    "label": 1
                },
                {
                    "sent": "Issues there, and basically you can imagine this is a normalization factor and this matrix actually mimics the.",
                    "label": 0
                },
                {
                    "sent": "The transition probability, but you can show that I've \u03c0 is not, is not stochastic, so it's not a transition matrix, but you can imagine its function as a transition matrix in the feature space, and you can show that I've pie has a very interesting properties that is the spectral radius of a pie is smaller than one, so this is a casing we will take advantage.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So we define multi step linear model in this way and if K equal to 1 we can show that it's just, it's just reduce it to single step linear model last page.",
                    "label": 0
                },
                {
                    "sent": "And if if your linear function approximation reduces to tabular representation of the world so this will reduce to the original key step model by certain certain.",
                    "label": 1
                },
                {
                    "sent": "95 so.",
                    "label": 0
                },
                {
                    "sent": "So see the property and for bigger than one it is well defined because the spectral radius of \u03c0 is smaller than One South.",
                    "label": 0
                },
                {
                    "sent": "Finally, if your key is going to Infinity, so this matrix actually going to zero, it shrinks step by step.",
                    "label": 0
                },
                {
                    "sent": "And also your FKF key.",
                    "label": 1
                },
                {
                    "sent": "We will be well defined.",
                    "label": 0
                },
                {
                    "sent": "And you can show that this definition is beautiful becausw.",
                    "label": 0
                },
                {
                    "sent": "In both linear and tabular case, this solution will give you the same solution with TD0.",
                    "label": 1
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is how to use the key step linear model we just defined for plans for Dina planning.",
                    "label": 0
                },
                {
                    "sent": "So planning always start from the latest value function you already learn and then.",
                    "label": 0
                },
                {
                    "sent": "This is the planning step.",
                    "label": 0
                },
                {
                    "sent": "After planning step you output the improved policy to your linking to your Twitter to your next step where you function.",
                    "label": 0
                },
                {
                    "sent": "You can use that for learning.",
                    "label": 0
                },
                {
                    "sent": "So in the planning step we sample according to some distribution.",
                    "label": 0
                },
                {
                    "sent": "So we have imaginary feature vector and then we applied key step linear model to project step ahead to see the key step results and then.",
                    "label": 0
                },
                {
                    "sent": "Also we project reward key step reward so finally we have imaginary key step transition experience.",
                    "label": 0
                },
                {
                    "sent": "That is fine too dear and this and this.",
                    "label": 0
                },
                {
                    "sent": "So you planning on this rather than the single step transition experience.",
                    "label": 0
                },
                {
                    "sent": "And then you apply a generalized TD learning.",
                    "label": 0
                },
                {
                    "sent": "So like this week.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is experimental results on by and change just a little bit about previous comparison of TD and Diner Linear Diner.",
                    "label": 0
                },
                {
                    "sent": "So in last year paper.",
                    "label": 0
                },
                {
                    "sent": "The show, I mean the paper that proposed linear Edina in UI by certain you tester and this girl is actually their terrorism which is a single step diner and their results.",
                    "label": 0
                },
                {
                    "sent": "Actually you can see that their results suggest that in the beginning linear diner is faster than than TD but after some episodes there result suggests linear dynamic blowup error curve graph.",
                    "label": 0
                },
                {
                    "sent": "That means their result.",
                    "label": 0
                },
                {
                    "sent": "Suggest Dina may be poor in the long run, so this results actually is stronger than the result because we we found that.",
                    "label": 0
                },
                {
                    "sent": "There is a three learning step size there, so which is learning with cooling step, which there's a also modeling step size and planning steps step size.",
                    "label": 0
                },
                {
                    "sent": "So the you seem step size for the two for the three step size and the user seems scheduling for the three step size and we actually decoupling the three step size on you.",
                    "label": 0
                },
                {
                    "sent": "Different scheduling, scheduling and so.",
                    "label": 0
                },
                {
                    "sent": "This is a key thing that we achieve better results and also this results also suggests that multistep dynamics more advantage advantage than single Step diner.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So some conclusion, sending your diner is constantly faster than TD.",
                    "label": 1
                },
                {
                    "sent": "And multi Step Diner is still faster than linear diner.",
                    "label": 1
                },
                {
                    "sent": "So planning for control we have some initial results.",
                    "label": 0
                },
                {
                    "sent": "So we build a multi step linear state action to state action model and we also this model is also interesting in that it attracts the optimal tracks greedy policy and in the long run we hope that this tracking model we will model the optimum policy and we also have some experiment on mountain car and the result shows that.",
                    "label": 0
                },
                {
                    "sent": "This tracking multistep model enables you to find the optimum policy faster than the ordinary model free.",
                    "label": 0
                },
                {
                    "sent": "Learning algorithm such as source and cleaning.",
                    "label": 0
                },
                {
                    "sent": "So if you're interested, we can discuss as a poster.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Question.",
                    "label": 0
                },
                {
                    "sent": "Quickly, but I.",
                    "label": 0
                },
                {
                    "sent": "Linear K step.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Basically saying there's a bunch of state features and we're getting going to approximate the true transition model with linear map.",
                    "label": 0
                },
                {
                    "sent": "Yeah, and so if K was large enough that so it's sort of like extended common filter, right?",
                    "label": 0
                },
                {
                    "sent": "It might be locally linear, but if you make a very big.",
                    "label": 0
                },
                {
                    "sent": "Then the linear approximation will breakdown.",
                    "label": 0
                },
                {
                    "sent": "So I think you are talking about you saying that if key big, maybe your model is not accurate.",
                    "label": 0
                },
                {
                    "sent": "Is that what you mean, right?",
                    "label": 0
                },
                {
                    "sent": "They don't on a large time scale.",
                    "label": 0
                },
                {
                    "sent": "It might not be linear.",
                    "label": 0
                },
                {
                    "sent": "That makes even make sense.",
                    "label": 0
                },
                {
                    "sent": "Or I mean, misunderstanding.",
                    "label": 0
                },
                {
                    "sent": "I think you are right.",
                    "label": 0
                },
                {
                    "sent": "It's not linear, but it's a transition model can be shows that it is a power is the power is a USA.",
                    "label": 0
                },
                {
                    "sent": "You apply linear step model multi times.",
                    "label": 0
                },
                {
                    "sent": "So it's not linear, but it's the powers of linear.",
                    "label": 0
                },
                {
                    "sent": "For the.",
                    "label": 0
                },
                {
                    "sent": "For the transition proximation right?",
                    "label": 0
                },
                {
                    "sent": "So the true transition model is indeed the power of the true transition model for one step, right?",
                    "label": 0
                },
                {
                    "sent": "Yeah, and the linear line is the power of the linear model for one step, yeah, but while the linear model might be a good approximation for short time scales, yeah, you're right, it could be not good approximation.",
                    "label": 0
                },
                {
                    "sent": "So in other words, there might be a good time scale.",
                    "label": 0
                },
                {
                    "sent": "For the domain and it's going to interact with gamma, so if you make gamma, yeah, you're right, close to 1, right that you might need to control you.",
                    "label": 0
                },
                {
                    "sent": "OK, very carefully so you don't get too much error.",
                    "label": 0
                },
                {
                    "sent": "Does that make sense?",
                    "label": 0
                },
                {
                    "sent": "Yeah, so my my experiment are mounting car shows that so more step you look into into the future so poor performance you get.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so some intermediate value of key.",
                    "label": 0
                },
                {
                    "sent": "For example K equal to 5 or 10.",
                    "label": 0
                },
                {
                    "sent": "You get best result and from 20 and later key from key equal to 20 and later your performance will degenerate.",
                    "label": 0
                },
                {
                    "sent": "So I think it's interesting to see how much you can rely on your multi step projection and how much accuracy can you provide.",
                    "label": 0
                },
                {
                    "sent": "But I think it's it's how program.",
                    "label": 0
                },
                {
                    "sent": "Right, maybe there is a better way to find the market step model.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}