{
    "id": "jgcxnrgccuzep5jsqll7m7qsbka2mh4v",
    "title": "Layered Object Detection for Multi-Class Segmentation",
    "info": {
        "author": [
            "Sam Hallman, Department of Computer Science, University of California, Irvine"
        ],
        "published": "July 19, 2010",
        "recorded": "June 2010",
        "category": [
            "Top->Computer Science->Computer Vision"
        ]
    },
    "url": "http://videolectures.net/cvpr2010_hallman_lodm/",
    "segmentation": [
        [
            "Hi, will this talk is an image segmentation for the Pascal competition."
        ],
        [
            "In the Pascal competition we have 20 object categories plus a background class and this work is on how we do, how we might do that with the help of object detection."
        ],
        [
            "Others.",
            "So the big picture is this.",
            "We instead of going straight from a photograph to a segmentation, we run a detector for every category and try to use the bounding boxes in conjunction with the pixel information from the original image to then somehow work torda segmentation.",
            "Furthermore, we use."
        ],
        [
            "Part based detectors.",
            "So that in addition."
        ],
        [
            "To the root bounding boxes we also get part bounding boxes and we try to use all of those to work toward a segmentation.",
            "Now the big problem with this, when you actually try and do this, you run into the problem that the bounding boxes overlap, just like in this picture.",
            "This is a big problem because then a pixel can be has.",
            "The can be claimed by potentially many detections.",
            "Now, the way that we deal with this, the primary step that we take Tord dealing with this problem is that we use a layered representation."
        ],
        [
            "Or object detections.",
            "So what does that even mean?",
            "It just means we get the object detections and we order them by depth from the camera.",
            "Just like how you have ordered layers in a paint program like Adobe Photoshop, it's exactly the same concept, but of course this immediately begs the question, how do you?",
            "How do you know the correct ordering?",
            "How do we know that the horses in front of the woman, for example, and I'll get to that little a little bit later on?",
            "But for now I want to mention."
        ],
        [
            "I want to say a quick word about related work.",
            "There's a wide variety of related work on combining segmentation and recognition.",
            "And Furthermore, there's also a line of work on layered models like our own, starting with Wing and Adelson in 1994.",
            "This has been pursued primarily in the video domain.",
            "For us, however, we are, as you know."
        ],
        [
            "King with static images.",
            "So step number one for us.",
            "Then as we run detectors for every category over the image.",
            "Now.",
            "Another problem with this is that the the local detectors.",
            "Output scores that are not comperable across object categories.",
            "So we seek to remedy this by finding by kind of calibrating the detectors and the way we do this is we.",
            "Find thresholds for each detector that maximize segmentation accuracy and we create segmentations straight from from the detections kind of making these box segmentations.",
            "As you can see."
        ],
        [
            "And we find that the optimal thresholds for each.",
            "Object detector varies widely across the classes, and now with these new detector thresholds we can kind of use it as a new bias term in a way so that hopefully the detectors are calibrated in some sense."
        ],
        [
            "So that's so we're done with detector calibration and no.",
            "So now we can go back to what we're here to do, which is segmentation.",
            "And so before I go on, I kind of want to give some intuition for how we approach the problem.",
            "What we do is well, when we work toward multiclass segmentation, when we're looking at a."
        ],
        [
            "Google Pixel, we don't try to find that pixels class label, at least not directly.",
            "Rather what we do is we try to find to which layer that pixel belongs or which picks which layer it comes from.",
            "Alright, so let's focus on a single pixel just for this example.",
            "So Pixel I now to allow for background pixels.",
            "We just pretend that there's a background detection.",
            "That's all the way in the back.",
            "Alright, it's this background layer that we just define into existence and then.",
            "We model the layer assignment of pixel I as a random variable ZI, so that means."
        ],
        [
            "Zi could be 0."
        ],
        [
            "It could be one."
        ],
        [
            "Or it could be 2.",
            "Now, if you repeat this kind of layer assignment for all."
        ],
        [
            "I then maybe you'll get something like this now.",
            "Something to notice here is that color could be really useful here, and in fact we could loop over all the layers and learn about the color distribution."
        ],
        [
            "Each and now this is really useful.",
            "For example, in say, we could see this portion right here and we could say, given the dominance of red and given the color models, it probably should have been assigned over to layer one.",
            "So that's the into it."
        ],
        [
            "And now I want to delve into the mathematical machinery that we use for the problem, which is basically everything I just showed you.",
            "But in some symbolic form rather than in picture form.",
            "So we're after the most probable layer assignments, right?",
            "So what that means is we want the Z vector that just maximizes that term right there, where X are the RGB values for the pixels, Theta are the color models like I showed you in the picture, and D pie are the order detection's.",
            "Just like I showed you in the picture.",
            "Now the way we compute this term is.",
            "First and foremost, we make a independence assumption so that it breaks down into a product over pixels, and then the term for each pixel further breaks down into two more terms shape turn, which is the probability of our particular layer assignment given just the detections, no color or anything like that, and then the next is the color likelihood term, which is the probability of seeing that pixels color given the color model for the for the layer assignment that you make.",
            "So if XI is maybe a reddish kind of color.",
            "Given the data for the card for the car layer, it'll probably be a high value.",
            "If it's data for the Theta for background, maybe it'll be a little bit lower.",
            "So we do."
        ],
        [
            "Inference by coordinate descent.",
            "This is actually just like in the picture.",
            "We make layer assignments.",
            "And then given those layer assignments, we loop over the detections and fit color models to the layers and then with those color models, we can further refine our chip away at our initial Z estimate.",
            "And then with that we can go back and learn color models again.",
            "And then just refine Z again and just keep doing that until convergence."
        ],
        [
            "So far so good, but.",
            "Right now all I've done is layer assignments and color and shape, but there's nothing about any kind of use of any kind of bottom up grouping constraints like such as the presence of contours, separating object boundaries, and the way we make use of that kind of information is that we run a segmentation engine over the image, and then we require that all pixels within a superpixel share the exact same label.",
            "I."
        ],
        [
            "And so that amounts to the following.",
            "We just do exactly the same thing, but we constrain Z to live in this set of pixel labelings consistent with the superpixel image.",
            "So I've shown you the inference procedure, but I haven't actually showed you how we even compute those orange and blue terms right there, so I want to get into that now the color term is easy to handle, we just build RGB histograms for each layer.",
            "Then you look up in the histogram and you're done.",
            "You have the probability, but the shape term on the other."
        ],
        [
            "It is a lot more complicated, alot trickier to deal with.",
            "So for that first step is to learn shape priors.",
            "So the way we build shape priors is I'm going to focus on the person category for now.",
            "We run the person detector over the whole training set and we grab the the true positive detections and then we kind of average the ground truth segmentations and so we end up with the shape prior for."
        ],
        [
            "Person class, but that's not everything we do because we're called that we are using a part based detector and so we can go through the exact same procedure."
        ],
        [
            "Build prior shape priors for the parts and Furthermore.",
            "The detector outputs one of two mixture components and so we."
        ],
        [
            "Can do the exact same thing for both mixture components."
        ],
        [
            "Now we repeat this process."
        ],
        [
            "Building shape priors for all the classes."
        ],
        [
            "You notice that they.",
            "Shape priors for the parts are in general more clean than the than are the root shape priors.",
            "For example, on the upper right you can see the legs, whereas in the root prior you really."
        ],
        [
            "Can't.",
            "Here it is for the bottle of class.",
            "There's not much intraclass variability within the bottle category, but you can see that it would be kind of helpful, because if the bottle is large, then maybe the parts can kind of hone in on those, and so you have a shape prior that's more kind of tuned to that particular in."
        ],
        [
            "So now we have the shape priors and that's all we need.",
            "Now we can go and build this distribution that we were after and to do that, we do so iteratively.",
            "We start from back to front an.",
            "I'm going to illustrate that with this picture and these detections."
        ],
        [
            "And I'm going to look at one pixel in particular to illustrate the process.",
            "So as I said, we start from back to front, so we're at the back and all we know of is the background layer.",
            "So then that means pixel I is background with probability one, so it has the following distribution.",
            "And so now we."
        ],
        [
            "Move up another step 'cause we're going from back to front and we encounter a person detection and thanks to that persons.",
            "Thanks to the person shape prior, we believe that that person occupies that region of space with probability, let's say .9.",
            "So that means that this pixel is goes to the background detection for the background layer with probability 1 -- .9 zero point 1."
        ],
        [
            "So now we take another step forward toward the camera and we believe that this person hits that region of space with probability, let's say 0.01, because it's far away and that's what the shape prior tells us.",
            "And so that means that the other two terms get multiplied by 1 -- .01 or .99."
        ],
        [
            "We continue in this match."
        ],
        [
            "Owner until we."
        ],
        [
            "Hit the front most detection.",
            "Now something to notice here is that the car is rather blurry, right?",
            "You can't really make out any kind of form so."
        ],
        [
            "We can do the exact same thing, but making use of parts."
        ],
        [
            "We make use of parts by."
        ],
        [
            "Pasting the shape right?"
        ],
        [
            "As for the parts right on top of the shape."
        ],
        [
            "Prior for the roots.",
            "And as you can see in the end we have a layer distribution which is kind of more tuned to the particular instances.",
            "In this image like you can see the tires for example, so it's tuned more for this car rather than the car class in general.",
            "So at this point I've showed the inference procedure and how we compute those two terms.",
            "So I've shown everything except for how we actually get that.",
            "Ordering the depth ordering Pi, the permutation and so the secret to computing that."
        ],
        [
            "Is.",
            "There is no secret.",
            "We just try every single permutation.",
            "So what that means is we start with one permutation, find the best Z for that permutation, and remember it.",
            "Now go to the next permutation, do the exact same thing and just do that for all the permutations.",
            "And remember the best that you ever found.",
            "And use that to construct the final segmentation."
        ],
        [
            "So I want to show some results now that was the whole model.",
            "The.",
            "Legend in the lower left indicates the pixels indicates the class that we mark the pixels with.",
            "Black means background."
        ],
        [
            "So this image on the left is a special one in that it illustrates something.",
            "It illustrates.",
            "Kind of the linking of disjoint object segments separated by an occluder.",
            "So for example, we would never interpret this as one large horse with three tiny horses at the bottom.",
            "We know because they're assigned to the same layer that it's part of 1 horse instance.",
            "And the the image on the right is important because it shows how our model correctly layered the table in front of the person."
        ],
        [
            "Here is some examples.",
            "Here are some examples of.",
            "Our model segmenting images with many people interacting with multiple objects we tend, we turned.",
            "It turned out that we did very well on the person category."
        ],
        [
            "And here are some examples with.",
            "People with different kinds of bikes in the bottom image you can notice that it correctly put the person's leg in front of the motorcycle."
        ],
        [
            "So here are results on the segmentation challenge.",
            "I unfortunately don't have time to go through it in detail, but the gist of it is that.",
            "We tend to do very well where the detector does well."
        ],
        [
            "But here's the more important analysis.",
            "This is kind of a breakdown of our performance on the competition, and in it the each column corresponds to our performance after just removing some portion of the code and seeing what happens.",
            "So finding that portion of the code and basically commenting it out and seeing what happens.",
            "And this yields some really nice insights, like for example the bicycle or super pixels are useful for segmenting bikes.",
            "This makes sense because kind of the low level segmentation cues are useful for kind of getting those high contrast beams of metal that make up bicycles.",
            "The color the color models are useful for people.",
            "Because you know, people wear different colored clothing and that helps kind of link those pieces together and on the bottom we can notice our average performance across all classes and we find that every component, the color superpixel and parts given improvement in general, but the ordering doesn't seem to play a big role, but there's."
        ],
        [
            "Reasoning for that, there's a reason for that, excuse me.",
            "And the reason is.",
            "First and foremost, let me go back one."
        ],
        [
            "Step when we did this, no ordering.",
            "Test.",
            "What that means is that rather than searching over orderings, what we did was we just ordered them according to detector score."
        ],
        [
            "That's already kind of helpful because detectors tend to have high confidence on unoccluded objects, and so when you order by detector score that tends to be that tends to perform reasonably well.",
            "And.",
            "The primary reason though, is that on the Pascal competition, most images have just one object, and then when there are more within one object and when those objects overlap, they typically are of the same class.",
            "You always see people overlapping with people.",
            "You always see sheep overlapping with sheep, but you hardly ever see people overlapping with sheep, for example.",
            "And so when it's two objects of the same category overlapping each other.",
            "What that means is.",
            "Then the order that you render them on it makes no difference in the final segmentation because we're making class segmentations rather than object segmentations."
        ],
        [
            "And so this is the end and in conclusion.",
            "What I've done is what I've given is.",
            "I've proposed a simple kind of layered model.",
            "For sending object detections into segmentations.",
            "And this, and in doing so, we're able to kind of leverage the performance of very powerful discriminatively trained detectors as well as sophisticated low level segmentation algorithms.",
            "And.",
            "Despite the simplicity of the model, we were able to perform rather well on the Pascal competition.",
            "Getting first place in.",
            "Some categories, including segmenting humans."
        ],
        [
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi, will this talk is an image segmentation for the Pascal competition.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the Pascal competition we have 20 object categories plus a background class and this work is on how we do, how we might do that with the help of object detection.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Others.",
                    "label": 0
                },
                {
                    "sent": "So the big picture is this.",
                    "label": 0
                },
                {
                    "sent": "We instead of going straight from a photograph to a segmentation, we run a detector for every category and try to use the bounding boxes in conjunction with the pixel information from the original image to then somehow work torda segmentation.",
                    "label": 0
                },
                {
                    "sent": "Furthermore, we use.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Part based detectors.",
                    "label": 0
                },
                {
                    "sent": "So that in addition.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To the root bounding boxes we also get part bounding boxes and we try to use all of those to work toward a segmentation.",
                    "label": 0
                },
                {
                    "sent": "Now the big problem with this, when you actually try and do this, you run into the problem that the bounding boxes overlap, just like in this picture.",
                    "label": 0
                },
                {
                    "sent": "This is a big problem because then a pixel can be has.",
                    "label": 0
                },
                {
                    "sent": "The can be claimed by potentially many detections.",
                    "label": 0
                },
                {
                    "sent": "Now, the way that we deal with this, the primary step that we take Tord dealing with this problem is that we use a layered representation.",
                    "label": 1
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Or object detections.",
                    "label": 0
                },
                {
                    "sent": "So what does that even mean?",
                    "label": 0
                },
                {
                    "sent": "It just means we get the object detections and we order them by depth from the camera.",
                    "label": 1
                },
                {
                    "sent": "Just like how you have ordered layers in a paint program like Adobe Photoshop, it's exactly the same concept, but of course this immediately begs the question, how do you?",
                    "label": 0
                },
                {
                    "sent": "How do you know the correct ordering?",
                    "label": 0
                },
                {
                    "sent": "How do we know that the horses in front of the woman, for example, and I'll get to that little a little bit later on?",
                    "label": 0
                },
                {
                    "sent": "But for now I want to mention.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I want to say a quick word about related work.",
                    "label": 1
                },
                {
                    "sent": "There's a wide variety of related work on combining segmentation and recognition.",
                    "label": 1
                },
                {
                    "sent": "And Furthermore, there's also a line of work on layered models like our own, starting with Wing and Adelson in 1994.",
                    "label": 1
                },
                {
                    "sent": "This has been pursued primarily in the video domain.",
                    "label": 0
                },
                {
                    "sent": "For us, however, we are, as you know.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "King with static images.",
                    "label": 0
                },
                {
                    "sent": "So step number one for us.",
                    "label": 0
                },
                {
                    "sent": "Then as we run detectors for every category over the image.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "Another problem with this is that the the local detectors.",
                    "label": 0
                },
                {
                    "sent": "Output scores that are not comperable across object categories.",
                    "label": 0
                },
                {
                    "sent": "So we seek to remedy this by finding by kind of calibrating the detectors and the way we do this is we.",
                    "label": 0
                },
                {
                    "sent": "Find thresholds for each detector that maximize segmentation accuracy and we create segmentations straight from from the detections kind of making these box segmentations.",
                    "label": 0
                },
                {
                    "sent": "As you can see.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we find that the optimal thresholds for each.",
                    "label": 0
                },
                {
                    "sent": "Object detector varies widely across the classes, and now with these new detector thresholds we can kind of use it as a new bias term in a way so that hopefully the detectors are calibrated in some sense.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that's so we're done with detector calibration and no.",
                    "label": 0
                },
                {
                    "sent": "So now we can go back to what we're here to do, which is segmentation.",
                    "label": 0
                },
                {
                    "sent": "And so before I go on, I kind of want to give some intuition for how we approach the problem.",
                    "label": 0
                },
                {
                    "sent": "What we do is well, when we work toward multiclass segmentation, when we're looking at a.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Google Pixel, we don't try to find that pixels class label, at least not directly.",
                    "label": 0
                },
                {
                    "sent": "Rather what we do is we try to find to which layer that pixel belongs or which picks which layer it comes from.",
                    "label": 0
                },
                {
                    "sent": "Alright, so let's focus on a single pixel just for this example.",
                    "label": 0
                },
                {
                    "sent": "So Pixel I now to allow for background pixels.",
                    "label": 0
                },
                {
                    "sent": "We just pretend that there's a background detection.",
                    "label": 0
                },
                {
                    "sent": "That's all the way in the back.",
                    "label": 0
                },
                {
                    "sent": "Alright, it's this background layer that we just define into existence and then.",
                    "label": 0
                },
                {
                    "sent": "We model the layer assignment of pixel I as a random variable ZI, so that means.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Zi could be 0.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It could be one.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or it could be 2.",
                    "label": 0
                },
                {
                    "sent": "Now, if you repeat this kind of layer assignment for all.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I then maybe you'll get something like this now.",
                    "label": 0
                },
                {
                    "sent": "Something to notice here is that color could be really useful here, and in fact we could loop over all the layers and learn about the color distribution.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Each and now this is really useful.",
                    "label": 0
                },
                {
                    "sent": "For example, in say, we could see this portion right here and we could say, given the dominance of red and given the color models, it probably should have been assigned over to layer one.",
                    "label": 0
                },
                {
                    "sent": "So that's the into it.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And now I want to delve into the mathematical machinery that we use for the problem, which is basically everything I just showed you.",
                    "label": 0
                },
                {
                    "sent": "But in some symbolic form rather than in picture form.",
                    "label": 0
                },
                {
                    "sent": "So we're after the most probable layer assignments, right?",
                    "label": 0
                },
                {
                    "sent": "So what that means is we want the Z vector that just maximizes that term right there, where X are the RGB values for the pixels, Theta are the color models like I showed you in the picture, and D pie are the order detection's.",
                    "label": 0
                },
                {
                    "sent": "Just like I showed you in the picture.",
                    "label": 0
                },
                {
                    "sent": "Now the way we compute this term is.",
                    "label": 0
                },
                {
                    "sent": "First and foremost, we make a independence assumption so that it breaks down into a product over pixels, and then the term for each pixel further breaks down into two more terms shape turn, which is the probability of our particular layer assignment given just the detections, no color or anything like that, and then the next is the color likelihood term, which is the probability of seeing that pixels color given the color model for the for the layer assignment that you make.",
                    "label": 0
                },
                {
                    "sent": "So if XI is maybe a reddish kind of color.",
                    "label": 0
                },
                {
                    "sent": "Given the data for the card for the car layer, it'll probably be a high value.",
                    "label": 0
                },
                {
                    "sent": "If it's data for the Theta for background, maybe it'll be a little bit lower.",
                    "label": 0
                },
                {
                    "sent": "So we do.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Inference by coordinate descent.",
                    "label": 0
                },
                {
                    "sent": "This is actually just like in the picture.",
                    "label": 0
                },
                {
                    "sent": "We make layer assignments.",
                    "label": 0
                },
                {
                    "sent": "And then given those layer assignments, we loop over the detections and fit color models to the layers and then with those color models, we can further refine our chip away at our initial Z estimate.",
                    "label": 1
                },
                {
                    "sent": "And then with that we can go back and learn color models again.",
                    "label": 0
                },
                {
                    "sent": "And then just refine Z again and just keep doing that until convergence.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So far so good, but.",
                    "label": 0
                },
                {
                    "sent": "Right now all I've done is layer assignments and color and shape, but there's nothing about any kind of use of any kind of bottom up grouping constraints like such as the presence of contours, separating object boundaries, and the way we make use of that kind of information is that we run a segmentation engine over the image, and then we require that all pixels within a superpixel share the exact same label.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so that amounts to the following.",
                    "label": 0
                },
                {
                    "sent": "We just do exactly the same thing, but we constrain Z to live in this set of pixel labelings consistent with the superpixel image.",
                    "label": 1
                },
                {
                    "sent": "So I've shown you the inference procedure, but I haven't actually showed you how we even compute those orange and blue terms right there, so I want to get into that now the color term is easy to handle, we just build RGB histograms for each layer.",
                    "label": 0
                },
                {
                    "sent": "Then you look up in the histogram and you're done.",
                    "label": 0
                },
                {
                    "sent": "You have the probability, but the shape term on the other.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It is a lot more complicated, alot trickier to deal with.",
                    "label": 0
                },
                {
                    "sent": "So for that first step is to learn shape priors.",
                    "label": 0
                },
                {
                    "sent": "So the way we build shape priors is I'm going to focus on the person category for now.",
                    "label": 0
                },
                {
                    "sent": "We run the person detector over the whole training set and we grab the the true positive detections and then we kind of average the ground truth segmentations and so we end up with the shape prior for.",
                    "label": 1
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Person class, but that's not everything we do because we're called that we are using a part based detector and so we can go through the exact same procedure.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Build prior shape priors for the parts and Furthermore.",
                    "label": 0
                },
                {
                    "sent": "The detector outputs one of two mixture components and so we.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Can do the exact same thing for both mixture components.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now we repeat this process.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Building shape priors for all the classes.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You notice that they.",
                    "label": 0
                },
                {
                    "sent": "Shape priors for the parts are in general more clean than the than are the root shape priors.",
                    "label": 0
                },
                {
                    "sent": "For example, on the upper right you can see the legs, whereas in the root prior you really.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Can't.",
                    "label": 0
                },
                {
                    "sent": "Here it is for the bottle of class.",
                    "label": 0
                },
                {
                    "sent": "There's not much intraclass variability within the bottle category, but you can see that it would be kind of helpful, because if the bottle is large, then maybe the parts can kind of hone in on those, and so you have a shape prior that's more kind of tuned to that particular in.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now we have the shape priors and that's all we need.",
                    "label": 0
                },
                {
                    "sent": "Now we can go and build this distribution that we were after and to do that, we do so iteratively.",
                    "label": 0
                },
                {
                    "sent": "We start from back to front an.",
                    "label": 0
                },
                {
                    "sent": "I'm going to illustrate that with this picture and these detections.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And I'm going to look at one pixel in particular to illustrate the process.",
                    "label": 0
                },
                {
                    "sent": "So as I said, we start from back to front, so we're at the back and all we know of is the background layer.",
                    "label": 0
                },
                {
                    "sent": "So then that means pixel I is background with probability one, so it has the following distribution.",
                    "label": 0
                },
                {
                    "sent": "And so now we.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Move up another step 'cause we're going from back to front and we encounter a person detection and thanks to that persons.",
                    "label": 0
                },
                {
                    "sent": "Thanks to the person shape prior, we believe that that person occupies that region of space with probability, let's say .9.",
                    "label": 0
                },
                {
                    "sent": "So that means that this pixel is goes to the background detection for the background layer with probability 1 -- .9 zero point 1.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now we take another step forward toward the camera and we believe that this person hits that region of space with probability, let's say 0.01, because it's far away and that's what the shape prior tells us.",
                    "label": 0
                },
                {
                    "sent": "And so that means that the other two terms get multiplied by 1 -- .01 or .99.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We continue in this match.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Owner until we.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hit the front most detection.",
                    "label": 0
                },
                {
                    "sent": "Now something to notice here is that the car is rather blurry, right?",
                    "label": 0
                },
                {
                    "sent": "You can't really make out any kind of form so.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We can do the exact same thing, but making use of parts.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We make use of parts by.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Pasting the shape right?",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As for the parts right on top of the shape.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Prior for the roots.",
                    "label": 0
                },
                {
                    "sent": "And as you can see in the end we have a layer distribution which is kind of more tuned to the particular instances.",
                    "label": 0
                },
                {
                    "sent": "In this image like you can see the tires for example, so it's tuned more for this car rather than the car class in general.",
                    "label": 0
                },
                {
                    "sent": "So at this point I've showed the inference procedure and how we compute those two terms.",
                    "label": 0
                },
                {
                    "sent": "So I've shown everything except for how we actually get that.",
                    "label": 0
                },
                {
                    "sent": "Ordering the depth ordering Pi, the permutation and so the secret to computing that.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is.",
                    "label": 0
                },
                {
                    "sent": "There is no secret.",
                    "label": 0
                },
                {
                    "sent": "We just try every single permutation.",
                    "label": 1
                },
                {
                    "sent": "So what that means is we start with one permutation, find the best Z for that permutation, and remember it.",
                    "label": 0
                },
                {
                    "sent": "Now go to the next permutation, do the exact same thing and just do that for all the permutations.",
                    "label": 0
                },
                {
                    "sent": "And remember the best that you ever found.",
                    "label": 0
                },
                {
                    "sent": "And use that to construct the final segmentation.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I want to show some results now that was the whole model.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "Legend in the lower left indicates the pixels indicates the class that we mark the pixels with.",
                    "label": 0
                },
                {
                    "sent": "Black means background.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this image on the left is a special one in that it illustrates something.",
                    "label": 0
                },
                {
                    "sent": "It illustrates.",
                    "label": 0
                },
                {
                    "sent": "Kind of the linking of disjoint object segments separated by an occluder.",
                    "label": 0
                },
                {
                    "sent": "So for example, we would never interpret this as one large horse with three tiny horses at the bottom.",
                    "label": 0
                },
                {
                    "sent": "We know because they're assigned to the same layer that it's part of 1 horse instance.",
                    "label": 0
                },
                {
                    "sent": "And the the image on the right is important because it shows how our model correctly layered the table in front of the person.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here is some examples.",
                    "label": 0
                },
                {
                    "sent": "Here are some examples of.",
                    "label": 0
                },
                {
                    "sent": "Our model segmenting images with many people interacting with multiple objects we tend, we turned.",
                    "label": 0
                },
                {
                    "sent": "It turned out that we did very well on the person category.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here are some examples with.",
                    "label": 0
                },
                {
                    "sent": "People with different kinds of bikes in the bottom image you can notice that it correctly put the person's leg in front of the motorcycle.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here are results on the segmentation challenge.",
                    "label": 1
                },
                {
                    "sent": "I unfortunately don't have time to go through it in detail, but the gist of it is that.",
                    "label": 1
                },
                {
                    "sent": "We tend to do very well where the detector does well.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But here's the more important analysis.",
                    "label": 0
                },
                {
                    "sent": "This is kind of a breakdown of our performance on the competition, and in it the each column corresponds to our performance after just removing some portion of the code and seeing what happens.",
                    "label": 0
                },
                {
                    "sent": "So finding that portion of the code and basically commenting it out and seeing what happens.",
                    "label": 0
                },
                {
                    "sent": "And this yields some really nice insights, like for example the bicycle or super pixels are useful for segmenting bikes.",
                    "label": 0
                },
                {
                    "sent": "This makes sense because kind of the low level segmentation cues are useful for kind of getting those high contrast beams of metal that make up bicycles.",
                    "label": 1
                },
                {
                    "sent": "The color the color models are useful for people.",
                    "label": 0
                },
                {
                    "sent": "Because you know, people wear different colored clothing and that helps kind of link those pieces together and on the bottom we can notice our average performance across all classes and we find that every component, the color superpixel and parts given improvement in general, but the ordering doesn't seem to play a big role, but there's.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Reasoning for that, there's a reason for that, excuse me.",
                    "label": 0
                },
                {
                    "sent": "And the reason is.",
                    "label": 0
                },
                {
                    "sent": "First and foremost, let me go back one.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Step when we did this, no ordering.",
                    "label": 0
                },
                {
                    "sent": "Test.",
                    "label": 0
                },
                {
                    "sent": "What that means is that rather than searching over orderings, what we did was we just ordered them according to detector score.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's already kind of helpful because detectors tend to have high confidence on unoccluded objects, and so when you order by detector score that tends to be that tends to perform reasonably well.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "The primary reason though, is that on the Pascal competition, most images have just one object, and then when there are more within one object and when those objects overlap, they typically are of the same class.",
                    "label": 0
                },
                {
                    "sent": "You always see people overlapping with people.",
                    "label": 0
                },
                {
                    "sent": "You always see sheep overlapping with sheep, but you hardly ever see people overlapping with sheep, for example.",
                    "label": 0
                },
                {
                    "sent": "And so when it's two objects of the same category overlapping each other.",
                    "label": 0
                },
                {
                    "sent": "What that means is.",
                    "label": 0
                },
                {
                    "sent": "Then the order that you render them on it makes no difference in the final segmentation because we're making class segmentations rather than object segmentations.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so this is the end and in conclusion.",
                    "label": 0
                },
                {
                    "sent": "What I've done is what I've given is.",
                    "label": 0
                },
                {
                    "sent": "I've proposed a simple kind of layered model.",
                    "label": 1
                },
                {
                    "sent": "For sending object detections into segmentations.",
                    "label": 1
                },
                {
                    "sent": "And this, and in doing so, we're able to kind of leverage the performance of very powerful discriminatively trained detectors as well as sophisticated low level segmentation algorithms.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Despite the simplicity of the model, we were able to perform rather well on the Pascal competition.",
                    "label": 0
                },
                {
                    "sent": "Getting first place in.",
                    "label": 0
                },
                {
                    "sent": "Some categories, including segmenting humans.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}