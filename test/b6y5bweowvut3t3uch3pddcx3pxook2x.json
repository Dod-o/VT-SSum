{
    "id": "b6y5bweowvut3t3uch3pddcx3pxook2x",
    "title": "Clustering",
    "info": {
        "author": [
            "Shai Ben-David, David R. Cheriton School of Computer Science, University of Waterloo"
        ],
        "published": "Dec. 14, 2007",
        "recorded": "October 2007",
        "category": [
            "Top->Computer Science->Machine Learning->Clustering"
        ]
    },
    "url": "http://videolectures.net/aop07_ben_david_clu/",
    "segmentation": [
        [
            "I want to talk about some issues in the theoretical foundations of clustering and my my talk will actually be 3.",
            "A different topics of different flavor.",
            "So the first one will be very fundamental.",
            "Try to discuss a little bit.",
            "How can we define what clustering is?",
            "The 2nd will be 11 progress that we made in the understanding.",
            "Trying to understand clustering is in a principled way and then tomorrow and in the morning.",
            "What I'll talk about is very specific clustering.",
            "Problem which is called big clustering and I'll discuss the algorithmic complexity of that problem.",
            "So the three different parts 2 today, 1:00 tomorrow and quite different in flavor so.",
            "You can pick and choose OK, so I want to talk about the theoretical foundations of clustering and I."
        ],
        [
            "So I think we all know that that clustering is very widely widely used for exploratory data analysis.",
            "You use it like all over the place in understanding social networks in biology, analysing an analysis of microarray data in astronomy to find groups of planets of stars and in computer science.",
            "Of course, we use clustering a lot in data mining.",
            "It's very heavily used.",
            "And surprisingly, in spite of this heavy use of clustering for many years.",
            "There is very very little theoretical understanding of what clustering is, so it's in sharp contrast to what we've seen classification, classification.",
            "We have beautiful theories, convergence results, large margins, VC theory, whatever you want.",
            "We understand the task.",
            "In clustering, it's almost as useful.",
            "I think Amanda can't compare, but it's very, very useful.",
            "We hardly have any theory at all.",
            "To understand to give us any guarantees about clustering.",
            "So this is the very ambitious task that I'm trying to address.",
            "And of course the task is very ambitious, we achieve only."
        ],
        [
            "Small steps, so the sum, of course, inherent obstacles.",
            "Why we don't have a theory of clustering, and I think the first one is that clustering is not well defined.",
            "Then.",
            "I mean, if I want to to cluster.",
            "If paintings, I can either cluster can cluster them, you can say the correct clustering is by identifying who the painter is, but another person will say the correct clustering is by the topic of the painting and there's no well defined notion of what is.",
            "The correct clustering so that it's not well defined.",
            "Another related problem in class ring is that we don't have any ground truth.",
            "It's not in classification.",
            "You eventually reveal the correct label of your data point and you can measure whether your prediction was correct or not.",
            "You saw those graphs at the end of Nicolas talk.",
            "We could see how well we're doing in clustering.",
            "There is no ground truth that we can compare our results to it so.",
            "There is no objective measure of how well we're doing, which makes it of course, much harder to develop any guarantees of performance."
        ],
        [
            "So.",
            "Just to demonstrate it is not well defined problem.",
            "You can say how how should I cluster this cloud of points and one way could be doing it this way by trying to make the separation at the point of the largest gap.",
            "But another solution which is."
        ],
        [
            "This is where it could be.",
            "Try to cluster it like this to find 2 centers that best attract the two points and what is the correct way of clustering this cloudpaw?"
        ],
        [
            "So here is another example.",
            "If you get this cloud, you can have look at these two clusterings and try to argue why is one of them better than the other."
        ],
        [
            "So there's several approaches to this problem.",
            "Of course it's not a new problem, and.",
            "And one approach that is very appealing is that somatic approach you try to postulate some clustering axioms.",
            "What should clustering satisfy, and ideally every clustering approach to satisfy these axioms and every function which is not a clustering should fail.",
            "Some of those axioms and regret somehow.",
            "I think disappointingly, most of the all of the literature that was trying to do this.",
            "Ended up showing negative results, showing that our axioms do not work, and I'll show you one such example of what do I mean by negative results.",
            "Another approach is to try to say OK, so clustering is not well defined.",
            "Let's add structure on top of just having a cloud of points.",
            "So for example, if we have a notion of relevant information on top of our collection of data points, then we can use approaches like information bottleneck or any kind of information theoretic approaches to somehow tell us what is the better clustering than other.",
            "Another way of adding structure is to define some.",
            "Objective utility function.",
            "So if you're doing clustering, for example for for coding, then you can say what I want to choose code words in such a way that the distance of a random word from the closest code word is minimized.",
            "So I add on top of my structure of just points and distances some notion of what's my objective is a precisely defined objective function, and this allows me to make progress in my theory.",
            "In my guarantees in analysis of my algorithms."
        ],
        [
            "Another approach that is widely addressed in the literature is consider only a restricted set of distributions.",
            "So we can say our data is not arbitrarily generated, but it's generated, say by a mixture of Gaussians.",
            "If we make such an assumption, then we have a ground truth.",
            "Then we can say how well did we do.",
            "We can measure it by how close did we approximate the original mixture of Gaussians that actually generated our data?",
            "So that's another way of adding structure.",
            "To make the task better defined, but of course.",
            "Assuming that you know what the distribution that generated the data is, I mean it's very common in statistics, but when you think about it, it's not really realistic, you don't.",
            "Really believe that I don't know what when you want to cluster documents on the web that generated by a mixture of three Gaussians or something, but it allows to do very nice theoretical work.",
            "An another solution is to focus on a specific arhythmic paradigm, so we can say all I care about is this type of clustering algorithms and I'm trying to analyze and understand them better.",
            "So there's a lot of work on.",
            "Projection based clustering like.",
            "Principal component analysis or spectral based clustering or speculate citations.",
            "So you fix one algorithm OK means algorithm.",
            "You focus on one algorithm that you really think is central and try to analyze or improve the.",
            "A behavior or the performance of algorithms under this specific padding."
        ],
        [
            "So the question is, what can we say about clustering which is independent of any algorithm or objective function or a model to generate the data?",
            "Can we say something which will be more general and apply to all of those different types of clustering?"
        ],
        [
            "Why do we want to answer such a question?",
            "I think that very important questions to answer here in the general setting.",
            "So.",
            "Like what is clustering?",
            "What is a good clustering?",
            "If I give you a clustering algorithm and you want to?",
            "I mean if you go to conferences and see people presenting the clustering algorithms, usually the way they show you that the algorithm is better than all the previous algorithms is by showing you pictures.",
            "Look at the picture.",
            "Aren't you convinced that my clustering is the right one?",
            "But this is limited scientific value and it can only work in dimension 2.",
            "But we are clustering that in hundreds of dimension.",
            "So we really want to answer the question what is a good clustering and we really want to be able to say.",
            "You know, can we carry out clustering efficiently?",
            "How much running time do you need?",
            "If you don't know what's a good clustering, you can't answer the question how much running time do you need and how much space do you need?",
            "Can we distinguish clusterable form structure?",
            "Is that if I give you some data and I tell you, here is my patience from a medical repository and I have I want, ask you do those patients naturally cluster into groups, so we will treat each group separately?",
            "All they are all just one big mix.",
            "Can we define a notion of classical data?",
            "These are very important questions and we don't have answers to this kind of questions, so I will start by presenting an axiomatic approach that was initiated by John Kleinberg and then we will see what can we."
        ],
        [
            "Take from there.",
            "So John Piper gotta I think was it 2002 he tries to give some formalism to allow definition of clustering and general way so it restricts the set of clustering that we're looking at.",
            "But it's still pretty general.",
            "So the idea is that our domain is going to be a finite set of points S and on top of it we can't cluster point since we don't have a notion of which points are most similar to each other and which points are not similar.",
            "So our input is a pair which is a set of domain points and distance function which I called this similarity function on pairs of points.",
            "So we have this notion of.",
            "Our input is just the final set of points and a notion of how similar they are to each other.",
            "So we require this dissimilarity function is symmetric the distance between X&Y is the same as YX, and distance 0 only.",
            "Of a point to itself.",
            "And then we define a clustering function as a function that takes such input, which is a pair of a domain and distance.",
            "So the clustering function takes such an input and outputs repetition of the domain.",
            "That's basically what clustering functions do.",
            "And what we wish to be able to define is to find some properties that distinguish clustering functions from functions which are not clustering functions.",
            "Not every function that takes data as input and outputs a petition of the data will be considered the clustering function, right?",
            "If I if you have a function that takes the real numbers as input and outputs the partition into rational numbers and irrational numbers, you are not likely to call it clustering.",
            "So how do we distinguish between functions that we call clustering and functions that we don't concussing so?"
        ],
        [
            "A client book offered three axioms.",
            "So and they all sound pretty natural, so the first one is scale invariant.",
            "So what do we mean by scary invariants?",
            "If I take my dissimilarity distance matrix and I multiplied by constant so I didn't change the relative distances, I just took all the distances and say if the similarity between.",
            "Me and John was two before now and multiply it by 10.",
            "It will be 20 and if the similarity between you or 70 two 9070 we multiply everything by 10.",
            "What we expect is that a good clustering function will not be sensitive to this.",
            "Scale scaling.",
            "If we scale all the distances, we should get the same clustering, so that's the scale invariants requirement.",
            "F is the clustering function that's the the input distance metric, and if we input Lambda times the distance D, we should get out the same in the same position as with input.",
            "DD is stands for the matrix of all the pairwise distances, so that's very natural the other one.",
            "It is richness.",
            "You want to say that the clustering function by rearranging the points by pulling some of them closer together and some of them further apart.",
            "I can force my function to give me any desired partitioning.",
            "So if I want to partition, it puts me on one side and all of you in the other cluster.",
            "All I have to do is just walk away far enough from you and then my function should give me this partitioning if I want the partitioning that divides the class into two here, then I'll just pull these two groups apart and maybe make them closer together.",
            "So you want a good clustering function to be rich in the sense that.",
            "If I look at all the possible clusterings when I vary the distance metrics in all possible ways, then I'll get all the possible partitions of my domain.",
            "So this is the other requirement that by varying the distances I can induce any possible partition.",
            "That's another requirement from a good clustering function.",
            "The last requirement is a little bit more complex, and it says the following.",
            "So now assume that we have a distance matrix D and we have a partitioning FD.",
            "So we already have our function.",
            "Looked at this class and say it pursuit is it partitions with this distance is well, I just take the geographical distances between US and it pushes the class into three clusters.",
            "This is 1 cluster.",
            "This is another cluster and I'm the third cluster.",
            "Now assume that I make a transformation of this distance D. Everybody in the same cluster gets closer together.",
            "And between clusters I increase the distances.",
            "So the requirement here if D prime equals D except for shrinking distances within the clusters and stretching.",
            "Distances between clusters then?",
            "The class ring that I get from this should be equal to clustering that I get from the prime.",
            "It seems like if I already got the clustering and now everything it wasn't the same cluster got closer together and between any two clusters we got further apart.",
            "I only strengthen my belief in this clustering, yes?",
            "I'm.",
            "These are accidents.",
            "But do you have any examples which would contradict kind of these?",
            "Because to me all of them seem very sort of natural and.",
            "It's been frozen for this game.",
            "Invariants, for example, do you have any examples that would violate that?",
            "Make us regarding that actually move right?",
            "So right yeah.",
            "So so overlapping clusters are not clustered right overlapping classes and or class, so we're only talking about the restricted definition that says clustering is a partitioning of the data.",
            "Every point belongs to a single cluster and all the points are being clustered.",
            "You don't have any points left in the background, so back to your question.",
            "So here there is.",
            "There is some kind of catch.",
            "So when John Kleinberg wrote these axioms, he had some model in mind.",
            "There is a famous theorem by.",
            "Arrow which is a economist that got the Nobel Prize for proving that if you want to have.",
            "A perfect an election a.",
            "A function that tells you that how, how do you do?",
            "How do how should you consider the vote of every voter in such a way that the results of the elections will satisfy all the desired properties?",
            "I mean, you don't want to be in a situation where, say I prefer a. I don't know which examples they can give you in Italy, but I prefer a candidate won over candidate 2, but I still prefer candidate three over both of them, so I voted for candidate three.",
            "But then it turns out that kind of the tree didn't get enough votes.",
            "And if instead of voting for three, I would have voted for two, I would have.",
            "Better reflect my have a better effect of my vote.",
            "So how can we have a voting function that doesn't have such errors and error?",
            "Proved that if you list down a list of just a list of desired properties from voting function, you get a contradiction.",
            "There is no function that satisfies all the desired properties now John Kleinberg.",
            "So this arrow theorem and knows that error got a Nobel Prize and John also wants to be famous.",
            "So he said I will do something similar for clustering an he designed those axiom.",
            "Especially to get the contradiction to get a similar result to the arrow theory here are desired properties of clustering and I will show you that no function can satisfy all those three desired properties simultaneously.",
            "But but they have sort of this region.",
            "This kind of thing is something which is very dependent on the parameters of the cluster graduates, because mostly all of the algorithms are imagination.",
            "It has some parameters that you have to provide, right?",
            "So in many algorithms you fix the number of clusters, for example in advance, and then rather than requiring richness you would like to require K richness.",
            "You get all possible partitions into K subsets rather than all possible partitions.",
            "Yeah, I'll discuss some variants of this.",
            "But let me first show you how to get climbers impossibility result.",
            "The funny thing I mean this is a nips paper, and as a nips paper clip they had to provide a rather complicated proof.",
            "But if you just want a proof and not just not to get it accepted techniques, you can get a much simpler proof so."
        ],
        [
            "Maybe I'll.",
            "OK, let me just go back, go to the proof and then I'll go back."
        ],
        [
            "Today's slide, so here is my very simple proof.",
            "So I want to prove to prove to you that no clustering can satisfy all those three requirements simultaneously.",
            "So assume that I do have a function that satisfies all those three requirements.",
            "So by richness I know that there is some arrangements of points in which every point will be in its own cluster, and I also know by richness.",
            "Rearrange the points in such a way that I'll get some clustering which is not the same one as the previous one.",
            "Because the requirement was pretty strong that by rearranging the points you can get any possible partitioning.",
            "Now what I can do is so I have this arrangement that gives me a classroom which is not a trivial clustering.",
            "So now by scaling up, just multiply it by big enough constant, I can make sure that by scaling it up every distance here is bigger than the maximal distance here.",
            "I'll just this final set of point.",
            "There is a maximal distance between all pairs here and I'll scale it up in such a way that any distance now is bigger than this maximal distance.",
            "So by the scaling requirement, my function applied to this should give me this partitioning.",
            "Right, but if I compare these two arrangements, what happens here is that every pair of points were in different clusters.",
            "And they only got further apart because all the distances here are bigger than any distance here.",
            "So by the last requirement I only took you points in different clusters and made them further apart.",
            "I should get back this clustering.",
            "So my function when applied to this arrangement is required by the scale invariants to output this partitioning.",
            "But by the consistency requirement it's forced to output the Singleton partitioning.",
            "So we get a contradiction because my function has to sues some particular partitioning for this set.",
            "Are you comparing speaker clustering to the right side which has K = 3 clusters?",
            "Why are you comparing now?",
            "I'm saying that if you had a function, assume that you have.",
            "Some function that satisfies all those requirements.",
            "We if you go back to the axioms you say the."
        ],
        [
            "The clan book Axsom said a clustering function F. A good class and shots function should simultaneously satisfy all those requirements.",
            "Now I want to show you that no such function exists.",
            "So I assume by way of contradiction that such a function does exist.",
            "So this function by varying the inputs, should be able to give you every possible partitioning.",
            "In particular, it should be able to give you the Singleton partitioning and some other partitioning into three clusters and many more.",
            "Usually by the number of customers.",
            "OK, but I mean I'm just saying that we just show the contradiction in trying to satisfy these requirements simultaneously.",
            "But you also think a lot about know you also think a lot about the question of I give you the data and you should find the right key, right?",
            "So you can think of it as the meta function that also chooses K. There's a big issue in clustering.",
            "How to choose the correct number of clusters.",
            "So assume that I have an algorithm that can do both things.",
            "It can choose the correct number of clusters and then cluster.",
            "Then I may.",
            "I wish that my function satisfies all those three properties.",
            "And this proof shows you that you cannot do it.",
            "Are you convenios?",
            "Any 20 OK, that's my next slide.",
            "So.",
            "I'm not sure where I saw they reached."
        ],
        [
            "Oh, the richness was used in a very limited way.",
            "The richness suggest use by requiring that they can get the Singleton clustering and any other clustering.",
            "So I was using much less than the full richness and I still could get a contradiction.",
            "So my result is stronger than clients.",
            "I get contradiction for much less.",
            "But on the other hand, it's a trivial proof, so I can't publish it.",
            "Pretty much is.",
            "No no.",
            "This is no, no.",
            "The proof is showing that any clustering function that satisfies scale invariants and consistency its range is an under chain.",
            "There's a notion of an antichain of classroom.",
            "Check check the paper.",
            "Anyway, the this is this is a proof that I. I mean I heard.",
            "John, give this talk and I was sitting in the audience and I saw this reaction.",
            "They raised my hand.",
            "So here's the proof and Johnson, OK?",
            "But let me show you my proof just the same."
        ],
        [
            "Alright, so let's go back to this.",
            "So as you remarked, and any two of those axioms are satisfied aghbal simultaneously, it's the problem is that we can satisfy all three of them together, but we do.",
            "I mean, if I just want to satisfy any two of them, then if you just look at the following, the very simple, maybe the simplest clustering algorithm is called single linkage.",
            "What you do in single linkage, you take the closest two points and you say.",
            "We're going to be in the same cluster and then you take the next.",
            "Minimal distance and put it in the same cluster so you keep growing your clusters in a greedy way each time adding the closest remaining distance into the closest cluster.",
            "That's called the single linkage clustering.",
            "It's a very simple greedy kind of algorithm, and the parameter that you can play with in a single linkage clustering is when do you stop?",
            "Because if I'll keep adding edges and swallowing more points in my clusters.",
            "At the end of the process, I'll have one big cluster with all the point.",
            "So the question is, what's your stopping criteria?",
            "So it turns out that even with this simple clustering algorithm, by playing with my stopping criteria I can satisfy any desired pair of properties.",
            "So if my stopping criteria is just, I stop when I get K components.",
            "Then I have richness and I have the consistency requirement.",
            "I have scaling variance and the consistency requirement, but I don't have richness because I'm forced to output exactly K clusters.",
            "If my stopping retainer is stopped when the distance when all the distance is now bigger than our.",
            "Then I get richness.",
            "I mean, I can rearrange the points to get any clustering by just saying I stop when the distance the minimal distance left is our and I get the consistency.",
            "But it's not scale invariant because these are is fixed.",
            "So if I now blow up my data it will fracture into more clusters and if my stopping criteria is some scaling things say and stop when I get to a distance Alpha times the Max distance.",
            "Then it will be scale invariant because if I multiply by a scale.",
            "This will take care of it, but.",
            "I'm going to lose the consistency, so any pair of them is mutually satisfied that all reasonable, but they can't be all three satisfied simultaneously.",
            "This richness means that we want to have clustering which is really able to do you any number of partitioning.",
            "So any number of clusters right?",
            "I'm talking here about the clustering algorithm is supposed to look at examine your data and decide which is the correct number of clusters and then cluster into this number of clusters.",
            "Your question about is it clusterable or structureless in the sense that if it returned at the single cluster, it might be saying right?",
            "It may say you might say if it returns everything in a single cluster or every point in a Singleton, then it answers my question that that is cluster.",
            "This is structureless, yeah.",
            "Right, but those requirements are pretty harsh as we saw.",
            "OK, so where do we go from here?",
            "So I think one of the big mistakes in the community.",
            "I don't know how many people were looking at it, but people that did is that people heard this talk of client back at NIPS was very widely.",
            "Cited and people don't remember what exactly the details as well, but they conclusion is there's no way to do a theory of clustering because there is this impossibility result, and so let's forget about it.",
            "There's no way to do theory well.",
            "I'm trying to claim is that this is a very.",
            "It's a very nice result, but it has limited application.",
            "It says that this choice of three axioms was miss fortunate or fortunate in the sense that it led to a contradiction.",
            "But it doesn't mean that you cannot do any theory, so.",
            "What will be the next step?",
            "What can we do?"
        ],
        [
            "So what I would like, in an ideal theory, is to have two types of requirements.",
            "One type is axioms and actions should be requirements that any clustering method satisfies the access.",
            "So in particular the Kleinberg.",
            "Axioms are not accent because each of them we know is falsified by many good clustering algorithm we know whenever we saw an example that two properties are satisfied by some clustering algorithm, But the inconsistency, we know that this clustering algorithm failed the third requirement.",
            "So each of those requirements is failed by some natural clustering algorithm.",
            "So if I gave you an axioms of geometry and then I'll tell you know these are axioms of geometry, but some lines and points satisfies these axioms but others some other lines and points don't satisfy the axioms, so you won't call them axioms right actions you want to add.",
            "By nature, you want it to be something that is satisfied, but all the objects that you're trying to describe.",
            "I can't give you axioms of group theory and tell you OK, these are the axioms of group theory, but some groups satisfy them and some groups don't.",
            "That's contradictory to the nature of accents.",
            "So when I want actions, I want something that any clustering method will satisfy and we know that I mean clamping himself showed us that his actions are not like that because each of them is failed by.",
            "The same classroom that satisfied the other two.",
            "And the other requirement is even more difficult to formalize where I wanted any function that is clearly not a clustering will fail to satisfy at least one of the actions, because I could give you a trivial actions, I can tell you my axioms is the actual what you should satisfy is the requirement that 1 + 1 = 2.",
            "So now any function you give me will satisfy the axioms and we're all happy.",
            "But it doesn't distinguish good functions from bad functions.",
            "So we want to mutually satisfy these two requirements from a set of axioms, and this is may be difficult to formulate because what do I mean by clustering?",
            "That is obviously not a clustering function, so it's not going to be an easy task.",
            "And on top of it I would call the kind of actions that climate suggested.",
            "I call them properties rather than accents.",
            "So I'll have properties.",
            "Which hopefully will distinguish between different clustering paradigms, so I can say here is a clustering paradigm that is scale invariant.",
            "He was a class ring paradigm that is rich.",
            "Here is the clustering paradigm that satisfy that property.",
            "So now a user that wants to apply clustering to his data could look at the list of properties and choose which properties I need for my specific applications.",
            "And here is the clustering that will have those properties.",
            "And the thing that we know from client work is that you won't have a clustering that satisfies all the possible properties, but you know the same for many things in life.",
            "You can't get the car which is beautiful and fast and convenient and cheap or whatever."
        ],
        [
            "So this is the ideal theory that I would like to see.",
            "So here I have a list of.",
            "Things that I will call axioms, and here I have a list of possible clustering paradigms, and then I can ask which clustering paradigm satisfies which requirement.",
            "Now the axioms should be satisfied by all clustering paradigms.",
            "The things which are properties like Rambo, consistency, cleansers, richness are satisfied by some paradigms but not by others and they should help me somehow.",
            "Classify or taxonomize the class different clustering methods by which properties that satisfy.",
            "So each clustering method will have a profile of which properties it satisfied, in which it doesn't.",
            "The axioms should be satisfied by all of them, and if I have a function which is not a clustering function, it should at least fail one of those requirements so they all clustering functions will satisfy all the properties they collections.",
            "Other properties distinguish between different clustering methods and.",
            "Functions which are not clustering should each at least falsify one of those actions, so that's the ideal theory.",
            "The now I'm not going to give you such a theory becausw.",
            "Then having difficulty here is that we don't have a clear definition of what is not a clustering, I mean.",
            "I have this requirement in every function which is not.",
            "The clustering should falsify one of the axioms, but it's circular.",
            "How should I define it?",
            "It's not a clustering by showing that it doesn't satisfy one of the properties that I want all the.",
            "So I get into a cycle here, but I can still come up with some properties which are more natural to be axioms than others and are satisfied by all the reasonable common clustering functions.",
            "So I'll only give you some."
        ],
        [
            "Example of such properties.",
            "So in general we can say that the actions that we saw the requirements is so they really partition into two types of properties, richness, properties.",
            "So one of them was the client back richness.",
            "Another one could be care richness that the range of your partitioning is all possible.",
            "Partitioning in 2K sets.",
            "So we need some richness requirement and we need some invariants or robustness requirements, like saying scale invariants.",
            "If you change the scale, the clustering will not change.",
            "So these are two different types of properties and for each of them we can come up with relaxations that are really met by all.",
            "Common popular clustering paradigms.",
            "Ann, so I'll just give you one example of a relaxation of a property of Kleinberg that once you do this relaxation, you really have it in all the."
        ],
        [
            "Reasonable clustering functions so.",
            "The problem with the client, but consistent.",
            "So let me remind you what the consistent was.",
            "The consistency was the requirement that if I pull together points in the same clusters and pull different clusters apart, then apply my clustering function again, I'll get the same partitioning, right?",
            "But the problem is this.",
            "It could be that maybe I'll draw a picture here.",
            "The problem is this could be that.",
            "Assume that I have this.",
            "My data initially looks like this.",
            "So my class ring function will say.",
            "Well, here is my clustering and now I'm pulling together points in the same cluster an I get something like this.",
            "So I just took some of the points in this class and pull them together and I don't touch the other class or pull away.",
            "We are the cluster and.",
            "So I screamed this cluster, pulled it a bit away, and half of those points were shrinked here and the other half here.",
            "So this is a consistent change.",
            "Inside this cluster I only reduce the distances between the clusters.",
            "I only increase the distances, but if I give you this for clustering you would probably give me not this clustering, but something like this, right?",
            "It was speaking from paper two Busters.",
            "What you were worried about?",
            "The fact that I didn't fix K right again?",
            "I'm talking about an algorithm that should find the correct number of classes and then cluster.",
            "So what I'm saying is that consistency requirement, although on a first glance it looks natural.",
            "It has problems becausw the very natural examples where you want to refute it in this case.",
            "This summer been in trouble because I don't know how to draw, but I could do it without increasing any internal distances.",
            "I could do it, you could.",
            "I mean, it doesn't even have to be embedded in a say that all the distances here.",
            "Here the XY.",
            "Equals one for every X&Y and between those 2D XY.",
            "Equals 10 if I pick a point from here in a point from here and now, I'll make all the distances here.",
            "The XY here equals .1, and here the XY equals .1 and between those two still have distance too.",
            "So I didn't extend any insight, but I can have it at once, so it's good to know that people are following here.",
            "So I still have distance one between these two groups, but inside the group I shrink the distances to .1.",
            "And I'll get a similar.",
            "I mean when I try to draw it.",
            "Of course I don't do it precisely, but you can easily.",
            "Formula is such a situation, so my suggested remedy for this problem is to say that the consistency should be not allow you to change their proportions which are within each cluster.",
            "So you have a list of constants.",
            "A Lambda I for every cluster and the new distance function should be.",
            "If A&B are in the same cluster, is the old distance times this constant Lambda?",
            "And if they are in different clusters, is the old distance time some Lambda 0?",
            "So I pick constants for every cluster.",
            "I have a shrinking constant and for all the between distances I have some expansion constant.",
            "And if I now do my shrinking and expansion I I'm ruling out those kind of counter examples and I can show that all the reasonable clustering functions do satisfy this relaxed consistency requirement.",
            "Hey you can.",
            "You can play with expansion for every pair but I wanted it when you allow different.",
            "Constants for every pair of clusters, you can create a counter example like this because you see if I if I had.",
            "You know, if I assume I had this three clusters now expanded such as this cluster is here.",
            "This cluster is here and the third cluster is here.",
            "Right and now what you will naturally do is say this is 1 cluster and there's another cluster becausw.",
            "With this proportions they look together.",
            "So I want a fixed constant for all the between clustering distances.",
            "OK, so so we have such relaxations of those axioms in such a way that we are pretty happy that every natural clustering function satisfies all of them.",
            "Of course, to show that every non clustering function fails one of them we have to come up with an exhaustive list of not clustering functions and that's not something which is readily doable.",
            "I don't know even how to formulate it so.",
            "As a summary."
        ],
        [
            "Come on.",
            "Let me give you some examples of class rings which do not fall into the client work framework, so the climate framework is that your input is just a set of points and pairwise distances.",
            "But sometimes when you do clustering, the relationship you're looking at and are not just pairwise relationship there.",
            "For example, in edge detection, if I just gave you pairs of this and says you will not know which points are in the same edge, but a relationship like this if I.",
            "If you have points like this and say.",
            "You want to cluster this picture and we naturally class straight into.",
            "Here is 1 cluster.",
            "Here is another cluster.",
            "We're not looking at pairwise distances, but we're looking at the linear relationship which involves triples of points rather than pairs of points.",
            "Or maybe more than triples of points, so it doesn't fall into the framework that the clustering is just a function of pairs.",
            "Here the function could be a.",
            "The class ring could be a function of triple wise relationship, which colinearity.",
            "So edge detection is a good example of a clustering which is done in practice but does not fall into this framework which is based on just pairwise distances, yes.",
            "Probably because we don't need clustering or mention what.",
            "Because then marriage is a discontinued this conduit and why I need her to do clustering to do an expression.",
            "No, I'm not.",
            "I'm not fooling you.",
            "Can you repeat it?",
            "No, it doesn't.",
            "It was just example OK, but there is no semantic beyond no no.",
            "I'm saying if I apply to our intuitive semantics of what you do when you do edge detection, when do detection is a task that you use clustering for when you have a picture you want to detect objects.",
            "You do edge detection.",
            "You say all those points are lying on the same edge.",
            "So you first do the detection of the gradients.",
            "You know where where the sort of.",
            "Can you change is you get a lot of points and then yeah, you just you just take your defining engineer.",
            "I'm talking about you.",
            "Assume that your picture is now coded as just binary pixels and now you want to do edge detection just over binary pixels.",
            "But I'm saying is that on over binary pixels when you want to say those are in an edge it's more than just the pairwise distances.",
            "It is some notion of linearity or continuity of the path or simplicity.",
            "Of the past that connects them.",
            "Yes.",
            "I did wrong, but I just say that you are talking about partitioning basement and this clearly cannot be solved by.",
            "Yeah, you can easily do it into petitioning.",
            "I mean, I'm very bad.",
            "I'm very bad at drawing, but it could be the case that your points look like this.",
            "Right and now I ask you to class written, you say here is 1 cluster and here is another cluster and there's no points that belong simultaneously to both clusters.",
            "I wonder?",
            "Presentation because with what?",
            "What does it say?",
            "Yeah, that's what I'm.",
            "Consider.",
            "My data representation here is just a set of elements and pairwise distances.",
            "And what I'm saying is that there's some things which cannot be captured by this very simple representation.",
            "If I have here on top of the distances between the points, I also have some geometrical structure, IE really embedded in our two and I have some relationship which are more complex.",
            "Adjust the pairwise distances.",
            "So your own as you've never distances.",
            "Yeah, in this analysis my input is only a set of pairwise distances.",
            "Question regarding why not?",
            "OK, center can be not inside of your pointless.",
            "OK, but so so so vector quantization, it is.",
            "And if your center is allowed to be, you can also formalize K means in this way, because K means all the all the information it looks at is the pairwise distances you want to minimize your worried about choosing the center outside your input set, right?",
            "But you can say this can be overcome by some technical addition, but if not, just consider.",
            "Vector quantization in which you are forced to pick.",
            "Yeah, yeah, right.",
            "But I don't want to get into this game of examples and counterexamples, I'm I enjoy it very much, but I don't think it's so instructive use of the time now.",
            "So here is another example of the clustering which is not based on just pairwise distances and this is texture clustering.",
            "If I give you such a picture and tell you to cluster it, then you will say I mean and you can have more interesting results.",
            "It's just my limitation in drawing of texture.",
            "They want to cluster things by the texture.",
            "It's more than just the pairwise distances, it's something about more points together relationship which are involved, more points together and another.",
            "Nice example that I know that I really like is the professors examples, because what is the professor example of clustering and one of the clustering tasks that people at NIPS especially like to test themselves on is you take the web pages of your University.",
            "That's what you have always can play with because there's something available to you.",
            "You take the web pages and you look at all the linkage connections.",
            "So if one person links to another, you say they have.",
            "Some edge between them and then you define distances by say how many edges do I have to cross between menu or what's the density of edges between us and so on?",
            "So you take the structure of the web pages of your University and you try to cluster it based on distances which are just based on the link in your web pages.",
            "And can you come up with the clustering that will give you as a cluster the set of our professors.",
            "And the problem is that professors never linked to each other if they're in the same University.",
            "So if you're just based on linkage information, you will not be able to detect that there all belonging to the same group.",
            "Which is, I mean, some people claim that they do it, but I always really question it because there's no way that you can say these are, yeah.",
            "4 is better presentation, so if you just consider English information, that's what they mean.",
            "You cannot really define custom, but if you consider another attribute, no.",
            "Yeah.",
            "But but I agree with you.",
            "But maybe the professors can be identified by saying it's a set of things that not connect to each other maximal set of nodes that never connect to each other, and each of them is connecting to a set of things that you cluster the students.",
            "Maybe there is a way to do it, but it's not just based.",
            "On pairwise relationship it based on we take into account larger sets of elements.",
            "Check the graph.",
            "No, but here it's a natural cluster.",
            "I mean, this collection of AD L4 nodes is a natural cluster and still it doesn't show as a cluster.",
            "You just look at pairwise distances.",
            "Then then after you TV space, you can still define a cluster on the basis of this yeah.",
            "My point, I mean, it depends on the richness, right?",
            "Well no, I understand completely.",
            "But what I'm saying is that even if you just consider linkage, you can still identify professors, but not as a natural notion of clustering.",
            "You can identify them by the way they link and don't link to other nodes.",
            "Just based on linkage information.",
            "OK, so this is the end of my of this part of my presentation and this was the my.",
            "The less technical part, the second part will require a little bit more time."
        ],
        [
            "And we don't have it so.",
            "OK, so I think I'll skip.",
            "The open questions here because."
        ],
        [
            "Wait and go into this different approach so the different approaches saying OK, so trying to define what clustering is maybe too ambitious or too vague, although I think it's an important task, so let's focus on sidestep this issue and focus on some.",
            "And let's say general task and the task will be find some necessary condition of good clustering.",
            "And just try to analyze one necessary condition that applies to good clustering regardless of the country clustering method or the data generation method."
        ],
        [
            "And one such candidate is the notion of stability.",
            "So what is the notion of stability?",
            "If you want to know that if the clustering that you are doing is meaningful, what you can do is take two independent samples of your data and cluster this sample and cluster that sample and compare.",
            "Did you get partitionings that look similar to each other?",
            "Because if each time that you take a sample, you get a completely different partitioning of data.",
            "It may be an indication that you're not doing the right thing in your clustering.",
            "So this idea is called stability.",
            "You cluster independent samples, you compare the resulting clusterings and meaningful clustering should not change much for money independent sample to another.",
            "And this idea has been employed.",
            "It's a very commonly used heuristic.",
            "People want to check how good is the clustering.",
            "They take samples of their data, cluster them, and want to see that they get similar results.",
            "And this idea, I mean, this is just a list of recent papers, but you can see in many areas of clustering the same idea being employed over and over again.",
            "The problem is that until two years ago we didn't have any theory to support this heuristic of stability.",
            "It's a very commonly used juristic, but we didn't have any theory that all that it really does what we expect it to do.",
            "It just sounds reasonable."
        ],
        [
            "Now, another reason it sounds reasonable because it really resonates with some very basic idea of science, which is replication.",
            "If I come to you with some physical experiment, if I drop an Apple, it falls to the ground you want to be able to replicate this experiment and get similar results, so it's the same thing here.",
            "I took my data and told you that partitions into two clusters like this you want to be able to replicate it, so we will take some other sample of the data and apply your clustering algorithm.",
            "We want to see similar results.",
            "So it's a very natural idea and replication has been investigating many application of clustering.",
            "The funny thing is it's mostly done by visual inspection.",
            "If you look at papers in social Sciences they do replication clustering but it just say look at those pictures.",
            "Aren't they like each other?",
            "You know look at my baby, isn't it nice?",
            "It's not very satisfying scientific way of doing stuff and we were trying to analyze this."
        ],
        [
            "OK, so the first step to analyze it, you have to define it precisely.",
            "So here is the definition.",
            "So now we assume because we want to take random samples, we assume that there is that your data is some probability distribution.",
            "So it's a probability distribution over a domain that gives you the points and clustering is defined over samples.",
            "So we can take a sample and apply your algorithm against a partitioning of your whole data space.",
            "And we need the notion of similarity between different classrooms.",
            "You where you want to be able to measure when two clusterings are similar or not.",
            "So we have to add to our structure notion of similarity which is capital D between those two clusters and for sample size MI said that the instability of my algorithm on this data set is the expected distance.",
            "If I take 2 independent samples of size N, is the expected distance between the clustering of.",
            "Induced by the 1st sample and the clustering induced by the 2nd sample.",
            "So my instability is the expected distance between the clustering that I get by clustering two independent random samples.",
            "And as you can see, it's a property of both my clustering algorithm and my data, and of course the sample size.",
            "Yes.",
            "The first one.",
            "When you in your dress and in result you assume that the person on your exam find do better, brother or sister.",
            "I mean right?",
            "Do you must have this right?",
            "So you have to define this notion of of distance.",
            "There are really two different settings here.",
            "One, when the number of clusters is fixed and one with it's not fixed and you have to be able to define in the non fixed number of classes you have to be able to define what's the distance between two clusterings over and there are natural definitions.",
            "I don't want to get into this, but for example a natural definition is that.",
            "I take random pair of points and I asked you what's the probability I asked the first clustering.",
            "Do these points belong in the same clusters or are there separated in different clusters an I can ask the same question to the other algorithm and my similarity will be the probability that will both give me the same answer.",
            "So you randomly pick pairs of points and ask the two clusterings.",
            "Are they in the same cluster or not?",
            "And this is a notion of similarity that is doesn't care about the number of clusters.",
            "OK, so we can overcome this problem, so that's my formal definition of."
        ],
        [
            "Ability and the first thing you hope to do.",
            "I don't know how many of you have been working in classification in statistical learning theory, the first thing you want to get is a uniform convergence results, no matter what my my.",
            "Input space distribution is if I take M large enough things converge and of course we cannot get it here.",
            "So for example, if my data is the uniform distribution over the circle and then any clustering algorithm they'll take will be unstable, because if I just want to partition it into two sets and I take a random sample, it will probably give me this petition.",
            "Then I take another random sample, it will give me that partition.",
            "So it will be very unstable in terms of how it partitions the point.",
            "So on such datasets I would be very unstable.",
            "Maybe it's a good indication that they are not cluster."
        ],
        [
            "Apple.",
            "Another problem of instability could be that depending on the algorithm, if this is my data, it's the uniform distribution over 2 rings.",
            "Then if I use linkage algorithms that try to connect points when they are close together, then when my sample size is big enough I'll get consistent some clustering.",
            "I always get one ring versus the other ring, but if I use the non appropriate a center based clustering like K means, K means on this picture will be very unstable even if I just try 2 means it will just separate it like this.",
            "So like this or like this, depending on the randomness of the sample.",
            "So it shows me that stability can be a good indication to what is the right paradigm.",
            "The appropriate clustering paradigm for my data here linkage based will work.",
            "K means will look very unstable, linkage base will look stable.",
            "Maybe it's indication that for this type of data, linkage based clustering is better.",
            "Because distance is only this is like conceptual clustering.",
            "How you treat me right now, I'm now talking, right?",
            "I switched gears and I'm now talking about clustering.",
            "Say in our end.",
            "So your points your input points are vectors in our end and you want to cluster them so we have more information.",
            "I there was this discussion of the axiomatic framework for the axiomatic framework I was trying to address.",
            "The simplest possible scenario.",
            "Now I'm talking about something very practical that people do all the time in many applications of clustering, and they usually it's being done.",
            "Points are vectors in RN and I want to analyze this very useful heuristic.",
            "So I'm not working my input spaces now are in.",
            "OK.",
            "So what I'm saying here is that stability can distinguish between an algorithm which is appropriate for my data, and an algorithm which is not a prop."
        ],
        [
            "So my data it can also help me choose the number of clusters.",
            "So for example, if this is if my input is a uniform distribution over those four spheres, then if I choose try to cluster it into two clusters, it will be very unstable because I can get depending on my sample.",
            "I take a sample and I class rate so high."
        ],
        [
            "Can either get this clustering or that clustering depending on the randomness of the my sample.",
            "If I forced it to have just two classes, but on the other hand, if I say I want four clusters, then it will be stable, so stability can also not not just help me choose between different clustering paradigms, but it can also help me choose the correct number of clusters so it looks like it."
        ],
        [
            "So promising tool, we view stability as a measure of fit between the probability distribution and the clustering model and.",
            "Stability fails when the clustering model is not aligned with your input data."
        ],
        [
            "And so we therefore can use it as a model selection tool, and that's the way it's being used.",
            "It's a model selection tool.",
            "You want to select the right model, the right algorithm, the right number of K for your data.",
            "You estimate the instability of your algorithm on your data, and you choose the algorithm or parameters that maximize the stability.",
            "That's the way it's being used as a model selection tool."
        ],
        [
            "And now we try.",
            "To prove that it really works.",
            "So.",
            "We looked at two different algorithms, basic algorithms, center based like K means and linkage based algorithms and we look at very simple sets of data.",
            "Since a synthetic set of data, mixture of Gaussians or mixture of cervical.",
            "A this uniform distributions and we could prove that in all those cases.",
            "Those two types of algorithms, these types of data, we could prove that in all those cases, stability correctly detects the right algorithm and the right number of clusters.",
            "This is a proof.",
            "Now it's not heuristic, but in order to prove it we needed to restrict our attention to very specific distributions.",
            "You can't very difficult to prove that it will give you the correct number of clusters for every distribution, but that was an initial step.",
            "And we also have."
        ],
        [
            "The results that showed it work very nicely.",
            "So here for example what I'm doing here is I have my distribution.",
            "Is this Swiss roll with three different components.",
            "So there is chocolate, vanilla and.",
            "Something Gen three different components in your Swiss roll, and you want to be able to class.",
            "And then I'm doing her single linkage clustering and my parameter is when do I stop merging points?",
            "So if I choose the distance.",
            "For merging points too large then I get this kind of.",
            "Picture where it connects points across different layers."
        ],
        [
            "If I choose my distances.",
            "To be my threshold to be .15 I get is very nice.",
            "Partitioning into 3 rolls if."
        ],
        [
            "So I choose my threshold to be too small.",
            "Each role fractions into small subgroups and the question is so we know that the correct for this data the correct value of threshold should be .15.",
            "Can stability detect it for me?",
            "So we have this very nice picture where here I draw the instability with different threshold values.",
            "And here, in order to know whether I got the correct thing or not, I what I draw here is the percentage of points that fall into the third largest cluster.",
            "So if you have 10 clusters, I just look at the third license cluster and what percentage of of points folder.",
            "And because we know that our data was generated by three rolls."
        ],
        [
            "We want that the third largest cluster will contain a third of the points, and if we compare here the graph of instability with different values and the size of the third largest cluster, we see that the instability beautifully detects the values that give you the correct clustering for this data.",
            "This empirical, this is a yeah this is empirical but we could also prove that it does it so the Scituate."
        ],
        [
            "Mission was.",
            "December 205 the situation was very nice.",
            "We could formally we formally define the notion of stability.",
            "We could argue that's a necessary property of any clustering method.",
            "We could prove that it really works for those very simple distributions like mixture of Gaussians and Swiss rolls.",
            "And.",
            "We're so we could prove that it works very nicely and it also worked very nicely in practice.",
            "So everybody was happy and we."
        ],
        [
            "Set.",
            "In the beginning of two or after at the beginning of Ingenerate or six, Ulrika looked vulnerable.",
            "Visited Maine with my student.",
            "We set to prove you know, to put the final nail into this structure to prove that stability really does what you want because we have all the possible evidence.",
            "And then.",
            "It's a question how do?",
            "Formulate what is the correct job, but don't."
        ],
        [
            "Sorry about that, but then we started working on this and.",
            "We started seeing some things which are not so satisfactory, so consider for example, these two data sets and assume that you have some K bigger than one.",
            "What will happen here?",
            "Will it be stable or not?",
            "If I just take a random sample, want to cluster into three sets, then another random sample clustering it resets.",
            "That's my generating distribution.",
            "Will it be stable or will it shift all the time?",
            "What?",
            "It shift all the time, right?",
            "But what will happen here?",
            "If this is my data, it will be stable, but this is a very small change of my data.",
            "If I take here any partitioning into three sets, eventually what I'll get is just three sets like this, but here it was unstable.",
            "Now the answer that the number of correct number of.",
            "Clusters is 3.",
            "You cannot really argue that the correct number is 3 here and not here.",
            "But stability doesn't detect it, so we started seeing those funny examples, and then we could turn."
        ],
        [
            "I'm into a theoreme, so the bottom line of our analysis, which lasted more than a year.",
            "Was that we collectivize exactly stability, at least for K means and.",
            "We know.",
            "Exactly what it detects, and we conclude that the success of stability in practice is only coincidence.",
            "It is not a general rule, so it's a very funny situation with something works in practice.",
            "It also works on very artificial data when you analyze it mathematically, but I'll give you the characterization and I argue that this characterization shows that stability should not work in general."
        ],
        [
            "So here is the characterization.",
            "So we say that the data is stable if the limit as the sample size goes to Infinity, it become the instability becomes 0, so that is stable is when you take large online sample sizes, it becomes more and more stable and we could prove the following that if your algorithm is cost minimizing like K means, you're trying to minimize the K means costs that what you algorithm is striving to get.",
            "If you have a cost minimizing algorithm.",
            "It is stable on a data set D if and only if there is a unique minimizer to the function you are trying to optimize.",
            "If and only if there is a unique partition that achieves.",
            "The optimal value.",
            "So rather than finding the correct number of clusters, it detects whether there is a unique optimal solution or several optimal solutions.",
            "You see, if we go back."
        ],
        [
            "If we go back to this picture here, if K = 2, There are many possible partitionings that will give you the same K means value.",
            "But here, for K = 2, There's only one partitioning that gives you the minimal value for K means an.",
            "What we found out this ability exactly detects this thing.",
            "The question whether there is optimal unique optimum solution or multiple optimal solutions.",
            "And now we can ask ourselves so."
        ],
        [
            "Yeah."
        ],
        [
            "Oh, that is set before us is a probability distribution over some domain.",
            "It doesn't matter, doesn't matter.",
            "Could be infinite or finite, so probabilities this will never sell domain.",
            "You can think of it as a file domain with uniform distribution if you want.",
            "And then the question is, you're trying to optimize some cost.",
            "Stability detects just this now.",
            "I don't think I have time to go into the proof."
        ],
        [
            "I mean, this is the proof."
        ],
        [
            "Idea?"
        ],
        [
            "I mean the idea of showing you the proof is just.",
            "Convincing you that this is hard proof, so you should accept it to whatever your can't."
        ],
        [
            "This is the proof is hard."
        ],
        [
            "OK, So what?",
            "What is the conclusion?",
            "Anne.",
            "The common belief was that a is stable or a distribution P if and only if our algorithm picks the correct number of clusters.",
            "That was the common belief and that was really the way it's being applied all over many domains.",
            "Yes.",
            "Suppose I have an algorithm that always reports a single cluster of all points is very stable, right?",
            "Right, it's stability is only a necessary condition for good clustering, not a sufficient condition for good classroom.",
            "OK yeah, OK, you're right, it's only a necessary condition.",
            "Now what our theorem is.",
            "Iff what we have is a complete characterization and it says that your if you if you algorithm.",
            "Is trying to minimize some notion of cost some well defined notion?",
            "Of course then.",
            "A is stable on P if and only if there is a unique solution.",
            "Unique optimized solution for this data set.",
            "So we have a complete characterization of what stability does and the question is.",
            "Are these two notions the same?",
            "Is correct K the same thing is saying we have a unique solution?",
            "And we already seen one example where it doesn't and I can show you now some more examples which really show that it can go wrong in many many ways, so here."
        ],
        [
            "Some very simple examples, so assume that all the time in my examples now.",
            "So now what I want to do is show you in examples that those two notions of correct number of clusters and having a unique minimizer for the cost function are not the same.",
            "So here is an example very simple example.",
            "All my data sets will be on the line and these are just the density function.",
            "So if your density function is 50% of your data is here and 50% of the data is here.",
            "So what you think is the correct number of clusters.",
            "Two, if I try K = 2, will it be stable?",
            "Yes, because there is a unique solution."
        ],
        [
            "Right, so if they try.",
            "Two centers, it's stable because the unique optimal solution.",
            "What happens if I try cake was three.",
            "Will it be stable?",
            "It will not be stable."
        ],
        [
            "'cause we have two.",
            "Sufficient suex same cost meaning optimisers.",
            "This is 1 optimizer and another optimizer."
        ],
        [
            "Is this one?",
            "Both of them achieve the same cost so I have non unique optimizer for.",
            "K = 3, So the conclusion is 3 is not is unstable, two was stable.",
            "Instability did a good job.",
            "Yes.",
            "What for fall is going to be stable again?",
            "Yeah, that that that you push into my next example, right?",
            "You're right, for for it will be stable again, right?",
            "So for maybe a good."
        ],
        [
            "Right, so here is another example.",
            "Now I change my example only a little bit.",
            "I put here 50% plus epsilon of my weight and here I have put 50% minus epsilon of my weight.",
            "Now with K, what's the correct number of clusters?",
            "We will agree that it's two with K equal 2.",
            "Will it be stable or not?",
            "It will be stable if I just have two."
        ],
        [
            "Once it will be stable, there's only one optimal solution, one in each center.",
            "What will happen for K = 3?",
            "It would be a nice table for K = 3."
        ],
        [
            "Be cause for K = 3 we have a unique optimum solution.",
            "We have to put the two here and the one there because this has higher.",
            "Hey wait, so we see here that if I use stability as my indicator to what's the correct number of clusters, I can distinguish between two and three, although in terms of our intuition two and three are clearly distinguishable.",
            "There's no argument here."
        ],
        [
            "And I can also do an example, yes."
        ],
        [
            "Easy easy.",
            "Maybe depends on what you mean by minimalization.",
            "Cause yeah, I'm talking about the K means cost here.",
            "Then we'll start posting is immunization, for example, or two centre, or just got two points and you change the time.",
            "I brought the two OK.",
            "Yes, it is the minimal cost that this algorithm is stable because.",
            "OK, so.",
            "No, OK, I I we we have a formal list of some properties that this cost function should satisfy so that this characterization holds, but in particular it holds for K means for K, median for sum of distances for many very useful class ring cost function this characterization hold so."
        ],
        [
            "Here is another example.",
            "Here I have 90% of my weight here in 10% of my wait here.",
            "Now what will happen here is if I play with the distances carefully."
        ],
        [
            "I can make it that there are two optimal solutions for K equal to the cost of this having two centers here.",
            "And no center there is the same cost as having one sensor in one center there just by playing with the parameters you can tailor it this way.",
            "So two will be unstable, 'cause if there are multiple solutions our theorem says it's unstable.",
            "And."
        ],
        [
            "We will be stable.",
            "OK, so well we no I I just lost my.",
            "Anne.",
            "We want to be here and then we want to go.",
            "I don't know what's the fastest way to get to this point anyway.",
            "It's a nice review for you of everything we did.",
            "Come on.",
            "OK, So what is the bottom line that?",
            "This is a very interesting point.",
            "In practice, no data set has more than one optimal solution.",
            "There's no symmetry in the world.",
            "I mean, the multiple solutions were because there was some very finely defined balance between different solutions, but in reality every natural data set will have only one optimizer, because there's no symmetry and therefore in practice if you check stability and your sample sizes become big enough.",
            "Everything will always look stable.",
            "So it's true, this ability is a necessary condition, but it's a trivial necessary condition.",
            "It will always hold once you sample sizes are big enough, and he's a very strange phenomenon.",
            "Usually we think that the larger the sample size we try, the better the results.",
            "And here we're in the situation that if you sample sizes grow too large, everything trivializes everything.",
            "In every real data set, everything will become stable.",
            "Therefore any choice of clustering parameters on real data set.",
            "Will always end up being stable if your sample sizes go.",
            "Large enough instability does not do the job that we thought it did I mean it does it in practice, but when we analyze it.",
            "There is some discrepancy between what should happen and what happens in practice.",
            "Maybe it's due to show using two small sample size, yes?",
            "It's very difficult to.",
            "Define systematically.",
            "If you imagine the images, yeah, but I'm saying when I'm saying it on real data there will never be a situation where two solutions are exactly optimal.",
            "Both of them will always be one of them, a little bit preferable to the other.",
            "Thanks ability already allow for like even just.",
            "I'm not trying to.",
            "I mean what I'm saying I'm using my theorem saying I don't have to evaluate stability.",
            "Would have to ask myself is I look at the K means cost function.",
            "Is there a unique minimizer to the K means?",
            "Oh, there are two solutions that have exactly the same value and in real data there will always be a unique minimizer.",
            "Yes.",
            "Yeah, it's important is the rate, but it's something that we cannot predict, right?",
            "True that there will be always minimizer if the data is somehow resembles some kind of fractal structures that you have.",
            "The broad feature three clusters you dig into the cluster begin has three clusters of different, even though we can always cluster it's in so well, I'm saying is I'm looking at the clustering.",
            "I say we consider only K means cost and you want to minimize the K means cost and you fix your K and I try to see whether K = 2 is good.",
            "OK equals 3 is good, OK equals 4.",
            "Cake was heaven is good because then it's zero, right?",
            "So what I'm saying is that you always get if you just use stability and your sample sizes are big enough, you will always get it no matter what your choice.",
            "What it will look good.",
            "That that's the.",
            "One way of interpreting those results."
        ],
        [
            "So.",
            "There is a very important take home message here and that is that syntactic datasets can be misleading.",
            "I mean, as long as I was working with syntactic data sets, a mixture of three Gaussians and mixture of trickle, there is some inherent regularity in syntactic data, and in this case it really misled our understanding of what is happening here.",
            "And in some cases, the distinction between syntactic and synthetic and real data is really crucial here.",
            "In our case, we in on synthetic data, it works beautifully both in simulations, and we could prove it even we can prove it for synthetic data.",
            "For mixture of Gaussians.",
            "But when you analyze it fully, you realize that this is all due to some inherent symmetry.",
            "In the way we generated our synthetic data and I think it's a very interesting take.",
            "Home messages sometimes think that what you get on synthetic data is not a true reflection of what you will get in reality.",
            "Our synthetic data is just too simplistic and this is a very strong demonstration of this principle.",
            "Things that work beautifully on synthetic data when we analyze them, we conclude that on real data they trivialize.",
            "Yes.",
            "What are you playing this video that I saw this right number cost is only say, repeat it again.",
            "I'm concerned about your work with.",
            "This ability will establish correct number.",
            "Really, really plastic primer on processors.",
            "If there is a slight difference in payment.",
            "Austin Gay pursuing cake was 50 and how much?",
            "Basically putting that well I'm saying is I wasn't saying I was saying it on when we check it on very simple synthetic data.",
            "Chris stability to good job.",
            "When you go to real data when the differences are very small no matter what is your choice of parameter when the sample size grows big enough.",
            "It will get stable.",
            "In the limit on large sample, it will always be stable, so if there are small differences when my samples have become big enough to detect those small differences, it will always home zoom in on one particular solution and will look stable.",
            "F. Today we are still relative differences between them before using them in various different.",
            "That's a very good question, and that's my next slide that I thought that I will not have to show you, why?",
            "So we still had the question of, so why does it work in practice?",
            "I mean, you cannot just say I prove that it shouldn't work, and I don't care about the world.",
            "I mean I, it works for you, but as far as I'm concerned.",
            "The world is irrelevant.",
            "Only my notebook is is interesting, so why does it work in PRAC?"
        ],
        [
            "So we carry it for further, so we know that in the limit of M Everything will go to zero, but we were looking at.",
            "Assume you're comparing two values of KK&K prime.",
            "So I know that on real data this will go to zero and this will go to zero, but I can look at this ratio of a fixed M. And I look at this ratio of what the instability with K and the instability in K prime and we are.",
            "On our way to proving, I mean we have still holds in our proof that if a K if with parameter K, we output the output clustering has boundaries that pass through considerably denser regions then the output of the clustering that I get with K prime.",
            "Then this ratio will be bounded away from one.",
            "Then although the in the limit both of them will go to zero, I will be able to tell if one of them is.",
            "Clearly better than the other in terms of the boundaries passing through dense through sparse regions.",
            "If it's a clear difference between them, then for all sufficiently large M this will be bounded away from one.",
            "It will show me that one of them is preferable.",
            "But the big problem about this result when you compare it to reality is that this holds only for sufficiently large M and we can show that there's no uniform convergence here, so you don't know when you see your data.",
            "You don't know what is the correct sample size.",
            "For my data, you just know that.",
            "If you're unhappy with the results, I can always have a good excuse.",
            "I'll tell you you didn't use the large enough samples.",
            "And you can never catch me because I'm just saying that in the limit something will happen, but it gives a partial explanation of why stability works so nicely in practice.",
            "But I still think that the more important conclusion"
        ],
        [
            "Is this very striking difference between what we see on synthetic data and what happens in real data?",
            "OK, so this is concludes my this part of my talk tomorrow morning I'll talk on completely different issue which is by clustering.",
            "When you want to cluster two sets together based on mutual relations between them and it will have a slightly more technical flavor.",
            "Thank you very much.",
            "Yes.",
            "So there is also the issue of noise and quite interesting.",
            "You're instead the issue whether we can see this between structured data and some data where it makes sense for clustering.",
            "So in fact we probably often have something like like an overlay between some background noise, let's say more or less equally.",
            "Moises Predator in our space.",
            "We have sort of clusters.",
            "We would like to have.",
            "So in those cases, ability help or so, it's again.",
            "This distinction here between stability in theory and stability in practice, and it in practice, I've seen many claims that stability works.",
            "I mean, like I was working with.",
            "Say for in in Germany and she was doing stability on Poles in Germany that we're asking people about their happiness.",
            "With life.",
            "I mean are you happy with your life?",
            "Are you happy with your salary and then clusters?",
            "The outcome of those results according to regions in Germany and she could reconstruct the border between West and East, the old Western East Germany.",
            "And this is very noisy data and she was just using stability to detect what is the correct number of clusters.",
            "And any things that became stable was giving her some meaningful partitioning of Germany.",
            "So in practice it seems to work even on noisy data sets.",
            "The theory indicates that sample size grow big enough, the picture becomes blurred no matter what you start with.",
            "Question sometimes.",
            "Example circular Baker.",
            "Some things you don't know.",
            "The many colored version data come from.",
            "Selection or search technique which one could apply for let's say so.",
            "Is on those artificial examples on these synthetic data, you could see that that just using stability could help you decide which algorithm you want to use.",
            "Case enters you want to link it based the on the synthetic data.",
            "The stability did a good job of telling you it doesn't tell you what the manifold is, but it tells you what method is more appropriate for your data, which is a big step in that direction, but it doesn't tell you what the data is.",
            "I mean that I agree.",
            "So do you think price is one thing that you are in my is that basically stability you can travel customers.",
            "I'm saying that this is the common use and our analysis shows that it gives you something different.",
            "Instead of giving you the number of clusters, it tells you whether there's a unique optimum or multiple optimal.",
            "As opposed to the practical use, the practical uses to detect K. But people hope to find escape, but sometimes if there is no pain, yeah yeah OK yeah, I mean of course this task of finding the right case very complex, but this is a tool that people apply very often to approximate this task of finding K. But it does something different than what you expect, yes?",
            "Yeah.",
            "Right, so so the gap gap statistics has no theory that what so I mean, there's a lot of mathematics, lot of calculations, people use it a lot, right?",
            "But there's no theory that try to argue why it gives you the correct values.",
            "So I agree that it may be appropriate to try to apply a similar analysis to get statistics.",
            "There are different methods, we just chose one method and try to analyze it, and that's what we got there.",
            "Many other methods that I really think it's a nice challenge.",
            "To try to analyze what are they really giving you an gap statistics are very natural candidate for that.",
            "I agree and it has not been done.",
            "OK.",
            "Thanks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I want to talk about some issues in the theoretical foundations of clustering and my my talk will actually be 3.",
                    "label": 0
                },
                {
                    "sent": "A different topics of different flavor.",
                    "label": 0
                },
                {
                    "sent": "So the first one will be very fundamental.",
                    "label": 0
                },
                {
                    "sent": "Try to discuss a little bit.",
                    "label": 0
                },
                {
                    "sent": "How can we define what clustering is?",
                    "label": 0
                },
                {
                    "sent": "The 2nd will be 11 progress that we made in the understanding.",
                    "label": 0
                },
                {
                    "sent": "Trying to understand clustering is in a principled way and then tomorrow and in the morning.",
                    "label": 0
                },
                {
                    "sent": "What I'll talk about is very specific clustering.",
                    "label": 0
                },
                {
                    "sent": "Problem which is called big clustering and I'll discuss the algorithmic complexity of that problem.",
                    "label": 0
                },
                {
                    "sent": "So the three different parts 2 today, 1:00 tomorrow and quite different in flavor so.",
                    "label": 0
                },
                {
                    "sent": "You can pick and choose OK, so I want to talk about the theoretical foundations of clustering and I.",
                    "label": 1
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I think we all know that that clustering is very widely widely used for exploratory data analysis.",
                    "label": 1
                },
                {
                    "sent": "You use it like all over the place in understanding social networks in biology, analysing an analysis of microarray data in astronomy to find groups of planets of stars and in computer science.",
                    "label": 0
                },
                {
                    "sent": "Of course, we use clustering a lot in data mining.",
                    "label": 0
                },
                {
                    "sent": "It's very heavily used.",
                    "label": 0
                },
                {
                    "sent": "And surprisingly, in spite of this heavy use of clustering for many years.",
                    "label": 1
                },
                {
                    "sent": "There is very very little theoretical understanding of what clustering is, so it's in sharp contrast to what we've seen classification, classification.",
                    "label": 0
                },
                {
                    "sent": "We have beautiful theories, convergence results, large margins, VC theory, whatever you want.",
                    "label": 0
                },
                {
                    "sent": "We understand the task.",
                    "label": 0
                },
                {
                    "sent": "In clustering, it's almost as useful.",
                    "label": 0
                },
                {
                    "sent": "I think Amanda can't compare, but it's very, very useful.",
                    "label": 0
                },
                {
                    "sent": "We hardly have any theory at all.",
                    "label": 0
                },
                {
                    "sent": "To understand to give us any guarantees about clustering.",
                    "label": 0
                },
                {
                    "sent": "So this is the very ambitious task that I'm trying to address.",
                    "label": 0
                },
                {
                    "sent": "And of course the task is very ambitious, we achieve only.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Small steps, so the sum, of course, inherent obstacles.",
                    "label": 0
                },
                {
                    "sent": "Why we don't have a theory of clustering, and I think the first one is that clustering is not well defined.",
                    "label": 1
                },
                {
                    "sent": "Then.",
                    "label": 0
                },
                {
                    "sent": "I mean, if I want to to cluster.",
                    "label": 0
                },
                {
                    "sent": "If paintings, I can either cluster can cluster them, you can say the correct clustering is by identifying who the painter is, but another person will say the correct clustering is by the topic of the painting and there's no well defined notion of what is.",
                    "label": 0
                },
                {
                    "sent": "The correct clustering so that it's not well defined.",
                    "label": 0
                },
                {
                    "sent": "Another related problem in class ring is that we don't have any ground truth.",
                    "label": 0
                },
                {
                    "sent": "It's not in classification.",
                    "label": 0
                },
                {
                    "sent": "You eventually reveal the correct label of your data point and you can measure whether your prediction was correct or not.",
                    "label": 0
                },
                {
                    "sent": "You saw those graphs at the end of Nicolas talk.",
                    "label": 0
                },
                {
                    "sent": "We could see how well we're doing in clustering.",
                    "label": 1
                },
                {
                    "sent": "There is no ground truth that we can compare our results to it so.",
                    "label": 0
                },
                {
                    "sent": "There is no objective measure of how well we're doing, which makes it of course, much harder to develop any guarantees of performance.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Just to demonstrate it is not well defined problem.",
                    "label": 1
                },
                {
                    "sent": "You can say how how should I cluster this cloud of points and one way could be doing it this way by trying to make the separation at the point of the largest gap.",
                    "label": 0
                },
                {
                    "sent": "But another solution which is.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is where it could be.",
                    "label": 0
                },
                {
                    "sent": "Try to cluster it like this to find 2 centers that best attract the two points and what is the correct way of clustering this cloudpaw?",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here is another example.",
                    "label": 0
                },
                {
                    "sent": "If you get this cloud, you can have look at these two clusterings and try to argue why is one of them better than the other.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So there's several approaches to this problem.",
                    "label": 0
                },
                {
                    "sent": "Of course it's not a new problem, and.",
                    "label": 0
                },
                {
                    "sent": "And one approach that is very appealing is that somatic approach you try to postulate some clustering axioms.",
                    "label": 1
                },
                {
                    "sent": "What should clustering satisfy, and ideally every clustering approach to satisfy these axioms and every function which is not a clustering should fail.",
                    "label": 1
                },
                {
                    "sent": "Some of those axioms and regret somehow.",
                    "label": 0
                },
                {
                    "sent": "I think disappointingly, most of the all of the literature that was trying to do this.",
                    "label": 0
                },
                {
                    "sent": "Ended up showing negative results, showing that our axioms do not work, and I'll show you one such example of what do I mean by negative results.",
                    "label": 0
                },
                {
                    "sent": "Another approach is to try to say OK, so clustering is not well defined.",
                    "label": 1
                },
                {
                    "sent": "Let's add structure on top of just having a cloud of points.",
                    "label": 0
                },
                {
                    "sent": "So for example, if we have a notion of relevant information on top of our collection of data points, then we can use approaches like information bottleneck or any kind of information theoretic approaches to somehow tell us what is the better clustering than other.",
                    "label": 0
                },
                {
                    "sent": "Another way of adding structure is to define some.",
                    "label": 0
                },
                {
                    "sent": "Objective utility function.",
                    "label": 0
                },
                {
                    "sent": "So if you're doing clustering, for example for for coding, then you can say what I want to choose code words in such a way that the distance of a random word from the closest code word is minimized.",
                    "label": 0
                },
                {
                    "sent": "So I add on top of my structure of just points and distances some notion of what's my objective is a precisely defined objective function, and this allows me to make progress in my theory.",
                    "label": 0
                },
                {
                    "sent": "In my guarantees in analysis of my algorithms.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Another approach that is widely addressed in the literature is consider only a restricted set of distributions.",
                    "label": 1
                },
                {
                    "sent": "So we can say our data is not arbitrarily generated, but it's generated, say by a mixture of Gaussians.",
                    "label": 0
                },
                {
                    "sent": "If we make such an assumption, then we have a ground truth.",
                    "label": 0
                },
                {
                    "sent": "Then we can say how well did we do.",
                    "label": 0
                },
                {
                    "sent": "We can measure it by how close did we approximate the original mixture of Gaussians that actually generated our data?",
                    "label": 0
                },
                {
                    "sent": "So that's another way of adding structure.",
                    "label": 0
                },
                {
                    "sent": "To make the task better defined, but of course.",
                    "label": 0
                },
                {
                    "sent": "Assuming that you know what the distribution that generated the data is, I mean it's very common in statistics, but when you think about it, it's not really realistic, you don't.",
                    "label": 0
                },
                {
                    "sent": "Really believe that I don't know what when you want to cluster documents on the web that generated by a mixture of three Gaussians or something, but it allows to do very nice theoretical work.",
                    "label": 0
                },
                {
                    "sent": "An another solution is to focus on a specific arhythmic paradigm, so we can say all I care about is this type of clustering algorithms and I'm trying to analyze and understand them better.",
                    "label": 0
                },
                {
                    "sent": "So there's a lot of work on.",
                    "label": 0
                },
                {
                    "sent": "Projection based clustering like.",
                    "label": 1
                },
                {
                    "sent": "Principal component analysis or spectral based clustering or speculate citations.",
                    "label": 0
                },
                {
                    "sent": "So you fix one algorithm OK means algorithm.",
                    "label": 0
                },
                {
                    "sent": "You focus on one algorithm that you really think is central and try to analyze or improve the.",
                    "label": 0
                },
                {
                    "sent": "A behavior or the performance of algorithms under this specific padding.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the question is, what can we say about clustering which is independent of any algorithm or objective function or a model to generate the data?",
                    "label": 0
                },
                {
                    "sent": "Can we say something which will be more general and apply to all of those different types of clustering?",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Why do we want to answer such a question?",
                    "label": 0
                },
                {
                    "sent": "I think that very important questions to answer here in the general setting.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Like what is clustering?",
                    "label": 0
                },
                {
                    "sent": "What is a good clustering?",
                    "label": 1
                },
                {
                    "sent": "If I give you a clustering algorithm and you want to?",
                    "label": 0
                },
                {
                    "sent": "I mean if you go to conferences and see people presenting the clustering algorithms, usually the way they show you that the algorithm is better than all the previous algorithms is by showing you pictures.",
                    "label": 0
                },
                {
                    "sent": "Look at the picture.",
                    "label": 0
                },
                {
                    "sent": "Aren't you convinced that my clustering is the right one?",
                    "label": 0
                },
                {
                    "sent": "But this is limited scientific value and it can only work in dimension 2.",
                    "label": 0
                },
                {
                    "sent": "But we are clustering that in hundreds of dimension.",
                    "label": 0
                },
                {
                    "sent": "So we really want to answer the question what is a good clustering and we really want to be able to say.",
                    "label": 0
                },
                {
                    "sent": "You know, can we carry out clustering efficiently?",
                    "label": 0
                },
                {
                    "sent": "How much running time do you need?",
                    "label": 0
                },
                {
                    "sent": "If you don't know what's a good clustering, you can't answer the question how much running time do you need and how much space do you need?",
                    "label": 1
                },
                {
                    "sent": "Can we distinguish clusterable form structure?",
                    "label": 0
                },
                {
                    "sent": "Is that if I give you some data and I tell you, here is my patience from a medical repository and I have I want, ask you do those patients naturally cluster into groups, so we will treat each group separately?",
                    "label": 0
                },
                {
                    "sent": "All they are all just one big mix.",
                    "label": 0
                },
                {
                    "sent": "Can we define a notion of classical data?",
                    "label": 0
                },
                {
                    "sent": "These are very important questions and we don't have answers to this kind of questions, so I will start by presenting an axiomatic approach that was initiated by John Kleinberg and then we will see what can we.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Take from there.",
                    "label": 0
                },
                {
                    "sent": "So John Piper gotta I think was it 2002 he tries to give some formalism to allow definition of clustering and general way so it restricts the set of clustering that we're looking at.",
                    "label": 0
                },
                {
                    "sent": "But it's still pretty general.",
                    "label": 0
                },
                {
                    "sent": "So the idea is that our domain is going to be a finite set of points S and on top of it we can't cluster point since we don't have a notion of which points are most similar to each other and which points are not similar.",
                    "label": 0
                },
                {
                    "sent": "So our input is a pair which is a set of domain points and distance function which I called this similarity function on pairs of points.",
                    "label": 0
                },
                {
                    "sent": "So we have this notion of.",
                    "label": 0
                },
                {
                    "sent": "Our input is just the final set of points and a notion of how similar they are to each other.",
                    "label": 0
                },
                {
                    "sent": "So we require this dissimilarity function is symmetric the distance between X&Y is the same as YX, and distance 0 only.",
                    "label": 0
                },
                {
                    "sent": "Of a point to itself.",
                    "label": 0
                },
                {
                    "sent": "And then we define a clustering function as a function that takes such input, which is a pair of a domain and distance.",
                    "label": 1
                },
                {
                    "sent": "So the clustering function takes such an input and outputs repetition of the domain.",
                    "label": 0
                },
                {
                    "sent": "That's basically what clustering functions do.",
                    "label": 0
                },
                {
                    "sent": "And what we wish to be able to define is to find some properties that distinguish clustering functions from functions which are not clustering functions.",
                    "label": 1
                },
                {
                    "sent": "Not every function that takes data as input and outputs a petition of the data will be considered the clustering function, right?",
                    "label": 0
                },
                {
                    "sent": "If I if you have a function that takes the real numbers as input and outputs the partition into rational numbers and irrational numbers, you are not likely to call it clustering.",
                    "label": 0
                },
                {
                    "sent": "So how do we distinguish between functions that we call clustering and functions that we don't concussing so?",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A client book offered three axioms.",
                    "label": 0
                },
                {
                    "sent": "So and they all sound pretty natural, so the first one is scale invariant.",
                    "label": 0
                },
                {
                    "sent": "So what do we mean by scary invariants?",
                    "label": 0
                },
                {
                    "sent": "If I take my dissimilarity distance matrix and I multiplied by constant so I didn't change the relative distances, I just took all the distances and say if the similarity between.",
                    "label": 0
                },
                {
                    "sent": "Me and John was two before now and multiply it by 10.",
                    "label": 0
                },
                {
                    "sent": "It will be 20 and if the similarity between you or 70 two 9070 we multiply everything by 10.",
                    "label": 0
                },
                {
                    "sent": "What we expect is that a good clustering function will not be sensitive to this.",
                    "label": 0
                },
                {
                    "sent": "Scale scaling.",
                    "label": 0
                },
                {
                    "sent": "If we scale all the distances, we should get the same clustering, so that's the scale invariants requirement.",
                    "label": 0
                },
                {
                    "sent": "F is the clustering function that's the the input distance metric, and if we input Lambda times the distance D, we should get out the same in the same position as with input.",
                    "label": 0
                },
                {
                    "sent": "DD is stands for the matrix of all the pairwise distances, so that's very natural the other one.",
                    "label": 0
                },
                {
                    "sent": "It is richness.",
                    "label": 0
                },
                {
                    "sent": "You want to say that the clustering function by rearranging the points by pulling some of them closer together and some of them further apart.",
                    "label": 0
                },
                {
                    "sent": "I can force my function to give me any desired partitioning.",
                    "label": 0
                },
                {
                    "sent": "So if I want to partition, it puts me on one side and all of you in the other cluster.",
                    "label": 0
                },
                {
                    "sent": "All I have to do is just walk away far enough from you and then my function should give me this partitioning if I want the partitioning that divides the class into two here, then I'll just pull these two groups apart and maybe make them closer together.",
                    "label": 0
                },
                {
                    "sent": "So you want a good clustering function to be rich in the sense that.",
                    "label": 0
                },
                {
                    "sent": "If I look at all the possible clusterings when I vary the distance metrics in all possible ways, then I'll get all the possible partitions of my domain.",
                    "label": 0
                },
                {
                    "sent": "So this is the other requirement that by varying the distances I can induce any possible partition.",
                    "label": 0
                },
                {
                    "sent": "That's another requirement from a good clustering function.",
                    "label": 0
                },
                {
                    "sent": "The last requirement is a little bit more complex, and it says the following.",
                    "label": 0
                },
                {
                    "sent": "So now assume that we have a distance matrix D and we have a partitioning FD.",
                    "label": 0
                },
                {
                    "sent": "So we already have our function.",
                    "label": 0
                },
                {
                    "sent": "Looked at this class and say it pursuit is it partitions with this distance is well, I just take the geographical distances between US and it pushes the class into three clusters.",
                    "label": 0
                },
                {
                    "sent": "This is 1 cluster.",
                    "label": 0
                },
                {
                    "sent": "This is another cluster and I'm the third cluster.",
                    "label": 0
                },
                {
                    "sent": "Now assume that I make a transformation of this distance D. Everybody in the same cluster gets closer together.",
                    "label": 0
                },
                {
                    "sent": "And between clusters I increase the distances.",
                    "label": 0
                },
                {
                    "sent": "So the requirement here if D prime equals D except for shrinking distances within the clusters and stretching.",
                    "label": 0
                },
                {
                    "sent": "Distances between clusters then?",
                    "label": 0
                },
                {
                    "sent": "The class ring that I get from this should be equal to clustering that I get from the prime.",
                    "label": 0
                },
                {
                    "sent": "It seems like if I already got the clustering and now everything it wasn't the same cluster got closer together and between any two clusters we got further apart.",
                    "label": 0
                },
                {
                    "sent": "I only strengthen my belief in this clustering, yes?",
                    "label": 0
                },
                {
                    "sent": "I'm.",
                    "label": 0
                },
                {
                    "sent": "These are accidents.",
                    "label": 0
                },
                {
                    "sent": "But do you have any examples which would contradict kind of these?",
                    "label": 0
                },
                {
                    "sent": "Because to me all of them seem very sort of natural and.",
                    "label": 0
                },
                {
                    "sent": "It's been frozen for this game.",
                    "label": 0
                },
                {
                    "sent": "Invariants, for example, do you have any examples that would violate that?",
                    "label": 0
                },
                {
                    "sent": "Make us regarding that actually move right?",
                    "label": 0
                },
                {
                    "sent": "So right yeah.",
                    "label": 0
                },
                {
                    "sent": "So so overlapping clusters are not clustered right overlapping classes and or class, so we're only talking about the restricted definition that says clustering is a partitioning of the data.",
                    "label": 0
                },
                {
                    "sent": "Every point belongs to a single cluster and all the points are being clustered.",
                    "label": 0
                },
                {
                    "sent": "You don't have any points left in the background, so back to your question.",
                    "label": 0
                },
                {
                    "sent": "So here there is.",
                    "label": 0
                },
                {
                    "sent": "There is some kind of catch.",
                    "label": 1
                },
                {
                    "sent": "So when John Kleinberg wrote these axioms, he had some model in mind.",
                    "label": 0
                },
                {
                    "sent": "There is a famous theorem by.",
                    "label": 0
                },
                {
                    "sent": "Arrow which is a economist that got the Nobel Prize for proving that if you want to have.",
                    "label": 0
                },
                {
                    "sent": "A perfect an election a.",
                    "label": 0
                },
                {
                    "sent": "A function that tells you that how, how do you do?",
                    "label": 0
                },
                {
                    "sent": "How do how should you consider the vote of every voter in such a way that the results of the elections will satisfy all the desired properties?",
                    "label": 0
                },
                {
                    "sent": "I mean, you don't want to be in a situation where, say I prefer a. I don't know which examples they can give you in Italy, but I prefer a candidate won over candidate 2, but I still prefer candidate three over both of them, so I voted for candidate three.",
                    "label": 0
                },
                {
                    "sent": "But then it turns out that kind of the tree didn't get enough votes.",
                    "label": 0
                },
                {
                    "sent": "And if instead of voting for three, I would have voted for two, I would have.",
                    "label": 0
                },
                {
                    "sent": "Better reflect my have a better effect of my vote.",
                    "label": 0
                },
                {
                    "sent": "So how can we have a voting function that doesn't have such errors and error?",
                    "label": 0
                },
                {
                    "sent": "Proved that if you list down a list of just a list of desired properties from voting function, you get a contradiction.",
                    "label": 0
                },
                {
                    "sent": "There is no function that satisfies all the desired properties now John Kleinberg.",
                    "label": 0
                },
                {
                    "sent": "So this arrow theorem and knows that error got a Nobel Prize and John also wants to be famous.",
                    "label": 0
                },
                {
                    "sent": "So he said I will do something similar for clustering an he designed those axiom.",
                    "label": 0
                },
                {
                    "sent": "Especially to get the contradiction to get a similar result to the arrow theory here are desired properties of clustering and I will show you that no function can satisfy all those three desired properties simultaneously.",
                    "label": 0
                },
                {
                    "sent": "But but they have sort of this region.",
                    "label": 0
                },
                {
                    "sent": "This kind of thing is something which is very dependent on the parameters of the cluster graduates, because mostly all of the algorithms are imagination.",
                    "label": 0
                },
                {
                    "sent": "It has some parameters that you have to provide, right?",
                    "label": 0
                },
                {
                    "sent": "So in many algorithms you fix the number of clusters, for example in advance, and then rather than requiring richness you would like to require K richness.",
                    "label": 0
                },
                {
                    "sent": "You get all possible partitions into K subsets rather than all possible partitions.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I'll discuss some variants of this.",
                    "label": 0
                },
                {
                    "sent": "But let me first show you how to get climbers impossibility result.",
                    "label": 0
                },
                {
                    "sent": "The funny thing I mean this is a nips paper, and as a nips paper clip they had to provide a rather complicated proof.",
                    "label": 0
                },
                {
                    "sent": "But if you just want a proof and not just not to get it accepted techniques, you can get a much simpler proof so.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Maybe I'll.",
                    "label": 0
                },
                {
                    "sent": "OK, let me just go back, go to the proof and then I'll go back.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Today's slide, so here is my very simple proof.",
                    "label": 0
                },
                {
                    "sent": "So I want to prove to prove to you that no clustering can satisfy all those three requirements simultaneously.",
                    "label": 1
                },
                {
                    "sent": "So assume that I do have a function that satisfies all those three requirements.",
                    "label": 0
                },
                {
                    "sent": "So by richness I know that there is some arrangements of points in which every point will be in its own cluster, and I also know by richness.",
                    "label": 0
                },
                {
                    "sent": "Rearrange the points in such a way that I'll get some clustering which is not the same one as the previous one.",
                    "label": 0
                },
                {
                    "sent": "Because the requirement was pretty strong that by rearranging the points you can get any possible partitioning.",
                    "label": 0
                },
                {
                    "sent": "Now what I can do is so I have this arrangement that gives me a classroom which is not a trivial clustering.",
                    "label": 0
                },
                {
                    "sent": "So now by scaling up, just multiply it by big enough constant, I can make sure that by scaling it up every distance here is bigger than the maximal distance here.",
                    "label": 0
                },
                {
                    "sent": "I'll just this final set of point.",
                    "label": 0
                },
                {
                    "sent": "There is a maximal distance between all pairs here and I'll scale it up in such a way that any distance now is bigger than this maximal distance.",
                    "label": 0
                },
                {
                    "sent": "So by the scaling requirement, my function applied to this should give me this partitioning.",
                    "label": 0
                },
                {
                    "sent": "Right, but if I compare these two arrangements, what happens here is that every pair of points were in different clusters.",
                    "label": 0
                },
                {
                    "sent": "And they only got further apart because all the distances here are bigger than any distance here.",
                    "label": 0
                },
                {
                    "sent": "So by the last requirement I only took you points in different clusters and made them further apart.",
                    "label": 0
                },
                {
                    "sent": "I should get back this clustering.",
                    "label": 0
                },
                {
                    "sent": "So my function when applied to this arrangement is required by the scale invariants to output this partitioning.",
                    "label": 0
                },
                {
                    "sent": "But by the consistency requirement it's forced to output the Singleton partitioning.",
                    "label": 0
                },
                {
                    "sent": "So we get a contradiction because my function has to sues some particular partitioning for this set.",
                    "label": 0
                },
                {
                    "sent": "Are you comparing speaker clustering to the right side which has K = 3 clusters?",
                    "label": 0
                },
                {
                    "sent": "Why are you comparing now?",
                    "label": 0
                },
                {
                    "sent": "I'm saying that if you had a function, assume that you have.",
                    "label": 0
                },
                {
                    "sent": "Some function that satisfies all those requirements.",
                    "label": 0
                },
                {
                    "sent": "We if you go back to the axioms you say the.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The clan book Axsom said a clustering function F. A good class and shots function should simultaneously satisfy all those requirements.",
                    "label": 0
                },
                {
                    "sent": "Now I want to show you that no such function exists.",
                    "label": 0
                },
                {
                    "sent": "So I assume by way of contradiction that such a function does exist.",
                    "label": 0
                },
                {
                    "sent": "So this function by varying the inputs, should be able to give you every possible partitioning.",
                    "label": 0
                },
                {
                    "sent": "In particular, it should be able to give you the Singleton partitioning and some other partitioning into three clusters and many more.",
                    "label": 0
                },
                {
                    "sent": "Usually by the number of customers.",
                    "label": 0
                },
                {
                    "sent": "OK, but I mean I'm just saying that we just show the contradiction in trying to satisfy these requirements simultaneously.",
                    "label": 0
                },
                {
                    "sent": "But you also think a lot about know you also think a lot about the question of I give you the data and you should find the right key, right?",
                    "label": 0
                },
                {
                    "sent": "So you can think of it as the meta function that also chooses K. There's a big issue in clustering.",
                    "label": 0
                },
                {
                    "sent": "How to choose the correct number of clusters.",
                    "label": 0
                },
                {
                    "sent": "So assume that I have an algorithm that can do both things.",
                    "label": 0
                },
                {
                    "sent": "It can choose the correct number of clusters and then cluster.",
                    "label": 0
                },
                {
                    "sent": "Then I may.",
                    "label": 0
                },
                {
                    "sent": "I wish that my function satisfies all those three properties.",
                    "label": 0
                },
                {
                    "sent": "And this proof shows you that you cannot do it.",
                    "label": 0
                },
                {
                    "sent": "Are you convenios?",
                    "label": 0
                },
                {
                    "sent": "Any 20 OK, that's my next slide.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure where I saw they reached.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Oh, the richness was used in a very limited way.",
                    "label": 0
                },
                {
                    "sent": "The richness suggest use by requiring that they can get the Singleton clustering and any other clustering.",
                    "label": 0
                },
                {
                    "sent": "So I was using much less than the full richness and I still could get a contradiction.",
                    "label": 0
                },
                {
                    "sent": "So my result is stronger than clients.",
                    "label": 0
                },
                {
                    "sent": "I get contradiction for much less.",
                    "label": 0
                },
                {
                    "sent": "But on the other hand, it's a trivial proof, so I can't publish it.",
                    "label": 0
                },
                {
                    "sent": "Pretty much is.",
                    "label": 0
                },
                {
                    "sent": "No no.",
                    "label": 0
                },
                {
                    "sent": "This is no, no.",
                    "label": 0
                },
                {
                    "sent": "The proof is showing that any clustering function that satisfies scale invariants and consistency its range is an under chain.",
                    "label": 0
                },
                {
                    "sent": "There's a notion of an antichain of classroom.",
                    "label": 0
                },
                {
                    "sent": "Check check the paper.",
                    "label": 0
                },
                {
                    "sent": "Anyway, the this is this is a proof that I. I mean I heard.",
                    "label": 0
                },
                {
                    "sent": "John, give this talk and I was sitting in the audience and I saw this reaction.",
                    "label": 0
                },
                {
                    "sent": "They raised my hand.",
                    "label": 0
                },
                {
                    "sent": "So here's the proof and Johnson, OK?",
                    "label": 0
                },
                {
                    "sent": "But let me show you my proof just the same.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so let's go back to this.",
                    "label": 0
                },
                {
                    "sent": "So as you remarked, and any two of those axioms are satisfied aghbal simultaneously, it's the problem is that we can satisfy all three of them together, but we do.",
                    "label": 0
                },
                {
                    "sent": "I mean, if I just want to satisfy any two of them, then if you just look at the following, the very simple, maybe the simplest clustering algorithm is called single linkage.",
                    "label": 0
                },
                {
                    "sent": "What you do in single linkage, you take the closest two points and you say.",
                    "label": 0
                },
                {
                    "sent": "We're going to be in the same cluster and then you take the next.",
                    "label": 0
                },
                {
                    "sent": "Minimal distance and put it in the same cluster so you keep growing your clusters in a greedy way each time adding the closest remaining distance into the closest cluster.",
                    "label": 0
                },
                {
                    "sent": "That's called the single linkage clustering.",
                    "label": 0
                },
                {
                    "sent": "It's a very simple greedy kind of algorithm, and the parameter that you can play with in a single linkage clustering is when do you stop?",
                    "label": 0
                },
                {
                    "sent": "Because if I'll keep adding edges and swallowing more points in my clusters.",
                    "label": 0
                },
                {
                    "sent": "At the end of the process, I'll have one big cluster with all the point.",
                    "label": 0
                },
                {
                    "sent": "So the question is, what's your stopping criteria?",
                    "label": 0
                },
                {
                    "sent": "So it turns out that even with this simple clustering algorithm, by playing with my stopping criteria I can satisfy any desired pair of properties.",
                    "label": 0
                },
                {
                    "sent": "So if my stopping criteria is just, I stop when I get K components.",
                    "label": 0
                },
                {
                    "sent": "Then I have richness and I have the consistency requirement.",
                    "label": 0
                },
                {
                    "sent": "I have scaling variance and the consistency requirement, but I don't have richness because I'm forced to output exactly K clusters.",
                    "label": 0
                },
                {
                    "sent": "If my stopping retainer is stopped when the distance when all the distance is now bigger than our.",
                    "label": 0
                },
                {
                    "sent": "Then I get richness.",
                    "label": 0
                },
                {
                    "sent": "I mean, I can rearrange the points to get any clustering by just saying I stop when the distance the minimal distance left is our and I get the consistency.",
                    "label": 0
                },
                {
                    "sent": "But it's not scale invariant because these are is fixed.",
                    "label": 0
                },
                {
                    "sent": "So if I now blow up my data it will fracture into more clusters and if my stopping criteria is some scaling things say and stop when I get to a distance Alpha times the Max distance.",
                    "label": 0
                },
                {
                    "sent": "Then it will be scale invariant because if I multiply by a scale.",
                    "label": 0
                },
                {
                    "sent": "This will take care of it, but.",
                    "label": 0
                },
                {
                    "sent": "I'm going to lose the consistency, so any pair of them is mutually satisfied that all reasonable, but they can't be all three satisfied simultaneously.",
                    "label": 0
                },
                {
                    "sent": "This richness means that we want to have clustering which is really able to do you any number of partitioning.",
                    "label": 0
                },
                {
                    "sent": "So any number of clusters right?",
                    "label": 0
                },
                {
                    "sent": "I'm talking here about the clustering algorithm is supposed to look at examine your data and decide which is the correct number of clusters and then cluster into this number of clusters.",
                    "label": 0
                },
                {
                    "sent": "Your question about is it clusterable or structureless in the sense that if it returned at the single cluster, it might be saying right?",
                    "label": 0
                },
                {
                    "sent": "It may say you might say if it returns everything in a single cluster or every point in a Singleton, then it answers my question that that is cluster.",
                    "label": 0
                },
                {
                    "sent": "This is structureless, yeah.",
                    "label": 0
                },
                {
                    "sent": "Right, but those requirements are pretty harsh as we saw.",
                    "label": 0
                },
                {
                    "sent": "OK, so where do we go from here?",
                    "label": 0
                },
                {
                    "sent": "So I think one of the big mistakes in the community.",
                    "label": 0
                },
                {
                    "sent": "I don't know how many people were looking at it, but people that did is that people heard this talk of client back at NIPS was very widely.",
                    "label": 0
                },
                {
                    "sent": "Cited and people don't remember what exactly the details as well, but they conclusion is there's no way to do a theory of clustering because there is this impossibility result, and so let's forget about it.",
                    "label": 0
                },
                {
                    "sent": "There's no way to do theory well.",
                    "label": 0
                },
                {
                    "sent": "I'm trying to claim is that this is a very.",
                    "label": 0
                },
                {
                    "sent": "It's a very nice result, but it has limited application.",
                    "label": 0
                },
                {
                    "sent": "It says that this choice of three axioms was miss fortunate or fortunate in the sense that it led to a contradiction.",
                    "label": 0
                },
                {
                    "sent": "But it doesn't mean that you cannot do any theory, so.",
                    "label": 0
                },
                {
                    "sent": "What will be the next step?",
                    "label": 0
                },
                {
                    "sent": "What can we do?",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what I would like, in an ideal theory, is to have two types of requirements.",
                    "label": 1
                },
                {
                    "sent": "One type is axioms and actions should be requirements that any clustering method satisfies the access.",
                    "label": 1
                },
                {
                    "sent": "So in particular the Kleinberg.",
                    "label": 0
                },
                {
                    "sent": "Axioms are not accent because each of them we know is falsified by many good clustering algorithm we know whenever we saw an example that two properties are satisfied by some clustering algorithm, But the inconsistency, we know that this clustering algorithm failed the third requirement.",
                    "label": 0
                },
                {
                    "sent": "So each of those requirements is failed by some natural clustering algorithm.",
                    "label": 0
                },
                {
                    "sent": "So if I gave you an axioms of geometry and then I'll tell you know these are axioms of geometry, but some lines and points satisfies these axioms but others some other lines and points don't satisfy the axioms, so you won't call them axioms right actions you want to add.",
                    "label": 0
                },
                {
                    "sent": "By nature, you want it to be something that is satisfied, but all the objects that you're trying to describe.",
                    "label": 0
                },
                {
                    "sent": "I can't give you axioms of group theory and tell you OK, these are the axioms of group theory, but some groups satisfy them and some groups don't.",
                    "label": 0
                },
                {
                    "sent": "That's contradictory to the nature of accents.",
                    "label": 0
                },
                {
                    "sent": "So when I want actions, I want something that any clustering method will satisfy and we know that I mean clamping himself showed us that his actions are not like that because each of them is failed by.",
                    "label": 0
                },
                {
                    "sent": "The same classroom that satisfied the other two.",
                    "label": 0
                },
                {
                    "sent": "And the other requirement is even more difficult to formalize where I wanted any function that is clearly not a clustering will fail to satisfy at least one of the actions, because I could give you a trivial actions, I can tell you my axioms is the actual what you should satisfy is the requirement that 1 + 1 = 2.",
                    "label": 1
                },
                {
                    "sent": "So now any function you give me will satisfy the axioms and we're all happy.",
                    "label": 0
                },
                {
                    "sent": "But it doesn't distinguish good functions from bad functions.",
                    "label": 0
                },
                {
                    "sent": "So we want to mutually satisfy these two requirements from a set of axioms, and this is may be difficult to formulate because what do I mean by clustering?",
                    "label": 0
                },
                {
                    "sent": "That is obviously not a clustering function, so it's not going to be an easy task.",
                    "label": 0
                },
                {
                    "sent": "And on top of it I would call the kind of actions that climate suggested.",
                    "label": 0
                },
                {
                    "sent": "I call them properties rather than accents.",
                    "label": 0
                },
                {
                    "sent": "So I'll have properties.",
                    "label": 0
                },
                {
                    "sent": "Which hopefully will distinguish between different clustering paradigms, so I can say here is a clustering paradigm that is scale invariant.",
                    "label": 0
                },
                {
                    "sent": "He was a class ring paradigm that is rich.",
                    "label": 0
                },
                {
                    "sent": "Here is the clustering paradigm that satisfy that property.",
                    "label": 0
                },
                {
                    "sent": "So now a user that wants to apply clustering to his data could look at the list of properties and choose which properties I need for my specific applications.",
                    "label": 0
                },
                {
                    "sent": "And here is the clustering that will have those properties.",
                    "label": 0
                },
                {
                    "sent": "And the thing that we know from client work is that you won't have a clustering that satisfies all the possible properties, but you know the same for many things in life.",
                    "label": 0
                },
                {
                    "sent": "You can't get the car which is beautiful and fast and convenient and cheap or whatever.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is the ideal theory that I would like to see.",
                    "label": 0
                },
                {
                    "sent": "So here I have a list of.",
                    "label": 0
                },
                {
                    "sent": "Things that I will call axioms, and here I have a list of possible clustering paradigms, and then I can ask which clustering paradigm satisfies which requirement.",
                    "label": 0
                },
                {
                    "sent": "Now the axioms should be satisfied by all clustering paradigms.",
                    "label": 1
                },
                {
                    "sent": "The things which are properties like Rambo, consistency, cleansers, richness are satisfied by some paradigms but not by others and they should help me somehow.",
                    "label": 0
                },
                {
                    "sent": "Classify or taxonomize the class different clustering methods by which properties that satisfy.",
                    "label": 0
                },
                {
                    "sent": "So each clustering method will have a profile of which properties it satisfied, in which it doesn't.",
                    "label": 0
                },
                {
                    "sent": "The axioms should be satisfied by all of them, and if I have a function which is not a clustering function, it should at least fail one of those requirements so they all clustering functions will satisfy all the properties they collections.",
                    "label": 0
                },
                {
                    "sent": "Other properties distinguish between different clustering methods and.",
                    "label": 1
                },
                {
                    "sent": "Functions which are not clustering should each at least falsify one of those actions, so that's the ideal theory.",
                    "label": 0
                },
                {
                    "sent": "The now I'm not going to give you such a theory becausw.",
                    "label": 0
                },
                {
                    "sent": "Then having difficulty here is that we don't have a clear definition of what is not a clustering, I mean.",
                    "label": 1
                },
                {
                    "sent": "I have this requirement in every function which is not.",
                    "label": 0
                },
                {
                    "sent": "The clustering should falsify one of the axioms, but it's circular.",
                    "label": 0
                },
                {
                    "sent": "How should I define it?",
                    "label": 0
                },
                {
                    "sent": "It's not a clustering by showing that it doesn't satisfy one of the properties that I want all the.",
                    "label": 0
                },
                {
                    "sent": "So I get into a cycle here, but I can still come up with some properties which are more natural to be axioms than others and are satisfied by all the reasonable common clustering functions.",
                    "label": 0
                },
                {
                    "sent": "So I'll only give you some.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Example of such properties.",
                    "label": 0
                },
                {
                    "sent": "So in general we can say that the actions that we saw the requirements is so they really partition into two types of properties, richness, properties.",
                    "label": 0
                },
                {
                    "sent": "So one of them was the client back richness.",
                    "label": 0
                },
                {
                    "sent": "Another one could be care richness that the range of your partitioning is all possible.",
                    "label": 0
                },
                {
                    "sent": "Partitioning in 2K sets.",
                    "label": 0
                },
                {
                    "sent": "So we need some richness requirement and we need some invariants or robustness requirements, like saying scale invariants.",
                    "label": 0
                },
                {
                    "sent": "If you change the scale, the clustering will not change.",
                    "label": 0
                },
                {
                    "sent": "So these are two different types of properties and for each of them we can come up with relaxations that are really met by all.",
                    "label": 0
                },
                {
                    "sent": "Common popular clustering paradigms.",
                    "label": 0
                },
                {
                    "sent": "Ann, so I'll just give you one example of a relaxation of a property of Kleinberg that once you do this relaxation, you really have it in all the.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Reasonable clustering functions so.",
                    "label": 0
                },
                {
                    "sent": "The problem with the client, but consistent.",
                    "label": 0
                },
                {
                    "sent": "So let me remind you what the consistent was.",
                    "label": 0
                },
                {
                    "sent": "The consistency was the requirement that if I pull together points in the same clusters and pull different clusters apart, then apply my clustering function again, I'll get the same partitioning, right?",
                    "label": 0
                },
                {
                    "sent": "But the problem is this.",
                    "label": 0
                },
                {
                    "sent": "It could be that maybe I'll draw a picture here.",
                    "label": 0
                },
                {
                    "sent": "The problem is this could be that.",
                    "label": 0
                },
                {
                    "sent": "Assume that I have this.",
                    "label": 0
                },
                {
                    "sent": "My data initially looks like this.",
                    "label": 0
                },
                {
                    "sent": "So my class ring function will say.",
                    "label": 0
                },
                {
                    "sent": "Well, here is my clustering and now I'm pulling together points in the same cluster an I get something like this.",
                    "label": 0
                },
                {
                    "sent": "So I just took some of the points in this class and pull them together and I don't touch the other class or pull away.",
                    "label": 0
                },
                {
                    "sent": "We are the cluster and.",
                    "label": 0
                },
                {
                    "sent": "So I screamed this cluster, pulled it a bit away, and half of those points were shrinked here and the other half here.",
                    "label": 0
                },
                {
                    "sent": "So this is a consistent change.",
                    "label": 0
                },
                {
                    "sent": "Inside this cluster I only reduce the distances between the clusters.",
                    "label": 0
                },
                {
                    "sent": "I only increase the distances, but if I give you this for clustering you would probably give me not this clustering, but something like this, right?",
                    "label": 0
                },
                {
                    "sent": "It was speaking from paper two Busters.",
                    "label": 0
                },
                {
                    "sent": "What you were worried about?",
                    "label": 0
                },
                {
                    "sent": "The fact that I didn't fix K right again?",
                    "label": 0
                },
                {
                    "sent": "I'm talking about an algorithm that should find the correct number of classes and then cluster.",
                    "label": 0
                },
                {
                    "sent": "So what I'm saying is that consistency requirement, although on a first glance it looks natural.",
                    "label": 0
                },
                {
                    "sent": "It has problems becausw the very natural examples where you want to refute it in this case.",
                    "label": 0
                },
                {
                    "sent": "This summer been in trouble because I don't know how to draw, but I could do it without increasing any internal distances.",
                    "label": 0
                },
                {
                    "sent": "I could do it, you could.",
                    "label": 0
                },
                {
                    "sent": "I mean, it doesn't even have to be embedded in a say that all the distances here.",
                    "label": 0
                },
                {
                    "sent": "Here the XY.",
                    "label": 0
                },
                {
                    "sent": "Equals one for every X&Y and between those 2D XY.",
                    "label": 0
                },
                {
                    "sent": "Equals 10 if I pick a point from here in a point from here and now, I'll make all the distances here.",
                    "label": 0
                },
                {
                    "sent": "The XY here equals .1, and here the XY equals .1 and between those two still have distance too.",
                    "label": 0
                },
                {
                    "sent": "So I didn't extend any insight, but I can have it at once, so it's good to know that people are following here.",
                    "label": 0
                },
                {
                    "sent": "So I still have distance one between these two groups, but inside the group I shrink the distances to .1.",
                    "label": 0
                },
                {
                    "sent": "And I'll get a similar.",
                    "label": 0
                },
                {
                    "sent": "I mean when I try to draw it.",
                    "label": 0
                },
                {
                    "sent": "Of course I don't do it precisely, but you can easily.",
                    "label": 0
                },
                {
                    "sent": "Formula is such a situation, so my suggested remedy for this problem is to say that the consistency should be not allow you to change their proportions which are within each cluster.",
                    "label": 0
                },
                {
                    "sent": "So you have a list of constants.",
                    "label": 0
                },
                {
                    "sent": "A Lambda I for every cluster and the new distance function should be.",
                    "label": 0
                },
                {
                    "sent": "If A&B are in the same cluster, is the old distance times this constant Lambda?",
                    "label": 1
                },
                {
                    "sent": "And if they are in different clusters, is the old distance time some Lambda 0?",
                    "label": 0
                },
                {
                    "sent": "So I pick constants for every cluster.",
                    "label": 0
                },
                {
                    "sent": "I have a shrinking constant and for all the between distances I have some expansion constant.",
                    "label": 0
                },
                {
                    "sent": "And if I now do my shrinking and expansion I I'm ruling out those kind of counter examples and I can show that all the reasonable clustering functions do satisfy this relaxed consistency requirement.",
                    "label": 0
                },
                {
                    "sent": "Hey you can.",
                    "label": 0
                },
                {
                    "sent": "You can play with expansion for every pair but I wanted it when you allow different.",
                    "label": 0
                },
                {
                    "sent": "Constants for every pair of clusters, you can create a counter example like this because you see if I if I had.",
                    "label": 0
                },
                {
                    "sent": "You know, if I assume I had this three clusters now expanded such as this cluster is here.",
                    "label": 0
                },
                {
                    "sent": "This cluster is here and the third cluster is here.",
                    "label": 0
                },
                {
                    "sent": "Right and now what you will naturally do is say this is 1 cluster and there's another cluster becausw.",
                    "label": 0
                },
                {
                    "sent": "With this proportions they look together.",
                    "label": 0
                },
                {
                    "sent": "So I want a fixed constant for all the between clustering distances.",
                    "label": 0
                },
                {
                    "sent": "OK, so so we have such relaxations of those axioms in such a way that we are pretty happy that every natural clustering function satisfies all of them.",
                    "label": 0
                },
                {
                    "sent": "Of course, to show that every non clustering function fails one of them we have to come up with an exhaustive list of not clustering functions and that's not something which is readily doable.",
                    "label": 0
                },
                {
                    "sent": "I don't know even how to formulate it so.",
                    "label": 0
                },
                {
                    "sent": "As a summary.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Come on.",
                    "label": 0
                },
                {
                    "sent": "Let me give you some examples of class rings which do not fall into the client work framework, so the climate framework is that your input is just a set of points and pairwise distances.",
                    "label": 0
                },
                {
                    "sent": "But sometimes when you do clustering, the relationship you're looking at and are not just pairwise relationship there.",
                    "label": 0
                },
                {
                    "sent": "For example, in edge detection, if I just gave you pairs of this and says you will not know which points are in the same edge, but a relationship like this if I.",
                    "label": 0
                },
                {
                    "sent": "If you have points like this and say.",
                    "label": 0
                },
                {
                    "sent": "You want to cluster this picture and we naturally class straight into.",
                    "label": 0
                },
                {
                    "sent": "Here is 1 cluster.",
                    "label": 0
                },
                {
                    "sent": "Here is another cluster.",
                    "label": 0
                },
                {
                    "sent": "We're not looking at pairwise distances, but we're looking at the linear relationship which involves triples of points rather than pairs of points.",
                    "label": 0
                },
                {
                    "sent": "Or maybe more than triples of points, so it doesn't fall into the framework that the clustering is just a function of pairs.",
                    "label": 0
                },
                {
                    "sent": "Here the function could be a.",
                    "label": 0
                },
                {
                    "sent": "The class ring could be a function of triple wise relationship, which colinearity.",
                    "label": 0
                },
                {
                    "sent": "So edge detection is a good example of a clustering which is done in practice but does not fall into this framework which is based on just pairwise distances, yes.",
                    "label": 0
                },
                {
                    "sent": "Probably because we don't need clustering or mention what.",
                    "label": 0
                },
                {
                    "sent": "Because then marriage is a discontinued this conduit and why I need her to do clustering to do an expression.",
                    "label": 0
                },
                {
                    "sent": "No, I'm not.",
                    "label": 0
                },
                {
                    "sent": "I'm not fooling you.",
                    "label": 0
                },
                {
                    "sent": "Can you repeat it?",
                    "label": 0
                },
                {
                    "sent": "No, it doesn't.",
                    "label": 0
                },
                {
                    "sent": "It was just example OK, but there is no semantic beyond no no.",
                    "label": 1
                },
                {
                    "sent": "I'm saying if I apply to our intuitive semantics of what you do when you do edge detection, when do detection is a task that you use clustering for when you have a picture you want to detect objects.",
                    "label": 0
                },
                {
                    "sent": "You do edge detection.",
                    "label": 0
                },
                {
                    "sent": "You say all those points are lying on the same edge.",
                    "label": 0
                },
                {
                    "sent": "So you first do the detection of the gradients.",
                    "label": 0
                },
                {
                    "sent": "You know where where the sort of.",
                    "label": 0
                },
                {
                    "sent": "Can you change is you get a lot of points and then yeah, you just you just take your defining engineer.",
                    "label": 0
                },
                {
                    "sent": "I'm talking about you.",
                    "label": 0
                },
                {
                    "sent": "Assume that your picture is now coded as just binary pixels and now you want to do edge detection just over binary pixels.",
                    "label": 0
                },
                {
                    "sent": "But I'm saying is that on over binary pixels when you want to say those are in an edge it's more than just the pairwise distances.",
                    "label": 1
                },
                {
                    "sent": "It is some notion of linearity or continuity of the path or simplicity.",
                    "label": 0
                },
                {
                    "sent": "Of the past that connects them.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "I did wrong, but I just say that you are talking about partitioning basement and this clearly cannot be solved by.",
                    "label": 0
                },
                {
                    "sent": "Yeah, you can easily do it into petitioning.",
                    "label": 0
                },
                {
                    "sent": "I mean, I'm very bad.",
                    "label": 0
                },
                {
                    "sent": "I'm very bad at drawing, but it could be the case that your points look like this.",
                    "label": 0
                },
                {
                    "sent": "Right and now I ask you to class written, you say here is 1 cluster and here is another cluster and there's no points that belong simultaneously to both clusters.",
                    "label": 0
                },
                {
                    "sent": "I wonder?",
                    "label": 0
                },
                {
                    "sent": "Presentation because with what?",
                    "label": 0
                },
                {
                    "sent": "What does it say?",
                    "label": 0
                },
                {
                    "sent": "Yeah, that's what I'm.",
                    "label": 0
                },
                {
                    "sent": "Consider.",
                    "label": 0
                },
                {
                    "sent": "My data representation here is just a set of elements and pairwise distances.",
                    "label": 0
                },
                {
                    "sent": "And what I'm saying is that there's some things which cannot be captured by this very simple representation.",
                    "label": 0
                },
                {
                    "sent": "If I have here on top of the distances between the points, I also have some geometrical structure, IE really embedded in our two and I have some relationship which are more complex.",
                    "label": 0
                },
                {
                    "sent": "Adjust the pairwise distances.",
                    "label": 0
                },
                {
                    "sent": "So your own as you've never distances.",
                    "label": 0
                },
                {
                    "sent": "Yeah, in this analysis my input is only a set of pairwise distances.",
                    "label": 0
                },
                {
                    "sent": "Question regarding why not?",
                    "label": 0
                },
                {
                    "sent": "OK, center can be not inside of your pointless.",
                    "label": 1
                },
                {
                    "sent": "OK, but so so so vector quantization, it is.",
                    "label": 0
                },
                {
                    "sent": "And if your center is allowed to be, you can also formalize K means in this way, because K means all the all the information it looks at is the pairwise distances you want to minimize your worried about choosing the center outside your input set, right?",
                    "label": 0
                },
                {
                    "sent": "But you can say this can be overcome by some technical addition, but if not, just consider.",
                    "label": 0
                },
                {
                    "sent": "Vector quantization in which you are forced to pick.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah, right.",
                    "label": 0
                },
                {
                    "sent": "But I don't want to get into this game of examples and counterexamples, I'm I enjoy it very much, but I don't think it's so instructive use of the time now.",
                    "label": 0
                },
                {
                    "sent": "So here is another example of the clustering which is not based on just pairwise distances and this is texture clustering.",
                    "label": 0
                },
                {
                    "sent": "If I give you such a picture and tell you to cluster it, then you will say I mean and you can have more interesting results.",
                    "label": 0
                },
                {
                    "sent": "It's just my limitation in drawing of texture.",
                    "label": 0
                },
                {
                    "sent": "They want to cluster things by the texture.",
                    "label": 0
                },
                {
                    "sent": "It's more than just the pairwise distances, it's something about more points together relationship which are involved, more points together and another.",
                    "label": 0
                },
                {
                    "sent": "Nice example that I know that I really like is the professors examples, because what is the professor example of clustering and one of the clustering tasks that people at NIPS especially like to test themselves on is you take the web pages of your University.",
                    "label": 0
                },
                {
                    "sent": "That's what you have always can play with because there's something available to you.",
                    "label": 0
                },
                {
                    "sent": "You take the web pages and you look at all the linkage connections.",
                    "label": 0
                },
                {
                    "sent": "So if one person links to another, you say they have.",
                    "label": 0
                },
                {
                    "sent": "Some edge between them and then you define distances by say how many edges do I have to cross between menu or what's the density of edges between us and so on?",
                    "label": 0
                },
                {
                    "sent": "So you take the structure of the web pages of your University and you try to cluster it based on distances which are just based on the link in your web pages.",
                    "label": 0
                },
                {
                    "sent": "And can you come up with the clustering that will give you as a cluster the set of our professors.",
                    "label": 0
                },
                {
                    "sent": "And the problem is that professors never linked to each other if they're in the same University.",
                    "label": 0
                },
                {
                    "sent": "So if you're just based on linkage information, you will not be able to detect that there all belonging to the same group.",
                    "label": 0
                },
                {
                    "sent": "Which is, I mean, some people claim that they do it, but I always really question it because there's no way that you can say these are, yeah.",
                    "label": 0
                },
                {
                    "sent": "4 is better presentation, so if you just consider English information, that's what they mean.",
                    "label": 0
                },
                {
                    "sent": "You cannot really define custom, but if you consider another attribute, no.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "But but I agree with you.",
                    "label": 0
                },
                {
                    "sent": "But maybe the professors can be identified by saying it's a set of things that not connect to each other maximal set of nodes that never connect to each other, and each of them is connecting to a set of things that you cluster the students.",
                    "label": 0
                },
                {
                    "sent": "Maybe there is a way to do it, but it's not just based.",
                    "label": 0
                },
                {
                    "sent": "On pairwise relationship it based on we take into account larger sets of elements.",
                    "label": 0
                },
                {
                    "sent": "Check the graph.",
                    "label": 0
                },
                {
                    "sent": "No, but here it's a natural cluster.",
                    "label": 0
                },
                {
                    "sent": "I mean, this collection of AD L4 nodes is a natural cluster and still it doesn't show as a cluster.",
                    "label": 0
                },
                {
                    "sent": "You just look at pairwise distances.",
                    "label": 0
                },
                {
                    "sent": "Then then after you TV space, you can still define a cluster on the basis of this yeah.",
                    "label": 0
                },
                {
                    "sent": "My point, I mean, it depends on the richness, right?",
                    "label": 0
                },
                {
                    "sent": "Well no, I understand completely.",
                    "label": 0
                },
                {
                    "sent": "But what I'm saying is that even if you just consider linkage, you can still identify professors, but not as a natural notion of clustering.",
                    "label": 0
                },
                {
                    "sent": "You can identify them by the way they link and don't link to other nodes.",
                    "label": 0
                },
                {
                    "sent": "Just based on linkage information.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is the end of my of this part of my presentation and this was the my.",
                    "label": 0
                },
                {
                    "sent": "The less technical part, the second part will require a little bit more time.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we don't have it so.",
                    "label": 0
                },
                {
                    "sent": "OK, so I think I'll skip.",
                    "label": 0
                },
                {
                    "sent": "The open questions here because.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Wait and go into this different approach so the different approaches saying OK, so trying to define what clustering is maybe too ambitious or too vague, although I think it's an important task, so let's focus on sidestep this issue and focus on some.",
                    "label": 0
                },
                {
                    "sent": "And let's say general task and the task will be find some necessary condition of good clustering.",
                    "label": 0
                },
                {
                    "sent": "And just try to analyze one necessary condition that applies to good clustering regardless of the country clustering method or the data generation method.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And one such candidate is the notion of stability.",
                    "label": 0
                },
                {
                    "sent": "So what is the notion of stability?",
                    "label": 0
                },
                {
                    "sent": "If you want to know that if the clustering that you are doing is meaningful, what you can do is take two independent samples of your data and cluster this sample and cluster that sample and compare.",
                    "label": 0
                },
                {
                    "sent": "Did you get partitionings that look similar to each other?",
                    "label": 0
                },
                {
                    "sent": "Because if each time that you take a sample, you get a completely different partitioning of data.",
                    "label": 0
                },
                {
                    "sent": "It may be an indication that you're not doing the right thing in your clustering.",
                    "label": 0
                },
                {
                    "sent": "So this idea is called stability.",
                    "label": 0
                },
                {
                    "sent": "You cluster independent samples, you compare the resulting clusterings and meaningful clustering should not change much for money independent sample to another.",
                    "label": 1
                },
                {
                    "sent": "And this idea has been employed.",
                    "label": 0
                },
                {
                    "sent": "It's a very commonly used heuristic.",
                    "label": 0
                },
                {
                    "sent": "People want to check how good is the clustering.",
                    "label": 0
                },
                {
                    "sent": "They take samples of their data, cluster them, and want to see that they get similar results.",
                    "label": 0
                },
                {
                    "sent": "And this idea, I mean, this is just a list of recent papers, but you can see in many areas of clustering the same idea being employed over and over again.",
                    "label": 0
                },
                {
                    "sent": "The problem is that until two years ago we didn't have any theory to support this heuristic of stability.",
                    "label": 0
                },
                {
                    "sent": "It's a very commonly used juristic, but we didn't have any theory that all that it really does what we expect it to do.",
                    "label": 0
                },
                {
                    "sent": "It just sounds reasonable.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now, another reason it sounds reasonable because it really resonates with some very basic idea of science, which is replication.",
                    "label": 0
                },
                {
                    "sent": "If I come to you with some physical experiment, if I drop an Apple, it falls to the ground you want to be able to replicate this experiment and get similar results, so it's the same thing here.",
                    "label": 0
                },
                {
                    "sent": "I took my data and told you that partitions into two clusters like this you want to be able to replicate it, so we will take some other sample of the data and apply your clustering algorithm.",
                    "label": 0
                },
                {
                    "sent": "We want to see similar results.",
                    "label": 0
                },
                {
                    "sent": "So it's a very natural idea and replication has been investigating many application of clustering.",
                    "label": 1
                },
                {
                    "sent": "The funny thing is it's mostly done by visual inspection.",
                    "label": 0
                },
                {
                    "sent": "If you look at papers in social Sciences they do replication clustering but it just say look at those pictures.",
                    "label": 0
                },
                {
                    "sent": "Aren't they like each other?",
                    "label": 0
                },
                {
                    "sent": "You know look at my baby, isn't it nice?",
                    "label": 0
                },
                {
                    "sent": "It's not very satisfying scientific way of doing stuff and we were trying to analyze this.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so the first step to analyze it, you have to define it precisely.",
                    "label": 0
                },
                {
                    "sent": "So here is the definition.",
                    "label": 0
                },
                {
                    "sent": "So now we assume because we want to take random samples, we assume that there is that your data is some probability distribution.",
                    "label": 1
                },
                {
                    "sent": "So it's a probability distribution over a domain that gives you the points and clustering is defined over samples.",
                    "label": 0
                },
                {
                    "sent": "So we can take a sample and apply your algorithm against a partitioning of your whole data space.",
                    "label": 0
                },
                {
                    "sent": "And we need the notion of similarity between different classrooms.",
                    "label": 0
                },
                {
                    "sent": "You where you want to be able to measure when two clusterings are similar or not.",
                    "label": 0
                },
                {
                    "sent": "So we have to add to our structure notion of similarity which is capital D between those two clusters and for sample size MI said that the instability of my algorithm on this data set is the expected distance.",
                    "label": 0
                },
                {
                    "sent": "If I take 2 independent samples of size N, is the expected distance between the clustering of.",
                    "label": 0
                },
                {
                    "sent": "Induced by the 1st sample and the clustering induced by the 2nd sample.",
                    "label": 0
                },
                {
                    "sent": "So my instability is the expected distance between the clustering that I get by clustering two independent random samples.",
                    "label": 0
                },
                {
                    "sent": "And as you can see, it's a property of both my clustering algorithm and my data, and of course the sample size.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "The first one.",
                    "label": 0
                },
                {
                    "sent": "When you in your dress and in result you assume that the person on your exam find do better, brother or sister.",
                    "label": 0
                },
                {
                    "sent": "I mean right?",
                    "label": 0
                },
                {
                    "sent": "Do you must have this right?",
                    "label": 0
                },
                {
                    "sent": "So you have to define this notion of of distance.",
                    "label": 0
                },
                {
                    "sent": "There are really two different settings here.",
                    "label": 0
                },
                {
                    "sent": "One, when the number of clusters is fixed and one with it's not fixed and you have to be able to define in the non fixed number of classes you have to be able to define what's the distance between two clusterings over and there are natural definitions.",
                    "label": 0
                },
                {
                    "sent": "I don't want to get into this, but for example a natural definition is that.",
                    "label": 0
                },
                {
                    "sent": "I take random pair of points and I asked you what's the probability I asked the first clustering.",
                    "label": 0
                },
                {
                    "sent": "Do these points belong in the same clusters or are there separated in different clusters an I can ask the same question to the other algorithm and my similarity will be the probability that will both give me the same answer.",
                    "label": 0
                },
                {
                    "sent": "So you randomly pick pairs of points and ask the two clusterings.",
                    "label": 0
                },
                {
                    "sent": "Are they in the same cluster or not?",
                    "label": 0
                },
                {
                    "sent": "And this is a notion of similarity that is doesn't care about the number of clusters.",
                    "label": 0
                },
                {
                    "sent": "OK, so we can overcome this problem, so that's my formal definition of.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Ability and the first thing you hope to do.",
                    "label": 0
                },
                {
                    "sent": "I don't know how many of you have been working in classification in statistical learning theory, the first thing you want to get is a uniform convergence results, no matter what my my.",
                    "label": 0
                },
                {
                    "sent": "Input space distribution is if I take M large enough things converge and of course we cannot get it here.",
                    "label": 0
                },
                {
                    "sent": "So for example, if my data is the uniform distribution over the circle and then any clustering algorithm they'll take will be unstable, because if I just want to partition it into two sets and I take a random sample, it will probably give me this petition.",
                    "label": 1
                },
                {
                    "sent": "Then I take another random sample, it will give me that partition.",
                    "label": 0
                },
                {
                    "sent": "So it will be very unstable in terms of how it partitions the point.",
                    "label": 0
                },
                {
                    "sent": "So on such datasets I would be very unstable.",
                    "label": 0
                },
                {
                    "sent": "Maybe it's a good indication that they are not cluster.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Apple.",
                    "label": 0
                },
                {
                    "sent": "Another problem of instability could be that depending on the algorithm, if this is my data, it's the uniform distribution over 2 rings.",
                    "label": 1
                },
                {
                    "sent": "Then if I use linkage algorithms that try to connect points when they are close together, then when my sample size is big enough I'll get consistent some clustering.",
                    "label": 0
                },
                {
                    "sent": "I always get one ring versus the other ring, but if I use the non appropriate a center based clustering like K means, K means on this picture will be very unstable even if I just try 2 means it will just separate it like this.",
                    "label": 0
                },
                {
                    "sent": "So like this or like this, depending on the randomness of the sample.",
                    "label": 0
                },
                {
                    "sent": "So it shows me that stability can be a good indication to what is the right paradigm.",
                    "label": 0
                },
                {
                    "sent": "The appropriate clustering paradigm for my data here linkage based will work.",
                    "label": 0
                },
                {
                    "sent": "K means will look very unstable, linkage base will look stable.",
                    "label": 0
                },
                {
                    "sent": "Maybe it's indication that for this type of data, linkage based clustering is better.",
                    "label": 0
                },
                {
                    "sent": "Because distance is only this is like conceptual clustering.",
                    "label": 0
                },
                {
                    "sent": "How you treat me right now, I'm now talking, right?",
                    "label": 0
                },
                {
                    "sent": "I switched gears and I'm now talking about clustering.",
                    "label": 0
                },
                {
                    "sent": "Say in our end.",
                    "label": 0
                },
                {
                    "sent": "So your points your input points are vectors in our end and you want to cluster them so we have more information.",
                    "label": 0
                },
                {
                    "sent": "I there was this discussion of the axiomatic framework for the axiomatic framework I was trying to address.",
                    "label": 0
                },
                {
                    "sent": "The simplest possible scenario.",
                    "label": 0
                },
                {
                    "sent": "Now I'm talking about something very practical that people do all the time in many applications of clustering, and they usually it's being done.",
                    "label": 0
                },
                {
                    "sent": "Points are vectors in RN and I want to analyze this very useful heuristic.",
                    "label": 0
                },
                {
                    "sent": "So I'm not working my input spaces now are in.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So what I'm saying here is that stability can distinguish between an algorithm which is appropriate for my data, and an algorithm which is not a prop.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So my data it can also help me choose the number of clusters.",
                    "label": 1
                },
                {
                    "sent": "So for example, if this is if my input is a uniform distribution over those four spheres, then if I choose try to cluster it into two clusters, it will be very unstable because I can get depending on my sample.",
                    "label": 0
                },
                {
                    "sent": "I take a sample and I class rate so high.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Can either get this clustering or that clustering depending on the randomness of the my sample.",
                    "label": 0
                },
                {
                    "sent": "If I forced it to have just two classes, but on the other hand, if I say I want four clusters, then it will be stable, so stability can also not not just help me choose between different clustering paradigms, but it can also help me choose the correct number of clusters so it looks like it.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So promising tool, we view stability as a measure of fit between the probability distribution and the clustering model and.",
                    "label": 0
                },
                {
                    "sent": "Stability fails when the clustering model is not aligned with your input data.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so we therefore can use it as a model selection tool, and that's the way it's being used.",
                    "label": 0
                },
                {
                    "sent": "It's a model selection tool.",
                    "label": 0
                },
                {
                    "sent": "You want to select the right model, the right algorithm, the right number of K for your data.",
                    "label": 0
                },
                {
                    "sent": "You estimate the instability of your algorithm on your data, and you choose the algorithm or parameters that maximize the stability.",
                    "label": 0
                },
                {
                    "sent": "That's the way it's being used as a model selection tool.",
                    "label": 1
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And now we try.",
                    "label": 0
                },
                {
                    "sent": "To prove that it really works.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We looked at two different algorithms, basic algorithms, center based like K means and linkage based algorithms and we look at very simple sets of data.",
                    "label": 1
                },
                {
                    "sent": "Since a synthetic set of data, mixture of Gaussians or mixture of cervical.",
                    "label": 0
                },
                {
                    "sent": "A this uniform distributions and we could prove that in all those cases.",
                    "label": 0
                },
                {
                    "sent": "Those two types of algorithms, these types of data, we could prove that in all those cases, stability correctly detects the right algorithm and the right number of clusters.",
                    "label": 1
                },
                {
                    "sent": "This is a proof.",
                    "label": 0
                },
                {
                    "sent": "Now it's not heuristic, but in order to prove it we needed to restrict our attention to very specific distributions.",
                    "label": 0
                },
                {
                    "sent": "You can't very difficult to prove that it will give you the correct number of clusters for every distribution, but that was an initial step.",
                    "label": 0
                },
                {
                    "sent": "And we also have.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The results that showed it work very nicely.",
                    "label": 0
                },
                {
                    "sent": "So here for example what I'm doing here is I have my distribution.",
                    "label": 0
                },
                {
                    "sent": "Is this Swiss roll with three different components.",
                    "label": 0
                },
                {
                    "sent": "So there is chocolate, vanilla and.",
                    "label": 0
                },
                {
                    "sent": "Something Gen three different components in your Swiss roll, and you want to be able to class.",
                    "label": 0
                },
                {
                    "sent": "And then I'm doing her single linkage clustering and my parameter is when do I stop merging points?",
                    "label": 1
                },
                {
                    "sent": "So if I choose the distance.",
                    "label": 0
                },
                {
                    "sent": "For merging points too large then I get this kind of.",
                    "label": 0
                },
                {
                    "sent": "Picture where it connects points across different layers.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If I choose my distances.",
                    "label": 0
                },
                {
                    "sent": "To be my threshold to be .15 I get is very nice.",
                    "label": 0
                },
                {
                    "sent": "Partitioning into 3 rolls if.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I choose my threshold to be too small.",
                    "label": 0
                },
                {
                    "sent": "Each role fractions into small subgroups and the question is so we know that the correct for this data the correct value of threshold should be .15.",
                    "label": 0
                },
                {
                    "sent": "Can stability detect it for me?",
                    "label": 0
                },
                {
                    "sent": "So we have this very nice picture where here I draw the instability with different threshold values.",
                    "label": 0
                },
                {
                    "sent": "And here, in order to know whether I got the correct thing or not, I what I draw here is the percentage of points that fall into the third largest cluster.",
                    "label": 0
                },
                {
                    "sent": "So if you have 10 clusters, I just look at the third license cluster and what percentage of of points folder.",
                    "label": 0
                },
                {
                    "sent": "And because we know that our data was generated by three rolls.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We want that the third largest cluster will contain a third of the points, and if we compare here the graph of instability with different values and the size of the third largest cluster, we see that the instability beautifully detects the values that give you the correct clustering for this data.",
                    "label": 0
                },
                {
                    "sent": "This empirical, this is a yeah this is empirical but we could also prove that it does it so the Scituate.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Mission was.",
                    "label": 0
                },
                {
                    "sent": "December 205 the situation was very nice.",
                    "label": 0
                },
                {
                    "sent": "We could formally we formally define the notion of stability.",
                    "label": 1
                },
                {
                    "sent": "We could argue that's a necessary property of any clustering method.",
                    "label": 1
                },
                {
                    "sent": "We could prove that it really works for those very simple distributions like mixture of Gaussians and Swiss rolls.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "We're so we could prove that it works very nicely and it also worked very nicely in practice.",
                    "label": 0
                },
                {
                    "sent": "So everybody was happy and we.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Set.",
                    "label": 0
                },
                {
                    "sent": "In the beginning of two or after at the beginning of Ingenerate or six, Ulrika looked vulnerable.",
                    "label": 0
                },
                {
                    "sent": "Visited Maine with my student.",
                    "label": 0
                },
                {
                    "sent": "We set to prove you know, to put the final nail into this structure to prove that stability really does what you want because we have all the possible evidence.",
                    "label": 1
                },
                {
                    "sent": "And then.",
                    "label": 1
                },
                {
                    "sent": "It's a question how do?",
                    "label": 0
                },
                {
                    "sent": "Formulate what is the correct job, but don't.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sorry about that, but then we started working on this and.",
                    "label": 0
                },
                {
                    "sent": "We started seeing some things which are not so satisfactory, so consider for example, these two data sets and assume that you have some K bigger than one.",
                    "label": 0
                },
                {
                    "sent": "What will happen here?",
                    "label": 0
                },
                {
                    "sent": "Will it be stable or not?",
                    "label": 0
                },
                {
                    "sent": "If I just take a random sample, want to cluster into three sets, then another random sample clustering it resets.",
                    "label": 0
                },
                {
                    "sent": "That's my generating distribution.",
                    "label": 0
                },
                {
                    "sent": "Will it be stable or will it shift all the time?",
                    "label": 0
                },
                {
                    "sent": "What?",
                    "label": 0
                },
                {
                    "sent": "It shift all the time, right?",
                    "label": 0
                },
                {
                    "sent": "But what will happen here?",
                    "label": 0
                },
                {
                    "sent": "If this is my data, it will be stable, but this is a very small change of my data.",
                    "label": 0
                },
                {
                    "sent": "If I take here any partitioning into three sets, eventually what I'll get is just three sets like this, but here it was unstable.",
                    "label": 0
                },
                {
                    "sent": "Now the answer that the number of correct number of.",
                    "label": 0
                },
                {
                    "sent": "Clusters is 3.",
                    "label": 0
                },
                {
                    "sent": "You cannot really argue that the correct number is 3 here and not here.",
                    "label": 0
                },
                {
                    "sent": "But stability doesn't detect it, so we started seeing those funny examples, and then we could turn.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm into a theoreme, so the bottom line of our analysis, which lasted more than a year.",
                    "label": 1
                },
                {
                    "sent": "Was that we collectivize exactly stability, at least for K means and.",
                    "label": 0
                },
                {
                    "sent": "We know.",
                    "label": 1
                },
                {
                    "sent": "Exactly what it detects, and we conclude that the success of stability in practice is only coincidence.",
                    "label": 0
                },
                {
                    "sent": "It is not a general rule, so it's a very funny situation with something works in practice.",
                    "label": 0
                },
                {
                    "sent": "It also works on very artificial data when you analyze it mathematically, but I'll give you the characterization and I argue that this characterization shows that stability should not work in general.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here is the characterization.",
                    "label": 0
                },
                {
                    "sent": "So we say that the data is stable if the limit as the sample size goes to Infinity, it become the instability becomes 0, so that is stable is when you take large online sample sizes, it becomes more and more stable and we could prove the following that if your algorithm is cost minimizing like K means, you're trying to minimize the K means costs that what you algorithm is striving to get.",
                    "label": 0
                },
                {
                    "sent": "If you have a cost minimizing algorithm.",
                    "label": 0
                },
                {
                    "sent": "It is stable on a data set D if and only if there is a unique minimizer to the function you are trying to optimize.",
                    "label": 1
                },
                {
                    "sent": "If and only if there is a unique partition that achieves.",
                    "label": 0
                },
                {
                    "sent": "The optimal value.",
                    "label": 0
                },
                {
                    "sent": "So rather than finding the correct number of clusters, it detects whether there is a unique optimal solution or several optimal solutions.",
                    "label": 0
                },
                {
                    "sent": "You see, if we go back.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If we go back to this picture here, if K = 2, There are many possible partitionings that will give you the same K means value.",
                    "label": 0
                },
                {
                    "sent": "But here, for K = 2, There's only one partitioning that gives you the minimal value for K means an.",
                    "label": 0
                },
                {
                    "sent": "What we found out this ability exactly detects this thing.",
                    "label": 0
                },
                {
                    "sent": "The question whether there is optimal unique optimum solution or multiple optimal solutions.",
                    "label": 0
                },
                {
                    "sent": "And now we can ask ourselves so.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Oh, that is set before us is a probability distribution over some domain.",
                    "label": 0
                },
                {
                    "sent": "It doesn't matter, doesn't matter.",
                    "label": 0
                },
                {
                    "sent": "Could be infinite or finite, so probabilities this will never sell domain.",
                    "label": 0
                },
                {
                    "sent": "You can think of it as a file domain with uniform distribution if you want.",
                    "label": 0
                },
                {
                    "sent": "And then the question is, you're trying to optimize some cost.",
                    "label": 0
                },
                {
                    "sent": "Stability detects just this now.",
                    "label": 0
                },
                {
                    "sent": "I don't think I have time to go into the proof.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I mean, this is the proof.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Idea?",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I mean the idea of showing you the proof is just.",
                    "label": 0
                },
                {
                    "sent": "Convincing you that this is hard proof, so you should accept it to whatever your can't.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is the proof is hard.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, So what?",
                    "label": 0
                },
                {
                    "sent": "What is the conclusion?",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "The common belief was that a is stable or a distribution P if and only if our algorithm picks the correct number of clusters.",
                    "label": 0
                },
                {
                    "sent": "That was the common belief and that was really the way it's being applied all over many domains.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Suppose I have an algorithm that always reports a single cluster of all points is very stable, right?",
                    "label": 0
                },
                {
                    "sent": "Right, it's stability is only a necessary condition for good clustering, not a sufficient condition for good classroom.",
                    "label": 0
                },
                {
                    "sent": "OK yeah, OK, you're right, it's only a necessary condition.",
                    "label": 0
                },
                {
                    "sent": "Now what our theorem is.",
                    "label": 0
                },
                {
                    "sent": "Iff what we have is a complete characterization and it says that your if you if you algorithm.",
                    "label": 0
                },
                {
                    "sent": "Is trying to minimize some notion of cost some well defined notion?",
                    "label": 0
                },
                {
                    "sent": "Of course then.",
                    "label": 0
                },
                {
                    "sent": "A is stable on P if and only if there is a unique solution.",
                    "label": 0
                },
                {
                    "sent": "Unique optimized solution for this data set.",
                    "label": 0
                },
                {
                    "sent": "So we have a complete characterization of what stability does and the question is.",
                    "label": 0
                },
                {
                    "sent": "Are these two notions the same?",
                    "label": 0
                },
                {
                    "sent": "Is correct K the same thing is saying we have a unique solution?",
                    "label": 0
                },
                {
                    "sent": "And we already seen one example where it doesn't and I can show you now some more examples which really show that it can go wrong in many many ways, so here.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some very simple examples, so assume that all the time in my examples now.",
                    "label": 0
                },
                {
                    "sent": "So now what I want to do is show you in examples that those two notions of correct number of clusters and having a unique minimizer for the cost function are not the same.",
                    "label": 0
                },
                {
                    "sent": "So here is an example very simple example.",
                    "label": 0
                },
                {
                    "sent": "All my data sets will be on the line and these are just the density function.",
                    "label": 0
                },
                {
                    "sent": "So if your density function is 50% of your data is here and 50% of the data is here.",
                    "label": 0
                },
                {
                    "sent": "So what you think is the correct number of clusters.",
                    "label": 0
                },
                {
                    "sent": "Two, if I try K = 2, will it be stable?",
                    "label": 0
                },
                {
                    "sent": "Yes, because there is a unique solution.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right, so if they try.",
                    "label": 0
                },
                {
                    "sent": "Two centers, it's stable because the unique optimal solution.",
                    "label": 0
                },
                {
                    "sent": "What happens if I try cake was three.",
                    "label": 0
                },
                {
                    "sent": "Will it be stable?",
                    "label": 0
                },
                {
                    "sent": "It will not be stable.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "'cause we have two.",
                    "label": 0
                },
                {
                    "sent": "Sufficient suex same cost meaning optimisers.",
                    "label": 0
                },
                {
                    "sent": "This is 1 optimizer and another optimizer.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is this one?",
                    "label": 0
                },
                {
                    "sent": "Both of them achieve the same cost so I have non unique optimizer for.",
                    "label": 0
                },
                {
                    "sent": "K = 3, So the conclusion is 3 is not is unstable, two was stable.",
                    "label": 0
                },
                {
                    "sent": "Instability did a good job.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "What for fall is going to be stable again?",
                    "label": 0
                },
                {
                    "sent": "Yeah, that that that you push into my next example, right?",
                    "label": 0
                },
                {
                    "sent": "You're right, for for it will be stable again, right?",
                    "label": 0
                },
                {
                    "sent": "So for maybe a good.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right, so here is another example.",
                    "label": 0
                },
                {
                    "sent": "Now I change my example only a little bit.",
                    "label": 0
                },
                {
                    "sent": "I put here 50% plus epsilon of my weight and here I have put 50% minus epsilon of my weight.",
                    "label": 0
                },
                {
                    "sent": "Now with K, what's the correct number of clusters?",
                    "label": 0
                },
                {
                    "sent": "We will agree that it's two with K equal 2.",
                    "label": 0
                },
                {
                    "sent": "Will it be stable or not?",
                    "label": 0
                },
                {
                    "sent": "It will be stable if I just have two.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Once it will be stable, there's only one optimal solution, one in each center.",
                    "label": 0
                },
                {
                    "sent": "What will happen for K = 3?",
                    "label": 0
                },
                {
                    "sent": "It would be a nice table for K = 3.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Be cause for K = 3 we have a unique optimum solution.",
                    "label": 0
                },
                {
                    "sent": "We have to put the two here and the one there because this has higher.",
                    "label": 0
                },
                {
                    "sent": "Hey wait, so we see here that if I use stability as my indicator to what's the correct number of clusters, I can distinguish between two and three, although in terms of our intuition two and three are clearly distinguishable.",
                    "label": 0
                },
                {
                    "sent": "There's no argument here.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And I can also do an example, yes.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Easy easy.",
                    "label": 0
                },
                {
                    "sent": "Maybe depends on what you mean by minimalization.",
                    "label": 0
                },
                {
                    "sent": "Cause yeah, I'm talking about the K means cost here.",
                    "label": 0
                },
                {
                    "sent": "Then we'll start posting is immunization, for example, or two centre, or just got two points and you change the time.",
                    "label": 0
                },
                {
                    "sent": "I brought the two OK.",
                    "label": 0
                },
                {
                    "sent": "Yes, it is the minimal cost that this algorithm is stable because.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "No, OK, I I we we have a formal list of some properties that this cost function should satisfy so that this characterization holds, but in particular it holds for K means for K, median for sum of distances for many very useful class ring cost function this characterization hold so.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here is another example.",
                    "label": 0
                },
                {
                    "sent": "Here I have 90% of my weight here in 10% of my wait here.",
                    "label": 0
                },
                {
                    "sent": "Now what will happen here is if I play with the distances carefully.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I can make it that there are two optimal solutions for K equal to the cost of this having two centers here.",
                    "label": 0
                },
                {
                    "sent": "And no center there is the same cost as having one sensor in one center there just by playing with the parameters you can tailor it this way.",
                    "label": 0
                },
                {
                    "sent": "So two will be unstable, 'cause if there are multiple solutions our theorem says it's unstable.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We will be stable.",
                    "label": 0
                },
                {
                    "sent": "OK, so well we no I I just lost my.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "We want to be here and then we want to go.",
                    "label": 0
                },
                {
                    "sent": "I don't know what's the fastest way to get to this point anyway.",
                    "label": 0
                },
                {
                    "sent": "It's a nice review for you of everything we did.",
                    "label": 0
                },
                {
                    "sent": "Come on.",
                    "label": 0
                },
                {
                    "sent": "OK, So what is the bottom line that?",
                    "label": 0
                },
                {
                    "sent": "This is a very interesting point.",
                    "label": 0
                },
                {
                    "sent": "In practice, no data set has more than one optimal solution.",
                    "label": 0
                },
                {
                    "sent": "There's no symmetry in the world.",
                    "label": 0
                },
                {
                    "sent": "I mean, the multiple solutions were because there was some very finely defined balance between different solutions, but in reality every natural data set will have only one optimizer, because there's no symmetry and therefore in practice if you check stability and your sample sizes become big enough.",
                    "label": 0
                },
                {
                    "sent": "Everything will always look stable.",
                    "label": 0
                },
                {
                    "sent": "So it's true, this ability is a necessary condition, but it's a trivial necessary condition.",
                    "label": 0
                },
                {
                    "sent": "It will always hold once you sample sizes are big enough, and he's a very strange phenomenon.",
                    "label": 0
                },
                {
                    "sent": "Usually we think that the larger the sample size we try, the better the results.",
                    "label": 0
                },
                {
                    "sent": "And here we're in the situation that if you sample sizes grow too large, everything trivializes everything.",
                    "label": 0
                },
                {
                    "sent": "In every real data set, everything will become stable.",
                    "label": 0
                },
                {
                    "sent": "Therefore any choice of clustering parameters on real data set.",
                    "label": 0
                },
                {
                    "sent": "Will always end up being stable if your sample sizes go.",
                    "label": 0
                },
                {
                    "sent": "Large enough instability does not do the job that we thought it did I mean it does it in practice, but when we analyze it.",
                    "label": 0
                },
                {
                    "sent": "There is some discrepancy between what should happen and what happens in practice.",
                    "label": 1
                },
                {
                    "sent": "Maybe it's due to show using two small sample size, yes?",
                    "label": 0
                },
                {
                    "sent": "It's very difficult to.",
                    "label": 0
                },
                {
                    "sent": "Define systematically.",
                    "label": 0
                },
                {
                    "sent": "If you imagine the images, yeah, but I'm saying when I'm saying it on real data there will never be a situation where two solutions are exactly optimal.",
                    "label": 0
                },
                {
                    "sent": "Both of them will always be one of them, a little bit preferable to the other.",
                    "label": 0
                },
                {
                    "sent": "Thanks ability already allow for like even just.",
                    "label": 0
                },
                {
                    "sent": "I'm not trying to.",
                    "label": 0
                },
                {
                    "sent": "I mean what I'm saying I'm using my theorem saying I don't have to evaluate stability.",
                    "label": 0
                },
                {
                    "sent": "Would have to ask myself is I look at the K means cost function.",
                    "label": 0
                },
                {
                    "sent": "Is there a unique minimizer to the K means?",
                    "label": 0
                },
                {
                    "sent": "Oh, there are two solutions that have exactly the same value and in real data there will always be a unique minimizer.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Yeah, it's important is the rate, but it's something that we cannot predict, right?",
                    "label": 0
                },
                {
                    "sent": "True that there will be always minimizer if the data is somehow resembles some kind of fractal structures that you have.",
                    "label": 0
                },
                {
                    "sent": "The broad feature three clusters you dig into the cluster begin has three clusters of different, even though we can always cluster it's in so well, I'm saying is I'm looking at the clustering.",
                    "label": 0
                },
                {
                    "sent": "I say we consider only K means cost and you want to minimize the K means cost and you fix your K and I try to see whether K = 2 is good.",
                    "label": 0
                },
                {
                    "sent": "OK equals 3 is good, OK equals 4.",
                    "label": 0
                },
                {
                    "sent": "Cake was heaven is good because then it's zero, right?",
                    "label": 0
                },
                {
                    "sent": "So what I'm saying is that you always get if you just use stability and your sample sizes are big enough, you will always get it no matter what your choice.",
                    "label": 0
                },
                {
                    "sent": "What it will look good.",
                    "label": 0
                },
                {
                    "sent": "That that's the.",
                    "label": 0
                },
                {
                    "sent": "One way of interpreting those results.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "There is a very important take home message here and that is that syntactic datasets can be misleading.",
                    "label": 1
                },
                {
                    "sent": "I mean, as long as I was working with syntactic data sets, a mixture of three Gaussians and mixture of trickle, there is some inherent regularity in syntactic data, and in this case it really misled our understanding of what is happening here.",
                    "label": 0
                },
                {
                    "sent": "And in some cases, the distinction between syntactic and synthetic and real data is really crucial here.",
                    "label": 1
                },
                {
                    "sent": "In our case, we in on synthetic data, it works beautifully both in simulations, and we could prove it even we can prove it for synthetic data.",
                    "label": 0
                },
                {
                    "sent": "For mixture of Gaussians.",
                    "label": 0
                },
                {
                    "sent": "But when you analyze it fully, you realize that this is all due to some inherent symmetry.",
                    "label": 0
                },
                {
                    "sent": "In the way we generated our synthetic data and I think it's a very interesting take.",
                    "label": 0
                },
                {
                    "sent": "Home messages sometimes think that what you get on synthetic data is not a true reflection of what you will get in reality.",
                    "label": 0
                },
                {
                    "sent": "Our synthetic data is just too simplistic and this is a very strong demonstration of this principle.",
                    "label": 0
                },
                {
                    "sent": "Things that work beautifully on synthetic data when we analyze them, we conclude that on real data they trivialize.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "What are you playing this video that I saw this right number cost is only say, repeat it again.",
                    "label": 0
                },
                {
                    "sent": "I'm concerned about your work with.",
                    "label": 0
                },
                {
                    "sent": "This ability will establish correct number.",
                    "label": 0
                },
                {
                    "sent": "Really, really plastic primer on processors.",
                    "label": 0
                },
                {
                    "sent": "If there is a slight difference in payment.",
                    "label": 0
                },
                {
                    "sent": "Austin Gay pursuing cake was 50 and how much?",
                    "label": 0
                },
                {
                    "sent": "Basically putting that well I'm saying is I wasn't saying I was saying it on when we check it on very simple synthetic data.",
                    "label": 0
                },
                {
                    "sent": "Chris stability to good job.",
                    "label": 0
                },
                {
                    "sent": "When you go to real data when the differences are very small no matter what is your choice of parameter when the sample size grows big enough.",
                    "label": 0
                },
                {
                    "sent": "It will get stable.",
                    "label": 0
                },
                {
                    "sent": "In the limit on large sample, it will always be stable, so if there are small differences when my samples have become big enough to detect those small differences, it will always home zoom in on one particular solution and will look stable.",
                    "label": 0
                },
                {
                    "sent": "F. Today we are still relative differences between them before using them in various different.",
                    "label": 0
                },
                {
                    "sent": "That's a very good question, and that's my next slide that I thought that I will not have to show you, why?",
                    "label": 0
                },
                {
                    "sent": "So we still had the question of, so why does it work in practice?",
                    "label": 0
                },
                {
                    "sent": "I mean, you cannot just say I prove that it shouldn't work, and I don't care about the world.",
                    "label": 0
                },
                {
                    "sent": "I mean I, it works for you, but as far as I'm concerned.",
                    "label": 0
                },
                {
                    "sent": "The world is irrelevant.",
                    "label": 0
                },
                {
                    "sent": "Only my notebook is is interesting, so why does it work in PRAC?",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we carry it for further, so we know that in the limit of M Everything will go to zero, but we were looking at.",
                    "label": 0
                },
                {
                    "sent": "Assume you're comparing two values of KK&K prime.",
                    "label": 0
                },
                {
                    "sent": "So I know that on real data this will go to zero and this will go to zero, but I can look at this ratio of a fixed M. And I look at this ratio of what the instability with K and the instability in K prime and we are.",
                    "label": 0
                },
                {
                    "sent": "On our way to proving, I mean we have still holds in our proof that if a K if with parameter K, we output the output clustering has boundaries that pass through considerably denser regions then the output of the clustering that I get with K prime.",
                    "label": 1
                },
                {
                    "sent": "Then this ratio will be bounded away from one.",
                    "label": 0
                },
                {
                    "sent": "Then although the in the limit both of them will go to zero, I will be able to tell if one of them is.",
                    "label": 0
                },
                {
                    "sent": "Clearly better than the other in terms of the boundaries passing through dense through sparse regions.",
                    "label": 1
                },
                {
                    "sent": "If it's a clear difference between them, then for all sufficiently large M this will be bounded away from one.",
                    "label": 0
                },
                {
                    "sent": "It will show me that one of them is preferable.",
                    "label": 0
                },
                {
                    "sent": "But the big problem about this result when you compare it to reality is that this holds only for sufficiently large M and we can show that there's no uniform convergence here, so you don't know when you see your data.",
                    "label": 0
                },
                {
                    "sent": "You don't know what is the correct sample size.",
                    "label": 0
                },
                {
                    "sent": "For my data, you just know that.",
                    "label": 0
                },
                {
                    "sent": "If you're unhappy with the results, I can always have a good excuse.",
                    "label": 0
                },
                {
                    "sent": "I'll tell you you didn't use the large enough samples.",
                    "label": 0
                },
                {
                    "sent": "And you can never catch me because I'm just saying that in the limit something will happen, but it gives a partial explanation of why stability works so nicely in practice.",
                    "label": 0
                },
                {
                    "sent": "But I still think that the more important conclusion",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is this very striking difference between what we see on synthetic data and what happens in real data?",
                    "label": 1
                },
                {
                    "sent": "OK, so this is concludes my this part of my talk tomorrow morning I'll talk on completely different issue which is by clustering.",
                    "label": 0
                },
                {
                    "sent": "When you want to cluster two sets together based on mutual relations between them and it will have a slightly more technical flavor.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 1
                },
                {
                    "sent": "So there is also the issue of noise and quite interesting.",
                    "label": 0
                },
                {
                    "sent": "You're instead the issue whether we can see this between structured data and some data where it makes sense for clustering.",
                    "label": 0
                },
                {
                    "sent": "So in fact we probably often have something like like an overlay between some background noise, let's say more or less equally.",
                    "label": 0
                },
                {
                    "sent": "Moises Predator in our space.",
                    "label": 0
                },
                {
                    "sent": "We have sort of clusters.",
                    "label": 0
                },
                {
                    "sent": "We would like to have.",
                    "label": 0
                },
                {
                    "sent": "So in those cases, ability help or so, it's again.",
                    "label": 0
                },
                {
                    "sent": "This distinction here between stability in theory and stability in practice, and it in practice, I've seen many claims that stability works.",
                    "label": 0
                },
                {
                    "sent": "I mean, like I was working with.",
                    "label": 0
                },
                {
                    "sent": "Say for in in Germany and she was doing stability on Poles in Germany that we're asking people about their happiness.",
                    "label": 0
                },
                {
                    "sent": "With life.",
                    "label": 0
                },
                {
                    "sent": "I mean are you happy with your life?",
                    "label": 0
                },
                {
                    "sent": "Are you happy with your salary and then clusters?",
                    "label": 0
                },
                {
                    "sent": "The outcome of those results according to regions in Germany and she could reconstruct the border between West and East, the old Western East Germany.",
                    "label": 0
                },
                {
                    "sent": "And this is very noisy data and she was just using stability to detect what is the correct number of clusters.",
                    "label": 1
                },
                {
                    "sent": "And any things that became stable was giving her some meaningful partitioning of Germany.",
                    "label": 0
                },
                {
                    "sent": "So in practice it seems to work even on noisy data sets.",
                    "label": 0
                },
                {
                    "sent": "The theory indicates that sample size grow big enough, the picture becomes blurred no matter what you start with.",
                    "label": 0
                },
                {
                    "sent": "Question sometimes.",
                    "label": 0
                },
                {
                    "sent": "Example circular Baker.",
                    "label": 0
                },
                {
                    "sent": "Some things you don't know.",
                    "label": 0
                },
                {
                    "sent": "The many colored version data come from.",
                    "label": 0
                },
                {
                    "sent": "Selection or search technique which one could apply for let's say so.",
                    "label": 0
                },
                {
                    "sent": "Is on those artificial examples on these synthetic data, you could see that that just using stability could help you decide which algorithm you want to use.",
                    "label": 0
                },
                {
                    "sent": "Case enters you want to link it based the on the synthetic data.",
                    "label": 0
                },
                {
                    "sent": "The stability did a good job of telling you it doesn't tell you what the manifold is, but it tells you what method is more appropriate for your data, which is a big step in that direction, but it doesn't tell you what the data is.",
                    "label": 0
                },
                {
                    "sent": "I mean that I agree.",
                    "label": 0
                },
                {
                    "sent": "So do you think price is one thing that you are in my is that basically stability you can travel customers.",
                    "label": 0
                },
                {
                    "sent": "I'm saying that this is the common use and our analysis shows that it gives you something different.",
                    "label": 0
                },
                {
                    "sent": "Instead of giving you the number of clusters, it tells you whether there's a unique optimum or multiple optimal.",
                    "label": 0
                },
                {
                    "sent": "As opposed to the practical use, the practical uses to detect K. But people hope to find escape, but sometimes if there is no pain, yeah yeah OK yeah, I mean of course this task of finding the right case very complex, but this is a tool that people apply very often to approximate this task of finding K. But it does something different than what you expect, yes?",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Right, so so the gap gap statistics has no theory that what so I mean, there's a lot of mathematics, lot of calculations, people use it a lot, right?",
                    "label": 0
                },
                {
                    "sent": "But there's no theory that try to argue why it gives you the correct values.",
                    "label": 0
                },
                {
                    "sent": "So I agree that it may be appropriate to try to apply a similar analysis to get statistics.",
                    "label": 0
                },
                {
                    "sent": "There are different methods, we just chose one method and try to analyze it, and that's what we got there.",
                    "label": 0
                },
                {
                    "sent": "Many other methods that I really think it's a nice challenge.",
                    "label": 0
                },
                {
                    "sent": "To try to analyze what are they really giving you an gap statistics are very natural candidate for that.",
                    "label": 0
                },
                {
                    "sent": "I agree and it has not been done.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Thanks.",
                    "label": 0
                }
            ]
        }
    }
}