{
    "id": "flkylw7zuy3jpvybyyj2swthwgyefnd5",
    "title": "On a L1-Test Statistic of Homogeneity",
    "info": {
        "author": [
            "G\u00e9rard Biau, LIP6, Universit\u00e9 Pierre et Marie Curie - Paris 6"
        ],
        "published": "Feb. 25, 2008",
        "recorded": "December 2007",
        "category": [
            "Top->Mathematics->Statistics"
        ]
    },
    "url": "http://videolectures.net/ripd07_biau_olt/",
    "segmentation": [
        [
            "OK, so good morning everyone.",
            "Thank you very much to the organizer for this very kind invitation.",
            "It's my pleasure to be here today.",
            "This is the first time in my life I give us talk so early in the morning but I try to do it.",
            "And this is joint work with Bone Walker from the economy superior or in cash or little boy from McGill University.",
            "And Lastly Jeffy from Technical University in Budapest.",
            "And the talk is entitled on L1 test statics of imagination.",
            "This is, let's say a combination of several results we have obtained on this topic."
        ],
        [
            "So basically my talk we will divide into sections.",
            "First I will present you this new test statistics for the two sample problem and then I will turn to a discussion about an interesting application to density model selection.",
            "But let's start."
        ],
        [
            "With the big inning and with."
        ],
        [
            "True sample problem.",
            "So basically what we are interested in is to test with the two samples of the same distribution, so we have to sample X1 exam.",
            "Experimenting problem in an which are both distributed according to unknown probability distribution measures melendy prime and what we want to test is that."
        ],
        [
            "The two samples are emoji news in the sense that view is equal to prime.",
            "This is our new assumption, and this is a very important problem which has a lot of practical applications.",
            "If you want an overview."
        ],
        [
            "The civil application just have a look at the recent paper by author and his collaborators.",
            "And basically what has been done so far?",
            "Well, the the method can be roughly divided in three approaches.",
            "The first approach is a parametric approach, so this is typically the case for normal.",
            "For normal or lognormal models.",
            "So if the model is OK, then this kind of test perform well.",
            "If the model is not OK, this perform usually bad.",
            "The signal approaches, typically nonparametric approach with Kolmogorov Smirnov typed statistics or come out from Mrs. Also type statistics which perform usually one small dimension but in higher dimension is order.",
            "And the third type of approach is a more learning theoretic oriented stuff.",
            "This is exactly what Arthur, his collaborators, try to develop right now, and today I will present you a nonparametric procedure that author has already tested in reality, so it can be much better than me if it performs well or not."
        ],
        [
            "So how do we do this?",
            "Where we first been R2D in?",
            "And cases right bins and we just define the less the test statistics TN as follows.",
            "In each bin we calculate the empirical measure associated with the first sample.",
            "We calculate the empirical measure associated with the second sample, right?",
            "We look at the difference and we make the same thing overall beans.",
            "Then we make assume.",
            "This is a kind of wanted statistics, right?",
            "And of course, we feel that when Mu is close to new prime then the two empirical measures should be close together and so Tien should be small.",
            "On the other hand, when you is very different from your prime then you end should be different from new Prime North and so that artistic should be big.",
            "Of course all this has to be quantified, but this is the ID and actually this is very closed from."
        ],
        [
            "An idea which has been introduced 17 years ago by last Jovian.",
            "Edward Vandermoon, which proposed the goodness of fit test statistics.",
            "Allen, which is defined exactly the same way, except that of course now you have on particles against true an the difficulty here.",
            "In our case TNT that we have empirical against empirical and yes.",
            "LM should not be parameterized by the petition because it depends on the position.",
            "It depends on the just on the bins, right?",
            "Yeah, measure depends on the end of a certain set of bins.",
            "If right, you can see like this, yeah?",
            "Different, that's correct, yeah, absolutely.",
            "Right, So what is already known about LM?"
        ],
        [
            "This results here, which was proven for years ago by Luke Bryan.",
            "Messenger fee this is about Ellen right empirical against through the proof that provided the sample set, the number of bins goes to Infinity, but not too fast and provided this condition here is satisfying.",
            "So this is a bad condition, right?",
            "This means typically that the merger is nonatomic bad condition, right?",
            "There is a condition, but this means that the merger is not atomic.",
            "So if you have a density, it's OK, but you have to impose some kind of density, right?",
            "Then the probability that Elaine is larger than some threshold behaves are exponential minus N times GL of epsilon, and the rate function GL of epsilon is here.",
            "This is a complicated function, right?",
            "But we can be drawn out no problem and the first thing we had to do was to see whether this result is large.",
            "Deviation results will generalize to empirical against empirical, and that's what we have done.",
            "Right?"
        ],
        [
            "And we have proven actually that the probability that tiene right, which is again in particle against empirical, is larger than some threshold.",
            "Behaves US exponential minus N comes from rate function.",
            "And this rate function is very simple expression here, which is GT of epsilon which is this function here.",
            "And of course, the first question which arises years are GT and Glu.",
            "Glu went there, and this is GT similar, and the answer is not."
        ],
        [
            "As epsilon goes to zero, the rate function for sample.",
            "Silver, four, whereas Gen 2.",
            "Right Moreover"
        ],
        [
            "GT is not is not bounded, whereas GL is unbounded.",
            "So the conclusion was inconclusive."
        ],
        [
            "Is that Ellen and TN have different large deviation properties, so this was the first important result that we got and Moreover."
        ],
        [
            "We had some reason like this.",
            "This is the rate function GT for the true sample program writes for the empirical to empirical and this is.",
            "Bounds for Americans against Rousseau GT is somewhere between GL epsilon two and Jalen of Epsilon.",
            "So write the message to take home with that GL angithi of different so the the two testing procedures of different behaviors.",
            "OK, now I would like to show you the."
        ],
        [
            "The way we obtained this presence because I think it's important, yes after.",
            "Not.",
            "Right both require, yeah, both recorded, but the test doesn't require the large deviation required boasted of.",
            "Yeah, both large aviation result record is under the same assumption, right?",
            "Absolutely, right, that's correct.",
            "But the tests that I'm going to present doesn't need it.",
            "So I'm going to show you the way we obtained this because I think it's important.",
            "I don't want to be technical today, but however I think it's important to spread out the."
        ],
        [
            "So just one one side of proof, right?",
            "We just start with the generating function of the sequence, the end.",
            "This is TN is a test statistics, right?",
            "So Lambda two offices, just the limit as N goes to Infinity of the expectation of exponential SMT.",
            "Alright log of this one over and we have to prove that.",
            "These guys here goes to some limit and for this we use Chef."
        ],
        [
            "For partitions, this is what is important here.",
            "And what does it say?",
            "It say that the test statistics tiene can just be rewriting as the maximum over the single algebra which is generated by the bins of the partition right of empirical against empirical and this is good because this Sigma algebra is fine, it right?",
            "It has at most two to the M elements because PM is fine partition and this is the way we go."
        ],
        [
            "Further to calculate the expectation of ESNTN right, we run down.",
            "This is the expectation of the maximum over this Sigma algebra using Shift theorem for petition.",
            "Then this is certainly smaller than two to the MN times the maximum, because the same algebra is finding number of elements.",
            "Then, since the two samples are independent, which is break spectation in two terms, right?",
            "And then under H0 these terms are the same distribution, so they behave exactly the same way and we can get this bound here, right?",
            "So the key of the proof is Schaefer Theorem, so this is for upper bound.",
            "So just taking logarithm one or limit we get what?"
        ],
        [
            "Wanted.",
            "We get lunch at your place more than this guy here and for the lower bound.",
            "This is."
        ],
        [
            "Similar, right?",
            "We arrived at the expectation of the generating function is just the expectation of the maximum we upper body lower bounded by the maximum of expectation and then some trick and there's zero.",
            "The true samples of the same distribution an we get."
        ],
        [
            "That Lambda T of S the rate function is to return the limit of the generating function is certainly larger than this expression there, so this is because of the lower and upper bound.",
            "There are exactly the same, and we conclude this by."
        ],
        [
            "Again, a theorem for large deviation, which tells us that the rate function is just the maximum of epsilon minus Lambda two epsilon, and this is that way that we obtain the rate function.",
            "OK, so sorry to be a little bit technical, but this was just to show you the way we do it now.",
            "We have this result right?",
            "We have this."
        ],
        [
            "Present here and the question is, can we use it?",
            "For obtaining statistical test.",
            "So the question the answer is yes.",
            "But you know, this is not really a central limit theorem, right?",
            "This is just a large deviation result, and so we're going to obtain some constraints, some some strange type of testing.",
            "And this this is."
        ],
        [
            "Called distribution free strong, consistent testing so.",
            "This is good because the test is going to be distribution free.",
            "That is no assumption about the distribution, but this is, well, let's say not bad, but less good, right?",
            "Because this is a different way of testing.",
            "But the idea is interesting.",
            "What does that mean?",
            "Strong, consistent test?",
            "It means that."
        ],
        [
            "Both on HO and on its complement, the test makes emotionally no mistake.",
            "After a random sample size, right?",
            "In other words, in."
        ],
        [
            "You mean that if you are underage zero then you are sure that after some random sample size that you have taken the good decision right?",
            "And on the other hand, if you are underage, one is exactly the same and this is strange way of testing, which is not the usual way, right?",
            "And this concept is very close to some concept which has been introduced in Denver in Paris in 94 which is called.",
            "And ability, and from ideas which have been up to also developed by the legacy in 2002.",
            "And this can be interesting, for example, when some kind of sequential testing when you have only one sample at ARM, right?",
            "You get the data once an you want to be sure after some random samples that you have taken the good decision OK?",
            "And so."
        ],
        [
            "So this is a test we obtain, and again this tells us no assumption about distribution, right?",
            "Completely free distribution free.",
            "So consider the test which rejects when teams becomes large.",
            "So this can be quantified right?",
            "So C one is 1.66.",
            "So providing MN goes to Infinity but not too fast then.",
            "After some random sample size, you are sure that the test makes no error and over if you are under the alternative right and provided this condition is satisfied.",
            "Well, this is just a small condition and basically this means that the partition is made of square.",
            "For example, this is not very small assumption.",
            "Then you are also sure that you have no error.",
            "Yep.",
            "Do you need a distribution?",
            "Of course.",
            "Oh, I should I should I?",
            "Each one extent of the same distribution, right?",
            "So there random they are independent, identically distributed, fixed.",
            "Absolutely, that's it, that's great.",
            "And so, this is, uh, this way of testing.",
            "Of course, now if you want a more traditional way of testing, you know without further procedure etc, then you have to get some central limit theorem and let me show you the way we obtain central limit theorem for this kind of statistiques."
        ],
        [
            "Well, first they seem to think of multi of Ln empirical against true was derived 10 years ago.",
            "Something like this by Berlin jophiel ago.",
            "She who have proven that squared valentime hell N minus the expectation over Sigma goes to some normal random variables and the techniques.",
            "Off"
        ],
        [
            "These authors involve poison representation of the empirical process in conjunction with very old ID.",
            "Oh, but let's of partial inversion for obtaining conditional characteristic distributions and the key point of this kind of results is really the personalization technique.",
            "I'm going to explain you out this goes.",
            "And before this."
        ],
        [
            "Here is the reason we have obtained, so we have also proven Central limit theorem.",
            "So provided again the number of bins goes to Infinity and provided the distribution is not atomic.",
            "This is this condition here which is required.",
            "Then under zero you have a central main reason.",
            "So that means that screwed event MTN minus some normalization goes to some normal random variable.",
            "And you have an expression of the variance which is independent of the dimension.",
            "What is interesting for me the way we obtained this results much more than the reason by itself.",
            "Anne why?"
        ],
        [
            "Is it difficult?",
            "The difficulty comes from the fact that tiene that aesthetics right is assume of dependent random variables full because all the empirical measure some to one.",
            "This is what is difficult.",
            "And to overcome this kind of problem."
        ],
        [
            "Right, we use a personalization argument, which is very powerful argument for proving central limit theorems and many other races on search statistics.",
            "So what is the idea is that we are going to make the sample size random.",
            "We make the sample size random poison basically."
        ],
        [
            "Like this we just define NNN NNN two person random variables which are independent of everything and independent between themselves independent of everything but which are on average equal to N right?",
            "And then we define just the person is that version."
        ],
        [
            "Of the test statistics, which is exactly the same as before.",
            "Accept that.",
            "We have replaced with sample size by some random stuff here.",
            "This is the let's say the randomly said empirical measure.",
            "This is a randomized empirical measure of the second sample right?",
            "Or there was a test statistic is exactly the same?",
            "And why is it important to do this?",
            "This is important because."
        ],
        [
            "Then if you just count the number of guys which form the first being, the number of gallons second, Meanwhile, would you call this vector while you do exactly for the same for the second sample?",
            "Right?",
            "Then of course, why NY Prime NR independent?",
            "This is easy because the samples are independent, but there is much more.",
            "The number of guys which one the first beam is independent of the number of guys returning the second bin and so on right?",
            "Because you make the sample size random and this is the key of this position tree and Moreover the on average the number of points which fall in each bin right?",
            "Is poison with the right distribution MUNG.",
            "Ann, this is the first argument in this segment."
        ],
        [
            "Is that conditional on the sample size right?",
            "Everything becomes multinomial.",
            "And this is called personalization and this is a statistical trick to prove their central limit theorem and actually the key of the pro."
        ],
        [
            "Uses forest inversion formula an.",
            "It's very technical, but every."
        ],
        [
            "It relies on 1L or proposition so.",
            "I explained why the way it works, so this is what we want to prove, right?",
            "We want to prove central limit theory about this statistics here.",
            "So J is nothing.",
            "This is just normalization right about this test statistics here.",
            "But all the guys are independent right?",
            "So you cannot use the usual way of proving this would happen.",
            "Or theorem example amid condition and so on.",
            "Of course, because everything is independent.",
            "But you have, this person is that version here.",
            "Where do you guys are independent and the proposition says that if you can prove something about a men which is approaching this version with an N and prime N right, some big central limit theorem.",
            "Then if you have this empty normality then you get this empty normality of.",
            "Let's say the original statistics, but these are some pretty normality.",
            "Here is easy to prove right?",
            "Where is it technically?",
            "It's easy to prove cause conditional North or the guys you are independent and you have all the distributions, so this is easy to do.",
            "This is technical, but is it?",
            "You can do it with usual central limit conditions.",
            "So this is an interesting approach.",
            "For handling empirical measures.",
            "And this leads to a status, of course."
        ],
        [
            "Test testing procedure, which is more classical, so putting some level Alpha right you take sister is 0.7.",
            "This is the best known variation constant right?",
            "And you consider the test which rejects H zero and TN becomes large so typically larger than this guys here.",
            "So 5 -- 1 is just the.",
            "The inverse of the distribution function of the Goshen right then.",
            "This test has a septic significance level Alpha and Moreover, provided this condition on the partition holds, the test is also consistently mean that if you are under the alternative fuel, the power goes to one.",
            "So this is a good test, except that it is based on the central limit result an you have to suppose that the distribution is not actually so this holds for measures which have density probability, but that's OK. Or restriction.",
            "Yep, so now."
        ],
        [
            "I'm going to discuss an application surprising application to density model selection problem."
        ],
        [
            "So what we want to do here?",
            "Well, we have a collection of sets right FK which are nested.",
            "Typically, a parametric sets F1F2F2 is bigger 3456.",
            "And you know that the target, the density you want to estimate is in one of these F. Right, you know that it is one of these F. You have a sample at unexplored extent and what you want to do is to pick to pick the Golden City estimate right?",
            "This is complicated.",
            "This is complicated.",
            "Why?",
            "Because you don't know where the city is living, of course, and this is complicated."
        ],
        [
            "K. The complexity is unknown.",
            "You don't know where it is and you want a full system 8K, and when you have chosen K you want to pick a density estimate in FK so there is there are two problems actually."
        ],
        [
            "And what we want to do, what is a challenging question here?",
            "The challenging question is to pick some density estimate.",
            "Have had key North right?",
            "So Keehan is an estimation of the set where the density is leaving.",
            "And we want that as N goes large, then we want that key N approaches kistar.",
            "So this is the first challenge and 2nd we want to pick it."
        ],
        [
            "Suggesting that even the selected key N search at the L1 error between the target and F goes to zero at the rate one of us proud of.",
            "And this is very difficult problem cause KN is unknown.",
            "If we nuke again.",
            "Of course this will be easy to obtain, but here the complexity is unknown.",
            "So we want to rate exactly as if the complexity I've been known before hand and this is a challenging question.",
            "So as you will see."
        ],
        [
            "In will be obtained by minimizing the error between models and empirical measure over the same ideas.",
            "And the second step."
        ],
        [
            "The model parameter that is the estimation effort came.",
            "Will be done using general community.",
            "Will choose which go back to Lacon then which have been explored by Jaco's and which have been finally formalized by.",
            "The value goes in a small book.",
            "In 2001.",
            "I will explain it later the way we do it.",
            "But let's start with the beginning."
        ],
        [
            "Alright, let's start with some examples, just to show you that this this problem is important.",
            "The first big example is of course the mixture class problem here.",
            "Each FK is made of mixture of Goshen, right?",
            "So each FK is composed of mixture of car Goshen City.",
            "So what is unknown here that the weights are unknown?",
            "The variance Sigma are known.",
            "The means are known right?",
            "And the problem is difficult because we don't know K and ASCII grows right?",
            "You have more and more models and you want to select the good key and this is a problem which has attracted alot alot alot of attention in the literature them.",
            "Plenty, plenty of papers about this about known K. The case where K is known about the case where key is unknown, so you have many, many papers on this and in many different communities actually."
        ],
        [
            "By using community.",
            "You have this promise treaty."
        ],
        [
            "You have in statistical learning literature."
        ],
        [
            "In clustering literature.",
            "In"
        ],
        [
            "More statistical literature, so you have this problem is very important because of course you all know it has a lot of applications, so this is the first illustration of the problem, right?"
        ],
        [
            "Good example in the case of the increasing exponential families.",
            "Year each density FK takes this form here and then you let key grows right.",
            "The model becomes more and more rich, and by letting car Groves.",
            "This model can be."
        ],
        [
            "Very powerful actually.",
            "You can get many many classes of density beta gamma Ray to Maxwell many million cities.",
            "So here the challenge is to select the good K and once you have selected K again to select a good density.",
            "But there are many."
        ],
        [
            "The models you can see into your networks, wavelets and many others, and of course we have to make some.",
            "We have to impose some conditions right because otherwise it's too large.",
            "The first condition we will impose a natural condition we have to impose in some way that the complexity of the class where K is leaving is not too big and this will be done."
        ],
        [
            "Using typically Yvc argument, right?",
            "I will explain later, but you will support the complexity or after the class is not too big where K is leaving.",
            "This is the first assumption, but there is a second assumption which also important is that the classes should be well separated, one of each other right?",
            "Because they are nested an in some way you have to support that they are closed in somehow and this was a very difficult part of the paper.",
            "We spend a lot of time trying to find good conditions.",
            "For these models to be closed and that we have imposed."
        ],
        [
            "Is on this paper on this slide.",
            "Sorry so I will come back a little bit later on this condition because I think it's very important.",
            "It has been fired by the refering right very frequently it's OK. Just put the condition that we gave some.",
            "You know some condition for this condition to hold and he said Oh no, it's too complicated whatever form it was most important part so.",
            "OK, but I will present it today.",
            "The paper is published but not part so.",
            "I just do not by default the set of free transform of a set of densities right and assume."
        ],
        [
            "And is that the set of free transform of each model is closed in the set of Fourier transform of order CDs right?",
            "With respect to the consistency topology?",
            "So what does that mean then?"
        ],
        [
            "That you have some clothes that in this sense here I mean whatever the sequence GN in FK, which goes to some limit, J right and so that whatever.",
            "The test function, Phi right, continuous, bounded, then the limit J belongs to FK.",
            "So this is a closure condition with respect to the consistency topology.",
            "And this is a good condition.",
            "This is a good condition because it works.",
            "Our other will show you for practically all usual densities.",
            "So let's assume As for now that this condition on the model that is closure condition holds right.",
            "So these are conditional complexity conditional clauses condition.",
            "The."
        ],
        [
            "How do we do to estimate the complexity?",
            "Well, we split the sample in two parts, each one in send an experiment experimental, so support at any level."
        ],
        [
            "We make a beating of our D right with partition with William H into the D. And we introduced the following test."
        ],
        [
            "Statistics we call DNK all that work.",
            "So for each model FK.",
            "We take some guy FJ in FJ, right can do that and we just compare.",
            "Overall been the merger associated to the bin by J and empirical measure.",
            "We do this over all the bins and we take them over all the guys which are leaving the FK of this quantity, which is a kind of L1 distance.",
            "And of course the NK is decreasing because the sequence of modeling is nested and what we feel.",
            "Either when key right the index key is close to kistar then you have J.",
            "You have F in ASCII star and this quantity should be very small and the idea is that we should select.",
            "The threshold K. We should see like a Wendy and K is below some threshold, but this threshold has to be clever.",
            "It has to be adapted as we based on the data it has to go to 0 fast but not too fast and we spend a lot of time trying to find some interesting threshold and we."
        ],
        [
            "Is interesting here.",
            "Is that the treasure is exactly the 2016 of the first part.",
            "So when we use the just the empirical differences right between the two samples, then this is a good estimate of the threshold and the test is very simple, right?"
        ],
        [
            "We select the complexity of the model just by taking the first K where the test statistic DNK is more than the threshold.",
            "This is random.",
            "This is random.",
            "And this works well.",
            "And what we prove actually is that with this."
        ],
        [
            "Dorism here.",
            "Then the probability that the selected key N is different from keystar.",
            "The true complexities that unknown goes exponentially faster zero.",
            "This is of course the result that we have proven in the first section about the.",
            "And so you're using broken till we can prove that almost surely for Ln large enough then key N. The estimated complexity is exactly equal to Keystone.",
            "So we are able to prove that we have an estimate which goes almost surely to the true complexity.",
            "This is fine with almost no assumption on density.",
            "So this is for the purse.",
            "For the first part of the algorithm of the method.",
            "Now the question is how do we do to select density in F in the selected key end, right?",
            "So for this as I said."
        ],
        [
            "We use a paradigma which has been first, which caused us to look um in the original setting then which has been.",
            "Put in the good way for densities by Luke gobble, gobble Gucci.",
            "Assuming this works as follows.",
            "So now I have models F1F two or three.",
            "I fix a model FK.",
            "I'll just take the.",
            "This weekend's offsets here.",
            "How do we do this?",
            "Well, you take 2 function in FK and you look at the bubble set where G1 is larger than the two and you do that you do many many comparisons with all the guys which are living in FK.",
            "This gives you a class of sets up.",
            "For example if K is the class of Goshen is easy to prove that this is just the set of intervals and their unions.",
            "So for many known models this is easy to calculate and this is the class of set which is which.",
            "But which is not huge and it is a clever class of said why?",
            "Because if we take a goodness.",
            "Sharing here this quantity Delta K of J.",
            "Which is.",
            "Just the difference between test and see TJ right and this is the merger which is associated to the set A by J right?",
            "This is the empirical measure an if you took the Supreme overall Borel sets.",
            "Of course this will be one.",
            "This will be the total variation between the measure associated with J and the empirical measure.",
            "So the idea is to find some class of sets to test which is.",
            "Big enough, but which is not too small, which is not too big, which is clever, and it turns out that this a cat does the job very well.",
            "An the guy which minimizes over each K this quantity here.",
            "Which is a kind of goodness criterion.",
            "We call it the."
        ],
        [
            "Distance.",
            "Distance but the minimum distance estimate FK an for each FK.",
            "We have a minimum distance estimate.",
            "Now the question is we have one estimate to estimate three estimates etc.",
            "Better bunch of estimate.",
            "Which one do we choose?",
            "We're going to choose a quarter one, which correspond to the cat M that we have estimated before.",
            "But what is known about this effort, K."
        ],
        [
            "Well.",
            "Basically what you should retain from the book of the Royal Legacy.",
            "This is this inequality.",
            "This is the central inequality of the paper of the book, sorry.",
            "Which tells you that once you have selected density like this in each, in each FK right, then the L1 error between half at K&F is not larger than three times.",
            "This term here, which is an approximation theorem, right?",
            "This is the best you can do by approaching F by the city in the model, right?",
            "Of course, this is kind of Oracle.",
            "This is unknown because you don't know you don't know F. But you have.",
            "This is less than three times this guy please some.",
            "Approach estimation term Delta K of F. And Please note that this inequality doesn't require any condition of the densities.",
            "This is what is very very very strong.",
            "Actually you have no smoothness, condition or whatever.",
            "This is true always.",
            "Moreover, this is a finding distance inequality, which is also very powerful, is not accepted result.",
            "Unfortunately, these are the three.",
            "So maybe we can think of to reduce the three to two, but it is a lot of job and we didn't fix it right now.",
            "So you have this inequality and then who is a natural candidate to force this?"
        ],
        [
            "Of course, the minimum estimates calculated.",
            "Exactly on.",
            "The Model F key anwer key has been estimated by the previous method and if we do this right just plug in KN instead of K. We prove."
        ],
        [
            "Objects between F8 key head F is not larger than.",
            "Peanuts 'cause this guy here, but where does it come from?",
            "We know that Keith is very close to the star when we have kissed are here.",
            "This is zero of course because G because F is in FK star.",
            "So this is what is left this term here.",
            "And this is just the Super Bowl over the class of sets at the star of polygons against true.",
            "And what is interesting and very funny list?",
            "Of course at this time here can be controlled using VC theory because this is just the expectation of Superman prequel again through an.",
            "For this you can for example use deadly."
        ],
        [
            "40 or inequality of your chores.",
            "Which tells you that expectation of this super form is certainly not larger than a constant times called VC over North, and Vicky, Vicky or Vicky stars just the VC dimension of.",
            "The Class A key star.",
            "And we process these suppose that this VC dimension is finite, right?",
            "And consequently we."
        ],
        [
            "Then either the L1 error between.",
            "The elected the CDF Hokkien in hand.",
            "The target is not larger than.",
            "Square root of weakest over N plus peanuts, and this is exactly what we wanted."
        ],
        [
            "Right, we have one of one of us quote of rate of consistency for this until even if K is unknown right with nearly any conditions.",
            "And this is a pretty results I think."
        ],
        [
            "Examples well, VC dimension.",
            "It's really easy to see that for Universal Goshen mixture then.",
            "The problem the VC dimensions are finite is exactly the same for the X."
        ],
        [
            "Initial family is it's not larger than keep is 1, so this is not really really not big condition right?",
            "You have examples.",
            "Of course there is a question.",
            "What happens if the true?"
        ],
        [
            "The city does not belong to F, right?",
            "If you're not in F, for example, if it's in the closure of F, What's going on where?",
            "It's more difficult.",
            "It seems that in that case we can have an error bound which is on the order of 10, but it's not completely sure and details should be written down.",
            "But we didn't do it right.",
            "So here we should put the density is somewhere inside.",
            "This is a restriction of course, OK, just to finish.",
            "I would like to discuss this."
        ],
        [
            "Closure condition sorry.",
            "The two next slide, which are the last one.",
            "Are going to be a little bit technical, but I think they're interesting so I want to talk.",
            "I'd like to show you the way we do this.",
            "So what is disclosure condition?",
            "Remember that we support that the set of free transfer, so you have a model, right?",
            "You take the free transfer.",
            "All the guys which are living in this model and you support that the set of free transform is closed in the set of all densities.",
            "And is it a good condition?",
            "Well, suppose that you have a parametric model.",
            "We should have that form.",
            "You have a generative function sign, right?",
            "So Peter.",
            "So for example side and just aggression.",
            "Syrian Theater is the mean and support the two."
        ],
        [
            "Assumption here old first the free transfer of the generative function is continuous on theater.",
            "He died a set of parameters right?",
            "This is not a very big condition, right?",
            "It's easy to easy to check on usual densities and certain that this condition is always true.",
            "Then you can prove that the set of Richmond at the Free Transform.",
            "All the guy which are leaving in the model is also closing the heart.",
            "So what is this second condition?",
            "This means that.",
            "Did you take some tea to 0 which is on the boundary of the of the set of parameters?",
            "Write an if you take any sequence we got to this mandaree, then on the boundary right?",
            "Then the free transform should be generated.",
            "And of course if the set of parameters is compact, this all this is true.",
            "This is trivial, but we didn't want any assumption of this kind and we had to impose this.",
            "And this is very nice condition because this is for Goshen and cities for exponential densities for Laplacian city, for many many models of densities, right?",
            "And this is in that way that we can say that the model are closed right on the boundaries of the parameters, then everything generates.",
            "And how do we transpose this to the mixture case?"
        ],
        [
            "So this is easy, is easy but not easy to prove right?",
            "This is a mixture class, right?",
            "This is a class of all mixture of groups of Goshen.",
            "For examples, right?",
            "So the weights are unknown, and for each case you have mixture of convex combination of car.",
            "Cities right and what we proved that provided the class generate just by this generating function here.",
            "Is closed with respect to this topology.",
            "Then also the model is completely closed, right?",
            "The convex combination is also closed.",
            "Again, this is not trying to prove.",
            "And then we can just say that."
        ],
        [
            "Provided the generating function is free transform, which is continuous, right and provided the title parameters is compacting in some sense right, then the model is closed.",
            "So that means that we were able to obtain this one over one of US quota and consistency rate with nearly no assumptions on the models.",
            "I'm going to stop here, Arthur.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so good morning everyone.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much to the organizer for this very kind invitation.",
                    "label": 0
                },
                {
                    "sent": "It's my pleasure to be here today.",
                    "label": 0
                },
                {
                    "sent": "This is the first time in my life I give us talk so early in the morning but I try to do it.",
                    "label": 0
                },
                {
                    "sent": "And this is joint work with Bone Walker from the economy superior or in cash or little boy from McGill University.",
                    "label": 0
                },
                {
                    "sent": "And Lastly Jeffy from Technical University in Budapest.",
                    "label": 0
                },
                {
                    "sent": "And the talk is entitled on L1 test statics of imagination.",
                    "label": 0
                },
                {
                    "sent": "This is, let's say a combination of several results we have obtained on this topic.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So basically my talk we will divide into sections.",
                    "label": 0
                },
                {
                    "sent": "First I will present you this new test statistics for the two sample problem and then I will turn to a discussion about an interesting application to density model selection.",
                    "label": 0
                },
                {
                    "sent": "But let's start.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With the big inning and with.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "True sample problem.",
                    "label": 0
                },
                {
                    "sent": "So basically what we are interested in is to test with the two samples of the same distribution, so we have to sample X1 exam.",
                    "label": 0
                },
                {
                    "sent": "Experimenting problem in an which are both distributed according to unknown probability distribution measures melendy prime and what we want to test is that.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The two samples are emoji news in the sense that view is equal to prime.",
                    "label": 0
                },
                {
                    "sent": "This is our new assumption, and this is a very important problem which has a lot of practical applications.",
                    "label": 0
                },
                {
                    "sent": "If you want an overview.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The civil application just have a look at the recent paper by author and his collaborators.",
                    "label": 0
                },
                {
                    "sent": "And basically what has been done so far?",
                    "label": 0
                },
                {
                    "sent": "Well, the the method can be roughly divided in three approaches.",
                    "label": 0
                },
                {
                    "sent": "The first approach is a parametric approach, so this is typically the case for normal.",
                    "label": 0
                },
                {
                    "sent": "For normal or lognormal models.",
                    "label": 0
                },
                {
                    "sent": "So if the model is OK, then this kind of test perform well.",
                    "label": 0
                },
                {
                    "sent": "If the model is not OK, this perform usually bad.",
                    "label": 0
                },
                {
                    "sent": "The signal approaches, typically nonparametric approach with Kolmogorov Smirnov typed statistics or come out from Mrs. Also type statistics which perform usually one small dimension but in higher dimension is order.",
                    "label": 0
                },
                {
                    "sent": "And the third type of approach is a more learning theoretic oriented stuff.",
                    "label": 0
                },
                {
                    "sent": "This is exactly what Arthur, his collaborators, try to develop right now, and today I will present you a nonparametric procedure that author has already tested in reality, so it can be much better than me if it performs well or not.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how do we do this?",
                    "label": 0
                },
                {
                    "sent": "Where we first been R2D in?",
                    "label": 0
                },
                {
                    "sent": "And cases right bins and we just define the less the test statistics TN as follows.",
                    "label": 0
                },
                {
                    "sent": "In each bin we calculate the empirical measure associated with the first sample.",
                    "label": 0
                },
                {
                    "sent": "We calculate the empirical measure associated with the second sample, right?",
                    "label": 0
                },
                {
                    "sent": "We look at the difference and we make the same thing overall beans.",
                    "label": 0
                },
                {
                    "sent": "Then we make assume.",
                    "label": 0
                },
                {
                    "sent": "This is a kind of wanted statistics, right?",
                    "label": 0
                },
                {
                    "sent": "And of course, we feel that when Mu is close to new prime then the two empirical measures should be close together and so Tien should be small.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, when you is very different from your prime then you end should be different from new Prime North and so that artistic should be big.",
                    "label": 0
                },
                {
                    "sent": "Of course all this has to be quantified, but this is the ID and actually this is very closed from.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "An idea which has been introduced 17 years ago by last Jovian.",
                    "label": 0
                },
                {
                    "sent": "Edward Vandermoon, which proposed the goodness of fit test statistics.",
                    "label": 1
                },
                {
                    "sent": "Allen, which is defined exactly the same way, except that of course now you have on particles against true an the difficulty here.",
                    "label": 0
                },
                {
                    "sent": "In our case TNT that we have empirical against empirical and yes.",
                    "label": 0
                },
                {
                    "sent": "LM should not be parameterized by the petition because it depends on the position.",
                    "label": 0
                },
                {
                    "sent": "It depends on the just on the bins, right?",
                    "label": 0
                },
                {
                    "sent": "Yeah, measure depends on the end of a certain set of bins.",
                    "label": 0
                },
                {
                    "sent": "If right, you can see like this, yeah?",
                    "label": 0
                },
                {
                    "sent": "Different, that's correct, yeah, absolutely.",
                    "label": 0
                },
                {
                    "sent": "Right, So what is already known about LM?",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This results here, which was proven for years ago by Luke Bryan.",
                    "label": 0
                },
                {
                    "sent": "Messenger fee this is about Ellen right empirical against through the proof that provided the sample set, the number of bins goes to Infinity, but not too fast and provided this condition here is satisfying.",
                    "label": 0
                },
                {
                    "sent": "So this is a bad condition, right?",
                    "label": 0
                },
                {
                    "sent": "This means typically that the merger is nonatomic bad condition, right?",
                    "label": 0
                },
                {
                    "sent": "There is a condition, but this means that the merger is not atomic.",
                    "label": 0
                },
                {
                    "sent": "So if you have a density, it's OK, but you have to impose some kind of density, right?",
                    "label": 0
                },
                {
                    "sent": "Then the probability that Elaine is larger than some threshold behaves are exponential minus N times GL of epsilon, and the rate function GL of epsilon is here.",
                    "label": 0
                },
                {
                    "sent": "This is a complicated function, right?",
                    "label": 0
                },
                {
                    "sent": "But we can be drawn out no problem and the first thing we had to do was to see whether this result is large.",
                    "label": 0
                },
                {
                    "sent": "Deviation results will generalize to empirical against empirical, and that's what we have done.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we have proven actually that the probability that tiene right, which is again in particle against empirical, is larger than some threshold.",
                    "label": 0
                },
                {
                    "sent": "Behaves US exponential minus N comes from rate function.",
                    "label": 0
                },
                {
                    "sent": "And this rate function is very simple expression here, which is GT of epsilon which is this function here.",
                    "label": 0
                },
                {
                    "sent": "And of course, the first question which arises years are GT and Glu.",
                    "label": 0
                },
                {
                    "sent": "Glu went there, and this is GT similar, and the answer is not.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As epsilon goes to zero, the rate function for sample.",
                    "label": 1
                },
                {
                    "sent": "Silver, four, whereas Gen 2.",
                    "label": 0
                },
                {
                    "sent": "Right Moreover",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "GT is not is not bounded, whereas GL is unbounded.",
                    "label": 0
                },
                {
                    "sent": "So the conclusion was inconclusive.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is that Ellen and TN have different large deviation properties, so this was the first important result that we got and Moreover.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We had some reason like this.",
                    "label": 0
                },
                {
                    "sent": "This is the rate function GT for the true sample program writes for the empirical to empirical and this is.",
                    "label": 0
                },
                {
                    "sent": "Bounds for Americans against Rousseau GT is somewhere between GL epsilon two and Jalen of Epsilon.",
                    "label": 0
                },
                {
                    "sent": "So write the message to take home with that GL angithi of different so the the two testing procedures of different behaviors.",
                    "label": 0
                },
                {
                    "sent": "OK, now I would like to show you the.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The way we obtained this presence because I think it's important, yes after.",
                    "label": 0
                },
                {
                    "sent": "Not.",
                    "label": 0
                },
                {
                    "sent": "Right both require, yeah, both recorded, but the test doesn't require the large deviation required boasted of.",
                    "label": 0
                },
                {
                    "sent": "Yeah, both large aviation result record is under the same assumption, right?",
                    "label": 0
                },
                {
                    "sent": "Absolutely, right, that's correct.",
                    "label": 0
                },
                {
                    "sent": "But the tests that I'm going to present doesn't need it.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to show you the way we obtained this because I think it's important.",
                    "label": 0
                },
                {
                    "sent": "I don't want to be technical today, but however I think it's important to spread out the.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So just one one side of proof, right?",
                    "label": 0
                },
                {
                    "sent": "We just start with the generating function of the sequence, the end.",
                    "label": 0
                },
                {
                    "sent": "This is TN is a test statistics, right?",
                    "label": 0
                },
                {
                    "sent": "So Lambda two offices, just the limit as N goes to Infinity of the expectation of exponential SMT.",
                    "label": 0
                },
                {
                    "sent": "Alright log of this one over and we have to prove that.",
                    "label": 0
                },
                {
                    "sent": "These guys here goes to some limit and for this we use Chef.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For partitions, this is what is important here.",
                    "label": 0
                },
                {
                    "sent": "And what does it say?",
                    "label": 0
                },
                {
                    "sent": "It say that the test statistics tiene can just be rewriting as the maximum over the single algebra which is generated by the bins of the partition right of empirical against empirical and this is good because this Sigma algebra is fine, it right?",
                    "label": 0
                },
                {
                    "sent": "It has at most two to the M elements because PM is fine partition and this is the way we go.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Further to calculate the expectation of ESNTN right, we run down.",
                    "label": 0
                },
                {
                    "sent": "This is the expectation of the maximum over this Sigma algebra using Shift theorem for petition.",
                    "label": 1
                },
                {
                    "sent": "Then this is certainly smaller than two to the MN times the maximum, because the same algebra is finding number of elements.",
                    "label": 0
                },
                {
                    "sent": "Then, since the two samples are independent, which is break spectation in two terms, right?",
                    "label": 0
                },
                {
                    "sent": "And then under H0 these terms are the same distribution, so they behave exactly the same way and we can get this bound here, right?",
                    "label": 0
                },
                {
                    "sent": "So the key of the proof is Schaefer Theorem, so this is for upper bound.",
                    "label": 0
                },
                {
                    "sent": "So just taking logarithm one or limit we get what?",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Wanted.",
                    "label": 0
                },
                {
                    "sent": "We get lunch at your place more than this guy here and for the lower bound.",
                    "label": 0
                },
                {
                    "sent": "This is.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Similar, right?",
                    "label": 0
                },
                {
                    "sent": "We arrived at the expectation of the generating function is just the expectation of the maximum we upper body lower bounded by the maximum of expectation and then some trick and there's zero.",
                    "label": 0
                },
                {
                    "sent": "The true samples of the same distribution an we get.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That Lambda T of S the rate function is to return the limit of the generating function is certainly larger than this expression there, so this is because of the lower and upper bound.",
                    "label": 0
                },
                {
                    "sent": "There are exactly the same, and we conclude this by.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Again, a theorem for large deviation, which tells us that the rate function is just the maximum of epsilon minus Lambda two epsilon, and this is that way that we obtain the rate function.",
                    "label": 0
                },
                {
                    "sent": "OK, so sorry to be a little bit technical, but this was just to show you the way we do it now.",
                    "label": 0
                },
                {
                    "sent": "We have this result right?",
                    "label": 0
                },
                {
                    "sent": "We have this.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Present here and the question is, can we use it?",
                    "label": 0
                },
                {
                    "sent": "For obtaining statistical test.",
                    "label": 0
                },
                {
                    "sent": "So the question the answer is yes.",
                    "label": 0
                },
                {
                    "sent": "But you know, this is not really a central limit theorem, right?",
                    "label": 0
                },
                {
                    "sent": "This is just a large deviation result, and so we're going to obtain some constraints, some some strange type of testing.",
                    "label": 0
                },
                {
                    "sent": "And this this is.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Called distribution free strong, consistent testing so.",
                    "label": 0
                },
                {
                    "sent": "This is good because the test is going to be distribution free.",
                    "label": 0
                },
                {
                    "sent": "That is no assumption about the distribution, but this is, well, let's say not bad, but less good, right?",
                    "label": 0
                },
                {
                    "sent": "Because this is a different way of testing.",
                    "label": 0
                },
                {
                    "sent": "But the idea is interesting.",
                    "label": 0
                },
                {
                    "sent": "What does that mean?",
                    "label": 0
                },
                {
                    "sent": "Strong, consistent test?",
                    "label": 0
                },
                {
                    "sent": "It means that.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Both on HO and on its complement, the test makes emotionally no mistake.",
                    "label": 1
                },
                {
                    "sent": "After a random sample size, right?",
                    "label": 0
                },
                {
                    "sent": "In other words, in.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You mean that if you are underage zero then you are sure that after some random sample size that you have taken the good decision right?",
                    "label": 0
                },
                {
                    "sent": "And on the other hand, if you are underage, one is exactly the same and this is strange way of testing, which is not the usual way, right?",
                    "label": 0
                },
                {
                    "sent": "And this concept is very close to some concept which has been introduced in Denver in Paris in 94 which is called.",
                    "label": 0
                },
                {
                    "sent": "And ability, and from ideas which have been up to also developed by the legacy in 2002.",
                    "label": 0
                },
                {
                    "sent": "And this can be interesting, for example, when some kind of sequential testing when you have only one sample at ARM, right?",
                    "label": 0
                },
                {
                    "sent": "You get the data once an you want to be sure after some random samples that you have taken the good decision OK?",
                    "label": 0
                },
                {
                    "sent": "And so.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is a test we obtain, and again this tells us no assumption about distribution, right?",
                    "label": 0
                },
                {
                    "sent": "Completely free distribution free.",
                    "label": 0
                },
                {
                    "sent": "So consider the test which rejects when teams becomes large.",
                    "label": 1
                },
                {
                    "sent": "So this can be quantified right?",
                    "label": 0
                },
                {
                    "sent": "So C one is 1.66.",
                    "label": 0
                },
                {
                    "sent": "So providing MN goes to Infinity but not too fast then.",
                    "label": 0
                },
                {
                    "sent": "After some random sample size, you are sure that the test makes no error and over if you are under the alternative right and provided this condition is satisfied.",
                    "label": 1
                },
                {
                    "sent": "Well, this is just a small condition and basically this means that the partition is made of square.",
                    "label": 1
                },
                {
                    "sent": "For example, this is not very small assumption.",
                    "label": 0
                },
                {
                    "sent": "Then you are also sure that you have no error.",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "Do you need a distribution?",
                    "label": 0
                },
                {
                    "sent": "Of course.",
                    "label": 0
                },
                {
                    "sent": "Oh, I should I should I?",
                    "label": 0
                },
                {
                    "sent": "Each one extent of the same distribution, right?",
                    "label": 0
                },
                {
                    "sent": "So there random they are independent, identically distributed, fixed.",
                    "label": 0
                },
                {
                    "sent": "Absolutely, that's it, that's great.",
                    "label": 0
                },
                {
                    "sent": "And so, this is, uh, this way of testing.",
                    "label": 0
                },
                {
                    "sent": "Of course, now if you want a more traditional way of testing, you know without further procedure etc, then you have to get some central limit theorem and let me show you the way we obtain central limit theorem for this kind of statistiques.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, first they seem to think of multi of Ln empirical against true was derived 10 years ago.",
                    "label": 0
                },
                {
                    "sent": "Something like this by Berlin jophiel ago.",
                    "label": 0
                },
                {
                    "sent": "She who have proven that squared valentime hell N minus the expectation over Sigma goes to some normal random variables and the techniques.",
                    "label": 0
                },
                {
                    "sent": "Off",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "These authors involve poison representation of the empirical process in conjunction with very old ID.",
                    "label": 1
                },
                {
                    "sent": "Oh, but let's of partial inversion for obtaining conditional characteristic distributions and the key point of this kind of results is really the personalization technique.",
                    "label": 0
                },
                {
                    "sent": "I'm going to explain you out this goes.",
                    "label": 0
                },
                {
                    "sent": "And before this.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here is the reason we have obtained, so we have also proven Central limit theorem.",
                    "label": 0
                },
                {
                    "sent": "So provided again the number of bins goes to Infinity and provided the distribution is not atomic.",
                    "label": 0
                },
                {
                    "sent": "This is this condition here which is required.",
                    "label": 0
                },
                {
                    "sent": "Then under zero you have a central main reason.",
                    "label": 0
                },
                {
                    "sent": "So that means that screwed event MTN minus some normalization goes to some normal random variable.",
                    "label": 0
                },
                {
                    "sent": "And you have an expression of the variance which is independent of the dimension.",
                    "label": 0
                },
                {
                    "sent": "What is interesting for me the way we obtained this results much more than the reason by itself.",
                    "label": 0
                },
                {
                    "sent": "Anne why?",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is it difficult?",
                    "label": 0
                },
                {
                    "sent": "The difficulty comes from the fact that tiene that aesthetics right is assume of dependent random variables full because all the empirical measure some to one.",
                    "label": 1
                },
                {
                    "sent": "This is what is difficult.",
                    "label": 1
                },
                {
                    "sent": "And to overcome this kind of problem.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right, we use a personalization argument, which is very powerful argument for proving central limit theorems and many other races on search statistics.",
                    "label": 0
                },
                {
                    "sent": "So what is the idea is that we are going to make the sample size random.",
                    "label": 0
                },
                {
                    "sent": "We make the sample size random poison basically.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Like this we just define NNN NNN two person random variables which are independent of everything and independent between themselves independent of everything but which are on average equal to N right?",
                    "label": 0
                },
                {
                    "sent": "And then we define just the person is that version.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of the test statistics, which is exactly the same as before.",
                    "label": 0
                },
                {
                    "sent": "Accept that.",
                    "label": 0
                },
                {
                    "sent": "We have replaced with sample size by some random stuff here.",
                    "label": 0
                },
                {
                    "sent": "This is the let's say the randomly said empirical measure.",
                    "label": 0
                },
                {
                    "sent": "This is a randomized empirical measure of the second sample right?",
                    "label": 0
                },
                {
                    "sent": "Or there was a test statistic is exactly the same?",
                    "label": 0
                },
                {
                    "sent": "And why is it important to do this?",
                    "label": 0
                },
                {
                    "sent": "This is important because.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then if you just count the number of guys which form the first being, the number of gallons second, Meanwhile, would you call this vector while you do exactly for the same for the second sample?",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "Then of course, why NY Prime NR independent?",
                    "label": 0
                },
                {
                    "sent": "This is easy because the samples are independent, but there is much more.",
                    "label": 1
                },
                {
                    "sent": "The number of guys which one the first beam is independent of the number of guys returning the second bin and so on right?",
                    "label": 0
                },
                {
                    "sent": "Because you make the sample size random and this is the key of this position tree and Moreover the on average the number of points which fall in each bin right?",
                    "label": 1
                },
                {
                    "sent": "Is poison with the right distribution MUNG.",
                    "label": 0
                },
                {
                    "sent": "Ann, this is the first argument in this segment.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is that conditional on the sample size right?",
                    "label": 0
                },
                {
                    "sent": "Everything becomes multinomial.",
                    "label": 0
                },
                {
                    "sent": "And this is called personalization and this is a statistical trick to prove their central limit theorem and actually the key of the pro.",
                    "label": 1
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Uses forest inversion formula an.",
                    "label": 0
                },
                {
                    "sent": "It's very technical, but every.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It relies on 1L or proposition so.",
                    "label": 0
                },
                {
                    "sent": "I explained why the way it works, so this is what we want to prove, right?",
                    "label": 0
                },
                {
                    "sent": "We want to prove central limit theory about this statistics here.",
                    "label": 0
                },
                {
                    "sent": "So J is nothing.",
                    "label": 0
                },
                {
                    "sent": "This is just normalization right about this test statistics here.",
                    "label": 0
                },
                {
                    "sent": "But all the guys are independent right?",
                    "label": 0
                },
                {
                    "sent": "So you cannot use the usual way of proving this would happen.",
                    "label": 0
                },
                {
                    "sent": "Or theorem example amid condition and so on.",
                    "label": 0
                },
                {
                    "sent": "Of course, because everything is independent.",
                    "label": 0
                },
                {
                    "sent": "But you have, this person is that version here.",
                    "label": 0
                },
                {
                    "sent": "Where do you guys are independent and the proposition says that if you can prove something about a men which is approaching this version with an N and prime N right, some big central limit theorem.",
                    "label": 0
                },
                {
                    "sent": "Then if you have this empty normality then you get this empty normality of.",
                    "label": 0
                },
                {
                    "sent": "Let's say the original statistics, but these are some pretty normality.",
                    "label": 0
                },
                {
                    "sent": "Here is easy to prove right?",
                    "label": 0
                },
                {
                    "sent": "Where is it technically?",
                    "label": 0
                },
                {
                    "sent": "It's easy to prove cause conditional North or the guys you are independent and you have all the distributions, so this is easy to do.",
                    "label": 0
                },
                {
                    "sent": "This is technical, but is it?",
                    "label": 0
                },
                {
                    "sent": "You can do it with usual central limit conditions.",
                    "label": 0
                },
                {
                    "sent": "So this is an interesting approach.",
                    "label": 0
                },
                {
                    "sent": "For handling empirical measures.",
                    "label": 0
                },
                {
                    "sent": "And this leads to a status, of course.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Test testing procedure, which is more classical, so putting some level Alpha right you take sister is 0.7.",
                    "label": 0
                },
                {
                    "sent": "This is the best known variation constant right?",
                    "label": 0
                },
                {
                    "sent": "And you consider the test which rejects H zero and TN becomes large so typically larger than this guys here.",
                    "label": 1
                },
                {
                    "sent": "So 5 -- 1 is just the.",
                    "label": 0
                },
                {
                    "sent": "The inverse of the distribution function of the Goshen right then.",
                    "label": 0
                },
                {
                    "sent": "This test has a septic significance level Alpha and Moreover, provided this condition on the partition holds, the test is also consistently mean that if you are under the alternative fuel, the power goes to one.",
                    "label": 1
                },
                {
                    "sent": "So this is a good test, except that it is based on the central limit result an you have to suppose that the distribution is not actually so this holds for measures which have density probability, but that's OK. Or restriction.",
                    "label": 0
                },
                {
                    "sent": "Yep, so now.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm going to discuss an application surprising application to density model selection problem.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what we want to do here?",
                    "label": 0
                },
                {
                    "sent": "Well, we have a collection of sets right FK which are nested.",
                    "label": 0
                },
                {
                    "sent": "Typically, a parametric sets F1F2F2 is bigger 3456.",
                    "label": 0
                },
                {
                    "sent": "And you know that the target, the density you want to estimate is in one of these F. Right, you know that it is one of these F. You have a sample at unexplored extent and what you want to do is to pick to pick the Golden City estimate right?",
                    "label": 0
                },
                {
                    "sent": "This is complicated.",
                    "label": 0
                },
                {
                    "sent": "This is complicated.",
                    "label": 0
                },
                {
                    "sent": "Why?",
                    "label": 0
                },
                {
                    "sent": "Because you don't know where the city is living, of course, and this is complicated.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "K. The complexity is unknown.",
                    "label": 0
                },
                {
                    "sent": "You don't know where it is and you want a full system 8K, and when you have chosen K you want to pick a density estimate in FK so there is there are two problems actually.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And what we want to do, what is a challenging question here?",
                    "label": 0
                },
                {
                    "sent": "The challenging question is to pick some density estimate.",
                    "label": 1
                },
                {
                    "sent": "Have had key North right?",
                    "label": 0
                },
                {
                    "sent": "So Keehan is an estimation of the set where the density is leaving.",
                    "label": 0
                },
                {
                    "sent": "And we want that as N goes large, then we want that key N approaches kistar.",
                    "label": 0
                },
                {
                    "sent": "So this is the first challenge and 2nd we want to pick it.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Suggesting that even the selected key N search at the L1 error between the target and F goes to zero at the rate one of us proud of.",
                    "label": 1
                },
                {
                    "sent": "And this is very difficult problem cause KN is unknown.",
                    "label": 0
                },
                {
                    "sent": "If we nuke again.",
                    "label": 0
                },
                {
                    "sent": "Of course this will be easy to obtain, but here the complexity is unknown.",
                    "label": 0
                },
                {
                    "sent": "So we want to rate exactly as if the complexity I've been known before hand and this is a challenging question.",
                    "label": 0
                },
                {
                    "sent": "So as you will see.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In will be obtained by minimizing the error between models and empirical measure over the same ideas.",
                    "label": 0
                },
                {
                    "sent": "And the second step.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The model parameter that is the estimation effort came.",
                    "label": 0
                },
                {
                    "sent": "Will be done using general community.",
                    "label": 0
                },
                {
                    "sent": "Will choose which go back to Lacon then which have been explored by Jaco's and which have been finally formalized by.",
                    "label": 0
                },
                {
                    "sent": "The value goes in a small book.",
                    "label": 0
                },
                {
                    "sent": "In 2001.",
                    "label": 0
                },
                {
                    "sent": "I will explain it later the way we do it.",
                    "label": 0
                },
                {
                    "sent": "But let's start with the beginning.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, let's start with some examples, just to show you that this this problem is important.",
                    "label": 0
                },
                {
                    "sent": "The first big example is of course the mixture class problem here.",
                    "label": 0
                },
                {
                    "sent": "Each FK is made of mixture of Goshen, right?",
                    "label": 0
                },
                {
                    "sent": "So each FK is composed of mixture of car Goshen City.",
                    "label": 0
                },
                {
                    "sent": "So what is unknown here that the weights are unknown?",
                    "label": 0
                },
                {
                    "sent": "The variance Sigma are known.",
                    "label": 0
                },
                {
                    "sent": "The means are known right?",
                    "label": 0
                },
                {
                    "sent": "And the problem is difficult because we don't know K and ASCII grows right?",
                    "label": 0
                },
                {
                    "sent": "You have more and more models and you want to select the good key and this is a problem which has attracted alot alot alot of attention in the literature them.",
                    "label": 0
                },
                {
                    "sent": "Plenty, plenty of papers about this about known K. The case where K is known about the case where key is unknown, so you have many, many papers on this and in many different communities actually.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "By using community.",
                    "label": 0
                },
                {
                    "sent": "You have this promise treaty.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You have in statistical learning literature.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In clustering literature.",
                    "label": 0
                },
                {
                    "sent": "In",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "More statistical literature, so you have this problem is very important because of course you all know it has a lot of applications, so this is the first illustration of the problem, right?",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Good example in the case of the increasing exponential families.",
                    "label": 1
                },
                {
                    "sent": "Year each density FK takes this form here and then you let key grows right.",
                    "label": 0
                },
                {
                    "sent": "The model becomes more and more rich, and by letting car Groves.",
                    "label": 0
                },
                {
                    "sent": "This model can be.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Very powerful actually.",
                    "label": 0
                },
                {
                    "sent": "You can get many many classes of density beta gamma Ray to Maxwell many million cities.",
                    "label": 0
                },
                {
                    "sent": "So here the challenge is to select the good K and once you have selected K again to select a good density.",
                    "label": 0
                },
                {
                    "sent": "But there are many.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The models you can see into your networks, wavelets and many others, and of course we have to make some.",
                    "label": 0
                },
                {
                    "sent": "We have to impose some conditions right because otherwise it's too large.",
                    "label": 0
                },
                {
                    "sent": "The first condition we will impose a natural condition we have to impose in some way that the complexity of the class where K is leaving is not too big and this will be done.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Using typically Yvc argument, right?",
                    "label": 0
                },
                {
                    "sent": "I will explain later, but you will support the complexity or after the class is not too big where K is leaving.",
                    "label": 0
                },
                {
                    "sent": "This is the first assumption, but there is a second assumption which also important is that the classes should be well separated, one of each other right?",
                    "label": 0
                },
                {
                    "sent": "Because they are nested an in some way you have to support that they are closed in somehow and this was a very difficult part of the paper.",
                    "label": 0
                },
                {
                    "sent": "We spend a lot of time trying to find good conditions.",
                    "label": 0
                },
                {
                    "sent": "For these models to be closed and that we have imposed.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is on this paper on this slide.",
                    "label": 0
                },
                {
                    "sent": "Sorry so I will come back a little bit later on this condition because I think it's very important.",
                    "label": 0
                },
                {
                    "sent": "It has been fired by the refering right very frequently it's OK. Just put the condition that we gave some.",
                    "label": 0
                },
                {
                    "sent": "You know some condition for this condition to hold and he said Oh no, it's too complicated whatever form it was most important part so.",
                    "label": 0
                },
                {
                    "sent": "OK, but I will present it today.",
                    "label": 0
                },
                {
                    "sent": "The paper is published but not part so.",
                    "label": 0
                },
                {
                    "sent": "I just do not by default the set of free transform of a set of densities right and assume.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And is that the set of free transform of each model is closed in the set of Fourier transform of order CDs right?",
                    "label": 1
                },
                {
                    "sent": "With respect to the consistency topology?",
                    "label": 0
                },
                {
                    "sent": "So what does that mean then?",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That you have some clothes that in this sense here I mean whatever the sequence GN in FK, which goes to some limit, J right and so that whatever.",
                    "label": 1
                },
                {
                    "sent": "The test function, Phi right, continuous, bounded, then the limit J belongs to FK.",
                    "label": 0
                },
                {
                    "sent": "So this is a closure condition with respect to the consistency topology.",
                    "label": 1
                },
                {
                    "sent": "And this is a good condition.",
                    "label": 0
                },
                {
                    "sent": "This is a good condition because it works.",
                    "label": 0
                },
                {
                    "sent": "Our other will show you for practically all usual densities.",
                    "label": 0
                },
                {
                    "sent": "So let's assume As for now that this condition on the model that is closure condition holds right.",
                    "label": 0
                },
                {
                    "sent": "So these are conditional complexity conditional clauses condition.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How do we do to estimate the complexity?",
                    "label": 0
                },
                {
                    "sent": "Well, we split the sample in two parts, each one in send an experiment experimental, so support at any level.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We make a beating of our D right with partition with William H into the D. And we introduced the following test.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Statistics we call DNK all that work.",
                    "label": 0
                },
                {
                    "sent": "So for each model FK.",
                    "label": 0
                },
                {
                    "sent": "We take some guy FJ in FJ, right can do that and we just compare.",
                    "label": 0
                },
                {
                    "sent": "Overall been the merger associated to the bin by J and empirical measure.",
                    "label": 0
                },
                {
                    "sent": "We do this over all the bins and we take them over all the guys which are leaving the FK of this quantity, which is a kind of L1 distance.",
                    "label": 0
                },
                {
                    "sent": "And of course the NK is decreasing because the sequence of modeling is nested and what we feel.",
                    "label": 0
                },
                {
                    "sent": "Either when key right the index key is close to kistar then you have J.",
                    "label": 0
                },
                {
                    "sent": "You have F in ASCII star and this quantity should be very small and the idea is that we should select.",
                    "label": 0
                },
                {
                    "sent": "The threshold K. We should see like a Wendy and K is below some threshold, but this threshold has to be clever.",
                    "label": 0
                },
                {
                    "sent": "It has to be adapted as we based on the data it has to go to 0 fast but not too fast and we spend a lot of time trying to find some interesting threshold and we.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is interesting here.",
                    "label": 0
                },
                {
                    "sent": "Is that the treasure is exactly the 2016 of the first part.",
                    "label": 0
                },
                {
                    "sent": "So when we use the just the empirical differences right between the two samples, then this is a good estimate of the threshold and the test is very simple, right?",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We select the complexity of the model just by taking the first K where the test statistic DNK is more than the threshold.",
                    "label": 0
                },
                {
                    "sent": "This is random.",
                    "label": 0
                },
                {
                    "sent": "This is random.",
                    "label": 0
                },
                {
                    "sent": "And this works well.",
                    "label": 0
                },
                {
                    "sent": "And what we prove actually is that with this.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Dorism here.",
                    "label": 0
                },
                {
                    "sent": "Then the probability that the selected key N is different from keystar.",
                    "label": 0
                },
                {
                    "sent": "The true complexities that unknown goes exponentially faster zero.",
                    "label": 0
                },
                {
                    "sent": "This is of course the result that we have proven in the first section about the.",
                    "label": 0
                },
                {
                    "sent": "And so you're using broken till we can prove that almost surely for Ln large enough then key N. The estimated complexity is exactly equal to Keystone.",
                    "label": 0
                },
                {
                    "sent": "So we are able to prove that we have an estimate which goes almost surely to the true complexity.",
                    "label": 0
                },
                {
                    "sent": "This is fine with almost no assumption on density.",
                    "label": 0
                },
                {
                    "sent": "So this is for the purse.",
                    "label": 0
                },
                {
                    "sent": "For the first part of the algorithm of the method.",
                    "label": 0
                },
                {
                    "sent": "Now the question is how do we do to select density in F in the selected key end, right?",
                    "label": 0
                },
                {
                    "sent": "So for this as I said.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We use a paradigma which has been first, which caused us to look um in the original setting then which has been.",
                    "label": 0
                },
                {
                    "sent": "Put in the good way for densities by Luke gobble, gobble Gucci.",
                    "label": 0
                },
                {
                    "sent": "Assuming this works as follows.",
                    "label": 0
                },
                {
                    "sent": "So now I have models F1F two or three.",
                    "label": 0
                },
                {
                    "sent": "I fix a model FK.",
                    "label": 0
                },
                {
                    "sent": "I'll just take the.",
                    "label": 0
                },
                {
                    "sent": "This weekend's offsets here.",
                    "label": 0
                },
                {
                    "sent": "How do we do this?",
                    "label": 0
                },
                {
                    "sent": "Well, you take 2 function in FK and you look at the bubble set where G1 is larger than the two and you do that you do many many comparisons with all the guys which are living in FK.",
                    "label": 0
                },
                {
                    "sent": "This gives you a class of sets up.",
                    "label": 1
                },
                {
                    "sent": "For example if K is the class of Goshen is easy to prove that this is just the set of intervals and their unions.",
                    "label": 0
                },
                {
                    "sent": "So for many known models this is easy to calculate and this is the class of set which is which.",
                    "label": 0
                },
                {
                    "sent": "But which is not huge and it is a clever class of said why?",
                    "label": 0
                },
                {
                    "sent": "Because if we take a goodness.",
                    "label": 0
                },
                {
                    "sent": "Sharing here this quantity Delta K of J.",
                    "label": 0
                },
                {
                    "sent": "Which is.",
                    "label": 0
                },
                {
                    "sent": "Just the difference between test and see TJ right and this is the merger which is associated to the set A by J right?",
                    "label": 0
                },
                {
                    "sent": "This is the empirical measure an if you took the Supreme overall Borel sets.",
                    "label": 0
                },
                {
                    "sent": "Of course this will be one.",
                    "label": 0
                },
                {
                    "sent": "This will be the total variation between the measure associated with J and the empirical measure.",
                    "label": 0
                },
                {
                    "sent": "So the idea is to find some class of sets to test which is.",
                    "label": 0
                },
                {
                    "sent": "Big enough, but which is not too small, which is not too big, which is clever, and it turns out that this a cat does the job very well.",
                    "label": 0
                },
                {
                    "sent": "An the guy which minimizes over each K this quantity here.",
                    "label": 1
                },
                {
                    "sent": "Which is a kind of goodness criterion.",
                    "label": 0
                },
                {
                    "sent": "We call it the.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Distance.",
                    "label": 0
                },
                {
                    "sent": "Distance but the minimum distance estimate FK an for each FK.",
                    "label": 1
                },
                {
                    "sent": "We have a minimum distance estimate.",
                    "label": 0
                },
                {
                    "sent": "Now the question is we have one estimate to estimate three estimates etc.",
                    "label": 0
                },
                {
                    "sent": "Better bunch of estimate.",
                    "label": 0
                },
                {
                    "sent": "Which one do we choose?",
                    "label": 0
                },
                {
                    "sent": "We're going to choose a quarter one, which correspond to the cat M that we have estimated before.",
                    "label": 0
                },
                {
                    "sent": "But what is known about this effort, K.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well.",
                    "label": 0
                },
                {
                    "sent": "Basically what you should retain from the book of the Royal Legacy.",
                    "label": 0
                },
                {
                    "sent": "This is this inequality.",
                    "label": 0
                },
                {
                    "sent": "This is the central inequality of the paper of the book, sorry.",
                    "label": 0
                },
                {
                    "sent": "Which tells you that once you have selected density like this in each, in each FK right, then the L1 error between half at K&F is not larger than three times.",
                    "label": 0
                },
                {
                    "sent": "This term here, which is an approximation theorem, right?",
                    "label": 0
                },
                {
                    "sent": "This is the best you can do by approaching F by the city in the model, right?",
                    "label": 0
                },
                {
                    "sent": "Of course, this is kind of Oracle.",
                    "label": 0
                },
                {
                    "sent": "This is unknown because you don't know you don't know F. But you have.",
                    "label": 0
                },
                {
                    "sent": "This is less than three times this guy please some.",
                    "label": 0
                },
                {
                    "sent": "Approach estimation term Delta K of F. And Please note that this inequality doesn't require any condition of the densities.",
                    "label": 1
                },
                {
                    "sent": "This is what is very very very strong.",
                    "label": 0
                },
                {
                    "sent": "Actually you have no smoothness, condition or whatever.",
                    "label": 0
                },
                {
                    "sent": "This is true always.",
                    "label": 0
                },
                {
                    "sent": "Moreover, this is a finding distance inequality, which is also very powerful, is not accepted result.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately, these are the three.",
                    "label": 0
                },
                {
                    "sent": "So maybe we can think of to reduce the three to two, but it is a lot of job and we didn't fix it right now.",
                    "label": 0
                },
                {
                    "sent": "So you have this inequality and then who is a natural candidate to force this?",
                    "label": 1
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of course, the minimum estimates calculated.",
                    "label": 0
                },
                {
                    "sent": "Exactly on.",
                    "label": 0
                },
                {
                    "sent": "The Model F key anwer key has been estimated by the previous method and if we do this right just plug in KN instead of K. We prove.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Objects between F8 key head F is not larger than.",
                    "label": 0
                },
                {
                    "sent": "Peanuts 'cause this guy here, but where does it come from?",
                    "label": 0
                },
                {
                    "sent": "We know that Keith is very close to the star when we have kissed are here.",
                    "label": 0
                },
                {
                    "sent": "This is zero of course because G because F is in FK star.",
                    "label": 0
                },
                {
                    "sent": "So this is what is left this term here.",
                    "label": 0
                },
                {
                    "sent": "And this is just the Super Bowl over the class of sets at the star of polygons against true.",
                    "label": 0
                },
                {
                    "sent": "And what is interesting and very funny list?",
                    "label": 0
                },
                {
                    "sent": "Of course at this time here can be controlled using VC theory because this is just the expectation of Superman prequel again through an.",
                    "label": 0
                },
                {
                    "sent": "For this you can for example use deadly.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "40 or inequality of your chores.",
                    "label": 0
                },
                {
                    "sent": "Which tells you that expectation of this super form is certainly not larger than a constant times called VC over North, and Vicky, Vicky or Vicky stars just the VC dimension of.",
                    "label": 0
                },
                {
                    "sent": "The Class A key star.",
                    "label": 0
                },
                {
                    "sent": "And we process these suppose that this VC dimension is finite, right?",
                    "label": 0
                },
                {
                    "sent": "And consequently we.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then either the L1 error between.",
                    "label": 0
                },
                {
                    "sent": "The elected the CDF Hokkien in hand.",
                    "label": 0
                },
                {
                    "sent": "The target is not larger than.",
                    "label": 0
                },
                {
                    "sent": "Square root of weakest over N plus peanuts, and this is exactly what we wanted.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right, we have one of one of us quote of rate of consistency for this until even if K is unknown right with nearly any conditions.",
                    "label": 0
                },
                {
                    "sent": "And this is a pretty results I think.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Examples well, VC dimension.",
                    "label": 0
                },
                {
                    "sent": "It's really easy to see that for Universal Goshen mixture then.",
                    "label": 0
                },
                {
                    "sent": "The problem the VC dimensions are finite is exactly the same for the X.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Initial family is it's not larger than keep is 1, so this is not really really not big condition right?",
                    "label": 0
                },
                {
                    "sent": "You have examples.",
                    "label": 0
                },
                {
                    "sent": "Of course there is a question.",
                    "label": 0
                },
                {
                    "sent": "What happens if the true?",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The city does not belong to F, right?",
                    "label": 0
                },
                {
                    "sent": "If you're not in F, for example, if it's in the closure of F, What's going on where?",
                    "label": 0
                },
                {
                    "sent": "It's more difficult.",
                    "label": 0
                },
                {
                    "sent": "It seems that in that case we can have an error bound which is on the order of 10, but it's not completely sure and details should be written down.",
                    "label": 1
                },
                {
                    "sent": "But we didn't do it right.",
                    "label": 0
                },
                {
                    "sent": "So here we should put the density is somewhere inside.",
                    "label": 0
                },
                {
                    "sent": "This is a restriction of course, OK, just to finish.",
                    "label": 0
                },
                {
                    "sent": "I would like to discuss this.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Closure condition sorry.",
                    "label": 0
                },
                {
                    "sent": "The two next slide, which are the last one.",
                    "label": 0
                },
                {
                    "sent": "Are going to be a little bit technical, but I think they're interesting so I want to talk.",
                    "label": 0
                },
                {
                    "sent": "I'd like to show you the way we do this.",
                    "label": 0
                },
                {
                    "sent": "So what is disclosure condition?",
                    "label": 0
                },
                {
                    "sent": "Remember that we support that the set of free transfer, so you have a model, right?",
                    "label": 0
                },
                {
                    "sent": "You take the free transfer.",
                    "label": 0
                },
                {
                    "sent": "All the guys which are living in this model and you support that the set of free transform is closed in the set of all densities.",
                    "label": 1
                },
                {
                    "sent": "And is it a good condition?",
                    "label": 0
                },
                {
                    "sent": "Well, suppose that you have a parametric model.",
                    "label": 0
                },
                {
                    "sent": "We should have that form.",
                    "label": 0
                },
                {
                    "sent": "You have a generative function sign, right?",
                    "label": 0
                },
                {
                    "sent": "So Peter.",
                    "label": 0
                },
                {
                    "sent": "So for example side and just aggression.",
                    "label": 0
                },
                {
                    "sent": "Syrian Theater is the mean and support the two.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Assumption here old first the free transfer of the generative function is continuous on theater.",
                    "label": 1
                },
                {
                    "sent": "He died a set of parameters right?",
                    "label": 0
                },
                {
                    "sent": "This is not a very big condition, right?",
                    "label": 0
                },
                {
                    "sent": "It's easy to easy to check on usual densities and certain that this condition is always true.",
                    "label": 0
                },
                {
                    "sent": "Then you can prove that the set of Richmond at the Free Transform.",
                    "label": 0
                },
                {
                    "sent": "All the guy which are leaving in the model is also closing the heart.",
                    "label": 0
                },
                {
                    "sent": "So what is this second condition?",
                    "label": 0
                },
                {
                    "sent": "This means that.",
                    "label": 1
                },
                {
                    "sent": "Did you take some tea to 0 which is on the boundary of the of the set of parameters?",
                    "label": 1
                },
                {
                    "sent": "Write an if you take any sequence we got to this mandaree, then on the boundary right?",
                    "label": 0
                },
                {
                    "sent": "Then the free transform should be generated.",
                    "label": 0
                },
                {
                    "sent": "And of course if the set of parameters is compact, this all this is true.",
                    "label": 0
                },
                {
                    "sent": "This is trivial, but we didn't want any assumption of this kind and we had to impose this.",
                    "label": 0
                },
                {
                    "sent": "And this is very nice condition because this is for Goshen and cities for exponential densities for Laplacian city, for many many models of densities, right?",
                    "label": 0
                },
                {
                    "sent": "And this is in that way that we can say that the model are closed right on the boundaries of the parameters, then everything generates.",
                    "label": 0
                },
                {
                    "sent": "And how do we transpose this to the mixture case?",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is easy, is easy but not easy to prove right?",
                    "label": 0
                },
                {
                    "sent": "This is a mixture class, right?",
                    "label": 0
                },
                {
                    "sent": "This is a class of all mixture of groups of Goshen.",
                    "label": 0
                },
                {
                    "sent": "For examples, right?",
                    "label": 0
                },
                {
                    "sent": "So the weights are unknown, and for each case you have mixture of convex combination of car.",
                    "label": 0
                },
                {
                    "sent": "Cities right and what we proved that provided the class generate just by this generating function here.",
                    "label": 0
                },
                {
                    "sent": "Is closed with respect to this topology.",
                    "label": 0
                },
                {
                    "sent": "Then also the model is completely closed, right?",
                    "label": 0
                },
                {
                    "sent": "The convex combination is also closed.",
                    "label": 0
                },
                {
                    "sent": "Again, this is not trying to prove.",
                    "label": 0
                },
                {
                    "sent": "And then we can just say that.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Provided the generating function is free transform, which is continuous, right and provided the title parameters is compacting in some sense right, then the model is closed.",
                    "label": 0
                },
                {
                    "sent": "So that means that we were able to obtain this one over one of US quota and consistency rate with nearly no assumptions on the models.",
                    "label": 0
                },
                {
                    "sent": "I'm going to stop here, Arthur.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}