{
    "id": "xbnpne46agehf2uisxlivnpbluksr3nv",
    "title": "Towards feasible PAC-learning probabilistic deterministic finite automata",
    "info": {
        "author": [
            "Ricard Gavalda, Departament de Llenguatges i Sistemes Inform\u00e0tics, Technical University of Catalonia"
        ],
        "published": "Oct. 9, 2008",
        "recorded": "September 2008",
        "category": [
            "Top->Computer Science->Machine Learning->Computational Learning Theory"
        ]
    },
    "url": "http://videolectures.net/icgi08_gavalda_tfpac/",
    "segmentation": [
        [
            "Probabilistic and stochastic methods and the first presentation is towards feasible.",
            "PAC Learning or PDF phase which is being presented by Rico.",
            "Thank you, good morning.",
            "So this is joint work with Jorge Castro at my Department too."
        ],
        [
            "Let me start by just getting the definition of the objects that we're going to be studying, although I don't think you have any doubts on what I'm talking about, so we'll be dealing with learning probabilistic finite automata, so finite number of states on finite alphabet.",
            "The phase as I will call them for short are just non deterministic finite automata where you associate probability distribution on every.",
            "State basically so reality on each transition, plus stopping probability on each state, and I'm specifically going to discuss.",
            "PDF is probabilistic deterministic finite automata, which is same except that we insist on the base machine being deterministic finite automata or equivalently there is one transition only for each state letter pair.",
            "We'll be talking about distributional learning, as I've heard it's called, which means that we look at these machines as computing a probability distribution on string.",
            "So on the set of all strings.",
            "So for, so for every probabilistic finite element, MI will be considering its associated probability distribution, which I will denote the of M."
        ],
        [
            "As you know, there are many, many algorithms to learn PDF.",
            "A most of them, many of them proposed by people in this audience, and they don't expect me to know them all since I'm at MIT, I'm relatively an outsider to the grammatical inference community I was.",
            "We were specifically interested in this algorithm by Alex Clark, and Frank followed the came out about four years ago.",
            "In part because it's an algorithm that probably learns in a framework similar to the well known pack style from guarantee, which is guaranteed to learn from a polynomial size sample of examples from the target, and there have been a number of follow-up papers so that discussed slightly different frameworks.",
            "Basically, extensions of these extensions or improvements or these algorithm by black in color.",
            "And I think in all of them one of the problems is that truly sample size polynomial sample size is guaranteed to be enough for learning.",
            "But this polynomial is just huge on practical values of the parameters, so I know that the authors of the algorithm in part look at it as like a endpoint of a line of research, meaning well, they're having these split merge.",
            "Algorithms it's good to know that at least one of them can be analyzed fully and shown to be.",
            "Regarding probably learns in one rigorous model of learning.",
            "But to me it would be a bit of a pity to let the story finish in this way, in the sense that.",
            "Why shouldn't we renounce from the start at should we?",
            "Not try to see if there are actually algorithms that can be regarded rigorously proven to be correct and at the same time be more or less practical, and that's what we're hoping for, in fact.",
            "I want to avoid these general idea that Pug learning is not practical, which is, you know what you hear sometimes.",
            "Well, there are back logarithms which are like theoretical curiosities that are good for publishing papers, but in practice you want to use something else.",
            "In fact, my own research for awhile has been different problems on different problems.",
            "Trying to see that this is not necessarily the case that you can actually use sound algorithms and make them at least competitive with other methods."
        ],
        [
            "So our contribution in this paper is a variation of the algorithm by Clark and solid for learning these PDF A.",
            "It's really a variation.",
            "There are no major conceptual changes to it, and it's it's a fairly standard algorithm of these state merging and splitting type that keeps the same formal formal guarantees as the Clarks algorithm, so it still learns in the back in this.",
            "Model with respect to the KL Divergent.",
            "In fact, the guarantees are slightly better.",
            "In one sense.",
            "I'll tell you it has the advantage that does not require as input any para meters that are in general unknown when you start with any data set and in several ways it is potentially much more efficient in practice.",
            "Due to a number of technical improvements, one is we use a final notion of notion of what is called the state distinguishability, which is a crucial notion in the Clock forward algorithm.",
            "We have level up to more efficient test to decide when to merge and split states, which in fact it's more efficient, specially cause of these other property that we don't require any input of the user's respect to unknown parameters, and in general we think that this algorithm adapts better to the complexity of the target it does.",
            "Not always ask for the same sample size, but it uses less samples when the input is.",
            "When the target you're going to learn is similar, right?",
            "We have done just a few tests.",
            "I would be ashamed to call this.",
            "An experimental evaluation is far from that, just.",
            "Sanity check to see that what we're doing is not totally hopeless, and still I think that the results are promising, so we have tried a few various model dynamical systems and also a large data set.",
            "That's why."
        ],
        [
            "I'll tell you what what we got.",
            "So let me first define what formal model of learning we're going to use.",
            "This is essentially the model that was used to buy Clock intolerant in their paper, and it probably came from all their papers as well.",
            "So you fix measure D of divergent among probability distributions, and we're going to use the Kullback Leibler KL divergent reissue, which is a popular choice.",
            "We say that an algorithm pack learns, say PDF A with respect to this.",
            "Divergens DE for every target PDF am the algorithm produces a PDF AM prime such that and then you have these two parameter version of success which is common in the park learning, which means that the divergent between the distributions produced by the target machine and the output machine is with high probability.",
            "Absolute high probability probability.",
            "More if you want then one minus epsilon.",
            "Less than epsilon.",
            "Right and in there is an efficiency notion which in principle you would like to be that the time used by this algorithm, hence the sample size used by this algorithm is polynomial in the problem parameters.",
            "Ideally you would like this to be the size of the target machine, like the number of States and something like the inverses of epsilon and Delta.",
            "Unfortunately."
        ],
        [
            "It is suspected that bug learning in this way may be impossible occurrence, and their coauthors showed that, assuming under some assumption that noisy parity problem is complicated infeasible, we're not going to bug learn PDF a in this.",
            "Is St model.",
            "It was later realized that if you consider acyclic PDF A and by considering as part of the complexity of the model, another parameter which is which was called indistinguishability of the target machine, then learning becomes possible.",
            "This distinguishability parameter is essentially a bound on how difficult it is.",
            "How similar two states can be?",
            "I will define it precisely.",
            "Later and.",
            "And this was had been observed before, that this was really the course that summer learning problems where difficult.",
            "What o'clock in Tolar, DDS.",
            "They extended the these possibility of learning to cyclic PDF A by introducing steal another parameter which is the expected length of the string generated by the target.",
            "And they have these theorem that their algorithm probably bug learns in the sense I said before with respect to callback library.",
            "Urgent if in the running time you also include the distinguishability and these expected length of generated strings in the polynomial."
        ],
        [
            "So again, some comments on this Clock and dollar algorithm.",
            "The good part, of course is there is this a company in theory that it learns with sample size that depends as a polynomial on.",
            "I think these are all the parameters, the size of the alphabet and the nodes.",
            "The number of states of the machine.",
            "One over this perimiter Delta in fact its logarithm one over epsilon one over mu where mu is in principle distinguishability of the target and L. And but it has a number of drawbacks.",
            "If you actually want, would like to use it, one is that it works in a bad way.",
            "It requires the full sample upfront before it does any useful work, really.",
            "Hands it always placed itself in the worst case with respect to sample size, even if the target is extremely simple then.",
            "For a given number of states, it will always use ask for the.",
            "Largest sample that is guaranteed to work for all targets of that size.",
            "Anyway, the polynomial is fairly large, is huge, so even for very moderate para meters it requires a sample size like 10 to 2025 easily.",
            "And another problem is that it asks for a number of parameters of the of the target.",
            "So number of states.",
            "This expected length and these distinguish ability.",
            "From the user, right?",
            "Specially the distinguishability is something that is hard to guess in practice, so the user will probably do its best guess.",
            "And if it wants to be on the conservative side, it will.",
            "He will have to probably give an upper bound, so the running time will not be actually be on the number of States and the distinguishability and blah blah blah of the target.",
            "But on the users on the users guess of the target, which is probably an overestimation."
        ],
        [
            "Let me now tell you how we try to go around this.",
            "This Dropbox in a way for this.",
            "Now I have to tell you what this distinguishability is formally.",
            "So, given a machine for each state Q, you associate one probability distributions on the strings by saying let's start from this particular state and that.",
            "Generate from there you generate strings."
        ],
        [
            "Adding to some probability distribution.",
            "So the notion used by cloud controller is called L. Infinity distinguish ability and basically says that.",
            "You say you you say how distinguishable to states Q&Q prime are distinguishable Q&Q prime R by saying let's look at the probabilities, solutions, overall strings and take the maximum.",
            "Alright, how much they differ on any particular string, and you say that the distinguishability of your machine is the minimum over all pairs of states.",
            "So how close any two states in your machine can be?",
            "So our first contribution is slightly different notion of distinguish ability."
        ],
        [
            "Which really has no particular meaning, particular deep meaning other than we can still use it for a test, and it's in general better than.",
            "Then the usual distinguishability, so we call it prefix L Infinity, distinguish ability, and the point is.",
            "Now you tell how different two states are by looking not only on what the weight of any particular string, but on the cone from any particular string, if you want.",
            "Right, and the point is that this can still be relatively well approximated from samples.",
            "If you want.",
            "In fact, what we use is why not take the maximum between the distinguishability, has it had been used before, and the one we are we are using here and?"
        ],
        [
            "'cause we're taking this Max, it is obvious that.",
            "Distinguishability we're using here is always at least as much as the previous one.",
            "So if we in fact our algorithm will use this notion of distinguishability.",
            "Hence, just because of these users, smaller samples, and we have observed in experiment, it really helps a bit using this."
        ],
        [
            "Let me tell you now about the algorithm.",
            "It really uses the same central structure as the cloud controller algorithm.",
            "Essentially we keep.",
            "Graph with what we call safe States and candidate states.",
            "A safe state is labeled by one string taken from your data set, and it really represents the state where the string that string ends in the target, and we try to keep the invariant that the graph formed by save states is isomorphic to a sub graph of the target will really relax a little bit in our in our algorithm, But that's that's the motion we.",
            "Identify parts of the of the target States and transitions, and we.",
            "Represent that in.",
            "In our graph.",
            "Candidate states are really pairs of safe States and letters, so we buy this candidate state.",
            "One letter S or one state S and one letter is what we mean is we don't know where we go yet with these safe state and this letter.",
            "So this is really a placeholder.",
            "And eventually every candidate stage will be either promote or save state.",
            "When we are sure that this is really a new state that we had not seen before, or to will merge with an existing staff safe state when we are reasonably sure that we had already seen this state with another name problem.",
            "So to do this, what we basically keep is a multiset, which we call be by 4 bag, which is intended to be a sample of the distribution generated at this candidate state."
        ],
        [
            "And.",
            "Now let me tell you what is really the difference in looks from the Clock control algorithm and our algorithm, it's it's.",
            "It's really like this, so the original algorithm first reads these parameters as input.",
            "As I had already told you, or I'm missing, even then end here for the number of states.",
            "Yeah, everything works under the assumption that the target is at least this much distinguishable that it has at least sorry that it has no more than N States and that the expected length is no more than L. Write an given these parameters it computes this number M, which is this probably huge polynomial on these parameters, asks for a sample of that size, and then it starts working.",
            "Importantly, it does not only work on this, but it again and again uses the values of these parameters during each word.",
            "Eventually produces a PDF.",
            "I'm not telling you exactly how I will give you some more details on my algorithm."
        ],
        [
            "And now there is an absolute theorem that says back learning or cures given these assumptions."
        ],
        [
            "In contrast, our algorithm works in this way.",
            "It only has input the alphabet size and Delta.",
            "I have to say that in the version in the proceedings, it also reads an epsilon, but by now we have also removed the need for products, so it really.",
            "Only uses really uses these Delta parameter, which is the confidence you want in your result and it reads the sample of what is available.",
            "That is really the case in many applications you have this data set and you have to do your best with that sample.",
            "It works on S. It does not use.",
            "Of course any of the para meters it doesn't know.",
            "And it eventually produces PDF."
        ],
        [
            "So now the theorem looks like assuming the sample is large enough then.",
            "But learning occurs, right?",
            "So there are two points to notice here.",
            "At first it looks like I have just moved the assumption in the algorithm to here, but the point is South does not use the para meters, and that is crucial for efficiency.",
            "And the second point is these parameters on which the running time when the sample size depends are not user guesses but are actually the number of States and distinguish ability and the expected length of the target, not their guesses."
        ],
        [
            "A bit more precisely, our algorithm works as follows.",
            "It won't be surprising to you, since you've seen so many algorithms based on.",
            "Splitting and merging into one again it reads.",
            "Alphabet size Delta available sample.",
            "These basically defines the initial graph.",
            "It puts an initial state label with the empty string and the initial candidates out of each one for each letter and the main look just goes and on and on.",
            "While there are any candidate states left.",
            "For each loop iteration, it processes the whole sample, putting placing strings in this box or strings and after the whole process whole sample has been processed.",
            "It chooses one candidate with the one with the largest bug, and that one is definitely either merged or promoted right.",
            "In contrast, the.",
            "Clock intolerable Algorithm, Tries tries to cut corners.",
            "Here it stops before all candidate states have been processed and some points it merges or promotes states before the whole sample has been.",
            "Has been processor that looks like more efficiency, but in fact to make this decision sounds you have to know something about the distinguish ability and the numbers states right.",
            "Eventually it builds the PDF in a fairly standard way and sets the provision transition probabilities and smoothing out, and this is really like in the original."
        ],
        [
            "Algorithm.",
            "Let me just point out one of the reasons why this way is more efficient than the other one, and it really depends on the criterion for emerging and promoting our criterion is we have chosen one candidate state.",
            "To be.",
            "Dealt with.",
            "We basically run a statistical test trying to distinguish this distribution.",
            "This empirical distribution on the candidate state from the empirical distributions at Safe stage we know.",
            "Essentially, for all of them, if all tests are passed, meaning all test, say this is a different state from the other one, then that candidate that candidate can be promoted.",
            "But if some test failed, the point is that this is similar as given the current sample and it's the all the sample we have.",
            "We cannot distinguish this from some at least existing seems same state, so we just go ahead and identify it."
        ],
        [
            "The idea is these are test independent of mu, and technically I think that's the most important contribution in our paper.",
            "While the Clock solar algorithm does use mu here intensively to do this test.",
            "These tests can be wrong, can be wrong, can take the wrong choice if the sample is too small, right park installer, insist on always make the right decision.",
            "So these sometimes needs huge samples and the point is that this works becauses we process the whole sample before before making any chances."
        ],
        [
            "Very quick comments on the experiments we've made.",
            "We tried a few simple dynamical processes, a couple that we took from a previous paper where we were basically caring about how well you could approximate Hmm's with PDFs.",
            "Let let me go faster with this.",
            "This is just a simple hmm that generates three out of the eight possible strings that of length 3 on.",
            "On 3 letters, and this is a cheese maze where essentially there is a cheese in here, and the states are the places in the maze where you are and you have some information for moving around the previous implementation of the cloud controller algorithm that we described in this paper required like 100,000 examples to just identify the straw."
        ],
        [
            "We also took this other grammar, which I'm sure you've heard about, since it seems to be fairly well known in.",
            "In this community."
        ],
        [
            "So All in all, three Penn State machines with alphabet size two or three.",
            "In our experiments, these took about 200, three, 100, maybe 500 samples to identify the structure, and the point is that the program will run, is 100% a pack algorithm.",
            "We didn't cut any corners.",
            "We didn't do any fancy optimizations.",
            "This is really a piece of Python code with guarantees.",
            "And well.",
            "This is sort of come parable like with other methods that I've seen around compareable meaning up to an order of magnitude rather than 20 orders of magnitude which is not."
        ],
        [
            "Not bad for a start.",
            "We also tried with another data set, fairly large one, which is really the.",
            "Uh.",
            "Reason why in part we became interested.",
            "We're working with an E Commerce website that provided this with these logs from their website and they sell flights and hotels and so on.",
            "So essentially each line of the data set is a user session or record of the clicks they use are made.",
            "There are basically 991 distinct pages and we had a few something over 100,000 sessions with an average length.",
            "Of 12 clicks per session.",
            "And so we decided to look at it as a set of about 100,000 strings of averaging about 12 over a 91 letter alphabet.",
            "This is definitely not generated by probably not even a finite state machine, which is what real people do when visiting webpages, certainly not by a PDF a an."
        ],
        [
            "The point is that our algorithm produced a nontrivial PDF, a out of it with 5060 states.",
            "We're having some expert from the company trying to look at the PDF.",
            "A Intel weather does something meaningful or not, but we haven't got an answer yet.",
            "We did our checks the L1 distance to the data set of the distribution generated by PDF on a new sample we generated of about 100,000 examples.",
            "Is a .44 and the point is that this looks pretty high.",
            "But notice that L1 can be up to 2.5 and that if we generate two samples from our automata and do the same test the the actual distance between them is around .39.",
            "The alphabet is large, which means that the.",
            "Expected variation is large."
        ],
        [
            "So again, not so bad.",
            "Anyway.",
            "That's conclusions.",
            "We have an algorithm that learns PDF A which has strictly rigorous pack guarantees.",
            "In this sense, that well doesn't do that bad as theory predicts for its polynomial in practice.",
            "And again, we think this is cause this algorithm is trying to adapt to the."
        ],
        [
            "Laxity of the actual problem it has in his hands.",
            "There's of course many ways in which this could continue.",
            "We could try to adapt these algorithms to other distances besides L, Infinity and some of the follow up papers to plug in color.",
            "The paper already did that, but we have not tried tried it.",
            "I suspect it's possible to find even better notions of distinguishability, since right now we're taking obviously this Max between two different distances.",
            "I would like to find one that somehow subsumed both and one thing that I think should be investigated.",
            "It's not clear whether it's going to be me doing it.",
            "Is there is paper by any Esposito and hear that learns the full class of PFA there, which I and they don't say.",
            "It's a pack algorithm, although spirit it is really an algorithm.",
            "And well, maybe that.",
            "Could be made practical with some of the ideas that we have.",
            "Set up here.",
            "Thank you very much.",
            "Two questions first, is very quick too.",
            "Sure, the previous slide you mentioned."
        ],
        [
            "Yes, the L1 distance.",
            "Figure, but I thought that the purpose was to look in my perversions so I would expect that you would actually measure with diversion.",
            "So I'm kind of guessing that they might be snoozing issue here.",
            "Alright, we have not really implemented the smoothing issues.",
            "That would be the next point and that's why we don't have the figure so we have not computed divergance.",
            "We should redo it.",
            "Yeah, yeah, I understand, yeah.",
            "The second question is you are basically making a test of distinguishability, but you didn't give much detail here on the test.",
            "I mean, these things are not viewing this regard not completely new.",
            "I mean the original original green can be considered as a way of testing this group distinguishability.",
            "Another algorithm after that, right?",
            "So what is the key feature of your test here?",
            "I don't think it's really that the test uses any new idea, it just wish comparison to the original algorithm, not assuming that we know abound on the distribution ability.",
            "So basically the.",
            "Can we see that with your proof we could consider that alergia satisfy the backline ability?",
            "I don't know the proof of the details of theology, agorism or others.",
            "I mean, there's probably yeah, yeah, actually.",
            "You look at the algorithm or even the test, and it doesn't look like specifically designed.",
            "The design to satisfy any part requirement.",
            "Yeah, actually well the test is in the sense that we use rigorous bounds to be able to prove things we use chernof bounds or so one way just so normal approximation.",
            "But in principle one can use any statistical test to check the two distributions differ in that part.",
            "And and actually, I'm sure that in practice one can do slightly better than our test.",
            "By using it, you know slightly less rigorous.",
            "We have time for one more question.",
            "I'm going to abuse my privilege.",
            "So one of the sort of major one huge inefficiencies in the Clock.",
            "The city algorithm is that you have to re sample after you do every comparison you need to re sample the data because otherwise the merging.",
            "10 chaly induces dependency.",
            "It seems to me that you're not doing that in this, that's right, but how do you then sort of guarantee that the errors you get independent, right?",
            "The the point is that the error the.",
            "Yeah, maybe I should have asked you that, but I really think that you can go around this.",
            "Just done a lot already.",
            "Make increasing the sample right?",
            "So even though the errors are not independent on every every sample, they in the worst case they add up additively and the sample basically depends on the log of that error, so I think it's possible to just increase.",
            "Do this with any logarithmically increasing.",
            "That definitely is in orbit.",
            "I think we have to stop now."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Probabilistic and stochastic methods and the first presentation is towards feasible.",
                    "label": 1
                },
                {
                    "sent": "PAC Learning or PDF phase which is being presented by Rico.",
                    "label": 0
                },
                {
                    "sent": "Thank you, good morning.",
                    "label": 1
                },
                {
                    "sent": "So this is joint work with Jorge Castro at my Department too.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let me start by just getting the definition of the objects that we're going to be studying, although I don't think you have any doubts on what I'm talking about, so we'll be dealing with learning probabilistic finite automata, so finite number of states on finite alphabet.",
                    "label": 0
                },
                {
                    "sent": "The phase as I will call them for short are just non deterministic finite automata where you associate probability distribution on every.",
                    "label": 1
                },
                {
                    "sent": "State basically so reality on each transition, plus stopping probability on each state, and I'm specifically going to discuss.",
                    "label": 0
                },
                {
                    "sent": "PDF is probabilistic deterministic finite automata, which is same except that we insist on the base machine being deterministic finite automata or equivalently there is one transition only for each state letter pair.",
                    "label": 1
                },
                {
                    "sent": "We'll be talking about distributional learning, as I've heard it's called, which means that we look at these machines as computing a probability distribution on string.",
                    "label": 0
                },
                {
                    "sent": "So on the set of all strings.",
                    "label": 0
                },
                {
                    "sent": "So for, so for every probabilistic finite element, MI will be considering its associated probability distribution, which I will denote the of M.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As you know, there are many, many algorithms to learn PDF.",
                    "label": 1
                },
                {
                    "sent": "A most of them, many of them proposed by people in this audience, and they don't expect me to know them all since I'm at MIT, I'm relatively an outsider to the grammatical inference community I was.",
                    "label": 0
                },
                {
                    "sent": "We were specifically interested in this algorithm by Alex Clark, and Frank followed the came out about four years ago.",
                    "label": 0
                },
                {
                    "sent": "In part because it's an algorithm that probably learns in a framework similar to the well known pack style from guarantee, which is guaranteed to learn from a polynomial size sample of examples from the target, and there have been a number of follow-up papers so that discussed slightly different frameworks.",
                    "label": 1
                },
                {
                    "sent": "Basically, extensions of these extensions or improvements or these algorithm by black in color.",
                    "label": 0
                },
                {
                    "sent": "And I think in all of them one of the problems is that truly sample size polynomial sample size is guaranteed to be enough for learning.",
                    "label": 0
                },
                {
                    "sent": "But this polynomial is just huge on practical values of the parameters, so I know that the authors of the algorithm in part look at it as like a endpoint of a line of research, meaning well, they're having these split merge.",
                    "label": 0
                },
                {
                    "sent": "Algorithms it's good to know that at least one of them can be analyzed fully and shown to be.",
                    "label": 0
                },
                {
                    "sent": "Regarding probably learns in one rigorous model of learning.",
                    "label": 0
                },
                {
                    "sent": "But to me it would be a bit of a pity to let the story finish in this way, in the sense that.",
                    "label": 0
                },
                {
                    "sent": "Why shouldn't we renounce from the start at should we?",
                    "label": 0
                },
                {
                    "sent": "Not try to see if there are actually algorithms that can be regarded rigorously proven to be correct and at the same time be more or less practical, and that's what we're hoping for, in fact.",
                    "label": 0
                },
                {
                    "sent": "I want to avoid these general idea that Pug learning is not practical, which is, you know what you hear sometimes.",
                    "label": 0
                },
                {
                    "sent": "Well, there are back logarithms which are like theoretical curiosities that are good for publishing papers, but in practice you want to use something else.",
                    "label": 0
                },
                {
                    "sent": "In fact, my own research for awhile has been different problems on different problems.",
                    "label": 0
                },
                {
                    "sent": "Trying to see that this is not necessarily the case that you can actually use sound algorithms and make them at least competitive with other methods.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So our contribution in this paper is a variation of the algorithm by Clark and solid for learning these PDF A.",
                    "label": 1
                },
                {
                    "sent": "It's really a variation.",
                    "label": 0
                },
                {
                    "sent": "There are no major conceptual changes to it, and it's it's a fairly standard algorithm of these state merging and splitting type that keeps the same formal formal guarantees as the Clarks algorithm, so it still learns in the back in this.",
                    "label": 0
                },
                {
                    "sent": "Model with respect to the KL Divergent.",
                    "label": 0
                },
                {
                    "sent": "In fact, the guarantees are slightly better.",
                    "label": 0
                },
                {
                    "sent": "In one sense.",
                    "label": 1
                },
                {
                    "sent": "I'll tell you it has the advantage that does not require as input any para meters that are in general unknown when you start with any data set and in several ways it is potentially much more efficient in practice.",
                    "label": 0
                },
                {
                    "sent": "Due to a number of technical improvements, one is we use a final notion of notion of what is called the state distinguishability, which is a crucial notion in the Clock forward algorithm.",
                    "label": 0
                },
                {
                    "sent": "We have level up to more efficient test to decide when to merge and split states, which in fact it's more efficient, specially cause of these other property that we don't require any input of the user's respect to unknown parameters, and in general we think that this algorithm adapts better to the complexity of the target it does.",
                    "label": 1
                },
                {
                    "sent": "Not always ask for the same sample size, but it uses less samples when the input is.",
                    "label": 0
                },
                {
                    "sent": "When the target you're going to learn is similar, right?",
                    "label": 0
                },
                {
                    "sent": "We have done just a few tests.",
                    "label": 0
                },
                {
                    "sent": "I would be ashamed to call this.",
                    "label": 0
                },
                {
                    "sent": "An experimental evaluation is far from that, just.",
                    "label": 0
                },
                {
                    "sent": "Sanity check to see that what we're doing is not totally hopeless, and still I think that the results are promising, so we have tried a few various model dynamical systems and also a large data set.",
                    "label": 0
                },
                {
                    "sent": "That's why.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'll tell you what what we got.",
                    "label": 0
                },
                {
                    "sent": "So let me first define what formal model of learning we're going to use.",
                    "label": 0
                },
                {
                    "sent": "This is essentially the model that was used to buy Clock intolerant in their paper, and it probably came from all their papers as well.",
                    "label": 0
                },
                {
                    "sent": "So you fix measure D of divergent among probability distributions, and we're going to use the Kullback Leibler KL divergent reissue, which is a popular choice.",
                    "label": 1
                },
                {
                    "sent": "We say that an algorithm pack learns, say PDF A with respect to this.",
                    "label": 1
                },
                {
                    "sent": "Divergens DE for every target PDF am the algorithm produces a PDF AM prime such that and then you have these two parameter version of success which is common in the park learning, which means that the divergent between the distributions produced by the target machine and the output machine is with high probability.",
                    "label": 1
                },
                {
                    "sent": "Absolute high probability probability.",
                    "label": 0
                },
                {
                    "sent": "More if you want then one minus epsilon.",
                    "label": 0
                },
                {
                    "sent": "Less than epsilon.",
                    "label": 0
                },
                {
                    "sent": "Right and in there is an efficiency notion which in principle you would like to be that the time used by this algorithm, hence the sample size used by this algorithm is polynomial in the problem parameters.",
                    "label": 0
                },
                {
                    "sent": "Ideally you would like this to be the size of the target machine, like the number of States and something like the inverses of epsilon and Delta.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It is suspected that bug learning in this way may be impossible occurrence, and their coauthors showed that, assuming under some assumption that noisy parity problem is complicated infeasible, we're not going to bug learn PDF a in this.",
                    "label": 1
                },
                {
                    "sent": "Is St model.",
                    "label": 0
                },
                {
                    "sent": "It was later realized that if you consider acyclic PDF A and by considering as part of the complexity of the model, another parameter which is which was called indistinguishability of the target machine, then learning becomes possible.",
                    "label": 0
                },
                {
                    "sent": "This distinguishability parameter is essentially a bound on how difficult it is.",
                    "label": 1
                },
                {
                    "sent": "How similar two states can be?",
                    "label": 1
                },
                {
                    "sent": "I will define it precisely.",
                    "label": 0
                },
                {
                    "sent": "Later and.",
                    "label": 0
                },
                {
                    "sent": "And this was had been observed before, that this was really the course that summer learning problems where difficult.",
                    "label": 0
                },
                {
                    "sent": "What o'clock in Tolar, DDS.",
                    "label": 0
                },
                {
                    "sent": "They extended the these possibility of learning to cyclic PDF A by introducing steal another parameter which is the expected length of the string generated by the target.",
                    "label": 0
                },
                {
                    "sent": "And they have these theorem that their algorithm probably bug learns in the sense I said before with respect to callback library.",
                    "label": 1
                },
                {
                    "sent": "Urgent if in the running time you also include the distinguishability and these expected length of generated strings in the polynomial.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So again, some comments on this Clock and dollar algorithm.",
                    "label": 0
                },
                {
                    "sent": "The good part, of course is there is this a company in theory that it learns with sample size that depends as a polynomial on.",
                    "label": 1
                },
                {
                    "sent": "I think these are all the parameters, the size of the alphabet and the nodes.",
                    "label": 0
                },
                {
                    "sent": "The number of states of the machine.",
                    "label": 0
                },
                {
                    "sent": "One over this perimiter Delta in fact its logarithm one over epsilon one over mu where mu is in principle distinguishability of the target and L. And but it has a number of drawbacks.",
                    "label": 0
                },
                {
                    "sent": "If you actually want, would like to use it, one is that it works in a bad way.",
                    "label": 0
                },
                {
                    "sent": "It requires the full sample upfront before it does any useful work, really.",
                    "label": 1
                },
                {
                    "sent": "Hands it always placed itself in the worst case with respect to sample size, even if the target is extremely simple then.",
                    "label": 0
                },
                {
                    "sent": "For a given number of states, it will always use ask for the.",
                    "label": 0
                },
                {
                    "sent": "Largest sample that is guaranteed to work for all targets of that size.",
                    "label": 0
                },
                {
                    "sent": "Anyway, the polynomial is fairly large, is huge, so even for very moderate para meters it requires a sample size like 10 to 2025 easily.",
                    "label": 1
                },
                {
                    "sent": "And another problem is that it asks for a number of parameters of the of the target.",
                    "label": 0
                },
                {
                    "sent": "So number of states.",
                    "label": 0
                },
                {
                    "sent": "This expected length and these distinguish ability.",
                    "label": 0
                },
                {
                    "sent": "From the user, right?",
                    "label": 0
                },
                {
                    "sent": "Specially the distinguishability is something that is hard to guess in practice, so the user will probably do its best guess.",
                    "label": 0
                },
                {
                    "sent": "And if it wants to be on the conservative side, it will.",
                    "label": 0
                },
                {
                    "sent": "He will have to probably give an upper bound, so the running time will not be actually be on the number of States and the distinguishability and blah blah blah of the target.",
                    "label": 0
                },
                {
                    "sent": "But on the users on the users guess of the target, which is probably an overestimation.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let me now tell you how we try to go around this.",
                    "label": 0
                },
                {
                    "sent": "This Dropbox in a way for this.",
                    "label": 0
                },
                {
                    "sent": "Now I have to tell you what this distinguishability is formally.",
                    "label": 0
                },
                {
                    "sent": "So, given a machine for each state Q, you associate one probability distributions on the strings by saying let's start from this particular state and that.",
                    "label": 0
                },
                {
                    "sent": "Generate from there you generate strings.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Adding to some probability distribution.",
                    "label": 0
                },
                {
                    "sent": "So the notion used by cloud controller is called L. Infinity distinguish ability and basically says that.",
                    "label": 0
                },
                {
                    "sent": "You say you you say how distinguishable to states Q&Q prime are distinguishable Q&Q prime R by saying let's look at the probabilities, solutions, overall strings and take the maximum.",
                    "label": 0
                },
                {
                    "sent": "Alright, how much they differ on any particular string, and you say that the distinguishability of your machine is the minimum over all pairs of states.",
                    "label": 0
                },
                {
                    "sent": "So how close any two states in your machine can be?",
                    "label": 0
                },
                {
                    "sent": "So our first contribution is slightly different notion of distinguish ability.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which really has no particular meaning, particular deep meaning other than we can still use it for a test, and it's in general better than.",
                    "label": 0
                },
                {
                    "sent": "Then the usual distinguishability, so we call it prefix L Infinity, distinguish ability, and the point is.",
                    "label": 0
                },
                {
                    "sent": "Now you tell how different two states are by looking not only on what the weight of any particular string, but on the cone from any particular string, if you want.",
                    "label": 0
                },
                {
                    "sent": "Right, and the point is that this can still be relatively well approximated from samples.",
                    "label": 0
                },
                {
                    "sent": "If you want.",
                    "label": 0
                },
                {
                    "sent": "In fact, what we use is why not take the maximum between the distinguishability, has it had been used before, and the one we are we are using here and?",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "'cause we're taking this Max, it is obvious that.",
                    "label": 0
                },
                {
                    "sent": "Distinguishability we're using here is always at least as much as the previous one.",
                    "label": 0
                },
                {
                    "sent": "So if we in fact our algorithm will use this notion of distinguishability.",
                    "label": 0
                },
                {
                    "sent": "Hence, just because of these users, smaller samples, and we have observed in experiment, it really helps a bit using this.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let me tell you now about the algorithm.",
                    "label": 0
                },
                {
                    "sent": "It really uses the same central structure as the cloud controller algorithm.",
                    "label": 0
                },
                {
                    "sent": "Essentially we keep.",
                    "label": 0
                },
                {
                    "sent": "Graph with what we call safe States and candidate states.",
                    "label": 1
                },
                {
                    "sent": "A safe state is labeled by one string taken from your data set, and it really represents the state where the string that string ends in the target, and we try to keep the invariant that the graph formed by save states is isomorphic to a sub graph of the target will really relax a little bit in our in our algorithm, But that's that's the motion we.",
                    "label": 0
                },
                {
                    "sent": "Identify parts of the of the target States and transitions, and we.",
                    "label": 0
                },
                {
                    "sent": "Represent that in.",
                    "label": 0
                },
                {
                    "sent": "In our graph.",
                    "label": 0
                },
                {
                    "sent": "Candidate states are really pairs of safe States and letters, so we buy this candidate state.",
                    "label": 1
                },
                {
                    "sent": "One letter S or one state S and one letter is what we mean is we don't know where we go yet with these safe state and this letter.",
                    "label": 0
                },
                {
                    "sent": "So this is really a placeholder.",
                    "label": 0
                },
                {
                    "sent": "And eventually every candidate stage will be either promote or save state.",
                    "label": 0
                },
                {
                    "sent": "When we are sure that this is really a new state that we had not seen before, or to will merge with an existing staff safe state when we are reasonably sure that we had already seen this state with another name problem.",
                    "label": 0
                },
                {
                    "sent": "So to do this, what we basically keep is a multiset, which we call be by 4 bag, which is intended to be a sample of the distribution generated at this candidate state.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Now let me tell you what is really the difference in looks from the Clock control algorithm and our algorithm, it's it's.",
                    "label": 0
                },
                {
                    "sent": "It's really like this, so the original algorithm first reads these parameters as input.",
                    "label": 0
                },
                {
                    "sent": "As I had already told you, or I'm missing, even then end here for the number of states.",
                    "label": 0
                },
                {
                    "sent": "Yeah, everything works under the assumption that the target is at least this much distinguishable that it has at least sorry that it has no more than N States and that the expected length is no more than L. Write an given these parameters it computes this number M, which is this probably huge polynomial on these parameters, asks for a sample of that size, and then it starts working.",
                    "label": 0
                },
                {
                    "sent": "Importantly, it does not only work on this, but it again and again uses the values of these parameters during each word.",
                    "label": 0
                },
                {
                    "sent": "Eventually produces a PDF.",
                    "label": 0
                },
                {
                    "sent": "I'm not telling you exactly how I will give you some more details on my algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And now there is an absolute theorem that says back learning or cures given these assumptions.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In contrast, our algorithm works in this way.",
                    "label": 1
                },
                {
                    "sent": "It only has input the alphabet size and Delta.",
                    "label": 0
                },
                {
                    "sent": "I have to say that in the version in the proceedings, it also reads an epsilon, but by now we have also removed the need for products, so it really.",
                    "label": 0
                },
                {
                    "sent": "Only uses really uses these Delta parameter, which is the confidence you want in your result and it reads the sample of what is available.",
                    "label": 0
                },
                {
                    "sent": "That is really the case in many applications you have this data set and you have to do your best with that sample.",
                    "label": 1
                },
                {
                    "sent": "It works on S. It does not use.",
                    "label": 0
                },
                {
                    "sent": "Of course any of the para meters it doesn't know.",
                    "label": 0
                },
                {
                    "sent": "And it eventually produces PDF.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now the theorem looks like assuming the sample is large enough then.",
                    "label": 0
                },
                {
                    "sent": "But learning occurs, right?",
                    "label": 0
                },
                {
                    "sent": "So there are two points to notice here.",
                    "label": 0
                },
                {
                    "sent": "At first it looks like I have just moved the assumption in the algorithm to here, but the point is South does not use the para meters, and that is crucial for efficiency.",
                    "label": 0
                },
                {
                    "sent": "And the second point is these parameters on which the running time when the sample size depends are not user guesses but are actually the number of States and distinguish ability and the expected length of the target, not their guesses.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A bit more precisely, our algorithm works as follows.",
                    "label": 1
                },
                {
                    "sent": "It won't be surprising to you, since you've seen so many algorithms based on.",
                    "label": 0
                },
                {
                    "sent": "Splitting and merging into one again it reads.",
                    "label": 1
                },
                {
                    "sent": "Alphabet size Delta available sample.",
                    "label": 0
                },
                {
                    "sent": "These basically defines the initial graph.",
                    "label": 1
                },
                {
                    "sent": "It puts an initial state label with the empty string and the initial candidates out of each one for each letter and the main look just goes and on and on.",
                    "label": 0
                },
                {
                    "sent": "While there are any candidate states left.",
                    "label": 1
                },
                {
                    "sent": "For each loop iteration, it processes the whole sample, putting placing strings in this box or strings and after the whole process whole sample has been processed.",
                    "label": 0
                },
                {
                    "sent": "It chooses one candidate with the one with the largest bug, and that one is definitely either merged or promoted right.",
                    "label": 0
                },
                {
                    "sent": "In contrast, the.",
                    "label": 0
                },
                {
                    "sent": "Clock intolerable Algorithm, Tries tries to cut corners.",
                    "label": 1
                },
                {
                    "sent": "Here it stops before all candidate states have been processed and some points it merges or promotes states before the whole sample has been.",
                    "label": 0
                },
                {
                    "sent": "Has been processor that looks like more efficiency, but in fact to make this decision sounds you have to know something about the distinguish ability and the numbers states right.",
                    "label": 0
                },
                {
                    "sent": "Eventually it builds the PDF in a fairly standard way and sets the provision transition probabilities and smoothing out, and this is really like in the original.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Algorithm.",
                    "label": 0
                },
                {
                    "sent": "Let me just point out one of the reasons why this way is more efficient than the other one, and it really depends on the criterion for emerging and promoting our criterion is we have chosen one candidate state.",
                    "label": 1
                },
                {
                    "sent": "To be.",
                    "label": 0
                },
                {
                    "sent": "Dealt with.",
                    "label": 1
                },
                {
                    "sent": "We basically run a statistical test trying to distinguish this distribution.",
                    "label": 0
                },
                {
                    "sent": "This empirical distribution on the candidate state from the empirical distributions at Safe stage we know.",
                    "label": 0
                },
                {
                    "sent": "Essentially, for all of them, if all tests are passed, meaning all test, say this is a different state from the other one, then that candidate that candidate can be promoted.",
                    "label": 1
                },
                {
                    "sent": "But if some test failed, the point is that this is similar as given the current sample and it's the all the sample we have.",
                    "label": 1
                },
                {
                    "sent": "We cannot distinguish this from some at least existing seems same state, so we just go ahead and identify it.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The idea is these are test independent of mu, and technically I think that's the most important contribution in our paper.",
                    "label": 1
                },
                {
                    "sent": "While the Clock solar algorithm does use mu here intensively to do this test.",
                    "label": 0
                },
                {
                    "sent": "These tests can be wrong, can be wrong, can take the wrong choice if the sample is too small, right park installer, insist on always make the right decision.",
                    "label": 1
                },
                {
                    "sent": "So these sometimes needs huge samples and the point is that this works becauses we process the whole sample before before making any chances.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Very quick comments on the experiments we've made.",
                    "label": 0
                },
                {
                    "sent": "We tried a few simple dynamical processes, a couple that we took from a previous paper where we were basically caring about how well you could approximate Hmm's with PDFs.",
                    "label": 1
                },
                {
                    "sent": "Let let me go faster with this.",
                    "label": 0
                },
                {
                    "sent": "This is just a simple hmm that generates three out of the eight possible strings that of length 3 on.",
                    "label": 1
                },
                {
                    "sent": "On 3 letters, and this is a cheese maze where essentially there is a cheese in here, and the states are the places in the maze where you are and you have some information for moving around the previous implementation of the cloud controller algorithm that we described in this paper required like 100,000 examples to just identify the straw.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We also took this other grammar, which I'm sure you've heard about, since it seems to be fairly well known in.",
                    "label": 0
                },
                {
                    "sent": "In this community.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So All in all, three Penn State machines with alphabet size two or three.",
                    "label": 0
                },
                {
                    "sent": "In our experiments, these took about 200, three, 100, maybe 500 samples to identify the structure, and the point is that the program will run, is 100% a pack algorithm.",
                    "label": 0
                },
                {
                    "sent": "We didn't cut any corners.",
                    "label": 0
                },
                {
                    "sent": "We didn't do any fancy optimizations.",
                    "label": 0
                },
                {
                    "sent": "This is really a piece of Python code with guarantees.",
                    "label": 0
                },
                {
                    "sent": "And well.",
                    "label": 0
                },
                {
                    "sent": "This is sort of come parable like with other methods that I've seen around compareable meaning up to an order of magnitude rather than 20 orders of magnitude which is not.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Not bad for a start.",
                    "label": 0
                },
                {
                    "sent": "We also tried with another data set, fairly large one, which is really the.",
                    "label": 0
                },
                {
                    "sent": "Uh.",
                    "label": 0
                },
                {
                    "sent": "Reason why in part we became interested.",
                    "label": 0
                },
                {
                    "sent": "We're working with an E Commerce website that provided this with these logs from their website and they sell flights and hotels and so on.",
                    "label": 0
                },
                {
                    "sent": "So essentially each line of the data set is a user session or record of the clicks they use are made.",
                    "label": 0
                },
                {
                    "sent": "There are basically 991 distinct pages and we had a few something over 100,000 sessions with an average length.",
                    "label": 1
                },
                {
                    "sent": "Of 12 clicks per session.",
                    "label": 0
                },
                {
                    "sent": "And so we decided to look at it as a set of about 100,000 strings of averaging about 12 over a 91 letter alphabet.",
                    "label": 0
                },
                {
                    "sent": "This is definitely not generated by probably not even a finite state machine, which is what real people do when visiting webpages, certainly not by a PDF a an.",
                    "label": 1
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The point is that our algorithm produced a nontrivial PDF, a out of it with 5060 states.",
                    "label": 1
                },
                {
                    "sent": "We're having some expert from the company trying to look at the PDF.",
                    "label": 0
                },
                {
                    "sent": "A Intel weather does something meaningful or not, but we haven't got an answer yet.",
                    "label": 0
                },
                {
                    "sent": "We did our checks the L1 distance to the data set of the distribution generated by PDF on a new sample we generated of about 100,000 examples.",
                    "label": 1
                },
                {
                    "sent": "Is a .44 and the point is that this looks pretty high.",
                    "label": 0
                },
                {
                    "sent": "But notice that L1 can be up to 2.5 and that if we generate two samples from our automata and do the same test the the actual distance between them is around .39.",
                    "label": 0
                },
                {
                    "sent": "The alphabet is large, which means that the.",
                    "label": 0
                },
                {
                    "sent": "Expected variation is large.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So again, not so bad.",
                    "label": 0
                },
                {
                    "sent": "Anyway.",
                    "label": 0
                },
                {
                    "sent": "That's conclusions.",
                    "label": 0
                },
                {
                    "sent": "We have an algorithm that learns PDF A which has strictly rigorous pack guarantees.",
                    "label": 0
                },
                {
                    "sent": "In this sense, that well doesn't do that bad as theory predicts for its polynomial in practice.",
                    "label": 0
                },
                {
                    "sent": "And again, we think this is cause this algorithm is trying to adapt to the.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Laxity of the actual problem it has in his hands.",
                    "label": 0
                },
                {
                    "sent": "There's of course many ways in which this could continue.",
                    "label": 0
                },
                {
                    "sent": "We could try to adapt these algorithms to other distances besides L, Infinity and some of the follow up papers to plug in color.",
                    "label": 0
                },
                {
                    "sent": "The paper already did that, but we have not tried tried it.",
                    "label": 0
                },
                {
                    "sent": "I suspect it's possible to find even better notions of distinguishability, since right now we're taking obviously this Max between two different distances.",
                    "label": 1
                },
                {
                    "sent": "I would like to find one that somehow subsumed both and one thing that I think should be investigated.",
                    "label": 0
                },
                {
                    "sent": "It's not clear whether it's going to be me doing it.",
                    "label": 1
                },
                {
                    "sent": "Is there is paper by any Esposito and hear that learns the full class of PFA there, which I and they don't say.",
                    "label": 0
                },
                {
                    "sent": "It's a pack algorithm, although spirit it is really an algorithm.",
                    "label": 0
                },
                {
                    "sent": "And well, maybe that.",
                    "label": 0
                },
                {
                    "sent": "Could be made practical with some of the ideas that we have.",
                    "label": 0
                },
                {
                    "sent": "Set up here.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                },
                {
                    "sent": "Two questions first, is very quick too.",
                    "label": 0
                },
                {
                    "sent": "Sure, the previous slide you mentioned.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yes, the L1 distance.",
                    "label": 0
                },
                {
                    "sent": "Figure, but I thought that the purpose was to look in my perversions so I would expect that you would actually measure with diversion.",
                    "label": 0
                },
                {
                    "sent": "So I'm kind of guessing that they might be snoozing issue here.",
                    "label": 0
                },
                {
                    "sent": "Alright, we have not really implemented the smoothing issues.",
                    "label": 0
                },
                {
                    "sent": "That would be the next point and that's why we don't have the figure so we have not computed divergance.",
                    "label": 0
                },
                {
                    "sent": "We should redo it.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah, I understand, yeah.",
                    "label": 0
                },
                {
                    "sent": "The second question is you are basically making a test of distinguishability, but you didn't give much detail here on the test.",
                    "label": 0
                },
                {
                    "sent": "I mean, these things are not viewing this regard not completely new.",
                    "label": 0
                },
                {
                    "sent": "I mean the original original green can be considered as a way of testing this group distinguishability.",
                    "label": 0
                },
                {
                    "sent": "Another algorithm after that, right?",
                    "label": 0
                },
                {
                    "sent": "So what is the key feature of your test here?",
                    "label": 0
                },
                {
                    "sent": "I don't think it's really that the test uses any new idea, it just wish comparison to the original algorithm, not assuming that we know abound on the distribution ability.",
                    "label": 0
                },
                {
                    "sent": "So basically the.",
                    "label": 0
                },
                {
                    "sent": "Can we see that with your proof we could consider that alergia satisfy the backline ability?",
                    "label": 0
                },
                {
                    "sent": "I don't know the proof of the details of theology, agorism or others.",
                    "label": 0
                },
                {
                    "sent": "I mean, there's probably yeah, yeah, actually.",
                    "label": 0
                },
                {
                    "sent": "You look at the algorithm or even the test, and it doesn't look like specifically designed.",
                    "label": 0
                },
                {
                    "sent": "The design to satisfy any part requirement.",
                    "label": 0
                },
                {
                    "sent": "Yeah, actually well the test is in the sense that we use rigorous bounds to be able to prove things we use chernof bounds or so one way just so normal approximation.",
                    "label": 0
                },
                {
                    "sent": "But in principle one can use any statistical test to check the two distributions differ in that part.",
                    "label": 0
                },
                {
                    "sent": "And and actually, I'm sure that in practice one can do slightly better than our test.",
                    "label": 0
                },
                {
                    "sent": "By using it, you know slightly less rigorous.",
                    "label": 0
                },
                {
                    "sent": "We have time for one more question.",
                    "label": 0
                },
                {
                    "sent": "I'm going to abuse my privilege.",
                    "label": 0
                },
                {
                    "sent": "So one of the sort of major one huge inefficiencies in the Clock.",
                    "label": 0
                },
                {
                    "sent": "The city algorithm is that you have to re sample after you do every comparison you need to re sample the data because otherwise the merging.",
                    "label": 0
                },
                {
                    "sent": "10 chaly induces dependency.",
                    "label": 0
                },
                {
                    "sent": "It seems to me that you're not doing that in this, that's right, but how do you then sort of guarantee that the errors you get independent, right?",
                    "label": 0
                },
                {
                    "sent": "The the point is that the error the.",
                    "label": 0
                },
                {
                    "sent": "Yeah, maybe I should have asked you that, but I really think that you can go around this.",
                    "label": 0
                },
                {
                    "sent": "Just done a lot already.",
                    "label": 0
                },
                {
                    "sent": "Make increasing the sample right?",
                    "label": 0
                },
                {
                    "sent": "So even though the errors are not independent on every every sample, they in the worst case they add up additively and the sample basically depends on the log of that error, so I think it's possible to just increase.",
                    "label": 0
                },
                {
                    "sent": "Do this with any logarithmically increasing.",
                    "label": 0
                },
                {
                    "sent": "That definitely is in orbit.",
                    "label": 0
                },
                {
                    "sent": "I think we have to stop now.",
                    "label": 0
                }
            ]
        }
    }
}