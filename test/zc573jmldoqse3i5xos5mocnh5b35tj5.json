{
    "id": "zc573jmldoqse3i5xos5mocnh5b35tj5",
    "title": "Generative Models I",
    "info": {
        "author": [
            "Ian Goodfellow, Google, Inc."
        ],
        "published": "July 27, 2017",
        "recorded": "June 2017",
        "category": [
            "Top->Computer Science->Machine Learning->Deep Learning",
            "Top->Computer Science->Machine Learning->Reinforcement Learning",
            "Top->Computer Science->Machine Learning->Unsupervised Learning"
        ]
    },
    "url": "http://videolectures.net/deeplearning2017_goodfellow_generative_models/",
    "segmentation": [
        [
            "I'll cover the first lesson on generative models.",
            "Erin will cover the second one later in the school.",
            "There will also be a few more lessons that are related to generative models."
        ],
        [
            "The basic idea of generative models is that we want to do density estimation.",
            "We want to take a bunch of training data and we want to fit a probability density function to that data.",
            "So in this example I have a bunch of points on the real number line and I've fitted Gaussian distribution to that collection of points and on the right I show you what that density function looks like.",
            "A lot of the time we do these estimation processes explicitly.",
            "We actually write down a density function and we adapt the parameters of that density function to match the data.",
            "You can also do what are called implicit models."
        ],
        [
            "Where you are able to generate samples from the data set.",
            "So here I show a bunch of training examples on the left from the image net data set and on the right I show what we would like to happen.",
            "We'd like to be able to generate more samples that come from that same distribution.",
            "We don't actually have a model that can do this yet at Yahoo is looking really shocked in the front row audience 'cause he thought this is the state of the art from Google Brain.",
            "But this is an idealization using test data.",
            "So this is the goal.",
            "This is.",
            "This is what all of you in the audience here to learn about generative modeling.",
            "If you decide this is what you want to study in the course of your deep learning career, this is what you're shooting for doing.",
            "If you're working on generative models."
        ],
        [
            "The main principle that people use for fitting generative models is maximum likelihood.",
            "The basic idea is you write down some density function that I'm going to call P_model and this density function tells you how likely a particular input point X is.",
            "So X is just a vector that we use to describe different kinds of data.",
            "It can be an image, it can be an audio waveform, it can be a sentence, it can be a sequence of words, and then we also have a set of parameters Theta.",
            "Where those can be many different things, they can be a collection of tensors that you used for convolution.",
            "They can be matrices that you use for a fully connected layer.",
            "We're going to summarize all of them with just a vector of data and the basic idea behind maximum likelihood is we write down the likelihood that the model assigns to the data and we adapt Theta to make that likelihood become as high as possible.",
            "In practice, there are many different ways of doing generative modeling.",
            "A lot of them maximize functions other than the likelihood.",
            "I'm going to show you how all of the different generative model families can approximate maximum likelihood.",
            "Not all of them are used to approximate maximum likelihood by default.",
            "Some of them approximate maximization of other functions, but if we look at all of them through the lens of maximum likelihood, it will be easier to see the similarities and differences in the approximations they make rather than in the cost functions that they optimize.",
            "But just keep that in the back of your mind that a lot of them actually use different cost functions in this."
        ],
        [
            "If we pretend that all of these different generative models use maximum likelihood, then we can build a taxonomy that basically looks at whether they use an explicit density function or an implicit density function, and what kinds of approximations they need to use there.",
            "Also, generative models that don't even really fit in this tree.",
            "So we're looking at the subtree."
        ],
        [
            "It starts with all the different generative models that can be coerced into doing maximum likelihood in one way or another.",
            "On the left branch of the tree we look at models that actually have an explicit density function.",
            "They actually have a P model of X given Theta that you can write down and maximize.",
            "So what are the challenges involved in building an explicit density model?",
            "The main challenge is that it can be really difficult to design AP model of X that is computationally tractable and is still actually flexible enough to capture the data distribution.",
            "There are a lot of probability distributions that are very easy to write down and very easy to work with computationally, like if you have a Gaussian distribution with diagonal covariance.",
            "That's very easy to write down, and it's very easy to do all the computations you need to manipulate it.",
            "Yeah, sure, so this morning I explained RNN switch our particular case.",
            "Yeah, so our names are an example of an explicit density function that's straightforward to work with.",
            "One of the challenges with scaling these explicit density functions to larger problems like generating image net images is that a lot of the probability density functions right down on these images are not necessarily all that straightforward to evaluate."
        ],
        [
            "So one category of explicit density models is to just carefully design the model to make sure it's tractable, like the RNS that yahshua covered this morning."
        ],
        [
            "In general, you don't need to be modeling a sequence like you usually do with an RNN.",
            "You can actually regard any vector valued piece of data as being a sequence, so you have some vector X with elements X one through XN.",
            "You can regard that vector as being a sequence, even though the different members of the vector come from different conditional distributions, and then you can use the chain rule of probability to expand the probability distribution over X into a sequence of multiplications of different probabilities.",
            "So you have P model of X 1 * P model of X2 given X one and so on until you have P model of XN.",
            "Given all of X1 through X N -- 1.",
            "The first time this was done, it was called fully visible belief Nets by Brendan Frey and his collaborators, and basically each of these conditional distributions was something like a logistic regression model, but you can really fill in any kind of model that you want, and this chain rule will still make sure that you're able to get a tractable model over the whole vector."
        ],
        [
            "The main disadvantage of this family is that if you want to generate a sample, you have to explicitly sample every member of the vector in sequence.",
            "You have to sample X one and then sample X2 given X one and then sample X3 given X1 and X2 and so on, and those computations can't be paralyzed because the value that you get for X3 is actually a function of the value get for X1 and X2.",
            "You can't just spin up N different CPUs that each generates 1 sample on its own.",
            "We'll also see that a lot of our different generative models have a latent code that tells us something about what sample it will generate, or it tells us something about the semantics of the input.",
            "These models usually don't come with a latent code that describes the entire image or the entire vector.",
            "They'll describe the state of the generation machine after each entry that they process, but it takes some special models like variational autoencoders with pixel CNN decoders if you want to get this kind of.",
            "Latent code control of an autoregressive model.",
            "So in."
        ],
        [
            "The more recent years after Brendan Fraser original work on the chain rule for building generative models, the modern version of these are mostly called autoregressive models.",
            "There's a model called made for neural autoregressive density estimation and then later made where the end now stands for masked rather than neural.",
            "Both of these are essentially using neural Nets to define these distributions.",
            "XI given X preceding I.",
            "There's also been a line of work coming from deep mind that calls these pixels CNN's or Pixel RNN's or for audio, it's called Wavenet.",
            "All of these work on the same basic principle of designing a model that has an explicit tractable density function.",
            "By generating a vector, one entry at a time."
        ],
        [
            "There's another kind of tractable density model that uses a very different principle to set up the way of making the probability distribution tractable, and that's to use a change of variables formula.",
            "So if you have some random variable Y and you have some differentiable invertible function G, that will take you from a random variable X to Y, you can actually transform the probability distribution over X into a probability distribution over why by looking at the determinant of the Jacobian.",
            "Of G. You can use this either to map from an observation X into a latent space and then have a nice probability distribution over the latent space, or because G is invertible, you can actually do the opposite.",
            "You can start out with a nice probability distribution over a latent variable and then map it back to the input space.",
            "The main disadvantage of this approach is that it can be difficult to design A transformation that's invertible, and in particular when you have to design A transformation that's invertible, you need to have the same number of latent variables as visible variables, because you need to make.",
            "An invertible transformation between those two spaces.",
            "In practice, we've seen that this is able to make decent samples in the image.",
            "Here I show you what happens when you run a version of this strategy called Real MVP on 64 by 64 image Net.",
            "This basic strategy of using nonlinear ICA I just any kind of model where you have a nonlinear G function and then an independent distribution of the latent variables that dates back to the work of APO hyvarinen in the 1990s, and I think maybe even back to the 1980s.",
            "But I'm not nearly as familiar with the ICA literatures in your thesis.",
            "OK, yeah.",
            "And."
        ],
        [
            "That basically concludes my description of the tractable density models.",
            "One comment is that I've focused on the deep tractable density models, things that can actually scale to generating images.",
            "There's obviously a lot of very simple distributions that are tractable but can't scale in that way.",
            "So we're still looking at the subtree of generative models that focuses on explicit density functions, where you can actually write down P submodel of X given Theta."
        ],
        [
            "But now we're moving to the branch where we give up on making piece of model of X given Theta be computationally tractable, we're going to start using very expensive piece of model given X in order to have fewer constraints on the design of the generative model.",
            "But we need to now use approximations to evaluate these intractable computations.",
            "So probably the most popular version of an approximate density model today is the variational auto income."
        ],
        [
            "The basic idea behind variational learning in general is you have a set of latent variables that will call Z and these are variables that more or less explain what's going to be in the input.",
            "You might have a variable that says whether a picture of a person is smiling or not, or another variable that might say whether or not they're wearing glasses, or if you're generating a sentence, you might have a variable that says which topic you are going to be discussing, and another variable that says whether you're going to write.",
            "This sentence, with more of an informal style or more of a journalistic style.",
            "Altogether, these different variables can be combined in a vector that will just call Z, and we define a probability distribution.",
            "Giving us a distribution over X in terms of what the Z variables are asking us to generate, so we have both some distribution P of Z and some distribution P of X given Z.",
            "If we want to do maximum likelihood learning, we need to get piece of model of X, though we actually don't want there to be a Z value in the expression because we need to maximize P model of X for every data point in the data set.",
            "We have to do then is actually taken integral.",
            "To marginalized Z out of the probability distribution, and then we maximize the resulting log probability over just X.",
            "Unfortunately, this integral is very computationally difficult to evaluate.",
            "There's usually not a closed form solution to it, and usually have to have some kind of Monte Carlo method for approximating it, and those methods often don't scale very well.",
            "So what variational models do instead is they say rather than trying to maximize literally P model of X, we're going to come up with a."
        ],
        [
            "Lower bound and P model of X.",
            "So we're going to come up with some value that is always less than P model of X and maximize that bound instead.",
            "The idea is if you maximize the bound and you get a number that you're happy with for the bound, you know that you're going to get an even better number for P model of X.",
            "You're not necessarily going to find the maximum possible value of P model of X, but you'll find a value that's pretty good.",
            "So the idea behind the variational bound is we introduce a new distribution over the latent variables that we're going to call queue of Z, and it turns out that the variational bound could be written as the log probability of X minus the KL divergent between our new distribution QZ and the true posterior distribution P of Z given X.",
            "So to maximize this bound, we want to make you of Z look more and more like the true distribution P of Z given X, the KL divergent measures how different different those two distributions are, and it goes to 0.",
            "If you can make them be identical.",
            "Basically, this means we want to try to find a way of pushing Q to be as close to zero as possible.",
            "In the past, people used to do this using an optimization algorithm directly on the parameters of Q itself.",
            "The really key insight for variational autoencoders."
        ],
        [
            "Is that you can actually define a neural network that predicts the parameters of Q, so you can actually think of the neural network is being like an optimization algorithm where instead of explicitly taking several steps to solve for the Q that will match P of Z given X as closely as possible, the neural net predicts the value of Q.",
            "That will solve the optimization problem.",
            "This means you can go."
        ],
        [
            "And actually just plug in the neural net for the definition of Q in this equation and you can actually just start maximizing the whole equation.",
            "You learn the parameters of P of X given Z, the parameters of P of Z, and the parameters for the predictor Q of Z, all at the same time, so it's."
        ],
        [
            "Very clean and elegant solution, but makes it possible to do variational learning without all of the complicated optimization alternating between optimizing queue and optimizing the model that we used to do.",
            "And the right I showed some samples from the cifar 10 data set that were generated from a state of the art variational autoencoder in 2016.",
            "And there will be an A."
        ],
        [
            "Your lesson about variational inference from Max Welling.",
            "Who's the leader of one of the labs where variational autoencoders first emerged, so he'll be able to tell you a lot more about this subject.",
            "I'm just giving you the teaser so that you have some context for how the tree fits together."
        ],
        [
            "So that's the main branch that's popular today in the sub branch of approximate density models.",
            "There's another branch under the approximate density models that is not very popular today, but was very popular during the time that I did my PhD.",
            "The current wave of popularity of deep learning began when deep belief networks were shown to outperform support vector machines back in 2006 on the endless data set and deep belief networks were based on a generative model called.",
            "Wholesome machines that could be stacked to form a deep model."
        ],
        [
            "The basic idea of Boltzmann machines is that they define a Markov chain where you can draw samples from the model by updating previous samples.",
            "So every time you stochastically update a sample, it moves toward a different fair sample from the same distribution defined by the model.",
            "You can use this to use samples from the model to approximately compute the gradients of the probability of the model even though the probability density function itself is intractable.",
            "Unfortunately, the Markov chains that we use for these Monte Carlo estimates don't seem to scale to high dimensional spaces very well.",
            "People have not yet been able to train Boltzmann machines on very large datasets like images of cifar 10 samples or image net samples, for example.",
            "And so they."
        ],
        [
            "I've been as popular for the past few years.",
            "And now we're moving to the last branch of the taxonomy of generative models that will show today.",
            "And this is the branch of implicit density models.",
            "So an implicit density model is a model where we actually can't write down very easily P density or P model of X.",
            "Instead we make a generative machine that generates samples from that distribution and being able to generate those samples is the only way that we actually interact with that representation of the distribution that we're learning.",
            "So the first branch on here is where we make a generative machine based on a Markov chain.",
            "It generates samples iteratively, where it will generate 1 sample and then stochastically update it to refine it."
        ],
        [
            "And after several steps you will get a different independent sample.",
            "So the main example of this part of the branch is generative stochastic networks that yahshua invented in 2013.",
            "The basic idea is shown here is that in each row we can see a sample evolving overtime as it stochastically updated in the first row.",
            "We see how we start with an S 9 and it gradually evolves into an M just four as we repeatedly sample it.",
            "So Markov chains are an effective way to get samples from the distribution, but we may also sometimes want to get a fair sample in a single shot.",
            "That's basically the problem that I was trying to solve when I came up with generative."
        ],
        [
            "Social networks the idea of general networks is that they are a generative model that creates data directly in a single step."
        ],
        [
            "And the way that they do that is they have a generator function G which is just a differentiable function mapping from latent variable Z to X.",
            "You'll recognize that this function G is basically the same thing as we have for the decoder of a variational autoencoder.",
            "It's also basically the same thing as we have in the generator.",
            "Net for a nonlinear ICA model, the main difference in the G function for variational autoencoders and for against from nonlinear ICA is that there's no constraint that Z has to have the same number of entries as X.",
            "So we require that G be differentiable, but we don't require that it be invertible.",
            "Now basically it works is we start out with some input noisy.",
            "We run it through the differentiable function G and we get a value of X that sampled from the model like the face that I show in the right and I've tried to show kind of a low quality image of a face that I just messed up a little bit in photo shop to illustrate conceptually the idea that the generator is not going to be perfect.",
            "And then there's another model that actually plays a game against the generator net called the discriminator, that we represent with a function D. So D will look at the image that came from the generator and try to output a value near 0.",
            "This value indicates the probability that the input is real rather than fake, so when the discriminator looks at fake samples coming from the generator, it tries to say that they have very low probability of being real.",
            "Simultaneously, the generator tries to fool the discriminator into out putting a value near 1 so the generator tries to fool it into saying that its samples are real rather than fake.",
            "We also train the discriminator on real data as shown on the left of this slide, where we load this actual photo of a face, and we trained the discriminator to say that it's real rather than fake.",
            "You can analyze this with game theory and find that there is a situation called a Nash equilibrium where neither player can improve without having to modify the other players strategy.",
            "And that Nash equilibrium corresponds to the generator recovering the training distribution."
        ],
        [
            "There's also a few different ways of making hybrids of different generative models, so one of them is you can actually combine veessen guns instead of using the Gan to generate the data you use the gun to represent that Q distribution that you need for the variational autoencoder.",
            "So usually when you make you distribution for variational autoencoder you use something like a Gaussian distribution and the problem is that Gaussian distribution is not very expressive.",
            "On this slide I show you a few different posterior distributions.",
            "The bottom row shows you the true posterior.",
            "Two different cross sections of it.",
            "The middle row shows you what happens when you use a Gaussian to approximate the posterior, and essentially you see that it has to pick one of the modes in each of the panels and zoom in on that mode, but discard the other one on the top row.",
            "If you use again as a generator to sample from the posterior, you can actually recover.",
            "Multiple modes because you now have this more complicated probabilistic model.",
            "Generating the output data so it's worth mentioning.",
            "I've shown you hear a figure from the most recent paper on this topic from Microsoft Research.",
            "This is called adversarial variational Bayes, but it's building on top of several models that came earlier, including adversarial autoencoders.",
            "Adversarially learned inference, and bygones.",
            "Basically, those earlier models had less variability in the output that the gun could learn, like they might restrict it to a single mode of output.",
            "It's also worth mentioning that if you want to make a variational autoencoder with a complicated posterior, you can also do that without guns.",
            "You can do that, for example with inverse autoregressive flow.",
            "That's actually the model that I showed earlier on the slide for variational autoencoders."
        ],
        [
            "So now that I've shown you more or less the family tree of how the different popular versions of deep generative models work, I'll tell you a little bit about the different things that you can do with generative models.",
            "And I guess you're all students starting out your career in deep learning research, so I'd like you to think a little bit about where you see opportunities to dive in while we're going through this talk.",
            "So you've seen now the tree of different models and some of the advantages and disadvantages of each of them.",
            "You might start to think of ways that you could add a new branch to that tree that escape some of the disadvantages of the models we've seen already.",
            "But in the second part of the talk, rather than thinking about how you might improve generative models.",
            "You can see some of the ways that generative models have been used in the past, and you might think about new applications that you can solve with them.",
            "So one thing that you can do with generative models is you can create simulated environments and training data."
        ],
        [
            "A lot of the time, we don't necessarily know why we'd want a generative model.",
            "Being able to create pictures is not always useful in and of itself, and a lot of the time we think it's much more useful to have something like a classifier or regression model that makes a prediction for us.",
            "Well, it turns out that generative models can actually help you, even if all you care about is classification.",
            "We've seen that it's possible to use generative models to create training data that can then go and train these models, so Apple's first ever research paper was about using a generative model to make training data for.",
            "I gaze direction predictor.",
            "They want to have a phone that can look at your face and use the camera to see your eyes and then tell which direction are your eyes pointing.",
            "The problem is they don't have a large training set of lots of people with their eyes looking in a specific known point on the screen."
        ],
        [
            "What they can do instead is they can use a 3D rendered model like I show in the lower left of this slide to make a synthetic rendering of an eyeball that's looking at a particular point on an imaginary screen, and so now they've got really good ground truth mapping from images of eyes to known eyeball directions.",
            "Unfortunately, these synthetic images are not very realistic looking, so they can take a generative model that's trained on real photos, and they can use that generative model to create what they call a refiner.",
            "Where they take the synthetic images and they improve their realism to get an image that looks realistic and also has a known gaze direction that can actually be used to train the gaze direction predictor."
        ],
        [
            "Another thing that you can do with generative models is you can handle missing data.",
            "Usually when we have classifiers 30 find in terms of taking a whole vector X as input and then giving you an output value Y but in a lot of real world applications you don't always get the whole vector X and your goal may not be to predict why your goal might be to predict different entries of X given other entries of X.",
            "This happens a lot, especially for medical data where there might be many different tests you could imagine running on a patient.",
            "Like you could imagine, doing a lumbar puncture where you pull out some of their cerebral spinal fluid.",
            "You can imagine doing like a biopsy on a tumor that they have and all these things are not only expensive but also painful.",
            "Even if you had infinite money, you wouldn't want to pay for all these things because they can harm the patient and cause suffering.",
            "So we would like to build machine learning models that can work if you give it only one of these tests.",
            "If you say, oh, here's the biopsy, but we didn't do the lumbar puncture."
        ],
        [
            "Because generative models define a probability distribution over the entire vector that you're studying, they can be used to solve all kinds of different inference problems related to different values that are missing from the vector that you're interested in.",
            "So does anybody have a guess of what this image is?",
            "If we could fill in the missing black pixels?",
            "Yes, it's a face, but is it a male or female?",
            "Yeah, so your brain can do this, but a standard classifier can't."
        ],
        [
            "Here's what a generative model gives us, so we actually fill in the male face just like you see with your your advanced neocortex."
        ],
        [
            "But there's an especially important branch of the missing data problem, which is semi supervised learning where you're trying to train a classifier, but a lot of your output labels are missing in the training set you have a whole lot of unlabeled data and then just a small amount of labeled data."
        ],
        [
            "One way that we can solve this with generative models is using guns, usually for the discriminator we have two different outputs, one that says that the input is real and one that says that the output is fake.",
            "Augusta Sardina and Tim Solomon's independently had an idea last year to replace the output of the discriminator with several different categories.",
            "So if you want to recognize real cats in real dogs or the classifier, you can make the category of real katriel Dogan fake data.",
            "I'll be categories that your discriminator learns about, and now when you train your discriminator you can.",
            "You can actually change the discriminator on real images that have labels, and you tell them to assign the correct label.",
            "So if you have a labeled image of a cat, you train the discriminator.",
            "Say this is not only real, but it is specifically a real cat.",
            "If you have an unlabeled image, you say that the sum of all the probabilities of the real classes should be high.",
            "So if you have an unlabeled image, you don't know whether the dog or cat you say I want.",
            "P of cat plus P of dog to be high and then finally if you have a fake image you want to maximize the probability of that class.",
            "Tim Solomon's in particular found a lot of other extensions to this basic idea that made it perform really well for semi soup."
        ],
        [
            "Revised learning on amnesty.",
            "He was able using only 100 training examples to get down to about 86 mistakes out of 10,000 test examples just a few years before that, we needed all 60,000 labeled examples to get down to that level of error rate.",
            "To give you some context, in 2014 I wrote a paper using all 60,000 labels where I was very proud of getting 78 mistakes and Tim is now down to 86 with only 100 labels."
        ],
        [
            "This also works on Cifar 10 and S VHN.",
            "It isn't quite as impressive on those as it is an amnesty.",
            "For example, in SVN you wouldn't want to replace a fully supervised model with the semi supervised one yet.",
            "Fully supervised model can get below 2% error and the semi supervised version got down to about 5.8.",
            "This line of work has been followed up in the meantime.",
            "Wrestling Salakhutdinov and his collaborators wrote a paper called Good Semi supervised learning that needs a bad Gan.",
            "That improved on a lot of these numbers."
        ],
        [
            "So another thing that you can do with generative models besides semi supervised learning is you can actually train the model to know that there are multiple correct answers and you can tell it that we want to get one of these correct answers.",
            "Traditionally when we had regression models, what we would do is reduce the mean squared error between some specific known answer for some training data and the predictions of the model.",
            "So if we wanted to train a regression model to say what's the price that a house will solve for?",
            "We might have an example of a house in the training set where we know the price that it sold for, and we tell the model we want you to output as close as possible to that price.",
            "You can think about is being extremely simple generative model, which is a Gaussian distribution conditioned on the input.",
            "But the nature of this mean squared error loss or this Gaussian output distribution means that you sort of blur together all of the different possible answers associated with the ginput."
        ],
        [
            "So we see how this works with video prediction.",
            "Let's look at this frame from paper by William Lauder on predicting videos of 3D heads as their animated.",
            "We know that this 3D head is going to rotate a little bit in the next frame, and we can kind of visualize what it might look like, but there are very many different possible futures.",
            "We don't know exactly how far it's going to move, so if we use mean squared error on several different examples where we try to predict the next frame given the current frame, we're going to see a lot of different possible futures.",
            "While we do that.",
            "And we'll end up averaging a lot of them together, and we'll get an image that's kind of blurry."
        ],
        [
            "So here's what actually happens on the left if we use.",
            "The ground truth image what the actual next frame looks like in the middle we see what happens if we train with mean squared error where the output is essentially a Gaussian distribution.",
            "We actually get a lot of blurring to the point where the person's ear more or less disappears and the eye is not very crisp at all.",
            "On the right we see what happens if we use a richer generative model that's able to understand that there are multiple possible futures and capture a distribution over all of them were not able to get samples that are individually crisp, and so we can actually see many different specific features that are all possible.",
            "Instead of blurring many of them.",
            "To get one image that is not representation representative of any of them."
        ],
        [
            "There are also a lot of tasks where what you actually want to do is just generate realistic data.",
            "A lot of us are working on solving healthcare problems or building self driving cars or figuring out which adds to show people and we don't really think of generating images is something useful, but there are actually media companies that make special effects and there are companies like Adobe that make tools for building these media products and these people really do need to generate realistic data."
        ],
        [
            "So one example of this is a model called Igam stands for Interactive again.",
            "And let's see if my Internet connection is good enough to play the YouTube video for you.",
            "Looks like maybe my Internet is too slow here, so I'll just show you the thumbnail.",
            "The idea behind again is that it assists an artist that you don't need to actually have real artistic skill.",
            "You can have like Ms Paint 101 level skill at drawing on a computer, and you draw a very simple sketch and then I again will search for the nearest natural image that has high probability according to the model.",
            "The basic idea is that in this slide.",
            "The user has scribbled some green paint down here.",
            "Just a few WAVY green lines and the model has turned it into a lush Greenfield.",
            "And then they've also drawn just as sharp black triangle with no real details.",
            "And the model has turned it into a mountain.",
            "You can also see on the right there's several different possible samples that you can choose from, so you get a real probability distribution over different things.",
            "You might want to draw.",
            "The question is, is this with auto dryers and I actually don't know about auto draw, so I'm afraid I don't know.",
            "Like oh right?",
            "OK yeah.",
            "Auto draw I should know more about because that's my colleague who made that it's a different kind of generative model, but it's still the basic principle that you can have generative models that clean up what you're what you've drawn."
        ],
        [
            "There's another thing called introspective adversarial networks that's very similar to again, and the applications they specialized on with editing faces, so you can actually change the position of peoples hair line, whether they're wearing glasses or not, and so on."
        ],
        [
            "There's another technique called image to image translation where you want to go from one kind of image to another kind of image.",
            "You might want to take an aerial photo and turn it into a map like I've shown on the lower left, or you might have a bitmap specifying what kind of object you would like to have at every pixel in an image.",
            "So on the upper left I show you this map of the road scene, where Magenta says Wetherby Rd Pixels.",
            "Blue says we want there to be cars and so on, and then an image to image translation model can actually generate.",
            "A picture of such a street scene with the road in cars in that place so you can use this to make simulated training data for self driving cars.",
            "And you can think of you know very difficult situations where those cars boxing you in that might not occur very often in real training data and so you can exercise the model on more difficult scenarios.",
            "The reason we need a generative model to do this is that for most of these image to image translation techniques there are multiple correct answers.",
            "Just like earlier I showed you how the rotating head would become blurry if we try to use mean squared error to guess what the next rotating head would look like.",
            "We would end up with blurry images if we try to use mean squared error to train a model to map inputs to outputs.",
            "You can especially see this for turning sketches and two photos.",
            "So on the right side I show you what happens if you build a training set.",
            "By taking a lot of photos, running edge detection on them to get edge images, and now you have these pairs of edge images and color images, and you can train a model to invert that process where it takes an edge image as input and produces a photo as output.",
            "You can see how there's two different columns of photos here.",
            "Both the ground truth and the real output.",
            "You can see that the real output often is a different color than the ground truth, and that's because the model isn't psychic.",
            "It doesn't know the color that's actually in the ground truth that we want to fill in, so it's given us a different legitimate color, and it's able to do that because it's a conditional generative model that can produce many different samples rather than needing to try to come up with one mean value that represents all the different photos it sees in the training set.",
            "Still sort of close, right?",
            "How's?",
            "It seems a little psychic.",
            "Oh, like you're saying it's still close in the sense that like it's a 10 purse versus a Brown purse, I think it's mostly the purses tend to be leather.",
            "2nd row, it's not nearly as close like like see the 2nd row.",
            "It's green, but it's made it leather.",
            "The model is made it leather everywhere.",
            "You actually see this alot for image colorization.",
            "Image colorization is another thing you can do is an example of image image translation, so image colorization is where you take a grayscale image and you turn it into a color image and a lot of the time you'll find that for objects that can have two different popular colors like apples are often green or often read, you'll find that the model turns those objects Gray or rather just leaves them Gray because it's averaging out the mode of green apples and the motive red apples.",
            "If you then use a generative model that can represent both modes.",
            "It will successfully turn the apples either green or red."
        ],
        [
            "So in the example I showed you so far, we actually had supervised learning to train these image to image translation models.",
            "So we would take a photo.",
            "We would extract its edges and then we would use the edges as the input to a supervised model and reduce the corresponding photo as the output target for that supervised learning process.",
            "It turns out that you can also learn to translate from one image to one image domain to another without supervision.",
            "So instead of having pairs of images that go with each other, you have a bunch of images from domain A and a bunch of images from domain B, but you don't tell them all the correspondence between them in this paper.",
            "From NVIDIA research, we see how you can take a collection of images of day scenes and a collection of images of night scenes, and you can learn to turn a day scene into the equivalent night scene, and it would be really hard to try to do this with supervised learning, because how would you actually gather the ground truth data?",
            "You'd have to find all the cars that were there at the time and drive them back to the exact same position at night.",
            "You just you wouldn't be able to do it in a natural environment the way that this works basically is you train a generative model that takes an input value from one domain as it's Z vector and transforms it into a sample from the other domain.",
            "And what that means, instead of using something like Gaussian noise, is the input to the model.",
            "We're actually using images from one domain as the input.",
            "And we just want to be a good generator of the other domain.",
            "And it turns out that the easiest way to be a good generator of the other domain is to find the true correspondence between the two domains.",
            "Usually you can bias the model toward doing this by putting restrictions on how much it can change the image, and so on and so forth, but it works remarkably well, and it also works with very few training examples, like maybe only a couple of 100, which is really unusual for deep learning.",
            "Where were you still wanting?",
            "10s of thousands?"
        ],
        [
            "One of my favorite examples of this kind of image to image translation is the cycle Gan model from UC Berkeley.",
            "Here they trained a model on a bunch of images of horses and a bunch of images of zebras.",
            "They didn't have any corresponding horses and corresponding zebras, because how would you gather those?",
            "You'd have to go out in the field and twist the zebra into the horse position.",
            "And they are now running it on this video of a horse running back and forth and we can see it turns it into a zebra cycle.",
            "Count is restricted in how much you can change the image.",
            "It wants to make only very local edits so you can see it has a little bit of trouble with some things like the horses tail.",
            "Zebra tails don't have the same shape as horse tails and so it doesn't actually successfully make a zebra tail.",
            "And state makes a striped horsetail.",
            "Also.",
            "Zebras have a standing Maine on the back of their neck.",
            "Horses have a main that hangs down over their neck.",
            "You can see that it struggles a little bit to try to erase where the horses neck, where the where the main hangs down over the horses neck.",
            "It tries to sort of conceal that hair with zebra stripes.",
            "An another interesting thing is there isn't anything here designed for video in particular, but the stripes are still relatively stable from one frame to the next.",
            "The main glitch in the way that the stripes move is that when the horse turns his head point weapons for right now, the stripes are relatively stationary in the image and the horses head moves across the stripes.",
            "One other thing you might see is that the background is very different.",
            "This is trained on pictures of horses living in pastures and zebras living in savannahs.",
            "So the background foliage actually turns to look more Savannah, like a lot of the time, you'll see that different machine learning algorithms have interesting implicit biases built into them, and it's important to think about the kind of biases that your data set produces for this, where we're just having fun turning images of horses into zebras, it's all harmless fun, but if you're using your machine learning algorithm to make important decisions that affect peoples lives, you should think about what kind of impact the choice of your training examples will have on the decisions that it will actually make.",
            "If it's doing something like approving mortgages or approving parole applications."
        ],
        [
            "Another kind of realistic image generation task that you can do with generative models is text to image synthesis.",
            "So a few years ago the Ms Coco data set came out with images and captions and everyone started publishing image captioning papers where you would have a neural net look at an image and output the caption.",
            "Now it's actually possible to do the reverse using a model called STACK.",
            "Again, we can take these sentences describing birds and we can produce high resolution 256 by 256 photos of birds.",
            "In the corresponding position."
        ],
        [
            "Another thing that you can do is you can actually.",
            "Run simulations using a predictive model rather than explicitly simulating the predictions you want to make.",
            "That sounds kind of abstract, so I'm going to give you a call."
        ],
        [
            "Example, if you're doing high energy particle physics, you have particles that you collide in a particle accelerator and they I guess, explode.",
            "I'm not really a particle physicist, so some of you are probably going to be face palming.",
            "Why discribed this?",
            "But basically the particles collide and pieces of them go flying out in different directions and energy radiates outward and you can use a calorimeter to make what's called a jet image which is this bitmap that I've shown here.",
            "Where the calorimeter actually shows how much energy lands at different points on the grid on the calorimeter.",
            "I physicists often produce these images, not using a real particle accelerator, but using a computational model where they actually understand how all the different steps in the reaction occur and they have a computer explicitly simulate those steps and a lot of them are stochastic steps, so it's a Monte Carlo simulation where you virtually roll a dice, decide what happens in each step, but basically you explicitly go through an imagine many different tiny concrete steps happening.",
            "And it's very computationally expensive.",
            "A generative model can learn a conditional distribution over jet image outcomes given the conditions of the experiment.",
            "So we can kind of by Association learn to simulate almost by muscle memory, and it can be computationally much cheaper and save millions of dollars of CPU time to do these predictive experiments, rather than doing the Monte Carlo ones.",
            "It's important to keep in mind that the prediction might introduce some errors.",
            "And so the authors of this paper spent a lot of time evaluating the different ways in which the samples from the generative model were realistic or unrealistic.",
            "But overall, it does seem like it was a useful tool for them."
        ],
        [
            "Another thing that you can do with generative models is you can learn useful embeddings for different kinds of data."
        ],
        [
            "We've seen how you can learn word embeddings using recurrent networks.",
            "It turns out that generative models can also learn embeddings for images, and presumably for other kinds of data that you could you could generate in this example from the DC Gan paper by Alec Redford and his collaborators, we see what happens if we take a latent space vector representing the concept of a man with glasses.",
            "So I represent the vector with the image that it decodes to here.",
            "That's not a real man with glasses.",
            "That's something confabulated by the model.",
            "I think Alex found this by averaging together several different vectors that all corresponded to men with glasses.",
            "You can then subtract off the vector representing the concept of a man, which I've also shown the decoded image of the man here and then you can add a vector representing the concept of a woman and you get a new vector that if you decode several noisy versions of that vector, you get several images of women with glasses, so you're actually able to do arithmetic in latent vector space, and this could enable lots of different things like.",
            "Hashing images to look up similar images or search over a database to look for image duplicates and remove duplicates."
        ],
        [
            "You can also work on learning how to make the latent codes become more interpretable, so you can try to design generative models where one particular value of the latent code will correspond to, for example, the lighting in an image, and you can make an image that is brighter or darker as you want by changing that latent variable."
        ],
        [
            "So one of the most exciting recent developments in generative models is a paper called Plug and Play Generative Networks.",
            "It came out in December 2016.",
            "I believe it makes 227 by 227 images.",
            "That's pretty high resolution by current standards.",
            "Maybe the highest resolution of any of the deep models.",
            "And it's trained on image net and it really combines a lot of the different techniques that we've talked about.",
            "It uses adverse aerial training like we used for guns.",
            "It uses moment matching, which we didn't discuss a whole lot in this talk and also denoising autoencoders and Monte Carlo methods of generating samples using a large event sampling."
        ],
        [
            "These are some of the samples that it makes it for each of the different image net categories you can get realistic images where you can actually recognize the object in the image you can see that there's actually this bird species called a redshank.",
            "You can see recognizable ants and volcanoes and so on."
        ],
        [
            "It can also make images that correspond to specific captions, so you can take a sentence like oranges on a table next to a liquor bottle, and you get these images.",
            "I actually, I don't see the liquor bottle for sure, but the oranges are pretty distinct and I guess there's a shape that looks somewhat like a liquor."
        ],
        [
            "Well.",
            "The basic idea is that you have a.",
            "Large events sampling chain.",
            "So this is a kind of Monte Carlo method.",
            "Like I said at the start of the talk I showed how GSN's and deep Boltzmann machines use a Markov chain to repeatedly update their samples.",
            "Lunch event sampling is a special version of this that follows the gradient of the log density with some extra noise and the way that this paper works that's different from previous approaches is that it uses denoising autoencoders to estimate that gradient instead of.",
            "Explicitly computing that gradient exactly, and the denoising autoencoder has been trained with several different losses that do things like activate different features in a pre trained Imagenet classifier which helps to get these real."
        ],
        [
            "Very realistic examples of images from the image net data set.",
            "It's also trained with."
        ],
        [
            "An adversarial loss where you train it to make the reconstructions look realistic.",
            "So if you train with."
        ],
        [
            "Just reconstruction lost the image on the right.",
            "Struggles to get this this pink bird looking highly realistic, but if you also include the adversarial loss it will become more realistic looking."
        ],
        [
            "If you don't actually use any classes to guide the learning process, you get images that don't look as much like realistic image net classes.",
            "This is something that applies to lots of different kinds of generative models, including ganzan Bolton machines.",
            "I'm not, I'm not sure about variational autoencoders, but basically the labels seem to guide the generative model toward making object classes that we recognize.",
            "It's kind of an interesting philosophical question.",
            "Is the model without the labels?",
            "Wrong?",
            "Or are we wrong?",
            "It is the human brain latching on to things that are are relevant to our reward function rather than latching on to things that are actually part of the probability distribution of a real values.",
            "Or is there something that the model fails to fit in the true probability density function that the labels helped to capture?",
            "It's kind of an interesting open problem and I don't really have a strong opinion on what the answer is.",
            "I actually lean a little bit toward thinking that.",
            "Our model of the world is subjective and that we tend to notice things that are relevant to our reward function, but that's a very difficult thing to prove."
        ],
        [
            "So I went in the other direction.",
            "The labels guide you toward capturing the true distribution better.",
            "Yeah, that arm.",
            "Yeah.",
            "I guess."
        ],
        [
            "So let me refine my positional by saying I think, given the training data that you have, I don't feel like the solution that the models produces objectively less correct than the one that has objects in it.",
            "But it's clear that the world contains objects, so so they're wrong in that sense."
        ],
        [
            "So I guess plug and play generative networks are pretty much the state of the art for generating image net images, and they combine a lot of the different ideas that we saw throughout the talk.",
            "And you can use generative models for many different applications that I showed you.",
            "Now that you've seen sort of a span of."
        ],
        [
            "If the tree of models that you can build and how they work, and you've seen a list of the different applications that you can do with generative models, you are ready for the second generative models class by Aaron, where he'll zoom into more detail on some of these things.",
            "Also, if you want more information on a lot of these subjects, you should check out the book that we all wrote together, which contains many chapters on generative models and the different techniques like variational learning that are the basis for a lot of them.",
            "And I'm free for questions.",
            "Can you repeat the question now that people are a little quieter?",
            "OK, so the question is how do you reduce the checkerboard effect from generated images and?",
            "Let me see if I can pull up a web browser or not because not everyone might be familiar with what you're asking about.",
            "Wild big.",
            "So the question is, is there a difference between training the discriminator with only fake data and versus?",
            "Should.",
            "Twice.",
            "Oh like should they be in the same mini batch or not?",
            "Is that what you mean by concatenated concatenated along the axis correspond to the batch size.",
            "Yeah, OK, so the question is when we train discriminator for again, we could imagine making one mini batch of data that contains both real and fake examples.",
            "Or you could imagine doing too many batches, one with real examples in one of the fake examples first, some kind of guns.",
            "It actually doesn't matter.",
            "The loss function is additive across different examples.",
            "And so if you just compute the loss on two batches and add it together, you'll get the same thing as if you computed the loss in one larger batch.",
            "The situation where it starts to matter a lot is if you're using batch normalization, so batch normalization will subtract off the mean of every feature in the mini batch and divide by the variance of every feature in the mini batch.",
            "One of the things that Alec, Radford, and Smith telephoned when they created the DC Gan is something very counter intuitive.",
            "If you use all of your data in one mini batch, the batch normalization for the discriminator doesn't work nearly as well.",
            "It works better if you apply the discriminator to all the real data.",
            "I'm going to play it separately to all the fake data, so the features for the real data are normalized using statistics from the real data and the features for the generated data are normalized.",
            "Using statistics from the fake data, it's very counter intuitive because it means you're technically applying a different function to the real data than to the fake data.",
            "That bothers a lot of people, theoretically.",
            "For me it seems aesthetically not very pleasing, so I tried doing a thing where for every layer I divide the features into two groups.",
            "So the first half of the features in the second half of the features and I run everything in one mini batch.",
            "I normalized the first half of the features on the real data and I normalize the second half of the features on the fake data.",
            "So I think what's going on is that batch norm works best if the data from each category gets normalized and having half the features we normalized in the real data and have the features they normalized affected.",
            "I mean some of the features always get a good learning signal where they are in their normal regime for each category of data.",
            "The interesting thing is, even though this version where we apply the same function to both sets of examples is more theoretically straightforward, it doesn't seem to work any better than batch mobilizing the two groups separately.",
            "It works about the same.",
            "I tend to use the version where I batch normalize half the features on one side and half the features of the other set.",
            "Just because the theory makes sense to me, but there isn't actually an empirical reason to do it.",
            "So checkerboard, yeah.",
            "So the earlier question where I waited for the website to come up with is a lot of these models get checkerboard artifacts, and so this is by this is a paper by Augustus Idina, who's on my team at Google Brain.",
            "This is before he joined my team.",
            "If it's not normal in here, Mila and Chris all day also at Google Brain they take a picture that I made actually of this polar bear thing generated by again and if you zoom in on it so you move this mouse around you can see that there's.",
            "This very fine checkerboard pattern.",
            "What's going on there is, as you move your convolution kernel around it overlaps with itself by different amounts at different positions in the image, so it places where the convolution kernel overlaps multiple times you get more input values coming to that pixel, and so it might have larger values.",
            "It might be a more white or more black rather than grey pixel in the image.",
            "There's a few different ways that you can resolve this, and there's a recommendation in this paper.",
            "I've also heard recommendations from other people recommendation in this paper.",
            "If I remember right, is to use a stride that is a factor of the kernel size so that you end up without these different amounts of overlap.",
            "My friend dirt Kingma has also told me that if you fix the artifact at the boundary of the image, where at the very sight of the image, there's fewer convolution kernels stacked up here.",
            "If you compensate for that difference in number of convolution kernels at that position, he says that that will also fix the checkerboard artifacts he thinks what's going on there is that if you have a weird artifact at the edge of the image, then your kernels need to have large values on the edge of the kernel in order to compensate for that.",
            "But then there's large values at the edge of the kernel appear throughout the rest of the images.",
            "Well, it seems a little bit architecture dependent in my opinion.",
            "It seems like both both techniques work.",
            "And depending on the architecture, using one trick or the other might work better or worse.",
            "Another thing that you can do is dilated convolution, where you're kernel is spaced out.",
            "So instead of being applied to like if you have a kernel that's with three instead of applying it to three consecutive pixels, you apply it to one pixel, and then if you have a dilation rate of two, you would skip two pixels over and apply the next member of the kernel and then skip another two pixels and apply the third Member.",
            "If you do dilated convolution with the right spacing, it's a little bit like doing subpixel sampling, and that can also reduce checkerboarding a little bit.",
            "Is there a way to evaluate how good generative modeling?",
            "So the question is, is there a way to evaluate how good a generative model is?",
            "There's a paper everyone should read, called a note on the evaluation of generative models.",
            "The paper basically says no.",
            "So, so there are several ways of evaluating generative models, but they all have different strengths and weaknesses to boil it down a little bit.",
            "One thing you can do is you can look at how good the density function function is at assigning high density to test set points.",
            "And another thing you can do is you can look at how realistic are the samples that come out of the model in this paper about a note on the evaluation of generative models.",
            "They argue that there are some models that have really good density on test points that make really bad samples.",
            "And there are some models that make really good samples that have really bad density on test points.",
            "So for example, variational autoencoders tend to be a lot better.",
            "Assigning high density to most points and guns tend to be better at producing realistic samples, but lots of generative models exist somewhere in the spectrum, and those are just two that I'm more familiar with myself.",
            "There's a few other things that are difficult about evaluating generative models.",
            "One is that so many of them rely on approximations, so if you compare two different families of models.",
            "It can be hard to tell whether one has the data density better than the other or if it's just that the approximations are making it look like one is better.",
            "So for example variational autoencoders.",
            "You can very easily compute a lower bound where you know that the real probability is better than what you have.",
            "There is some models where you use Monte Carlo methods to get a stochastic estimate of the density that they're assigning to the data, and a lot of these Monte Carlo.",
            "Methods are biased toward overestimating the density, so the number that you get from the variational autoencoder is probably not quite as good as it really is, and the number that you get for some of these Markov chain based models is often an average better than what you would actually get.",
            "There is also funny situations where if you do a worse job of evaluative implementing your evaluation code, you get a higher number, and so people have an incentive to not try very hard to make their evaluation good, and that muddies the waters further.",
            "Yeah.",
            "Looks like your connection works now.",
            "Yeah, I can try to do that.",
            "Here we go.",
            "So it's possible that my connection is working, but just not fast enough for YouTube.",
            "Just second more.",
            "So let me skip ahead a little bit here.",
            "They're showing how they can use the again to edit an image of a handbag.",
            "And we're already buffering again.",
            "The basic idea is that suppose you have this image of a handbag and you know that you want something similar to it, but a little bit smaller and a different color.",
            "You can use the paint to actually change the kind of bag that you get, and then you can use the reverse image search to look for bags of that kind so you can use it as like an assisted shopping tool basically.",
            "I can also show you the animated version of.",
            "I described it's going on in the thumbnail here, but once it loads you can see the animation of sketching the grass and mountain scene.",
            "So the user just painted with green paint and got the grass.",
            "And they're choosing from different samples from the distribution together when they like the most.",
            "Now they're sketching with black paint to add the mountain.",
            "Another sketching with blue paint to add this guy and the model in real time adepts.",
            "The image to look like what they're sketching.",
            "So if I need to generate more data, this means that my training set.",
            "One can.",
            "Source.",
            "Yeah, so the question is if you don't have enough data and you want to make more went down the guns also need data.",
            "So one way that guns can help you is if they have access to some kind of information that your classifier you want to train wouldn't have.",
            "So for.",
            "For the example from Apple, where they trained the refiner to make the images look better, the refiner can make use of unlabeled images of photos to learn about how realistic eyes look.",
            "We don't actually know where those photos of eyes are pointed, so they can't be used to train the eye direction prediction model, but they can be used to train the generative model that knows how they look.",
            "In the example of semi supervised learning, by having a discriminator that recognizes different real classes and then also the fake class, it's able to learn from fake images.",
            "It's able to learn from unlabeled images and a traditional classifier would only be able to learn from labeled images.",
            "So that's the way that it gets additional data is that you have data where you couldn't obtain the labels for one reason or another.",
            "Another thing that's kind of interesting is these image to image translation models.",
            "They don't actually need very many examples like only a few 100.",
            "I didn't realize that until I went to visit Berkeley a few weeks ago.",
            "An filippello is telling me that he was surprised that these required very few examples to get them going.",
            "I don't really know why it is.",
            "It would be an interesting thing to study.",
            "So as soon as the generator is broken or anything like reasonable sample.",
            "Then nothing forces there Gan to generate like more samples basically.",
            "So there's a variety of generated samples are not as much as like the real data, and that's because they like the mean masking mean, Max cost function and again pushes the generated samples who.",
            "Who are the area of a manifold that have high probability?",
            "So.",
            "So personal my first question is that is it the problem at all or in my second question is that is there any solution around that?",
            "So the question is basically, is the mode collapse problem in guns of a problem?",
            "I guess the way I worded I serve answered it.",
            "And is there a solution to it so I would save mode?",
            "Collapse is probably the biggest problem for games.",
            "The cause is not entirely clear.",
            "It might be something to do with the cost function, but I actually don't think so.",
            "It might be something to do with the way that the learning dynamics work, but.",
            "Starting to look a little bit less likely given some recent results, and I'll explain to everybody that in a second, and I actually think it might be something related to the model family that we use in ways that are kind of strange and hard to understand from the knowledge I have.",
            "So one thing I've seen that's kind of interesting is if I take an autoencoder, not a variational autoencoder, just a regular load.",
            "The input propagate through the network, reconstruct the output type auto encoder.",
            "I can train a convolutional autoencoder on image net to make reconstructions that are essentially perfect to the human eye, and then I can look at the code layer and I can get a like 1000 dimensional code for image net.",
            "I think actually probably 3000 dimensional was what I used.",
            "If I fit a Gaussian distribution to those code values and then I sample from the Gaussian and decode them, I get really bad mode.",
            "Collapse all those samples look the same as each other.",
            "They're not literally the same, but they have differences that are not interesting to the human visual system, but they're all more or less the same color the same texture.",
            "They might have differences in exactly where pixels of that texture are located, but they are all semantically very similar to each other, and I would not have expected that outcome for this experiment.",
            "I didn't think it would.",
            "Right away result in good image net samples, but I did think that samples from this Gaussian distribution in code space of an autoencoder would look very different from each other and something about the way that the decoder works actually made them all look similar.",
            "I can't really explain why that's happening yet, but I do think that might be part of what causes gunstone mode collapse so often.",
            "I would have expected the opposite, like you would get lots of spurious images.",
            "Is very surprising.",
            "Well, they weren't good images.",
            "They were all the same.",
            "Serious image, yeah.",
            "So yeah, so for again it could be that the loss function makes them collapse.",
            "Too high probability points, so you could say maybe guns are doing something like minimizing the Jensen, Shannon Divergent and then that would say that they prefer to pick one mode and sample from it rather than capture all the modes.",
            "But now we have all kinds of things like Afghans from Microsoft Research that can do the KL divergent between data and model, and that should that should prefer to capture all the modes rather than sample from just one.",
            "I have my own formulation of doing the KL divergent's in a different way and it still has mode collapse too.",
            "And then there's a few other papers like the one by Ben Poole.",
            "Where he he has like an Alpha parameter, we can interpolate between diversity and quality of samples, but they all suffer from mode collapse to some extent, so that kind of makes me think maybe it's not really the last function.",
            "It could also be something to do with the dynamics of the game, so if you have a cost function for each player and you start doing gradient descent on each players cost with respect to that players parameters, you don't know that you'll actually find the Nash equilibrium for the two players, so it could be happening is we're getting stuck in a setting where the generator has mode collapsed and the dynamics just can't take us out of that setting.",
            "So then the question becomes, why do the dynamics?",
            "Repeatadly take us to that pathological setting, and that's a bit harder to explain.",
            "One thing that came out recently that started to make me worry a little bit less about the dynamics compared to some of the other parts of the model is Zico, Kolter and one of his grad students at CMU wrote a paper where they said that if you analyze gradient descent on guns as a dynamical system.",
            "It's locally stable near the Nash equilibrium, so that means if you get near the Nash equilibrium you should converge to it.",
            "Sort of like if you have an optimization problem and you can get near a local minimum, you should converge to it for if you're sufficiently near before that paper, we didn't actually know whether guns were localised, able, and I kind of suspected that they weren't.",
            "I'm not a dynamical systems expert, so I had taken the Jacobian of the of the dynamics, and I saw that had a big block of zeros in it.",
            "And I thought that would make too many of the eigenvalues be 0 and that it wouldn't be stable, but the CMU people are more more skilled at analyzing nonlinear dynamical systems, and they found that.",
            "Regular guns are stable, and Wasserstein guns are unstable for.",
            "For their analysis, it's important to keep in mind that further analysis the way that they were running the Wasserstein Gan is not the same way that the Wasserstein Gan paper advises to run it.",
            "They were looking at a single step on each players cast simultaneously, and you're supposed to run Wasserstein gowns with multiple steps on the discriminator.",
            "But that's the multiple step.",
            "Scenario is a lot harder to analyze with traditional.",
            "Dynamical systems equations.",
            "So the question is, guns are hard to train.",
            "Do we have any tips for how to train them better?",
            "See me.",
            "Facebook AI Research has a repo called Gan Hacks where he lists a lot of tips for training guns better.",
            "Some of them you know he marks them pretty clearly like this one is very well accepted.",
            "As always helping and you know this one seems like it helps some people and hurt some people.",
            "Depending on the problem they're solving.",
            "It's a pretty good repository.",
            "I recommend it to the people at Google who are working on guns, and I think other people are pretty happy with it too.",
            "Philly.",
            "By sampling biases you mean?",
            "Like the data not being representative of a population in a way that could result in bad decision-making, or.",
            "Playing.",
            "Generation.",
            "You can do that.",
            "So the question is, do we have a better way of finding biases in the model?",
            "If we have an implicit model, is it harder than if we have an explicit one?",
            "Or are people working on it?",
            "I don't know as much about this topic.",
            "Other people that I work with our front under Viega smart and Water Wattenberg and been Kim at Google are all working on these topics and I'd be able to tell you more than that.",
            "I can off the top of my head, I feel like.",
            "It's usually the data set itself that has a lot of these problems and an explicit density function in the model may not necessarily tell us what those problems are.",
            "The density function can tell us what the model believes in, but it doesn't necessarily tell us what was in the data to start with.",
            "It can be hard to tell if a problem in the final density function was a problem with the learning algorithm or a problem with the data itself.",
            "There's also the issue that.",
            "The model will just tell you that your training data is likely to occur, but the model can't tell you about the things that didn't go into the data that you're overlooking.",
            "And the model will just be confident in its own mistakes.",
            "It's kind of hard to use a model to look at itself and figure out what's wrong with it.",
            "So like on image net, an example of the kind of bias you're talking about is.",
            "A lot of the time you know you'll have a class like rugby ball and you always see the rugby ball in a rugby field.",
            "You never see the rugby balls sitting in someone's garage, so a lot of the time Imagenet models will see a rugby field with no ball in view and they'll classify it as a rugby ball.",
            "But the problem is the model is confident in what it's doing, so they can't tell you that that's a mistake.",
            "You have to just label the data independently and find that it's a mistake.",
            "Why would you normalize?",
            "The question is, why do you normalize images between minus one and one rather than zero and one?",
            "Both of them seem to work in the original Gan paper.",
            "I think I normalize them between zero and one, at least for amnesty.",
            "I'm pretty confident I did.",
            "In my paper on generating image net images.",
            "The reason I used negative one positive one is that.",
            "I think his name is Taehoon Kim.",
            "I know his GitHub username is carpe diem.",
            "Made an open source implementation of DC guns and he standardized the images to negative one positive one.",
            "So I just took his code and started hacking off of that and I never changed the preprocessing.",
            "So.",
            "Stand by music.",
            "Soccer downsample wild.",
            "Images.",
            "Yeah, so so you can get things that are a kind of proper downsample using strided convolution, overside, dilated convolution and then you can also do the like Gaussian weighted.",
            "You know better quality downsampling.",
            "I found that tends to get rid of the checkerboard artifact, but at least in Tensorflow, the true downsampling is a lot slower, and I didn't find the improvement in quality was worth the reduction in speed.",
            "I've also found sometimes like images, the models that learn to generate images with better objects in them often have more checkerboards and a lot of the time I do things that get rid of the checkerboards, but also get rid of the higher level semantics of the objects.",
            "I don't really know exactly what's going on there.",
            "Pics and what kind of data are text data.",
            "Yeah, so the question is how do I see the success of guns and text data?",
            "Do you mean comment on where they are right now or?",
            "Uh.",
            "So there is the the Wasserstein Gan with gradient penalty can generate text 1 character at a time.",
            "The majority of words that it produces are not recognizable English words, at least in the paper that I saw.",
            "I don't have access to a large corpus of samples from it to evaluate that test.",
            "So basically I feel like guns aren't quite there yet.",
            "One thing I don't understand is there's quite a lot of enthusiasm for guns for text in general, and to me that's a little bit confusing because text seems like one of the places where guns are least likely to help you.",
            "For against the they work best if the output is differentiable because you need to back propagate through the discriminator and then through the output of the generator and then through the generator itself.",
            "So it's hard to make a VE that has discrete latent variables.",
            "It's hard to make again that has discrete output variables and.",
            "I guess I personally have focused my efforts on trying to make guns for images very stable and reliable, because I think that's going to happen earlier than guns.",
            "For text.",
            "It just seems like if we can't even handle the case where the output is continuous yet then the case where the output is discrete is like tackling two difficulties at once and you've got to resolve both of them before you really see success.",
            "So yeah, it's a really hard thing, and it doesn't seem to have caught up to like where RNN text generation is.",
            "Alright, thank you very much, thanks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'll cover the first lesson on generative models.",
                    "label": 1
                },
                {
                    "sent": "Erin will cover the second one later in the school.",
                    "label": 0
                },
                {
                    "sent": "There will also be a few more lessons that are related to generative models.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The basic idea of generative models is that we want to do density estimation.",
                    "label": 0
                },
                {
                    "sent": "We want to take a bunch of training data and we want to fit a probability density function to that data.",
                    "label": 0
                },
                {
                    "sent": "So in this example I have a bunch of points on the real number line and I've fitted Gaussian distribution to that collection of points and on the right I show you what that density function looks like.",
                    "label": 0
                },
                {
                    "sent": "A lot of the time we do these estimation processes explicitly.",
                    "label": 0
                },
                {
                    "sent": "We actually write down a density function and we adapt the parameters of that density function to match the data.",
                    "label": 0
                },
                {
                    "sent": "You can also do what are called implicit models.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Where you are able to generate samples from the data set.",
                    "label": 0
                },
                {
                    "sent": "So here I show a bunch of training examples on the left from the image net data set and on the right I show what we would like to happen.",
                    "label": 0
                },
                {
                    "sent": "We'd like to be able to generate more samples that come from that same distribution.",
                    "label": 0
                },
                {
                    "sent": "We don't actually have a model that can do this yet at Yahoo is looking really shocked in the front row audience 'cause he thought this is the state of the art from Google Brain.",
                    "label": 0
                },
                {
                    "sent": "But this is an idealization using test data.",
                    "label": 0
                },
                {
                    "sent": "So this is the goal.",
                    "label": 0
                },
                {
                    "sent": "This is.",
                    "label": 0
                },
                {
                    "sent": "This is what all of you in the audience here to learn about generative modeling.",
                    "label": 0
                },
                {
                    "sent": "If you decide this is what you want to study in the course of your deep learning career, this is what you're shooting for doing.",
                    "label": 0
                },
                {
                    "sent": "If you're working on generative models.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The main principle that people use for fitting generative models is maximum likelihood.",
                    "label": 0
                },
                {
                    "sent": "The basic idea is you write down some density function that I'm going to call P_model and this density function tells you how likely a particular input point X is.",
                    "label": 0
                },
                {
                    "sent": "So X is just a vector that we use to describe different kinds of data.",
                    "label": 0
                },
                {
                    "sent": "It can be an image, it can be an audio waveform, it can be a sentence, it can be a sequence of words, and then we also have a set of parameters Theta.",
                    "label": 0
                },
                {
                    "sent": "Where those can be many different things, they can be a collection of tensors that you used for convolution.",
                    "label": 0
                },
                {
                    "sent": "They can be matrices that you use for a fully connected layer.",
                    "label": 0
                },
                {
                    "sent": "We're going to summarize all of them with just a vector of data and the basic idea behind maximum likelihood is we write down the likelihood that the model assigns to the data and we adapt Theta to make that likelihood become as high as possible.",
                    "label": 0
                },
                {
                    "sent": "In practice, there are many different ways of doing generative modeling.",
                    "label": 0
                },
                {
                    "sent": "A lot of them maximize functions other than the likelihood.",
                    "label": 0
                },
                {
                    "sent": "I'm going to show you how all of the different generative model families can approximate maximum likelihood.",
                    "label": 0
                },
                {
                    "sent": "Not all of them are used to approximate maximum likelihood by default.",
                    "label": 1
                },
                {
                    "sent": "Some of them approximate maximization of other functions, but if we look at all of them through the lens of maximum likelihood, it will be easier to see the similarities and differences in the approximations they make rather than in the cost functions that they optimize.",
                    "label": 0
                },
                {
                    "sent": "But just keep that in the back of your mind that a lot of them actually use different cost functions in this.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If we pretend that all of these different generative models use maximum likelihood, then we can build a taxonomy that basically looks at whether they use an explicit density function or an implicit density function, and what kinds of approximations they need to use there.",
                    "label": 1
                },
                {
                    "sent": "Also, generative models that don't even really fit in this tree.",
                    "label": 0
                },
                {
                    "sent": "So we're looking at the subtree.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It starts with all the different generative models that can be coerced into doing maximum likelihood in one way or another.",
                    "label": 1
                },
                {
                    "sent": "On the left branch of the tree we look at models that actually have an explicit density function.",
                    "label": 0
                },
                {
                    "sent": "They actually have a P model of X given Theta that you can write down and maximize.",
                    "label": 1
                },
                {
                    "sent": "So what are the challenges involved in building an explicit density model?",
                    "label": 0
                },
                {
                    "sent": "The main challenge is that it can be really difficult to design AP model of X that is computationally tractable and is still actually flexible enough to capture the data distribution.",
                    "label": 0
                },
                {
                    "sent": "There are a lot of probability distributions that are very easy to write down and very easy to work with computationally, like if you have a Gaussian distribution with diagonal covariance.",
                    "label": 0
                },
                {
                    "sent": "That's very easy to write down, and it's very easy to do all the computations you need to manipulate it.",
                    "label": 0
                },
                {
                    "sent": "Yeah, sure, so this morning I explained RNN switch our particular case.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so our names are an example of an explicit density function that's straightforward to work with.",
                    "label": 0
                },
                {
                    "sent": "One of the challenges with scaling these explicit density functions to larger problems like generating image net images is that a lot of the probability density functions right down on these images are not necessarily all that straightforward to evaluate.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So one category of explicit density models is to just carefully design the model to make sure it's tractable, like the RNS that yahshua covered this morning.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In general, you don't need to be modeling a sequence like you usually do with an RNN.",
                    "label": 0
                },
                {
                    "sent": "You can actually regard any vector valued piece of data as being a sequence, so you have some vector X with elements X one through XN.",
                    "label": 1
                },
                {
                    "sent": "You can regard that vector as being a sequence, even though the different members of the vector come from different conditional distributions, and then you can use the chain rule of probability to expand the probability distribution over X into a sequence of multiplications of different probabilities.",
                    "label": 0
                },
                {
                    "sent": "So you have P model of X 1 * P model of X2 given X one and so on until you have P model of XN.",
                    "label": 1
                },
                {
                    "sent": "Given all of X1 through X N -- 1.",
                    "label": 0
                },
                {
                    "sent": "The first time this was done, it was called fully visible belief Nets by Brendan Frey and his collaborators, and basically each of these conditional distributions was something like a logistic regression model, but you can really fill in any kind of model that you want, and this chain rule will still make sure that you're able to get a tractable model over the whole vector.",
                    "label": 1
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The main disadvantage of this family is that if you want to generate a sample, you have to explicitly sample every member of the vector in sequence.",
                    "label": 0
                },
                {
                    "sent": "You have to sample X one and then sample X2 given X one and then sample X3 given X1 and X2 and so on, and those computations can't be paralyzed because the value that you get for X3 is actually a function of the value get for X1 and X2.",
                    "label": 0
                },
                {
                    "sent": "You can't just spin up N different CPUs that each generates 1 sample on its own.",
                    "label": 0
                },
                {
                    "sent": "We'll also see that a lot of our different generative models have a latent code that tells us something about what sample it will generate, or it tells us something about the semantics of the input.",
                    "label": 0
                },
                {
                    "sent": "These models usually don't come with a latent code that describes the entire image or the entire vector.",
                    "label": 1
                },
                {
                    "sent": "They'll describe the state of the generation machine after each entry that they process, but it takes some special models like variational autoencoders with pixel CNN decoders if you want to get this kind of.",
                    "label": 0
                },
                {
                    "sent": "Latent code control of an autoregressive model.",
                    "label": 0
                },
                {
                    "sent": "So in.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The more recent years after Brendan Fraser original work on the chain rule for building generative models, the modern version of these are mostly called autoregressive models.",
                    "label": 1
                },
                {
                    "sent": "There's a model called made for neural autoregressive density estimation and then later made where the end now stands for masked rather than neural.",
                    "label": 0
                },
                {
                    "sent": "Both of these are essentially using neural Nets to define these distributions.",
                    "label": 0
                },
                {
                    "sent": "XI given X preceding I.",
                    "label": 0
                },
                {
                    "sent": "There's also been a line of work coming from deep mind that calls these pixels CNN's or Pixel RNN's or for audio, it's called Wavenet.",
                    "label": 0
                },
                {
                    "sent": "All of these work on the same basic principle of designing a model that has an explicit tractable density function.",
                    "label": 0
                },
                {
                    "sent": "By generating a vector, one entry at a time.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There's another kind of tractable density model that uses a very different principle to set up the way of making the probability distribution tractable, and that's to use a change of variables formula.",
                    "label": 1
                },
                {
                    "sent": "So if you have some random variable Y and you have some differentiable invertible function G, that will take you from a random variable X to Y, you can actually transform the probability distribution over X into a probability distribution over why by looking at the determinant of the Jacobian.",
                    "label": 0
                },
                {
                    "sent": "Of G. You can use this either to map from an observation X into a latent space and then have a nice probability distribution over the latent space, or because G is invertible, you can actually do the opposite.",
                    "label": 0
                },
                {
                    "sent": "You can start out with a nice probability distribution over a latent variable and then map it back to the input space.",
                    "label": 0
                },
                {
                    "sent": "The main disadvantage of this approach is that it can be difficult to design A transformation that's invertible, and in particular when you have to design A transformation that's invertible, you need to have the same number of latent variables as visible variables, because you need to make.",
                    "label": 0
                },
                {
                    "sent": "An invertible transformation between those two spaces.",
                    "label": 1
                },
                {
                    "sent": "In practice, we've seen that this is able to make decent samples in the image.",
                    "label": 0
                },
                {
                    "sent": "Here I show you what happens when you run a version of this strategy called Real MVP on 64 by 64 image Net.",
                    "label": 0
                },
                {
                    "sent": "This basic strategy of using nonlinear ICA I just any kind of model where you have a nonlinear G function and then an independent distribution of the latent variables that dates back to the work of APO hyvarinen in the 1990s, and I think maybe even back to the 1980s.",
                    "label": 1
                },
                {
                    "sent": "But I'm not nearly as familiar with the ICA literatures in your thesis.",
                    "label": 0
                },
                {
                    "sent": "OK, yeah.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That basically concludes my description of the tractable density models.",
                    "label": 1
                },
                {
                    "sent": "One comment is that I've focused on the deep tractable density models, things that can actually scale to generating images.",
                    "label": 0
                },
                {
                    "sent": "There's obviously a lot of very simple distributions that are tractable but can't scale in that way.",
                    "label": 0
                },
                {
                    "sent": "So we're still looking at the subtree of generative models that focuses on explicit density functions, where you can actually write down P submodel of X given Theta.",
                    "label": 1
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But now we're moving to the branch where we give up on making piece of model of X given Theta be computationally tractable, we're going to start using very expensive piece of model given X in order to have fewer constraints on the design of the generative model.",
                    "label": 0
                },
                {
                    "sent": "But we need to now use approximations to evaluate these intractable computations.",
                    "label": 0
                },
                {
                    "sent": "So probably the most popular version of an approximate density model today is the variational auto income.",
                    "label": 1
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The basic idea behind variational learning in general is you have a set of latent variables that will call Z and these are variables that more or less explain what's going to be in the input.",
                    "label": 1
                },
                {
                    "sent": "You might have a variable that says whether a picture of a person is smiling or not, or another variable that might say whether or not they're wearing glasses, or if you're generating a sentence, you might have a variable that says which topic you are going to be discussing, and another variable that says whether you're going to write.",
                    "label": 0
                },
                {
                    "sent": "This sentence, with more of an informal style or more of a journalistic style.",
                    "label": 0
                },
                {
                    "sent": "Altogether, these different variables can be combined in a vector that will just call Z, and we define a probability distribution.",
                    "label": 0
                },
                {
                    "sent": "Giving us a distribution over X in terms of what the Z variables are asking us to generate, so we have both some distribution P of Z and some distribution P of X given Z.",
                    "label": 0
                },
                {
                    "sent": "If we want to do maximum likelihood learning, we need to get piece of model of X, though we actually don't want there to be a Z value in the expression because we need to maximize P model of X for every data point in the data set.",
                    "label": 0
                },
                {
                    "sent": "We have to do then is actually taken integral.",
                    "label": 0
                },
                {
                    "sent": "To marginalized Z out of the probability distribution, and then we maximize the resulting log probability over just X.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately, this integral is very computationally difficult to evaluate.",
                    "label": 0
                },
                {
                    "sent": "There's usually not a closed form solution to it, and usually have to have some kind of Monte Carlo method for approximating it, and those methods often don't scale very well.",
                    "label": 0
                },
                {
                    "sent": "So what variational models do instead is they say rather than trying to maximize literally P model of X, we're going to come up with a.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Lower bound and P model of X.",
                    "label": 0
                },
                {
                    "sent": "So we're going to come up with some value that is always less than P model of X and maximize that bound instead.",
                    "label": 0
                },
                {
                    "sent": "The idea is if you maximize the bound and you get a number that you're happy with for the bound, you know that you're going to get an even better number for P model of X.",
                    "label": 0
                },
                {
                    "sent": "You're not necessarily going to find the maximum possible value of P model of X, but you'll find a value that's pretty good.",
                    "label": 1
                },
                {
                    "sent": "So the idea behind the variational bound is we introduce a new distribution over the latent variables that we're going to call queue of Z, and it turns out that the variational bound could be written as the log probability of X minus the KL divergent between our new distribution QZ and the true posterior distribution P of Z given X.",
                    "label": 1
                },
                {
                    "sent": "So to maximize this bound, we want to make you of Z look more and more like the true distribution P of Z given X, the KL divergent measures how different different those two distributions are, and it goes to 0.",
                    "label": 0
                },
                {
                    "sent": "If you can make them be identical.",
                    "label": 1
                },
                {
                    "sent": "Basically, this means we want to try to find a way of pushing Q to be as close to zero as possible.",
                    "label": 1
                },
                {
                    "sent": "In the past, people used to do this using an optimization algorithm directly on the parameters of Q itself.",
                    "label": 0
                },
                {
                    "sent": "The really key insight for variational autoencoders.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is that you can actually define a neural network that predicts the parameters of Q, so you can actually think of the neural network is being like an optimization algorithm where instead of explicitly taking several steps to solve for the Q that will match P of Z given X as closely as possible, the neural net predicts the value of Q.",
                    "label": 1
                },
                {
                    "sent": "That will solve the optimization problem.",
                    "label": 0
                },
                {
                    "sent": "This means you can go.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And actually just plug in the neural net for the definition of Q in this equation and you can actually just start maximizing the whole equation.",
                    "label": 0
                },
                {
                    "sent": "You learn the parameters of P of X given Z, the parameters of P of Z, and the parameters for the predictor Q of Z, all at the same time, so it's.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Very clean and elegant solution, but makes it possible to do variational learning without all of the complicated optimization alternating between optimizing queue and optimizing the model that we used to do.",
                    "label": 0
                },
                {
                    "sent": "And the right I showed some samples from the cifar 10 data set that were generated from a state of the art variational autoencoder in 2016.",
                    "label": 1
                },
                {
                    "sent": "And there will be an A.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Your lesson about variational inference from Max Welling.",
                    "label": 0
                },
                {
                    "sent": "Who's the leader of one of the labs where variational autoencoders first emerged, so he'll be able to tell you a lot more about this subject.",
                    "label": 0
                },
                {
                    "sent": "I'm just giving you the teaser so that you have some context for how the tree fits together.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that's the main branch that's popular today in the sub branch of approximate density models.",
                    "label": 0
                },
                {
                    "sent": "There's another branch under the approximate density models that is not very popular today, but was very popular during the time that I did my PhD.",
                    "label": 0
                },
                {
                    "sent": "The current wave of popularity of deep learning began when deep belief networks were shown to outperform support vector machines back in 2006 on the endless data set and deep belief networks were based on a generative model called.",
                    "label": 0
                },
                {
                    "sent": "Wholesome machines that could be stacked to form a deep model.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The basic idea of Boltzmann machines is that they define a Markov chain where you can draw samples from the model by updating previous samples.",
                    "label": 1
                },
                {
                    "sent": "So every time you stochastically update a sample, it moves toward a different fair sample from the same distribution defined by the model.",
                    "label": 0
                },
                {
                    "sent": "You can use this to use samples from the model to approximately compute the gradients of the probability of the model even though the probability density function itself is intractable.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately, the Markov chains that we use for these Monte Carlo estimates don't seem to scale to high dimensional spaces very well.",
                    "label": 0
                },
                {
                    "sent": "People have not yet been able to train Boltzmann machines on very large datasets like images of cifar 10 samples or image net samples, for example.",
                    "label": 0
                },
                {
                    "sent": "And so they.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I've been as popular for the past few years.",
                    "label": 0
                },
                {
                    "sent": "And now we're moving to the last branch of the taxonomy of generative models that will show today.",
                    "label": 1
                },
                {
                    "sent": "And this is the branch of implicit density models.",
                    "label": 0
                },
                {
                    "sent": "So an implicit density model is a model where we actually can't write down very easily P density or P model of X.",
                    "label": 0
                },
                {
                    "sent": "Instead we make a generative machine that generates samples from that distribution and being able to generate those samples is the only way that we actually interact with that representation of the distribution that we're learning.",
                    "label": 1
                },
                {
                    "sent": "So the first branch on here is where we make a generative machine based on a Markov chain.",
                    "label": 0
                },
                {
                    "sent": "It generates samples iteratively, where it will generate 1 sample and then stochastically update it to refine it.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And after several steps you will get a different independent sample.",
                    "label": 0
                },
                {
                    "sent": "So the main example of this part of the branch is generative stochastic networks that yahshua invented in 2013.",
                    "label": 1
                },
                {
                    "sent": "The basic idea is shown here is that in each row we can see a sample evolving overtime as it stochastically updated in the first row.",
                    "label": 0
                },
                {
                    "sent": "We see how we start with an S 9 and it gradually evolves into an M just four as we repeatedly sample it.",
                    "label": 0
                },
                {
                    "sent": "So Markov chains are an effective way to get samples from the distribution, but we may also sometimes want to get a fair sample in a single shot.",
                    "label": 0
                },
                {
                    "sent": "That's basically the problem that I was trying to solve when I came up with generative.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Social networks the idea of general networks is that they are a generative model that creates data directly in a single step.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the way that they do that is they have a generator function G which is just a differentiable function mapping from latent variable Z to X.",
                    "label": 1
                },
                {
                    "sent": "You'll recognize that this function G is basically the same thing as we have for the decoder of a variational autoencoder.",
                    "label": 0
                },
                {
                    "sent": "It's also basically the same thing as we have in the generator.",
                    "label": 0
                },
                {
                    "sent": "Net for a nonlinear ICA model, the main difference in the G function for variational autoencoders and for against from nonlinear ICA is that there's no constraint that Z has to have the same number of entries as X.",
                    "label": 0
                },
                {
                    "sent": "So we require that G be differentiable, but we don't require that it be invertible.",
                    "label": 0
                },
                {
                    "sent": "Now basically it works is we start out with some input noisy.",
                    "label": 0
                },
                {
                    "sent": "We run it through the differentiable function G and we get a value of X that sampled from the model like the face that I show in the right and I've tried to show kind of a low quality image of a face that I just messed up a little bit in photo shop to illustrate conceptually the idea that the generator is not going to be perfect.",
                    "label": 1
                },
                {
                    "sent": "And then there's another model that actually plays a game against the generator net called the discriminator, that we represent with a function D. So D will look at the image that came from the generator and try to output a value near 0.",
                    "label": 0
                },
                {
                    "sent": "This value indicates the probability that the input is real rather than fake, so when the discriminator looks at fake samples coming from the generator, it tries to say that they have very low probability of being real.",
                    "label": 1
                },
                {
                    "sent": "Simultaneously, the generator tries to fool the discriminator into out putting a value near 1 so the generator tries to fool it into saying that its samples are real rather than fake.",
                    "label": 0
                },
                {
                    "sent": "We also train the discriminator on real data as shown on the left of this slide, where we load this actual photo of a face, and we trained the discriminator to say that it's real rather than fake.",
                    "label": 0
                },
                {
                    "sent": "You can analyze this with game theory and find that there is a situation called a Nash equilibrium where neither player can improve without having to modify the other players strategy.",
                    "label": 0
                },
                {
                    "sent": "And that Nash equilibrium corresponds to the generator recovering the training distribution.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There's also a few different ways of making hybrids of different generative models, so one of them is you can actually combine veessen guns instead of using the Gan to generate the data you use the gun to represent that Q distribution that you need for the variational autoencoder.",
                    "label": 0
                },
                {
                    "sent": "So usually when you make you distribution for variational autoencoder you use something like a Gaussian distribution and the problem is that Gaussian distribution is not very expressive.",
                    "label": 0
                },
                {
                    "sent": "On this slide I show you a few different posterior distributions.",
                    "label": 0
                },
                {
                    "sent": "The bottom row shows you the true posterior.",
                    "label": 0
                },
                {
                    "sent": "Two different cross sections of it.",
                    "label": 0
                },
                {
                    "sent": "The middle row shows you what happens when you use a Gaussian to approximate the posterior, and essentially you see that it has to pick one of the modes in each of the panels and zoom in on that mode, but discard the other one on the top row.",
                    "label": 0
                },
                {
                    "sent": "If you use again as a generator to sample from the posterior, you can actually recover.",
                    "label": 0
                },
                {
                    "sent": "Multiple modes because you now have this more complicated probabilistic model.",
                    "label": 0
                },
                {
                    "sent": "Generating the output data so it's worth mentioning.",
                    "label": 0
                },
                {
                    "sent": "I've shown you hear a figure from the most recent paper on this topic from Microsoft Research.",
                    "label": 0
                },
                {
                    "sent": "This is called adversarial variational Bayes, but it's building on top of several models that came earlier, including adversarial autoencoders.",
                    "label": 1
                },
                {
                    "sent": "Adversarially learned inference, and bygones.",
                    "label": 0
                },
                {
                    "sent": "Basically, those earlier models had less variability in the output that the gun could learn, like they might restrict it to a single mode of output.",
                    "label": 0
                },
                {
                    "sent": "It's also worth mentioning that if you want to make a variational autoencoder with a complicated posterior, you can also do that without guns.",
                    "label": 0
                },
                {
                    "sent": "You can do that, for example with inverse autoregressive flow.",
                    "label": 0
                },
                {
                    "sent": "That's actually the model that I showed earlier on the slide for variational autoencoders.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now that I've shown you more or less the family tree of how the different popular versions of deep generative models work, I'll tell you a little bit about the different things that you can do with generative models.",
                    "label": 0
                },
                {
                    "sent": "And I guess you're all students starting out your career in deep learning research, so I'd like you to think a little bit about where you see opportunities to dive in while we're going through this talk.",
                    "label": 0
                },
                {
                    "sent": "So you've seen now the tree of different models and some of the advantages and disadvantages of each of them.",
                    "label": 0
                },
                {
                    "sent": "You might start to think of ways that you could add a new branch to that tree that escape some of the disadvantages of the models we've seen already.",
                    "label": 0
                },
                {
                    "sent": "But in the second part of the talk, rather than thinking about how you might improve generative models.",
                    "label": 0
                },
                {
                    "sent": "You can see some of the ways that generative models have been used in the past, and you might think about new applications that you can solve with them.",
                    "label": 0
                },
                {
                    "sent": "So one thing that you can do with generative models is you can create simulated environments and training data.",
                    "label": 1
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A lot of the time, we don't necessarily know why we'd want a generative model.",
                    "label": 0
                },
                {
                    "sent": "Being able to create pictures is not always useful in and of itself, and a lot of the time we think it's much more useful to have something like a classifier or regression model that makes a prediction for us.",
                    "label": 0
                },
                {
                    "sent": "Well, it turns out that generative models can actually help you, even if all you care about is classification.",
                    "label": 0
                },
                {
                    "sent": "We've seen that it's possible to use generative models to create training data that can then go and train these models, so Apple's first ever research paper was about using a generative model to make training data for.",
                    "label": 0
                },
                {
                    "sent": "I gaze direction predictor.",
                    "label": 0
                },
                {
                    "sent": "They want to have a phone that can look at your face and use the camera to see your eyes and then tell which direction are your eyes pointing.",
                    "label": 0
                },
                {
                    "sent": "The problem is they don't have a large training set of lots of people with their eyes looking in a specific known point on the screen.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What they can do instead is they can use a 3D rendered model like I show in the lower left of this slide to make a synthetic rendering of an eyeball that's looking at a particular point on an imaginary screen, and so now they've got really good ground truth mapping from images of eyes to known eyeball directions.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately, these synthetic images are not very realistic looking, so they can take a generative model that's trained on real photos, and they can use that generative model to create what they call a refiner.",
                    "label": 0
                },
                {
                    "sent": "Where they take the synthetic images and they improve their realism to get an image that looks realistic and also has a known gaze direction that can actually be used to train the gaze direction predictor.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Another thing that you can do with generative models is you can handle missing data.",
                    "label": 1
                },
                {
                    "sent": "Usually when we have classifiers 30 find in terms of taking a whole vector X as input and then giving you an output value Y but in a lot of real world applications you don't always get the whole vector X and your goal may not be to predict why your goal might be to predict different entries of X given other entries of X.",
                    "label": 0
                },
                {
                    "sent": "This happens a lot, especially for medical data where there might be many different tests you could imagine running on a patient.",
                    "label": 0
                },
                {
                    "sent": "Like you could imagine, doing a lumbar puncture where you pull out some of their cerebral spinal fluid.",
                    "label": 0
                },
                {
                    "sent": "You can imagine doing like a biopsy on a tumor that they have and all these things are not only expensive but also painful.",
                    "label": 0
                },
                {
                    "sent": "Even if you had infinite money, you wouldn't want to pay for all these things because they can harm the patient and cause suffering.",
                    "label": 0
                },
                {
                    "sent": "So we would like to build machine learning models that can work if you give it only one of these tests.",
                    "label": 0
                },
                {
                    "sent": "If you say, oh, here's the biopsy, but we didn't do the lumbar puncture.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Because generative models define a probability distribution over the entire vector that you're studying, they can be used to solve all kinds of different inference problems related to different values that are missing from the vector that you're interested in.",
                    "label": 0
                },
                {
                    "sent": "So does anybody have a guess of what this image is?",
                    "label": 1
                },
                {
                    "sent": "If we could fill in the missing black pixels?",
                    "label": 0
                },
                {
                    "sent": "Yes, it's a face, but is it a male or female?",
                    "label": 0
                },
                {
                    "sent": "Yeah, so your brain can do this, but a standard classifier can't.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here's what a generative model gives us, so we actually fill in the male face just like you see with your your advanced neocortex.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But there's an especially important branch of the missing data problem, which is semi supervised learning where you're trying to train a classifier, but a lot of your output labels are missing in the training set you have a whole lot of unlabeled data and then just a small amount of labeled data.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "One way that we can solve this with generative models is using guns, usually for the discriminator we have two different outputs, one that says that the input is real and one that says that the output is fake.",
                    "label": 0
                },
                {
                    "sent": "Augusta Sardina and Tim Solomon's independently had an idea last year to replace the output of the discriminator with several different categories.",
                    "label": 0
                },
                {
                    "sent": "So if you want to recognize real cats in real dogs or the classifier, you can make the category of real katriel Dogan fake data.",
                    "label": 0
                },
                {
                    "sent": "I'll be categories that your discriminator learns about, and now when you train your discriminator you can.",
                    "label": 0
                },
                {
                    "sent": "You can actually change the discriminator on real images that have labels, and you tell them to assign the correct label.",
                    "label": 0
                },
                {
                    "sent": "So if you have a labeled image of a cat, you train the discriminator.",
                    "label": 1
                },
                {
                    "sent": "Say this is not only real, but it is specifically a real cat.",
                    "label": 0
                },
                {
                    "sent": "If you have an unlabeled image, you say that the sum of all the probabilities of the real classes should be high.",
                    "label": 0
                },
                {
                    "sent": "So if you have an unlabeled image, you don't know whether the dog or cat you say I want.",
                    "label": 0
                },
                {
                    "sent": "P of cat plus P of dog to be high and then finally if you have a fake image you want to maximize the probability of that class.",
                    "label": 0
                },
                {
                    "sent": "Tim Solomon's in particular found a lot of other extensions to this basic idea that made it perform really well for semi soup.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Revised learning on amnesty.",
                    "label": 0
                },
                {
                    "sent": "He was able using only 100 training examples to get down to about 86 mistakes out of 10,000 test examples just a few years before that, we needed all 60,000 labeled examples to get down to that level of error rate.",
                    "label": 0
                },
                {
                    "sent": "To give you some context, in 2014 I wrote a paper using all 60,000 labels where I was very proud of getting 78 mistakes and Tim is now down to 86 with only 100 labels.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This also works on Cifar 10 and S VHN.",
                    "label": 0
                },
                {
                    "sent": "It isn't quite as impressive on those as it is an amnesty.",
                    "label": 0
                },
                {
                    "sent": "For example, in SVN you wouldn't want to replace a fully supervised model with the semi supervised one yet.",
                    "label": 0
                },
                {
                    "sent": "Fully supervised model can get below 2% error and the semi supervised version got down to about 5.8.",
                    "label": 0
                },
                {
                    "sent": "This line of work has been followed up in the meantime.",
                    "label": 0
                },
                {
                    "sent": "Wrestling Salakhutdinov and his collaborators wrote a paper called Good Semi supervised learning that needs a bad Gan.",
                    "label": 0
                },
                {
                    "sent": "That improved on a lot of these numbers.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So another thing that you can do with generative models besides semi supervised learning is you can actually train the model to know that there are multiple correct answers and you can tell it that we want to get one of these correct answers.",
                    "label": 1
                },
                {
                    "sent": "Traditionally when we had regression models, what we would do is reduce the mean squared error between some specific known answer for some training data and the predictions of the model.",
                    "label": 0
                },
                {
                    "sent": "So if we wanted to train a regression model to say what's the price that a house will solve for?",
                    "label": 0
                },
                {
                    "sent": "We might have an example of a house in the training set where we know the price that it sold for, and we tell the model we want you to output as close as possible to that price.",
                    "label": 0
                },
                {
                    "sent": "You can think about is being extremely simple generative model, which is a Gaussian distribution conditioned on the input.",
                    "label": 0
                },
                {
                    "sent": "But the nature of this mean squared error loss or this Gaussian output distribution means that you sort of blur together all of the different possible answers associated with the ginput.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we see how this works with video prediction.",
                    "label": 0
                },
                {
                    "sent": "Let's look at this frame from paper by William Lauder on predicting videos of 3D heads as their animated.",
                    "label": 0
                },
                {
                    "sent": "We know that this 3D head is going to rotate a little bit in the next frame, and we can kind of visualize what it might look like, but there are very many different possible futures.",
                    "label": 0
                },
                {
                    "sent": "We don't know exactly how far it's going to move, so if we use mean squared error on several different examples where we try to predict the next frame given the current frame, we're going to see a lot of different possible futures.",
                    "label": 0
                },
                {
                    "sent": "While we do that.",
                    "label": 0
                },
                {
                    "sent": "And we'll end up averaging a lot of them together, and we'll get an image that's kind of blurry.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's what actually happens on the left if we use.",
                    "label": 0
                },
                {
                    "sent": "The ground truth image what the actual next frame looks like in the middle we see what happens if we train with mean squared error where the output is essentially a Gaussian distribution.",
                    "label": 0
                },
                {
                    "sent": "We actually get a lot of blurring to the point where the person's ear more or less disappears and the eye is not very crisp at all.",
                    "label": 0
                },
                {
                    "sent": "On the right we see what happens if we use a richer generative model that's able to understand that there are multiple possible futures and capture a distribution over all of them were not able to get samples that are individually crisp, and so we can actually see many different specific features that are all possible.",
                    "label": 0
                },
                {
                    "sent": "Instead of blurring many of them.",
                    "label": 0
                },
                {
                    "sent": "To get one image that is not representation representative of any of them.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There are also a lot of tasks where what you actually want to do is just generate realistic data.",
                    "label": 0
                },
                {
                    "sent": "A lot of us are working on solving healthcare problems or building self driving cars or figuring out which adds to show people and we don't really think of generating images is something useful, but there are actually media companies that make special effects and there are companies like Adobe that make tools for building these media products and these people really do need to generate realistic data.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So one example of this is a model called Igam stands for Interactive again.",
                    "label": 0
                },
                {
                    "sent": "And let's see if my Internet connection is good enough to play the YouTube video for you.",
                    "label": 0
                },
                {
                    "sent": "Looks like maybe my Internet is too slow here, so I'll just show you the thumbnail.",
                    "label": 0
                },
                {
                    "sent": "The idea behind again is that it assists an artist that you don't need to actually have real artistic skill.",
                    "label": 0
                },
                {
                    "sent": "You can have like Ms Paint 101 level skill at drawing on a computer, and you draw a very simple sketch and then I again will search for the nearest natural image that has high probability according to the model.",
                    "label": 0
                },
                {
                    "sent": "The basic idea is that in this slide.",
                    "label": 0
                },
                {
                    "sent": "The user has scribbled some green paint down here.",
                    "label": 0
                },
                {
                    "sent": "Just a few WAVY green lines and the model has turned it into a lush Greenfield.",
                    "label": 0
                },
                {
                    "sent": "And then they've also drawn just as sharp black triangle with no real details.",
                    "label": 0
                },
                {
                    "sent": "And the model has turned it into a mountain.",
                    "label": 0
                },
                {
                    "sent": "You can also see on the right there's several different possible samples that you can choose from, so you get a real probability distribution over different things.",
                    "label": 0
                },
                {
                    "sent": "You might want to draw.",
                    "label": 0
                },
                {
                    "sent": "The question is, is this with auto dryers and I actually don't know about auto draw, so I'm afraid I don't know.",
                    "label": 0
                },
                {
                    "sent": "Like oh right?",
                    "label": 0
                },
                {
                    "sent": "OK yeah.",
                    "label": 0
                },
                {
                    "sent": "Auto draw I should know more about because that's my colleague who made that it's a different kind of generative model, but it's still the basic principle that you can have generative models that clean up what you're what you've drawn.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There's another thing called introspective adversarial networks that's very similar to again, and the applications they specialized on with editing faces, so you can actually change the position of peoples hair line, whether they're wearing glasses or not, and so on.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There's another technique called image to image translation where you want to go from one kind of image to another kind of image.",
                    "label": 0
                },
                {
                    "sent": "You might want to take an aerial photo and turn it into a map like I've shown on the lower left, or you might have a bitmap specifying what kind of object you would like to have at every pixel in an image.",
                    "label": 0
                },
                {
                    "sent": "So on the upper left I show you this map of the road scene, where Magenta says Wetherby Rd Pixels.",
                    "label": 0
                },
                {
                    "sent": "Blue says we want there to be cars and so on, and then an image to image translation model can actually generate.",
                    "label": 1
                },
                {
                    "sent": "A picture of such a street scene with the road in cars in that place so you can use this to make simulated training data for self driving cars.",
                    "label": 0
                },
                {
                    "sent": "And you can think of you know very difficult situations where those cars boxing you in that might not occur very often in real training data and so you can exercise the model on more difficult scenarios.",
                    "label": 1
                },
                {
                    "sent": "The reason we need a generative model to do this is that for most of these image to image translation techniques there are multiple correct answers.",
                    "label": 0
                },
                {
                    "sent": "Just like earlier I showed you how the rotating head would become blurry if we try to use mean squared error to guess what the next rotating head would look like.",
                    "label": 1
                },
                {
                    "sent": "We would end up with blurry images if we try to use mean squared error to train a model to map inputs to outputs.",
                    "label": 0
                },
                {
                    "sent": "You can especially see this for turning sketches and two photos.",
                    "label": 0
                },
                {
                    "sent": "So on the right side I show you what happens if you build a training set.",
                    "label": 0
                },
                {
                    "sent": "By taking a lot of photos, running edge detection on them to get edge images, and now you have these pairs of edge images and color images, and you can train a model to invert that process where it takes an edge image as input and produces a photo as output.",
                    "label": 0
                },
                {
                    "sent": "You can see how there's two different columns of photos here.",
                    "label": 1
                },
                {
                    "sent": "Both the ground truth and the real output.",
                    "label": 1
                },
                {
                    "sent": "You can see that the real output often is a different color than the ground truth, and that's because the model isn't psychic.",
                    "label": 0
                },
                {
                    "sent": "It doesn't know the color that's actually in the ground truth that we want to fill in, so it's given us a different legitimate color, and it's able to do that because it's a conditional generative model that can produce many different samples rather than needing to try to come up with one mean value that represents all the different photos it sees in the training set.",
                    "label": 0
                },
                {
                    "sent": "Still sort of close, right?",
                    "label": 0
                },
                {
                    "sent": "How's?",
                    "label": 0
                },
                {
                    "sent": "It seems a little psychic.",
                    "label": 0
                },
                {
                    "sent": "Oh, like you're saying it's still close in the sense that like it's a 10 purse versus a Brown purse, I think it's mostly the purses tend to be leather.",
                    "label": 0
                },
                {
                    "sent": "2nd row, it's not nearly as close like like see the 2nd row.",
                    "label": 0
                },
                {
                    "sent": "It's green, but it's made it leather.",
                    "label": 1
                },
                {
                    "sent": "The model is made it leather everywhere.",
                    "label": 0
                },
                {
                    "sent": "You actually see this alot for image colorization.",
                    "label": 0
                },
                {
                    "sent": "Image colorization is another thing you can do is an example of image image translation, so image colorization is where you take a grayscale image and you turn it into a color image and a lot of the time you'll find that for objects that can have two different popular colors like apples are often green or often read, you'll find that the model turns those objects Gray or rather just leaves them Gray because it's averaging out the mode of green apples and the motive red apples.",
                    "label": 0
                },
                {
                    "sent": "If you then use a generative model that can represent both modes.",
                    "label": 0
                },
                {
                    "sent": "It will successfully turn the apples either green or red.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in the example I showed you so far, we actually had supervised learning to train these image to image translation models.",
                    "label": 0
                },
                {
                    "sent": "So we would take a photo.",
                    "label": 0
                },
                {
                    "sent": "We would extract its edges and then we would use the edges as the input to a supervised model and reduce the corresponding photo as the output target for that supervised learning process.",
                    "label": 0
                },
                {
                    "sent": "It turns out that you can also learn to translate from one image to one image domain to another without supervision.",
                    "label": 0
                },
                {
                    "sent": "So instead of having pairs of images that go with each other, you have a bunch of images from domain A and a bunch of images from domain B, but you don't tell them all the correspondence between them in this paper.",
                    "label": 0
                },
                {
                    "sent": "From NVIDIA research, we see how you can take a collection of images of day scenes and a collection of images of night scenes, and you can learn to turn a day scene into the equivalent night scene, and it would be really hard to try to do this with supervised learning, because how would you actually gather the ground truth data?",
                    "label": 0
                },
                {
                    "sent": "You'd have to find all the cars that were there at the time and drive them back to the exact same position at night.",
                    "label": 0
                },
                {
                    "sent": "You just you wouldn't be able to do it in a natural environment the way that this works basically is you train a generative model that takes an input value from one domain as it's Z vector and transforms it into a sample from the other domain.",
                    "label": 0
                },
                {
                    "sent": "And what that means, instead of using something like Gaussian noise, is the input to the model.",
                    "label": 0
                },
                {
                    "sent": "We're actually using images from one domain as the input.",
                    "label": 0
                },
                {
                    "sent": "And we just want to be a good generator of the other domain.",
                    "label": 0
                },
                {
                    "sent": "And it turns out that the easiest way to be a good generator of the other domain is to find the true correspondence between the two domains.",
                    "label": 0
                },
                {
                    "sent": "Usually you can bias the model toward doing this by putting restrictions on how much it can change the image, and so on and so forth, but it works remarkably well, and it also works with very few training examples, like maybe only a couple of 100, which is really unusual for deep learning.",
                    "label": 0
                },
                {
                    "sent": "Where were you still wanting?",
                    "label": 0
                },
                {
                    "sent": "10s of thousands?",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One of my favorite examples of this kind of image to image translation is the cycle Gan model from UC Berkeley.",
                    "label": 0
                },
                {
                    "sent": "Here they trained a model on a bunch of images of horses and a bunch of images of zebras.",
                    "label": 0
                },
                {
                    "sent": "They didn't have any corresponding horses and corresponding zebras, because how would you gather those?",
                    "label": 0
                },
                {
                    "sent": "You'd have to go out in the field and twist the zebra into the horse position.",
                    "label": 0
                },
                {
                    "sent": "And they are now running it on this video of a horse running back and forth and we can see it turns it into a zebra cycle.",
                    "label": 0
                },
                {
                    "sent": "Count is restricted in how much you can change the image.",
                    "label": 0
                },
                {
                    "sent": "It wants to make only very local edits so you can see it has a little bit of trouble with some things like the horses tail.",
                    "label": 0
                },
                {
                    "sent": "Zebra tails don't have the same shape as horse tails and so it doesn't actually successfully make a zebra tail.",
                    "label": 0
                },
                {
                    "sent": "And state makes a striped horsetail.",
                    "label": 0
                },
                {
                    "sent": "Also.",
                    "label": 0
                },
                {
                    "sent": "Zebras have a standing Maine on the back of their neck.",
                    "label": 0
                },
                {
                    "sent": "Horses have a main that hangs down over their neck.",
                    "label": 0
                },
                {
                    "sent": "You can see that it struggles a little bit to try to erase where the horses neck, where the where the main hangs down over the horses neck.",
                    "label": 0
                },
                {
                    "sent": "It tries to sort of conceal that hair with zebra stripes.",
                    "label": 0
                },
                {
                    "sent": "An another interesting thing is there isn't anything here designed for video in particular, but the stripes are still relatively stable from one frame to the next.",
                    "label": 0
                },
                {
                    "sent": "The main glitch in the way that the stripes move is that when the horse turns his head point weapons for right now, the stripes are relatively stationary in the image and the horses head moves across the stripes.",
                    "label": 0
                },
                {
                    "sent": "One other thing you might see is that the background is very different.",
                    "label": 0
                },
                {
                    "sent": "This is trained on pictures of horses living in pastures and zebras living in savannahs.",
                    "label": 0
                },
                {
                    "sent": "So the background foliage actually turns to look more Savannah, like a lot of the time, you'll see that different machine learning algorithms have interesting implicit biases built into them, and it's important to think about the kind of biases that your data set produces for this, where we're just having fun turning images of horses into zebras, it's all harmless fun, but if you're using your machine learning algorithm to make important decisions that affect peoples lives, you should think about what kind of impact the choice of your training examples will have on the decisions that it will actually make.",
                    "label": 0
                },
                {
                    "sent": "If it's doing something like approving mortgages or approving parole applications.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another kind of realistic image generation task that you can do with generative models is text to image synthesis.",
                    "label": 0
                },
                {
                    "sent": "So a few years ago the Ms Coco data set came out with images and captions and everyone started publishing image captioning papers where you would have a neural net look at an image and output the caption.",
                    "label": 0
                },
                {
                    "sent": "Now it's actually possible to do the reverse using a model called STACK.",
                    "label": 0
                },
                {
                    "sent": "Again, we can take these sentences describing birds and we can produce high resolution 256 by 256 photos of birds.",
                    "label": 0
                },
                {
                    "sent": "In the corresponding position.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another thing that you can do is you can actually.",
                    "label": 0
                },
                {
                    "sent": "Run simulations using a predictive model rather than explicitly simulating the predictions you want to make.",
                    "label": 0
                },
                {
                    "sent": "That sounds kind of abstract, so I'm going to give you a call.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Example, if you're doing high energy particle physics, you have particles that you collide in a particle accelerator and they I guess, explode.",
                    "label": 0
                },
                {
                    "sent": "I'm not really a particle physicist, so some of you are probably going to be face palming.",
                    "label": 0
                },
                {
                    "sent": "Why discribed this?",
                    "label": 0
                },
                {
                    "sent": "But basically the particles collide and pieces of them go flying out in different directions and energy radiates outward and you can use a calorimeter to make what's called a jet image which is this bitmap that I've shown here.",
                    "label": 0
                },
                {
                    "sent": "Where the calorimeter actually shows how much energy lands at different points on the grid on the calorimeter.",
                    "label": 0
                },
                {
                    "sent": "I physicists often produce these images, not using a real particle accelerator, but using a computational model where they actually understand how all the different steps in the reaction occur and they have a computer explicitly simulate those steps and a lot of them are stochastic steps, so it's a Monte Carlo simulation where you virtually roll a dice, decide what happens in each step, but basically you explicitly go through an imagine many different tiny concrete steps happening.",
                    "label": 0
                },
                {
                    "sent": "And it's very computationally expensive.",
                    "label": 0
                },
                {
                    "sent": "A generative model can learn a conditional distribution over jet image outcomes given the conditions of the experiment.",
                    "label": 0
                },
                {
                    "sent": "So we can kind of by Association learn to simulate almost by muscle memory, and it can be computationally much cheaper and save millions of dollars of CPU time to do these predictive experiments, rather than doing the Monte Carlo ones.",
                    "label": 1
                },
                {
                    "sent": "It's important to keep in mind that the prediction might introduce some errors.",
                    "label": 0
                },
                {
                    "sent": "And so the authors of this paper spent a lot of time evaluating the different ways in which the samples from the generative model were realistic or unrealistic.",
                    "label": 0
                },
                {
                    "sent": "But overall, it does seem like it was a useful tool for them.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another thing that you can do with generative models is you can learn useful embeddings for different kinds of data.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We've seen how you can learn word embeddings using recurrent networks.",
                    "label": 0
                },
                {
                    "sent": "It turns out that generative models can also learn embeddings for images, and presumably for other kinds of data that you could you could generate in this example from the DC Gan paper by Alec Redford and his collaborators, we see what happens if we take a latent space vector representing the concept of a man with glasses.",
                    "label": 1
                },
                {
                    "sent": "So I represent the vector with the image that it decodes to here.",
                    "label": 1
                },
                {
                    "sent": "That's not a real man with glasses.",
                    "label": 0
                },
                {
                    "sent": "That's something confabulated by the model.",
                    "label": 0
                },
                {
                    "sent": "I think Alex found this by averaging together several different vectors that all corresponded to men with glasses.",
                    "label": 0
                },
                {
                    "sent": "You can then subtract off the vector representing the concept of a man, which I've also shown the decoded image of the man here and then you can add a vector representing the concept of a woman and you get a new vector that if you decode several noisy versions of that vector, you get several images of women with glasses, so you're actually able to do arithmetic in latent vector space, and this could enable lots of different things like.",
                    "label": 1
                },
                {
                    "sent": "Hashing images to look up similar images or search over a database to look for image duplicates and remove duplicates.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can also work on learning how to make the latent codes become more interpretable, so you can try to design generative models where one particular value of the latent code will correspond to, for example, the lighting in an image, and you can make an image that is brighter or darker as you want by changing that latent variable.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So one of the most exciting recent developments in generative models is a paper called Plug and Play Generative Networks.",
                    "label": 1
                },
                {
                    "sent": "It came out in December 2016.",
                    "label": 0
                },
                {
                    "sent": "I believe it makes 227 by 227 images.",
                    "label": 0
                },
                {
                    "sent": "That's pretty high resolution by current standards.",
                    "label": 0
                },
                {
                    "sent": "Maybe the highest resolution of any of the deep models.",
                    "label": 0
                },
                {
                    "sent": "And it's trained on image net and it really combines a lot of the different techniques that we've talked about.",
                    "label": 0
                },
                {
                    "sent": "It uses adverse aerial training like we used for guns.",
                    "label": 1
                },
                {
                    "sent": "It uses moment matching, which we didn't discuss a whole lot in this talk and also denoising autoencoders and Monte Carlo methods of generating samples using a large event sampling.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "These are some of the samples that it makes it for each of the different image net categories you can get realistic images where you can actually recognize the object in the image you can see that there's actually this bird species called a redshank.",
                    "label": 0
                },
                {
                    "sent": "You can see recognizable ants and volcanoes and so on.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It can also make images that correspond to specific captions, so you can take a sentence like oranges on a table next to a liquor bottle, and you get these images.",
                    "label": 0
                },
                {
                    "sent": "I actually, I don't see the liquor bottle for sure, but the oranges are pretty distinct and I guess there's a shape that looks somewhat like a liquor.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well.",
                    "label": 0
                },
                {
                    "sent": "The basic idea is that you have a.",
                    "label": 1
                },
                {
                    "sent": "Large events sampling chain.",
                    "label": 0
                },
                {
                    "sent": "So this is a kind of Monte Carlo method.",
                    "label": 0
                },
                {
                    "sent": "Like I said at the start of the talk I showed how GSN's and deep Boltzmann machines use a Markov chain to repeatedly update their samples.",
                    "label": 0
                },
                {
                    "sent": "Lunch event sampling is a special version of this that follows the gradient of the log density with some extra noise and the way that this paper works that's different from previous approaches is that it uses denoising autoencoders to estimate that gradient instead of.",
                    "label": 1
                },
                {
                    "sent": "Explicitly computing that gradient exactly, and the denoising autoencoder has been trained with several different losses that do things like activate different features in a pre trained Imagenet classifier which helps to get these real.",
                    "label": 1
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Very realistic examples of images from the image net data set.",
                    "label": 0
                },
                {
                    "sent": "It's also trained with.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "An adversarial loss where you train it to make the reconstructions look realistic.",
                    "label": 0
                },
                {
                    "sent": "So if you train with.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just reconstruction lost the image on the right.",
                    "label": 0
                },
                {
                    "sent": "Struggles to get this this pink bird looking highly realistic, but if you also include the adversarial loss it will become more realistic looking.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you don't actually use any classes to guide the learning process, you get images that don't look as much like realistic image net classes.",
                    "label": 0
                },
                {
                    "sent": "This is something that applies to lots of different kinds of generative models, including ganzan Bolton machines.",
                    "label": 0
                },
                {
                    "sent": "I'm not, I'm not sure about variational autoencoders, but basically the labels seem to guide the generative model toward making object classes that we recognize.",
                    "label": 0
                },
                {
                    "sent": "It's kind of an interesting philosophical question.",
                    "label": 0
                },
                {
                    "sent": "Is the model without the labels?",
                    "label": 0
                },
                {
                    "sent": "Wrong?",
                    "label": 0
                },
                {
                    "sent": "Or are we wrong?",
                    "label": 0
                },
                {
                    "sent": "It is the human brain latching on to things that are are relevant to our reward function rather than latching on to things that are actually part of the probability distribution of a real values.",
                    "label": 0
                },
                {
                    "sent": "Or is there something that the model fails to fit in the true probability density function that the labels helped to capture?",
                    "label": 0
                },
                {
                    "sent": "It's kind of an interesting open problem and I don't really have a strong opinion on what the answer is.",
                    "label": 0
                },
                {
                    "sent": "I actually lean a little bit toward thinking that.",
                    "label": 0
                },
                {
                    "sent": "Our model of the world is subjective and that we tend to notice things that are relevant to our reward function, but that's a very difficult thing to prove.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I went in the other direction.",
                    "label": 0
                },
                {
                    "sent": "The labels guide you toward capturing the true distribution better.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that arm.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "I guess.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let me refine my positional by saying I think, given the training data that you have, I don't feel like the solution that the models produces objectively less correct than the one that has objects in it.",
                    "label": 0
                },
                {
                    "sent": "But it's clear that the world contains objects, so so they're wrong in that sense.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I guess plug and play generative networks are pretty much the state of the art for generating image net images, and they combine a lot of the different ideas that we saw throughout the talk.",
                    "label": 0
                },
                {
                    "sent": "And you can use generative models for many different applications that I showed you.",
                    "label": 0
                },
                {
                    "sent": "Now that you've seen sort of a span of.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If the tree of models that you can build and how they work, and you've seen a list of the different applications that you can do with generative models, you are ready for the second generative models class by Aaron, where he'll zoom into more detail on some of these things.",
                    "label": 0
                },
                {
                    "sent": "Also, if you want more information on a lot of these subjects, you should check out the book that we all wrote together, which contains many chapters on generative models and the different techniques like variational learning that are the basis for a lot of them.",
                    "label": 0
                },
                {
                    "sent": "And I'm free for questions.",
                    "label": 0
                },
                {
                    "sent": "Can you repeat the question now that people are a little quieter?",
                    "label": 0
                },
                {
                    "sent": "OK, so the question is how do you reduce the checkerboard effect from generated images and?",
                    "label": 0
                },
                {
                    "sent": "Let me see if I can pull up a web browser or not because not everyone might be familiar with what you're asking about.",
                    "label": 0
                },
                {
                    "sent": "Wild big.",
                    "label": 0
                },
                {
                    "sent": "So the question is, is there a difference between training the discriminator with only fake data and versus?",
                    "label": 0
                },
                {
                    "sent": "Should.",
                    "label": 0
                },
                {
                    "sent": "Twice.",
                    "label": 0
                },
                {
                    "sent": "Oh like should they be in the same mini batch or not?",
                    "label": 0
                },
                {
                    "sent": "Is that what you mean by concatenated concatenated along the axis correspond to the batch size.",
                    "label": 0
                },
                {
                    "sent": "Yeah, OK, so the question is when we train discriminator for again, we could imagine making one mini batch of data that contains both real and fake examples.",
                    "label": 0
                },
                {
                    "sent": "Or you could imagine doing too many batches, one with real examples in one of the fake examples first, some kind of guns.",
                    "label": 0
                },
                {
                    "sent": "It actually doesn't matter.",
                    "label": 0
                },
                {
                    "sent": "The loss function is additive across different examples.",
                    "label": 0
                },
                {
                    "sent": "And so if you just compute the loss on two batches and add it together, you'll get the same thing as if you computed the loss in one larger batch.",
                    "label": 0
                },
                {
                    "sent": "The situation where it starts to matter a lot is if you're using batch normalization, so batch normalization will subtract off the mean of every feature in the mini batch and divide by the variance of every feature in the mini batch.",
                    "label": 0
                },
                {
                    "sent": "One of the things that Alec, Radford, and Smith telephoned when they created the DC Gan is something very counter intuitive.",
                    "label": 0
                },
                {
                    "sent": "If you use all of your data in one mini batch, the batch normalization for the discriminator doesn't work nearly as well.",
                    "label": 0
                },
                {
                    "sent": "It works better if you apply the discriminator to all the real data.",
                    "label": 0
                },
                {
                    "sent": "I'm going to play it separately to all the fake data, so the features for the real data are normalized using statistics from the real data and the features for the generated data are normalized.",
                    "label": 0
                },
                {
                    "sent": "Using statistics from the fake data, it's very counter intuitive because it means you're technically applying a different function to the real data than to the fake data.",
                    "label": 0
                },
                {
                    "sent": "That bothers a lot of people, theoretically.",
                    "label": 0
                },
                {
                    "sent": "For me it seems aesthetically not very pleasing, so I tried doing a thing where for every layer I divide the features into two groups.",
                    "label": 0
                },
                {
                    "sent": "So the first half of the features in the second half of the features and I run everything in one mini batch.",
                    "label": 0
                },
                {
                    "sent": "I normalized the first half of the features on the real data and I normalize the second half of the features on the fake data.",
                    "label": 0
                },
                {
                    "sent": "So I think what's going on is that batch norm works best if the data from each category gets normalized and having half the features we normalized in the real data and have the features they normalized affected.",
                    "label": 0
                },
                {
                    "sent": "I mean some of the features always get a good learning signal where they are in their normal regime for each category of data.",
                    "label": 0
                },
                {
                    "sent": "The interesting thing is, even though this version where we apply the same function to both sets of examples is more theoretically straightforward, it doesn't seem to work any better than batch mobilizing the two groups separately.",
                    "label": 0
                },
                {
                    "sent": "It works about the same.",
                    "label": 0
                },
                {
                    "sent": "I tend to use the version where I batch normalize half the features on one side and half the features of the other set.",
                    "label": 0
                },
                {
                    "sent": "Just because the theory makes sense to me, but there isn't actually an empirical reason to do it.",
                    "label": 0
                },
                {
                    "sent": "So checkerboard, yeah.",
                    "label": 0
                },
                {
                    "sent": "So the earlier question where I waited for the website to come up with is a lot of these models get checkerboard artifacts, and so this is by this is a paper by Augustus Idina, who's on my team at Google Brain.",
                    "label": 0
                },
                {
                    "sent": "This is before he joined my team.",
                    "label": 0
                },
                {
                    "sent": "If it's not normal in here, Mila and Chris all day also at Google Brain they take a picture that I made actually of this polar bear thing generated by again and if you zoom in on it so you move this mouse around you can see that there's.",
                    "label": 0
                },
                {
                    "sent": "This very fine checkerboard pattern.",
                    "label": 0
                },
                {
                    "sent": "What's going on there is, as you move your convolution kernel around it overlaps with itself by different amounts at different positions in the image, so it places where the convolution kernel overlaps multiple times you get more input values coming to that pixel, and so it might have larger values.",
                    "label": 0
                },
                {
                    "sent": "It might be a more white or more black rather than grey pixel in the image.",
                    "label": 0
                },
                {
                    "sent": "There's a few different ways that you can resolve this, and there's a recommendation in this paper.",
                    "label": 0
                },
                {
                    "sent": "I've also heard recommendations from other people recommendation in this paper.",
                    "label": 0
                },
                {
                    "sent": "If I remember right, is to use a stride that is a factor of the kernel size so that you end up without these different amounts of overlap.",
                    "label": 0
                },
                {
                    "sent": "My friend dirt Kingma has also told me that if you fix the artifact at the boundary of the image, where at the very sight of the image, there's fewer convolution kernels stacked up here.",
                    "label": 0
                },
                {
                    "sent": "If you compensate for that difference in number of convolution kernels at that position, he says that that will also fix the checkerboard artifacts he thinks what's going on there is that if you have a weird artifact at the edge of the image, then your kernels need to have large values on the edge of the kernel in order to compensate for that.",
                    "label": 0
                },
                {
                    "sent": "But then there's large values at the edge of the kernel appear throughout the rest of the images.",
                    "label": 0
                },
                {
                    "sent": "Well, it seems a little bit architecture dependent in my opinion.",
                    "label": 0
                },
                {
                    "sent": "It seems like both both techniques work.",
                    "label": 0
                },
                {
                    "sent": "And depending on the architecture, using one trick or the other might work better or worse.",
                    "label": 0
                },
                {
                    "sent": "Another thing that you can do is dilated convolution, where you're kernel is spaced out.",
                    "label": 0
                },
                {
                    "sent": "So instead of being applied to like if you have a kernel that's with three instead of applying it to three consecutive pixels, you apply it to one pixel, and then if you have a dilation rate of two, you would skip two pixels over and apply the next member of the kernel and then skip another two pixels and apply the third Member.",
                    "label": 0
                },
                {
                    "sent": "If you do dilated convolution with the right spacing, it's a little bit like doing subpixel sampling, and that can also reduce checkerboarding a little bit.",
                    "label": 0
                },
                {
                    "sent": "Is there a way to evaluate how good generative modeling?",
                    "label": 0
                },
                {
                    "sent": "So the question is, is there a way to evaluate how good a generative model is?",
                    "label": 0
                },
                {
                    "sent": "There's a paper everyone should read, called a note on the evaluation of generative models.",
                    "label": 0
                },
                {
                    "sent": "The paper basically says no.",
                    "label": 0
                },
                {
                    "sent": "So, so there are several ways of evaluating generative models, but they all have different strengths and weaknesses to boil it down a little bit.",
                    "label": 0
                },
                {
                    "sent": "One thing you can do is you can look at how good the density function function is at assigning high density to test set points.",
                    "label": 0
                },
                {
                    "sent": "And another thing you can do is you can look at how realistic are the samples that come out of the model in this paper about a note on the evaluation of generative models.",
                    "label": 0
                },
                {
                    "sent": "They argue that there are some models that have really good density on test points that make really bad samples.",
                    "label": 0
                },
                {
                    "sent": "And there are some models that make really good samples that have really bad density on test points.",
                    "label": 0
                },
                {
                    "sent": "So for example, variational autoencoders tend to be a lot better.",
                    "label": 0
                },
                {
                    "sent": "Assigning high density to most points and guns tend to be better at producing realistic samples, but lots of generative models exist somewhere in the spectrum, and those are just two that I'm more familiar with myself.",
                    "label": 0
                },
                {
                    "sent": "There's a few other things that are difficult about evaluating generative models.",
                    "label": 0
                },
                {
                    "sent": "One is that so many of them rely on approximations, so if you compare two different families of models.",
                    "label": 0
                },
                {
                    "sent": "It can be hard to tell whether one has the data density better than the other or if it's just that the approximations are making it look like one is better.",
                    "label": 0
                },
                {
                    "sent": "So for example variational autoencoders.",
                    "label": 0
                },
                {
                    "sent": "You can very easily compute a lower bound where you know that the real probability is better than what you have.",
                    "label": 0
                },
                {
                    "sent": "There is some models where you use Monte Carlo methods to get a stochastic estimate of the density that they're assigning to the data, and a lot of these Monte Carlo.",
                    "label": 0
                },
                {
                    "sent": "Methods are biased toward overestimating the density, so the number that you get from the variational autoencoder is probably not quite as good as it really is, and the number that you get for some of these Markov chain based models is often an average better than what you would actually get.",
                    "label": 0
                },
                {
                    "sent": "There is also funny situations where if you do a worse job of evaluative implementing your evaluation code, you get a higher number, and so people have an incentive to not try very hard to make their evaluation good, and that muddies the waters further.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Looks like your connection works now.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I can try to do that.",
                    "label": 0
                },
                {
                    "sent": "Here we go.",
                    "label": 0
                },
                {
                    "sent": "So it's possible that my connection is working, but just not fast enough for YouTube.",
                    "label": 0
                },
                {
                    "sent": "Just second more.",
                    "label": 0
                },
                {
                    "sent": "So let me skip ahead a little bit here.",
                    "label": 0
                },
                {
                    "sent": "They're showing how they can use the again to edit an image of a handbag.",
                    "label": 0
                },
                {
                    "sent": "And we're already buffering again.",
                    "label": 0
                },
                {
                    "sent": "The basic idea is that suppose you have this image of a handbag and you know that you want something similar to it, but a little bit smaller and a different color.",
                    "label": 0
                },
                {
                    "sent": "You can use the paint to actually change the kind of bag that you get, and then you can use the reverse image search to look for bags of that kind so you can use it as like an assisted shopping tool basically.",
                    "label": 0
                },
                {
                    "sent": "I can also show you the animated version of.",
                    "label": 0
                },
                {
                    "sent": "I described it's going on in the thumbnail here, but once it loads you can see the animation of sketching the grass and mountain scene.",
                    "label": 0
                },
                {
                    "sent": "So the user just painted with green paint and got the grass.",
                    "label": 0
                },
                {
                    "sent": "And they're choosing from different samples from the distribution together when they like the most.",
                    "label": 0
                },
                {
                    "sent": "Now they're sketching with black paint to add the mountain.",
                    "label": 0
                },
                {
                    "sent": "Another sketching with blue paint to add this guy and the model in real time adepts.",
                    "label": 0
                },
                {
                    "sent": "The image to look like what they're sketching.",
                    "label": 0
                },
                {
                    "sent": "So if I need to generate more data, this means that my training set.",
                    "label": 0
                },
                {
                    "sent": "One can.",
                    "label": 0
                },
                {
                    "sent": "Source.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so the question is if you don't have enough data and you want to make more went down the guns also need data.",
                    "label": 0
                },
                {
                    "sent": "So one way that guns can help you is if they have access to some kind of information that your classifier you want to train wouldn't have.",
                    "label": 0
                },
                {
                    "sent": "So for.",
                    "label": 0
                },
                {
                    "sent": "For the example from Apple, where they trained the refiner to make the images look better, the refiner can make use of unlabeled images of photos to learn about how realistic eyes look.",
                    "label": 0
                },
                {
                    "sent": "We don't actually know where those photos of eyes are pointed, so they can't be used to train the eye direction prediction model, but they can be used to train the generative model that knows how they look.",
                    "label": 0
                },
                {
                    "sent": "In the example of semi supervised learning, by having a discriminator that recognizes different real classes and then also the fake class, it's able to learn from fake images.",
                    "label": 0
                },
                {
                    "sent": "It's able to learn from unlabeled images and a traditional classifier would only be able to learn from labeled images.",
                    "label": 0
                },
                {
                    "sent": "So that's the way that it gets additional data is that you have data where you couldn't obtain the labels for one reason or another.",
                    "label": 0
                },
                {
                    "sent": "Another thing that's kind of interesting is these image to image translation models.",
                    "label": 0
                },
                {
                    "sent": "They don't actually need very many examples like only a few 100.",
                    "label": 0
                },
                {
                    "sent": "I didn't realize that until I went to visit Berkeley a few weeks ago.",
                    "label": 0
                },
                {
                    "sent": "An filippello is telling me that he was surprised that these required very few examples to get them going.",
                    "label": 0
                },
                {
                    "sent": "I don't really know why it is.",
                    "label": 0
                },
                {
                    "sent": "It would be an interesting thing to study.",
                    "label": 0
                },
                {
                    "sent": "So as soon as the generator is broken or anything like reasonable sample.",
                    "label": 0
                },
                {
                    "sent": "Then nothing forces there Gan to generate like more samples basically.",
                    "label": 0
                },
                {
                    "sent": "So there's a variety of generated samples are not as much as like the real data, and that's because they like the mean masking mean, Max cost function and again pushes the generated samples who.",
                    "label": 0
                },
                {
                    "sent": "Who are the area of a manifold that have high probability?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So personal my first question is that is it the problem at all or in my second question is that is there any solution around that?",
                    "label": 0
                },
                {
                    "sent": "So the question is basically, is the mode collapse problem in guns of a problem?",
                    "label": 0
                },
                {
                    "sent": "I guess the way I worded I serve answered it.",
                    "label": 0
                },
                {
                    "sent": "And is there a solution to it so I would save mode?",
                    "label": 0
                },
                {
                    "sent": "Collapse is probably the biggest problem for games.",
                    "label": 0
                },
                {
                    "sent": "The cause is not entirely clear.",
                    "label": 0
                },
                {
                    "sent": "It might be something to do with the cost function, but I actually don't think so.",
                    "label": 0
                },
                {
                    "sent": "It might be something to do with the way that the learning dynamics work, but.",
                    "label": 0
                },
                {
                    "sent": "Starting to look a little bit less likely given some recent results, and I'll explain to everybody that in a second, and I actually think it might be something related to the model family that we use in ways that are kind of strange and hard to understand from the knowledge I have.",
                    "label": 0
                },
                {
                    "sent": "So one thing I've seen that's kind of interesting is if I take an autoencoder, not a variational autoencoder, just a regular load.",
                    "label": 0
                },
                {
                    "sent": "The input propagate through the network, reconstruct the output type auto encoder.",
                    "label": 0
                },
                {
                    "sent": "I can train a convolutional autoencoder on image net to make reconstructions that are essentially perfect to the human eye, and then I can look at the code layer and I can get a like 1000 dimensional code for image net.",
                    "label": 0
                },
                {
                    "sent": "I think actually probably 3000 dimensional was what I used.",
                    "label": 0
                },
                {
                    "sent": "If I fit a Gaussian distribution to those code values and then I sample from the Gaussian and decode them, I get really bad mode.",
                    "label": 0
                },
                {
                    "sent": "Collapse all those samples look the same as each other.",
                    "label": 0
                },
                {
                    "sent": "They're not literally the same, but they have differences that are not interesting to the human visual system, but they're all more or less the same color the same texture.",
                    "label": 0
                },
                {
                    "sent": "They might have differences in exactly where pixels of that texture are located, but they are all semantically very similar to each other, and I would not have expected that outcome for this experiment.",
                    "label": 0
                },
                {
                    "sent": "I didn't think it would.",
                    "label": 0
                },
                {
                    "sent": "Right away result in good image net samples, but I did think that samples from this Gaussian distribution in code space of an autoencoder would look very different from each other and something about the way that the decoder works actually made them all look similar.",
                    "label": 0
                },
                {
                    "sent": "I can't really explain why that's happening yet, but I do think that might be part of what causes gunstone mode collapse so often.",
                    "label": 0
                },
                {
                    "sent": "I would have expected the opposite, like you would get lots of spurious images.",
                    "label": 0
                },
                {
                    "sent": "Is very surprising.",
                    "label": 0
                },
                {
                    "sent": "Well, they weren't good images.",
                    "label": 0
                },
                {
                    "sent": "They were all the same.",
                    "label": 0
                },
                {
                    "sent": "Serious image, yeah.",
                    "label": 0
                },
                {
                    "sent": "So yeah, so for again it could be that the loss function makes them collapse.",
                    "label": 0
                },
                {
                    "sent": "Too high probability points, so you could say maybe guns are doing something like minimizing the Jensen, Shannon Divergent and then that would say that they prefer to pick one mode and sample from it rather than capture all the modes.",
                    "label": 0
                },
                {
                    "sent": "But now we have all kinds of things like Afghans from Microsoft Research that can do the KL divergent between data and model, and that should that should prefer to capture all the modes rather than sample from just one.",
                    "label": 0
                },
                {
                    "sent": "I have my own formulation of doing the KL divergent's in a different way and it still has mode collapse too.",
                    "label": 0
                },
                {
                    "sent": "And then there's a few other papers like the one by Ben Poole.",
                    "label": 0
                },
                {
                    "sent": "Where he he has like an Alpha parameter, we can interpolate between diversity and quality of samples, but they all suffer from mode collapse to some extent, so that kind of makes me think maybe it's not really the last function.",
                    "label": 0
                },
                {
                    "sent": "It could also be something to do with the dynamics of the game, so if you have a cost function for each player and you start doing gradient descent on each players cost with respect to that players parameters, you don't know that you'll actually find the Nash equilibrium for the two players, so it could be happening is we're getting stuck in a setting where the generator has mode collapsed and the dynamics just can't take us out of that setting.",
                    "label": 0
                },
                {
                    "sent": "So then the question becomes, why do the dynamics?",
                    "label": 0
                },
                {
                    "sent": "Repeatadly take us to that pathological setting, and that's a bit harder to explain.",
                    "label": 0
                },
                {
                    "sent": "One thing that came out recently that started to make me worry a little bit less about the dynamics compared to some of the other parts of the model is Zico, Kolter and one of his grad students at CMU wrote a paper where they said that if you analyze gradient descent on guns as a dynamical system.",
                    "label": 0
                },
                {
                    "sent": "It's locally stable near the Nash equilibrium, so that means if you get near the Nash equilibrium you should converge to it.",
                    "label": 0
                },
                {
                    "sent": "Sort of like if you have an optimization problem and you can get near a local minimum, you should converge to it for if you're sufficiently near before that paper, we didn't actually know whether guns were localised, able, and I kind of suspected that they weren't.",
                    "label": 0
                },
                {
                    "sent": "I'm not a dynamical systems expert, so I had taken the Jacobian of the of the dynamics, and I saw that had a big block of zeros in it.",
                    "label": 0
                },
                {
                    "sent": "And I thought that would make too many of the eigenvalues be 0 and that it wouldn't be stable, but the CMU people are more more skilled at analyzing nonlinear dynamical systems, and they found that.",
                    "label": 0
                },
                {
                    "sent": "Regular guns are stable, and Wasserstein guns are unstable for.",
                    "label": 0
                },
                {
                    "sent": "For their analysis, it's important to keep in mind that further analysis the way that they were running the Wasserstein Gan is not the same way that the Wasserstein Gan paper advises to run it.",
                    "label": 0
                },
                {
                    "sent": "They were looking at a single step on each players cast simultaneously, and you're supposed to run Wasserstein gowns with multiple steps on the discriminator.",
                    "label": 0
                },
                {
                    "sent": "But that's the multiple step.",
                    "label": 0
                },
                {
                    "sent": "Scenario is a lot harder to analyze with traditional.",
                    "label": 0
                },
                {
                    "sent": "Dynamical systems equations.",
                    "label": 0
                },
                {
                    "sent": "So the question is, guns are hard to train.",
                    "label": 0
                },
                {
                    "sent": "Do we have any tips for how to train them better?",
                    "label": 0
                },
                {
                    "sent": "See me.",
                    "label": 0
                },
                {
                    "sent": "Facebook AI Research has a repo called Gan Hacks where he lists a lot of tips for training guns better.",
                    "label": 0
                },
                {
                    "sent": "Some of them you know he marks them pretty clearly like this one is very well accepted.",
                    "label": 0
                },
                {
                    "sent": "As always helping and you know this one seems like it helps some people and hurt some people.",
                    "label": 0
                },
                {
                    "sent": "Depending on the problem they're solving.",
                    "label": 0
                },
                {
                    "sent": "It's a pretty good repository.",
                    "label": 0
                },
                {
                    "sent": "I recommend it to the people at Google who are working on guns, and I think other people are pretty happy with it too.",
                    "label": 0
                },
                {
                    "sent": "Philly.",
                    "label": 0
                },
                {
                    "sent": "By sampling biases you mean?",
                    "label": 0
                },
                {
                    "sent": "Like the data not being representative of a population in a way that could result in bad decision-making, or.",
                    "label": 0
                },
                {
                    "sent": "Playing.",
                    "label": 0
                },
                {
                    "sent": "Generation.",
                    "label": 0
                },
                {
                    "sent": "You can do that.",
                    "label": 0
                },
                {
                    "sent": "So the question is, do we have a better way of finding biases in the model?",
                    "label": 0
                },
                {
                    "sent": "If we have an implicit model, is it harder than if we have an explicit one?",
                    "label": 0
                },
                {
                    "sent": "Or are people working on it?",
                    "label": 0
                },
                {
                    "sent": "I don't know as much about this topic.",
                    "label": 0
                },
                {
                    "sent": "Other people that I work with our front under Viega smart and Water Wattenberg and been Kim at Google are all working on these topics and I'd be able to tell you more than that.",
                    "label": 0
                },
                {
                    "sent": "I can off the top of my head, I feel like.",
                    "label": 0
                },
                {
                    "sent": "It's usually the data set itself that has a lot of these problems and an explicit density function in the model may not necessarily tell us what those problems are.",
                    "label": 0
                },
                {
                    "sent": "The density function can tell us what the model believes in, but it doesn't necessarily tell us what was in the data to start with.",
                    "label": 0
                },
                {
                    "sent": "It can be hard to tell if a problem in the final density function was a problem with the learning algorithm or a problem with the data itself.",
                    "label": 0
                },
                {
                    "sent": "There's also the issue that.",
                    "label": 0
                },
                {
                    "sent": "The model will just tell you that your training data is likely to occur, but the model can't tell you about the things that didn't go into the data that you're overlooking.",
                    "label": 0
                },
                {
                    "sent": "And the model will just be confident in its own mistakes.",
                    "label": 0
                },
                {
                    "sent": "It's kind of hard to use a model to look at itself and figure out what's wrong with it.",
                    "label": 0
                },
                {
                    "sent": "So like on image net, an example of the kind of bias you're talking about is.",
                    "label": 0
                },
                {
                    "sent": "A lot of the time you know you'll have a class like rugby ball and you always see the rugby ball in a rugby field.",
                    "label": 0
                },
                {
                    "sent": "You never see the rugby balls sitting in someone's garage, so a lot of the time Imagenet models will see a rugby field with no ball in view and they'll classify it as a rugby ball.",
                    "label": 0
                },
                {
                    "sent": "But the problem is the model is confident in what it's doing, so they can't tell you that that's a mistake.",
                    "label": 0
                },
                {
                    "sent": "You have to just label the data independently and find that it's a mistake.",
                    "label": 0
                },
                {
                    "sent": "Why would you normalize?",
                    "label": 0
                },
                {
                    "sent": "The question is, why do you normalize images between minus one and one rather than zero and one?",
                    "label": 0
                },
                {
                    "sent": "Both of them seem to work in the original Gan paper.",
                    "label": 0
                },
                {
                    "sent": "I think I normalize them between zero and one, at least for amnesty.",
                    "label": 0
                },
                {
                    "sent": "I'm pretty confident I did.",
                    "label": 0
                },
                {
                    "sent": "In my paper on generating image net images.",
                    "label": 0
                },
                {
                    "sent": "The reason I used negative one positive one is that.",
                    "label": 0
                },
                {
                    "sent": "I think his name is Taehoon Kim.",
                    "label": 0
                },
                {
                    "sent": "I know his GitHub username is carpe diem.",
                    "label": 0
                },
                {
                    "sent": "Made an open source implementation of DC guns and he standardized the images to negative one positive one.",
                    "label": 0
                },
                {
                    "sent": "So I just took his code and started hacking off of that and I never changed the preprocessing.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Stand by music.",
                    "label": 0
                },
                {
                    "sent": "Soccer downsample wild.",
                    "label": 0
                },
                {
                    "sent": "Images.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so so you can get things that are a kind of proper downsample using strided convolution, overside, dilated convolution and then you can also do the like Gaussian weighted.",
                    "label": 0
                },
                {
                    "sent": "You know better quality downsampling.",
                    "label": 0
                },
                {
                    "sent": "I found that tends to get rid of the checkerboard artifact, but at least in Tensorflow, the true downsampling is a lot slower, and I didn't find the improvement in quality was worth the reduction in speed.",
                    "label": 0
                },
                {
                    "sent": "I've also found sometimes like images, the models that learn to generate images with better objects in them often have more checkerboards and a lot of the time I do things that get rid of the checkerboards, but also get rid of the higher level semantics of the objects.",
                    "label": 0
                },
                {
                    "sent": "I don't really know exactly what's going on there.",
                    "label": 0
                },
                {
                    "sent": "Pics and what kind of data are text data.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so the question is how do I see the success of guns and text data?",
                    "label": 0
                },
                {
                    "sent": "Do you mean comment on where they are right now or?",
                    "label": 0
                },
                {
                    "sent": "Uh.",
                    "label": 0
                },
                {
                    "sent": "So there is the the Wasserstein Gan with gradient penalty can generate text 1 character at a time.",
                    "label": 0
                },
                {
                    "sent": "The majority of words that it produces are not recognizable English words, at least in the paper that I saw.",
                    "label": 0
                },
                {
                    "sent": "I don't have access to a large corpus of samples from it to evaluate that test.",
                    "label": 0
                },
                {
                    "sent": "So basically I feel like guns aren't quite there yet.",
                    "label": 0
                },
                {
                    "sent": "One thing I don't understand is there's quite a lot of enthusiasm for guns for text in general, and to me that's a little bit confusing because text seems like one of the places where guns are least likely to help you.",
                    "label": 0
                },
                {
                    "sent": "For against the they work best if the output is differentiable because you need to back propagate through the discriminator and then through the output of the generator and then through the generator itself.",
                    "label": 0
                },
                {
                    "sent": "So it's hard to make a VE that has discrete latent variables.",
                    "label": 0
                },
                {
                    "sent": "It's hard to make again that has discrete output variables and.",
                    "label": 0
                },
                {
                    "sent": "I guess I personally have focused my efforts on trying to make guns for images very stable and reliable, because I think that's going to happen earlier than guns.",
                    "label": 0
                },
                {
                    "sent": "For text.",
                    "label": 0
                },
                {
                    "sent": "It just seems like if we can't even handle the case where the output is continuous yet then the case where the output is discrete is like tackling two difficulties at once and you've got to resolve both of them before you really see success.",
                    "label": 0
                },
                {
                    "sent": "So yeah, it's a really hard thing, and it doesn't seem to have caught up to like where RNN text generation is.",
                    "label": 0
                },
                {
                    "sent": "Alright, thank you very much, thanks.",
                    "label": 0
                }
            ]
        }
    }
}