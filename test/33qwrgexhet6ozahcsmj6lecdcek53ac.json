{
    "id": "33qwrgexhet6ozahcsmj6lecdcek53ac",
    "title": "Detecting Erroneous Identity Links on the Web using Network Metrics",
    "info": {
        "author": [
            "Joe Raad, INRIA Saclay - \u00cele-de-France"
        ],
        "published": "Nov. 22, 2018",
        "recorded": "October 2018",
        "category": [
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/iswc2018_raad_detecting_erroneous/",
    "segmentation": [
        [
            "So I'm jerad.",
            "I'll present to you today.",
            "Our approach of detecting around news identity links in the web of data.",
            "As we all know."
        ],
        [
            "Identity is an essential agreement.",
            "I essential thing for linked open data, essentially gradient.",
            "It allows to link different diarize.",
            "Sorry link I arise from different datasets and consequently linking these datasets.",
            "This is done usually by linking two things that refer to the same entity by another same as statement.",
            "This statement means that every property asserted that the first YRI will be asserted to the other.",
            "I'm talking about all same as."
        ],
        [
            "As it's the most adopted identity statement at the lot, as we can see it sparkly adoption in the Loudcloud and 1015 compared to the other identity and near identity links."
        ],
        [
            "However, from all these 500 million say mass statements, there exists a number of erroneous identity links.",
            "And there has been studies that have proven that all same as is being used incorrectly in the web.",
            "This is due to the lack of precision.",
            "Maybe not 100% precision of data linking approaches.",
            "In addition, people tend to use our same as because it's the closest formalized identity predicate that can be used, for example, because sometimes you don't need to make another the same as link, but since it's the only available standardized identity link, people are tend to use it, sometimes incorrectly.",
            "In addition to our eyes that are linked to each other, sometimes these high rise meaning tend to change by time.",
            "For example, thing referring to a person now might refer to the web page of that person.",
            "And finally, the notion of identity in itself is problematic, as in philosophy many critics have been made against this notion of identity, which is standardized in our same ads.",
            "This time."
        ],
        [
            "This problem is obvious in the loudcloud as we calculated the equivalence closure of the owl same as statements and in one equality set, which means that 177 terms are actually linked by, same as transitively and should refer to the same real world entity.",
            "Actually what we have is a bunch of terms which do not refer to the same real world entity, like the list of countries, Albert Einstein and many other different things.",
            "So this is obvious that all same as is being used incorrectly in the web and we need to detect these strong same as links.",
            "How can we detect these strong same as links?"
        ],
        [
            "Many approaches have been already tried to detect these links.",
            "Some of them have been based on inconsistency approaches.",
            "For example, they put hypothesized that links that cause inconsistency are probably incorrect.",
            "Other type of approaches have relied on the content of the IRS.",
            "So for example that comparing the textual descriptions and the properties of these two arise in order to see if this is the correct same as link or not.",
            "And finally the other type of approaches have relied on the network structure.",
            "For example, they study the effect of an owl, same as statement to the RDF graph, for example, and I'll say mass statement with, which enriches the other YRI is probably more correct, and then I'll say my statement, which tend to close and open same as chain could also be probably correct.",
            "So we have these kind of approaches that aim to detect the wrong identity links.",
            "What we need from such approaches?"
        ],
        [
            "Is to have obviously high accuracy, recall and precision.",
            "We want them to be tested on real world data.",
            "We want them to be scalable to the web.",
            "And we don't need assumptions that cannot be available in the log in the web.",
            "For example, many approaches has relied that each other.",
            "I has a textual description, which is not the case in the log, for example, or the presence of schema mappings, which is also rarely the case.",
            "So for example, so we find ourselves with no existing approach that can combines all these criteria to detect the wrong same as links.",
            "And that's why today we're going to introduce you and."
        ],
        [
            "Our approach that takes in consideration some of these criteria necessary for detecting the wrong same as links."
        ],
        [
            "Overall idea of our approach is that we want to use the Community structure of the AL same as networks to assign another degree to each, same as link.",
            "What we hypothesize is that terms that are densely connected to each other are probably the same as links between them is probably correct, while a term that is an outlier, like not connected to the other terms, is probably connected by wrong same as link.",
            "In addition, we take in consideration the symmetrical property of all same as link and we consider that I'll same as link which is duplicative.",
            "Duplicate symmetrical links are probably more correct than all same as link which are not symmetrically asserted.",
            "I present to our approach, which is composed of four main steps."
        ],
        [
            "Before I'm just going to say that we have used a lot.",
            "A lot data set containing that contains 28 billion tripled and the 1st."
        ],
        [
            "Half of our approach necessary necessitates extracting the same as statements from this data set, obviously.",
            "So when we extracted the same as statement, we have now 558 million statements from this network."
        ],
        [
            "Of same as statement, we want to detect the equality set.",
            "An equality set is just a connected component.",
            "Meaning that things in the same equality set are actually should refer to the same thing.",
            "An example of an equality set."
        ],
        [
            "Is the Barack Obama equality set?",
            "For example, in the loud cloud, in 2015, Barack Obama has four 440 identifiers that should refer to the same thing, which is Barack Obama linked by many same as links.",
            "So this is 1 equality set.",
            "After that we have detected the 49 million equality sets existing in the log."
        ],
        [
            "We want to detect the community structure in each equality set.",
            "There's there exist many algorithms to detect such community structure, and we have used the Luba algorithm because we want to detect non overlapping communities.",
            "We want an algorithm that can consider the weight of the edges.",
            "We also want an algorithm that has low computational complexity.",
            "And because the Luba algorithm has proven its efficiency according to the other survey in this domain.",
            "So now we have the same as network which are composed to different equality set and after we apply the Community detection algorithm on each equality set, Now we want to."
        ],
        [
            "Assign another degree to each, same as link in each equality set.",
            "As I said before, our degree is based mainly on two things.",
            "The density of the community in which our same as link exists in, and if this same as link is symmetrical or not.",
            "So the idea is, as I said, terms that are very connected to each other the same as link between them is probably more correct than a term that is not connected to the rest of the terms.",
            "Therefore, with this hypothesis we assign another degree between zero and one.",
            "And we can we as I said, also consider this symmetrical characteristic."
        ],
        [
            "For example, on the Barack Obama equality set of 440 terms, we can detect this Community structure composed of four communities.",
            "What's interesting about this community, as we see that the Community zero community three and community two, the arise in this community is mostly referred to the person of Barack Obama.",
            "While in the community through all the RI is most of the eye is actually refer to the government at the administration of Barack Obama.",
            "So this is also obvious.",
            "That same as link.",
            "The same as is is used incorrectly, and this is also approved.",
            "So what we need for example, is to detect the links that is causing the linkage between the person and administration."
        ],
        [
            "So we know that you have assigned an error."
        ],
        [
            "Agree to each same as link we have here.",
            "The distribution of this error degree on the 556 million because we're not counting the reflexive ones because by definition are now will same as which is reflexive is correct.",
            "So."
        ],
        [
            "Objective of our evaluation is to check if our degree actually assigns a higher error degree to wrong links.",
            "Then the correct links and the second, the second objective of our approach of our approach is to investigate which criteria are actually affecting this error degree."
        ],
        [
            "So to do that, we have asked the authors of this paper to evaluate 200 manually evaluate 200 same as links.",
            "From each bin of the bins that I've showed you before.",
            "So for example, authors have evaluated 40 links from with an error degree from zero to 0.2 and etc.",
            "So from this table we can see the 1st result is that the higher an error degree is, the more likely and all same as link is erroneous.",
            "For example, we can see that from zero to 0.2 or the same as links evaluated were actually judge as correct, same as while same as links from with another degree from Zero Point 8 to 168% of them were only correct.",
            "So we can see that our error degree tend to give higher error degree to wrong same as links than to correct ones so that the first is what we can see from that table."
        ],
        [
            "The 2nd result you can see that all the same as links with another degree less than 0.4 are actually correct, judged by by the authors of this paper.",
            "But what we cannot deduce from this table is which error degree and which which is the threshold of the error degree in which the link starts to be incorrect.",
            "So because we have here like 31% of them which are incorrect, in order to investigate more this bin, actually we have evaluated."
        ],
        [
            "60 more links.",
            "But this time we have taken same as links with another degree higher than 0.9 and with three other different criteria.",
            "The first criteria is we took.",
            "20 same as links with another degree higher than 0.9 in the largest equality set.",
            "The second criteria is that we took 20 random same as links with another degree higher than 0.99 and the third criteria is we combined both by taking another degree which is higher than 0.99 from the largest equality set.",
            "So from this table we can see that actually our error degree works better and larger equality sets and when we set the threshold at 0.99 for example, we can see that in this in this criteria, 88% of the links evaluated in the largest equality set with another degree higher than 0.99 were actually incorrect.",
            "So that means that the size of the equality set can impact massively the distribution of the error degree.",
            "However."
        ],
        [
            "And since the equality set size is not included in our error degree, we took only the threshold at 0.99.",
            "And we, by looking at the links we have evaluated in this approach, we can see that we have an 86% accuracy from the links we evaluated, so we assigned.",
            "So the links that are lower than 0.99 were actually correct and links that are higher than 0.99 are actually incorrect with 86% accuracy.",
            "The precision is 73%.",
            "And which is also according to the links that we evaluated.",
            "However, randomly we also because we saw in the other criteria."
        ],
        [
            "Here randomly, if we took links that are higher than 0.99, actually the precision tends to be more than to 40%, so we can see that the precision depends heavily on the equality set in which this link is taken from."
        ],
        [
            "To evaluate our approach on other identity links that we that we took, we relied on the only gold standard we have seen.",
            "The lot, which is that done by Acosta Al from crowdsourcing.",
            "They have actually took 95 same as link connecting the PDF to Freebase.",
            "They manually evaluated them and I've seen that all these links are actually correct so we have.",
            "So we wanted to see this actually correct links.",
            "What kind of error degree they have in our approach?",
            "We managed to find only 78 in our data set from this 7870.",
            "Seven were assigned another degree lower than 0.99.",
            "Which shows an accuracy of 98% in validating identity links at least."
        ],
        [
            "In order to evaluate the recall of our approach.",
            "We have chosen 40 random different terms like Facebook, Strawberry, chair.",
            "We just took 40 random terms that are not the same.",
            "We made sure that they are not asserted same as in the log.",
            "But we've also made sure that some of them are actually in the same equality set.",
            "By mistake, which is erroneously in the same equality set.",
            "And we added all the possible 780 links between these 40 terms and we have seen that 77125 of them have actually another degree higher than 0.99, which shows that we actually managed to assign 93% of these strong, same as link that we added as a threshold as a higher than the threshold we set, which is higher than 0.99.",
            "Which shows in 90 three percent recall."
        ],
        [
            "So in order to finalize my presentation, I'm going to come back to the quality stat of the barrack Obama, and we saw that the government community is connected to the rest of the terms of the other communities by only two links which are here.",
            "This link is actually a freebase.",
            "This I I is actually Freebase YRI connect."
        ],
        [
            "Into 2D Pris, which is by these two links.",
            "We looked at this freeways YRI and we saw that this freeways right?",
            "It's actually the Presidency of Barack Obama linked to President Barack Obama and President Obama.",
            "So we looked at these two links.",
            "What is the error degree of them?",
            "And we saw that we have actually managed to assign another degree that is 0.999 which are the two only two Lincoln this equality set with this kind of error degree.",
            "So we."
        ],
        [
            "And see that it was effective also in this equality set of size 440 for example.",
            "So now to order and finalize my my talk, we want to just look how much messed up is a lot.",
            "How many incorrect same as links are in the load.",
            "So we also did other analysis that are not included in this paper about the symmetry.",
            "Of same as we have seen that 98% of symmetrical, same as links tend to be correct.",
            "And we took this in consideration.",
            "With the number of same as links which have higher than 0.99 error degree and we can estimate that 4% of all same all same as links in the log are actually around us.",
            "Which means around 22,000,000, same as links.",
            "This estimation falls in line with Hogan Al summation in 2012 and is much more optimistic than the estimation of helping out in 2010.",
            "Also, which said that 21% of all same as links are incorrect."
        ],
        [
            "So in."
        ],
        [
            "This talk we present to you an approach to detect erroneous identity links using the same as network structure and network community structure.",
            "Our approach do not require any assumption on the data like the previous approaches in state of the art.",
            "So which makes it feasible on the web and with the total runtime of 11 hours in total to extract the same as links and that the connected component and designer degree makes it very scalable to the web.",
            "With an accuracy of 86% and the record of 93%, we have shown some good results on this.",
            "Evaluated the set of links that we manually evaluated.",
            "However, we have seen that the precision of our approach depends heavily on the equality set size and clearly an equality set size of size 2.",
            "For example, our approach will not be effective because we cannot detect the Community structure inequality in such a small equality set.",
            "And all the all the numbers that I'm showing you are actually based on the manual revelation of around only 300, same as links."
        ],
        [
            "So as perspective we can just include the duplicate, same as triple.",
            "We can see if you can include equality set size.",
            "We can combine multiple community detection algorithms combined with other state of the art approaches and maybe replace this erroneous same as links with contextual identity links.",
            "Thank you."
        ],
        [
            "Much about using graph embeddings and what would be some of the limitations to think about unsupervised clustering of graph embeddings.",
            "To do this, no we haven't thought about this for now.",
            "Actually there's another approach which relies on the vectors of the same of our eyes, so it constructs a vector which is done by.",
            "Haiku poem, and so that's the closest to machine learning.",
            "Maybe approach detect wrong.",
            "Same as links, but actually only relied on the community structure and the density of the communities and the symmetrical same as links at the moment.",
            "But we can check this as perspective things.",
            "Yep.",
            "Yes, actually what what's good in that?",
            "In our approach, for example, we can pass in the beginning because we're scalable in the web, so we can assign another degree to each same as link before and give maybe the same as links which I have a higher degree to other type approaches.",
            "We do not scale to the web like content based or maybe crowdsourcing or some other approaches to verify and improve our precision.",
            "Thank you.",
            "You want."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I'm jerad.",
                    "label": 0
                },
                {
                    "sent": "I'll present to you today.",
                    "label": 0
                },
                {
                    "sent": "Our approach of detecting around news identity links in the web of data.",
                    "label": 1
                },
                {
                    "sent": "As we all know.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Identity is an essential agreement.",
                    "label": 0
                },
                {
                    "sent": "I essential thing for linked open data, essentially gradient.",
                    "label": 0
                },
                {
                    "sent": "It allows to link different diarize.",
                    "label": 0
                },
                {
                    "sent": "Sorry link I arise from different datasets and consequently linking these datasets.",
                    "label": 0
                },
                {
                    "sent": "This is done usually by linking two things that refer to the same entity by another same as statement.",
                    "label": 0
                },
                {
                    "sent": "This statement means that every property asserted that the first YRI will be asserted to the other.",
                    "label": 0
                },
                {
                    "sent": "I'm talking about all same as.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As it's the most adopted identity statement at the lot, as we can see it sparkly adoption in the Loudcloud and 1015 compared to the other identity and near identity links.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "However, from all these 500 million say mass statements, there exists a number of erroneous identity links.",
                    "label": 1
                },
                {
                    "sent": "And there has been studies that have proven that all same as is being used incorrectly in the web.",
                    "label": 1
                },
                {
                    "sent": "This is due to the lack of precision.",
                    "label": 0
                },
                {
                    "sent": "Maybe not 100% precision of data linking approaches.",
                    "label": 0
                },
                {
                    "sent": "In addition, people tend to use our same as because it's the closest formalized identity predicate that can be used, for example, because sometimes you don't need to make another the same as link, but since it's the only available standardized identity link, people are tend to use it, sometimes incorrectly.",
                    "label": 0
                },
                {
                    "sent": "In addition to our eyes that are linked to each other, sometimes these high rise meaning tend to change by time.",
                    "label": 0
                },
                {
                    "sent": "For example, thing referring to a person now might refer to the web page of that person.",
                    "label": 1
                },
                {
                    "sent": "And finally, the notion of identity in itself is problematic, as in philosophy many critics have been made against this notion of identity, which is standardized in our same ads.",
                    "label": 0
                },
                {
                    "sent": "This time.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This problem is obvious in the loudcloud as we calculated the equivalence closure of the owl same as statements and in one equality set, which means that 177 terms are actually linked by, same as transitively and should refer to the same real world entity.",
                    "label": 0
                },
                {
                    "sent": "Actually what we have is a bunch of terms which do not refer to the same real world entity, like the list of countries, Albert Einstein and many other different things.",
                    "label": 1
                },
                {
                    "sent": "So this is obvious that all same as is being used incorrectly in the web and we need to detect these strong same as links.",
                    "label": 0
                },
                {
                    "sent": "How can we detect these strong same as links?",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Many approaches have been already tried to detect these links.",
                    "label": 0
                },
                {
                    "sent": "Some of them have been based on inconsistency approaches.",
                    "label": 0
                },
                {
                    "sent": "For example, they put hypothesized that links that cause inconsistency are probably incorrect.",
                    "label": 0
                },
                {
                    "sent": "Other type of approaches have relied on the content of the IRS.",
                    "label": 0
                },
                {
                    "sent": "So for example that comparing the textual descriptions and the properties of these two arise in order to see if this is the correct same as link or not.",
                    "label": 0
                },
                {
                    "sent": "And finally the other type of approaches have relied on the network structure.",
                    "label": 0
                },
                {
                    "sent": "For example, they study the effect of an owl, same as statement to the RDF graph, for example, and I'll say mass statement with, which enriches the other YRI is probably more correct, and then I'll say my statement, which tend to close and open same as chain could also be probably correct.",
                    "label": 0
                },
                {
                    "sent": "So we have these kind of approaches that aim to detect the wrong identity links.",
                    "label": 0
                },
                {
                    "sent": "What we need from such approaches?",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is to have obviously high accuracy, recall and precision.",
                    "label": 0
                },
                {
                    "sent": "We want them to be tested on real world data.",
                    "label": 1
                },
                {
                    "sent": "We want them to be scalable to the web.",
                    "label": 0
                },
                {
                    "sent": "And we don't need assumptions that cannot be available in the log in the web.",
                    "label": 0
                },
                {
                    "sent": "For example, many approaches has relied that each other.",
                    "label": 0
                },
                {
                    "sent": "I has a textual description, which is not the case in the log, for example, or the presence of schema mappings, which is also rarely the case.",
                    "label": 1
                },
                {
                    "sent": "So for example, so we find ourselves with no existing approach that can combines all these criteria to detect the wrong same as links.",
                    "label": 0
                },
                {
                    "sent": "And that's why today we're going to introduce you and.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Our approach that takes in consideration some of these criteria necessary for detecting the wrong same as links.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Overall idea of our approach is that we want to use the Community structure of the AL same as networks to assign another degree to each, same as link.",
                    "label": 1
                },
                {
                    "sent": "What we hypothesize is that terms that are densely connected to each other are probably the same as links between them is probably correct, while a term that is an outlier, like not connected to the other terms, is probably connected by wrong same as link.",
                    "label": 0
                },
                {
                    "sent": "In addition, we take in consideration the symmetrical property of all same as link and we consider that I'll same as link which is duplicative.",
                    "label": 0
                },
                {
                    "sent": "Duplicate symmetrical links are probably more correct than all same as link which are not symmetrically asserted.",
                    "label": 0
                },
                {
                    "sent": "I present to our approach, which is composed of four main steps.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Before I'm just going to say that we have used a lot.",
                    "label": 0
                },
                {
                    "sent": "A lot data set containing that contains 28 billion tripled and the 1st.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Half of our approach necessary necessitates extracting the same as statements from this data set, obviously.",
                    "label": 0
                },
                {
                    "sent": "So when we extracted the same as statement, we have now 558 million statements from this network.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of same as statement, we want to detect the equality set.",
                    "label": 0
                },
                {
                    "sent": "An equality set is just a connected component.",
                    "label": 0
                },
                {
                    "sent": "Meaning that things in the same equality set are actually should refer to the same thing.",
                    "label": 0
                },
                {
                    "sent": "An example of an equality set.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is the Barack Obama equality set?",
                    "label": 1
                },
                {
                    "sent": "For example, in the loud cloud, in 2015, Barack Obama has four 440 identifiers that should refer to the same thing, which is Barack Obama linked by many same as links.",
                    "label": 0
                },
                {
                    "sent": "So this is 1 equality set.",
                    "label": 0
                },
                {
                    "sent": "After that we have detected the 49 million equality sets existing in the log.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We want to detect the community structure in each equality set.",
                    "label": 1
                },
                {
                    "sent": "There's there exist many algorithms to detect such community structure, and we have used the Luba algorithm because we want to detect non overlapping communities.",
                    "label": 0
                },
                {
                    "sent": "We want an algorithm that can consider the weight of the edges.",
                    "label": 1
                },
                {
                    "sent": "We also want an algorithm that has low computational complexity.",
                    "label": 0
                },
                {
                    "sent": "And because the Luba algorithm has proven its efficiency according to the other survey in this domain.",
                    "label": 0
                },
                {
                    "sent": "So now we have the same as network which are composed to different equality set and after we apply the Community detection algorithm on each equality set, Now we want to.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Assign another degree to each, same as link in each equality set.",
                    "label": 0
                },
                {
                    "sent": "As I said before, our degree is based mainly on two things.",
                    "label": 0
                },
                {
                    "sent": "The density of the community in which our same as link exists in, and if this same as link is symmetrical or not.",
                    "label": 1
                },
                {
                    "sent": "So the idea is, as I said, terms that are very connected to each other the same as link between them is probably more correct than a term that is not connected to the rest of the terms.",
                    "label": 0
                },
                {
                    "sent": "Therefore, with this hypothesis we assign another degree between zero and one.",
                    "label": 0
                },
                {
                    "sent": "And we can we as I said, also consider this symmetrical characteristic.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For example, on the Barack Obama equality set of 440 terms, we can detect this Community structure composed of four communities.",
                    "label": 0
                },
                {
                    "sent": "What's interesting about this community, as we see that the Community zero community three and community two, the arise in this community is mostly referred to the person of Barack Obama.",
                    "label": 0
                },
                {
                    "sent": "While in the community through all the RI is most of the eye is actually refer to the government at the administration of Barack Obama.",
                    "label": 0
                },
                {
                    "sent": "So this is also obvious.",
                    "label": 0
                },
                {
                    "sent": "That same as link.",
                    "label": 0
                },
                {
                    "sent": "The same as is is used incorrectly, and this is also approved.",
                    "label": 0
                },
                {
                    "sent": "So what we need for example, is to detect the links that is causing the linkage between the person and administration.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we know that you have assigned an error.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Agree to each same as link we have here.",
                    "label": 0
                },
                {
                    "sent": "The distribution of this error degree on the 556 million because we're not counting the reflexive ones because by definition are now will same as which is reflexive is correct.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Objective of our evaluation is to check if our degree actually assigns a higher error degree to wrong links.",
                    "label": 0
                },
                {
                    "sent": "Then the correct links and the second, the second objective of our approach of our approach is to investigate which criteria are actually affecting this error degree.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to do that, we have asked the authors of this paper to evaluate 200 manually evaluate 200 same as links.",
                    "label": 0
                },
                {
                    "sent": "From each bin of the bins that I've showed you before.",
                    "label": 0
                },
                {
                    "sent": "So for example, authors have evaluated 40 links from with an error degree from zero to 0.2 and etc.",
                    "label": 0
                },
                {
                    "sent": "So from this table we can see the 1st result is that the higher an error degree is, the more likely and all same as link is erroneous.",
                    "label": 1
                },
                {
                    "sent": "For example, we can see that from zero to 0.2 or the same as links evaluated were actually judge as correct, same as while same as links from with another degree from Zero Point 8 to 168% of them were only correct.",
                    "label": 0
                },
                {
                    "sent": "So we can see that our error degree tend to give higher error degree to wrong same as links than to correct ones so that the first is what we can see from that table.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The 2nd result you can see that all the same as links with another degree less than 0.4 are actually correct, judged by by the authors of this paper.",
                    "label": 1
                },
                {
                    "sent": "But what we cannot deduce from this table is which error degree and which which is the threshold of the error degree in which the link starts to be incorrect.",
                    "label": 0
                },
                {
                    "sent": "So because we have here like 31% of them which are incorrect, in order to investigate more this bin, actually we have evaluated.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "60 more links.",
                    "label": 0
                },
                {
                    "sent": "But this time we have taken same as links with another degree higher than 0.9 and with three other different criteria.",
                    "label": 0
                },
                {
                    "sent": "The first criteria is we took.",
                    "label": 0
                },
                {
                    "sent": "20 same as links with another degree higher than 0.9 in the largest equality set.",
                    "label": 0
                },
                {
                    "sent": "The second criteria is that we took 20 random same as links with another degree higher than 0.99 and the third criteria is we combined both by taking another degree which is higher than 0.99 from the largest equality set.",
                    "label": 1
                },
                {
                    "sent": "So from this table we can see that actually our error degree works better and larger equality sets and when we set the threshold at 0.99 for example, we can see that in this in this criteria, 88% of the links evaluated in the largest equality set with another degree higher than 0.99 were actually incorrect.",
                    "label": 0
                },
                {
                    "sent": "So that means that the size of the equality set can impact massively the distribution of the error degree.",
                    "label": 0
                },
                {
                    "sent": "However.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And since the equality set size is not included in our error degree, we took only the threshold at 0.99.",
                    "label": 0
                },
                {
                    "sent": "And we, by looking at the links we have evaluated in this approach, we can see that we have an 86% accuracy from the links we evaluated, so we assigned.",
                    "label": 0
                },
                {
                    "sent": "So the links that are lower than 0.99 were actually correct and links that are higher than 0.99 are actually incorrect with 86% accuracy.",
                    "label": 0
                },
                {
                    "sent": "The precision is 73%.",
                    "label": 0
                },
                {
                    "sent": "And which is also according to the links that we evaluated.",
                    "label": 0
                },
                {
                    "sent": "However, randomly we also because we saw in the other criteria.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here randomly, if we took links that are higher than 0.99, actually the precision tends to be more than to 40%, so we can see that the precision depends heavily on the equality set in which this link is taken from.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To evaluate our approach on other identity links that we that we took, we relied on the only gold standard we have seen.",
                    "label": 0
                },
                {
                    "sent": "The lot, which is that done by Acosta Al from crowdsourcing.",
                    "label": 0
                },
                {
                    "sent": "They have actually took 95 same as link connecting the PDF to Freebase.",
                    "label": 0
                },
                {
                    "sent": "They manually evaluated them and I've seen that all these links are actually correct so we have.",
                    "label": 0
                },
                {
                    "sent": "So we wanted to see this actually correct links.",
                    "label": 0
                },
                {
                    "sent": "What kind of error degree they have in our approach?",
                    "label": 1
                },
                {
                    "sent": "We managed to find only 78 in our data set from this 7870.",
                    "label": 0
                },
                {
                    "sent": "Seven were assigned another degree lower than 0.99.",
                    "label": 0
                },
                {
                    "sent": "Which shows an accuracy of 98% in validating identity links at least.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In order to evaluate the recall of our approach.",
                    "label": 0
                },
                {
                    "sent": "We have chosen 40 random different terms like Facebook, Strawberry, chair.",
                    "label": 1
                },
                {
                    "sent": "We just took 40 random terms that are not the same.",
                    "label": 1
                },
                {
                    "sent": "We made sure that they are not asserted same as in the log.",
                    "label": 0
                },
                {
                    "sent": "But we've also made sure that some of them are actually in the same equality set.",
                    "label": 1
                },
                {
                    "sent": "By mistake, which is erroneously in the same equality set.",
                    "label": 0
                },
                {
                    "sent": "And we added all the possible 780 links between these 40 terms and we have seen that 77125 of them have actually another degree higher than 0.99, which shows that we actually managed to assign 93% of these strong, same as link that we added as a threshold as a higher than the threshold we set, which is higher than 0.99.",
                    "label": 0
                },
                {
                    "sent": "Which shows in 90 three percent recall.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in order to finalize my presentation, I'm going to come back to the quality stat of the barrack Obama, and we saw that the government community is connected to the rest of the terms of the other communities by only two links which are here.",
                    "label": 0
                },
                {
                    "sent": "This link is actually a freebase.",
                    "label": 0
                },
                {
                    "sent": "This I I is actually Freebase YRI connect.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Into 2D Pris, which is by these two links.",
                    "label": 0
                },
                {
                    "sent": "We looked at this freeways YRI and we saw that this freeways right?",
                    "label": 0
                },
                {
                    "sent": "It's actually the Presidency of Barack Obama linked to President Barack Obama and President Obama.",
                    "label": 1
                },
                {
                    "sent": "So we looked at these two links.",
                    "label": 0
                },
                {
                    "sent": "What is the error degree of them?",
                    "label": 0
                },
                {
                    "sent": "And we saw that we have actually managed to assign another degree that is 0.999 which are the two only two Lincoln this equality set with this kind of error degree.",
                    "label": 1
                },
                {
                    "sent": "So we.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And see that it was effective also in this equality set of size 440 for example.",
                    "label": 0
                },
                {
                    "sent": "So now to order and finalize my my talk, we want to just look how much messed up is a lot.",
                    "label": 1
                },
                {
                    "sent": "How many incorrect same as links are in the load.",
                    "label": 0
                },
                {
                    "sent": "So we also did other analysis that are not included in this paper about the symmetry.",
                    "label": 1
                },
                {
                    "sent": "Of same as we have seen that 98% of symmetrical, same as links tend to be correct.",
                    "label": 0
                },
                {
                    "sent": "And we took this in consideration.",
                    "label": 0
                },
                {
                    "sent": "With the number of same as links which have higher than 0.99 error degree and we can estimate that 4% of all same all same as links in the log are actually around us.",
                    "label": 1
                },
                {
                    "sent": "Which means around 22,000,000, same as links.",
                    "label": 0
                },
                {
                    "sent": "This estimation falls in line with Hogan Al summation in 2012 and is much more optimistic than the estimation of helping out in 2010.",
                    "label": 0
                },
                {
                    "sent": "Also, which said that 21% of all same as links are incorrect.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This talk we present to you an approach to detect erroneous identity links using the same as network structure and network community structure.",
                    "label": 1
                },
                {
                    "sent": "Our approach do not require any assumption on the data like the previous approaches in state of the art.",
                    "label": 1
                },
                {
                    "sent": "So which makes it feasible on the web and with the total runtime of 11 hours in total to extract the same as links and that the connected component and designer degree makes it very scalable to the web.",
                    "label": 0
                },
                {
                    "sent": "With an accuracy of 86% and the record of 93%, we have shown some good results on this.",
                    "label": 0
                },
                {
                    "sent": "Evaluated the set of links that we manually evaluated.",
                    "label": 0
                },
                {
                    "sent": "However, we have seen that the precision of our approach depends heavily on the equality set size and clearly an equality set size of size 2.",
                    "label": 0
                },
                {
                    "sent": "For example, our approach will not be effective because we cannot detect the Community structure inequality in such a small equality set.",
                    "label": 0
                },
                {
                    "sent": "And all the all the numbers that I'm showing you are actually based on the manual revelation of around only 300, same as links.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So as perspective we can just include the duplicate, same as triple.",
                    "label": 0
                },
                {
                    "sent": "We can see if you can include equality set size.",
                    "label": 1
                },
                {
                    "sent": "We can combine multiple community detection algorithms combined with other state of the art approaches and maybe replace this erroneous same as links with contextual identity links.",
                    "label": 1
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Much about using graph embeddings and what would be some of the limitations to think about unsupervised clustering of graph embeddings.",
                    "label": 0
                },
                {
                    "sent": "To do this, no we haven't thought about this for now.",
                    "label": 0
                },
                {
                    "sent": "Actually there's another approach which relies on the vectors of the same of our eyes, so it constructs a vector which is done by.",
                    "label": 0
                },
                {
                    "sent": "Haiku poem, and so that's the closest to machine learning.",
                    "label": 0
                },
                {
                    "sent": "Maybe approach detect wrong.",
                    "label": 0
                },
                {
                    "sent": "Same as links, but actually only relied on the community structure and the density of the communities and the symmetrical same as links at the moment.",
                    "label": 0
                },
                {
                    "sent": "But we can check this as perspective things.",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "Yes, actually what what's good in that?",
                    "label": 0
                },
                {
                    "sent": "In our approach, for example, we can pass in the beginning because we're scalable in the web, so we can assign another degree to each same as link before and give maybe the same as links which I have a higher degree to other type approaches.",
                    "label": 0
                },
                {
                    "sent": "We do not scale to the web like content based or maybe crowdsourcing or some other approaches to verify and improve our precision.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "You want.",
                    "label": 0
                }
            ]
        }
    }
}