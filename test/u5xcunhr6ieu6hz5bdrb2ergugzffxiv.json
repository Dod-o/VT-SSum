{
    "id": "u5xcunhr6ieu6hz5bdrb2ergugzffxiv",
    "title": "ATT: Analyzing Temporal Dynamics of Topics and Authors in Social Media",
    "info": {
        "author": [
            "Nasir Naveed, Institute for Web Science and Technologies (WeST), University of Koblenz-Landau"
        ],
        "published": "July 19, 2011",
        "recorded": "June 2011",
        "category": [
            "Top->Computer Science->Social Media"
        ]
    },
    "url": "http://videolectures.net/acmwebsci2011_naveed_topics/",
    "segmentation": [
        [
            "Thank you very much for spending your time and good afternoon, so I'll be talking about our work, which is about analyzing the temporal dynamics of topics and authors in the social media so.",
            "OK, so."
        ],
        [
            "So maybe you know this interface is snapshots different snapshots from Google Scholar.",
            "Actually when you look for some particular article on some particular topics, you come up with list of companies.",
            "So when you have a careful look on this topic, you see this guy after awhile.",
            "So he's talking about databases and if you look for his articles in 2009 also is talking about again about the data.",
            "It seems that this guy is securely from databases.",
            "But if you look for some other articles so just pour it in 2002.",
            "We have articles on like Symantec Web along with.",
            "He has also articles on databases in 2009 so it seems or subserved that users interest changes with respect to time.",
            "So and few users have interests that stays the same.",
            "So we met on them as they have the static interest rates do not change with the passage of time.",
            "So the other observation is that with the passage of time to new topic emerges and some public stays longer.",
            "Some topics are shortly topics there."
        ],
        [
            "How then the question jumps?",
            "How do we model these topic evolutions, and how do we capture dynamic user interest with respect to this evolving topics?"
        ],
        [
            "Then the natural question is why we need this.",
            "So we want to model topics to observe public trends and also we can use this topics to find consimilar documents.",
            "And we want to model the user interest to Rentify work.",
            "The users right about.",
            "And also to identify authors who have similar interests and you can use this to find some unusual work by an author, so an modeling time can help us in identifying how the topic involves how the topic lifecycle changes and also to capture the dynamic interest with respect to.",
            "The time"
        ],
        [
            "So having said that, OK, we want to capture these things.",
            "Now let's be more clear about the problem that what we have and what we want to achieve.",
            "So the available information is like there are users who are writing some contents at some particular time.",
            "So with the passage of time, some new user comes in and writes about few topics or content and produce content.",
            "That key plus one time and later.",
            "In the time for more users Act or the same user keep producing contents over a period of time.",
            "So once we have this available information which we want to extract from this information is what these users right about about this about this actually means here.",
            "So what's the user writes about?",
            "So what are the topics of interest for the user?",
            "See efforts at some particular time.",
            "So is and the second thing.",
            "How these authors are associated.",
            "With these topics.",
            "So as the time pass on these topics keep evolving so new topic emerges.",
            "So with the emergence of the new topics we need to relocate the user interest that if their interests got changed or not.",
            "So we observe that users interest to change with the passage of time's at the start to write books in particular topic and later in the lifecycle they move on to other topics and keep producing the contents with respect to the other topics.",
            "So we have now available information and we know what you want to achieve from this.",
            "So we're talking about the topic so.",
            "What topic actually means here?"
        ],
        [
            "So if you look at this text sniper.",
            "And if you read this text me, but we will come up, you will quickly come back.",
            "OK, this document or this text sniper is about this thing or about this.",
            "This information is about these objects.",
            "So this thing is actually your topic an you can easily find few terms that define your topic within that document.",
            "So these terms are mostly occurring together in the most similar documents.",
            "And there defines the topic.",
            "So we define the topic like as a probability distribution of words.",
            "So for each.",
            "So there's.",
            "These are the example topics.",
            "If you look at these terms so this.",
            "Terms like on the left column, database, Curie Sequence Control, search law, molecular and schema.",
            "They do catch up.",
            "They have some semantic relationships which are with each other and one can see OK.",
            "These terms are representing the say the topic like databases and similarly on the right side you can see these Trump's Web Ontology, semantic language RDF, so these terms are semantically related with each other and you may infer that OK, this is about the semantic web.",
            "So each of these terms has some weight associated with it.",
            "That with what weight this term is associate associated with this particular topic.",
            "So normally we define this topic as a probability distribution over the vocabulary."
        ],
        [
            "So once we have this information with us.",
            "So we know what we want to achieve.",
            "We know what the topic is and we know this information is available, so we need some kind of a mechanism or tool or machine which can help us in converting this available information into our desired format.",
            "So for this purpose we introduce the author topic and Time model which is helpful in capturing and producing the desired output.",
            "It captures these dependencies between.",
            "Topics, authors and time and produces the topics and the topic lifecycle and the authors that are that are.",
            "And that are associated with these particular topics."
        ],
        [
            "So we.",
            "Run this model on a site seer data set.",
            "So, but before that.",
            "So this model can be useful or helpful to answer the questions like so, which are the important authors for argument topics.",
            "Once you have this model, you have input and it has produced the desired output.",
            "Then you can cure this model for different queries or for different questions, so some of them like which are the important authors forearc even topic or who are The Pioneers of a topic.",
            "And similarly you can see this model can potentially be used for monitoring the topic absolution and also the monitoring the author's profile.",
            "And also if you want to compare some users interests, you have a given user interest.",
            "If you want to find the similar users so you can also post this query to model to find the similar authors."
        ],
        [
            "So what the experimental data set?",
            "So you will see this quite unusual data set.",
            "We restricted this data set due to certain reasons, so we have total of about 5000 documents from the sightseer publications of the King from the computer science remain and the time period was from 2001 to 2009, so we opted out for about 18 authors and having publications from 180 to 300 publications so.",
            "And we did get a cleaning with and remove the stock words and use Porter stemmer to remove the.",
            "Remove the word inflections.",
            "So an we used Jax.",
            "Jax is just another Gibbs sampler which is normally used for basis for learning the para meters for Bayesian models.",
            "So we use jacks for implementing the model and the rational behind this limitation of the data set.",
            "So for publication limit we actually want to include certain authors which we know before hand so we know their author profile.",
            "So we use these authors to later confirmed that.",
            "OK there author profile conforms to the profile which we have.",
            "Extracted from the input data set using our model so and better cleaning force used to reduce noise and sparsity and checks and particularly checks is not so scalable to the larger data corpses for Bayesian modeling, so that was another reason to keep the data set a little bit smaller.",
            "So if you find some unusual reserves, like maybe for semantic web topic, you don't see some very highly.",
            "They acknowledge the author for their son.",
            "Maybe the reason is that they have produced more number of publications as we have.",
            "Said here."
        ],
        [
            "So they're not included there, so these were the results about this running of this model on the data set.",
            "So the top is semantic web topics, and here is the top terms with the associated probability for these terms to be in this topic.",
            "Semantic lab and here are the top authors, or establishing an much done so on to the right side with this topic.",
            "Evolution that how this topic is actually evolving with passage of the time.",
            "So we are.",
            "Where to search was from 2001 to 2009.",
            "Miss you see.",
            "So from 2001 onward, the semantic web topic is still gaining and on the left side on the bottom side, if you see there is a database system.",
            "So if you look at the authors the doctor after all and Forex georgiann Marshall, so probably this car is also well known for the databases and or it is also semantic web and he is also producing the publications in the database.",
            "Area, and so if you look at the evolution of this database topics, it seems to be like this dipping down towards the end in from 2007 onward.",
            "And if you see at the same time when this topic of semantic web start emerging, so almost at the same time.",
            "So the database topic is just dipping down so it could be the reason that the meaning of the authors that are producing contents in the database fields with the emergence of the topic of the semantic vectors by semantic web they move from here to there.",
            "Save for the new topic or they may have pioneered this new topic of the semantic Web."
        ],
        [
            "Set to evaluate whether we are.",
            "Good or not, so normally in basin modeling you evaluate 2 on two types like you qualitatively easy if the topics detected by your model or good enough or not and and we have compared our model with the basic model for your basic model LDA.",
            "So if you look at qualitatively on the terms of these topics that appears that these topics tends to be more homogeneous with respect to the terms within the topic.",
            "So if you look at these topics, one can easily see OK.",
            "These topics are more covering topics when the LDA, the other thing works you can do.",
            "You change the quality of the topic is to my Arthur distance between the topics so that how distant these topics are to each other.",
            "Like if the topics are more distance for a model, that means the model is performing better than the other one.",
            "So we measure this distance using symmetric KL divergent between in all the topics or ATT and for the LDA and we see their service that the value for this metric here divergents.",
            "Of ATT is about 14 miles for the LDS rate, which indicates that the topics detected by the ATT they are more distant to each other, while the topics detected by idea there are less distinct to each."
        ],
        [
            "Other similarly we have also computer the author similarities using the symmetrical divergent.",
            "Also, the first we computed the authors who are intercropping concepts like say everyone is from database and form is from the crypt computing, so their distance is 9.05.",
            "That means they are far apart from each other.",
            "So in the next week my years the author similarity in topic, author similarity.",
            "So this loaded.",
            "Shows that these authors are very similar to each other with respect to their profiles so cruel and RX they share in 2.2 or 2.1 two their distance and similarly stop and or if they are well known.",
            "Guys in the semantic web so they are also very close to either piece of each other with respect to this distance Maya so."
        ],
        [
            "Both summary and future work.",
            "Here we are actually working to extract this model to incorporate the larger data set to incorporate our own.",
            "Limitation of the Gibbs sampler.",
            "Rather, to use the jacks for this.",
            "Implementation and also we want to test this HT in the recommendation scenario that for a given user profile is good too far.",
            "Find out the similar interests and also to make better use of the time information for curing this model."
        ],
        [
            "Thank you very much for your attention.",
            "We have time for a couple of questions.",
            "No one else.",
            "So.",
            "Search this is just.",
            "Only to figure out the temporal.",
            "I didn't quite understand the motivation.",
            "Basically.",
            "Like if you want to find some particular outdoor air, some particular time span, like if you look at the semantic web topic now, you can find lots of authors here in the semantic web area.",
            "So you want to know which are the authors who have pioneered this property.",
            "For that purpose you need the time information there.",
            "So at what time these are?",
            "What are the top level authors for this particular topic?",
            "So I haven't presented these results here, so but.",
            "We are able to calculate these results from this model, but because you have jointly computed the probabilities of authors, topics and time, so when you have the trend probabilities of these three variables, then you can condition these variables one on the other two Calculator.",
            "For other things, like given a particular topic, finds the top authors are in a particular time span.",
            "You can find this.",
            "So that's actually the purpose, so it's not the complete, it's an ongoing work basically.",
            "So it's just one step closer to our ultimate goal.",
            "Can use.",
            "I'm wondering if you need this.",
            "Well, I have just given you an example that if you want to find who have pioneered this particular author, how you can find this, then probably you need to improve things.",
            "So what the author writes about and at what time he writes about work.",
            "So that's why you use this model for that.",
            "Yes.",
            "The problem is you need to stay home topics to use in your model perfectly there did you do after she sat down with something, so I intentionally.",
            "Skip the technical details because of the community here.",
            "So yeah, for the LDA, you need to predefine the number of topics for your corpus actually, and there are different measures which you can use to identify OK, the which number of topics are, and that's normally you plot a log likelihood against your the number of topics and for which you've got the maximum log likelihood you suspect number of topics for your ideas, so that's right.",
            "Skipped international here.",
            "Network is it.",
            "Because we have extended the NDA so it's the same after you.",
            "You can use all those measures which you can use for LDA.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you very much for spending your time and good afternoon, so I'll be talking about our work, which is about analyzing the temporal dynamics of topics and authors in the social media so.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So maybe you know this interface is snapshots different snapshots from Google Scholar.",
                    "label": 0
                },
                {
                    "sent": "Actually when you look for some particular article on some particular topics, you come up with list of companies.",
                    "label": 0
                },
                {
                    "sent": "So when you have a careful look on this topic, you see this guy after awhile.",
                    "label": 0
                },
                {
                    "sent": "So he's talking about databases and if you look for his articles in 2009 also is talking about again about the data.",
                    "label": 0
                },
                {
                    "sent": "It seems that this guy is securely from databases.",
                    "label": 0
                },
                {
                    "sent": "But if you look for some other articles so just pour it in 2002.",
                    "label": 0
                },
                {
                    "sent": "We have articles on like Symantec Web along with.",
                    "label": 0
                },
                {
                    "sent": "He has also articles on databases in 2009 so it seems or subserved that users interest changes with respect to time.",
                    "label": 0
                },
                {
                    "sent": "So and few users have interests that stays the same.",
                    "label": 0
                },
                {
                    "sent": "So we met on them as they have the static interest rates do not change with the passage of time.",
                    "label": 0
                },
                {
                    "sent": "So the other observation is that with the passage of time to new topic emerges and some public stays longer.",
                    "label": 0
                },
                {
                    "sent": "Some topics are shortly topics there.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How then the question jumps?",
                    "label": 0
                },
                {
                    "sent": "How do we model these topic evolutions, and how do we capture dynamic user interest with respect to this evolving topics?",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then the natural question is why we need this.",
                    "label": 0
                },
                {
                    "sent": "So we want to model topics to observe public trends and also we can use this topics to find consimilar documents.",
                    "label": 1
                },
                {
                    "sent": "And we want to model the user interest to Rentify work.",
                    "label": 0
                },
                {
                    "sent": "The users right about.",
                    "label": 0
                },
                {
                    "sent": "And also to identify authors who have similar interests and you can use this to find some unusual work by an author, so an modeling time can help us in identifying how the topic involves how the topic lifecycle changes and also to capture the dynamic interest with respect to.",
                    "label": 1
                },
                {
                    "sent": "The time",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So having said that, OK, we want to capture these things.",
                    "label": 0
                },
                {
                    "sent": "Now let's be more clear about the problem that what we have and what we want to achieve.",
                    "label": 0
                },
                {
                    "sent": "So the available information is like there are users who are writing some contents at some particular time.",
                    "label": 0
                },
                {
                    "sent": "So with the passage of time, some new user comes in and writes about few topics or content and produce content.",
                    "label": 0
                },
                {
                    "sent": "That key plus one time and later.",
                    "label": 0
                },
                {
                    "sent": "In the time for more users Act or the same user keep producing contents over a period of time.",
                    "label": 0
                },
                {
                    "sent": "So once we have this available information which we want to extract from this information is what these users right about about this about this actually means here.",
                    "label": 0
                },
                {
                    "sent": "So what's the user writes about?",
                    "label": 0
                },
                {
                    "sent": "So what are the topics of interest for the user?",
                    "label": 0
                },
                {
                    "sent": "See efforts at some particular time.",
                    "label": 0
                },
                {
                    "sent": "So is and the second thing.",
                    "label": 0
                },
                {
                    "sent": "How these authors are associated.",
                    "label": 0
                },
                {
                    "sent": "With these topics.",
                    "label": 0
                },
                {
                    "sent": "So as the time pass on these topics keep evolving so new topic emerges.",
                    "label": 0
                },
                {
                    "sent": "So with the emergence of the new topics we need to relocate the user interest that if their interests got changed or not.",
                    "label": 0
                },
                {
                    "sent": "So we observe that users interest to change with the passage of time's at the start to write books in particular topic and later in the lifecycle they move on to other topics and keep producing the contents with respect to the other topics.",
                    "label": 0
                },
                {
                    "sent": "So we have now available information and we know what you want to achieve from this.",
                    "label": 0
                },
                {
                    "sent": "So we're talking about the topic so.",
                    "label": 0
                },
                {
                    "sent": "What topic actually means here?",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if you look at this text sniper.",
                    "label": 0
                },
                {
                    "sent": "And if you read this text me, but we will come up, you will quickly come back.",
                    "label": 0
                },
                {
                    "sent": "OK, this document or this text sniper is about this thing or about this.",
                    "label": 0
                },
                {
                    "sent": "This information is about these objects.",
                    "label": 0
                },
                {
                    "sent": "So this thing is actually your topic an you can easily find few terms that define your topic within that document.",
                    "label": 0
                },
                {
                    "sent": "So these terms are mostly occurring together in the most similar documents.",
                    "label": 0
                },
                {
                    "sent": "And there defines the topic.",
                    "label": 0
                },
                {
                    "sent": "So we define the topic like as a probability distribution of words.",
                    "label": 0
                },
                {
                    "sent": "So for each.",
                    "label": 0
                },
                {
                    "sent": "So there's.",
                    "label": 0
                },
                {
                    "sent": "These are the example topics.",
                    "label": 0
                },
                {
                    "sent": "If you look at these terms so this.",
                    "label": 0
                },
                {
                    "sent": "Terms like on the left column, database, Curie Sequence Control, search law, molecular and schema.",
                    "label": 0
                },
                {
                    "sent": "They do catch up.",
                    "label": 0
                },
                {
                    "sent": "They have some semantic relationships which are with each other and one can see OK.",
                    "label": 0
                },
                {
                    "sent": "These terms are representing the say the topic like databases and similarly on the right side you can see these Trump's Web Ontology, semantic language RDF, so these terms are semantically related with each other and you may infer that OK, this is about the semantic web.",
                    "label": 0
                },
                {
                    "sent": "So each of these terms has some weight associated with it.",
                    "label": 0
                },
                {
                    "sent": "That with what weight this term is associate associated with this particular topic.",
                    "label": 0
                },
                {
                    "sent": "So normally we define this topic as a probability distribution over the vocabulary.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So once we have this information with us.",
                    "label": 0
                },
                {
                    "sent": "So we know what we want to achieve.",
                    "label": 0
                },
                {
                    "sent": "We know what the topic is and we know this information is available, so we need some kind of a mechanism or tool or machine which can help us in converting this available information into our desired format.",
                    "label": 0
                },
                {
                    "sent": "So for this purpose we introduce the author topic and Time model which is helpful in capturing and producing the desired output.",
                    "label": 0
                },
                {
                    "sent": "It captures these dependencies between.",
                    "label": 0
                },
                {
                    "sent": "Topics, authors and time and produces the topics and the topic lifecycle and the authors that are that are.",
                    "label": 0
                },
                {
                    "sent": "And that are associated with these particular topics.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we.",
                    "label": 0
                },
                {
                    "sent": "Run this model on a site seer data set.",
                    "label": 0
                },
                {
                    "sent": "So, but before that.",
                    "label": 0
                },
                {
                    "sent": "So this model can be useful or helpful to answer the questions like so, which are the important authors for argument topics.",
                    "label": 0
                },
                {
                    "sent": "Once you have this model, you have input and it has produced the desired output.",
                    "label": 0
                },
                {
                    "sent": "Then you can cure this model for different queries or for different questions, so some of them like which are the important authors forearc even topic or who are The Pioneers of a topic.",
                    "label": 1
                },
                {
                    "sent": "And similarly you can see this model can potentially be used for monitoring the topic absolution and also the monitoring the author's profile.",
                    "label": 0
                },
                {
                    "sent": "And also if you want to compare some users interests, you have a given user interest.",
                    "label": 0
                },
                {
                    "sent": "If you want to find the similar users so you can also post this query to model to find the similar authors.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what the experimental data set?",
                    "label": 0
                },
                {
                    "sent": "So you will see this quite unusual data set.",
                    "label": 0
                },
                {
                    "sent": "We restricted this data set due to certain reasons, so we have total of about 5000 documents from the sightseer publications of the King from the computer science remain and the time period was from 2001 to 2009, so we opted out for about 18 authors and having publications from 180 to 300 publications so.",
                    "label": 0
                },
                {
                    "sent": "And we did get a cleaning with and remove the stock words and use Porter stemmer to remove the.",
                    "label": 0
                },
                {
                    "sent": "Remove the word inflections.",
                    "label": 0
                },
                {
                    "sent": "So an we used Jax.",
                    "label": 0
                },
                {
                    "sent": "Jax is just another Gibbs sampler which is normally used for basis for learning the para meters for Bayesian models.",
                    "label": 0
                },
                {
                    "sent": "So we use jacks for implementing the model and the rational behind this limitation of the data set.",
                    "label": 1
                },
                {
                    "sent": "So for publication limit we actually want to include certain authors which we know before hand so we know their author profile.",
                    "label": 0
                },
                {
                    "sent": "So we use these authors to later confirmed that.",
                    "label": 0
                },
                {
                    "sent": "OK there author profile conforms to the profile which we have.",
                    "label": 0
                },
                {
                    "sent": "Extracted from the input data set using our model so and better cleaning force used to reduce noise and sparsity and checks and particularly checks is not so scalable to the larger data corpses for Bayesian modeling, so that was another reason to keep the data set a little bit smaller.",
                    "label": 1
                },
                {
                    "sent": "So if you find some unusual reserves, like maybe for semantic web topic, you don't see some very highly.",
                    "label": 0
                },
                {
                    "sent": "They acknowledge the author for their son.",
                    "label": 0
                },
                {
                    "sent": "Maybe the reason is that they have produced more number of publications as we have.",
                    "label": 0
                },
                {
                    "sent": "Said here.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So they're not included there, so these were the results about this running of this model on the data set.",
                    "label": 0
                },
                {
                    "sent": "So the top is semantic web topics, and here is the top terms with the associated probability for these terms to be in this topic.",
                    "label": 0
                },
                {
                    "sent": "Semantic lab and here are the top authors, or establishing an much done so on to the right side with this topic.",
                    "label": 0
                },
                {
                    "sent": "Evolution that how this topic is actually evolving with passage of the time.",
                    "label": 0
                },
                {
                    "sent": "So we are.",
                    "label": 0
                },
                {
                    "sent": "Where to search was from 2001 to 2009.",
                    "label": 0
                },
                {
                    "sent": "Miss you see.",
                    "label": 0
                },
                {
                    "sent": "So from 2001 onward, the semantic web topic is still gaining and on the left side on the bottom side, if you see there is a database system.",
                    "label": 0
                },
                {
                    "sent": "So if you look at the authors the doctor after all and Forex georgiann Marshall, so probably this car is also well known for the databases and or it is also semantic web and he is also producing the publications in the database.",
                    "label": 0
                },
                {
                    "sent": "Area, and so if you look at the evolution of this database topics, it seems to be like this dipping down towards the end in from 2007 onward.",
                    "label": 0
                },
                {
                    "sent": "And if you see at the same time when this topic of semantic web start emerging, so almost at the same time.",
                    "label": 0
                },
                {
                    "sent": "So the database topic is just dipping down so it could be the reason that the meaning of the authors that are producing contents in the database fields with the emergence of the topic of the semantic vectors by semantic web they move from here to there.",
                    "label": 0
                },
                {
                    "sent": "Save for the new topic or they may have pioneered this new topic of the semantic Web.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Set to evaluate whether we are.",
                    "label": 0
                },
                {
                    "sent": "Good or not, so normally in basin modeling you evaluate 2 on two types like you qualitatively easy if the topics detected by your model or good enough or not and and we have compared our model with the basic model for your basic model LDA.",
                    "label": 0
                },
                {
                    "sent": "So if you look at qualitatively on the terms of these topics that appears that these topics tends to be more homogeneous with respect to the terms within the topic.",
                    "label": 0
                },
                {
                    "sent": "So if you look at these topics, one can easily see OK.",
                    "label": 0
                },
                {
                    "sent": "These topics are more covering topics when the LDA, the other thing works you can do.",
                    "label": 0
                },
                {
                    "sent": "You change the quality of the topic is to my Arthur distance between the topics so that how distant these topics are to each other.",
                    "label": 1
                },
                {
                    "sent": "Like if the topics are more distance for a model, that means the model is performing better than the other one.",
                    "label": 0
                },
                {
                    "sent": "So we measure this distance using symmetric KL divergent between in all the topics or ATT and for the LDA and we see their service that the value for this metric here divergents.",
                    "label": 0
                },
                {
                    "sent": "Of ATT is about 14 miles for the LDS rate, which indicates that the topics detected by the ATT they are more distant to each other, while the topics detected by idea there are less distinct to each.",
                    "label": 1
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Other similarly we have also computer the author similarities using the symmetrical divergent.",
                    "label": 0
                },
                {
                    "sent": "Also, the first we computed the authors who are intercropping concepts like say everyone is from database and form is from the crypt computing, so their distance is 9.05.",
                    "label": 0
                },
                {
                    "sent": "That means they are far apart from each other.",
                    "label": 0
                },
                {
                    "sent": "So in the next week my years the author similarity in topic, author similarity.",
                    "label": 0
                },
                {
                    "sent": "So this loaded.",
                    "label": 0
                },
                {
                    "sent": "Shows that these authors are very similar to each other with respect to their profiles so cruel and RX they share in 2.2 or 2.1 two their distance and similarly stop and or if they are well known.",
                    "label": 0
                },
                {
                    "sent": "Guys in the semantic web so they are also very close to either piece of each other with respect to this distance Maya so.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Both summary and future work.",
                    "label": 0
                },
                {
                    "sent": "Here we are actually working to extract this model to incorporate the larger data set to incorporate our own.",
                    "label": 0
                },
                {
                    "sent": "Limitation of the Gibbs sampler.",
                    "label": 1
                },
                {
                    "sent": "Rather, to use the jacks for this.",
                    "label": 0
                },
                {
                    "sent": "Implementation and also we want to test this HT in the recommendation scenario that for a given user profile is good too far.",
                    "label": 0
                },
                {
                    "sent": "Find out the similar interests and also to make better use of the time information for curing this model.",
                    "label": 1
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you very much for your attention.",
                    "label": 0
                },
                {
                    "sent": "We have time for a couple of questions.",
                    "label": 0
                },
                {
                    "sent": "No one else.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Search this is just.",
                    "label": 0
                },
                {
                    "sent": "Only to figure out the temporal.",
                    "label": 0
                },
                {
                    "sent": "I didn't quite understand the motivation.",
                    "label": 0
                },
                {
                    "sent": "Basically.",
                    "label": 0
                },
                {
                    "sent": "Like if you want to find some particular outdoor air, some particular time span, like if you look at the semantic web topic now, you can find lots of authors here in the semantic web area.",
                    "label": 0
                },
                {
                    "sent": "So you want to know which are the authors who have pioneered this property.",
                    "label": 0
                },
                {
                    "sent": "For that purpose you need the time information there.",
                    "label": 0
                },
                {
                    "sent": "So at what time these are?",
                    "label": 0
                },
                {
                    "sent": "What are the top level authors for this particular topic?",
                    "label": 0
                },
                {
                    "sent": "So I haven't presented these results here, so but.",
                    "label": 0
                },
                {
                    "sent": "We are able to calculate these results from this model, but because you have jointly computed the probabilities of authors, topics and time, so when you have the trend probabilities of these three variables, then you can condition these variables one on the other two Calculator.",
                    "label": 0
                },
                {
                    "sent": "For other things, like given a particular topic, finds the top authors are in a particular time span.",
                    "label": 0
                },
                {
                    "sent": "You can find this.",
                    "label": 0
                },
                {
                    "sent": "So that's actually the purpose, so it's not the complete, it's an ongoing work basically.",
                    "label": 0
                },
                {
                    "sent": "So it's just one step closer to our ultimate goal.",
                    "label": 0
                },
                {
                    "sent": "Can use.",
                    "label": 0
                },
                {
                    "sent": "I'm wondering if you need this.",
                    "label": 0
                },
                {
                    "sent": "Well, I have just given you an example that if you want to find who have pioneered this particular author, how you can find this, then probably you need to improve things.",
                    "label": 0
                },
                {
                    "sent": "So what the author writes about and at what time he writes about work.",
                    "label": 0
                },
                {
                    "sent": "So that's why you use this model for that.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "The problem is you need to stay home topics to use in your model perfectly there did you do after she sat down with something, so I intentionally.",
                    "label": 0
                },
                {
                    "sent": "Skip the technical details because of the community here.",
                    "label": 0
                },
                {
                    "sent": "So yeah, for the LDA, you need to predefine the number of topics for your corpus actually, and there are different measures which you can use to identify OK, the which number of topics are, and that's normally you plot a log likelihood against your the number of topics and for which you've got the maximum log likelihood you suspect number of topics for your ideas, so that's right.",
                    "label": 0
                },
                {
                    "sent": "Skipped international here.",
                    "label": 0
                },
                {
                    "sent": "Network is it.",
                    "label": 0
                },
                {
                    "sent": "Because we have extended the NDA so it's the same after you.",
                    "label": 0
                },
                {
                    "sent": "You can use all those measures which you can use for LDA.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}