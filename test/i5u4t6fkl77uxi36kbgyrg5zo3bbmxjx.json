{
    "id": "i5u4t6fkl77uxi36kbgyrg5zo3bbmxjx",
    "title": "The Neuroscience of Reinforcement Learning",
    "info": {
        "author": [
            "Yael Niv, Princeton Neuroscience Institute, Princeton University"
        ],
        "published": "Aug. 26, 2009",
        "recorded": "June 2009",
        "category": [
            "Top->Computer Science->Machine Learning->Reinforcement Learning"
        ]
    },
    "url": "http://videolectures.net/icml09_niv_tnorl/",
    "segmentation": [
        [
            "Guys, for those of you who are here on time and I wasn't, it was the fault of this little thing.",
            "Everything in the Mac is excellent except that.",
            "And they charge $50.00 for it.",
            "I ran back to my hotel room where when I packed my bag today said to myself, this is the one most important thing to take and then I left it there because it was standing right next to the telephone cord which looks exactly the same.",
            "So classic object recognition problem.",
            "And the presentation.",
            "OK so.",
            "Wow.",
            "So the neuroscience of reinforcement learning.",
            "Now I don't have my notes either, so I'm like driving blind.",
            "That's fine, so I'm yelling if you'll you won't forget me now after so many mishaps and I'm at Princeton University."
        ],
        [
            "And the reason I decided to give this tutorial."
        ],
        [
            "Are basically well, the one reason is that reinforcement learning.",
            "'cause do you hear me by the way?",
            "Reinforcement learning is revolutionized.",
            "Our understanding of learning in the brain in the last two decades or so, yeah.",
            "But this mic is only for the camera, it doesn't.",
            "It's not connected to anything that you can hear, so it is on.",
            "You could also come and sit closer 'cause they're closer seats.",
            "OK, so as I said, reinforcement learning is really revolutionized.",
            "The field of neuroscience in general, but more understanding learning."
        ],
        [
            "In the brain, and it turns out, surprisingly, that not many machine learners know this, and I thought this was kind of amazing.",
            "First of all, well."
        ],
        [
            "You should know this because first of all you can take pride an know that you know if you study reinforcement learning.",
            "There are a bunch of neuro scientists that read your papers and then convert that to knowledge about the brain.",
            "And for some of us it's important to understand the brain so it can be proud that you that you contributed to that."
        ],
        [
            "The second thing is you can ask, you know not only what can I do for neuroscience?",
            "Welcome neuroscience do for me.",
            "So how can neuroscience advance reinforcement learning?",
            "And that's the thing that I want to try to try to show you today.",
            "Mostly talk about.",
            "What we understand about the brain given reinforcement learning.",
            "But it's your job to do the opposite and I'll try to point out some places where where you can actually do this inversion easily.",
            "So."
        ],
        [
            "Why are you here of?",
            "Except for the fact that he had an extra 15 minutes to read your email.",
            "Hopeful."
        ],
        [
            "Lee, you're here because you want to learn something about learning and animals and humans.",
            "And."
        ],
        [
            "Because you want to find out the latest about how the brain does reinforcement learning."
        ],
        [
            "And as I said, to find out how understanding learning in the brain can help reinforcement learning greisser.",
            "So these are the three things that I'll cover today and the."
        ],
        [
            "That is, if you're here for any other reason.",
            "An your time is probably better spent elsewhere, so we're not going to.",
            "I'm not going to talk about the brain in general too much.",
            "I'm not going to teach you reinforcement learning.",
            "And yeah, reading email can do outside, so I'll just do just a quick survey so I know I know why you are really here.",
            "So how many of you on a scale of 1 to three with one being?",
            "Not very 2, being quite well in three.",
            "I'm an expert in it.",
            "How many of you know reinforcement learning?",
            "So first one, not very.",
            "OK. Kind of.",
            "Experts OK, so the not very will have to like do a quick speed up learning on this 'cause I'm not really going to introduce reinforcement learning in its basics now.",
            "Same for neuroscience.",
            "How many of you don't know very much about neuroscience in the brain?",
            "How many know kind of?",
            "How many are experts nor scientists in the crowd?",
            "OK, well, OK, so it's kind of balanced the way the way I'd plan for it to be.",
            "So I was thinking of giving a break in the middle, but now given that I'm so late I won't, but you can."
        ],
        [
            "Feel free to give yourself a break at some point or go get coffee if you feel that you really need it.",
            "This is a hard hour right after lunch.",
            "Those of you who came from Europe or like me came from Israel.",
            "It's a much more comfortable hour.",
            "It's now like 8:00 PM my time so."
        ],
        [
            "Easier time then right after lunch, but basically the outline.",
            "Well I'll tell you.",
            "The outline of the top of the tutorial, but I'll tell you in advance that each part of this tutorial is kind of a module that lives on its own except for the first three parts.",
            "So that's why I said feel free to like if you feel that you need your coffee or your fault, otherwise you'll fall asleep.",
            "Just go get coffee, come back and tune into the next module in the same if you kind of fade, fade out then just wait till the next time I show the outline, 'cause every time I'm going to show the outline, the beginning of each."
        ],
        [
            "Action.",
            "So what are we going to talk about?",
            "I'll start with talking a little bit about the brain.",
            "Very coarse grained, just in general to put us all on the same footing.",
            "And then talk about learning and decision making and animals and humans.",
            "Again, very broadly, trying to tie that to reinforcement learning and why.",
            "Why do we think that reinforcement learning has something to do with actual animal learning or human?"
        ],
        [
            "Turning then I'll talk about the most important part, which is dopamine and prediction errors.",
            "The biggest success story of computational neuroscience I think.",
            "Or one of the biggest so far.",
            "So these three parts kind of go together, and from here start."
        ],
        [
            "Being modular.",
            "We'll talk about our actor critic architectures in the basal ganglia.",
            "Um?"
        ],
        [
            "We'll talk about two other algorithms, so actually critic is one way to do model free reinforcement.",
            "Learning.",
            "Sarsa and Q Learning are two other ways to do model free reinforcement learning and will talk about whether well after we talk about actor critic in the basal ganglia.",
            "It turns out that maybe the brain actually does sorceror Q learning, and this is this is 1 area where the brain can teach us a little bit about machine learning because we could basically ask.",
            "There are three algorithms, which one does the brain use.",
            "And since the brain does what it does pretty well, maybe that will give us some insight.",
            "On comparing between these algorithms.",
            "Then it will."
        ],
        [
            "Talk about model free and model based reinforcement learning in the brain.",
            "So until now everything was model free but there will be a model based part."
        ],
        [
            "And then average reward reinforcement learning a different formulation that's not used as widely reinforcement learning, but may tell us something about tonic dopamine in the brain."
        ],
        [
            "Add finally next to last.",
            "If we have time.",
            "This was not in the slides that I put on line.",
            "I added it as a bonus so if we get to it will talk about risk sensitivity and reinforcement learning in the brain."
        ],
        [
            "And with open challenges and future directions for neuro scientists.",
            "For the one or a scientist in the crowd.",
            "And for reinforcement learning.",
            "OK, so as I said.",
            "We'll start with the brain coarse grain, just to kind of."
        ],
        [
            "The feel of what what we're talking about here.",
            "So the first question is a question for you, which is why do we have a brain?",
            "Ideas?",
            "To survive.",
            "To answer my question, why do animals?",
            "Why?",
            "What is the main purpose of a brain?",
            "To move good answer."
        ],
        [
            "So I thought maybe you'd say because there weren't computers when we were invented."
        ],
        [
            "Actually, yes, I think it is in order to to move or to behave.",
            "And actually Daniel Wolpert, who is the person I stole this idea from, usually puts to move up there."
        ],
        [
            "And an example is this animal called the C squared.",
            "So the C squared is a little marine animal and what it does in the beginning of its life."
        ],
        [
            "Has two stages of its life.",
            "When it's a larva, it has a primitive brain that has an eye.",
            "It swims around, finds a nice place to attach to, attaches to a rock.",
            "And then once it attached."
        ],
        [
            "In the second part of its life and its adult stage, it just sits on the rock doesn't move anymore in a digests its own brain.",
            "So to move is a good answer, and in fact you all know many living creatures that live happily without a brain and they don't move for instance."
        ],
        [
            "This one."
        ],
        [
            "So this is our brain.",
            "This is a human brain.",
            "You've probably seen pictures like this many times and it won't go into the names of the different areas.",
            "They don't really matter for our purpose.",
            "What does matter is this is by the way, aside for you looking at the human brain from the side, the eyes would be here.",
            "The neck down here somewhere you know face neck.",
            "This is the back of the brain."
        ],
        [
            "And you can think about the whole interaction between the brain and the world.",
            "In this way we have."
        ],
        [
            "World.",
            "And the world enters into our realm in our knowledge, through sensory processing in the brain.",
            "So the brain, first of all, has to take in all its sensory data and process that and huge chunks of the brain are devoted to that.",
            "The visual cortex.",
            "Here, the auditory cortex, the.",
            "Matter sensory cortex.",
            "The olfactory cortex.",
            "Huge areas.",
            "And then on the other side."
        ],
        [
            "Comes out motor processing and again huge areas of the brain.",
            "This whole area and some of this area deals with motor processing.",
            "How to tell our muscles to do what we want to do so that we can perform motor actions?",
            "That will of course impact on the world and this thing will start again where in the mid?"
        ],
        [
            "So they're kind of smaller parts of the brain, but there are the parts that were interested in which you do the interesting things right.",
            "They take the sensory processing, they take the sensory data and decide what motor action to make using memory, cognition, decision making, all the high level functions, etc.",
            "So will be interested today and these areas kind of, assuming that how to turn things into motor commands and how to take input from the world is already done for us.",
            "The question is what to do?",
            "What to choose to do based on the inputs?"
        ],
        [
            "So what do we know about the brain?",
            "But this is going to be very coarse grained, right?",
            "Because we know we can teach classes about whole classes about the brain, but in general.",
            "In terms of anatomy, we know a lot about what is where in the brain."
        ],
        [
            "And what area is connected to which so we can draw these diagrams with different colors for different areas that that are distinct.",
            "Unfortunately, you should know if you read literature about the brain or listen to talks like this that the names of errors in the brain were made up before people knew what these areas did.",
            "So they follow structure, not function.",
            "So sometimes two areas will be called global pallidus, internal capsule and external capsule.",
            "They're completely different.",
            "They do completely different things.",
            "And two other areas that have the same name.",
            "Have very different names like the caudete nucleus in the payment because they have a big 5 big of.",
            "What's it called bundle of fibers?",
            "Going through them, they were given two different names with their part of the same structure we know today they do very similar things, so you can't always go from name to function, but in general we know a lot about what is, what is where, which areas connected to which area."
        ],
        [
            "In terms of single neurons, so the single cells that make up the brain, we also know quite a bit about how they work.",
            "That was actually the first big kind of computational neuroscience revolution.",
            "Hodgkin Huxley and understanding how neuronal spikes are generated, how neurons send electronic messages to each other.",
            "But I should say all that we know in general what a neuron does.",
            "If it were a very very simplified pointer on a point that gets inputs, decides what to do and sends an output that we know.",
            "But neurons are not."
        ],
        [
            "Point neurons they have.",
            "They have a complex 3D structure, so this is the cell body of a neuron and these are dendrites where the neuron gets its input and this is the Axon where the neuron sends its output and we know how the the cell body takes the inputs, it basically computes.",
            "The sum of them, and if the sum is higher than a threshold, then the neuron sends output.",
            "The thing is, these little things that in the picture look like they don't really match."
        ],
        [
            "Sure.",
            "What they really look like is that.",
            "So they're very, very delicate and intertwine structures where neurons can touch each other in many, many places or in few places.",
            "And it's unclear what this big 3D structure is, therefore, but clearly it's there for some reason.",
            "Otherwise the brain went well, biology wouldn't bother.",
            "Came on this side.",
            "These can be so both these and these can be very very complex structures and there are models of.",
            "How an input that comes at this point can be different from an input that comes at this point, but it's very hard to integrate this into a functional understanding of.",
            "You know how does the neuron even know where to put its dendrites?"
        ],
        [
            "Networks of neurons.",
            "So going from the level of single neurons to networks, we have some ideas how networks work.",
            "But in general we're still in the dark.",
            "I would almost say we have no idea, but you know I wrote we have some ideas for those people who do have some ideas.",
            "I don't understand it much."
        ],
        [
            "In terms of learning in the brain that really, that's really what we're here for today.",
            "So this is 1 area where we know a lot of facts.",
            "We know things about LTP, which is long term potentiation, long term depression, spike, timing dependent plasticity.",
            "So how do connections between neurons synapses between neurons change when?",
            "A signal is passed through a neuron, but although we know all these facts and although people think that learning happens through these changes in synaptic strength or synaptic weights.",
            "There is no direct proof of that.",
            "There's no direct proof of that is at all related to learning in the general behavioral sense.",
            "It's not clear.",
            "What is the relationship between these kinds of synaptic learning and the computations that we'll talk about today?"
        ],
        [
            "And finally, in terms of function, as I said, we have very coarse grained knowledge of what different brain areas do, but we have to be careful, especially the names are sometimes misleading like you can have neurons in motor cortex that actually respond to color and not to motor.",
            "And rather than controlling motor commands, and it's definitely more complex when you get to higher cognitive areas.",
            "So the whole front of the brain, the frontal cortex used to be considered an area that does nothing because it does the most important things.",
            "It does the higher cognitive function, so you leave it in the frontal cortex and people still can move and eat and drink and sleep.",
            "They look like.",
            "They are animals that behave like animals do, but they're just not people anymore.",
            "So or they are people, but their personality changes their memory ability, their learning ability changes.",
            "So those areas we know much less about.",
            "OK."
        ],
        [
            "So.",
            "The the status of neuroscience today is we have a lot of facts about the brain and people do thousands and millions of experiments.",
            "Which gather more and more facts, but the problem is we still don't understand how to put these facts together and how the brain works.",
            "And this is where machine learning can perhaps help, or at least I believe that machine learning can help."
        ],
        [
            "So.",
            "Let's talk about learning and decision making and why it's related to reinforcement learning.",
            "By the way, stop me if you have questions.",
            "Just raise your hand and hopefully I'll see."
        ],
        [
            "So.",
            "You might ask yourself, what did our scientists do all day?",
            "You know what?",
            "You guys do all day.",
            "You sitting right simulations and it's really hard.",
            "What do these newer scientists do?",
            "Just collect data points.",
            "What we do all day is."
        ],
        [
            "We try to figure out how the brain generates behavior, so this two way St between the brain and behavior."
        ],
        [
            "And so you might ask yourself, well, OK, if it's one question, do we need so many neuro scientists for one simple question?",
            "So from the introduction I already gave, you might."
        ],
        [
            "Already realized that the problem is that the brain is really complex.",
            "This is a picture of what was known 20 years ago about the circuitry of vision processing.",
            "So all these little blocks are vision areas and the the main connections between them.",
            "Not all the connections between them.",
            "This was 20 years ago, so today you can imagine you can't even draw.",
            "The excess of data that we've collected there."
        ],
        [
            "So the old idea of studying the brain was, well, we can look at the brain structure and get from structure to function 'cause the structure is not is not there for no reason.",
            "It's not random structure, it's very orderly.",
            "Different animals have the same structure in their brain.",
            "It must be that the structure is important to function.",
            "But the problem was indeed this structure is real."
        ],
        [
            "Complicated and you know this kind of structure that we've looked at before really, really complicated.",
            "And it turns out that just looking at structure and inferring function from it is kind of like trying to reverse engineer your computer by looking at the motherboard and saying what does this do is very orderly structure.",
            "We must be able to look at it and know what it does."
        ],
        [
            "So.",
            "Just to put numbers on thanks the brain."
        ],
        [
            "As 10 to the power of 11.",
            "So that's 100 billion if I'm not mistaken, neurons and each neuron is connected on average to 1000 others, so you know, quite some."
        ],
        [
            "Actually there.",
            "So it seems like, well, I started with why do we need so many neuroscience?",
            "It seems like we don't need any neuro scientists because we actually don't stand a chance and we should just give up."
        ],
        [
            "Now.",
            "But that's where computational."
        ],
        [
            "Our science comes in with the idea with a relatively new idea that well."
        ],
        [
            "Brain is a computing device, right?",
            "So if you wanted to.",
            "Reverse engineer your computer.",
            "The first thing he would ask was, well, what can I do with my computer?",
            "My computer computes things.",
            "The same thing about the brain.",
            "The brain is a computing device, So what we can ask is."
        ],
        [
            "Can we use computational models?",
            "To understand the functions of the brain rather than going from structure, we can go from what does it need to compute?",
            "What would it need in order to compute these things and then search for those functions in the brain?"
        ],
        [
            "And at this point we can take something that's very abstract in form abstract theory.",
            "It's not concrete.",
            "It's not like structure, but the abstract theory can miraculously help us organize and interpret all the concrete data that we have, and we don't know how to put together."
        ],
        [
            "So that's that's in general.",
            "How I how I see the contribution of computational neuroscience to understanding the brain and there is a framework that was suggested by David Marr."
        ],
        [
            "In the 70s.",
            "Um?",
            "He was a researcher who studied vision, one of the first computational neuro scientists.",
            "So this framework really helps us do computational neuroscience in the."
        ],
        [
            "Well.",
            "Understand what we're doing and what level of analysis we're looking at and the framework basically says that when you do computational neuroscience and we try to understand what is the computational function of the brain and how that is.",
            "How that is realized in the brain, you should always remember that there are three levels of analysis.",
            "One level is what is the problem that's called the computational level?",
            "What problem is the brain trying to solve?",
            "And this at this level it doesn't have to be the brain.",
            "This same problem could be solved by a computer by an algorithm by a robot.",
            "It's also hopefully solved by the brain if we're studying the."
        ],
        [
            "Rain.",
            "Then you can ask yourself what's the strategy or what are different strategies.",
            "Different algorithms that can solve this computational problem?",
            "Still, we're staying in the very abstract and the census that until here everything could still apply to a robot."
        ],
        [
            "And finally, the third level is how it's actually done by networks of neurons in the brain.",
            "This is called implementational level.",
            "So.",
            "David Marr suggested these three levels and what we're going to talk about today is.",
            "Mostly well, we're going to talk about all of them because The thing is reinforcement.",
            "Learning helps us define the problem.",
            "Define a set of strategies, and then understand how these are realized in the brain."
        ],
        [
            "What's the hardest problem you face in your life?",
            "Every day.",
            "What is that?",
            "I don't wanna know.",
            "OK.",
            "So my claim is one of the problems one of the hard problems we face.",
            "Everyone of us faces in our."
        ],
        [
            "A like for instance, you know, and we're choosing what to order at a restaurant."
        ],
        [
            "Or when we're playing video games or games with other people, like a game of chess or making high level decisions about what we want to do with our life.",
            "Our problem is exactly."
        ],
        [
            "The reinforcement learning problem of optimal decision making?",
            "How do we maximize our reward and minimize the punishment that we get from the world for everything that we do and reinforcement learning already tells us?"
        ],
        [
            "Why this problem is hard, right?"
        ],
        [
            "We know that reward or punishment may be delayed.",
            "Doesn't come immediately if you eat sushi, you might get a stomach ache 4 hours later if you make a move in chess, you might win or lose the game after many."
        ],
        [
            "Or actions, and that's the second problem that the outcome might depend not only on one action, but on many actions that you perform."
        ],
        [
            "And these two problems were termed years ago by by Rich Sutton actually in his.",
            "BA thesis the credit assignment problem.",
            "So this is a big problem that faces reinforcement learning is also the big problem that faces the brain.",
            "We interact with the world all the time.",
            "We get rewards, we get punishments.",
            "We have to decide what actions were the right actions that we did and what were the wrong ones.",
            "Which one wants to do in the future.",
            "Probably going to grad school is not a good one."
        ],
        [
            "So as I said."
        ],
        [
            "This is where reinforcement learning comes."
        ],
        [
            "And basically, oops.",
            "Specifies all three of Mars levels, so the problem the problem level.",
            "The computational level is optimal decision making.",
            "The algorithm is reinforcement learning, basically is a set of algorithms to solve this credit assignment problem.",
            "And the neural implementation, which we'll talk about today, is in the basal ganglia, dopamine, dependent learning, etc."
        ],
        [
            "So what we have so far is this idea of studying the brain is a computer is a computing device which may not seem so revolutionary to you, but it was quite revolutionary in neuroscience and still many neuroscientists kind of look at computation.",
            "There are scientists with an IO like what are you doing here?",
            "And this is a different take on networks of neurons.",
            "What neurons do people are used to asking themselves?",
            "What do these neurons represent?",
            "These represent a motor action or a combination of motor actions, or a line in space, or a line in a certain angle, etc.",
            "And I'm talking about looking at what these neurons compute, 'cause if you think about it, the brain doesn't care about just representing the world.",
            "Each area represents something.",
            "What will we get out of that we have to compute something with these representations in order to get to the point where we actually behave.",
            "So the next thing I want to talk about is what do animals brains really compute and that that should be kind of the guideline to computations we want to look at."
        ],
        [
            "So in general, there's.",
            "100 plus years or 100 plus years of animal learning theory behind us and this theory has identified over these experiments have identified two basic types of animal learning called also animal conditioning.",
            "So I want to go through each of them very quickly.",
            "And talk about how these two types relate to reinforcement learning."
        ],
        [
            "So I'm sure you've all heard about Pavlov this guy.",
            "So Pavlovi and conditioning is this kind of conditioning that that.",
            "We learn about in school where animals slobber when they expect food so."
        ],
        [
            "Pavlov did is.",
            "He showed that, well, he actually studied.",
            "He was a Russian neuro physiologist studying the endocrine system and and secretion of.",
            "Digestive juices in the pancreas.",
            "I think that's what he got his Nobel Prize for, not for anything about animal learning.",
            "And what he did?"
        ],
        [
            "It was he'd give the dog give dogs food and collect their saliva to analyze the different enzymes in it, etc.",
            "And what he noticed is that after a while the dog starts secreting saliva, right when he comes into the room before they got any food and that was the clue that actually there has been some conditioning, some learning about the relationship between him, Pavlov and food.",
            "But when he made this into a much more controlled.",
            "Experiment what he did is he."
        ],
        [
            "Would pair some stimulus, let's say a Bell with the food.",
            "So every time he would sound the Bell and two 2 minutes later give the dog.",
            "The steak."
        ],
        [
            "And what he says after a while, if he would just sound the Bell with no stakes."
        ],
        [
            "Til the dog would secrete these Salvation juices and so the idea here is that the animal learned that the Bell predicts food so so one thing that we know about animals is they can learn to predict what's going to happen in the future, which is a really, really useful thing to learn in the world because you don't have to wait for it to happen.",
            "You can act in advance like salivate."
        ],
        [
            "Of.",
            "And I want to show you 2 movies.",
            "I will show them here, let's hope.",
            "You know what?",
            "Since this won't work.",
            "OK."
        ],
        [
            "So in this movie, what you're going to see?",
            "This is a.",
            "View from the top of four cages with different with four different rats that are undergoing conditioning.",
            "And in the first part, so these rats, they have food.",
            "They have little food magazine in this corner where they can eat food pellets, and they're happily eating and getting used to the boxes that they're in.",
            "And now, in this light turned on, that means that a tone is sounded to them.",
            "You can't hear it here.",
            "So the light is just telling you that it's on and they're ignoring the tone.",
            "Now in the second stage, what happened was once the once the tone turned on a few seconds later they got a shock afoot.",
            "Shock to these bars.",
            "You saw that now you saw them jumping.",
            "That's when they got the shock.",
            "And now, 24 hours later, now I should say that it's enough to pair the tone with the shock once or twice for what you'll see now.",
            "So, 24 hours later, they are happily eating the food and you'll see what happens when the tone comes on.",
            "The video is continuing, it's just they are freezing.",
            "Out of fear, this one is like risking his life trying to get to the food.",
            "So you can think of this in the biological sense of there is something telling them that a predator is around and the right thing to do is freeze so the predator won't see you.",
            "That's why I said that one was risking his life.",
            "But that was a conditioned response.",
            "A learned response to that own.",
            "They did not get any shock in this experiment.",
            "In this phase of the experiment.",
            "So that was one movie.",
            "What was the other movie that I wanted to show you oh?",
            "Um?",
            "So this is another movie of conditioning and animals and this is a famous pigeon conditioning.",
            "But Skinner did a lot of So what happens here is the light.",
            "The little circle turned on over there.",
            "Now the food is available.",
            "You see the pigeon is like I don't care.",
            "Light is turning on.",
            "It doesn't care.",
            "Oh wow, here's some food.",
            "I'll eat the food.",
            "After awhile the pigeons like.",
            "What's that like there?",
            "I haven't seen that before.",
            "Oh food.",
            "After a few more trials.",
            "Or maybe this is not after a few more trials, yet fish is like suspiciously looking at that light.",
            "I remember that one.",
            "Came right before the food last time too.",
            "And now he's already learned, and he's looking at, you, know, when's that light going to come on?",
            "Oh came on.",
            "We need to show a closeup of what it's doing to the light.",
            "This looks tasty.",
            "So this is called autoshaping because automatically the.",
            "The pigeon learns to Peck at the light without it ever needing to pick at the light right?",
            "The light is just there and you could just like be standing next to the food and waiting for the food the whole time.",
            "But he starts pecking at the light and this is because the light predicts food and this behavior is so strong that actually if you try to ask the pigeon to not packet delight.",
            "You get into real trouble.",
            "So this is the same pigeon after some training and now every time it pecks at the at the light he will not get food.",
            "He's basically causing himself to not get food by this pecking if he just ignored the light it would be completely fine, but no picking allowed.",
            "And he's like no food after 8 days 32 trials every day.",
            "Still, it's pretty hard for him to ignore that light, but he's managing to not pick.",
            "He is looking at it and almost picking, but not exactly faking.",
            "And you'll get a close up now to see the packing as close as possible without touching.",
            "So this kind of what's called pavlovi and conditioned behavior is very, very powerful.",
            "What was the?",
            "What was the thing that made it full screen?",
            "Mcel you saw this?",
            "So it's very it's very very power."
        ],
        [
            "Careful behavior animals even have have trouble not emitting this, and the idea is if we rewrite all this to reinforcement learning that there is some.",
            "Learning probably model free in this case, but I didn't have to put that word in there.",
            "Some learning of the values of different stimuli, So what reward different stimuli, or what we'd call in reinforcement learning?",
            "Different states predict this is learned through experience, and then the idea is that once an animal learns this kind of value, it responds based on the value, and it's really hard to even avoid this response and not emit it, because this light does predict food in the pigeon.",
            "Can't ignore it, even though.",
            "We try so hard to make it ignore it.",
            "So this is one kind of learning prediction learning and it's related to reinforcement learning in this way.",
            "Why?"
        ],
        [
            "Before reinforcement learning and the 70s are worse, color and Wagner suggested that this kind of learning is error driven.",
            "So what they postulated is that the change in value of a stimulus.",
            "On a certain trial is proportional to the difference between the actual reward obtained on that trial and the sum of the values of all the stimuli that were present in that trial, and I should say this is one out of four equations that you'll have today.",
            "I think I'll have the.",
            "Well, tutorial with the least equations ever.",
            "So the idea here there were two assumptions.",
            "One is this idea of.",
            "An error correcting learning rule, so learning driven by errors in prediction.",
            "So if the sum of the values doesn't equal the reward, there is an error.",
            "And the second, the second assumption was that different predictors are summed linearly, and these two assumptions were based on a lot of experimentation.",
            "I'll just give you the important one."
        ],
        [
            "How do we know that animals really use an error correcting rule?",
            "And of course we care about this.",
            "'cause reinforcement learning uses error correcting rules.",
            "So this is an experiment called blocking and the idea is."
        ],
        [
            "In phase one, you pair a stimulus with reward with some kind of."
        ],
        [
            "Rewarding event and of course we already know from Pavlov then that."
        ],
        [
            "Stimulus will generate some Pavlovian response.",
            "If we test it even without the food.",
            "And now."
        ],
        [
            "Now in phase two we show 2 stimuli together.",
            "For instance, a tone and a light, and they predict."
        ],
        [
            "The same food, so the same food is given the same delay that it was given before.",
            "And now if you test the Bell."
        ],
        [
            "On its own, there is still a response to the Bell, but it turns out that there is no."
        ],
        [
            "Response to the light.",
            "So there is no new learning about the light in this case, and that's why it's called blocking.",
            "The idea is that."
        ],
        [
            "The fact that the tone already predicted the food block learning for the light, and this is true not only in animals, is true in humans as well, in experiments in which, for instance, they give humans they give people sets of symptoms that predict different diseases.",
            "An unknowingly.",
            "Within these symptoms there is this kind of structure where first there are a bunch of symptoms that predicted disease and then later a bunch of others are added to them, and then in the test people are asked does this symptom.",
            "On its own predicted disease, does this predicted disease in the same kind of blocking is shown?",
            "So actually this learning is very prevalent.",
            "It's very important in our life because there are always lots of.",
            "Stimulate together we want the one that's most predictive.",
            "We want to learn about the one that's most predictive of reward, but this was a major.",
            "Clue that learning is driven by errors in prediction."
        ],
        [
            "OK, second form yeah.",
            "Experiments experiments to determine whether the pigeon is learning costs on appeal just correlation.",
            "I.",
            "Do animals?",
            "That's a very good question.",
            "So the question was I was talking about the light predicting the food, but the question is, is this just correlation or is it causal?",
            "So you know if we think about it, the light does not cause the food the experimental causes both the light and the food.",
            "But what does the pigeon understand here?",
            "Does it understand a causal structure or does it understand some higher structure where there's a hidden cause causing these two different events to happen and?",
            "Um?",
            "Their computational models to both directions, and I think that the this is still a point of argument point of contention, but you asked, do animals actually intervene to test their causal hypothesis?",
            "And that's where instrumental conditioning actually comes in, because in instrumental conditioning animals have some control over the environment.",
            "In Pavlovi and conditioning, what defines approval?",
            "Open condition situation is that no matter what the animal does.",
            "Things won't change, it will get the food at the same time no matter what it did in the omission schedule that I showed you, the one where if the pigeon pecks, he doesn't get food.",
            "That's not a pavlovi and conditioning situation anymore, that's instrumental conditioning.",
            "That's where the actions actually determine rewards, so we'll talk about this and it might answer your question a little bit.",
            "Probably not directly.",
            "We can talk about that more.",
            "I'm just not not thinking right now.",
            "Nothing comes to mind a specific experiment that would tell the two apart, but.",
            "After think about a little bit more.",
            "OK.",
            "So."
        ],
        [
            "So the background to instrumental conditioning everybody knows povoa pavlof.",
            "I don't know if you've heard of Edward Thorndike.",
            "He's a little bit less famous, but also famous psychologists.",
            "He was he did research in the days when, right after Darwin's theory of evolution, there were all kinds of attempts to show that animals are indeed intelligent, because the idea was that, you know, we evolved from animals were intelligent.",
            "Are animals really intelligent?",
            "And people had all these anecdotes about their pets seemingly understanding language etc.",
            "And I could tell you that's true about my cat, but Thorndike was the first to show."
        ],
        [
            "So this is a non anecdotal way and his thesis at the age of 23.",
            "Which was called Animal Intelligence, an experimental study of the associative processes in animals and what Thorndike studies is these?"
        ],
        [
            "Puzzle boxes actually, if you see there are like original pictures of the puzzle boxes that he made, I think he was.",
            "He was actually a Carpenter and not a scientist so much, but, well, a good scientist and a good Carpenter.",
            "He would make these intricate puzzle boxes where you can put a cat inside a hungry cat inside the box and the cat had to learn an arbitrary set of actions that would get him out of the box and the boxes were more and more complex.",
            "The first box that he made a lever had to be pressed, but then others.",
            "He had.",
            "The cat had to pull a chain and press the lever and do something else and they became very complex and what he measured as a measure of learning is just how long?"
        ],
        [
            "To take the cat to escape, and that's what you're seeing in the graph here over different time trials, how many seconds it took the cat.",
            "Just get the food was outside the box I should say, and the cat was hungry.",
            "So how long it took him to get out and go get the food?",
            "And you can see that it decreases overtime, it's not.",
            "Monotonic decrease and what?"
        ],
        [
            "Thorndike saw over many animals in many boxes.",
            "Is that there are these gradual learning curves, but they don't look like all or none insight at some point.",
            "Suddenly the cat does it perfectly every time it looked more like trial and error.",
            "So he turned this the law of effect that cat does all kinds of random things and the ones that are most effective in getting the cat to state that is satisfactory that using his words.",
            "He called this set once it.",
            "Bring satisfaction to the animals are actions that are repeated more in the future."
        ],
        [
            "And a very good example of this kind of instrumental or operant conditioning.",
            "Is rats lever pressing in boxes, which is what Skinner who is actually more famous of.",
            "Thorndyke came about 50 years later studied.",
            "Um?",
            "A lot study to death basically and I wanted."
        ],
        [
            "Show you a movie here as well.",
            "Just so again, you get a feel of what we're talking about.",
            "What movie was that?",
            "That's a question I don't remember its name.",
            "Um?",
            "Not this one.",
            "This one.",
            "Skinner box.",
            "So here is a rat liver pressing for food.",
            "If he presses successfully, this light will turn on, so he's looking to see if he succeeded, and then when this light is on, he gets food.",
            "And you see, you know he knows what he's doing now.",
            "Delta sit level pricing is quite an arbitrary action for rats.",
            "Rats do not press levers in the world in the real world.",
            "They certainly if they want food, they usually go to the place of the food.",
            "There is were used to going to turn the light on there for it to turn on the ceiling, but rats are not used to going to press one thing in order to get food somewhere else.",
            "This is completely crazy for a rat to learn and still they managed to learn it.",
            "OK, he's just going to continue for a long time."
        ],
        [
            "So how is this related to reinforcement learning?",
            "So the idea is that if animals can learn something arbitrary like this, it can probably learn any arbitrary policy.",
            "To some degree.",
            "It might take some longer and longer to learn a policy that's really, really complex, but so does so.",
            "So is the case for our simulations and robots.",
            "But this policy is specifically learned in order to obtain rewards and avoid punishments in some causal way, because here if the rat doesn't press the lever, he won't get food at all, and so this is kind of the second part of reinforcement learning.",
            "So we have prediction, learning, learning values, and now we have policy learning learning of actions."
        ],
        [
            "So so far what we have is the world presenting animals or humans.",
            "Everything I said now is true also for humans with a huge reinforcement learning problem.",
            "Or maybe it's better to look at it is many small reinforcement learning problems and we know that animals and humans can learn both prediction and control which are the two important ingredients to solve these problems.",
            "Now the question is, now that we know that the brain does reinforcement learning, can reinforcement learning help us understand how the brain solves this problem?",
            "How it realizes these algorithms?",
            "And this brings us to the biggest success story of computational neuroscience in the last 20 years, which is the relationship between."
        ],
        [
            "Dopamine and prediction errors."
        ],
        [
            "So you might have heard about dopamine.",
            "How many people have heard about dopamine?",
            "Most of you.",
            "So dopamine is a neuromodulator that is created in the brain from 2 nuclei, kind of in the middle of an area called the midbrain called eventual mental area in the substantia nigra, and it's and it's sent all over the place so the whole brain mostly you see these arrows here because these are its main target, so the stratum and the prefrontal cortex and actually the amygdala as well, are the main target.",
            "Of dopaminergic projections, but dopamine basically goes everywhere, even in the visual cortex, there is some dopamine, and the reason that people are really, really interested in dopamine."
        ],
        [
            "Well, you've all heard about dopamine, probably because of its relationship to Parkinson's disease.",
            "So Parkinson's disease is caused by the death of dopaminergic neurons.",
            "There is less and less dopamine in the brain.",
            "At some point, people develop Parkinson's disease from losing these neurons.",
            "And so this."
        ],
        [
            "The original theories about what dopamine doesn't.",
            "The brain were very related to this, and people thought well in Parkinson's disease what gets damaged.",
            "What we see is that people stop behaving Motoric Lee as they normally did.",
            "They have a problem initiating actions, so maybe that is the role of dopamine in the brain and helping us initiate actions and control movement."
        ],
        [
            "But later it turned on that dopamine is also related to a host of other things, to drug addiction.",
            "So virtually all addictive drugs have some influence through dopamine, if not directly on dopamine.",
            "So cocaine amphetamine speed directly affects dopamine.",
            "Some affect dopamine less directly.",
            "Alcohol is maybe the only one that doesn't go.",
            "Through dopamine, but I think.",
            "I take that back.",
            "Some of the influence of alcohol is also through dopamine.",
            "Gambling addictions also related to dopamine.",
            "Natural rewards in general, learning with natural rewards turns out to."
        ],
        [
            "Related to dopamine, so this cause people to think that."
        ],
        [
            "They'll put me in.",
            "This may be involved in reward or in learning, which is very different from motor control.",
            "So now we already have three different functions for dopamine.",
            "And if that's not enough, it turns out."
        ],
        [
            "Dopamine is also involved in working memory and dealing with novel situations, in attention, deficit, hyperactive disorder, and schizophrenia in depression.",
            "Anything you want, basically anything that people care about in the brain.",
            "Dopamine is part of it.",
            "And this way it sounds crazy, but actually the brain only has four different neuromodulators.",
            "Their neurotransmitters, which are ways which are molecules by which one neuron communicates with another neuron.",
            "But the forward neuromodulators are molecules that are sent all over the place, and you might think if there are only four of these in the brain, they must have really, really important widespread functions and affect a lot of processing in the brain.",
            "So it's maybe not so surprising that dopamine is related to all these things.",
            "But still it makes neuro scientists really want to understand how it does what it does and how we can cure the situations where it does the wrong thing.",
            "So as there are many functions, there are many hypothesis."
        ],
        [
            "Or I should say, as there are many scientists, there are many hypothesis.",
            "And we won't go through all of them for lack of time.",
            "I'll only talk about the first 2 by just to put these on the board and so you know that although I'm going to tell you that I think this one is true, it doesn't mean that it.",
            "But there are others to consider."
        ],
        [
            "So originally in the 80s, the first hypothesis about dopamine, well, not the first, but the very influential hypothesis was called the anhedonia hypothesis."
        ],
        [
            "And, um.",
            "Anhedonia is the inability to experience positive emotional states, so usually if you eat something nice or you have some positive experience with another person or whatever, you feel good about it.",
            "Anhedonia is a state where you don't feel good about things that used to make you feel good."
        ],
        [
            "And what why is saw is that neuroleptics which are drugs that are antagonist dopamine, so they stop the function of dopamine in the brain.",
            "These drugs cause anhedonia, so they cause people to not enjoy things that they used to."
        ],
        [
            "Joy in life.",
            "And so that basically."
        ],
        [
            "That was.",
            "His the reason is to suggest that dopamine.",
            "Maybe it has something to do with hedonic sore with enjoying pleasure in the world and.",
            "Perhaps the last movie know there will be another movie later."
        ],
        [
            "This is a movie from Peter.",
            "She's gallon Concordia here in Montreal, and what you're seeing here is a rat that is lever pressing but not for food.",
            "As you see there is no food magazine here.",
            "Whenever he presses the lever, he gets a ZAP of.",
            "Electrical current straight to the dopaminergic area of his brain and he loves it.",
            "He really, really wants to get this.",
            "You can see how he doesn't want the lever to go away.",
            "He's really like trying to coax it out because every time he gets this snap into his reign it just makes him feel really good.",
            "So this is called.",
            "Brain self stimulation reward and it was studied extensively.",
            "At the time when people realize that dopamine has something to do with reward and till today.",
            "So.",
            "In general, the idea was."
        ],
        [
            "OK, there are rewards in the real world.",
            "You know, coffee, cake, money, etc.",
            "How does the brain know that I got a reward?",
            "Well, it might know that I got a reward."
        ],
        [
            "Through this molecule, through this through dopamine, dopamine squirted all over the place, telling the brain a good thing now happened and that was why this anhedonia hypothesis and this explains."
        ],
        [
            "First of all, it explained.",
            "Uh, electrophysiological recordings that people had known of at the time, So what you see here is.",
            "These are recordings from the dopaminergic neurons of a monkey.",
            "Every dot here is when the neuron fired and every row is 1 trial on every trial.",
            "Sometime past then the monkey God's got some juice into his mouth.",
            "This is a thirsty monkey, so this is the time when he got the juice and then some more time passed.",
            "And what you see is this is a sum of all these dots here of all this raster plot and what you see is these dopaminergic neurons fire right after a reward and then after a while it go back to baseline.",
            "So the idea is they signal to the brain that our reward happened, that juice was obtained and this of course explains why the rat would want zaps."
        ],
        [
            "This brain to the dopaminergic area, because that's exactly like getting real rewards in the world.",
            "And it explains why if you block dopamine."
        ],
        [
            "Animals stop learning, so if you give neuroleptics and you try to do conditioning studies, they don't learn to lever press and they don't have to lever press for food.",
            "They don't work for normal rewards in the same way."
        ],
        [
            "But this story would have been simple and nice and we would have not needed reinforcement learning and the whole thing would have ended, except that in the 90s Schultz Wolfram."
        ],
        [
            "Delta also.",
            "Did these recordings started make?"
        ],
        [
            "His experiments a little bit more complex by adding the stimulus before the reward and what he saw is that."
        ],
        [
            "When a stimulus is shown here in, the reward is obtained 2 seconds later.",
            "This is again recordings in monkeys.",
            "The monkeys are getting juice rewards after seeing a visual stimulus, honest screen.",
            "Suddenly there is no response at all to the reward, as if the reward didn't happen.",
            "But there is a response to the stimulus instead.",
            "And if you take that same monkey."
        ],
        [
            "And occasionally not trial after trial, but occasionally show it the stimulus and not give the reward.",
            "Then you see that at the time were no reward was expected, but nothing happened.",
            "Actually, in these trouser was just a stimulus and then nothing happened.",
            "When the reward is expected, there is a dip in the firing, so the the neurons stop firing.",
            "So this is really puzzling.",
            "This doesn't look anymore like a signal.",
            "A straight off signal for reward, because here reward is obtained with no signal."
        ],
        [
            "So this is what we have.",
            "This is what Schultz had."
        ],
        [
            "Does it look familiar?",
            "If."
        ],
        [
            "It doesn't.",
            "I'll give you a hint.",
            "Does it look familiar?",
            "So the idea was."
        ],
        [
            "That perhaps what dopamine does its signals not reward, but a prediction error.",
            "So."
        ],
        [
            "So the reason?",
            "Huawei.",
            "Before the relationship between a stimulus center award is learned, there is responding to the reward and after their relationship is established in response to reward goes away is in the beginning of training.",
            "The reward induces a prediction error and after it's already well predicted by the stimulus that comes before there is no prediction error at the time for reward, there's actually a prediction error at the time the stimulus because the stimulus was unexpected and arrived on its own, and these are three different experiments.",
            "From shelters, labs showing the same kind of disappearance of the prediction error of the dopaminergic signal after a reward through training."
        ],
        [
            "This is another experiment from the same lab where there were five different stimuli in each trial.",
            "The monkey could see one of these five stimuli in that signal to him.",
            "How much reward he was going to get if it was this stimulus he was going to get 0 milliliters fit with.",
            "This one is going to be oh point, oh, 75 and oh point, 25 milliliters, etc.",
            "And as I said, the reward is now predicted, but the stimulus itself, the identity of the stimulus is not predicted and so that generates should generate.",
            "A prediction error, an indeed you see dopaminergic response responses to the stimuli with a size that grows with the predicted reward.",
            "So that's what we would expect from prediction error signal.",
            "And we can do the same thing."
        ],
        [
            "Not with the amount of reward, but probability of reward again from the same lab.",
            "Five different stimuli giving the same amount of reward but with different probabilities and what you see is there is a higher response for higher probability and also at the time of rewards the opposite.",
            "Now if the reward was 100% predicted, there is no response to the reward, but if it was only 50% predicted, then there is a 50% prediction error unrewarded trials.",
            "These are only rewarded trials.",
            "And so forth.",
            "So it seems like everything fits this idea that what dopamine actually does is signal prediction errors."
        ],
        [
            "Other than just rewards.",
            "Yeah.",
            "Suppose you have stimulus which predicts stimulus, which predicts a reward.",
            "So will you get a dopamine response in the sectors?",
            "According to this theory, know if all the timing between everything is fixed then you shouldn't.",
            "It should go back to the very first predictor.",
            "There is one experiment in rats by.",
            "Brian Hyland that shows that it doesn't completely go all the way back, but that experiment.",
            "It's very, very hard to record dopaminergic neurons in rats.",
            "He was the first one to record them and he had very, very few neurons.",
            "So I'm not sure we can rest assured with those data.",
            "I don't think Wolfram Schultz Wolfram Schultz is kind of the expert of recording dopamine neurons and monkeys, and I don't think he's ever done stimulus stimulus reward.",
            "You might also ask what about stimulus reward reward?",
            "You would want the stimulus to have you know twice as much prediction error, nothing to the rewards, so there are still things to be done.",
            "But people have put this theory to."
        ],
        [
            "Stringent tests, not only the ones that we saw here with different probabilities in different magnitudes, but also.",
            "What Hannah Buyer and Paul Glimcher did is they said well.",
            "We know that if we have regular temporal difference, learning the value at each point in time should be basically a an exponentially weighted sum of all the previous rewards.",
            "So you can work that out out of TD learning and then we won't work it out right now, but you can check it later that the last reward should have the highest influence on the current value and then the one before that.",
            "Less influence in less according to the learning rate, so they're exponentially discounted because of the learning rate.",
            "And so the question is, could we see that in dopamine neurons?"
        ],
        [
            "And what they did is they gave monkeys different amounts of reward in each trial and recorded the prediction error.",
            "The dopamine signal at each trial.",
            "And.",
            "Fit a model.",
            "Well, let me be very clear here now we're looking at a prediction error.",
            "Prediction error should be reward minus value, right?",
            "So the last reward should have awaiting of 1.",
            "Minus the value.",
            "So minus this kind of exponent.",
            "And so they took the prediction error.",
            "Regressed it on all the previous of the last 10.",
            "The magnitudes of the last 10 rewards an indeed found.",
            "These points, the black point which fit amazingly well to the red line, which is a prediction of the model with a constant learning rate.",
            "And in the same study they they could also.",
            "Do a kind of slightly different analysis, where on every trial that model predicted what the prediction error should be after fitting the learning rate to the specific monkey and the measured firing rate is on this access that you see that it's basically a straight line as you could want from noisy biological measurements up to a prediction error of minus oh point 1.",
            "Then it kind of.",
            "Flattens out and that's that's an issue that we're still that people are still grappling with.",
            "The thing is."
        ],
        [
            "Prediction errors if dopamine firing is a prediction error.",
            "There can't be negative firing.",
            "It can only stop firing completely, right?",
            "So at some point this has to level out and something else maybe has to.",
            "Help in representing negative prediction errors that are hypothesis.",
            "Another endura body later does this or that.",
            "The length of the gap in firing.",
            "That's a hypothesis from Hannah Buyer that the length of the gap represents how big this prediction error.",
            "The negative prediction areas, but at least for positive prediction errors there's a nice linear relationship between what the model says the prediction error should be and how much the neuron fires."
        ],
        [
            "So the idea is the dopamine represents a prediction error and we know that prediction errors have a role in reinforcement learning.",
            "Prediction errors are for learning, right?",
            "So first of all, as we said, dopamine projects mainly to the basal ganglia.",
            "The basal ganglia are these complex structures on both sides, kind of inside there, not in the cortex there inside your brain.",
            "If you go kind of from here towards the middle.",
            "Um?"
        ],
        [
            "And what we know about."
        ],
        [
            "Dopamine does there is."
        ],
        [
            "That cortical straddle synapses show dopamine dependent plasticity, so this is quite a mouthful, but I'll.",
            "Unwrap, unpack."
        ],
        [
            "That so this is a neuron in the stratum.",
            "And it gets inputs from 2 director from 2 areas.",
            "One is from the cortex from from the outside.",
            "The frontal area of the cortex mostly.",
            "So this is this input coming to this synapse.",
            "And on the other hand it gets dopamine afferents.",
            "That kind of hug the synapses.",
            "This is called the neck of the spine, and this is the head of the spine.",
            "They hug the next of the spines of each and every synapse."
        ],
        [
            "It turns out.",
            "But if you.",
            "Invoke.",
            "If you excite the neurons here, so you invoke activity in these neurons and in a way that causes this neuron to fire and measure how that affects the strength of the synapse.",
            "Usually LTP, long-term potentiation and Hebbian learning prescribes that fire together wire together.",
            "If this fires, and then this fires, their connection strengthens, but it turns out that in these cortex to striatal synapses only if there is still coming around that happen.",
            "So here you see.",
            "At these measurements, dopamine was around and so the height of the activation of this neuron became higher after pairing their activity, their activity.",
            "In the bottom here there was no dopamine around, and it actually even became lower.",
            "So the idea is that it's not regular Hebbian learning here, but a three phase."
        ],
        [
            "After learning rule, you need to have both the presynaptic neuron and the postsynaptic neuron and dopamine around for learning, which is exactly what we wanted.",
            "We wanted learning contingent on prediction errors.",
            "If there is a prediction error, you should learn and if there is no prediction error, you don't need to learn."
        ],
        [
            "OK, so so far.",
            "What we have is that conditioning can be viewed as prediction learning."
        ],
        [
            "And we already have."
        ],
        [
            "An algorithm for how to do that given by reinforcement learning, which is temporal difference."
        ],
        [
            "Turning.",
            "And now we have a neural implementation of that.",
            "We have temporal difference errors in dopamine that affect learning in cortical striatal synapses in the basal ganglia."
        ],
        [
            "So this is very very very exciting for neuroscience because we want to understand what dopamine does and not only do we have an answer here, but we have a normative theory for why dopamine firing is the way it is.",
            "It's not only telling us that it's a prediction.",
            "Error tells us why would we want this to be?",
            "This way we want prediction errors for optimal learning of values that predict future rewards, so it's much more than just describing the function here."
        ],
        [
            "And this is.",
            "Also, an example of how once we have a computational model of learning that allows us to look in the brain for hidden variables that the model postulates, so a prediction error is basically a hidden variable.",
            "You can't see it in people's behavior or in the inputs from the world.",
            "It's something that the model.",
            "Suggested an here.",
            "We found it in the brain and will see other examples today of how these computational models can help us look for hidden variables and find them in the brain.",
            "Which one tells us what the brain does and two tells us that the model well doesn't tell us that the model is correct, but it's more support for the model."
        ],
        [
            "Yeah.",
            "Plus you have long hair here.",
            "Like a lot of models, I suppose, but it depends heavily on Auckland Razor.",
            "It's simply it's.",
            "Close to the sequels.",
            "Model possible, but only one of a class of models could imagine would have the same.",
            "Right, right?",
            "How much?",
            "The restaurant is sexy believe.",
            "This is the model.",
            "Up how well so there are two questions combined here.",
            "Why the question was?",
            "This is a simple model.",
            "Is this really as simple as what is dopamine does this very simple model?",
            "Or is this sub case of a more complex model that we haven't worked out yet and it might be?",
            "These experiments are very simple experiments, right?",
            "This is simple learning stimulus and then reward.",
            "You can think of much more complex learning scenarios, and dopamine hasn't been recorded in many more complex scenarios, so we don't know yet where it doesn't fit the theory.",
            "I'll come straight.",
            "There is a good thing to work by and something that's as prevalent and goes all over.",
            "The Braden intervenes in so many functions as dopamine, you would want it to be some simple story of what it does it not some very complex, intricate things that in this situation it does a in that situation.",
            "It does be because then how would the brain know how to interpret that?",
            "But that's not a reason to believe in this theory you have to do more experiments, basically free.",
            "The other three, or something like that?",
            "What if the other three, what?",
            "At least I don't mean like right, right?",
            "There are interactions between aura modulators, but not so strongly in this trade.",
            "Him at least as freedom is mostly innervate idby dopamine and not the others, so that Luckily we have kind of an isolated case there.",
            "That's why it's been studied mostly in the stratum and not in other areas.",
            "Whether neuro scientists actually believe that this is the function of dopamine.",
            "Depends on who you ask.",
            "'cause people like to have alternative theories and you know it's really boring.",
            "You can't publish 7 papers saying that theory is right.",
            "It's much easier or much more exciting to publish a paper saying that theory is wrong.",
            "I have a different theory, so people have different theories.",
            "I feel that it's been become more and more mainstream and people now kind of regularly talk about dopamine is a prediction error, whereas 10 years ago we were still trying to convince people to listen.",
            "So.",
            "But not everybody believes it, and it's not necessarily true.",
            "Yeah.",
            "So don't mean is partly sorry system.",
            "Part of the.",
            "Oh, there's.",
            "Is that correct?",
            "Not the same not the same though for me it doesn't cross the blood brain barrier, so dopamine that we have in the rest of our body does not go into the brain.",
            "That's why in Parkinson's disease you can't give people dopamine medication.",
            "You have to give them L DOPA, which is a precursor of dopamine that does cross the blood brain barrier.",
            "Rapidly doesn't distribute itself in the brain.",
            "What do you mean distribute itself?",
            "It's generated.",
            "Cody, of the arrow.",
            "So those responses are very, very quick.",
            "There are less than 100 milliseconds in the cases that I've shown.",
            "In some cases when it takes longer for information to filter into, the system has been shown more recently that the response could be slower, but it first actually one of the main criticisms against a prediction or hypothesis was how could it be so quickly and so quick?",
            "How could the brain know what it's predicting and what is its error in less than 100 milliseconds?",
            "But it turns out that in these very simple experiments.",
            "It can be done.",
            "The visual stimulus appears each time in a different area of the screen and there is a direct pathway through the superior colliculus to dopamine, telling it what stimulus.",
            "It's also very quickly it can compute the predictions.",
            "In other experiments it takes a little bit longer, but once you have it seems like once you have the prediction, dopamine tells the rest of the brain what the prediction error is.",
            "Yeah.",
            "You mentioned that in the rat experiment that if we have a net negative prediction error, then the dopamine just stopped.",
            "So what I don't understand this how people can steal sort of a Dick to gamble for example because they are keep getting negative rewards.",
            "So that's that's a great question.",
            "So the question is how can people get addicted to gambling although they get negative rewards all the time?",
            "And there are theories of how this kind of prediction error signal can be hijacked by substances of abuse, like drugs and by situations like gambling in order to create abnormal learning.",
            "The answer is the bottom line answer is we don't know for sure, but for this specific question there is a nice paper by David Reddish where he suggests that what happens is there is a false.",
            "Division into states.",
            "So the gambler basically assumes that whenever he gets a negative prediction error, he assigns that to one state of the world and he gets a positive prediction error.",
            "He assigns it to another state of the world.",
            "You know, like gamblers will kiss the guy before throwing them, and things like that.",
            "In his theory, that's a way in which the gambler tries to steer the world to the state where he got the positive prediction errors rather than the state where he gets negative prediction errors.",
            "But you're right, there is a puzzle here.",
            "About you know the more complex situations of learning.",
            "And one of the puzzles is how do we know what state of the world we're in?",
            "Paragraph that bottoms out and get splat there.",
            "That the gambler he gets his payoff on the linear side, but then he he's found the flat bottom wow.",
            "I think we yeah no.",
            "I think negative feedback is also scaled in the brain.",
            "The question is how?",
            "Maybe not through dopamine?",
            "Maybe through the length of the pause as I said, but that's not very clear.",
            "And also we have to learn to release or stormy right?",
            "Because at the beginning.",
            "First of all, we do know money is a good thing, so we sure.",
            "You know we have many years of education, so we of course alot of this is learned.",
            "Yeah.",
            "Are there any objective criteria that you need for, like reward stimulus?",
            "What I mean by that is, like you can imagine having a light and get food.",
            "So you can imagine instead of food you have a light and then another light.",
            "So do use would you see the same firing pattern?",
            "If it's 2 lines?",
            "Or is there something inherent about the fact that food is good for the animals?",
            "Yes, that that property needs to exist, whatever that property might be in order for this morning.",
            "So the answer to this is yes, rewards are special.",
            "In that they have some motivational rewards and punishments.",
            "They have some motivational significance, good or bad, motivational significance to the animal.",
            "This is a very, very fuzzy way of defining them.",
            "Because psychologists have argued for years and not gotten to a conclusion of what is the definition of a reward, but it somehow very clear some things are rewards and some things are not food.",
            "As a reward, light is not.",
            "But if light starts predicting or reward then now light becomes.",
            "A reward itself and animals will work, will press the lever just to get the light to turn on, and it's exactly like this story with money that we've learned through life, that money is a predictor of reward and we will work very, very hard for money where we actually don't eat money, right?",
            "So conditioned reinforcers are learned, and then they become like a reinforcer themselves, but apriori think there are some things that are reinforcers without needing to be learned, like food, even that some people say is somewhat learned so very, very young rats.",
            "When they're born, they don't necessarily know that sweet is good.",
            "That's actually we used to think that's innate, but it's not.",
            "That's also learned, but just learned in a very early stage.",
            "And then all these things become conditioned rewards.",
            "Even food is not really a reward.",
            "That's the metabolic, you know, the thing that gets to your blood hours later is the real reward, but we don't have to wait for that.",
            "Normally we sweetness is already the reward for us.",
            "I do want to continue on OK so so."
        ],
        [
            "Let's continue and you can ask me these questions later.",
            "OK.",
            "So.",
            "There are three model free learning algorithms or three basic classes for model free learning algorithms and reinforcement learning.",
            "Actor critic learning Q Learning and Sarsa and I'll go through each of them.",
            "And whether we think they exist in the brain or not."
        ],
        [
            "And the first one is actor critic, which which has been associated most with learning in the brain.",
            "So the idea was actor in actor critic to go over it really quickly is that there are states the states of the environment feed into two modules, the critic in the actor.",
            "The critic takes these States and Maps them into values which then feed into the temporal difference module which computes prediction errors which train these values so that the values become true.",
            "Predictions of the sum of their discounted sum of future rewards for each state.",
            "And this prediction error also feeds into the actor module.",
            "The actor Maps a policy from states to actions and it uses these prediction errors to improve its policy.",
            "So positive prediction error means that the situation is better than it was before and so that action should be repeated more in the future and negative prediction error means the action should be not repeated in the future.",
            "So these policy connection strengths or just strength of different actions in different states can be updated.",
            "Based on the same prediction error and of course the actions come out of the actor an influence the environment and so forth.",
            "So it turns out that this."
        ],
        [
            "Picture can be tentatively mapped on two areas of the brain psych.",
            "I put the names of the different areas that do these things or that we think do these things in each one of these areas.",
            "So as we said, the prediction areas dopamine from the VTA and SNC, and we think that the two parts of this trade in the ventral stratum in the dorsolateral stratum are the critic and the actor, respectively, and reward comes in through several areas, habenula and the peduncle pontine nucleus.",
            "It and some other areas with even longer names.",
            "And we already know that you know actions are through motor cortex, and perception is through all these areas in the back and then through frontal cortex.",
            "So we can map this whole thing on to the brain.",
            "And people were very excited about this, especially because there are two nuclei, two dopaminergic nuclei which seemed to project the same kind of signal, but to two different areas.",
            "So that made people immediately think Ha actor critic right?",
            "This one signal goes to the critic and one signal goes to the actor.",
            "It's the same signal but goes to two different places.",
            "So is there any evidence?"
        ],
        [
            "For this in the brain, I should say this is a very very prominent theory of learning in the brain an I think my opinion and this might be wrong.",
            "I'm glad there are not many neuro scientists here to tell me that I'm wrong, but my opinion is really it was because of this excitement of two nuclei of dopamine that signal the same thing to two different areas, not based on more stringent evidence.",
            "It just looked really good.",
            "But there is some evidence, and before I show you some."
        ],
        [
            "It's a little small aside to functional imaging and how that helps us look for this kind of evidence, and I'm doing this where I didn't do it for other methods in neuroscience because this is kind of the new wave of research into reinforcement learning in the brain, so it's good for you to know how it's done.",
            "So fMRI, functional magnetic resonance imaging.",
            "It all starts with a big magnet that looks like this and the subject lies on a bed and it's inserted so that their head is in the magnet and they see stimuli that they have like a little mirror and they see the stimuli from the screen and they have a button box and they make their choices or do whatever the experiment tells him to do, or even get juice into their mouth with a little too.",
            "They just do the experiment lying down and looking at this little camera at this little mirror.",
            "And trying to not move their head at all."
        ],
        [
            "At least we hope they don't move their head because ideas what we what we're measuring in these experiments is what's called a bold signal or a that's short for blood oxygenation level dependent."
        ],
        [
            "Hello.",
            "So what happens is in the brain there is.",
            "There is a lot of blood.",
            "There are lots of blood vessels.",
            "Every neuron needs blood because it needs oxygen.",
            "And there's a difference in the magnetic properties of oxygenated and deoxygenated hemoglobin hemoglobin in the blood.",
            "So, after the options in has been taken by the neurons, the blood has a different magnetic property than it did before."
        ],
        [
            "And we can detect this.",
            "These little magnetic fluctuations with this huge superconducting magnet that makes a lot of noise and cause."
        ],
        [
            "A lot of money."
        ],
        [
            "And So what we're relying here is is on the fact that the brain is functionally modular, so different areas of the brain get blood via different vessels.",
            "And if one area is active, it will use up more oxygen will actually ask the body for more oxygen than it needs, and we will see more oxygenation in that area because."
        ],
        [
            "It was active.",
            "So what this does?",
            "The reason it's called functional MRI is it shows as function."
        ],
        [
            "It shows us what brain area was used at what time, just some very."
        ],
        [
            "Very coarse.",
            "Resolution so the space."
        ],
        [
            "Actual resolution is about 3 millimeters cubed, so we can kind of tell apart these kind of these small voxels of three by three by three, which is certainly not at the level of 1 neuron to the level of thousands of neurons, but.",
            "The motor cortex sensory motor areas that they're differentiated enough that we can tell them apart.",
            "The temporal resolution is also quite shabby.",
            "It's 5 to 10 seconds because it takes time for the blood to get there and two away.",
            "It's not like for every spike of a neuron we see some blood blood difference, but if a whole area is active for awhile, 5 seconds later will see this extra blood that actually what happens is it it asks for more blood than it needs, so we see.",
            "The signal 5."
        ],
        [
            "Seconds later.",
            "So what can we do with this?",
            "We can study reinforcement learning and the brain.",
            "In humans.",
            "We can take this hidden variable of the model prediction errors an for instance, say OK during my experiment where my subject was playing some game, choosing stimuli, getting rewards during gambling or whatever.",
            "In my little experiment video game, the model predicts that there would have been prediction errors overtime.",
            "Second one, there would have been a positive prediction error and then it second four negative one and so forth.",
            "So I predict these prediction errors."
        ],
        [
            "Then I know that the bold signal usually has a typical time constant or a response.",
            "It looks like this, so if there was an event here 5 seconds later, we'll see a peak in bold.",
            "15 seconds later will see a dip and you know the whole thing levels out.",
            "After about 32 seconds.",
            "So basically 5 seconds later we'll see a peak so we can convolve our prediction error signals or Delta functions as we call them, although they're not really Delta functions, they have different Heights.",
            "With this"
        ],
        [
            "Bold and get the signal that we're expecting in the brain were expecting a peak caused by this, then a truck caused by this ahnapee caused by this, etc.",
            "And take this and use linear regression to regress this against activity of the brain and ask is there an area in the brain that looks like this, like this green line?"
        ],
        [
            "And so that's what Odartey ET al did in 2004 to look for actor critic mechanisms in the brain.",
            "In their experiment, the game."
        ],
        [
            "The subjects played went like this ohmygod.",
            "There's almost no time when did we start.",
            "At 1:30 one OK so not so bad there's two to half hours.",
            "I thought 2 hours.",
            "So they saw two stimuli on the screen.",
            "And these stimuli could be included.",
            "Either you know, like the location was randomized from trial to trial and there were two types of trial, either the trial."
        ],
        [
            "With this like Snowflake and weird looking thing or trials with these two weird looking things.",
            "These were actually randomized for different subjects.",
            "There were different pairs, different fractals, and the deal was on trials where they saw these.",
            "They say."
        ],
        [
            "Had a chance to get a reward.",
            "The juice reward if they chose one stimulus they would get the reward with 60% probability.",
            "Another stimulus with 30% probability they didn't know they sent advance.",
            "They had to learn this by trial and error.",
            "The other type of trial."
        ],
        [
            "They would also get something with 60% probability and 30% probability, But this wasn't juice.",
            "This was considered a neutral reward.",
            "This was actually artificial saliva.",
            "They didn't know that 'cause that stops being neutral.",
            "I see peoples faces, but actually when you just get it in your mouth it just feels like nothing.",
            "It's kind of like your own space.",
            "And they had subjects to play this game."
        ],
        [
            "Randomly interleaving these kinds of trials and what they saw before I get to the two conditions, what they saw was that in this case, subjects started preferring this stimulus, and in this case they were indifferent because they didn't really care about their rewards.",
            "So firstly, we can see that the subjects learned the contingencies.",
            "Another had two blocks in this experiment and one block.",
            "Everything was as I described it right now, so.",
            "This was called the instrumental block where subjects actions could affect their rewards.",
            "Just as I said, and then they had another block that was."
        ],
        [
            "Of Lothian Block where actually they didn't get to choose, they would see to stimulate.",
            "Then the computer would make a square around one of them.",
            "So that's the computer made the choice and they just had to indicate whether the computer chose left or right.",
            "That was to equate the motor action the computer actually chose based on their previous choices.",
            "It was yoked to their own previous choices.",
            "But they didn't know that doesn't matter.",
            "So they could they they had to choose what the computer chose and they got their rewards with the same probabilities.",
            "According to the stimuli that the computer, the stimulus that the computer chose."
        ],
        [
            "I take home question for you.",
            "Is to think about why the experiment was designed this way and.",
            "Think of prediction errors.",
            "They were trying to generate as many prediction errors as possible, so a reason that all these experiments use probabilistic rewards is to get prediction errors at the time reward 'cause their reward can't can't ever be completely.",
            "Predicted and the recent views.",
            "The reason that they use two different trial types is so that the stimuli can't be predicted either, and so there is a prediction error at the time the stimulus.",
            "Head out."
        ],
        [
            "What did the results show?",
            "What the results showed was that.",
            "If you take a prediction error signal as so you take a model, you fit it to the behavior you generate the prediction errors that you think should."
        ],
        [
            "To happen at different times, you convolve it with this hemodynamic response function.",
            "Exactly what I showed you before, and now you look for areas in the brain that."
        ],
        [
            "It correlate with this prediction error.",
            "And what they saw was that there were two areas in the stratum as you now expect from an actor critic mechanism.",
            "There's the area the ventral straight up.",
            "Each one of these blobs shows correlation.",
            "Shows areas that were correlated.",
            "The ventral stratum was correlated with prediction errors both in the pavlovi and task, so both.",
            "When they did, when their choices.",
            "Well, their choices were not their own when they could only predict what was going to happen, but the computer made the choices.",
            "And in the instrumental task where they made their own choices.",
            "And this isn't this is showing the conjunction of both.",
            "Both tasks."
        ],
        [
            "While in the dorsal straight have been the more ventral ISM is ventral and dorsal or they come from animal from the animal anatomy, so ventral is to the belly and dorsal is to the back.",
            "So think of animals with their head like that somewhere to the top is dorsal.",
            "More to the bottom is ventral, so this is eventual.",
            "Straighten up here is the dorsal well.",
            "Higher up here is the dorsal stratum and the dorsal stratum only correlated with prediction errors.",
            "In the instrumental task and not in the pool.",
            "Open tasks so the idea was.",
            "In Pavlovi and behavior, when you only need predictions, you need the critic but not the actor.",
            "And the instrumental task.",
            "You need both the critic and the actor, so both of them correlate with prediction errors.",
            "And you might ask yourself, why are we seeing prediction errors in the stratum here and not in dopamine areas in the area where dopamine comes from, and that's.",
            "Shown in many many fMRI studies so far, the the largest targets, as I said of dopamine, are the stratum and the bold response seems to correlate more with the input to an area, not the actual activity to an area.",
            "So we're seeing something that perhaps is generated by dopamine prediction errors in the target of dopamine and not in the place where dopamine comes from."
        ],
        [
            "Let's skip."
        ],
        [
            "Yes, because we don't have time so.",
            "So so far.",
            "This is some evidence for actor critic for our actor critic architecture in the brain.",
            "It it is interesting because an actor critic, architecture, links, prediction, learning, so links, pavlovi and behavior of open learning or the critic to control to the actor in a very, very specific way.",
            "It assumes kind of that they can't be.",
            "Tis the that they can't be separated in that prediction like pavlovi and learning would be completely separate from instrumental learning.",
            "It also assumes that there are no Q values.",
            "You don't need Q values inactive, critical just need state values in the act in the.",
            "Critic and the actor learns a policy rather than Q values.",
            "But as I said, this isn't very conclusive evidence.",
            "There is one study of maybe it and the rest of the evidence for the ventral dorsal divide for actor critic is more circumstantial.",
            "It deals with their roles in other kinds of learning, but it's not direct evidence.",
            "For actor."
        ],
        [
            "Eric.",
            "So we should ask ourselves, is it really actor critic?",
            "Or maybe there there is Q value learning sarsa or Q learning in the brain?"
        ],
        [
            "And that's what Maurice said Al asked themselves at well as well in a study in 2005.",
            "So they they also, they did a study on monkeys and recorded from actual dopamine neurons.",
            "So what they were asking is, is the prediction error that we see in dopamine neurons at the time of the stimulus that look like a state value prediction error like we would have an actor critic?",
            "Or does it look like a Q value prediction error or?",
            "Q Learning prediction error source of prediction error because these algorithms would they differ in is what prediction error controls learning?",
            "Is the prediction error that's based on the best possible action you can take or the action that you will actually taken Sarzo or the average policy an actor critic.",
            "So the experiment went like this.",
            "Normally what a monkey would see was it would see a stimulus would have to wait awhile until it got a ghost screen, and then it could.",
            "It had to say either right or left to whether the stimulus was on the right or on the left, so this is Pablo, but it doesn't get to choose a stimulus.",
            "It just says this is just to keep the monkey attentive.",
            "Is it on the right or is it on the left and then it got a reward with the probability that dependent on the stimulus there were five different stimuli like in the Schultz experiment, one gave reward with zero probability, one with 25% fifty percent 75 and 100%, and the monkeys learned this many many, many trials like.",
            "Thousands and thousands and thousands of trials where they learn this everyday.",
            "The reason they're learning it for so many trials is not because it takes him so long to learn 5 stimuli.",
            "It's because every day you can only record one dopaminergic neuron, and they want a lot of neurons so they can publish a paper, so they have to do this for many, many, many days.",
            "But once in awhile they intervened and they put in test trials and which is the monkey saw two stimuli rather than 1.",
            "Two out of the five, and now this was instrumental task where the monkey could actually choose when he saw the goal.",
            "He could either go right or go left, and that was a choice of one of the two stimuli, and then he got a reward according to the probability associated with stimulus that he chose.",
            "And let's say he knows from Preve."
        ],
        [
            "If learning that this stimulus rewards 25% probability in this one with 100% probability, and let's say his policy.",
            "Is in this case, he usually chooses this one, but sometimes he chooses this one, so this one is chosen 20% of the time and this one is 80% of the time, which is what the monkeys actually showed.",
            "For this they showed probability with called in the animal literature probability matching behavior.",
            "It's kind of like a softmax.",
            "They're choosing the best, but not all the time.",
            "So now there are different things that the monkey can compute at this time point.",
            "You can compute the value of this display, which is 20% times this reward plus 80% times this reward, and this value is the same dependent on whether he will choose left or right, because it just it already takes the whole policy into consideration.",
            "Or he can do the Q learning thing, which is to say the value of this display is the value of the.",
            "The best thing I could get.",
            "So that's what's drawn here, and again, it doesn't depend on whether he will choose left or right, because Q learning is off policy.",
            "The value here is.",
            "The value for the best thing, although he might not choose the best thing.",
            "Or he might do Sarsa, which is to say the value of this display is the value of the thing that I'm actually going to choose, so it's going to be oh point 25 if I choose left and one if I choose right.",
            "And the reason I'm plotting the value here is because the prediction error at this time there is no reward yet.",
            "So the prediction error is.",
            "The future value minus the previous value.",
            "The previous value we can assume was zero because there was no nothing on the display.",
            "So this is basically what the prediction error will show us.",
            "The value of this display, and now we're asking, is it going to be.",
            "Willerton Q Learning or sarsa?",
            "And what they saw."
        ],
        [
            "And plotted in a way that's really, really hard to understand.",
            "Unfortunately.",
            "Well, I'll tell you the bottom line.",
            "What they saw was Sarsa, the way they're showing it here is.",
            "Look only at the empty.",
            "Circles these show.",
            "The value of different stimuli.",
            "So the different stimuli, the 25, fifty, 75 and 100% stimuli and the responses of the neurons and then the black ones.",
            "Our trials in which they saw two, but we're going to choose this stimulus, or this, or this, or this later, and the reason they're not exactly.",
            "The action value there is not exactly the same as in the Pavlov in case because the because they had errors and they didn't always choose something in general, or something like that can't remember exactly why it's a little bit off, but the idea is that the values conform to the thing that they're going to choose an not the best option that they have."
        ],
        [
            "In a different way that they showed this is they took all the choice trials in which a certain stimulus was chosen was chosen.",
            "And all the force trials of that same stimulus in aligned one on the other.",
            "The dopaminergic responses and they look.",
            "This is for the.",
            "100 percent, 75 percent, 50%, and 25% for each one of them they align very well on each other.",
            "So the bottom line here is.",
            "It seems like the prediction errors in dopaminergic neurons look like a source of prediction error and not like a critic of V prediction error state value prediction error, but an action value.",
            "Q value prediction error."
        ],
        [
            "Um?"
        ],
        [
            "I think I'm not going to go through this in detail."
        ],
        [
            "But just to say that."
        ],
        [
            "A different study."
        ],
        [
            "There have been only two studies on."
        ],
        [
            "Yes, the."
        ],
        [
            "Can study from Roshell was in rats and they had a somewhat different design where they had odors, predicting immediate rewards and delayed rewards and large rewards and small rewards etc.",
            "And we won't go."
        ],
        [
            "Through all this now, but when they looked at their responses, it looked more like they saw they thought they were seeing.",
            "Q Learning rather than SAR, so so they were seeing.",
            "In a forced choice trial where the rat had to get.",
            "Either.",
            "Let's look at this.",
            "Well, either a reward with a short delay or with a long delay.",
            "Rewards with long delays are discounted by time, right?",
            "So they had more firing look only at the firing here 'cause this is already the time, the reward more firing for the short delay rewards it for the long delay rewards and the same or firing for a high for a large reward than for small reward.",
            "But when they got a choice.",
            "In both cases they saw the same firing whether they're going to choose the short or the long delay.",
            "They first saw the same kind of Q value of the best possible option, so this fits this regardless of whether they are going to choose the best one or they're going to choose the second one.",
            "The long delay one.",
            "In the same here."
        ],
        [
            "So."
        ],
        [
            "So this some of this summary of the story here is that the jury is still out on Sarcee versus Q learning or even starts versus Q learning versus actor critic.",
            "There are a small handful of studies looking at this directly and what really needs to be done is more neuro scientists to do more experiments recording from dopamine neuron, especially an I wrote here.",
            "Telltale task syntax that are designed especially for this purpose that could really tease apart these different models and the reason.",
            "We want them to do that is that as I said, this is 1 area where the brain can inform reinforcement learning because the brain actually learns in a task that's much harder than a normal reinforcement learning task, right?",
            "It learns and real time with real noise and."
        ],
        [
            "The problem is that if you look at these signals, sorry, you'll see that they are very very noisy and kind of you know, not what we'd expect from a nice prediction error signal.",
            "But yeah, the brain is noisy.",
            "The world is noisy.",
            "It's true that also are specific measurement devices.",
            "Putting electrodes into the brain don't give us the nicest signal in the world, and it could be that the brain itself sees a cleaner signal that we're seeing here.",
            "But in general, since the brain learns so well, it would be interesting to know what algorithm.",
            "It uses to do that learning, and that could maybe help the debate between these different algorithms."
        ],
        [
            "Reinforcement learning."
        ],
        [
            "OK, so you have half an hour left.",
            "Which means that will probably not get to risk sensitivity in the brain, but will do these two, so that's good.",
            "OK, so until now I've talked about 3 algorithms for model free learning, but one question is, do animals really only learn model free trial and error prediction errors?",
            "You know, run around the world blindly and see what happens, or is it?",
            "Or is there also model based reinforcement learning in the brain?",
            "And it turns out that way before."
        ],
        [
            "Reinforcement learning came into the picture.",
            "Neuro scientists are, at that point.",
            "Psychologists had fierce debates on this.",
            "Where some psychologists like Thorndike thought that everything was stimulus response.",
            "You see a stimulus.",
            "You learn a response.",
            "Basically, learn a policy for it and this model free, and some people like Tolman thought thought that rats were much smarter than that.",
            "So what experiment that old man did?"
        ],
        [
            "To show this was this experiment.",
            "So in this experiment, the rats started from here ran into this big arena.",
            "Had to find this second pathway, run down the pathway and got food over here.",
            "And did this again and again over several days.",
            "So the 1946 so I don't have a video."
        ],
        [
            "To show you.",
            "And then in the test phase, told them change the situation.",
            "This same table was now connected to a bunch of different.",
            "Array of of pathways.",
            "The main pathway this pathway was blocked.",
            "And he asked himself, where would the rats go?",
            "Which pathway would they choose?",
            "And so.",
            "You can probably see that this is where the goal used to be before, so the question is, will they know to go down pathway #6?",
            "And indeed.",
            "Most of the rats chose pathway 6, some of them chose one."
        ],
        [
            "Something went right, which is kind of the policy here.",
            "The policy closest to the food, but many of them knew a completely new policy that they'd never been trained on before, which which basically showed Tolman."
        ],
        [
            "In his words.",
            "Well, his words are humble rat.",
            "He said even the humble rat can learn spatial structure and use it to plan flexibly.",
            "So the rats didn't just learn straight left, right, right, food.",
            "They learned something about the world, they learned what he called a cognitive map of the environment, which is what we'd call a transition function between states.",
            "Or model of the world."
        ],
        [
            "A more modern way of testing this same thing.",
            "Which actually looks at the other half, not transitions between states, but the reward function in reinforcement learning is called outcome devaluation.",
            "So here what have."
        ],
        [
            "It says your trainer at to press a lever in order to get food.",
            "And then after the rat is trained, it change the value of the food separately in a separate scenario, not in the same box where the rat is used to pressing for food.",
            "But like in the home cage for instance, by letting the rat eat the food and then in."
        ],
        [
            "Acting it with lithium chloride, which makes rats feel really, really sick to their stomach.",
            "It makes him not want to eat that food anymore.",
            "It's like food poisoning.",
            "It happens to us too, is called conditioned taste aversion.",
            "You go to a restaurant to eat something to get a really bad stomach ache.",
            "You don't ever want to go to that restaurant again, or certainly not order that food.",
            "So that's what happens to the rats here.",
            "They don't want to eat the food anymore.",
            "You give them the food and they like they walk away.",
            "Sometimes they even like throw things at it."
        ],
        [
            "Or another way to do this is to just make the rat sated on even on another food.",
            "Just make him really, really say to give him as much food as he wants so that now the original food in the experiment has a much lower value in both."
        ],
        [
            "Aces and now the question is, will the rat continue pressing for the food?",
            "And that is compared to a rat the den."
        ],
        [
            "We have this devaluation so a normal rat that was trained on this and then just tested so we know that this rat will continue pressing.",
            "The question is will these continue pressing at the same rate and the reason we're doing this in a in a comparison situation is specifically because this test is usually done with no rewards anymore, so we don't want to see new learning.",
            "We want to see whether the rat put together its knowledge of contingencies.",
            "What does this lever pressing give me an it's knowledge of?",
            "What is the worth of this cheese?",
            "So the reward function in the transition function?",
            "Are these going to be put together without new learning about the food?"
        ],
        [
            "And."
        ],
        [
            "The result is.",
            "Well, the results are.",
            "It depends.",
            "If you train the rat only moderately, so you train the rat for four days to start with him in four sessions, each of them half an hour, and then do the devaluation and then do the test, you see that rats press much less for the devalued reward than for a reward that was not devalue."
        ],
        [
            "But if you train them more in the initial training I'm talking about."
        ],
        [
            "In this stage, if you train them for 15 days, they're not for four days."
        ],
        [
            "Then they don't stop pressing even when the reward is devalued.",
            "They press the same.",
            "Is that the average of the 2D value?",
            "This in this experiment they used SoC, not lithium chloride.",
            "Are there different experiments?",
            "Are a whole host of experiments have shown this this is.",
            "You know what?",
            "No, I think this is Holland's results and not kill cross, so this is with lithium chloride."
        ],
        [
            "With the poisoning.",
            "So it seems like animals will sometimes work for food that they don't want, and the reason I'm saying they don't want it even in this case is that we can look at their magazine, behave."
        ],
        [
            "Which is how many times they go to the food magazine to actually eat the food, and we see that in both cases even after extensive training, they go to the magazine less for when the food is devalued in one.",
            "It sound evaluated.",
            "This looks like it's not significant, but it's a within subject design and it is significantly different these two.",
            "So in both cases they don't go to get the food, but in one case they continue pressing to earn the food.",
            "I saw question from side.",
            "OK."
        ],
        [
            "And this has been associated this kind of behavior after extensive training with what we know about our daily life, which is in our daily life.",
            "Actions sometimes become automatic or we call them habitual.",
            "After their extensively trained.",
            "If we repeat them again and again and again, we drive home to the same place every day.",
            "Then even when we move house we continue driving by mistake to the old place.",
            "Although we know in our cognition and everything that we don't live there anymore, it's not that we don't know that the reward is not there anymore, we just failed to put 2 two and two together.",
            "And not drive to the old."
        ],
        [
            "Place.",
            "Hence."
        ],
        [
            "So this has been termed the same in rats.",
            "Habitual behavior when they continue pressing and goal directed behavior when they stop pressing, whether directed to a goal that they kind of put together in their mind.",
            "Evaluating this is so you either had to keep waiting or did.",
            "Made them sated.",
            "If you are doing the voice thing.",
            "Value or so.",
            "Right, yeah, I understand.",
            "Yeah no, this is a good question, so you're asking, what's the devaluation really?",
            "As effective after extensive training as it was after moderate training and they check that.",
            "So sometimes here it's enough to do one poisoning.",
            "And here you have to do.",
            "You know, three poisoning three poisonings on three different days, but they poisoned them until the point where they give them the food and they just don't want to eat it.",
            "And that's when they go do the they put them back in the box with the lever and.",
            "Test that so that's controlled for, but that's a good question."
        ],
        [
            "OK, so we saw that in some case.",
            "In some cases animals are habitual and in other cases in other cases animals are goal directed, so people were really, really interested in this and started to look at what areas of the brain lead to these kinds of behaviors in this kind of learning and what they saw.",
            "And I'll show you only two results.",
            "Just to not encumber you with all kinds of areas of the brain that mean nothing at this point is that there are some areas of the brain, specifically the dorsolateral stratum.",
            "Where in this experiment these are over trained rats.",
            "So if you don't leash in their brain what they're going to do is we're going to continue responding in the devalued case as much as they responded in the non devalued case."
        ],
        [
            "But if you lesion, if you cut the dorsolateral stratum out of their brain and then do all the training and everything, then suddenly their goal directed so they press less for the devalued option than for the valued option.",
            "Even after 30 days of training or as long as you want to train them, but never become habitual.",
            "So the idea was that the dorsolateral stratum is the seat of habits.",
            "If you don't have the dorsolateral stratum in your brain, you."
        ],
        [
            "Can't learn habits.",
            "And."
        ],
        [
            "This is also true if you don't leash in the dorsal lateral strata, but you just deplete dopamine from it.",
            "You kill all dopamine neurons that project to it, and there are a whole."
        ],
        [
            "There's a whole suite of areas, basically a loop of areas that are connected in the brain, areas in the prefrontal cortex areas in the thalamus at each of them.",
            "If you lesion them, you lose this habitual behavior, so there seems to be a whole loop of areas that are involved in habitual learning."
        ],
        [
            "On the other hand, there is another loop, another host of areas, another group of areas, the dorsomedial stratum in the areas there.",
            "Related to it's a slightly different part of the stratum where if you lesion that.",
            "You get the opposite.",
            "You get animals, they're always habitual, right from the very beginning, so.",
            "This isn't the best part of it in the world 'cause these are.",
            "Both of them are very low, but the idea is the regular behavior here after short training.",
            "Is this a difference between the devalued in the non devalued and there is no difference after lesioning the posterior dorsal medial stratum.",
            "In other experiments these two were as high as this one.",
            "This experiment is a.",
            "Bad choice on my part, but there are many experiments showing."
        ],
        [
            "Yes, and so the idea is that."
        ],
        [
            "There's a whole loop in the brain that is responsible for goal directed learning, and if that doesn't exist from the very beginning, animals are habitual or they don't show sensitivity to devaluation right from the beginning of."
        ],
        [
            "Raining"
        ],
        [
            "So what does all this mean?",
            "On one hand, we've learned one thing we've learned that the same action that we look at we see the rat lever pressing it can arise from 2 psychologically dissociable pathways.",
            "So the fact that he's lever pressing doesn't tell us why he's lever pressing."
        ],
        [
            "Will we test with evaluation?",
            "We can see that he might be lever pressing in a goal directed way dependent on the outcome representation, putting that today."
        ],
        [
            "Either with the contingencies, or he might be pressing in a habitual way just because.",
            "Oh this is a lever I press levers not because this lever is going to give me food.",
            "Same as in driving right?",
            "I get into this car.",
            "I get to this junction.",
            "I take her right just you know, stimulus response.",
            "That's a habitual one.",
            "Goal directed is I'm going home so I take a right."
        ],
        [
            "And to complement this Association, the psychological dissociation there is also a deletion suggests that there are two neurally dissociable parallel systems in the brain that support each type of this behavior behavior, and they can support at any stage of training if the other one isn't there.",
            "The second one, if one isn't there, a second one takes over."
        ],
        [
            "And So what we asked here, this was a study done by my colleague Nathaniel Da and myself it Anne.",
            "Peter Dan was.",
            "Can reinforcement learning help us make any sense?",
            "Of this behavioral mess.",
            "And this LED us to think about Red Force."
        ],
        [
            "Learning and the two main strategies in reinforcement learning, model based and model free.",
            "So think of a task like this.",
            "Instead of level pricing, it's harder to draw the lever.",
            "Pressing MDP, although it's.",
            "It's not that difficult, but it's it's easier to draw an MVP for forumers.",
            "So the rat here is is navigating this maze and tries to get the maximum reward and has to choose whether to go left or right.",
            "The reward.",
            "This rat likes most is cheese, that's why it's worth 4 compared to carrots and water."
        ],
        [
            "And we know that there are two ways to solve this problem.",
            "The model based one is learn the map of the task, learn the contingency learning the transition, so state one take left.",
            "You'll get to State 2.",
            "Oops, this should have been 012.",
            "ETC and the values of the rewards.",
            "And then if you have these transitions in this reward function you can use."
        ],
        [
            "Your favorite model based methods?",
            "Dynamic programming or any other method of look ahead of planning and figure out what is the value of taking the left here and taking a right here.",
            "It's sorry taking left to say.",
            "Here are taking right?",
            "So taking left the value would be for and taking right the value would be 2, so of course the rat should go left."
        ],
        [
            "And importantly, this is computed on the fly, so the dynamic programming problem has to be solved on the fly, which means this computationally costly.",
            "It can take a while, especially for the maze is bigger, but it's also flexible and immediately sensitive to change, because if the rat learns that."
        ],
        [
            "The reward function here has changed.",
            "It will immediately affect the computed value of taking left in state.",
            "In the initial state here.",
            "So this is model based reinforcement learning.",
            "On the other hand."
        ],
        [
            "We can solve the same exact task with model free reinforcement learning."
        ],
        [
            "Learning via trial and error and prediction errors.",
            "This stored Q values and the Q values are.",
            "A prediction for future for some of future rewards right now."
        ],
        [
            "This case, because we already have.",
            "Q Values choosing actions is really easy.",
            "You don't have to compute anything you don't have to solve a dynamic programming problem.",
            "You're at state zero.",
            "You look at the two Q values and you see that left is better done OK?",
            "So this is it."
        ],
        [
            "Kind of quick and reflexive behavior that we could imagine from habitual behavior, but.",
            "One thing is you need a lot of experience to learn.",
            "You need to go through this many, many times to get the correct Q value."
        ],
        [
            "News.",
            "And the second thing is this will be inflexible, right?",
            "If I now change the value of the cheese to zero, it's not immediately clear which Q value should change without experiencing this maze again and again, and having prediction errors update these values.",
            "So the idea was that goal directed behavior is actually model based reinforcement learning where."
        ],
        [
            "Should have said this before where the rat learns the model of the world and plans in it, and that's why we see devaluation sensitivity."
        ],
        [
            "And habitual behavior is model free reinforcement learning in the brain.",
            "But now the quote."
        ],
        [
            "But now this answer raises 2 new questions 'cause we're still."
        ],
        [
            "Stuck with the question of.",
            "Why the hell should the brain use two different strategies in parallel?",
            "Like why not just choose the best of the two and use that one?"
        ],
        [
            "Always.",
            "And if you do decide to use two now, what do you do if you have two parallel systems telling you what to do, and they say that they say different things, so one system is telling you, press the lever and the other is saying no, don't press the lever.",
            "Now there is a new control problem of like which controller to listen to.",
            "Nude"
        ],
        [
            "Decision making problem, sorry.",
            "And so our answer here."
        ],
        [
            "Was.",
            "That one way to think about this is to look at the pros and cons of each of the model based and model free reinforcement learning.",
            "So each of these two systems is best in different situations and what you really want from a robust.",
            "Smart complex brain is that it would be able to use each system in the place where it's most appropriate.",
            "So for instance."
        ],
        [
            "If you have very limited training model based learning is does better with with little data compared to model free learning because model free learning bootstraps and uses you know it's.",
            "It uses its own junk to learn basically and bootstrapping, so it takes a lot of time to take that junk out.",
            "Well, model based learning puts each piece of information in the right place and does better with limited training.",
            "On the other hand, model based reinforcement learning will do better when it's close to the reward.",
            "So this tree or the dynamic programming problem is much easier to solve than when you're playing a game of chess and have to, you know.",
            "Solve the tree of all the possible actions until the end of the game.",
            "So in the case where you're close to the reward or have limited training, the brain would do wisely to use goal directed to use a goal directed to use a model based forward."
        ],
        [
            "Search mechanism and the opposite.",
            "After a lot of experience or when the reward is really far away, it would be better to use a caching Q learning.",
            "Model free or SARSA model free.",
            "Mechanism.",
            "So that's the answer for why have two systems?",
            "And now if those two systems this answer kind of says in one situation use one system and the other use the other.",
            "But you have to have these two systems learning all the time.",
            "You don't want to waste experience and teach only this system with some of the trials in this system with others, so that learning should happen in both in parallel.",
            "And then if."
        ],
        [
            "Ask yourself.",
            "Well, I have two systems that have already learned.",
            "Rather than decide which one to use apriori by the constraints of the problem, I can basically ask each of them to tell me based on everything they've learned so far.",
            "What do they suggest that I do?",
            "But ask them to not only say what they suggest, but how confident are they in this suggestion and trust the one that's most confident and you would hope that this one would be more confident.",
            "Only after a lot of experience and this one would be on more confident.",
            "Only when it's close to the reward."
        ],
        [
            "So the idea is.",
            "To use some form of Bayesian reinforcement learning where you track."
        ],
        [
            "Not only values but also the variance, not fair.",
            "And sorry, the uncertainty about these values and then what you get from the two systems is at each point you're asking what's the value of lever pressing versus not lever pressing or what's the value of turning left or turning right in the maze and you get for one system while high value.",
            "And I'm quite sure about it from the other system low value and I'm not really sure.",
            "Well then you go for this systems value.",
            "You believe this one and you compare that value to values of other actions.",
            "Well, in another case, if this was more certain, you'd believe this one, so this is the."
        ],
        [
            "I Bayesian the normative basin.",
            "Think to do.",
            "And as I said, there are different sources of uncertainty in the two systems, so if they track their uncertainty correctly, that would automatically solve the problem of using each one when it's most appropriate."
        ],
        [
            "So what we've learned so far is that animal condition behavior.",
            "Although it looks like you know animals, slobbering for food or pressing lever, is not very complex.",
            "Still, it's not a unitary phenomenon.",
            "The phenomenon.",
            "The same responses can result from different neural and computational origins.",
            "And it seems like these different neural mechanisms work in parallel to support behavior so they can cooperate, and they can also compete and reinforcement learning provides us clues not only to what these two systems do, but why this should be the case.",
            "Why would you want these two systems in parallel and when would you want to use each of them?",
            "And I should say I didn't write it here, but this could also feed back to planning simulations in robots, where if we want robust behavior from a robot, we might want to put in these two parallel mechanisms as well, and not only one of the two."
        ],
        [
            "So I want to do this one or the next one.",
            "Maybe I'll do the next one, it's more interesting.",
            "This also you might have seen at NIPS a few years ago I presented this.",
            "Clash is gonna take a lot to get through it.",
            "OK, let's go for the last one.",
            "So the last topic in the last 7 minutes before we get to the open challenges is risk sensitivity in reinforcement learning in the brain.",
            "This is Brian new.",
            "It's not yet published, that's why you also didn't have it in the slides.",
            "I'm kind of being a little bit paranoid.",
            "I've been taught that that's the right thing to do, so."
        ],
        [
            "This is showing to this because I think this is another area where we where the brain can tell us something about reinforcement learning and this study what we asked was."
        ],
        [
            "This question, if I offer you once you leave the room.",
            "$20.00 for sure in your hand.",
            "20 Canadian dollars are now worth $0.80 each 80."
        ],
        [
            "2nd dollar cents each.",
            "Or Casa coin for $0.00 or $40?",
            "Fifty 50 chance.",
            "Which one do you prefer so?",
            "Who prefers the sure 20?",
            "OK, who prefers the risky?",
            "Who doesn't care in different altitudes for them?",
            "Three of you whose sleep joking?",
            "OK, so."
        ],
        [
            "What you've shown is behavior that normal people show as well, which is most people are sensitive to, risk they care.",
            "Very few people say they are indifferent in this situation.",
            "Most people care in most people are also risk averse.",
            "They prefer the $20 to the gamble, as most of you."
        ],
        [
            "Now this is kind of curious because in reinforcement learning we're used to thinking about expected values, which are expected reward from these two options, and that is the same for both options.",
            "So reinforcement learning normally ignores risk.",
            "People normally don't ignore risk, and that's what we wanted to do in this."
        ],
        [
            "We wanted to go and look at that specifically wanted to go and look at the bold signals in fMRI that correlate with prediction errors.",
            "The ones that we know already reflect reinforcement learning processes in the human brain.",
            "An ask do those prediction errors care about risk or not."
        ],
        [
            "So the actual question that we were asking was will the reinforcement learning neural value of sure $0.20 or we didn't have that much money?",
            "Tougher subject so it went for sense be the same as that of a 5050 chance to get $0.40, yeah.",
            "Possibly just changing them.",
            "Dollars.",
            "It is OK. That's a great question.",
            "So so."
        ],
        [
            "As has been pointed out here, there are different ways to understand computation.",
            "To understand how we solve this problem, and some of them predict the same neural valleys in the brain, and some predict different neural cells in the brain.",
            "One of them is going to be a utility function, but before I get to that, let's start so."
        ],
        [
            "Basically, we thought of four models here, two that predict same neural values for the $0.20 and zero $0.40, and two that predict different neural values and to make a Long story short, the same girl values could come from either from.",
            "Basically, it could be that reinforcement learning learns expected reward another area in the brain learns the variance and then the decision value combines those two.",
            "But still if we look at reinforcement learning areas in the brain, they will be our good old.",
            "Expected real."
        ],
        [
            "Or"
        ],
        [
            "It could be.",
            "That we learn expected rewards, but due to sampling biases we still get risk sensitivity and the ID."
        ],
        [
            "Here here is if you do normal reinforcement learning on these two options.",
            "You still will get risk sensitivity.",
            "And I'm going through this way too quickly, but the idea is, imagine you choose A and you get 20."
        ],
        [
            "Dollars.",
            "Then an imagine he started with finish."
        ],
        [
            "Values of expecting 20 from each of these simulations, and of course you don't have a prediction error you don't."
        ],
        [
            "Update the values.",
            "Everything is great."
        ],
        [
            "Now you choose."
        ],
        [
            "And let's say you get $40, then you have a prediction error of plus 20.",
            "And let's say your learning rate is oh point 5."
        ],
        [
            "Really high, I know, but it's easier to demonstrate with that then you update the value of B to B 30.",
            "Now of course 30 is higher than 20.",
            "Then in the next row."
        ],
        [
            "You choose to be again, but now let's say you get a zero and you're playing this by trial and error.",
            "You don't know that it's 5050 chance this is.",
            "This was the first time you fell for it.",
            "This is the first time you saw zero."
        ],
        [
            "But now your prediction is minus.",
            "30 and so once you update with zero."
        ],
        [
            "Put five learning rate.",
            "You'll get 15 versus 20."
        ],
        [
            "So now, of course you'll choose the red A.",
            "Get."
        ],
        [
            "20 because."
        ],
        [
            "Always gives 20 an no update etc etc and this will just continue forever."
        ],
        [
            "Basically because whatever you believe has a lower value, stop sampling it.",
            "You stop learning about it and you don't know that that value is not its true mean.",
            "And this is in regular reinforcement learning, so we could theoretically have completely normal reinforcement learning of means and auto variances and still get risk sensitivity.",
            "But in this case, if we didn't let you sample, if I forced you to see 10 Eisen, 10 bees, on average, their values would be the same, which is what I'm going to do in the experiment."
        ],
        [
            "The two models on this side that predict different neural values are."
        ],
        [
            "A utility function as."
        ],
        [
            "As mentioned, so economists think for many years that the utility of rewards diminishes with amount.",
            "So with diminishing utility's what you would get is that getting 40 half the time is worth less than getting 20 right.",
            "Because you have this concave utility function between real amounts in the world in this objective."
        ],
        [
            "Tility they give you.",
            "Or you could be you could have this kind of function which would lead to."
        ],
        [
            "Risk seeking be."
        ],
        [
            "Savior.",
            "And the last model that we were really interested in actually was this model that's called risk sensitive temporal difference."
        ],
        [
            "Meaning I don't know how many of you are familiar with it.",
            "It was published in 2002 in the Journal Machine Learning."
        ],
        [
            "I think or neural networks I can't remember right now and the idea here was that."
        ],
        [
            "You can collapse learning about variance into temporal difference learning in."
        ],
        [
            "This way.",
            "Instead of having.",
            "Normal reinforcement learning where positive prediction where in this case around 20 you get half the time of positive prediction or half the time a negative prediction error, and they'd on average."
        ],
        [
            "Balance each other out.",
            "Instead of that."
        ],
        [
            "You might overweigh negative prediction errors compared to positive prediction errors when doing the update of the values and then on average you learn.",
            "A lower.",
            "Value for this variable stimulus.",
            "So you basically take variance into account, because when you have variables stimuli you have prediction errors all the time, and if you weigh prediction errors differently for positive and negative, the more variance you have, the more skewed your final."
        ],
        [
            "The result will be in this."
        ],
        [
            "You this could be to negative or positive depending on how you weigh positive and negative prediction errors.",
            "So.",
            "Shit, I'm really out of."
        ],
        [
            "So we have four models and we wanted to compare between them and I really.",
            "Don't have time to go?"
        ],
        [
            "Through the details, but the idea was we let subjects choose between different stimuli that had different rewards, and in this we had this choice between $0.20 and zero, $0.40.",
            "And then we went to looked in their brain.",
            "To see whether there would be a relationship between how risk averse they were, so how many times did they choose the $0.20 versus the zero?",
            "$0.40, and what were the differences between the neural values of these two?",
            "So we went into their nucleus of comments, took the bold signal extracted from that the prediction error signal extracted from that the values for $0.20 and zero $0.40 and basically.",
            "What we would want to see if if they were not learning about risk, these two values should be the same.",
            "If they were learning about risk, then when 20 is larger than zero forty, they should be choosing the 20 more times and when.",
            "Zero 40 is larger than 20.",
            "Then they should be choosing the 20 less times.",
            "And that's exactly what we saw.",
            "So that basically said.",
            "That we're looking at one of these two algorithms.",
            "Risk sensitive value learning or or nonlinear utility functions.",
            "Because we did see differences between 20 and zero 40.",
            "And to test whether it was this one or this one, what we did was we looked at the the actual values of.",
            "Sure 20 ensure 40 and asked whether they were non linearly related to choice and there we didn't see that relationship.",
            "And I'm sorry I'm running through this really, really quickly, but the take home message from this really is this."
        ],
        [
            "It's that, although we're used to thinking about expected rewards and reinforcement learning, you might not believe this study."
        ],
        [
            "It doesn't really matter whether you believe it or not.",
            "What matters is that we could.",
            "We can do studies like this and see what the brain does with risk.",
            "And in this study at least, it seems that the brain folds risk into predictive values.",
            "And that's a place where I think the brain can tell us new things about reinforcement learning, because now if."
        ],
        [
            "That is really true.",
            "We can ask ourselves well why is this a good thing to do?",
            "We haven't done it so far, but is it actually optimal in some situations?",
            "Will it help reinforcement learning if we use this?",
            "Risk sensitive read."
        ],
        [
            "But learning and fold risk into values can help in our reinforcement learning applications.",
            "If it helps the brain, perhaps it's a sensible thing to do."
        ],
        [
            "So I want to finish with one slide.",
            "About the open challenges in future direct."
        ],
        [
            "Since.",
            "And basically what I want to encourage you to think about based on this whole tutorial is this interplay between looking at reinforcement learning and looking at the brain.",
            "Because the challenges are the same."
        ],
        [
            "In both cases, if we think about reinforcement learning and how can reinforcement learning to deal with noisy inputs problems that many of you who study reinforcement learning might be grappling with, especially if you're using robots or or agents that work in the real."
        ],
        [
            "World well the brain has that exact same problem.",
            "Even worse, and input to the brain is noisy all the time.",
            "For instance, there is huge temporal noise.",
            "Temporal difference learning relies on knowing the exact time between events and predicting exact timing.",
            "We don't have internal clocks that are that precise.",
            "We know that we have a lot of timing noise.",
            "Still, the brain manages to learn still dopamine looks like temporal difference prediction errors where if we actually ran temporal difference learning with the noise that that exists in the brain.",
            "It would completely not work.",
            "So the question is how can we learn from the brain how to improve our temporal difference algorithm?",
            "Maybe use semi Markov decision?",
            "Up formulation their their ideas out there but.",
            "Since the brain knows how to deal with this, it can maybe teach us how reinforcement learning can deal with this.",
            "Same thing when you think about how."
        ],
        [
            "And reinforcement learning deal with an unspecified state space, so I know that there is a new trend.",
            "Great trend of looking at how the how reinforcement learning can learn useful state representations.",
            "Well, the brain."
        ],
        [
            "Has to deal with the exact same thing, so maybe if we have no clue how to do this, we can ask the brain how it does it and learn from that."
        ],
        [
            "How can reinforcement learning to deal with multiple goals with the fact that there are many problems with the fact that there is maybe hierarchical?",
            "Structure to problems.",
            "How can reinforcement learning transfer learning between tasks?",
            "All problems with the brain deals with and is very good at.",
            "We don't know how it does it, but we know it does."
        ],
        [
            "Well, so by asking neuroscience and neuro scientists to tell us how the brain solves these problems, we might learn."
        ],
        [
            "Something about how we can solve them in reinforcement learning.",
            "So I started by telling you."
        ],
        [
            "Reinforcement learning is revolutionized.",
            "How we think about learning in the brain.",
            "And I showed you in some ways some examples of theoretical and also practical there.",
            "There might be even clinical implications of this reinforcement learning framework for neuroscience.",
            "If we think about dopamine and Parkinson's disease and gambling, etc.",
            "So there are scientists really continue to be consumers of machine learning theory and algorithms, not only reinforcement learning is also based in learning is classification methods.",
            "Graphical models I go to NIPS every year and I kind of treat it as a big supermarket like what's out there that I can copy that I can use to study the brain.",
            "I haven't gone to ACNL before but this is the first year that I'm going to be shopping here as well as an earth scientist.",
            "But important for you guys, I think this doesn't have to be a one way St.",
            "Since humans and animals solve some of these problems that you are confronted with so well, it would be silly to not look at human learning and learn from that.",
            "How we can do artificial learning better?"
        ],
        [
            "Thank you very much for your attention."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Guys, for those of you who are here on time and I wasn't, it was the fault of this little thing.",
                    "label": 0
                },
                {
                    "sent": "Everything in the Mac is excellent except that.",
                    "label": 0
                },
                {
                    "sent": "And they charge $50.00 for it.",
                    "label": 0
                },
                {
                    "sent": "I ran back to my hotel room where when I packed my bag today said to myself, this is the one most important thing to take and then I left it there because it was standing right next to the telephone cord which looks exactly the same.",
                    "label": 0
                },
                {
                    "sent": "So classic object recognition problem.",
                    "label": 0
                },
                {
                    "sent": "And the presentation.",
                    "label": 0
                },
                {
                    "sent": "OK so.",
                    "label": 0
                },
                {
                    "sent": "Wow.",
                    "label": 0
                },
                {
                    "sent": "So the neuroscience of reinforcement learning.",
                    "label": 1
                },
                {
                    "sent": "Now I don't have my notes either, so I'm like driving blind.",
                    "label": 0
                },
                {
                    "sent": "That's fine, so I'm yelling if you'll you won't forget me now after so many mishaps and I'm at Princeton University.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the reason I decided to give this tutorial.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Are basically well, the one reason is that reinforcement learning.",
                    "label": 0
                },
                {
                    "sent": "'cause do you hear me by the way?",
                    "label": 0
                },
                {
                    "sent": "Reinforcement learning is revolutionized.",
                    "label": 0
                },
                {
                    "sent": "Our understanding of learning in the brain in the last two decades or so, yeah.",
                    "label": 1
                },
                {
                    "sent": "But this mic is only for the camera, it doesn't.",
                    "label": 0
                },
                {
                    "sent": "It's not connected to anything that you can hear, so it is on.",
                    "label": 0
                },
                {
                    "sent": "You could also come and sit closer 'cause they're closer seats.",
                    "label": 0
                },
                {
                    "sent": "OK, so as I said, reinforcement learning is really revolutionized.",
                    "label": 0
                },
                {
                    "sent": "The field of neuroscience in general, but more understanding learning.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the brain, and it turns out, surprisingly, that not many machine learners know this, and I thought this was kind of amazing.",
                    "label": 0
                },
                {
                    "sent": "First of all, well.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You should know this because first of all you can take pride an know that you know if you study reinforcement learning.",
                    "label": 1
                },
                {
                    "sent": "There are a bunch of neuro scientists that read your papers and then convert that to knowledge about the brain.",
                    "label": 0
                },
                {
                    "sent": "And for some of us it's important to understand the brain so it can be proud that you that you contributed to that.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The second thing is you can ask, you know not only what can I do for neuroscience?",
                    "label": 0
                },
                {
                    "sent": "Welcome neuroscience do for me.",
                    "label": 1
                },
                {
                    "sent": "So how can neuroscience advance reinforcement learning?",
                    "label": 0
                },
                {
                    "sent": "And that's the thing that I want to try to try to show you today.",
                    "label": 0
                },
                {
                    "sent": "Mostly talk about.",
                    "label": 0
                },
                {
                    "sent": "What we understand about the brain given reinforcement learning.",
                    "label": 0
                },
                {
                    "sent": "But it's your job to do the opposite and I'll try to point out some places where where you can actually do this inversion easily.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Why are you here of?",
                    "label": 0
                },
                {
                    "sent": "Except for the fact that he had an extra 15 minutes to read your email.",
                    "label": 0
                },
                {
                    "sent": "Hopeful.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Lee, you're here because you want to learn something about learning and animals and humans.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Because you want to find out the latest about how the brain does reinforcement learning.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And as I said, to find out how understanding learning in the brain can help reinforcement learning greisser.",
                    "label": 0
                },
                {
                    "sent": "So these are the three things that I'll cover today and the.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That is, if you're here for any other reason.",
                    "label": 1
                },
                {
                    "sent": "An your time is probably better spent elsewhere, so we're not going to.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to talk about the brain in general too much.",
                    "label": 1
                },
                {
                    "sent": "I'm not going to teach you reinforcement learning.",
                    "label": 0
                },
                {
                    "sent": "And yeah, reading email can do outside, so I'll just do just a quick survey so I know I know why you are really here.",
                    "label": 0
                },
                {
                    "sent": "So how many of you on a scale of 1 to three with one being?",
                    "label": 0
                },
                {
                    "sent": "Not very 2, being quite well in three.",
                    "label": 0
                },
                {
                    "sent": "I'm an expert in it.",
                    "label": 0
                },
                {
                    "sent": "How many of you know reinforcement learning?",
                    "label": 0
                },
                {
                    "sent": "So first one, not very.",
                    "label": 0
                },
                {
                    "sent": "OK. Kind of.",
                    "label": 0
                },
                {
                    "sent": "Experts OK, so the not very will have to like do a quick speed up learning on this 'cause I'm not really going to introduce reinforcement learning in its basics now.",
                    "label": 0
                },
                {
                    "sent": "Same for neuroscience.",
                    "label": 0
                },
                {
                    "sent": "How many of you don't know very much about neuroscience in the brain?",
                    "label": 0
                },
                {
                    "sent": "How many know kind of?",
                    "label": 0
                },
                {
                    "sent": "How many are experts nor scientists in the crowd?",
                    "label": 0
                },
                {
                    "sent": "OK, well, OK, so it's kind of balanced the way the way I'd plan for it to be.",
                    "label": 0
                },
                {
                    "sent": "So I was thinking of giving a break in the middle, but now given that I'm so late I won't, but you can.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Feel free to give yourself a break at some point or go get coffee if you feel that you really need it.",
                    "label": 0
                },
                {
                    "sent": "This is a hard hour right after lunch.",
                    "label": 0
                },
                {
                    "sent": "Those of you who came from Europe or like me came from Israel.",
                    "label": 0
                },
                {
                    "sent": "It's a much more comfortable hour.",
                    "label": 0
                },
                {
                    "sent": "It's now like 8:00 PM my time so.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Easier time then right after lunch, but basically the outline.",
                    "label": 0
                },
                {
                    "sent": "Well I'll tell you.",
                    "label": 0
                },
                {
                    "sent": "The outline of the top of the tutorial, but I'll tell you in advance that each part of this tutorial is kind of a module that lives on its own except for the first three parts.",
                    "label": 0
                },
                {
                    "sent": "So that's why I said feel free to like if you feel that you need your coffee or your fault, otherwise you'll fall asleep.",
                    "label": 0
                },
                {
                    "sent": "Just go get coffee, come back and tune into the next module in the same if you kind of fade, fade out then just wait till the next time I show the outline, 'cause every time I'm going to show the outline, the beginning of each.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Action.",
                    "label": 0
                },
                {
                    "sent": "So what are we going to talk about?",
                    "label": 0
                },
                {
                    "sent": "I'll start with talking a little bit about the brain.",
                    "label": 0
                },
                {
                    "sent": "Very coarse grained, just in general to put us all on the same footing.",
                    "label": 0
                },
                {
                    "sent": "And then talk about learning and decision making and animals and humans.",
                    "label": 1
                },
                {
                    "sent": "Again, very broadly, trying to tie that to reinforcement learning and why.",
                    "label": 0
                },
                {
                    "sent": "Why do we think that reinforcement learning has something to do with actual animal learning or human?",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Turning then I'll talk about the most important part, which is dopamine and prediction errors.",
                    "label": 1
                },
                {
                    "sent": "The biggest success story of computational neuroscience I think.",
                    "label": 0
                },
                {
                    "sent": "Or one of the biggest so far.",
                    "label": 0
                },
                {
                    "sent": "So these three parts kind of go together, and from here start.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Being modular.",
                    "label": 0
                },
                {
                    "sent": "We'll talk about our actor critic architectures in the basal ganglia.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We'll talk about two other algorithms, so actually critic is one way to do model free reinforcement.",
                    "label": 0
                },
                {
                    "sent": "Learning.",
                    "label": 0
                },
                {
                    "sent": "Sarsa and Q Learning are two other ways to do model free reinforcement learning and will talk about whether well after we talk about actor critic in the basal ganglia.",
                    "label": 1
                },
                {
                    "sent": "It turns out that maybe the brain actually does sorceror Q learning, and this is this is 1 area where the brain can teach us a little bit about machine learning because we could basically ask.",
                    "label": 1
                },
                {
                    "sent": "There are three algorithms, which one does the brain use.",
                    "label": 0
                },
                {
                    "sent": "And since the brain does what it does pretty well, maybe that will give us some insight.",
                    "label": 0
                },
                {
                    "sent": "On comparing between these algorithms.",
                    "label": 0
                },
                {
                    "sent": "Then it will.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Talk about model free and model based reinforcement learning in the brain.",
                    "label": 0
                },
                {
                    "sent": "So until now everything was model free but there will be a model based part.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then average reward reinforcement learning a different formulation that's not used as widely reinforcement learning, but may tell us something about tonic dopamine in the brain.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Add finally next to last.",
                    "label": 0
                },
                {
                    "sent": "If we have time.",
                    "label": 0
                },
                {
                    "sent": "This was not in the slides that I put on line.",
                    "label": 0
                },
                {
                    "sent": "I added it as a bonus so if we get to it will talk about risk sensitivity and reinforcement learning in the brain.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And with open challenges and future directions for neuro scientists.",
                    "label": 0
                },
                {
                    "sent": "For the one or a scientist in the crowd.",
                    "label": 0
                },
                {
                    "sent": "And for reinforcement learning.",
                    "label": 0
                },
                {
                    "sent": "OK, so as I said.",
                    "label": 0
                },
                {
                    "sent": "We'll start with the brain coarse grain, just to kind of.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The feel of what what we're talking about here.",
                    "label": 0
                },
                {
                    "sent": "So the first question is a question for you, which is why do we have a brain?",
                    "label": 1
                },
                {
                    "sent": "Ideas?",
                    "label": 0
                },
                {
                    "sent": "To survive.",
                    "label": 0
                },
                {
                    "sent": "To answer my question, why do animals?",
                    "label": 0
                },
                {
                    "sent": "Why?",
                    "label": 0
                },
                {
                    "sent": "What is the main purpose of a brain?",
                    "label": 0
                },
                {
                    "sent": "To move good answer.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I thought maybe you'd say because there weren't computers when we were invented.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Actually, yes, I think it is in order to to move or to behave.",
                    "label": 0
                },
                {
                    "sent": "And actually Daniel Wolpert, who is the person I stole this idea from, usually puts to move up there.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And an example is this animal called the C squared.",
                    "label": 0
                },
                {
                    "sent": "So the C squared is a little marine animal and what it does in the beginning of its life.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Has two stages of its life.",
                    "label": 0
                },
                {
                    "sent": "When it's a larva, it has a primitive brain that has an eye.",
                    "label": 0
                },
                {
                    "sent": "It swims around, finds a nice place to attach to, attaches to a rock.",
                    "label": 1
                },
                {
                    "sent": "And then once it attached.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the second part of its life and its adult stage, it just sits on the rock doesn't move anymore in a digests its own brain.",
                    "label": 0
                },
                {
                    "sent": "So to move is a good answer, and in fact you all know many living creatures that live happily without a brain and they don't move for instance.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This one.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is our brain.",
                    "label": 0
                },
                {
                    "sent": "This is a human brain.",
                    "label": 0
                },
                {
                    "sent": "You've probably seen pictures like this many times and it won't go into the names of the different areas.",
                    "label": 0
                },
                {
                    "sent": "They don't really matter for our purpose.",
                    "label": 0
                },
                {
                    "sent": "What does matter is this is by the way, aside for you looking at the human brain from the side, the eyes would be here.",
                    "label": 0
                },
                {
                    "sent": "The neck down here somewhere you know face neck.",
                    "label": 0
                },
                {
                    "sent": "This is the back of the brain.",
                    "label": 1
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And you can think about the whole interaction between the brain and the world.",
                    "label": 0
                },
                {
                    "sent": "In this way we have.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "World.",
                    "label": 0
                },
                {
                    "sent": "And the world enters into our realm in our knowledge, through sensory processing in the brain.",
                    "label": 1
                },
                {
                    "sent": "So the brain, first of all, has to take in all its sensory data and process that and huge chunks of the brain are devoted to that.",
                    "label": 0
                },
                {
                    "sent": "The visual cortex.",
                    "label": 0
                },
                {
                    "sent": "Here, the auditory cortex, the.",
                    "label": 0
                },
                {
                    "sent": "Matter sensory cortex.",
                    "label": 0
                },
                {
                    "sent": "The olfactory cortex.",
                    "label": 0
                },
                {
                    "sent": "Huge areas.",
                    "label": 0
                },
                {
                    "sent": "And then on the other side.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Comes out motor processing and again huge areas of the brain.",
                    "label": 1
                },
                {
                    "sent": "This whole area and some of this area deals with motor processing.",
                    "label": 0
                },
                {
                    "sent": "How to tell our muscles to do what we want to do so that we can perform motor actions?",
                    "label": 0
                },
                {
                    "sent": "That will of course impact on the world and this thing will start again where in the mid?",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So they're kind of smaller parts of the brain, but there are the parts that were interested in which you do the interesting things right.",
                    "label": 1
                },
                {
                    "sent": "They take the sensory processing, they take the sensory data and decide what motor action to make using memory, cognition, decision making, all the high level functions, etc.",
                    "label": 0
                },
                {
                    "sent": "So will be interested today and these areas kind of, assuming that how to turn things into motor commands and how to take input from the world is already done for us.",
                    "label": 0
                },
                {
                    "sent": "The question is what to do?",
                    "label": 0
                },
                {
                    "sent": "What to choose to do based on the inputs?",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what do we know about the brain?",
                    "label": 1
                },
                {
                    "sent": "But this is going to be very coarse grained, right?",
                    "label": 0
                },
                {
                    "sent": "Because we know we can teach classes about whole classes about the brain, but in general.",
                    "label": 0
                },
                {
                    "sent": "In terms of anatomy, we know a lot about what is where in the brain.",
                    "label": 1
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And what area is connected to which so we can draw these diagrams with different colors for different areas that that are distinct.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately, you should know if you read literature about the brain or listen to talks like this that the names of errors in the brain were made up before people knew what these areas did.",
                    "label": 0
                },
                {
                    "sent": "So they follow structure, not function.",
                    "label": 1
                },
                {
                    "sent": "So sometimes two areas will be called global pallidus, internal capsule and external capsule.",
                    "label": 0
                },
                {
                    "sent": "They're completely different.",
                    "label": 0
                },
                {
                    "sent": "They do completely different things.",
                    "label": 0
                },
                {
                    "sent": "And two other areas that have the same name.",
                    "label": 0
                },
                {
                    "sent": "Have very different names like the caudete nucleus in the payment because they have a big 5 big of.",
                    "label": 0
                },
                {
                    "sent": "What's it called bundle of fibers?",
                    "label": 0
                },
                {
                    "sent": "Going through them, they were given two different names with their part of the same structure we know today they do very similar things, so you can't always go from name to function, but in general we know a lot about what is, what is where, which areas connected to which area.",
                    "label": 1
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In terms of single neurons, so the single cells that make up the brain, we also know quite a bit about how they work.",
                    "label": 1
                },
                {
                    "sent": "That was actually the first big kind of computational neuroscience revolution.",
                    "label": 0
                },
                {
                    "sent": "Hodgkin Huxley and understanding how neuronal spikes are generated, how neurons send electronic messages to each other.",
                    "label": 1
                },
                {
                    "sent": "But I should say all that we know in general what a neuron does.",
                    "label": 0
                },
                {
                    "sent": "If it were a very very simplified pointer on a point that gets inputs, decides what to do and sends an output that we know.",
                    "label": 0
                },
                {
                    "sent": "But neurons are not.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Point neurons they have.",
                    "label": 0
                },
                {
                    "sent": "They have a complex 3D structure, so this is the cell body of a neuron and these are dendrites where the neuron gets its input and this is the Axon where the neuron sends its output and we know how the the cell body takes the inputs, it basically computes.",
                    "label": 0
                },
                {
                    "sent": "The sum of them, and if the sum is higher than a threshold, then the neuron sends output.",
                    "label": 0
                },
                {
                    "sent": "The thing is, these little things that in the picture look like they don't really match.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sure.",
                    "label": 0
                },
                {
                    "sent": "What they really look like is that.",
                    "label": 0
                },
                {
                    "sent": "So they're very, very delicate and intertwine structures where neurons can touch each other in many, many places or in few places.",
                    "label": 0
                },
                {
                    "sent": "And it's unclear what this big 3D structure is, therefore, but clearly it's there for some reason.",
                    "label": 0
                },
                {
                    "sent": "Otherwise the brain went well, biology wouldn't bother.",
                    "label": 0
                },
                {
                    "sent": "Came on this side.",
                    "label": 0
                },
                {
                    "sent": "These can be so both these and these can be very very complex structures and there are models of.",
                    "label": 0
                },
                {
                    "sent": "How an input that comes at this point can be different from an input that comes at this point, but it's very hard to integrate this into a functional understanding of.",
                    "label": 0
                },
                {
                    "sent": "You know how does the neuron even know where to put its dendrites?",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Networks of neurons.",
                    "label": 0
                },
                {
                    "sent": "So going from the level of single neurons to networks, we have some ideas how networks work.",
                    "label": 1
                },
                {
                    "sent": "But in general we're still in the dark.",
                    "label": 1
                },
                {
                    "sent": "I would almost say we have no idea, but you know I wrote we have some ideas for those people who do have some ideas.",
                    "label": 0
                },
                {
                    "sent": "I don't understand it much.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In terms of learning in the brain that really, that's really what we're here for today.",
                    "label": 1
                },
                {
                    "sent": "So this is 1 area where we know a lot of facts.",
                    "label": 1
                },
                {
                    "sent": "We know things about LTP, which is long term potentiation, long term depression, spike, timing dependent plasticity.",
                    "label": 0
                },
                {
                    "sent": "So how do connections between neurons synapses between neurons change when?",
                    "label": 0
                },
                {
                    "sent": "A signal is passed through a neuron, but although we know all these facts and although people think that learning happens through these changes in synaptic strength or synaptic weights.",
                    "label": 0
                },
                {
                    "sent": "There is no direct proof of that.",
                    "label": 0
                },
                {
                    "sent": "There's no direct proof of that is at all related to learning in the general behavioral sense.",
                    "label": 0
                },
                {
                    "sent": "It's not clear.",
                    "label": 1
                },
                {
                    "sent": "What is the relationship between these kinds of synaptic learning and the computations that we'll talk about today?",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And finally, in terms of function, as I said, we have very coarse grained knowledge of what different brain areas do, but we have to be careful, especially the names are sometimes misleading like you can have neurons in motor cortex that actually respond to color and not to motor.",
                    "label": 1
                },
                {
                    "sent": "And rather than controlling motor commands, and it's definitely more complex when you get to higher cognitive areas.",
                    "label": 0
                },
                {
                    "sent": "So the whole front of the brain, the frontal cortex used to be considered an area that does nothing because it does the most important things.",
                    "label": 0
                },
                {
                    "sent": "It does the higher cognitive function, so you leave it in the frontal cortex and people still can move and eat and drink and sleep.",
                    "label": 0
                },
                {
                    "sent": "They look like.",
                    "label": 0
                },
                {
                    "sent": "They are animals that behave like animals do, but they're just not people anymore.",
                    "label": 1
                },
                {
                    "sent": "So or they are people, but their personality changes their memory ability, their learning ability changes.",
                    "label": 0
                },
                {
                    "sent": "So those areas we know much less about.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The the status of neuroscience today is we have a lot of facts about the brain and people do thousands and millions of experiments.",
                    "label": 0
                },
                {
                    "sent": "Which gather more and more facts, but the problem is we still don't understand how to put these facts together and how the brain works.",
                    "label": 0
                },
                {
                    "sent": "And this is where machine learning can perhaps help, or at least I believe that machine learning can help.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Let's talk about learning and decision making and why it's related to reinforcement learning.",
                    "label": 1
                },
                {
                    "sent": "By the way, stop me if you have questions.",
                    "label": 0
                },
                {
                    "sent": "Just raise your hand and hopefully I'll see.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "You might ask yourself, what did our scientists do all day?",
                    "label": 0
                },
                {
                    "sent": "You know what?",
                    "label": 0
                },
                {
                    "sent": "You guys do all day.",
                    "label": 1
                },
                {
                    "sent": "You sitting right simulations and it's really hard.",
                    "label": 1
                },
                {
                    "sent": "What do these newer scientists do?",
                    "label": 0
                },
                {
                    "sent": "Just collect data points.",
                    "label": 0
                },
                {
                    "sent": "What we do all day is.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We try to figure out how the brain generates behavior, so this two way St between the brain and behavior.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so you might ask yourself, well, OK, if it's one question, do we need so many neuro scientists for one simple question?",
                    "label": 0
                },
                {
                    "sent": "So from the introduction I already gave, you might.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Already realized that the problem is that the brain is really complex.",
                    "label": 0
                },
                {
                    "sent": "This is a picture of what was known 20 years ago about the circuitry of vision processing.",
                    "label": 0
                },
                {
                    "sent": "So all these little blocks are vision areas and the the main connections between them.",
                    "label": 0
                },
                {
                    "sent": "Not all the connections between them.",
                    "label": 0
                },
                {
                    "sent": "This was 20 years ago, so today you can imagine you can't even draw.",
                    "label": 0
                },
                {
                    "sent": "The excess of data that we've collected there.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the old idea of studying the brain was, well, we can look at the brain structure and get from structure to function 'cause the structure is not is not there for no reason.",
                    "label": 0
                },
                {
                    "sent": "It's not random structure, it's very orderly.",
                    "label": 0
                },
                {
                    "sent": "Different animals have the same structure in their brain.",
                    "label": 0
                },
                {
                    "sent": "It must be that the structure is important to function.",
                    "label": 0
                },
                {
                    "sent": "But the problem was indeed this structure is real.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Complicated and you know this kind of structure that we've looked at before really, really complicated.",
                    "label": 0
                },
                {
                    "sent": "And it turns out that just looking at structure and inferring function from it is kind of like trying to reverse engineer your computer by looking at the motherboard and saying what does this do is very orderly structure.",
                    "label": 0
                },
                {
                    "sent": "We must be able to look at it and know what it does.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Just to put numbers on thanks the brain.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As 10 to the power of 11.",
                    "label": 0
                },
                {
                    "sent": "So that's 100 billion if I'm not mistaken, neurons and each neuron is connected on average to 1000 others, so you know, quite some.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Actually there.",
                    "label": 0
                },
                {
                    "sent": "So it seems like, well, I started with why do we need so many neuroscience?",
                    "label": 1
                },
                {
                    "sent": "It seems like we don't need any neuro scientists because we actually don't stand a chance and we should just give up.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "But that's where computational.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Our science comes in with the idea with a relatively new idea that well.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Brain is a computing device, right?",
                    "label": 1
                },
                {
                    "sent": "So if you wanted to.",
                    "label": 0
                },
                {
                    "sent": "Reverse engineer your computer.",
                    "label": 0
                },
                {
                    "sent": "The first thing he would ask was, well, what can I do with my computer?",
                    "label": 0
                },
                {
                    "sent": "My computer computes things.",
                    "label": 0
                },
                {
                    "sent": "The same thing about the brain.",
                    "label": 0
                },
                {
                    "sent": "The brain is a computing device, So what we can ask is.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Can we use computational models?",
                    "label": 1
                },
                {
                    "sent": "To understand the functions of the brain rather than going from structure, we can go from what does it need to compute?",
                    "label": 1
                },
                {
                    "sent": "What would it need in order to compute these things and then search for those functions in the brain?",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And at this point we can take something that's very abstract in form abstract theory.",
                    "label": 0
                },
                {
                    "sent": "It's not concrete.",
                    "label": 0
                },
                {
                    "sent": "It's not like structure, but the abstract theory can miraculously help us organize and interpret all the concrete data that we have, and we don't know how to put together.",
                    "label": 1
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that's that's in general.",
                    "label": 0
                },
                {
                    "sent": "How I how I see the contribution of computational neuroscience to understanding the brain and there is a framework that was suggested by David Marr.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In the 70s.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "He was a researcher who studied vision, one of the first computational neuro scientists.",
                    "label": 0
                },
                {
                    "sent": "So this framework really helps us do computational neuroscience in the.",
                    "label": 1
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well.",
                    "label": 0
                },
                {
                    "sent": "Understand what we're doing and what level of analysis we're looking at and the framework basically says that when you do computational neuroscience and we try to understand what is the computational function of the brain and how that is.",
                    "label": 0
                },
                {
                    "sent": "How that is realized in the brain, you should always remember that there are three levels of analysis.",
                    "label": 1
                },
                {
                    "sent": "One level is what is the problem that's called the computational level?",
                    "label": 0
                },
                {
                    "sent": "What problem is the brain trying to solve?",
                    "label": 0
                },
                {
                    "sent": "And this at this level it doesn't have to be the brain.",
                    "label": 0
                },
                {
                    "sent": "This same problem could be solved by a computer by an algorithm by a robot.",
                    "label": 0
                },
                {
                    "sent": "It's also hopefully solved by the brain if we're studying the.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Rain.",
                    "label": 0
                },
                {
                    "sent": "Then you can ask yourself what's the strategy or what are different strategies.",
                    "label": 1
                },
                {
                    "sent": "Different algorithms that can solve this computational problem?",
                    "label": 0
                },
                {
                    "sent": "Still, we're staying in the very abstract and the census that until here everything could still apply to a robot.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And finally, the third level is how it's actually done by networks of neurons in the brain.",
                    "label": 0
                },
                {
                    "sent": "This is called implementational level.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "David Marr suggested these three levels and what we're going to talk about today is.",
                    "label": 1
                },
                {
                    "sent": "Mostly well, we're going to talk about all of them because The thing is reinforcement.",
                    "label": 0
                },
                {
                    "sent": "Learning helps us define the problem.",
                    "label": 0
                },
                {
                    "sent": "Define a set of strategies, and then understand how these are realized in the brain.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What's the hardest problem you face in your life?",
                    "label": 1
                },
                {
                    "sent": "Every day.",
                    "label": 0
                },
                {
                    "sent": "What is that?",
                    "label": 0
                },
                {
                    "sent": "I don't wanna know.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So my claim is one of the problems one of the hard problems we face.",
                    "label": 0
                },
                {
                    "sent": "Everyone of us faces in our.",
                    "label": 1
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A like for instance, you know, and we're choosing what to order at a restaurant.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or when we're playing video games or games with other people, like a game of chess or making high level decisions about what we want to do with our life.",
                    "label": 0
                },
                {
                    "sent": "Our problem is exactly.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The reinforcement learning problem of optimal decision making?",
                    "label": 0
                },
                {
                    "sent": "How do we maximize our reward and minimize the punishment that we get from the world for everything that we do and reinforcement learning already tells us?",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Why this problem is hard, right?",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We know that reward or punishment may be delayed.",
                    "label": 0
                },
                {
                    "sent": "Doesn't come immediately if you eat sushi, you might get a stomach ache 4 hours later if you make a move in chess, you might win or lose the game after many.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or actions, and that's the second problem that the outcome might depend not only on one action, but on many actions that you perform.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And these two problems were termed years ago by by Rich Sutton actually in his.",
                    "label": 0
                },
                {
                    "sent": "BA thesis the credit assignment problem.",
                    "label": 0
                },
                {
                    "sent": "So this is a big problem that faces reinforcement learning is also the big problem that faces the brain.",
                    "label": 0
                },
                {
                    "sent": "We interact with the world all the time.",
                    "label": 0
                },
                {
                    "sent": "We get rewards, we get punishments.",
                    "label": 0
                },
                {
                    "sent": "We have to decide what actions were the right actions that we did and what were the wrong ones.",
                    "label": 0
                },
                {
                    "sent": "Which one wants to do in the future.",
                    "label": 0
                },
                {
                    "sent": "Probably going to grad school is not a good one.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So as I said.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is where reinforcement learning comes.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And basically, oops.",
                    "label": 0
                },
                {
                    "sent": "Specifies all three of Mars levels, so the problem the problem level.",
                    "label": 0
                },
                {
                    "sent": "The computational level is optimal decision making.",
                    "label": 1
                },
                {
                    "sent": "The algorithm is reinforcement learning, basically is a set of algorithms to solve this credit assignment problem.",
                    "label": 0
                },
                {
                    "sent": "And the neural implementation, which we'll talk about today, is in the basal ganglia, dopamine, dependent learning, etc.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what we have so far is this idea of studying the brain is a computer is a computing device which may not seem so revolutionary to you, but it was quite revolutionary in neuroscience and still many neuroscientists kind of look at computation.",
                    "label": 0
                },
                {
                    "sent": "There are scientists with an IO like what are you doing here?",
                    "label": 0
                },
                {
                    "sent": "And this is a different take on networks of neurons.",
                    "label": 0
                },
                {
                    "sent": "What neurons do people are used to asking themselves?",
                    "label": 0
                },
                {
                    "sent": "What do these neurons represent?",
                    "label": 0
                },
                {
                    "sent": "These represent a motor action or a combination of motor actions, or a line in space, or a line in a certain angle, etc.",
                    "label": 0
                },
                {
                    "sent": "And I'm talking about looking at what these neurons compute, 'cause if you think about it, the brain doesn't care about just representing the world.",
                    "label": 0
                },
                {
                    "sent": "Each area represents something.",
                    "label": 0
                },
                {
                    "sent": "What will we get out of that we have to compute something with these representations in order to get to the point where we actually behave.",
                    "label": 0
                },
                {
                    "sent": "So the next thing I want to talk about is what do animals brains really compute and that that should be kind of the guideline to computations we want to look at.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in general, there's.",
                    "label": 0
                },
                {
                    "sent": "100 plus years or 100 plus years of animal learning theory behind us and this theory has identified over these experiments have identified two basic types of animal learning called also animal conditioning.",
                    "label": 0
                },
                {
                    "sent": "So I want to go through each of them very quickly.",
                    "label": 0
                },
                {
                    "sent": "And talk about how these two types relate to reinforcement learning.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I'm sure you've all heard about Pavlov this guy.",
                    "label": 0
                },
                {
                    "sent": "So Pavlovi and conditioning is this kind of conditioning that that.",
                    "label": 0
                },
                {
                    "sent": "We learn about in school where animals slobber when they expect food so.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Pavlov did is.",
                    "label": 0
                },
                {
                    "sent": "He showed that, well, he actually studied.",
                    "label": 0
                },
                {
                    "sent": "He was a Russian neuro physiologist studying the endocrine system and and secretion of.",
                    "label": 0
                },
                {
                    "sent": "Digestive juices in the pancreas.",
                    "label": 0
                },
                {
                    "sent": "I think that's what he got his Nobel Prize for, not for anything about animal learning.",
                    "label": 1
                },
                {
                    "sent": "And what he did?",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It was he'd give the dog give dogs food and collect their saliva to analyze the different enzymes in it, etc.",
                    "label": 0
                },
                {
                    "sent": "And what he noticed is that after a while the dog starts secreting saliva, right when he comes into the room before they got any food and that was the clue that actually there has been some conditioning, some learning about the relationship between him, Pavlov and food.",
                    "label": 0
                },
                {
                    "sent": "But when he made this into a much more controlled.",
                    "label": 0
                },
                {
                    "sent": "Experiment what he did is he.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Would pair some stimulus, let's say a Bell with the food.",
                    "label": 0
                },
                {
                    "sent": "So every time he would sound the Bell and two 2 minutes later give the dog.",
                    "label": 0
                },
                {
                    "sent": "The steak.",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And what he says after a while, if he would just sound the Bell with no stakes.",
                    "label": 0
                }
            ]
        },
        "clip_80": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Til the dog would secrete these Salvation juices and so the idea here is that the animal learned that the Bell predicts food so so one thing that we know about animals is they can learn to predict what's going to happen in the future, which is a really, really useful thing to learn in the world because you don't have to wait for it to happen.",
                    "label": 0
                },
                {
                    "sent": "You can act in advance like salivate.",
                    "label": 0
                }
            ]
        },
        "clip_81": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of.",
                    "label": 0
                },
                {
                    "sent": "And I want to show you 2 movies.",
                    "label": 0
                },
                {
                    "sent": "I will show them here, let's hope.",
                    "label": 0
                },
                {
                    "sent": "You know what?",
                    "label": 0
                },
                {
                    "sent": "Since this won't work.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_82": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in this movie, what you're going to see?",
                    "label": 0
                },
                {
                    "sent": "This is a.",
                    "label": 0
                },
                {
                    "sent": "View from the top of four cages with different with four different rats that are undergoing conditioning.",
                    "label": 0
                },
                {
                    "sent": "And in the first part, so these rats, they have food.",
                    "label": 0
                },
                {
                    "sent": "They have little food magazine in this corner where they can eat food pellets, and they're happily eating and getting used to the boxes that they're in.",
                    "label": 0
                },
                {
                    "sent": "And now, in this light turned on, that means that a tone is sounded to them.",
                    "label": 0
                },
                {
                    "sent": "You can't hear it here.",
                    "label": 0
                },
                {
                    "sent": "So the light is just telling you that it's on and they're ignoring the tone.",
                    "label": 0
                },
                {
                    "sent": "Now in the second stage, what happened was once the once the tone turned on a few seconds later they got a shock afoot.",
                    "label": 0
                },
                {
                    "sent": "Shock to these bars.",
                    "label": 0
                },
                {
                    "sent": "You saw that now you saw them jumping.",
                    "label": 0
                },
                {
                    "sent": "That's when they got the shock.",
                    "label": 0
                },
                {
                    "sent": "And now, 24 hours later, now I should say that it's enough to pair the tone with the shock once or twice for what you'll see now.",
                    "label": 0
                },
                {
                    "sent": "So, 24 hours later, they are happily eating the food and you'll see what happens when the tone comes on.",
                    "label": 0
                },
                {
                    "sent": "The video is continuing, it's just they are freezing.",
                    "label": 0
                },
                {
                    "sent": "Out of fear, this one is like risking his life trying to get to the food.",
                    "label": 0
                },
                {
                    "sent": "So you can think of this in the biological sense of there is something telling them that a predator is around and the right thing to do is freeze so the predator won't see you.",
                    "label": 0
                },
                {
                    "sent": "That's why I said that one was risking his life.",
                    "label": 0
                },
                {
                    "sent": "But that was a conditioned response.",
                    "label": 0
                },
                {
                    "sent": "A learned response to that own.",
                    "label": 0
                },
                {
                    "sent": "They did not get any shock in this experiment.",
                    "label": 0
                },
                {
                    "sent": "In this phase of the experiment.",
                    "label": 0
                },
                {
                    "sent": "So that was one movie.",
                    "label": 0
                },
                {
                    "sent": "What was the other movie that I wanted to show you oh?",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So this is another movie of conditioning and animals and this is a famous pigeon conditioning.",
                    "label": 0
                },
                {
                    "sent": "But Skinner did a lot of So what happens here is the light.",
                    "label": 0
                },
                {
                    "sent": "The little circle turned on over there.",
                    "label": 0
                },
                {
                    "sent": "Now the food is available.",
                    "label": 0
                },
                {
                    "sent": "You see the pigeon is like I don't care.",
                    "label": 0
                },
                {
                    "sent": "Light is turning on.",
                    "label": 0
                },
                {
                    "sent": "It doesn't care.",
                    "label": 0
                },
                {
                    "sent": "Oh wow, here's some food.",
                    "label": 0
                },
                {
                    "sent": "I'll eat the food.",
                    "label": 0
                },
                {
                    "sent": "After awhile the pigeons like.",
                    "label": 0
                },
                {
                    "sent": "What's that like there?",
                    "label": 0
                },
                {
                    "sent": "I haven't seen that before.",
                    "label": 0
                },
                {
                    "sent": "Oh food.",
                    "label": 0
                },
                {
                    "sent": "After a few more trials.",
                    "label": 0
                },
                {
                    "sent": "Or maybe this is not after a few more trials, yet fish is like suspiciously looking at that light.",
                    "label": 0
                },
                {
                    "sent": "I remember that one.",
                    "label": 0
                },
                {
                    "sent": "Came right before the food last time too.",
                    "label": 0
                },
                {
                    "sent": "And now he's already learned, and he's looking at, you, know, when's that light going to come on?",
                    "label": 0
                },
                {
                    "sent": "Oh came on.",
                    "label": 0
                },
                {
                    "sent": "We need to show a closeup of what it's doing to the light.",
                    "label": 0
                },
                {
                    "sent": "This looks tasty.",
                    "label": 0
                },
                {
                    "sent": "So this is called autoshaping because automatically the.",
                    "label": 0
                },
                {
                    "sent": "The pigeon learns to Peck at the light without it ever needing to pick at the light right?",
                    "label": 0
                },
                {
                    "sent": "The light is just there and you could just like be standing next to the food and waiting for the food the whole time.",
                    "label": 0
                },
                {
                    "sent": "But he starts pecking at the light and this is because the light predicts food and this behavior is so strong that actually if you try to ask the pigeon to not packet delight.",
                    "label": 0
                },
                {
                    "sent": "You get into real trouble.",
                    "label": 0
                },
                {
                    "sent": "So this is the same pigeon after some training and now every time it pecks at the at the light he will not get food.",
                    "label": 0
                },
                {
                    "sent": "He's basically causing himself to not get food by this pecking if he just ignored the light it would be completely fine, but no picking allowed.",
                    "label": 0
                },
                {
                    "sent": "And he's like no food after 8 days 32 trials every day.",
                    "label": 0
                },
                {
                    "sent": "Still, it's pretty hard for him to ignore that light, but he's managing to not pick.",
                    "label": 0
                },
                {
                    "sent": "He is looking at it and almost picking, but not exactly faking.",
                    "label": 0
                },
                {
                    "sent": "And you'll get a close up now to see the packing as close as possible without touching.",
                    "label": 0
                },
                {
                    "sent": "So this kind of what's called pavlovi and conditioned behavior is very, very powerful.",
                    "label": 0
                },
                {
                    "sent": "What was the?",
                    "label": 0
                },
                {
                    "sent": "What was the thing that made it full screen?",
                    "label": 0
                },
                {
                    "sent": "Mcel you saw this?",
                    "label": 0
                },
                {
                    "sent": "So it's very it's very very power.",
                    "label": 0
                }
            ]
        },
        "clip_83": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Careful behavior animals even have have trouble not emitting this, and the idea is if we rewrite all this to reinforcement learning that there is some.",
                    "label": 0
                },
                {
                    "sent": "Learning probably model free in this case, but I didn't have to put that word in there.",
                    "label": 0
                },
                {
                    "sent": "Some learning of the values of different stimuli, So what reward different stimuli, or what we'd call in reinforcement learning?",
                    "label": 0
                },
                {
                    "sent": "Different states predict this is learned through experience, and then the idea is that once an animal learns this kind of value, it responds based on the value, and it's really hard to even avoid this response and not emit it, because this light does predict food in the pigeon.",
                    "label": 0
                },
                {
                    "sent": "Can't ignore it, even though.",
                    "label": 0
                },
                {
                    "sent": "We try so hard to make it ignore it.",
                    "label": 0
                },
                {
                    "sent": "So this is one kind of learning prediction learning and it's related to reinforcement learning in this way.",
                    "label": 0
                },
                {
                    "sent": "Why?",
                    "label": 0
                }
            ]
        },
        "clip_84": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Before reinforcement learning and the 70s are worse, color and Wagner suggested that this kind of learning is error driven.",
                    "label": 0
                },
                {
                    "sent": "So what they postulated is that the change in value of a stimulus.",
                    "label": 0
                },
                {
                    "sent": "On a certain trial is proportional to the difference between the actual reward obtained on that trial and the sum of the values of all the stimuli that were present in that trial, and I should say this is one out of four equations that you'll have today.",
                    "label": 0
                },
                {
                    "sent": "I think I'll have the.",
                    "label": 0
                },
                {
                    "sent": "Well, tutorial with the least equations ever.",
                    "label": 0
                },
                {
                    "sent": "So the idea here there were two assumptions.",
                    "label": 0
                },
                {
                    "sent": "One is this idea of.",
                    "label": 1
                },
                {
                    "sent": "An error correcting learning rule, so learning driven by errors in prediction.",
                    "label": 0
                },
                {
                    "sent": "So if the sum of the values doesn't equal the reward, there is an error.",
                    "label": 0
                },
                {
                    "sent": "And the second, the second assumption was that different predictors are summed linearly, and these two assumptions were based on a lot of experimentation.",
                    "label": 0
                },
                {
                    "sent": "I'll just give you the important one.",
                    "label": 0
                }
            ]
        },
        "clip_85": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How do we know that animals really use an error correcting rule?",
                    "label": 0
                },
                {
                    "sent": "And of course we care about this.",
                    "label": 0
                },
                {
                    "sent": "'cause reinforcement learning uses error correcting rules.",
                    "label": 0
                },
                {
                    "sent": "So this is an experiment called blocking and the idea is.",
                    "label": 0
                }
            ]
        },
        "clip_86": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In phase one, you pair a stimulus with reward with some kind of.",
                    "label": 0
                }
            ]
        },
        "clip_87": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Rewarding event and of course we already know from Pavlov then that.",
                    "label": 0
                }
            ]
        },
        "clip_88": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Stimulus will generate some Pavlovian response.",
                    "label": 0
                },
                {
                    "sent": "If we test it even without the food.",
                    "label": 0
                },
                {
                    "sent": "And now.",
                    "label": 0
                }
            ]
        },
        "clip_89": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now in phase two we show 2 stimuli together.",
                    "label": 0
                },
                {
                    "sent": "For instance, a tone and a light, and they predict.",
                    "label": 0
                }
            ]
        },
        "clip_90": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The same food, so the same food is given the same delay that it was given before.",
                    "label": 0
                },
                {
                    "sent": "And now if you test the Bell.",
                    "label": 0
                }
            ]
        },
        "clip_91": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On its own, there is still a response to the Bell, but it turns out that there is no.",
                    "label": 0
                }
            ]
        },
        "clip_92": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Response to the light.",
                    "label": 0
                },
                {
                    "sent": "So there is no new learning about the light in this case, and that's why it's called blocking.",
                    "label": 0
                },
                {
                    "sent": "The idea is that.",
                    "label": 0
                }
            ]
        },
        "clip_93": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The fact that the tone already predicted the food block learning for the light, and this is true not only in animals, is true in humans as well, in experiments in which, for instance, they give humans they give people sets of symptoms that predict different diseases.",
                    "label": 0
                },
                {
                    "sent": "An unknowingly.",
                    "label": 0
                },
                {
                    "sent": "Within these symptoms there is this kind of structure where first there are a bunch of symptoms that predicted disease and then later a bunch of others are added to them, and then in the test people are asked does this symptom.",
                    "label": 0
                },
                {
                    "sent": "On its own predicted disease, does this predicted disease in the same kind of blocking is shown?",
                    "label": 0
                },
                {
                    "sent": "So actually this learning is very prevalent.",
                    "label": 0
                },
                {
                    "sent": "It's very important in our life because there are always lots of.",
                    "label": 0
                },
                {
                    "sent": "Stimulate together we want the one that's most predictive.",
                    "label": 0
                },
                {
                    "sent": "We want to learn about the one that's most predictive of reward, but this was a major.",
                    "label": 0
                },
                {
                    "sent": "Clue that learning is driven by errors in prediction.",
                    "label": 0
                }
            ]
        },
        "clip_94": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, second form yeah.",
                    "label": 0
                },
                {
                    "sent": "Experiments experiments to determine whether the pigeon is learning costs on appeal just correlation.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                },
                {
                    "sent": "Do animals?",
                    "label": 0
                },
                {
                    "sent": "That's a very good question.",
                    "label": 0
                },
                {
                    "sent": "So the question was I was talking about the light predicting the food, but the question is, is this just correlation or is it causal?",
                    "label": 0
                },
                {
                    "sent": "So you know if we think about it, the light does not cause the food the experimental causes both the light and the food.",
                    "label": 0
                },
                {
                    "sent": "But what does the pigeon understand here?",
                    "label": 0
                },
                {
                    "sent": "Does it understand a causal structure or does it understand some higher structure where there's a hidden cause causing these two different events to happen and?",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Their computational models to both directions, and I think that the this is still a point of argument point of contention, but you asked, do animals actually intervene to test their causal hypothesis?",
                    "label": 0
                },
                {
                    "sent": "And that's where instrumental conditioning actually comes in, because in instrumental conditioning animals have some control over the environment.",
                    "label": 0
                },
                {
                    "sent": "In Pavlovi and conditioning, what defines approval?",
                    "label": 0
                },
                {
                    "sent": "Open condition situation is that no matter what the animal does.",
                    "label": 0
                },
                {
                    "sent": "Things won't change, it will get the food at the same time no matter what it did in the omission schedule that I showed you, the one where if the pigeon pecks, he doesn't get food.",
                    "label": 0
                },
                {
                    "sent": "That's not a pavlovi and conditioning situation anymore, that's instrumental conditioning.",
                    "label": 0
                },
                {
                    "sent": "That's where the actions actually determine rewards, so we'll talk about this and it might answer your question a little bit.",
                    "label": 0
                },
                {
                    "sent": "Probably not directly.",
                    "label": 0
                },
                {
                    "sent": "We can talk about that more.",
                    "label": 0
                },
                {
                    "sent": "I'm just not not thinking right now.",
                    "label": 0
                },
                {
                    "sent": "Nothing comes to mind a specific experiment that would tell the two apart, but.",
                    "label": 0
                },
                {
                    "sent": "After think about a little bit more.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_95": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the background to instrumental conditioning everybody knows povoa pavlof.",
                    "label": 0
                },
                {
                    "sent": "I don't know if you've heard of Edward Thorndike.",
                    "label": 1
                },
                {
                    "sent": "He's a little bit less famous, but also famous psychologists.",
                    "label": 0
                },
                {
                    "sent": "He was he did research in the days when, right after Darwin's theory of evolution, there were all kinds of attempts to show that animals are indeed intelligent, because the idea was that, you know, we evolved from animals were intelligent.",
                    "label": 0
                },
                {
                    "sent": "Are animals really intelligent?",
                    "label": 0
                },
                {
                    "sent": "And people had all these anecdotes about their pets seemingly understanding language etc.",
                    "label": 0
                },
                {
                    "sent": "And I could tell you that's true about my cat, but Thorndike was the first to show.",
                    "label": 0
                }
            ]
        },
        "clip_96": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is a non anecdotal way and his thesis at the age of 23.",
                    "label": 0
                },
                {
                    "sent": "Which was called Animal Intelligence, an experimental study of the associative processes in animals and what Thorndike studies is these?",
                    "label": 0
                }
            ]
        },
        "clip_97": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Puzzle boxes actually, if you see there are like original pictures of the puzzle boxes that he made, I think he was.",
                    "label": 0
                },
                {
                    "sent": "He was actually a Carpenter and not a scientist so much, but, well, a good scientist and a good Carpenter.",
                    "label": 0
                },
                {
                    "sent": "He would make these intricate puzzle boxes where you can put a cat inside a hungry cat inside the box and the cat had to learn an arbitrary set of actions that would get him out of the box and the boxes were more and more complex.",
                    "label": 0
                },
                {
                    "sent": "The first box that he made a lever had to be pressed, but then others.",
                    "label": 0
                },
                {
                    "sent": "He had.",
                    "label": 0
                },
                {
                    "sent": "The cat had to pull a chain and press the lever and do something else and they became very complex and what he measured as a measure of learning is just how long?",
                    "label": 0
                }
            ]
        },
        "clip_98": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To take the cat to escape, and that's what you're seeing in the graph here over different time trials, how many seconds it took the cat.",
                    "label": 0
                },
                {
                    "sent": "Just get the food was outside the box I should say, and the cat was hungry.",
                    "label": 0
                },
                {
                    "sent": "So how long it took him to get out and go get the food?",
                    "label": 0
                },
                {
                    "sent": "And you can see that it decreases overtime, it's not.",
                    "label": 0
                },
                {
                    "sent": "Monotonic decrease and what?",
                    "label": 0
                }
            ]
        },
        "clip_99": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Thorndike saw over many animals in many boxes.",
                    "label": 0
                },
                {
                    "sent": "Is that there are these gradual learning curves, but they don't look like all or none insight at some point.",
                    "label": 0
                },
                {
                    "sent": "Suddenly the cat does it perfectly every time it looked more like trial and error.",
                    "label": 0
                },
                {
                    "sent": "So he turned this the law of effect that cat does all kinds of random things and the ones that are most effective in getting the cat to state that is satisfactory that using his words.",
                    "label": 1
                },
                {
                    "sent": "He called this set once it.",
                    "label": 1
                },
                {
                    "sent": "Bring satisfaction to the animals are actions that are repeated more in the future.",
                    "label": 0
                }
            ]
        },
        "clip_100": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And a very good example of this kind of instrumental or operant conditioning.",
                    "label": 0
                },
                {
                    "sent": "Is rats lever pressing in boxes, which is what Skinner who is actually more famous of.",
                    "label": 0
                },
                {
                    "sent": "Thorndyke came about 50 years later studied.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "A lot study to death basically and I wanted.",
                    "label": 0
                }
            ]
        },
        "clip_101": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Show you a movie here as well.",
                    "label": 0
                },
                {
                    "sent": "Just so again, you get a feel of what we're talking about.",
                    "label": 0
                },
                {
                    "sent": "What movie was that?",
                    "label": 0
                },
                {
                    "sent": "That's a question I don't remember its name.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Not this one.",
                    "label": 0
                },
                {
                    "sent": "This one.",
                    "label": 0
                },
                {
                    "sent": "Skinner box.",
                    "label": 0
                },
                {
                    "sent": "So here is a rat liver pressing for food.",
                    "label": 0
                },
                {
                    "sent": "If he presses successfully, this light will turn on, so he's looking to see if he succeeded, and then when this light is on, he gets food.",
                    "label": 0
                },
                {
                    "sent": "And you see, you know he knows what he's doing now.",
                    "label": 0
                },
                {
                    "sent": "Delta sit level pricing is quite an arbitrary action for rats.",
                    "label": 0
                },
                {
                    "sent": "Rats do not press levers in the world in the real world.",
                    "label": 0
                },
                {
                    "sent": "They certainly if they want food, they usually go to the place of the food.",
                    "label": 0
                },
                {
                    "sent": "There is were used to going to turn the light on there for it to turn on the ceiling, but rats are not used to going to press one thing in order to get food somewhere else.",
                    "label": 0
                },
                {
                    "sent": "This is completely crazy for a rat to learn and still they managed to learn it.",
                    "label": 0
                },
                {
                    "sent": "OK, he's just going to continue for a long time.",
                    "label": 0
                }
            ]
        },
        "clip_102": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how is this related to reinforcement learning?",
                    "label": 0
                },
                {
                    "sent": "So the idea is that if animals can learn something arbitrary like this, it can probably learn any arbitrary policy.",
                    "label": 0
                },
                {
                    "sent": "To some degree.",
                    "label": 0
                },
                {
                    "sent": "It might take some longer and longer to learn a policy that's really, really complex, but so does so.",
                    "label": 0
                },
                {
                    "sent": "So is the case for our simulations and robots.",
                    "label": 0
                },
                {
                    "sent": "But this policy is specifically learned in order to obtain rewards and avoid punishments in some causal way, because here if the rat doesn't press the lever, he won't get food at all, and so this is kind of the second part of reinforcement learning.",
                    "label": 0
                },
                {
                    "sent": "So we have prediction, learning, learning values, and now we have policy learning learning of actions.",
                    "label": 0
                }
            ]
        },
        "clip_103": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So so far what we have is the world presenting animals or humans.",
                    "label": 0
                },
                {
                    "sent": "Everything I said now is true also for humans with a huge reinforcement learning problem.",
                    "label": 0
                },
                {
                    "sent": "Or maybe it's better to look at it is many small reinforcement learning problems and we know that animals and humans can learn both prediction and control which are the two important ingredients to solve these problems.",
                    "label": 0
                },
                {
                    "sent": "Now the question is, now that we know that the brain does reinforcement learning, can reinforcement learning help us understand how the brain solves this problem?",
                    "label": 0
                },
                {
                    "sent": "How it realizes these algorithms?",
                    "label": 0
                },
                {
                    "sent": "And this brings us to the biggest success story of computational neuroscience in the last 20 years, which is the relationship between.",
                    "label": 0
                }
            ]
        },
        "clip_104": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Dopamine and prediction errors.",
                    "label": 0
                }
            ]
        },
        "clip_105": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So you might have heard about dopamine.",
                    "label": 0
                },
                {
                    "sent": "How many people have heard about dopamine?",
                    "label": 0
                },
                {
                    "sent": "Most of you.",
                    "label": 0
                },
                {
                    "sent": "So dopamine is a neuromodulator that is created in the brain from 2 nuclei, kind of in the middle of an area called the midbrain called eventual mental area in the substantia nigra, and it's and it's sent all over the place so the whole brain mostly you see these arrows here because these are its main target, so the stratum and the prefrontal cortex and actually the amygdala as well, are the main target.",
                    "label": 0
                },
                {
                    "sent": "Of dopaminergic projections, but dopamine basically goes everywhere, even in the visual cortex, there is some dopamine, and the reason that people are really, really interested in dopamine.",
                    "label": 0
                }
            ]
        },
        "clip_106": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well, you've all heard about dopamine, probably because of its relationship to Parkinson's disease.",
                    "label": 0
                },
                {
                    "sent": "So Parkinson's disease is caused by the death of dopaminergic neurons.",
                    "label": 1
                },
                {
                    "sent": "There is less and less dopamine in the brain.",
                    "label": 0
                },
                {
                    "sent": "At some point, people develop Parkinson's disease from losing these neurons.",
                    "label": 0
                },
                {
                    "sent": "And so this.",
                    "label": 0
                }
            ]
        },
        "clip_107": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The original theories about what dopamine doesn't.",
                    "label": 0
                },
                {
                    "sent": "The brain were very related to this, and people thought well in Parkinson's disease what gets damaged.",
                    "label": 0
                },
                {
                    "sent": "What we see is that people stop behaving Motoric Lee as they normally did.",
                    "label": 0
                },
                {
                    "sent": "They have a problem initiating actions, so maybe that is the role of dopamine in the brain and helping us initiate actions and control movement.",
                    "label": 0
                }
            ]
        },
        "clip_108": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But later it turned on that dopamine is also related to a host of other things, to drug addiction.",
                    "label": 1
                },
                {
                    "sent": "So virtually all addictive drugs have some influence through dopamine, if not directly on dopamine.",
                    "label": 0
                },
                {
                    "sent": "So cocaine amphetamine speed directly affects dopamine.",
                    "label": 0
                },
                {
                    "sent": "Some affect dopamine less directly.",
                    "label": 0
                },
                {
                    "sent": "Alcohol is maybe the only one that doesn't go.",
                    "label": 0
                },
                {
                    "sent": "Through dopamine, but I think.",
                    "label": 0
                },
                {
                    "sent": "I take that back.",
                    "label": 0
                },
                {
                    "sent": "Some of the influence of alcohol is also through dopamine.",
                    "label": 1
                },
                {
                    "sent": "Gambling addictions also related to dopamine.",
                    "label": 0
                },
                {
                    "sent": "Natural rewards in general, learning with natural rewards turns out to.",
                    "label": 1
                }
            ]
        },
        "clip_109": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Related to dopamine, so this cause people to think that.",
                    "label": 0
                }
            ]
        },
        "clip_110": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "They'll put me in.",
                    "label": 0
                },
                {
                    "sent": "This may be involved in reward or in learning, which is very different from motor control.",
                    "label": 1
                },
                {
                    "sent": "So now we already have three different functions for dopamine.",
                    "label": 0
                },
                {
                    "sent": "And if that's not enough, it turns out.",
                    "label": 0
                }
            ]
        },
        "clip_111": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Dopamine is also involved in working memory and dealing with novel situations, in attention, deficit, hyperactive disorder, and schizophrenia in depression.",
                    "label": 1
                },
                {
                    "sent": "Anything you want, basically anything that people care about in the brain.",
                    "label": 0
                },
                {
                    "sent": "Dopamine is part of it.",
                    "label": 0
                },
                {
                    "sent": "And this way it sounds crazy, but actually the brain only has four different neuromodulators.",
                    "label": 0
                },
                {
                    "sent": "Their neurotransmitters, which are ways which are molecules by which one neuron communicates with another neuron.",
                    "label": 0
                },
                {
                    "sent": "But the forward neuromodulators are molecules that are sent all over the place, and you might think if there are only four of these in the brain, they must have really, really important widespread functions and affect a lot of processing in the brain.",
                    "label": 0
                },
                {
                    "sent": "So it's maybe not so surprising that dopamine is related to all these things.",
                    "label": 0
                },
                {
                    "sent": "But still it makes neuro scientists really want to understand how it does what it does and how we can cure the situations where it does the wrong thing.",
                    "label": 0
                },
                {
                    "sent": "So as there are many functions, there are many hypothesis.",
                    "label": 0
                }
            ]
        },
        "clip_112": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or I should say, as there are many scientists, there are many hypothesis.",
                    "label": 0
                },
                {
                    "sent": "And we won't go through all of them for lack of time.",
                    "label": 0
                },
                {
                    "sent": "I'll only talk about the first 2 by just to put these on the board and so you know that although I'm going to tell you that I think this one is true, it doesn't mean that it.",
                    "label": 0
                },
                {
                    "sent": "But there are others to consider.",
                    "label": 0
                }
            ]
        },
        "clip_113": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So originally in the 80s, the first hypothesis about dopamine, well, not the first, but the very influential hypothesis was called the anhedonia hypothesis.",
                    "label": 0
                }
            ]
        },
        "clip_114": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And, um.",
                    "label": 0
                },
                {
                    "sent": "Anhedonia is the inability to experience positive emotional states, so usually if you eat something nice or you have some positive experience with another person or whatever, you feel good about it.",
                    "label": 0
                },
                {
                    "sent": "Anhedonia is a state where you don't feel good about things that used to make you feel good.",
                    "label": 0
                }
            ]
        },
        "clip_115": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And what why is saw is that neuroleptics which are drugs that are antagonist dopamine, so they stop the function of dopamine in the brain.",
                    "label": 0
                },
                {
                    "sent": "These drugs cause anhedonia, so they cause people to not enjoy things that they used to.",
                    "label": 0
                }
            ]
        },
        "clip_116": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Joy in life.",
                    "label": 0
                },
                {
                    "sent": "And so that basically.",
                    "label": 0
                }
            ]
        },
        "clip_117": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That was.",
                    "label": 0
                },
                {
                    "sent": "His the reason is to suggest that dopamine.",
                    "label": 0
                },
                {
                    "sent": "Maybe it has something to do with hedonic sore with enjoying pleasure in the world and.",
                    "label": 0
                },
                {
                    "sent": "Perhaps the last movie know there will be another movie later.",
                    "label": 0
                }
            ]
        },
        "clip_118": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is a movie from Peter.",
                    "label": 0
                },
                {
                    "sent": "She's gallon Concordia here in Montreal, and what you're seeing here is a rat that is lever pressing but not for food.",
                    "label": 0
                },
                {
                    "sent": "As you see there is no food magazine here.",
                    "label": 0
                },
                {
                    "sent": "Whenever he presses the lever, he gets a ZAP of.",
                    "label": 0
                },
                {
                    "sent": "Electrical current straight to the dopaminergic area of his brain and he loves it.",
                    "label": 0
                },
                {
                    "sent": "He really, really wants to get this.",
                    "label": 0
                },
                {
                    "sent": "You can see how he doesn't want the lever to go away.",
                    "label": 0
                },
                {
                    "sent": "He's really like trying to coax it out because every time he gets this snap into his reign it just makes him feel really good.",
                    "label": 0
                },
                {
                    "sent": "So this is called.",
                    "label": 0
                },
                {
                    "sent": "Brain self stimulation reward and it was studied extensively.",
                    "label": 0
                },
                {
                    "sent": "At the time when people realize that dopamine has something to do with reward and till today.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "In general, the idea was.",
                    "label": 0
                }
            ]
        },
        "clip_119": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, there are rewards in the real world.",
                    "label": 0
                },
                {
                    "sent": "You know, coffee, cake, money, etc.",
                    "label": 0
                },
                {
                    "sent": "How does the brain know that I got a reward?",
                    "label": 0
                },
                {
                    "sent": "Well, it might know that I got a reward.",
                    "label": 0
                }
            ]
        },
        "clip_120": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Through this molecule, through this through dopamine, dopamine squirted all over the place, telling the brain a good thing now happened and that was why this anhedonia hypothesis and this explains.",
                    "label": 0
                }
            ]
        },
        "clip_121": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "First of all, it explained.",
                    "label": 0
                },
                {
                    "sent": "Uh, electrophysiological recordings that people had known of at the time, So what you see here is.",
                    "label": 0
                },
                {
                    "sent": "These are recordings from the dopaminergic neurons of a monkey.",
                    "label": 0
                },
                {
                    "sent": "Every dot here is when the neuron fired and every row is 1 trial on every trial.",
                    "label": 0
                },
                {
                    "sent": "Sometime past then the monkey God's got some juice into his mouth.",
                    "label": 0
                },
                {
                    "sent": "This is a thirsty monkey, so this is the time when he got the juice and then some more time passed.",
                    "label": 0
                },
                {
                    "sent": "And what you see is this is a sum of all these dots here of all this raster plot and what you see is these dopaminergic neurons fire right after a reward and then after a while it go back to baseline.",
                    "label": 0
                },
                {
                    "sent": "So the idea is they signal to the brain that our reward happened, that juice was obtained and this of course explains why the rat would want zaps.",
                    "label": 0
                }
            ]
        },
        "clip_122": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This brain to the dopaminergic area, because that's exactly like getting real rewards in the world.",
                    "label": 0
                },
                {
                    "sent": "And it explains why if you block dopamine.",
                    "label": 0
                }
            ]
        },
        "clip_123": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Animals stop learning, so if you give neuroleptics and you try to do conditioning studies, they don't learn to lever press and they don't have to lever press for food.",
                    "label": 0
                },
                {
                    "sent": "They don't work for normal rewards in the same way.",
                    "label": 0
                }
            ]
        },
        "clip_124": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But this story would have been simple and nice and we would have not needed reinforcement learning and the whole thing would have ended, except that in the 90s Schultz Wolfram.",
                    "label": 0
                }
            ]
        },
        "clip_125": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Delta also.",
                    "label": 0
                },
                {
                    "sent": "Did these recordings started make?",
                    "label": 0
                }
            ]
        },
        "clip_126": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "His experiments a little bit more complex by adding the stimulus before the reward and what he saw is that.",
                    "label": 0
                }
            ]
        },
        "clip_127": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "When a stimulus is shown here in, the reward is obtained 2 seconds later.",
                    "label": 0
                },
                {
                    "sent": "This is again recordings in monkeys.",
                    "label": 0
                },
                {
                    "sent": "The monkeys are getting juice rewards after seeing a visual stimulus, honest screen.",
                    "label": 0
                },
                {
                    "sent": "Suddenly there is no response at all to the reward, as if the reward didn't happen.",
                    "label": 0
                },
                {
                    "sent": "But there is a response to the stimulus instead.",
                    "label": 0
                },
                {
                    "sent": "And if you take that same monkey.",
                    "label": 0
                }
            ]
        },
        "clip_128": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And occasionally not trial after trial, but occasionally show it the stimulus and not give the reward.",
                    "label": 0
                },
                {
                    "sent": "Then you see that at the time were no reward was expected, but nothing happened.",
                    "label": 0
                },
                {
                    "sent": "Actually, in these trouser was just a stimulus and then nothing happened.",
                    "label": 0
                },
                {
                    "sent": "When the reward is expected, there is a dip in the firing, so the the neurons stop firing.",
                    "label": 0
                },
                {
                    "sent": "So this is really puzzling.",
                    "label": 0
                },
                {
                    "sent": "This doesn't look anymore like a signal.",
                    "label": 0
                },
                {
                    "sent": "A straight off signal for reward, because here reward is obtained with no signal.",
                    "label": 0
                }
            ]
        },
        "clip_129": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_130": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_131": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is what we have.",
                    "label": 0
                },
                {
                    "sent": "This is what Schultz had.",
                    "label": 0
                }
            ]
        },
        "clip_132": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Does it look familiar?",
                    "label": 0
                },
                {
                    "sent": "If.",
                    "label": 0
                }
            ]
        },
        "clip_133": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It doesn't.",
                    "label": 0
                },
                {
                    "sent": "I'll give you a hint.",
                    "label": 0
                },
                {
                    "sent": "Does it look familiar?",
                    "label": 0
                },
                {
                    "sent": "So the idea was.",
                    "label": 0
                }
            ]
        },
        "clip_134": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That perhaps what dopamine does its signals not reward, but a prediction error.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_135": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the reason?",
                    "label": 0
                },
                {
                    "sent": "Huawei.",
                    "label": 0
                },
                {
                    "sent": "Before the relationship between a stimulus center award is learned, there is responding to the reward and after their relationship is established in response to reward goes away is in the beginning of training.",
                    "label": 0
                },
                {
                    "sent": "The reward induces a prediction error and after it's already well predicted by the stimulus that comes before there is no prediction error at the time for reward, there's actually a prediction error at the time the stimulus because the stimulus was unexpected and arrived on its own, and these are three different experiments.",
                    "label": 0
                },
                {
                    "sent": "From shelters, labs showing the same kind of disappearance of the prediction error of the dopaminergic signal after a reward through training.",
                    "label": 1
                }
            ]
        },
        "clip_136": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is another experiment from the same lab where there were five different stimuli in each trial.",
                    "label": 0
                },
                {
                    "sent": "The monkey could see one of these five stimuli in that signal to him.",
                    "label": 0
                },
                {
                    "sent": "How much reward he was going to get if it was this stimulus he was going to get 0 milliliters fit with.",
                    "label": 0
                },
                {
                    "sent": "This one is going to be oh point, oh, 75 and oh point, 25 milliliters, etc.",
                    "label": 0
                },
                {
                    "sent": "And as I said, the reward is now predicted, but the stimulus itself, the identity of the stimulus is not predicted and so that generates should generate.",
                    "label": 0
                },
                {
                    "sent": "A prediction error, an indeed you see dopaminergic response responses to the stimuli with a size that grows with the predicted reward.",
                    "label": 1
                },
                {
                    "sent": "So that's what we would expect from prediction error signal.",
                    "label": 1
                },
                {
                    "sent": "And we can do the same thing.",
                    "label": 0
                }
            ]
        },
        "clip_137": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Not with the amount of reward, but probability of reward again from the same lab.",
                    "label": 0
                },
                {
                    "sent": "Five different stimuli giving the same amount of reward but with different probabilities and what you see is there is a higher response for higher probability and also at the time of rewards the opposite.",
                    "label": 0
                },
                {
                    "sent": "Now if the reward was 100% predicted, there is no response to the reward, but if it was only 50% predicted, then there is a 50% prediction error unrewarded trials.",
                    "label": 0
                },
                {
                    "sent": "These are only rewarded trials.",
                    "label": 0
                },
                {
                    "sent": "And so forth.",
                    "label": 0
                },
                {
                    "sent": "So it seems like everything fits this idea that what dopamine actually does is signal prediction errors.",
                    "label": 0
                }
            ]
        },
        "clip_138": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Other than just rewards.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Suppose you have stimulus which predicts stimulus, which predicts a reward.",
                    "label": 0
                },
                {
                    "sent": "So will you get a dopamine response in the sectors?",
                    "label": 0
                },
                {
                    "sent": "According to this theory, know if all the timing between everything is fixed then you shouldn't.",
                    "label": 0
                },
                {
                    "sent": "It should go back to the very first predictor.",
                    "label": 0
                },
                {
                    "sent": "There is one experiment in rats by.",
                    "label": 0
                },
                {
                    "sent": "Brian Hyland that shows that it doesn't completely go all the way back, but that experiment.",
                    "label": 0
                },
                {
                    "sent": "It's very, very hard to record dopaminergic neurons in rats.",
                    "label": 0
                },
                {
                    "sent": "He was the first one to record them and he had very, very few neurons.",
                    "label": 0
                },
                {
                    "sent": "So I'm not sure we can rest assured with those data.",
                    "label": 0
                },
                {
                    "sent": "I don't think Wolfram Schultz Wolfram Schultz is kind of the expert of recording dopamine neurons and monkeys, and I don't think he's ever done stimulus stimulus reward.",
                    "label": 0
                },
                {
                    "sent": "You might also ask what about stimulus reward reward?",
                    "label": 0
                },
                {
                    "sent": "You would want the stimulus to have you know twice as much prediction error, nothing to the rewards, so there are still things to be done.",
                    "label": 0
                },
                {
                    "sent": "But people have put this theory to.",
                    "label": 0
                }
            ]
        },
        "clip_139": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Stringent tests, not only the ones that we saw here with different probabilities in different magnitudes, but also.",
                    "label": 0
                },
                {
                    "sent": "What Hannah Buyer and Paul Glimcher did is they said well.",
                    "label": 0
                },
                {
                    "sent": "We know that if we have regular temporal difference, learning the value at each point in time should be basically a an exponentially weighted sum of all the previous rewards.",
                    "label": 0
                },
                {
                    "sent": "So you can work that out out of TD learning and then we won't work it out right now, but you can check it later that the last reward should have the highest influence on the current value and then the one before that.",
                    "label": 0
                },
                {
                    "sent": "Less influence in less according to the learning rate, so they're exponentially discounted because of the learning rate.",
                    "label": 0
                },
                {
                    "sent": "And so the question is, could we see that in dopamine neurons?",
                    "label": 0
                }
            ]
        },
        "clip_140": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And what they did is they gave monkeys different amounts of reward in each trial and recorded the prediction error.",
                    "label": 0
                },
                {
                    "sent": "The dopamine signal at each trial.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Fit a model.",
                    "label": 0
                },
                {
                    "sent": "Well, let me be very clear here now we're looking at a prediction error.",
                    "label": 0
                },
                {
                    "sent": "Prediction error should be reward minus value, right?",
                    "label": 0
                },
                {
                    "sent": "So the last reward should have awaiting of 1.",
                    "label": 0
                },
                {
                    "sent": "Minus the value.",
                    "label": 0
                },
                {
                    "sent": "So minus this kind of exponent.",
                    "label": 0
                },
                {
                    "sent": "And so they took the prediction error.",
                    "label": 1
                },
                {
                    "sent": "Regressed it on all the previous of the last 10.",
                    "label": 0
                },
                {
                    "sent": "The magnitudes of the last 10 rewards an indeed found.",
                    "label": 0
                },
                {
                    "sent": "These points, the black point which fit amazingly well to the red line, which is a prediction of the model with a constant learning rate.",
                    "label": 0
                },
                {
                    "sent": "And in the same study they they could also.",
                    "label": 0
                },
                {
                    "sent": "Do a kind of slightly different analysis, where on every trial that model predicted what the prediction error should be after fitting the learning rate to the specific monkey and the measured firing rate is on this access that you see that it's basically a straight line as you could want from noisy biological measurements up to a prediction error of minus oh point 1.",
                    "label": 0
                },
                {
                    "sent": "Then it kind of.",
                    "label": 0
                },
                {
                    "sent": "Flattens out and that's that's an issue that we're still that people are still grappling with.",
                    "label": 0
                },
                {
                    "sent": "The thing is.",
                    "label": 0
                }
            ]
        },
        "clip_141": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Prediction errors if dopamine firing is a prediction error.",
                    "label": 1
                },
                {
                    "sent": "There can't be negative firing.",
                    "label": 0
                },
                {
                    "sent": "It can only stop firing completely, right?",
                    "label": 0
                },
                {
                    "sent": "So at some point this has to level out and something else maybe has to.",
                    "label": 0
                },
                {
                    "sent": "Help in representing negative prediction errors that are hypothesis.",
                    "label": 0
                },
                {
                    "sent": "Another endura body later does this or that.",
                    "label": 0
                },
                {
                    "sent": "The length of the gap in firing.",
                    "label": 0
                },
                {
                    "sent": "That's a hypothesis from Hannah Buyer that the length of the gap represents how big this prediction error.",
                    "label": 0
                },
                {
                    "sent": "The negative prediction areas, but at least for positive prediction errors there's a nice linear relationship between what the model says the prediction error should be and how much the neuron fires.",
                    "label": 0
                }
            ]
        },
        "clip_142": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the idea is the dopamine represents a prediction error and we know that prediction errors have a role in reinforcement learning.",
                    "label": 0
                },
                {
                    "sent": "Prediction errors are for learning, right?",
                    "label": 0
                },
                {
                    "sent": "So first of all, as we said, dopamine projects mainly to the basal ganglia.",
                    "label": 0
                },
                {
                    "sent": "The basal ganglia are these complex structures on both sides, kind of inside there, not in the cortex there inside your brain.",
                    "label": 0
                },
                {
                    "sent": "If you go kind of from here towards the middle.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_143": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And what we know about.",
                    "label": 0
                }
            ]
        },
        "clip_144": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Dopamine does there is.",
                    "label": 0
                }
            ]
        },
        "clip_145": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That cortical straddle synapses show dopamine dependent plasticity, so this is quite a mouthful, but I'll.",
                    "label": 0
                },
                {
                    "sent": "Unwrap, unpack.",
                    "label": 0
                }
            ]
        },
        "clip_146": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That so this is a neuron in the stratum.",
                    "label": 0
                },
                {
                    "sent": "And it gets inputs from 2 director from 2 areas.",
                    "label": 0
                },
                {
                    "sent": "One is from the cortex from from the outside.",
                    "label": 0
                },
                {
                    "sent": "The frontal area of the cortex mostly.",
                    "label": 0
                },
                {
                    "sent": "So this is this input coming to this synapse.",
                    "label": 0
                },
                {
                    "sent": "And on the other hand it gets dopamine afferents.",
                    "label": 0
                },
                {
                    "sent": "That kind of hug the synapses.",
                    "label": 0
                },
                {
                    "sent": "This is called the neck of the spine, and this is the head of the spine.",
                    "label": 0
                },
                {
                    "sent": "They hug the next of the spines of each and every synapse.",
                    "label": 0
                }
            ]
        },
        "clip_147": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It turns out.",
                    "label": 0
                },
                {
                    "sent": "But if you.",
                    "label": 0
                },
                {
                    "sent": "Invoke.",
                    "label": 0
                },
                {
                    "sent": "If you excite the neurons here, so you invoke activity in these neurons and in a way that causes this neuron to fire and measure how that affects the strength of the synapse.",
                    "label": 0
                },
                {
                    "sent": "Usually LTP, long-term potentiation and Hebbian learning prescribes that fire together wire together.",
                    "label": 0
                },
                {
                    "sent": "If this fires, and then this fires, their connection strengthens, but it turns out that in these cortex to striatal synapses only if there is still coming around that happen.",
                    "label": 0
                },
                {
                    "sent": "So here you see.",
                    "label": 0
                },
                {
                    "sent": "At these measurements, dopamine was around and so the height of the activation of this neuron became higher after pairing their activity, their activity.",
                    "label": 0
                },
                {
                    "sent": "In the bottom here there was no dopamine around, and it actually even became lower.",
                    "label": 0
                },
                {
                    "sent": "So the idea is that it's not regular Hebbian learning here, but a three phase.",
                    "label": 0
                }
            ]
        },
        "clip_148": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "After learning rule, you need to have both the presynaptic neuron and the postsynaptic neuron and dopamine around for learning, which is exactly what we wanted.",
                    "label": 0
                },
                {
                    "sent": "We wanted learning contingent on prediction errors.",
                    "label": 1
                },
                {
                    "sent": "If there is a prediction error, you should learn and if there is no prediction error, you don't need to learn.",
                    "label": 0
                }
            ]
        },
        "clip_149": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_150": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so so far.",
                    "label": 0
                },
                {
                    "sent": "What we have is that conditioning can be viewed as prediction learning.",
                    "label": 0
                }
            ]
        },
        "clip_151": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we already have.",
                    "label": 0
                }
            ]
        },
        "clip_152": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "An algorithm for how to do that given by reinforcement learning, which is temporal difference.",
                    "label": 0
                }
            ]
        },
        "clip_153": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Turning.",
                    "label": 0
                },
                {
                    "sent": "And now we have a neural implementation of that.",
                    "label": 0
                },
                {
                    "sent": "We have temporal difference errors in dopamine that affect learning in cortical striatal synapses in the basal ganglia.",
                    "label": 0
                }
            ]
        },
        "clip_154": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is very very very exciting for neuroscience because we want to understand what dopamine does and not only do we have an answer here, but we have a normative theory for why dopamine firing is the way it is.",
                    "label": 0
                },
                {
                    "sent": "It's not only telling us that it's a prediction.",
                    "label": 0
                },
                {
                    "sent": "Error tells us why would we want this to be?",
                    "label": 0
                },
                {
                    "sent": "This way we want prediction errors for optimal learning of values that predict future rewards, so it's much more than just describing the function here.",
                    "label": 0
                }
            ]
        },
        "clip_155": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is.",
                    "label": 0
                },
                {
                    "sent": "Also, an example of how once we have a computational model of learning that allows us to look in the brain for hidden variables that the model postulates, so a prediction error is basically a hidden variable.",
                    "label": 0
                },
                {
                    "sent": "You can't see it in people's behavior or in the inputs from the world.",
                    "label": 0
                },
                {
                    "sent": "It's something that the model.",
                    "label": 0
                },
                {
                    "sent": "Suggested an here.",
                    "label": 0
                },
                {
                    "sent": "We found it in the brain and will see other examples today of how these computational models can help us look for hidden variables and find them in the brain.",
                    "label": 0
                },
                {
                    "sent": "Which one tells us what the brain does and two tells us that the model well doesn't tell us that the model is correct, but it's more support for the model.",
                    "label": 0
                }
            ]
        },
        "clip_156": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Plus you have long hair here.",
                    "label": 0
                },
                {
                    "sent": "Like a lot of models, I suppose, but it depends heavily on Auckland Razor.",
                    "label": 0
                },
                {
                    "sent": "It's simply it's.",
                    "label": 0
                },
                {
                    "sent": "Close to the sequels.",
                    "label": 0
                },
                {
                    "sent": "Model possible, but only one of a class of models could imagine would have the same.",
                    "label": 0
                },
                {
                    "sent": "Right, right?",
                    "label": 0
                },
                {
                    "sent": "How much?",
                    "label": 0
                },
                {
                    "sent": "The restaurant is sexy believe.",
                    "label": 0
                },
                {
                    "sent": "This is the model.",
                    "label": 0
                },
                {
                    "sent": "Up how well so there are two questions combined here.",
                    "label": 0
                },
                {
                    "sent": "Why the question was?",
                    "label": 0
                },
                {
                    "sent": "This is a simple model.",
                    "label": 0
                },
                {
                    "sent": "Is this really as simple as what is dopamine does this very simple model?",
                    "label": 0
                },
                {
                    "sent": "Or is this sub case of a more complex model that we haven't worked out yet and it might be?",
                    "label": 0
                },
                {
                    "sent": "These experiments are very simple experiments, right?",
                    "label": 0
                },
                {
                    "sent": "This is simple learning stimulus and then reward.",
                    "label": 0
                },
                {
                    "sent": "You can think of much more complex learning scenarios, and dopamine hasn't been recorded in many more complex scenarios, so we don't know yet where it doesn't fit the theory.",
                    "label": 0
                },
                {
                    "sent": "I'll come straight.",
                    "label": 0
                },
                {
                    "sent": "There is a good thing to work by and something that's as prevalent and goes all over.",
                    "label": 0
                },
                {
                    "sent": "The Braden intervenes in so many functions as dopamine, you would want it to be some simple story of what it does it not some very complex, intricate things that in this situation it does a in that situation.",
                    "label": 0
                },
                {
                    "sent": "It does be because then how would the brain know how to interpret that?",
                    "label": 0
                },
                {
                    "sent": "But that's not a reason to believe in this theory you have to do more experiments, basically free.",
                    "label": 0
                },
                {
                    "sent": "The other three, or something like that?",
                    "label": 0
                },
                {
                    "sent": "What if the other three, what?",
                    "label": 0
                },
                {
                    "sent": "At least I don't mean like right, right?",
                    "label": 0
                },
                {
                    "sent": "There are interactions between aura modulators, but not so strongly in this trade.",
                    "label": 0
                },
                {
                    "sent": "Him at least as freedom is mostly innervate idby dopamine and not the others, so that Luckily we have kind of an isolated case there.",
                    "label": 0
                },
                {
                    "sent": "That's why it's been studied mostly in the stratum and not in other areas.",
                    "label": 0
                },
                {
                    "sent": "Whether neuro scientists actually believe that this is the function of dopamine.",
                    "label": 1
                },
                {
                    "sent": "Depends on who you ask.",
                    "label": 0
                },
                {
                    "sent": "'cause people like to have alternative theories and you know it's really boring.",
                    "label": 0
                },
                {
                    "sent": "You can't publish 7 papers saying that theory is right.",
                    "label": 0
                },
                {
                    "sent": "It's much easier or much more exciting to publish a paper saying that theory is wrong.",
                    "label": 0
                },
                {
                    "sent": "I have a different theory, so people have different theories.",
                    "label": 0
                },
                {
                    "sent": "I feel that it's been become more and more mainstream and people now kind of regularly talk about dopamine is a prediction error, whereas 10 years ago we were still trying to convince people to listen.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "But not everybody believes it, and it's not necessarily true.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "So don't mean is partly sorry system.",
                    "label": 0
                },
                {
                    "sent": "Part of the.",
                    "label": 0
                },
                {
                    "sent": "Oh, there's.",
                    "label": 0
                },
                {
                    "sent": "Is that correct?",
                    "label": 0
                },
                {
                    "sent": "Not the same not the same though for me it doesn't cross the blood brain barrier, so dopamine that we have in the rest of our body does not go into the brain.",
                    "label": 0
                },
                {
                    "sent": "That's why in Parkinson's disease you can't give people dopamine medication.",
                    "label": 0
                },
                {
                    "sent": "You have to give them L DOPA, which is a precursor of dopamine that does cross the blood brain barrier.",
                    "label": 0
                },
                {
                    "sent": "Rapidly doesn't distribute itself in the brain.",
                    "label": 1
                },
                {
                    "sent": "What do you mean distribute itself?",
                    "label": 0
                },
                {
                    "sent": "It's generated.",
                    "label": 0
                },
                {
                    "sent": "Cody, of the arrow.",
                    "label": 0
                },
                {
                    "sent": "So those responses are very, very quick.",
                    "label": 0
                },
                {
                    "sent": "There are less than 100 milliseconds in the cases that I've shown.",
                    "label": 0
                },
                {
                    "sent": "In some cases when it takes longer for information to filter into, the system has been shown more recently that the response could be slower, but it first actually one of the main criticisms against a prediction or hypothesis was how could it be so quickly and so quick?",
                    "label": 0
                },
                {
                    "sent": "How could the brain know what it's predicting and what is its error in less than 100 milliseconds?",
                    "label": 0
                },
                {
                    "sent": "But it turns out that in these very simple experiments.",
                    "label": 0
                },
                {
                    "sent": "It can be done.",
                    "label": 0
                },
                {
                    "sent": "The visual stimulus appears each time in a different area of the screen and there is a direct pathway through the superior colliculus to dopamine, telling it what stimulus.",
                    "label": 0
                },
                {
                    "sent": "It's also very quickly it can compute the predictions.",
                    "label": 0
                },
                {
                    "sent": "In other experiments it takes a little bit longer, but once you have it seems like once you have the prediction, dopamine tells the rest of the brain what the prediction error is.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "You mentioned that in the rat experiment that if we have a net negative prediction error, then the dopamine just stopped.",
                    "label": 0
                },
                {
                    "sent": "So what I don't understand this how people can steal sort of a Dick to gamble for example because they are keep getting negative rewards.",
                    "label": 0
                },
                {
                    "sent": "So that's that's a great question.",
                    "label": 0
                },
                {
                    "sent": "So the question is how can people get addicted to gambling although they get negative rewards all the time?",
                    "label": 0
                },
                {
                    "sent": "And there are theories of how this kind of prediction error signal can be hijacked by substances of abuse, like drugs and by situations like gambling in order to create abnormal learning.",
                    "label": 0
                },
                {
                    "sent": "The answer is the bottom line answer is we don't know for sure, but for this specific question there is a nice paper by David Reddish where he suggests that what happens is there is a false.",
                    "label": 0
                },
                {
                    "sent": "Division into states.",
                    "label": 0
                },
                {
                    "sent": "So the gambler basically assumes that whenever he gets a negative prediction error, he assigns that to one state of the world and he gets a positive prediction error.",
                    "label": 0
                },
                {
                    "sent": "He assigns it to another state of the world.",
                    "label": 0
                },
                {
                    "sent": "You know, like gamblers will kiss the guy before throwing them, and things like that.",
                    "label": 0
                },
                {
                    "sent": "In his theory, that's a way in which the gambler tries to steer the world to the state where he got the positive prediction errors rather than the state where he gets negative prediction errors.",
                    "label": 0
                },
                {
                    "sent": "But you're right, there is a puzzle here.",
                    "label": 0
                },
                {
                    "sent": "About you know the more complex situations of learning.",
                    "label": 0
                },
                {
                    "sent": "And one of the puzzles is how do we know what state of the world we're in?",
                    "label": 0
                },
                {
                    "sent": "Paragraph that bottoms out and get splat there.",
                    "label": 0
                },
                {
                    "sent": "That the gambler he gets his payoff on the linear side, but then he he's found the flat bottom wow.",
                    "label": 0
                },
                {
                    "sent": "I think we yeah no.",
                    "label": 0
                },
                {
                    "sent": "I think negative feedback is also scaled in the brain.",
                    "label": 0
                },
                {
                    "sent": "The question is how?",
                    "label": 0
                },
                {
                    "sent": "Maybe not through dopamine?",
                    "label": 0
                },
                {
                    "sent": "Maybe through the length of the pause as I said, but that's not very clear.",
                    "label": 0
                },
                {
                    "sent": "And also we have to learn to release or stormy right?",
                    "label": 0
                },
                {
                    "sent": "Because at the beginning.",
                    "label": 0
                },
                {
                    "sent": "First of all, we do know money is a good thing, so we sure.",
                    "label": 0
                },
                {
                    "sent": "You know we have many years of education, so we of course alot of this is learned.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Are there any objective criteria that you need for, like reward stimulus?",
                    "label": 0
                },
                {
                    "sent": "What I mean by that is, like you can imagine having a light and get food.",
                    "label": 0
                },
                {
                    "sent": "So you can imagine instead of food you have a light and then another light.",
                    "label": 0
                },
                {
                    "sent": "So do use would you see the same firing pattern?",
                    "label": 0
                },
                {
                    "sent": "If it's 2 lines?",
                    "label": 0
                },
                {
                    "sent": "Or is there something inherent about the fact that food is good for the animals?",
                    "label": 0
                },
                {
                    "sent": "Yes, that that property needs to exist, whatever that property might be in order for this morning.",
                    "label": 0
                },
                {
                    "sent": "So the answer to this is yes, rewards are special.",
                    "label": 0
                },
                {
                    "sent": "In that they have some motivational rewards and punishments.",
                    "label": 0
                },
                {
                    "sent": "They have some motivational significance, good or bad, motivational significance to the animal.",
                    "label": 0
                },
                {
                    "sent": "This is a very, very fuzzy way of defining them.",
                    "label": 0
                },
                {
                    "sent": "Because psychologists have argued for years and not gotten to a conclusion of what is the definition of a reward, but it somehow very clear some things are rewards and some things are not food.",
                    "label": 0
                },
                {
                    "sent": "As a reward, light is not.",
                    "label": 0
                },
                {
                    "sent": "But if light starts predicting or reward then now light becomes.",
                    "label": 0
                },
                {
                    "sent": "A reward itself and animals will work, will press the lever just to get the light to turn on, and it's exactly like this story with money that we've learned through life, that money is a predictor of reward and we will work very, very hard for money where we actually don't eat money, right?",
                    "label": 0
                },
                {
                    "sent": "So conditioned reinforcers are learned, and then they become like a reinforcer themselves, but apriori think there are some things that are reinforcers without needing to be learned, like food, even that some people say is somewhat learned so very, very young rats.",
                    "label": 0
                },
                {
                    "sent": "When they're born, they don't necessarily know that sweet is good.",
                    "label": 0
                },
                {
                    "sent": "That's actually we used to think that's innate, but it's not.",
                    "label": 0
                },
                {
                    "sent": "That's also learned, but just learned in a very early stage.",
                    "label": 0
                },
                {
                    "sent": "And then all these things become conditioned rewards.",
                    "label": 0
                },
                {
                    "sent": "Even food is not really a reward.",
                    "label": 0
                },
                {
                    "sent": "That's the metabolic, you know, the thing that gets to your blood hours later is the real reward, but we don't have to wait for that.",
                    "label": 0
                },
                {
                    "sent": "Normally we sweetness is already the reward for us.",
                    "label": 0
                },
                {
                    "sent": "I do want to continue on OK so so.",
                    "label": 0
                }
            ]
        },
        "clip_157": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let's continue and you can ask me these questions later.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "There are three model free learning algorithms or three basic classes for model free learning algorithms and reinforcement learning.",
                    "label": 0
                },
                {
                    "sent": "Actor critic learning Q Learning and Sarsa and I'll go through each of them.",
                    "label": 0
                },
                {
                    "sent": "And whether we think they exist in the brain or not.",
                    "label": 1
                }
            ]
        },
        "clip_158": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the first one is actor critic, which which has been associated most with learning in the brain.",
                    "label": 1
                },
                {
                    "sent": "So the idea was actor in actor critic to go over it really quickly is that there are states the states of the environment feed into two modules, the critic in the actor.",
                    "label": 0
                },
                {
                    "sent": "The critic takes these States and Maps them into values which then feed into the temporal difference module which computes prediction errors which train these values so that the values become true.",
                    "label": 0
                },
                {
                    "sent": "Predictions of the sum of their discounted sum of future rewards for each state.",
                    "label": 0
                },
                {
                    "sent": "And this prediction error also feeds into the actor module.",
                    "label": 1
                },
                {
                    "sent": "The actor Maps a policy from states to actions and it uses these prediction errors to improve its policy.",
                    "label": 0
                },
                {
                    "sent": "So positive prediction error means that the situation is better than it was before and so that action should be repeated more in the future and negative prediction error means the action should be not repeated in the future.",
                    "label": 0
                },
                {
                    "sent": "So these policy connection strengths or just strength of different actions in different states can be updated.",
                    "label": 0
                },
                {
                    "sent": "Based on the same prediction error and of course the actions come out of the actor an influence the environment and so forth.",
                    "label": 0
                },
                {
                    "sent": "So it turns out that this.",
                    "label": 0
                }
            ]
        },
        "clip_159": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Picture can be tentatively mapped on two areas of the brain psych.",
                    "label": 0
                },
                {
                    "sent": "I put the names of the different areas that do these things or that we think do these things in each one of these areas.",
                    "label": 0
                },
                {
                    "sent": "So as we said, the prediction areas dopamine from the VTA and SNC, and we think that the two parts of this trade in the ventral stratum in the dorsolateral stratum are the critic and the actor, respectively, and reward comes in through several areas, habenula and the peduncle pontine nucleus.",
                    "label": 0
                },
                {
                    "sent": "It and some other areas with even longer names.",
                    "label": 0
                },
                {
                    "sent": "And we already know that you know actions are through motor cortex, and perception is through all these areas in the back and then through frontal cortex.",
                    "label": 0
                },
                {
                    "sent": "So we can map this whole thing on to the brain.",
                    "label": 0
                },
                {
                    "sent": "And people were very excited about this, especially because there are two nuclei, two dopaminergic nuclei which seemed to project the same kind of signal, but to two different areas.",
                    "label": 0
                },
                {
                    "sent": "So that made people immediately think Ha actor critic right?",
                    "label": 0
                },
                {
                    "sent": "This one signal goes to the critic and one signal goes to the actor.",
                    "label": 0
                },
                {
                    "sent": "It's the same signal but goes to two different places.",
                    "label": 0
                },
                {
                    "sent": "So is there any evidence?",
                    "label": 0
                }
            ]
        },
        "clip_160": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For this in the brain, I should say this is a very very prominent theory of learning in the brain an I think my opinion and this might be wrong.",
                    "label": 1
                },
                {
                    "sent": "I'm glad there are not many neuro scientists here to tell me that I'm wrong, but my opinion is really it was because of this excitement of two nuclei of dopamine that signal the same thing to two different areas, not based on more stringent evidence.",
                    "label": 0
                },
                {
                    "sent": "It just looked really good.",
                    "label": 0
                },
                {
                    "sent": "But there is some evidence, and before I show you some.",
                    "label": 0
                }
            ]
        },
        "clip_161": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It's a little small aside to functional imaging and how that helps us look for this kind of evidence, and I'm doing this where I didn't do it for other methods in neuroscience because this is kind of the new wave of research into reinforcement learning in the brain, so it's good for you to know how it's done.",
                    "label": 1
                },
                {
                    "sent": "So fMRI, functional magnetic resonance imaging.",
                    "label": 0
                },
                {
                    "sent": "It all starts with a big magnet that looks like this and the subject lies on a bed and it's inserted so that their head is in the magnet and they see stimuli that they have like a little mirror and they see the stimuli from the screen and they have a button box and they make their choices or do whatever the experiment tells him to do, or even get juice into their mouth with a little too.",
                    "label": 0
                },
                {
                    "sent": "They just do the experiment lying down and looking at this little camera at this little mirror.",
                    "label": 0
                },
                {
                    "sent": "And trying to not move their head at all.",
                    "label": 0
                }
            ]
        },
        "clip_162": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At least we hope they don't move their head because ideas what we what we're measuring in these experiments is what's called a bold signal or a that's short for blood oxygenation level dependent.",
                    "label": 0
                }
            ]
        },
        "clip_163": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hello.",
                    "label": 0
                },
                {
                    "sent": "So what happens is in the brain there is.",
                    "label": 0
                },
                {
                    "sent": "There is a lot of blood.",
                    "label": 0
                },
                {
                    "sent": "There are lots of blood vessels.",
                    "label": 0
                },
                {
                    "sent": "Every neuron needs blood because it needs oxygen.",
                    "label": 0
                },
                {
                    "sent": "And there's a difference in the magnetic properties of oxygenated and deoxygenated hemoglobin hemoglobin in the blood.",
                    "label": 0
                },
                {
                    "sent": "So, after the options in has been taken by the neurons, the blood has a different magnetic property than it did before.",
                    "label": 0
                }
            ]
        },
        "clip_164": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we can detect this.",
                    "label": 0
                },
                {
                    "sent": "These little magnetic fluctuations with this huge superconducting magnet that makes a lot of noise and cause.",
                    "label": 0
                }
            ]
        },
        "clip_165": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A lot of money.",
                    "label": 0
                }
            ]
        },
        "clip_166": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And So what we're relying here is is on the fact that the brain is functionally modular, so different areas of the brain get blood via different vessels.",
                    "label": 0
                },
                {
                    "sent": "And if one area is active, it will use up more oxygen will actually ask the body for more oxygen than it needs, and we will see more oxygenation in that area because.",
                    "label": 0
                }
            ]
        },
        "clip_167": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It was active.",
                    "label": 0
                },
                {
                    "sent": "So what this does?",
                    "label": 0
                },
                {
                    "sent": "The reason it's called functional MRI is it shows as function.",
                    "label": 0
                }
            ]
        },
        "clip_168": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It shows us what brain area was used at what time, just some very.",
                    "label": 0
                }
            ]
        },
        "clip_169": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Very coarse.",
                    "label": 0
                },
                {
                    "sent": "Resolution so the space.",
                    "label": 0
                }
            ]
        },
        "clip_170": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Actual resolution is about 3 millimeters cubed, so we can kind of tell apart these kind of these small voxels of three by three by three, which is certainly not at the level of 1 neuron to the level of thousands of neurons, but.",
                    "label": 0
                },
                {
                    "sent": "The motor cortex sensory motor areas that they're differentiated enough that we can tell them apart.",
                    "label": 0
                },
                {
                    "sent": "The temporal resolution is also quite shabby.",
                    "label": 0
                },
                {
                    "sent": "It's 5 to 10 seconds because it takes time for the blood to get there and two away.",
                    "label": 0
                },
                {
                    "sent": "It's not like for every spike of a neuron we see some blood blood difference, but if a whole area is active for awhile, 5 seconds later will see this extra blood that actually what happens is it it asks for more blood than it needs, so we see.",
                    "label": 0
                },
                {
                    "sent": "The signal 5.",
                    "label": 0
                }
            ]
        },
        "clip_171": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Seconds later.",
                    "label": 0
                },
                {
                    "sent": "So what can we do with this?",
                    "label": 0
                },
                {
                    "sent": "We can study reinforcement learning and the brain.",
                    "label": 0
                },
                {
                    "sent": "In humans.",
                    "label": 0
                },
                {
                    "sent": "We can take this hidden variable of the model prediction errors an for instance, say OK during my experiment where my subject was playing some game, choosing stimuli, getting rewards during gambling or whatever.",
                    "label": 0
                },
                {
                    "sent": "In my little experiment video game, the model predicts that there would have been prediction errors overtime.",
                    "label": 0
                },
                {
                    "sent": "Second one, there would have been a positive prediction error and then it second four negative one and so forth.",
                    "label": 0
                },
                {
                    "sent": "So I predict these prediction errors.",
                    "label": 0
                }
            ]
        },
        "clip_172": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then I know that the bold signal usually has a typical time constant or a response.",
                    "label": 0
                },
                {
                    "sent": "It looks like this, so if there was an event here 5 seconds later, we'll see a peak in bold.",
                    "label": 0
                },
                {
                    "sent": "15 seconds later will see a dip and you know the whole thing levels out.",
                    "label": 0
                },
                {
                    "sent": "After about 32 seconds.",
                    "label": 0
                },
                {
                    "sent": "So basically 5 seconds later we'll see a peak so we can convolve our prediction error signals or Delta functions as we call them, although they're not really Delta functions, they have different Heights.",
                    "label": 0
                },
                {
                    "sent": "With this",
                    "label": 0
                }
            ]
        },
        "clip_173": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Bold and get the signal that we're expecting in the brain were expecting a peak caused by this, then a truck caused by this ahnapee caused by this, etc.",
                    "label": 0
                },
                {
                    "sent": "And take this and use linear regression to regress this against activity of the brain and ask is there an area in the brain that looks like this, like this green line?",
                    "label": 0
                }
            ]
        },
        "clip_174": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so that's what Odartey ET al did in 2004 to look for actor critic mechanisms in the brain.",
                    "label": 0
                },
                {
                    "sent": "In their experiment, the game.",
                    "label": 0
                }
            ]
        },
        "clip_175": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The subjects played went like this ohmygod.",
                    "label": 0
                },
                {
                    "sent": "There's almost no time when did we start.",
                    "label": 0
                },
                {
                    "sent": "At 1:30 one OK so not so bad there's two to half hours.",
                    "label": 0
                },
                {
                    "sent": "I thought 2 hours.",
                    "label": 0
                },
                {
                    "sent": "So they saw two stimuli on the screen.",
                    "label": 0
                },
                {
                    "sent": "And these stimuli could be included.",
                    "label": 0
                },
                {
                    "sent": "Either you know, like the location was randomized from trial to trial and there were two types of trial, either the trial.",
                    "label": 0
                }
            ]
        },
        "clip_176": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With this like Snowflake and weird looking thing or trials with these two weird looking things.",
                    "label": 0
                },
                {
                    "sent": "These were actually randomized for different subjects.",
                    "label": 0
                },
                {
                    "sent": "There were different pairs, different fractals, and the deal was on trials where they saw these.",
                    "label": 0
                },
                {
                    "sent": "They say.",
                    "label": 0
                }
            ]
        },
        "clip_177": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Had a chance to get a reward.",
                    "label": 0
                },
                {
                    "sent": "The juice reward if they chose one stimulus they would get the reward with 60% probability.",
                    "label": 0
                },
                {
                    "sent": "Another stimulus with 30% probability they didn't know they sent advance.",
                    "label": 0
                },
                {
                    "sent": "They had to learn this by trial and error.",
                    "label": 0
                },
                {
                    "sent": "The other type of trial.",
                    "label": 0
                }
            ]
        },
        "clip_178": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "They would also get something with 60% probability and 30% probability, But this wasn't juice.",
                    "label": 0
                },
                {
                    "sent": "This was considered a neutral reward.",
                    "label": 0
                },
                {
                    "sent": "This was actually artificial saliva.",
                    "label": 0
                },
                {
                    "sent": "They didn't know that 'cause that stops being neutral.",
                    "label": 0
                },
                {
                    "sent": "I see peoples faces, but actually when you just get it in your mouth it just feels like nothing.",
                    "label": 0
                },
                {
                    "sent": "It's kind of like your own space.",
                    "label": 0
                },
                {
                    "sent": "And they had subjects to play this game.",
                    "label": 0
                }
            ]
        },
        "clip_179": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Randomly interleaving these kinds of trials and what they saw before I get to the two conditions, what they saw was that in this case, subjects started preferring this stimulus, and in this case they were indifferent because they didn't really care about their rewards.",
                    "label": 0
                },
                {
                    "sent": "So firstly, we can see that the subjects learned the contingencies.",
                    "label": 0
                },
                {
                    "sent": "Another had two blocks in this experiment and one block.",
                    "label": 0
                },
                {
                    "sent": "Everything was as I described it right now, so.",
                    "label": 0
                },
                {
                    "sent": "This was called the instrumental block where subjects actions could affect their rewards.",
                    "label": 0
                },
                {
                    "sent": "Just as I said, and then they had another block that was.",
                    "label": 0
                }
            ]
        },
        "clip_180": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of Lothian Block where actually they didn't get to choose, they would see to stimulate.",
                    "label": 0
                },
                {
                    "sent": "Then the computer would make a square around one of them.",
                    "label": 0
                },
                {
                    "sent": "So that's the computer made the choice and they just had to indicate whether the computer chose left or right.",
                    "label": 0
                },
                {
                    "sent": "That was to equate the motor action the computer actually chose based on their previous choices.",
                    "label": 0
                },
                {
                    "sent": "It was yoked to their own previous choices.",
                    "label": 0
                },
                {
                    "sent": "But they didn't know that doesn't matter.",
                    "label": 0
                },
                {
                    "sent": "So they could they they had to choose what the computer chose and they got their rewards with the same probabilities.",
                    "label": 0
                },
                {
                    "sent": "According to the stimuli that the computer, the stimulus that the computer chose.",
                    "label": 0
                }
            ]
        },
        "clip_181": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I take home question for you.",
                    "label": 0
                },
                {
                    "sent": "Is to think about why the experiment was designed this way and.",
                    "label": 0
                },
                {
                    "sent": "Think of prediction errors.",
                    "label": 0
                },
                {
                    "sent": "They were trying to generate as many prediction errors as possible, so a reason that all these experiments use probabilistic rewards is to get prediction errors at the time reward 'cause their reward can't can't ever be completely.",
                    "label": 0
                },
                {
                    "sent": "Predicted and the recent views.",
                    "label": 0
                },
                {
                    "sent": "The reason that they use two different trial types is so that the stimuli can't be predicted either, and so there is a prediction error at the time the stimulus.",
                    "label": 0
                },
                {
                    "sent": "Head out.",
                    "label": 0
                }
            ]
        },
        "clip_182": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What did the results show?",
                    "label": 0
                },
                {
                    "sent": "What the results showed was that.",
                    "label": 0
                },
                {
                    "sent": "If you take a prediction error signal as so you take a model, you fit it to the behavior you generate the prediction errors that you think should.",
                    "label": 0
                }
            ]
        },
        "clip_183": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To happen at different times, you convolve it with this hemodynamic response function.",
                    "label": 0
                },
                {
                    "sent": "Exactly what I showed you before, and now you look for areas in the brain that.",
                    "label": 0
                }
            ]
        },
        "clip_184": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It correlate with this prediction error.",
                    "label": 1
                },
                {
                    "sent": "And what they saw was that there were two areas in the stratum as you now expect from an actor critic mechanism.",
                    "label": 0
                },
                {
                    "sent": "There's the area the ventral straight up.",
                    "label": 0
                },
                {
                    "sent": "Each one of these blobs shows correlation.",
                    "label": 0
                },
                {
                    "sent": "Shows areas that were correlated.",
                    "label": 0
                },
                {
                    "sent": "The ventral stratum was correlated with prediction errors both in the pavlovi and task, so both.",
                    "label": 1
                },
                {
                    "sent": "When they did, when their choices.",
                    "label": 0
                },
                {
                    "sent": "Well, their choices were not their own when they could only predict what was going to happen, but the computer made the choices.",
                    "label": 0
                },
                {
                    "sent": "And in the instrumental task where they made their own choices.",
                    "label": 0
                },
                {
                    "sent": "And this isn't this is showing the conjunction of both.",
                    "label": 0
                },
                {
                    "sent": "Both tasks.",
                    "label": 0
                }
            ]
        },
        "clip_185": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "While in the dorsal straight have been the more ventral ISM is ventral and dorsal or they come from animal from the animal anatomy, so ventral is to the belly and dorsal is to the back.",
                    "label": 0
                },
                {
                    "sent": "So think of animals with their head like that somewhere to the top is dorsal.",
                    "label": 1
                },
                {
                    "sent": "More to the bottom is ventral, so this is eventual.",
                    "label": 0
                },
                {
                    "sent": "Straighten up here is the dorsal well.",
                    "label": 1
                },
                {
                    "sent": "Higher up here is the dorsal stratum and the dorsal stratum only correlated with prediction errors.",
                    "label": 0
                },
                {
                    "sent": "In the instrumental task and not in the pool.",
                    "label": 1
                },
                {
                    "sent": "Open tasks so the idea was.",
                    "label": 0
                },
                {
                    "sent": "In Pavlovi and behavior, when you only need predictions, you need the critic but not the actor.",
                    "label": 0
                },
                {
                    "sent": "And the instrumental task.",
                    "label": 0
                },
                {
                    "sent": "You need both the critic and the actor, so both of them correlate with prediction errors.",
                    "label": 0
                },
                {
                    "sent": "And you might ask yourself, why are we seeing prediction errors in the stratum here and not in dopamine areas in the area where dopamine comes from, and that's.",
                    "label": 0
                },
                {
                    "sent": "Shown in many many fMRI studies so far, the the largest targets, as I said of dopamine, are the stratum and the bold response seems to correlate more with the input to an area, not the actual activity to an area.",
                    "label": 0
                },
                {
                    "sent": "So we're seeing something that perhaps is generated by dopamine prediction errors in the target of dopamine and not in the place where dopamine comes from.",
                    "label": 0
                }
            ]
        },
        "clip_186": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_187": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's skip.",
                    "label": 0
                }
            ]
        },
        "clip_188": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yes, because we don't have time so.",
                    "label": 0
                },
                {
                    "sent": "So so far.",
                    "label": 0
                },
                {
                    "sent": "This is some evidence for actor critic for our actor critic architecture in the brain.",
                    "label": 0
                },
                {
                    "sent": "It it is interesting because an actor critic, architecture, links, prediction, learning, so links, pavlovi and behavior of open learning or the critic to control to the actor in a very, very specific way.",
                    "label": 0
                },
                {
                    "sent": "It assumes kind of that they can't be.",
                    "label": 0
                },
                {
                    "sent": "Tis the that they can't be separated in that prediction like pavlovi and learning would be completely separate from instrumental learning.",
                    "label": 0
                },
                {
                    "sent": "It also assumes that there are no Q values.",
                    "label": 0
                },
                {
                    "sent": "You don't need Q values inactive, critical just need state values in the act in the.",
                    "label": 0
                },
                {
                    "sent": "Critic and the actor learns a policy rather than Q values.",
                    "label": 0
                },
                {
                    "sent": "But as I said, this isn't very conclusive evidence.",
                    "label": 0
                },
                {
                    "sent": "There is one study of maybe it and the rest of the evidence for the ventral dorsal divide for actor critic is more circumstantial.",
                    "label": 0
                },
                {
                    "sent": "It deals with their roles in other kinds of learning, but it's not direct evidence.",
                    "label": 0
                },
                {
                    "sent": "For actor.",
                    "label": 0
                }
            ]
        },
        "clip_189": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Eric.",
                    "label": 0
                },
                {
                    "sent": "So we should ask ourselves, is it really actor critic?",
                    "label": 0
                },
                {
                    "sent": "Or maybe there there is Q value learning sarsa or Q learning in the brain?",
                    "label": 0
                }
            ]
        },
        "clip_190": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And that's what Maurice said Al asked themselves at well as well in a study in 2005.",
                    "label": 0
                },
                {
                    "sent": "So they they also, they did a study on monkeys and recorded from actual dopamine neurons.",
                    "label": 0
                },
                {
                    "sent": "So what they were asking is, is the prediction error that we see in dopamine neurons at the time of the stimulus that look like a state value prediction error like we would have an actor critic?",
                    "label": 0
                },
                {
                    "sent": "Or does it look like a Q value prediction error or?",
                    "label": 0
                },
                {
                    "sent": "Q Learning prediction error source of prediction error because these algorithms would they differ in is what prediction error controls learning?",
                    "label": 0
                },
                {
                    "sent": "Is the prediction error that's based on the best possible action you can take or the action that you will actually taken Sarzo or the average policy an actor critic.",
                    "label": 0
                },
                {
                    "sent": "So the experiment went like this.",
                    "label": 0
                },
                {
                    "sent": "Normally what a monkey would see was it would see a stimulus would have to wait awhile until it got a ghost screen, and then it could.",
                    "label": 0
                },
                {
                    "sent": "It had to say either right or left to whether the stimulus was on the right or on the left, so this is Pablo, but it doesn't get to choose a stimulus.",
                    "label": 0
                },
                {
                    "sent": "It just says this is just to keep the monkey attentive.",
                    "label": 0
                },
                {
                    "sent": "Is it on the right or is it on the left and then it got a reward with the probability that dependent on the stimulus there were five different stimuli like in the Schultz experiment, one gave reward with zero probability, one with 25% fifty percent 75 and 100%, and the monkeys learned this many many, many trials like.",
                    "label": 0
                },
                {
                    "sent": "Thousands and thousands and thousands of trials where they learn this everyday.",
                    "label": 0
                },
                {
                    "sent": "The reason they're learning it for so many trials is not because it takes him so long to learn 5 stimuli.",
                    "label": 0
                },
                {
                    "sent": "It's because every day you can only record one dopaminergic neuron, and they want a lot of neurons so they can publish a paper, so they have to do this for many, many, many days.",
                    "label": 0
                },
                {
                    "sent": "But once in awhile they intervened and they put in test trials and which is the monkey saw two stimuli rather than 1.",
                    "label": 0
                },
                {
                    "sent": "Two out of the five, and now this was instrumental task where the monkey could actually choose when he saw the goal.",
                    "label": 0
                },
                {
                    "sent": "He could either go right or go left, and that was a choice of one of the two stimuli, and then he got a reward according to the probability associated with stimulus that he chose.",
                    "label": 0
                },
                {
                    "sent": "And let's say he knows from Preve.",
                    "label": 0
                }
            ]
        },
        "clip_191": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If learning that this stimulus rewards 25% probability in this one with 100% probability, and let's say his policy.",
                    "label": 0
                },
                {
                    "sent": "Is in this case, he usually chooses this one, but sometimes he chooses this one, so this one is chosen 20% of the time and this one is 80% of the time, which is what the monkeys actually showed.",
                    "label": 0
                },
                {
                    "sent": "For this they showed probability with called in the animal literature probability matching behavior.",
                    "label": 0
                },
                {
                    "sent": "It's kind of like a softmax.",
                    "label": 0
                },
                {
                    "sent": "They're choosing the best, but not all the time.",
                    "label": 0
                },
                {
                    "sent": "So now there are different things that the monkey can compute at this time point.",
                    "label": 0
                },
                {
                    "sent": "You can compute the value of this display, which is 20% times this reward plus 80% times this reward, and this value is the same dependent on whether he will choose left or right, because it just it already takes the whole policy into consideration.",
                    "label": 0
                },
                {
                    "sent": "Or he can do the Q learning thing, which is to say the value of this display is the value of the.",
                    "label": 0
                },
                {
                    "sent": "The best thing I could get.",
                    "label": 0
                },
                {
                    "sent": "So that's what's drawn here, and again, it doesn't depend on whether he will choose left or right, because Q learning is off policy.",
                    "label": 0
                },
                {
                    "sent": "The value here is.",
                    "label": 0
                },
                {
                    "sent": "The value for the best thing, although he might not choose the best thing.",
                    "label": 0
                },
                {
                    "sent": "Or he might do Sarsa, which is to say the value of this display is the value of the thing that I'm actually going to choose, so it's going to be oh point 25 if I choose left and one if I choose right.",
                    "label": 0
                },
                {
                    "sent": "And the reason I'm plotting the value here is because the prediction error at this time there is no reward yet.",
                    "label": 0
                },
                {
                    "sent": "So the prediction error is.",
                    "label": 0
                },
                {
                    "sent": "The future value minus the previous value.",
                    "label": 0
                },
                {
                    "sent": "The previous value we can assume was zero because there was no nothing on the display.",
                    "label": 0
                },
                {
                    "sent": "So this is basically what the prediction error will show us.",
                    "label": 0
                },
                {
                    "sent": "The value of this display, and now we're asking, is it going to be.",
                    "label": 0
                },
                {
                    "sent": "Willerton Q Learning or sarsa?",
                    "label": 0
                },
                {
                    "sent": "And what they saw.",
                    "label": 0
                }
            ]
        },
        "clip_192": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And plotted in a way that's really, really hard to understand.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately.",
                    "label": 0
                },
                {
                    "sent": "Well, I'll tell you the bottom line.",
                    "label": 0
                },
                {
                    "sent": "What they saw was Sarsa, the way they're showing it here is.",
                    "label": 0
                },
                {
                    "sent": "Look only at the empty.",
                    "label": 0
                },
                {
                    "sent": "Circles these show.",
                    "label": 0
                },
                {
                    "sent": "The value of different stimuli.",
                    "label": 0
                },
                {
                    "sent": "So the different stimuli, the 25, fifty, 75 and 100% stimuli and the responses of the neurons and then the black ones.",
                    "label": 0
                },
                {
                    "sent": "Our trials in which they saw two, but we're going to choose this stimulus, or this, or this, or this later, and the reason they're not exactly.",
                    "label": 0
                },
                {
                    "sent": "The action value there is not exactly the same as in the Pavlov in case because the because they had errors and they didn't always choose something in general, or something like that can't remember exactly why it's a little bit off, but the idea is that the values conform to the thing that they're going to choose an not the best option that they have.",
                    "label": 0
                }
            ]
        },
        "clip_193": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In a different way that they showed this is they took all the choice trials in which a certain stimulus was chosen was chosen.",
                    "label": 0
                },
                {
                    "sent": "And all the force trials of that same stimulus in aligned one on the other.",
                    "label": 0
                },
                {
                    "sent": "The dopaminergic responses and they look.",
                    "label": 0
                },
                {
                    "sent": "This is for the.",
                    "label": 0
                },
                {
                    "sent": "100 percent, 75 percent, 50%, and 25% for each one of them they align very well on each other.",
                    "label": 0
                },
                {
                    "sent": "So the bottom line here is.",
                    "label": 0
                },
                {
                    "sent": "It seems like the prediction errors in dopaminergic neurons look like a source of prediction error and not like a critic of V prediction error state value prediction error, but an action value.",
                    "label": 0
                },
                {
                    "sent": "Q value prediction error.",
                    "label": 0
                }
            ]
        },
        "clip_194": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_195": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I think I'm not going to go through this in detail.",
                    "label": 0
                }
            ]
        },
        "clip_196": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But just to say that.",
                    "label": 0
                }
            ]
        },
        "clip_197": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A different study.",
                    "label": 0
                }
            ]
        },
        "clip_198": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There have been only two studies on.",
                    "label": 0
                }
            ]
        },
        "clip_199": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yes, the.",
                    "label": 0
                }
            ]
        },
        "clip_200": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Can study from Roshell was in rats and they had a somewhat different design where they had odors, predicting immediate rewards and delayed rewards and large rewards and small rewards etc.",
                    "label": 0
                },
                {
                    "sent": "And we won't go.",
                    "label": 0
                }
            ]
        },
        "clip_201": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Through all this now, but when they looked at their responses, it looked more like they saw they thought they were seeing.",
                    "label": 0
                },
                {
                    "sent": "Q Learning rather than SAR, so so they were seeing.",
                    "label": 0
                },
                {
                    "sent": "In a forced choice trial where the rat had to get.",
                    "label": 0
                },
                {
                    "sent": "Either.",
                    "label": 0
                },
                {
                    "sent": "Let's look at this.",
                    "label": 0
                },
                {
                    "sent": "Well, either a reward with a short delay or with a long delay.",
                    "label": 0
                },
                {
                    "sent": "Rewards with long delays are discounted by time, right?",
                    "label": 0
                },
                {
                    "sent": "So they had more firing look only at the firing here 'cause this is already the time, the reward more firing for the short delay rewards it for the long delay rewards and the same or firing for a high for a large reward than for small reward.",
                    "label": 0
                },
                {
                    "sent": "But when they got a choice.",
                    "label": 0
                },
                {
                    "sent": "In both cases they saw the same firing whether they're going to choose the short or the long delay.",
                    "label": 0
                },
                {
                    "sent": "They first saw the same kind of Q value of the best possible option, so this fits this regardless of whether they are going to choose the best one or they're going to choose the second one.",
                    "label": 0
                },
                {
                    "sent": "The long delay one.",
                    "label": 0
                },
                {
                    "sent": "In the same here.",
                    "label": 0
                }
            ]
        },
        "clip_202": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_203": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_204": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this some of this summary of the story here is that the jury is still out on Sarcee versus Q learning or even starts versus Q learning versus actor critic.",
                    "label": 0
                },
                {
                    "sent": "There are a small handful of studies looking at this directly and what really needs to be done is more neuro scientists to do more experiments recording from dopamine neuron, especially an I wrote here.",
                    "label": 0
                },
                {
                    "sent": "Telltale task syntax that are designed especially for this purpose that could really tease apart these different models and the reason.",
                    "label": 0
                },
                {
                    "sent": "We want them to do that is that as I said, this is 1 area where the brain can inform reinforcement learning because the brain actually learns in a task that's much harder than a normal reinforcement learning task, right?",
                    "label": 0
                },
                {
                    "sent": "It learns and real time with real noise and.",
                    "label": 0
                }
            ]
        },
        "clip_205": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The problem is that if you look at these signals, sorry, you'll see that they are very very noisy and kind of you know, not what we'd expect from a nice prediction error signal.",
                    "label": 0
                },
                {
                    "sent": "But yeah, the brain is noisy.",
                    "label": 0
                },
                {
                    "sent": "The world is noisy.",
                    "label": 0
                },
                {
                    "sent": "It's true that also are specific measurement devices.",
                    "label": 0
                },
                {
                    "sent": "Putting electrodes into the brain don't give us the nicest signal in the world, and it could be that the brain itself sees a cleaner signal that we're seeing here.",
                    "label": 0
                },
                {
                    "sent": "But in general, since the brain learns so well, it would be interesting to know what algorithm.",
                    "label": 0
                },
                {
                    "sent": "It uses to do that learning, and that could maybe help the debate between these different algorithms.",
                    "label": 0
                }
            ]
        },
        "clip_206": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Reinforcement learning.",
                    "label": 0
                }
            ]
        },
        "clip_207": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so you have half an hour left.",
                    "label": 0
                },
                {
                    "sent": "Which means that will probably not get to risk sensitivity in the brain, but will do these two, so that's good.",
                    "label": 0
                },
                {
                    "sent": "OK, so until now I've talked about 3 algorithms for model free learning, but one question is, do animals really only learn model free trial and error prediction errors?",
                    "label": 0
                },
                {
                    "sent": "You know, run around the world blindly and see what happens, or is it?",
                    "label": 0
                },
                {
                    "sent": "Or is there also model based reinforcement learning in the brain?",
                    "label": 0
                },
                {
                    "sent": "And it turns out that way before.",
                    "label": 0
                }
            ]
        },
        "clip_208": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Reinforcement learning came into the picture.",
                    "label": 0
                },
                {
                    "sent": "Neuro scientists are, at that point.",
                    "label": 0
                },
                {
                    "sent": "Psychologists had fierce debates on this.",
                    "label": 0
                },
                {
                    "sent": "Where some psychologists like Thorndike thought that everything was stimulus response.",
                    "label": 0
                },
                {
                    "sent": "You see a stimulus.",
                    "label": 0
                },
                {
                    "sent": "You learn a response.",
                    "label": 0
                },
                {
                    "sent": "Basically, learn a policy for it and this model free, and some people like Tolman thought thought that rats were much smarter than that.",
                    "label": 0
                },
                {
                    "sent": "So what experiment that old man did?",
                    "label": 0
                }
            ]
        },
        "clip_209": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To show this was this experiment.",
                    "label": 0
                },
                {
                    "sent": "So in this experiment, the rats started from here ran into this big arena.",
                    "label": 0
                },
                {
                    "sent": "Had to find this second pathway, run down the pathway and got food over here.",
                    "label": 0
                },
                {
                    "sent": "And did this again and again over several days.",
                    "label": 0
                },
                {
                    "sent": "So the 1946 so I don't have a video.",
                    "label": 0
                }
            ]
        },
        "clip_210": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To show you.",
                    "label": 0
                },
                {
                    "sent": "And then in the test phase, told them change the situation.",
                    "label": 0
                },
                {
                    "sent": "This same table was now connected to a bunch of different.",
                    "label": 0
                },
                {
                    "sent": "Array of of pathways.",
                    "label": 0
                },
                {
                    "sent": "The main pathway this pathway was blocked.",
                    "label": 0
                },
                {
                    "sent": "And he asked himself, where would the rats go?",
                    "label": 0
                },
                {
                    "sent": "Which pathway would they choose?",
                    "label": 0
                },
                {
                    "sent": "And so.",
                    "label": 0
                },
                {
                    "sent": "You can probably see that this is where the goal used to be before, so the question is, will they know to go down pathway #6?",
                    "label": 0
                },
                {
                    "sent": "And indeed.",
                    "label": 0
                },
                {
                    "sent": "Most of the rats chose pathway 6, some of them chose one.",
                    "label": 0
                }
            ]
        },
        "clip_211": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Something went right, which is kind of the policy here.",
                    "label": 0
                },
                {
                    "sent": "The policy closest to the food, but many of them knew a completely new policy that they'd never been trained on before, which which basically showed Tolman.",
                    "label": 0
                }
            ]
        },
        "clip_212": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In his words.",
                    "label": 0
                },
                {
                    "sent": "Well, his words are humble rat.",
                    "label": 0
                },
                {
                    "sent": "He said even the humble rat can learn spatial structure and use it to plan flexibly.",
                    "label": 0
                },
                {
                    "sent": "So the rats didn't just learn straight left, right, right, food.",
                    "label": 0
                },
                {
                    "sent": "They learned something about the world, they learned what he called a cognitive map of the environment, which is what we'd call a transition function between states.",
                    "label": 0
                },
                {
                    "sent": "Or model of the world.",
                    "label": 0
                }
            ]
        },
        "clip_213": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A more modern way of testing this same thing.",
                    "label": 0
                },
                {
                    "sent": "Which actually looks at the other half, not transitions between states, but the reward function in reinforcement learning is called outcome devaluation.",
                    "label": 0
                },
                {
                    "sent": "So here what have.",
                    "label": 0
                }
            ]
        },
        "clip_214": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It says your trainer at to press a lever in order to get food.",
                    "label": 0
                },
                {
                    "sent": "And then after the rat is trained, it change the value of the food separately in a separate scenario, not in the same box where the rat is used to pressing for food.",
                    "label": 0
                },
                {
                    "sent": "But like in the home cage for instance, by letting the rat eat the food and then in.",
                    "label": 0
                }
            ]
        },
        "clip_215": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Acting it with lithium chloride, which makes rats feel really, really sick to their stomach.",
                    "label": 0
                },
                {
                    "sent": "It makes him not want to eat that food anymore.",
                    "label": 0
                },
                {
                    "sent": "It's like food poisoning.",
                    "label": 0
                },
                {
                    "sent": "It happens to us too, is called conditioned taste aversion.",
                    "label": 0
                },
                {
                    "sent": "You go to a restaurant to eat something to get a really bad stomach ache.",
                    "label": 0
                },
                {
                    "sent": "You don't ever want to go to that restaurant again, or certainly not order that food.",
                    "label": 0
                },
                {
                    "sent": "So that's what happens to the rats here.",
                    "label": 0
                },
                {
                    "sent": "They don't want to eat the food anymore.",
                    "label": 0
                },
                {
                    "sent": "You give them the food and they like they walk away.",
                    "label": 0
                },
                {
                    "sent": "Sometimes they even like throw things at it.",
                    "label": 0
                }
            ]
        },
        "clip_216": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or another way to do this is to just make the rat sated on even on another food.",
                    "label": 0
                },
                {
                    "sent": "Just make him really, really say to give him as much food as he wants so that now the original food in the experiment has a much lower value in both.",
                    "label": 0
                }
            ]
        },
        "clip_217": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Aces and now the question is, will the rat continue pressing for the food?",
                    "label": 0
                },
                {
                    "sent": "And that is compared to a rat the den.",
                    "label": 0
                }
            ]
        },
        "clip_218": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We have this devaluation so a normal rat that was trained on this and then just tested so we know that this rat will continue pressing.",
                    "label": 0
                },
                {
                    "sent": "The question is will these continue pressing at the same rate and the reason we're doing this in a in a comparison situation is specifically because this test is usually done with no rewards anymore, so we don't want to see new learning.",
                    "label": 0
                },
                {
                    "sent": "We want to see whether the rat put together its knowledge of contingencies.",
                    "label": 0
                },
                {
                    "sent": "What does this lever pressing give me an it's knowledge of?",
                    "label": 0
                },
                {
                    "sent": "What is the worth of this cheese?",
                    "label": 0
                },
                {
                    "sent": "So the reward function in the transition function?",
                    "label": 0
                },
                {
                    "sent": "Are these going to be put together without new learning about the food?",
                    "label": 0
                }
            ]
        },
        "clip_219": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_220": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_221": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The result is.",
                    "label": 0
                },
                {
                    "sent": "Well, the results are.",
                    "label": 0
                },
                {
                    "sent": "It depends.",
                    "label": 0
                },
                {
                    "sent": "If you train the rat only moderately, so you train the rat for four days to start with him in four sessions, each of them half an hour, and then do the devaluation and then do the test, you see that rats press much less for the devalued reward than for a reward that was not devalue.",
                    "label": 0
                }
            ]
        },
        "clip_222": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But if you train them more in the initial training I'm talking about.",
                    "label": 0
                }
            ]
        },
        "clip_223": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In this stage, if you train them for 15 days, they're not for four days.",
                    "label": 0
                }
            ]
        },
        "clip_224": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then they don't stop pressing even when the reward is devalued.",
                    "label": 0
                },
                {
                    "sent": "They press the same.",
                    "label": 0
                },
                {
                    "sent": "Is that the average of the 2D value?",
                    "label": 0
                },
                {
                    "sent": "This in this experiment they used SoC, not lithium chloride.",
                    "label": 0
                },
                {
                    "sent": "Are there different experiments?",
                    "label": 0
                },
                {
                    "sent": "Are a whole host of experiments have shown this this is.",
                    "label": 0
                },
                {
                    "sent": "You know what?",
                    "label": 0
                },
                {
                    "sent": "No, I think this is Holland's results and not kill cross, so this is with lithium chloride.",
                    "label": 0
                }
            ]
        },
        "clip_225": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With the poisoning.",
                    "label": 0
                },
                {
                    "sent": "So it seems like animals will sometimes work for food that they don't want, and the reason I'm saying they don't want it even in this case is that we can look at their magazine, behave.",
                    "label": 0
                }
            ]
        },
        "clip_226": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which is how many times they go to the food magazine to actually eat the food, and we see that in both cases even after extensive training, they go to the magazine less for when the food is devalued in one.",
                    "label": 0
                },
                {
                    "sent": "It sound evaluated.",
                    "label": 0
                },
                {
                    "sent": "This looks like it's not significant, but it's a within subject design and it is significantly different these two.",
                    "label": 0
                },
                {
                    "sent": "So in both cases they don't go to get the food, but in one case they continue pressing to earn the food.",
                    "label": 0
                },
                {
                    "sent": "I saw question from side.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_227": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this has been associated this kind of behavior after extensive training with what we know about our daily life, which is in our daily life.",
                    "label": 0
                },
                {
                    "sent": "Actions sometimes become automatic or we call them habitual.",
                    "label": 0
                },
                {
                    "sent": "After their extensively trained.",
                    "label": 0
                },
                {
                    "sent": "If we repeat them again and again and again, we drive home to the same place every day.",
                    "label": 0
                },
                {
                    "sent": "Then even when we move house we continue driving by mistake to the old place.",
                    "label": 0
                },
                {
                    "sent": "Although we know in our cognition and everything that we don't live there anymore, it's not that we don't know that the reward is not there anymore, we just failed to put 2 two and two together.",
                    "label": 0
                },
                {
                    "sent": "And not drive to the old.",
                    "label": 0
                }
            ]
        },
        "clip_228": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Place.",
                    "label": 0
                },
                {
                    "sent": "Hence.",
                    "label": 0
                }
            ]
        },
        "clip_229": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this has been termed the same in rats.",
                    "label": 0
                },
                {
                    "sent": "Habitual behavior when they continue pressing and goal directed behavior when they stop pressing, whether directed to a goal that they kind of put together in their mind.",
                    "label": 0
                },
                {
                    "sent": "Evaluating this is so you either had to keep waiting or did.",
                    "label": 0
                },
                {
                    "sent": "Made them sated.",
                    "label": 0
                },
                {
                    "sent": "If you are doing the voice thing.",
                    "label": 0
                },
                {
                    "sent": "Value or so.",
                    "label": 0
                },
                {
                    "sent": "Right, yeah, I understand.",
                    "label": 0
                },
                {
                    "sent": "Yeah no, this is a good question, so you're asking, what's the devaluation really?",
                    "label": 0
                },
                {
                    "sent": "As effective after extensive training as it was after moderate training and they check that.",
                    "label": 1
                },
                {
                    "sent": "So sometimes here it's enough to do one poisoning.",
                    "label": 0
                },
                {
                    "sent": "And here you have to do.",
                    "label": 0
                },
                {
                    "sent": "You know, three poisoning three poisonings on three different days, but they poisoned them until the point where they give them the food and they just don't want to eat it.",
                    "label": 0
                },
                {
                    "sent": "And that's when they go do the they put them back in the box with the lever and.",
                    "label": 0
                },
                {
                    "sent": "Test that so that's controlled for, but that's a good question.",
                    "label": 0
                }
            ]
        },
        "clip_230": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so we saw that in some case.",
                    "label": 0
                },
                {
                    "sent": "In some cases animals are habitual and in other cases in other cases animals are goal directed, so people were really, really interested in this and started to look at what areas of the brain lead to these kinds of behaviors in this kind of learning and what they saw.",
                    "label": 0
                },
                {
                    "sent": "And I'll show you only two results.",
                    "label": 0
                },
                {
                    "sent": "Just to not encumber you with all kinds of areas of the brain that mean nothing at this point is that there are some areas of the brain, specifically the dorsolateral stratum.",
                    "label": 0
                },
                {
                    "sent": "Where in this experiment these are over trained rats.",
                    "label": 0
                },
                {
                    "sent": "So if you don't leash in their brain what they're going to do is we're going to continue responding in the devalued case as much as they responded in the non devalued case.",
                    "label": 0
                }
            ]
        },
        "clip_231": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But if you lesion, if you cut the dorsolateral stratum out of their brain and then do all the training and everything, then suddenly their goal directed so they press less for the devalued option than for the valued option.",
                    "label": 0
                },
                {
                    "sent": "Even after 30 days of training or as long as you want to train them, but never become habitual.",
                    "label": 0
                },
                {
                    "sent": "So the idea was that the dorsolateral stratum is the seat of habits.",
                    "label": 0
                },
                {
                    "sent": "If you don't have the dorsolateral stratum in your brain, you.",
                    "label": 0
                }
            ]
        },
        "clip_232": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Can't learn habits.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_233": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is also true if you don't leash in the dorsal lateral strata, but you just deplete dopamine from it.",
                    "label": 0
                },
                {
                    "sent": "You kill all dopamine neurons that project to it, and there are a whole.",
                    "label": 0
                }
            ]
        },
        "clip_234": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There's a whole suite of areas, basically a loop of areas that are connected in the brain, areas in the prefrontal cortex areas in the thalamus at each of them.",
                    "label": 0
                },
                {
                    "sent": "If you lesion them, you lose this habitual behavior, so there seems to be a whole loop of areas that are involved in habitual learning.",
                    "label": 0
                }
            ]
        },
        "clip_235": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On the other hand, there is another loop, another host of areas, another group of areas, the dorsomedial stratum in the areas there.",
                    "label": 0
                },
                {
                    "sent": "Related to it's a slightly different part of the stratum where if you lesion that.",
                    "label": 0
                },
                {
                    "sent": "You get the opposite.",
                    "label": 0
                },
                {
                    "sent": "You get animals, they're always habitual, right from the very beginning, so.",
                    "label": 0
                },
                {
                    "sent": "This isn't the best part of it in the world 'cause these are.",
                    "label": 0
                },
                {
                    "sent": "Both of them are very low, but the idea is the regular behavior here after short training.",
                    "label": 0
                },
                {
                    "sent": "Is this a difference between the devalued in the non devalued and there is no difference after lesioning the posterior dorsal medial stratum.",
                    "label": 0
                },
                {
                    "sent": "In other experiments these two were as high as this one.",
                    "label": 0
                },
                {
                    "sent": "This experiment is a.",
                    "label": 0
                },
                {
                    "sent": "Bad choice on my part, but there are many experiments showing.",
                    "label": 0
                }
            ]
        },
        "clip_236": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yes, and so the idea is that.",
                    "label": 0
                }
            ]
        },
        "clip_237": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There's a whole loop in the brain that is responsible for goal directed learning, and if that doesn't exist from the very beginning, animals are habitual or they don't show sensitivity to devaluation right from the beginning of.",
                    "label": 0
                }
            ]
        },
        "clip_238": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Raining",
                    "label": 0
                }
            ]
        },
        "clip_239": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what does all this mean?",
                    "label": 0
                },
                {
                    "sent": "On one hand, we've learned one thing we've learned that the same action that we look at we see the rat lever pressing it can arise from 2 psychologically dissociable pathways.",
                    "label": 0
                },
                {
                    "sent": "So the fact that he's lever pressing doesn't tell us why he's lever pressing.",
                    "label": 0
                }
            ]
        },
        "clip_240": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Will we test with evaluation?",
                    "label": 0
                },
                {
                    "sent": "We can see that he might be lever pressing in a goal directed way dependent on the outcome representation, putting that today.",
                    "label": 0
                }
            ]
        },
        "clip_241": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Either with the contingencies, or he might be pressing in a habitual way just because.",
                    "label": 0
                },
                {
                    "sent": "Oh this is a lever I press levers not because this lever is going to give me food.",
                    "label": 0
                },
                {
                    "sent": "Same as in driving right?",
                    "label": 0
                },
                {
                    "sent": "I get into this car.",
                    "label": 0
                },
                {
                    "sent": "I get to this junction.",
                    "label": 0
                },
                {
                    "sent": "I take her right just you know, stimulus response.",
                    "label": 0
                },
                {
                    "sent": "That's a habitual one.",
                    "label": 0
                },
                {
                    "sent": "Goal directed is I'm going home so I take a right.",
                    "label": 0
                }
            ]
        },
        "clip_242": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And to complement this Association, the psychological dissociation there is also a deletion suggests that there are two neurally dissociable parallel systems in the brain that support each type of this behavior behavior, and they can support at any stage of training if the other one isn't there.",
                    "label": 0
                },
                {
                    "sent": "The second one, if one isn't there, a second one takes over.",
                    "label": 0
                }
            ]
        },
        "clip_243": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And So what we asked here, this was a study done by my colleague Nathaniel Da and myself it Anne.",
                    "label": 0
                },
                {
                    "sent": "Peter Dan was.",
                    "label": 0
                },
                {
                    "sent": "Can reinforcement learning help us make any sense?",
                    "label": 0
                },
                {
                    "sent": "Of this behavioral mess.",
                    "label": 0
                },
                {
                    "sent": "And this LED us to think about Red Force.",
                    "label": 0
                }
            ]
        },
        "clip_244": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Learning and the two main strategies in reinforcement learning, model based and model free.",
                    "label": 0
                },
                {
                    "sent": "So think of a task like this.",
                    "label": 0
                },
                {
                    "sent": "Instead of level pricing, it's harder to draw the lever.",
                    "label": 0
                },
                {
                    "sent": "Pressing MDP, although it's.",
                    "label": 0
                },
                {
                    "sent": "It's not that difficult, but it's it's easier to draw an MVP for forumers.",
                    "label": 0
                },
                {
                    "sent": "So the rat here is is navigating this maze and tries to get the maximum reward and has to choose whether to go left or right.",
                    "label": 0
                },
                {
                    "sent": "The reward.",
                    "label": 0
                },
                {
                    "sent": "This rat likes most is cheese, that's why it's worth 4 compared to carrots and water.",
                    "label": 0
                }
            ]
        },
        "clip_245": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we know that there are two ways to solve this problem.",
                    "label": 0
                },
                {
                    "sent": "The model based one is learn the map of the task, learn the contingency learning the transition, so state one take left.",
                    "label": 0
                },
                {
                    "sent": "You'll get to State 2.",
                    "label": 0
                },
                {
                    "sent": "Oops, this should have been 012.",
                    "label": 0
                },
                {
                    "sent": "ETC and the values of the rewards.",
                    "label": 0
                },
                {
                    "sent": "And then if you have these transitions in this reward function you can use.",
                    "label": 0
                }
            ]
        },
        "clip_246": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Your favorite model based methods?",
                    "label": 0
                },
                {
                    "sent": "Dynamic programming or any other method of look ahead of planning and figure out what is the value of taking the left here and taking a right here.",
                    "label": 0
                },
                {
                    "sent": "It's sorry taking left to say.",
                    "label": 0
                },
                {
                    "sent": "Here are taking right?",
                    "label": 0
                },
                {
                    "sent": "So taking left the value would be for and taking right the value would be 2, so of course the rat should go left.",
                    "label": 0
                }
            ]
        },
        "clip_247": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And importantly, this is computed on the fly, so the dynamic programming problem has to be solved on the fly, which means this computationally costly.",
                    "label": 0
                },
                {
                    "sent": "It can take a while, especially for the maze is bigger, but it's also flexible and immediately sensitive to change, because if the rat learns that.",
                    "label": 0
                }
            ]
        },
        "clip_248": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The reward function here has changed.",
                    "label": 0
                },
                {
                    "sent": "It will immediately affect the computed value of taking left in state.",
                    "label": 0
                },
                {
                    "sent": "In the initial state here.",
                    "label": 0
                },
                {
                    "sent": "So this is model based reinforcement learning.",
                    "label": 1
                },
                {
                    "sent": "On the other hand.",
                    "label": 0
                }
            ]
        },
        "clip_249": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We can solve the same exact task with model free reinforcement learning.",
                    "label": 0
                }
            ]
        },
        "clip_250": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Learning via trial and error and prediction errors.",
                    "label": 0
                },
                {
                    "sent": "This stored Q values and the Q values are.",
                    "label": 0
                },
                {
                    "sent": "A prediction for future for some of future rewards right now.",
                    "label": 0
                }
            ]
        },
        "clip_251": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This case, because we already have.",
                    "label": 0
                },
                {
                    "sent": "Q Values choosing actions is really easy.",
                    "label": 0
                },
                {
                    "sent": "You don't have to compute anything you don't have to solve a dynamic programming problem.",
                    "label": 0
                },
                {
                    "sent": "You're at state zero.",
                    "label": 0
                },
                {
                    "sent": "You look at the two Q values and you see that left is better done OK?",
                    "label": 0
                },
                {
                    "sent": "So this is it.",
                    "label": 0
                }
            ]
        },
        "clip_252": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Kind of quick and reflexive behavior that we could imagine from habitual behavior, but.",
                    "label": 0
                },
                {
                    "sent": "One thing is you need a lot of experience to learn.",
                    "label": 0
                },
                {
                    "sent": "You need to go through this many, many times to get the correct Q value.",
                    "label": 0
                }
            ]
        },
        "clip_253": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "News.",
                    "label": 0
                },
                {
                    "sent": "And the second thing is this will be inflexible, right?",
                    "label": 0
                },
                {
                    "sent": "If I now change the value of the cheese to zero, it's not immediately clear which Q value should change without experiencing this maze again and again, and having prediction errors update these values.",
                    "label": 0
                },
                {
                    "sent": "So the idea was that goal directed behavior is actually model based reinforcement learning where.",
                    "label": 0
                }
            ]
        },
        "clip_254": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Should have said this before where the rat learns the model of the world and plans in it, and that's why we see devaluation sensitivity.",
                    "label": 0
                }
            ]
        },
        "clip_255": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And habitual behavior is model free reinforcement learning in the brain.",
                    "label": 0
                },
                {
                    "sent": "But now the quote.",
                    "label": 0
                }
            ]
        },
        "clip_256": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But now this answer raises 2 new questions 'cause we're still.",
                    "label": 0
                }
            ]
        },
        "clip_257": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Stuck with the question of.",
                    "label": 0
                },
                {
                    "sent": "Why the hell should the brain use two different strategies in parallel?",
                    "label": 0
                },
                {
                    "sent": "Like why not just choose the best of the two and use that one?",
                    "label": 0
                }
            ]
        },
        "clip_258": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Always.",
                    "label": 0
                },
                {
                    "sent": "And if you do decide to use two now, what do you do if you have two parallel systems telling you what to do, and they say that they say different things, so one system is telling you, press the lever and the other is saying no, don't press the lever.",
                    "label": 0
                },
                {
                    "sent": "Now there is a new control problem of like which controller to listen to.",
                    "label": 0
                },
                {
                    "sent": "Nude",
                    "label": 0
                }
            ]
        },
        "clip_259": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Decision making problem, sorry.",
                    "label": 0
                },
                {
                    "sent": "And so our answer here.",
                    "label": 0
                }
            ]
        },
        "clip_260": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Was.",
                    "label": 0
                },
                {
                    "sent": "That one way to think about this is to look at the pros and cons of each of the model based and model free reinforcement learning.",
                    "label": 0
                },
                {
                    "sent": "So each of these two systems is best in different situations and what you really want from a robust.",
                    "label": 0
                },
                {
                    "sent": "Smart complex brain is that it would be able to use each system in the place where it's most appropriate.",
                    "label": 0
                },
                {
                    "sent": "So for instance.",
                    "label": 0
                }
            ]
        },
        "clip_261": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you have very limited training model based learning is does better with with little data compared to model free learning because model free learning bootstraps and uses you know it's.",
                    "label": 0
                },
                {
                    "sent": "It uses its own junk to learn basically and bootstrapping, so it takes a lot of time to take that junk out.",
                    "label": 0
                },
                {
                    "sent": "Well, model based learning puts each piece of information in the right place and does better with limited training.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, model based reinforcement learning will do better when it's close to the reward.",
                    "label": 0
                },
                {
                    "sent": "So this tree or the dynamic programming problem is much easier to solve than when you're playing a game of chess and have to, you know.",
                    "label": 0
                },
                {
                    "sent": "Solve the tree of all the possible actions until the end of the game.",
                    "label": 0
                },
                {
                    "sent": "So in the case where you're close to the reward or have limited training, the brain would do wisely to use goal directed to use a goal directed to use a model based forward.",
                    "label": 0
                }
            ]
        },
        "clip_262": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Search mechanism and the opposite.",
                    "label": 0
                },
                {
                    "sent": "After a lot of experience or when the reward is really far away, it would be better to use a caching Q learning.",
                    "label": 0
                },
                {
                    "sent": "Model free or SARSA model free.",
                    "label": 0
                },
                {
                    "sent": "Mechanism.",
                    "label": 0
                },
                {
                    "sent": "So that's the answer for why have two systems?",
                    "label": 0
                },
                {
                    "sent": "And now if those two systems this answer kind of says in one situation use one system and the other use the other.",
                    "label": 0
                },
                {
                    "sent": "But you have to have these two systems learning all the time.",
                    "label": 0
                },
                {
                    "sent": "You don't want to waste experience and teach only this system with some of the trials in this system with others, so that learning should happen in both in parallel.",
                    "label": 0
                },
                {
                    "sent": "And then if.",
                    "label": 0
                }
            ]
        },
        "clip_263": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Ask yourself.",
                    "label": 0
                },
                {
                    "sent": "Well, I have two systems that have already learned.",
                    "label": 0
                },
                {
                    "sent": "Rather than decide which one to use apriori by the constraints of the problem, I can basically ask each of them to tell me based on everything they've learned so far.",
                    "label": 0
                },
                {
                    "sent": "What do they suggest that I do?",
                    "label": 0
                },
                {
                    "sent": "But ask them to not only say what they suggest, but how confident are they in this suggestion and trust the one that's most confident and you would hope that this one would be more confident.",
                    "label": 0
                },
                {
                    "sent": "Only after a lot of experience and this one would be on more confident.",
                    "label": 0
                },
                {
                    "sent": "Only when it's close to the reward.",
                    "label": 0
                }
            ]
        },
        "clip_264": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the idea is.",
                    "label": 0
                },
                {
                    "sent": "To use some form of Bayesian reinforcement learning where you track.",
                    "label": 0
                }
            ]
        },
        "clip_265": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Not only values but also the variance, not fair.",
                    "label": 0
                },
                {
                    "sent": "And sorry, the uncertainty about these values and then what you get from the two systems is at each point you're asking what's the value of lever pressing versus not lever pressing or what's the value of turning left or turning right in the maze and you get for one system while high value.",
                    "label": 0
                },
                {
                    "sent": "And I'm quite sure about it from the other system low value and I'm not really sure.",
                    "label": 0
                },
                {
                    "sent": "Well then you go for this systems value.",
                    "label": 0
                },
                {
                    "sent": "You believe this one and you compare that value to values of other actions.",
                    "label": 0
                },
                {
                    "sent": "Well, in another case, if this was more certain, you'd believe this one, so this is the.",
                    "label": 0
                }
            ]
        },
        "clip_266": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I Bayesian the normative basin.",
                    "label": 0
                },
                {
                    "sent": "Think to do.",
                    "label": 0
                },
                {
                    "sent": "And as I said, there are different sources of uncertainty in the two systems, so if they track their uncertainty correctly, that would automatically solve the problem of using each one when it's most appropriate.",
                    "label": 0
                }
            ]
        },
        "clip_267": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what we've learned so far is that animal condition behavior.",
                    "label": 0
                },
                {
                    "sent": "Although it looks like you know animals, slobbering for food or pressing lever, is not very complex.",
                    "label": 0
                },
                {
                    "sent": "Still, it's not a unitary phenomenon.",
                    "label": 0
                },
                {
                    "sent": "The phenomenon.",
                    "label": 0
                },
                {
                    "sent": "The same responses can result from different neural and computational origins.",
                    "label": 0
                },
                {
                    "sent": "And it seems like these different neural mechanisms work in parallel to support behavior so they can cooperate, and they can also compete and reinforcement learning provides us clues not only to what these two systems do, but why this should be the case.",
                    "label": 0
                },
                {
                    "sent": "Why would you want these two systems in parallel and when would you want to use each of them?",
                    "label": 0
                },
                {
                    "sent": "And I should say I didn't write it here, but this could also feed back to planning simulations in robots, where if we want robust behavior from a robot, we might want to put in these two parallel mechanisms as well, and not only one of the two.",
                    "label": 0
                }
            ]
        },
        "clip_268": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I want to do this one or the next one.",
                    "label": 0
                },
                {
                    "sent": "Maybe I'll do the next one, it's more interesting.",
                    "label": 0
                },
                {
                    "sent": "This also you might have seen at NIPS a few years ago I presented this.",
                    "label": 0
                },
                {
                    "sent": "Clash is gonna take a lot to get through it.",
                    "label": 0
                },
                {
                    "sent": "OK, let's go for the last one.",
                    "label": 0
                },
                {
                    "sent": "So the last topic in the last 7 minutes before we get to the open challenges is risk sensitivity in reinforcement learning in the brain.",
                    "label": 0
                },
                {
                    "sent": "This is Brian new.",
                    "label": 0
                },
                {
                    "sent": "It's not yet published, that's why you also didn't have it in the slides.",
                    "label": 0
                },
                {
                    "sent": "I'm kind of being a little bit paranoid.",
                    "label": 0
                },
                {
                    "sent": "I've been taught that that's the right thing to do, so.",
                    "label": 0
                }
            ]
        },
        "clip_269": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is showing to this because I think this is another area where we where the brain can tell us something about reinforcement learning and this study what we asked was.",
                    "label": 0
                }
            ]
        },
        "clip_270": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This question, if I offer you once you leave the room.",
                    "label": 0
                },
                {
                    "sent": "$20.00 for sure in your hand.",
                    "label": 0
                },
                {
                    "sent": "20 Canadian dollars are now worth $0.80 each 80.",
                    "label": 0
                }
            ]
        },
        "clip_271": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "2nd dollar cents each.",
                    "label": 0
                },
                {
                    "sent": "Or Casa coin for $0.00 or $40?",
                    "label": 0
                },
                {
                    "sent": "Fifty 50 chance.",
                    "label": 0
                },
                {
                    "sent": "Which one do you prefer so?",
                    "label": 0
                },
                {
                    "sent": "Who prefers the sure 20?",
                    "label": 0
                },
                {
                    "sent": "OK, who prefers the risky?",
                    "label": 0
                },
                {
                    "sent": "Who doesn't care in different altitudes for them?",
                    "label": 0
                },
                {
                    "sent": "Three of you whose sleep joking?",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_272": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What you've shown is behavior that normal people show as well, which is most people are sensitive to, risk they care.",
                    "label": 0
                },
                {
                    "sent": "Very few people say they are indifferent in this situation.",
                    "label": 0
                },
                {
                    "sent": "Most people care in most people are also risk averse.",
                    "label": 0
                },
                {
                    "sent": "They prefer the $20 to the gamble, as most of you.",
                    "label": 0
                }
            ]
        },
        "clip_273": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now this is kind of curious because in reinforcement learning we're used to thinking about expected values, which are expected reward from these two options, and that is the same for both options.",
                    "label": 0
                },
                {
                    "sent": "So reinforcement learning normally ignores risk.",
                    "label": 0
                },
                {
                    "sent": "People normally don't ignore risk, and that's what we wanted to do in this.",
                    "label": 0
                }
            ]
        },
        "clip_274": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We wanted to go and look at that specifically wanted to go and look at the bold signals in fMRI that correlate with prediction errors.",
                    "label": 0
                },
                {
                    "sent": "The ones that we know already reflect reinforcement learning processes in the human brain.",
                    "label": 0
                },
                {
                    "sent": "An ask do those prediction errors care about risk or not.",
                    "label": 0
                }
            ]
        },
        "clip_275": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the actual question that we were asking was will the reinforcement learning neural value of sure $0.20 or we didn't have that much money?",
                    "label": 0
                },
                {
                    "sent": "Tougher subject so it went for sense be the same as that of a 5050 chance to get $0.40, yeah.",
                    "label": 0
                },
                {
                    "sent": "Possibly just changing them.",
                    "label": 0
                },
                {
                    "sent": "Dollars.",
                    "label": 0
                },
                {
                    "sent": "It is OK. That's a great question.",
                    "label": 0
                },
                {
                    "sent": "So so.",
                    "label": 0
                }
            ]
        },
        "clip_276": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As has been pointed out here, there are different ways to understand computation.",
                    "label": 0
                },
                {
                    "sent": "To understand how we solve this problem, and some of them predict the same neural valleys in the brain, and some predict different neural cells in the brain.",
                    "label": 0
                },
                {
                    "sent": "One of them is going to be a utility function, but before I get to that, let's start so.",
                    "label": 0
                }
            ]
        },
        "clip_277": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Basically, we thought of four models here, two that predict same neural values for the $0.20 and zero $0.40, and two that predict different neural values and to make a Long story short, the same girl values could come from either from.",
                    "label": 0
                },
                {
                    "sent": "Basically, it could be that reinforcement learning learns expected reward another area in the brain learns the variance and then the decision value combines those two.",
                    "label": 0
                },
                {
                    "sent": "But still if we look at reinforcement learning areas in the brain, they will be our good old.",
                    "label": 0
                },
                {
                    "sent": "Expected real.",
                    "label": 0
                }
            ]
        },
        "clip_278": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or",
                    "label": 0
                }
            ]
        },
        "clip_279": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It could be.",
                    "label": 0
                },
                {
                    "sent": "That we learn expected rewards, but due to sampling biases we still get risk sensitivity and the ID.",
                    "label": 0
                }
            ]
        },
        "clip_280": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here here is if you do normal reinforcement learning on these two options.",
                    "label": 0
                },
                {
                    "sent": "You still will get risk sensitivity.",
                    "label": 0
                },
                {
                    "sent": "And I'm going through this way too quickly, but the idea is, imagine you choose A and you get 20.",
                    "label": 0
                }
            ]
        },
        "clip_281": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Dollars.",
                    "label": 0
                },
                {
                    "sent": "Then an imagine he started with finish.",
                    "label": 0
                }
            ]
        },
        "clip_282": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Values of expecting 20 from each of these simulations, and of course you don't have a prediction error you don't.",
                    "label": 0
                }
            ]
        },
        "clip_283": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Update the values.",
                    "label": 0
                },
                {
                    "sent": "Everything is great.",
                    "label": 0
                }
            ]
        },
        "clip_284": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now you choose.",
                    "label": 0
                }
            ]
        },
        "clip_285": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And let's say you get $40, then you have a prediction error of plus 20.",
                    "label": 0
                },
                {
                    "sent": "And let's say your learning rate is oh point 5.",
                    "label": 0
                }
            ]
        },
        "clip_286": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Really high, I know, but it's easier to demonstrate with that then you update the value of B to B 30.",
                    "label": 0
                },
                {
                    "sent": "Now of course 30 is higher than 20.",
                    "label": 0
                },
                {
                    "sent": "Then in the next row.",
                    "label": 0
                }
            ]
        },
        "clip_287": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You choose to be again, but now let's say you get a zero and you're playing this by trial and error.",
                    "label": 0
                },
                {
                    "sent": "You don't know that it's 5050 chance this is.",
                    "label": 0
                },
                {
                    "sent": "This was the first time you fell for it.",
                    "label": 0
                },
                {
                    "sent": "This is the first time you saw zero.",
                    "label": 0
                }
            ]
        },
        "clip_288": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But now your prediction is minus.",
                    "label": 0
                },
                {
                    "sent": "30 and so once you update with zero.",
                    "label": 0
                }
            ]
        },
        "clip_289": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Put five learning rate.",
                    "label": 0
                },
                {
                    "sent": "You'll get 15 versus 20.",
                    "label": 0
                }
            ]
        },
        "clip_290": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now, of course you'll choose the red A.",
                    "label": 0
                },
                {
                    "sent": "Get.",
                    "label": 0
                }
            ]
        },
        "clip_291": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "20 because.",
                    "label": 0
                }
            ]
        },
        "clip_292": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Always gives 20 an no update etc etc and this will just continue forever.",
                    "label": 0
                }
            ]
        },
        "clip_293": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Basically because whatever you believe has a lower value, stop sampling it.",
                    "label": 0
                },
                {
                    "sent": "You stop learning about it and you don't know that that value is not its true mean.",
                    "label": 0
                },
                {
                    "sent": "And this is in regular reinforcement learning, so we could theoretically have completely normal reinforcement learning of means and auto variances and still get risk sensitivity.",
                    "label": 0
                },
                {
                    "sent": "But in this case, if we didn't let you sample, if I forced you to see 10 Eisen, 10 bees, on average, their values would be the same, which is what I'm going to do in the experiment.",
                    "label": 0
                }
            ]
        },
        "clip_294": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The two models on this side that predict different neural values are.",
                    "label": 0
                }
            ]
        },
        "clip_295": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A utility function as.",
                    "label": 0
                }
            ]
        },
        "clip_296": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As mentioned, so economists think for many years that the utility of rewards diminishes with amount.",
                    "label": 0
                },
                {
                    "sent": "So with diminishing utility's what you would get is that getting 40 half the time is worth less than getting 20 right.",
                    "label": 0
                },
                {
                    "sent": "Because you have this concave utility function between real amounts in the world in this objective.",
                    "label": 0
                }
            ]
        },
        "clip_297": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Tility they give you.",
                    "label": 0
                },
                {
                    "sent": "Or you could be you could have this kind of function which would lead to.",
                    "label": 0
                }
            ]
        },
        "clip_298": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Risk seeking be.",
                    "label": 0
                }
            ]
        },
        "clip_299": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Savior.",
                    "label": 0
                },
                {
                    "sent": "And the last model that we were really interested in actually was this model that's called risk sensitive temporal difference.",
                    "label": 0
                }
            ]
        },
        "clip_300": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Meaning I don't know how many of you are familiar with it.",
                    "label": 0
                },
                {
                    "sent": "It was published in 2002 in the Journal Machine Learning.",
                    "label": 0
                }
            ]
        },
        "clip_301": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I think or neural networks I can't remember right now and the idea here was that.",
                    "label": 0
                }
            ]
        },
        "clip_302": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can collapse learning about variance into temporal difference learning in.",
                    "label": 0
                }
            ]
        },
        "clip_303": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This way.",
                    "label": 0
                },
                {
                    "sent": "Instead of having.",
                    "label": 0
                },
                {
                    "sent": "Normal reinforcement learning where positive prediction where in this case around 20 you get half the time of positive prediction or half the time a negative prediction error, and they'd on average.",
                    "label": 0
                }
            ]
        },
        "clip_304": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Balance each other out.",
                    "label": 0
                },
                {
                    "sent": "Instead of that.",
                    "label": 0
                }
            ]
        },
        "clip_305": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You might overweigh negative prediction errors compared to positive prediction errors when doing the update of the values and then on average you learn.",
                    "label": 0
                },
                {
                    "sent": "A lower.",
                    "label": 0
                },
                {
                    "sent": "Value for this variable stimulus.",
                    "label": 0
                },
                {
                    "sent": "So you basically take variance into account, because when you have variables stimuli you have prediction errors all the time, and if you weigh prediction errors differently for positive and negative, the more variance you have, the more skewed your final.",
                    "label": 0
                }
            ]
        },
        "clip_306": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The result will be in this.",
                    "label": 0
                }
            ]
        },
        "clip_307": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You this could be to negative or positive depending on how you weigh positive and negative prediction errors.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Shit, I'm really out of.",
                    "label": 0
                }
            ]
        },
        "clip_308": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we have four models and we wanted to compare between them and I really.",
                    "label": 0
                },
                {
                    "sent": "Don't have time to go?",
                    "label": 0
                }
            ]
        },
        "clip_309": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Through the details, but the idea was we let subjects choose between different stimuli that had different rewards, and in this we had this choice between $0.20 and zero, $0.40.",
                    "label": 0
                },
                {
                    "sent": "And then we went to looked in their brain.",
                    "label": 0
                },
                {
                    "sent": "To see whether there would be a relationship between how risk averse they were, so how many times did they choose the $0.20 versus the zero?",
                    "label": 0
                },
                {
                    "sent": "$0.40, and what were the differences between the neural values of these two?",
                    "label": 0
                },
                {
                    "sent": "So we went into their nucleus of comments, took the bold signal extracted from that the prediction error signal extracted from that the values for $0.20 and zero $0.40 and basically.",
                    "label": 0
                },
                {
                    "sent": "What we would want to see if if they were not learning about risk, these two values should be the same.",
                    "label": 0
                },
                {
                    "sent": "If they were learning about risk, then when 20 is larger than zero forty, they should be choosing the 20 more times and when.",
                    "label": 0
                },
                {
                    "sent": "Zero 40 is larger than 20.",
                    "label": 0
                },
                {
                    "sent": "Then they should be choosing the 20 less times.",
                    "label": 0
                },
                {
                    "sent": "And that's exactly what we saw.",
                    "label": 0
                },
                {
                    "sent": "So that basically said.",
                    "label": 0
                },
                {
                    "sent": "That we're looking at one of these two algorithms.",
                    "label": 0
                },
                {
                    "sent": "Risk sensitive value learning or or nonlinear utility functions.",
                    "label": 1
                },
                {
                    "sent": "Because we did see differences between 20 and zero 40.",
                    "label": 0
                },
                {
                    "sent": "And to test whether it was this one or this one, what we did was we looked at the the actual values of.",
                    "label": 0
                },
                {
                    "sent": "Sure 20 ensure 40 and asked whether they were non linearly related to choice and there we didn't see that relationship.",
                    "label": 0
                },
                {
                    "sent": "And I'm sorry I'm running through this really, really quickly, but the take home message from this really is this.",
                    "label": 0
                }
            ]
        },
        "clip_310": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's that, although we're used to thinking about expected rewards and reinforcement learning, you might not believe this study.",
                    "label": 0
                }
            ]
        },
        "clip_311": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It doesn't really matter whether you believe it or not.",
                    "label": 0
                },
                {
                    "sent": "What matters is that we could.",
                    "label": 0
                },
                {
                    "sent": "We can do studies like this and see what the brain does with risk.",
                    "label": 0
                },
                {
                    "sent": "And in this study at least, it seems that the brain folds risk into predictive values.",
                    "label": 0
                },
                {
                    "sent": "And that's a place where I think the brain can tell us new things about reinforcement learning, because now if.",
                    "label": 0
                }
            ]
        },
        "clip_312": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That is really true.",
                    "label": 0
                },
                {
                    "sent": "We can ask ourselves well why is this a good thing to do?",
                    "label": 0
                },
                {
                    "sent": "We haven't done it so far, but is it actually optimal in some situations?",
                    "label": 0
                },
                {
                    "sent": "Will it help reinforcement learning if we use this?",
                    "label": 0
                },
                {
                    "sent": "Risk sensitive read.",
                    "label": 0
                }
            ]
        },
        "clip_313": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But learning and fold risk into values can help in our reinforcement learning applications.",
                    "label": 0
                },
                {
                    "sent": "If it helps the brain, perhaps it's a sensible thing to do.",
                    "label": 0
                }
            ]
        },
        "clip_314": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I want to finish with one slide.",
                    "label": 0
                },
                {
                    "sent": "About the open challenges in future direct.",
                    "label": 0
                }
            ]
        },
        "clip_315": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Since.",
                    "label": 0
                },
                {
                    "sent": "And basically what I want to encourage you to think about based on this whole tutorial is this interplay between looking at reinforcement learning and looking at the brain.",
                    "label": 0
                },
                {
                    "sent": "Because the challenges are the same.",
                    "label": 0
                }
            ]
        },
        "clip_316": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In both cases, if we think about reinforcement learning and how can reinforcement learning to deal with noisy inputs problems that many of you who study reinforcement learning might be grappling with, especially if you're using robots or or agents that work in the real.",
                    "label": 0
                }
            ]
        },
        "clip_317": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "World well the brain has that exact same problem.",
                    "label": 0
                },
                {
                    "sent": "Even worse, and input to the brain is noisy all the time.",
                    "label": 0
                },
                {
                    "sent": "For instance, there is huge temporal noise.",
                    "label": 0
                },
                {
                    "sent": "Temporal difference learning relies on knowing the exact time between events and predicting exact timing.",
                    "label": 0
                },
                {
                    "sent": "We don't have internal clocks that are that precise.",
                    "label": 0
                },
                {
                    "sent": "We know that we have a lot of timing noise.",
                    "label": 0
                },
                {
                    "sent": "Still, the brain manages to learn still dopamine looks like temporal difference prediction errors where if we actually ran temporal difference learning with the noise that that exists in the brain.",
                    "label": 0
                },
                {
                    "sent": "It would completely not work.",
                    "label": 0
                },
                {
                    "sent": "So the question is how can we learn from the brain how to improve our temporal difference algorithm?",
                    "label": 0
                },
                {
                    "sent": "Maybe use semi Markov decision?",
                    "label": 0
                },
                {
                    "sent": "Up formulation their their ideas out there but.",
                    "label": 0
                },
                {
                    "sent": "Since the brain knows how to deal with this, it can maybe teach us how reinforcement learning can deal with this.",
                    "label": 0
                },
                {
                    "sent": "Same thing when you think about how.",
                    "label": 0
                }
            ]
        },
        "clip_318": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And reinforcement learning deal with an unspecified state space, so I know that there is a new trend.",
                    "label": 0
                },
                {
                    "sent": "Great trend of looking at how the how reinforcement learning can learn useful state representations.",
                    "label": 0
                },
                {
                    "sent": "Well, the brain.",
                    "label": 0
                }
            ]
        },
        "clip_319": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Has to deal with the exact same thing, so maybe if we have no clue how to do this, we can ask the brain how it does it and learn from that.",
                    "label": 0
                }
            ]
        },
        "clip_320": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "How can reinforcement learning to deal with multiple goals with the fact that there are many problems with the fact that there is maybe hierarchical?",
                    "label": 1
                },
                {
                    "sent": "Structure to problems.",
                    "label": 0
                },
                {
                    "sent": "How can reinforcement learning transfer learning between tasks?",
                    "label": 0
                },
                {
                    "sent": "All problems with the brain deals with and is very good at.",
                    "label": 0
                },
                {
                    "sent": "We don't know how it does it, but we know it does.",
                    "label": 0
                }
            ]
        },
        "clip_321": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, so by asking neuroscience and neuro scientists to tell us how the brain solves these problems, we might learn.",
                    "label": 0
                }
            ]
        },
        "clip_322": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Something about how we can solve them in reinforcement learning.",
                    "label": 0
                },
                {
                    "sent": "So I started by telling you.",
                    "label": 0
                }
            ]
        },
        "clip_323": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Reinforcement learning is revolutionized.",
                    "label": 0
                },
                {
                    "sent": "How we think about learning in the brain.",
                    "label": 1
                },
                {
                    "sent": "And I showed you in some ways some examples of theoretical and also practical there.",
                    "label": 0
                },
                {
                    "sent": "There might be even clinical implications of this reinforcement learning framework for neuroscience.",
                    "label": 0
                },
                {
                    "sent": "If we think about dopamine and Parkinson's disease and gambling, etc.",
                    "label": 0
                },
                {
                    "sent": "So there are scientists really continue to be consumers of machine learning theory and algorithms, not only reinforcement learning is also based in learning is classification methods.",
                    "label": 0
                },
                {
                    "sent": "Graphical models I go to NIPS every year and I kind of treat it as a big supermarket like what's out there that I can copy that I can use to study the brain.",
                    "label": 0
                },
                {
                    "sent": "I haven't gone to ACNL before but this is the first year that I'm going to be shopping here as well as an earth scientist.",
                    "label": 0
                },
                {
                    "sent": "But important for you guys, I think this doesn't have to be a one way St.",
                    "label": 0
                },
                {
                    "sent": "Since humans and animals solve some of these problems that you are confronted with so well, it would be silly to not look at human learning and learn from that.",
                    "label": 0
                },
                {
                    "sent": "How we can do artificial learning better?",
                    "label": 0
                }
            ]
        },
        "clip_324": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you very much for your attention.",
                    "label": 0
                }
            ]
        },
        "clip_325": {
            "is_summarization_sample": false,
            "summarization_data": []
        }
    }
}