{
    "id": "euskfzebdkod6pbbtrkgtptk77mecjtk",
    "title": "Visualization of text document corpus",
    "info": {
        "author": [
            "Bla\u017e Fortuna, Artificial Intelligence Laboratory, Jo\u017eef Stefan Institute"
        ],
        "published": "Feb. 25, 2007",
        "recorded": "November 2005",
        "category": [
            "Top->Computer Science->Data Visualisation"
        ]
    },
    "url": "http://videolectures.net/cov05_fortuna_vtdc/",
    "segmentation": [
        [
            "Check.",
            "OK our.",
            "There it is.",
            "Blush how are you guys from?",
            "So, and the joint paper with.",
            "Heat on.",
            "Basically, on the system which.",
            "Produce the features images which I showed before so this landscape on the star project, so this would be kind of short short introduction.",
            "This system actually works.",
            "It will be little bit more in detail here, so that's why I didn't touch it before in the tutorial.",
            "OK, so I'm black Fortuna and as Marco said, this is joint work with me.",
            "Mark on Lumia on visualization of document corpora.",
            "So."
        ],
        [
            "For some motivation, why would we like to?",
            "Visualize some document document collection and there are more reasons for that.",
            "So one of the most common is that we would like to see what are the topics covered in this document collection.",
            "Then we also like to see what are covered the documents from the collection related how are the topics from the collection related and also we would like to enable user to explore these things in a very simple and fast way.",
            "So to explore these so called document space."
        ],
        [
            "So first about how do we represent documents?",
            "We use a bag of words representation.",
            "We heard about that in last talk already.",
            "If you just repeat in shortly, so each document is representing code that was a vector elements of vector.",
            "Each element of vector corresponds to one specific word, and it contains the frequency of this word.",
            "For example, if you take this.",
            "Take care that said, this is a document.",
            "We get this list of words, and for each word we know the frequency with which this word Co occurs occurs in the document.",
            "And some words can appear 0 times.",
            "Some appear more times and.",
            "So this is a.",
            "At the end we get very high dimensional vectors.",
            "So this is the original representation of the documents from the collection and.",
            "Of course, we also use the weighting Marco described before this TS IDF vectors.",
            "The prob."
        ],
        [
            "In this representation, is that each vector the dimensionality of the spaces?",
            "It corresponds to the number of different words that appear in the document collection, and usually this number of different parts is very high.",
            "It's totally normal to have 10,000 or 100,000 different words, and that means that we have the vectors representing documents are vectors living in this very high dimensional space in.",
            "If we want to visualize these documents to draw them on some on the computer screen, we must reduce this to just two dimensions, and that's a very big step.",
            "So."
        ],
        [
            "We do this in more stages, so first we start with this original document representation.",
            "That is quite a national vectors.",
            "And the first step is using so-called Latin semantic indexing technique, and we use this to get down to around 100 dimensions."
        ],
        [
            "What is Latin semantic indexing?",
            "So it's a technique which finds similar words and groups them together in so called latent variables and words are grouped corresponding to the Co occurrences in the documents.",
            "So if 2 words appear together more often very often.",
            "We say that these words are most likely have some similar meaning.",
            "If machine learning appears very often and said OK, machine learning is some specific concept we call them concepts and.",
            "After we do this step of finding this so called latent variables.",
            "We describe documents we change the way we encode documents into vectors before we encode them as by the words.",
            "But now we include them as these concepts and usually not this number of this discovered concepts.",
            "It's much lower than number of different words, so when we get from this way, we get from around 10,000 or more dimensions to few hundreds.",
            "So this is still.",
            "And the background of this method is singular value decomposition and it finds a low dimensional approximation of document vectors.",
            "And the basis vectors of this lodac dimensional subspace are called matter."
        ],
        [
            "Variables.",
            "So now we only go to around 100 dimensions and we still have to get down to two dimensions and for that we use multidimensional scaling."
        ],
        [
            "This is another technique for dimensionality reduction for the difference between PS1 and this one is that Latin semantic indexing is linear production technique and this is nonlinear, so it can be much more much more radical in reducing the dimensions by still preserving the similarities between documents.",
            "And the goal of this technique is to find the position points given on the dimensional Euclidean plane so that the Euclidean distance on the plane matches the original similarity between documents.",
            "So for example, if you use causes similarity, then we would like the cause in similarity of two documents is about the same as the greedy and distance on the map view.",
            "Some iterative gradient descent algorithm to.",
            "Calculate this new positions.",
            "An output of this algorithm is those two dimensional.",
            "Points so we can put draw them on a plane.",
            "If we go again."
        ],
        [
            "The first weekend bag of words, representation of documents or documents as words.",
            "Then use that in semantic indexing to describe documents just by topics.",
            "All these concepts that in variables and then we get down to do dimension using multidimensional scaling.",
            "We could also go directly from here to here but.",
            "We did some experiments and the quality of visualization is much lower.",
            "So.",
            "And once we get this 2 dimensional.",
            "Positions of each document we can draw it on computer screen.",
            "So."
        ],
        [
            "These yellow crosses 1 yellow cross represents one document and once we have the position of the documents it can also generate the background landscape.",
            "This is this is the landscape marker showed before and it's based on the density, so the.",
            "In this case, the lighter the background color is, the more dense that area is.",
            "For example, this is darker.",
            "There's no documented column here, it's a big group of documents, so it's very light color."
        ],
        [
            "Then we connect also keywords to the map.",
            "So this white words are keywords.",
            "And for example, this work for each work.",
            "For each point we take some.",
            "Sample of documents surrounding this point.",
            "For example, for this point we take these documents around here, and we take the.",
            "The sum there.",
            "TF IDF vector and we calculate the average document for that area.",
            "And we check which is the most important word in that average document.",
            "And we this position of these points is randomly randomly selected."
        ],
        [
            "Then you can also, if we enable user to position on some specific part of the gap, for example here this dark cross.",
            "And we show here so user selects that part of the map and we look to show here the list of the keywords for the documents which are inside that dark circle.",
            "So now I showed the live demo of this office software on 2 document collections.",
            "Both are made from.",
            "Are related to Pascal.",
            "First, document Collection is a collection of abstract of scientific papers which are available through Pascal.",
            "Eprints server on the Internet.",
            "And the second data set is.",
            "In the second data set, each document is 1 Pascal.",
            "Researcher and.",
            "Each researcher is the content of this document is.",
            "Sum of all the abstracts of the papers he's coauthored."
        ],
        [
            "So good.",
            "So this is an example of the papers.",
            "For example, each each point here.",
            "This represents one document and you can just checking the white words.",
            "We see what are the topic for each area.",
            "You can see this is some document.",
            "So this is the picture marker showing before only in.",
            "This is a bit, but it's not really into the.",
            "The.",
            "Visualization and here we see the text mining.",
            "Here we see multimedia up there.",
            "We see kernel methods so we can see the topic just by checking the word.",
            "For example, here we have image image object.",
            "Kernel images or.",
            "Something about images and we can click some point, for example this one.",
            "And we see this is.",
            "The.",
            "Future selection challenge.",
            "Probably this is about was.",
            "Some of the datasets or something was related to images.",
            "Reduces object categorization.",
            "So population of images and so on.",
            "If you check here.",
            "Network here is probably some.",
            "This is some the theoretical parts and these are kernel methods if you check.",
            "Make sure progression.",
            "So on.",
            "So, but just looking at this picture in few minutes, you can have a very good idea of what are the.",
            "Papers from Pascal researchers covering.",
            "The second visualization now.",
            "Each this.",
            "Yellow crosses a person.",
            "Put this so these are now the person names are visible.",
            "So these orange names are document names.",
            "In this case documents are persons and you can zoom in.",
            "For example in some area.",
            "And we can see here.",
            "What are the researchers and you can see this is?",
            "Checking into the coffee can see this is text mining area.",
            "And.",
            "We can, but try checking the people you can see which people are working in this field.",
            "We can like that no, we have not shown is user profiling.",
            "So.",
            "Lumia it's text mining.",
            "Tutorial so micropenis.",
            "Jones Colonel.",
            "So this is joint for Taylor next to Bernhard Shelkoff.",
            "I like small eyes here so.",
            "Thunder.",
            "Then you can click and you can see all the papers.",
            "Up stepped in the papers from keys from the key posted on the Pascal.",
            "So this is these are the demos."
        ],
        [
            "Can also by extending the block.",
            "For now, this landscape was just the the color of the background.",
            "If we can use this instead of for the color of the brain background, diffuse it for as a High Peak and through this 3D pictures.",
            "So this is European projects and.",
            "I'd like this card is here.",
            "So and.",
            "Let's let's also thank you."
        ],
        [
            "Question.",
            "OK, so this is much faster than this, for example.",
            "That is money, even if it's for these datasets, it's a matter of seconds, and this one is the method means.",
            "How can you explain the voice?",
            "The moment loans near management.",
            "You can check on that.",
            "He's very.",
            "So yeah, because.",
            "This weekend there.",
            "Yes, but what is your interpretation?",
            "Why is there no?",
            "Doesn't fit into any of these topics.",
            "The bank is on the power people.",
            "It could be that we his papers are not just from.",
            "Yeah, so there's this is not such a big gap.",
            "Or kernel method, so it's.",
            "So we can assume who I'm talking about.",
            "There's no other signs of getting this topic, but not many.",
            "It is not not many from these, from there, yeah.",
            "Identified.",
            "Other words, every dentify, maybe a 6000 feet are not discriminating useless words, so that then speed up in this way that we only focus on so there is."
        ],
        [
            "You can already throw out when we do preprocessing, so like this end or this so called stop words.",
            "Then you can also reduce by.",
            "Cutting prefixes suffixes are suffixes by popularity timing, so this is one way and another who is this?",
            "He basically identifies which words are similar, and it's another way of.",
            "This place is a space CK opening who was developing so-called basic elimination based initially.",
            "No eight hundreds and then then somebody increased to 1000 and there are there are such which say that anything he needs can be expressed with these 800 words.",
            "And then I look at this idea.",
            "We have 3 lines.",
            "Discard but at least this way you can.",
            "You know translating from English to basically anything different.",
            "So we usually deal with this problem with if first 2 hours of town.",
            "So instead of letting having this kind of basic English usually use this desires expert net, which basically where the meanings of perverts, our senses of the words are organized in this one big three.",
            "So roughly, we have 100 thousands of sensors, each senses a set of synonyms for each word, and we know that I don't know.",
            "The hierarchy of the senses of the top level ones are very high level.",
            "One in the bottom level are very concrete stuff, so one way would be to map the words into this census so the other way which actually is kind of side effectively interesting that this eigenvectors which are identified basically produce sort of set of synonyms for this particular domain, so maybe.",
            "This set of basic English words.",
            "Boolean wouldn't cover vocabulary.",
            "Speech appeared in this very technical texts, so this is the problem.",
            "So here we can.",
            "Automatic means to identify this sort of.",
            "Say people have met the grapple colocations between versions of this.",
            "Please, if we talk about this, I connected spaces with because of eigenvectors and but basically effects impact this set of synonyms which are automatically identified.",
            "So this is the way how we deal with this.",
            "Can you find an item coming bedding dimensions of this?",
            "These documents is mean you still asleep visualizations.",
            "Thank you, I didn't try it.",
            "Where we are aiming for two from it so we didn't really try anything else.",
            "They just need to know what was in Coleman's office.",
            "Is minimal inventing promotions.",
            "Leslie here the goal was mainly this vision.",
            "Another point of these, going from hundred to two, there are at least that's how much I understand that visible component method using chemical applications you apply to some system system that uses 20 descriptors and principal component with elevated only six ascension.",
            "So at least they will know that you mention running.",
            "Maybe you know something.",
            "So this lattice mannequin this thing is very similar to principal component analysis and.",
            "One thing we found here that so for using just principle component analysis, for example, it's a linear method.",
            "Then it's not.",
            "It doesn't capture enough information if you just put it on 2 dimensions, so.",
            "It would be because it would be something nonlinear to in order to.",
            "Capture as much information as possible because it mentions.",
            "But these are size.",
            "Is very very similar to this.",
            "Even in the pilot fire plan, it would be easily to change it.",
            "Yeah, so all these tools which you saw here before now basically these are all within this so called text Garden software package and basically the actual single tools are the particular.",
            "Is just set of a pipeline of individual tools like from here, so he could easily exchange.",
            "PCA.",
            "Just posted something.",
            "Did you try send my countries today?",
            "My kind of crazy 8 if I'm not incredibly say.",
            "Any other comments?",
            "OK then, thanks.",
            "So."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Check.",
                    "label": 0
                },
                {
                    "sent": "OK our.",
                    "label": 0
                },
                {
                    "sent": "There it is.",
                    "label": 0
                },
                {
                    "sent": "Blush how are you guys from?",
                    "label": 0
                },
                {
                    "sent": "So, and the joint paper with.",
                    "label": 0
                },
                {
                    "sent": "Heat on.",
                    "label": 0
                },
                {
                    "sent": "Basically, on the system which.",
                    "label": 0
                },
                {
                    "sent": "Produce the features images which I showed before so this landscape on the star project, so this would be kind of short short introduction.",
                    "label": 0
                },
                {
                    "sent": "This system actually works.",
                    "label": 0
                },
                {
                    "sent": "It will be little bit more in detail here, so that's why I didn't touch it before in the tutorial.",
                    "label": 0
                },
                {
                    "sent": "OK, so I'm black Fortuna and as Marco said, this is joint work with me.",
                    "label": 0
                },
                {
                    "sent": "Mark on Lumia on visualization of document corpora.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For some motivation, why would we like to?",
                    "label": 0
                },
                {
                    "sent": "Visualize some document document collection and there are more reasons for that.",
                    "label": 0
                },
                {
                    "sent": "So one of the most common is that we would like to see what are the topics covered in this document collection.",
                    "label": 0
                },
                {
                    "sent": "Then we also like to see what are covered the documents from the collection related how are the topics from the collection related and also we would like to enable user to explore these things in a very simple and fast way.",
                    "label": 1
                },
                {
                    "sent": "So to explore these so called document space.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So first about how do we represent documents?",
                    "label": 0
                },
                {
                    "sent": "We use a bag of words representation.",
                    "label": 0
                },
                {
                    "sent": "We heard about that in last talk already.",
                    "label": 0
                },
                {
                    "sent": "If you just repeat in shortly, so each document is representing code that was a vector elements of vector.",
                    "label": 0
                },
                {
                    "sent": "Each element of vector corresponds to one specific word, and it contains the frequency of this word.",
                    "label": 1
                },
                {
                    "sent": "For example, if you take this.",
                    "label": 0
                },
                {
                    "sent": "Take care that said, this is a document.",
                    "label": 0
                },
                {
                    "sent": "We get this list of words, and for each word we know the frequency with which this word Co occurs occurs in the document.",
                    "label": 0
                },
                {
                    "sent": "And some words can appear 0 times.",
                    "label": 0
                },
                {
                    "sent": "Some appear more times and.",
                    "label": 0
                },
                {
                    "sent": "So this is a.",
                    "label": 1
                },
                {
                    "sent": "At the end we get very high dimensional vectors.",
                    "label": 0
                },
                {
                    "sent": "So this is the original representation of the documents from the collection and.",
                    "label": 0
                },
                {
                    "sent": "Of course, we also use the weighting Marco described before this TS IDF vectors.",
                    "label": 0
                },
                {
                    "sent": "The prob.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In this representation, is that each vector the dimensionality of the spaces?",
                    "label": 0
                },
                {
                    "sent": "It corresponds to the number of different words that appear in the document collection, and usually this number of different parts is very high.",
                    "label": 1
                },
                {
                    "sent": "It's totally normal to have 10,000 or 100,000 different words, and that means that we have the vectors representing documents are vectors living in this very high dimensional space in.",
                    "label": 0
                },
                {
                    "sent": "If we want to visualize these documents to draw them on some on the computer screen, we must reduce this to just two dimensions, and that's a very big step.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We do this in more stages, so first we start with this original document representation.",
                    "label": 0
                },
                {
                    "sent": "That is quite a national vectors.",
                    "label": 0
                },
                {
                    "sent": "And the first step is using so-called Latin semantic indexing technique, and we use this to get down to around 100 dimensions.",
                    "label": 1
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What is Latin semantic indexing?",
                    "label": 1
                },
                {
                    "sent": "So it's a technique which finds similar words and groups them together in so called latent variables and words are grouped corresponding to the Co occurrences in the documents.",
                    "label": 1
                },
                {
                    "sent": "So if 2 words appear together more often very often.",
                    "label": 0
                },
                {
                    "sent": "We say that these words are most likely have some similar meaning.",
                    "label": 0
                },
                {
                    "sent": "If machine learning appears very often and said OK, machine learning is some specific concept we call them concepts and.",
                    "label": 0
                },
                {
                    "sent": "After we do this step of finding this so called latent variables.",
                    "label": 0
                },
                {
                    "sent": "We describe documents we change the way we encode documents into vectors before we encode them as by the words.",
                    "label": 0
                },
                {
                    "sent": "But now we include them as these concepts and usually not this number of this discovered concepts.",
                    "label": 0
                },
                {
                    "sent": "It's much lower than number of different words, so when we get from this way, we get from around 10,000 or more dimensions to few hundreds.",
                    "label": 0
                },
                {
                    "sent": "So this is still.",
                    "label": 1
                },
                {
                    "sent": "And the background of this method is singular value decomposition and it finds a low dimensional approximation of document vectors.",
                    "label": 1
                },
                {
                    "sent": "And the basis vectors of this lodac dimensional subspace are called matter.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Variables.",
                    "label": 0
                },
                {
                    "sent": "So now we only go to around 100 dimensions and we still have to get down to two dimensions and for that we use multidimensional scaling.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is another technique for dimensionality reduction for the difference between PS1 and this one is that Latin semantic indexing is linear production technique and this is nonlinear, so it can be much more much more radical in reducing the dimensions by still preserving the similarities between documents.",
                    "label": 0
                },
                {
                    "sent": "And the goal of this technique is to find the position points given on the dimensional Euclidean plane so that the Euclidean distance on the plane matches the original similarity between documents.",
                    "label": 0
                },
                {
                    "sent": "So for example, if you use causes similarity, then we would like the cause in similarity of two documents is about the same as the greedy and distance on the map view.",
                    "label": 0
                },
                {
                    "sent": "Some iterative gradient descent algorithm to.",
                    "label": 1
                },
                {
                    "sent": "Calculate this new positions.",
                    "label": 1
                },
                {
                    "sent": "An output of this algorithm is those two dimensional.",
                    "label": 0
                },
                {
                    "sent": "Points so we can put draw them on a plane.",
                    "label": 0
                },
                {
                    "sent": "If we go again.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The first weekend bag of words, representation of documents or documents as words.",
                    "label": 0
                },
                {
                    "sent": "Then use that in semantic indexing to describe documents just by topics.",
                    "label": 1
                },
                {
                    "sent": "All these concepts that in variables and then we get down to do dimension using multidimensional scaling.",
                    "label": 0
                },
                {
                    "sent": "We could also go directly from here to here but.",
                    "label": 0
                },
                {
                    "sent": "We did some experiments and the quality of visualization is much lower.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "And once we get this 2 dimensional.",
                    "label": 0
                },
                {
                    "sent": "Positions of each document we can draw it on computer screen.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "These yellow crosses 1 yellow cross represents one document and once we have the position of the documents it can also generate the background landscape.",
                    "label": 0
                },
                {
                    "sent": "This is this is the landscape marker showed before and it's based on the density, so the.",
                    "label": 0
                },
                {
                    "sent": "In this case, the lighter the background color is, the more dense that area is.",
                    "label": 0
                },
                {
                    "sent": "For example, this is darker.",
                    "label": 0
                },
                {
                    "sent": "There's no documented column here, it's a big group of documents, so it's very light color.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then we connect also keywords to the map.",
                    "label": 0
                },
                {
                    "sent": "So this white words are keywords.",
                    "label": 0
                },
                {
                    "sent": "And for example, this work for each work.",
                    "label": 0
                },
                {
                    "sent": "For each point we take some.",
                    "label": 0
                },
                {
                    "sent": "Sample of documents surrounding this point.",
                    "label": 0
                },
                {
                    "sent": "For example, for this point we take these documents around here, and we take the.",
                    "label": 0
                },
                {
                    "sent": "The sum there.",
                    "label": 0
                },
                {
                    "sent": "TF IDF vector and we calculate the average document for that area.",
                    "label": 0
                },
                {
                    "sent": "And we check which is the most important word in that average document.",
                    "label": 0
                },
                {
                    "sent": "And we this position of these points is randomly randomly selected.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then you can also, if we enable user to position on some specific part of the gap, for example here this dark cross.",
                    "label": 1
                },
                {
                    "sent": "And we show here so user selects that part of the map and we look to show here the list of the keywords for the documents which are inside that dark circle.",
                    "label": 0
                },
                {
                    "sent": "So now I showed the live demo of this office software on 2 document collections.",
                    "label": 0
                },
                {
                    "sent": "Both are made from.",
                    "label": 0
                },
                {
                    "sent": "Are related to Pascal.",
                    "label": 0
                },
                {
                    "sent": "First, document Collection is a collection of abstract of scientific papers which are available through Pascal.",
                    "label": 0
                },
                {
                    "sent": "Eprints server on the Internet.",
                    "label": 0
                },
                {
                    "sent": "And the second data set is.",
                    "label": 0
                },
                {
                    "sent": "In the second data set, each document is 1 Pascal.",
                    "label": 0
                },
                {
                    "sent": "Researcher and.",
                    "label": 0
                },
                {
                    "sent": "Each researcher is the content of this document is.",
                    "label": 0
                },
                {
                    "sent": "Sum of all the abstracts of the papers he's coauthored.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So good.",
                    "label": 0
                },
                {
                    "sent": "So this is an example of the papers.",
                    "label": 0
                },
                {
                    "sent": "For example, each each point here.",
                    "label": 0
                },
                {
                    "sent": "This represents one document and you can just checking the white words.",
                    "label": 0
                },
                {
                    "sent": "We see what are the topic for each area.",
                    "label": 0
                },
                {
                    "sent": "You can see this is some document.",
                    "label": 0
                },
                {
                    "sent": "So this is the picture marker showing before only in.",
                    "label": 0
                },
                {
                    "sent": "This is a bit, but it's not really into the.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "Visualization and here we see the text mining.",
                    "label": 0
                },
                {
                    "sent": "Here we see multimedia up there.",
                    "label": 0
                },
                {
                    "sent": "We see kernel methods so we can see the topic just by checking the word.",
                    "label": 0
                },
                {
                    "sent": "For example, here we have image image object.",
                    "label": 0
                },
                {
                    "sent": "Kernel images or.",
                    "label": 0
                },
                {
                    "sent": "Something about images and we can click some point, for example this one.",
                    "label": 0
                },
                {
                    "sent": "And we see this is.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "Future selection challenge.",
                    "label": 0
                },
                {
                    "sent": "Probably this is about was.",
                    "label": 0
                },
                {
                    "sent": "Some of the datasets or something was related to images.",
                    "label": 0
                },
                {
                    "sent": "Reduces object categorization.",
                    "label": 0
                },
                {
                    "sent": "So population of images and so on.",
                    "label": 0
                },
                {
                    "sent": "If you check here.",
                    "label": 0
                },
                {
                    "sent": "Network here is probably some.",
                    "label": 0
                },
                {
                    "sent": "This is some the theoretical parts and these are kernel methods if you check.",
                    "label": 0
                },
                {
                    "sent": "Make sure progression.",
                    "label": 0
                },
                {
                    "sent": "So on.",
                    "label": 0
                },
                {
                    "sent": "So, but just looking at this picture in few minutes, you can have a very good idea of what are the.",
                    "label": 0
                },
                {
                    "sent": "Papers from Pascal researchers covering.",
                    "label": 1
                },
                {
                    "sent": "The second visualization now.",
                    "label": 0
                },
                {
                    "sent": "Each this.",
                    "label": 0
                },
                {
                    "sent": "Yellow crosses a person.",
                    "label": 0
                },
                {
                    "sent": "Put this so these are now the person names are visible.",
                    "label": 0
                },
                {
                    "sent": "So these orange names are document names.",
                    "label": 0
                },
                {
                    "sent": "In this case documents are persons and you can zoom in.",
                    "label": 0
                },
                {
                    "sent": "For example in some area.",
                    "label": 0
                },
                {
                    "sent": "And we can see here.",
                    "label": 0
                },
                {
                    "sent": "What are the researchers and you can see this is?",
                    "label": 0
                },
                {
                    "sent": "Checking into the coffee can see this is text mining area.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "We can, but try checking the people you can see which people are working in this field.",
                    "label": 0
                },
                {
                    "sent": "We can like that no, we have not shown is user profiling.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Lumia it's text mining.",
                    "label": 0
                },
                {
                    "sent": "Tutorial so micropenis.",
                    "label": 0
                },
                {
                    "sent": "Jones Colonel.",
                    "label": 0
                },
                {
                    "sent": "So this is joint for Taylor next to Bernhard Shelkoff.",
                    "label": 0
                },
                {
                    "sent": "I like small eyes here so.",
                    "label": 0
                },
                {
                    "sent": "Thunder.",
                    "label": 0
                },
                {
                    "sent": "Then you can click and you can see all the papers.",
                    "label": 0
                },
                {
                    "sent": "Up stepped in the papers from keys from the key posted on the Pascal.",
                    "label": 0
                },
                {
                    "sent": "So this is these are the demos.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Can also by extending the block.",
                    "label": 0
                },
                {
                    "sent": "For now, this landscape was just the the color of the background.",
                    "label": 0
                },
                {
                    "sent": "If we can use this instead of for the color of the brain background, diffuse it for as a High Peak and through this 3D pictures.",
                    "label": 0
                },
                {
                    "sent": "So this is European projects and.",
                    "label": 0
                },
                {
                    "sent": "I'd like this card is here.",
                    "label": 0
                },
                {
                    "sent": "So and.",
                    "label": 0
                },
                {
                    "sent": "Let's let's also thank you.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Question.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is much faster than this, for example.",
                    "label": 0
                },
                {
                    "sent": "That is money, even if it's for these datasets, it's a matter of seconds, and this one is the method means.",
                    "label": 0
                },
                {
                    "sent": "How can you explain the voice?",
                    "label": 0
                },
                {
                    "sent": "The moment loans near management.",
                    "label": 0
                },
                {
                    "sent": "You can check on that.",
                    "label": 0
                },
                {
                    "sent": "He's very.",
                    "label": 0
                },
                {
                    "sent": "So yeah, because.",
                    "label": 0
                },
                {
                    "sent": "This weekend there.",
                    "label": 0
                },
                {
                    "sent": "Yes, but what is your interpretation?",
                    "label": 0
                },
                {
                    "sent": "Why is there no?",
                    "label": 0
                },
                {
                    "sent": "Doesn't fit into any of these topics.",
                    "label": 0
                },
                {
                    "sent": "The bank is on the power people.",
                    "label": 0
                },
                {
                    "sent": "It could be that we his papers are not just from.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so there's this is not such a big gap.",
                    "label": 0
                },
                {
                    "sent": "Or kernel method, so it's.",
                    "label": 0
                },
                {
                    "sent": "So we can assume who I'm talking about.",
                    "label": 0
                },
                {
                    "sent": "There's no other signs of getting this topic, but not many.",
                    "label": 0
                },
                {
                    "sent": "It is not not many from these, from there, yeah.",
                    "label": 0
                },
                {
                    "sent": "Identified.",
                    "label": 0
                },
                {
                    "sent": "Other words, every dentify, maybe a 6000 feet are not discriminating useless words, so that then speed up in this way that we only focus on so there is.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can already throw out when we do preprocessing, so like this end or this so called stop words.",
                    "label": 0
                },
                {
                    "sent": "Then you can also reduce by.",
                    "label": 0
                },
                {
                    "sent": "Cutting prefixes suffixes are suffixes by popularity timing, so this is one way and another who is this?",
                    "label": 0
                },
                {
                    "sent": "He basically identifies which words are similar, and it's another way of.",
                    "label": 0
                },
                {
                    "sent": "This place is a space CK opening who was developing so-called basic elimination based initially.",
                    "label": 0
                },
                {
                    "sent": "No eight hundreds and then then somebody increased to 1000 and there are there are such which say that anything he needs can be expressed with these 800 words.",
                    "label": 0
                },
                {
                    "sent": "And then I look at this idea.",
                    "label": 0
                },
                {
                    "sent": "We have 3 lines.",
                    "label": 0
                },
                {
                    "sent": "Discard but at least this way you can.",
                    "label": 0
                },
                {
                    "sent": "You know translating from English to basically anything different.",
                    "label": 0
                },
                {
                    "sent": "So we usually deal with this problem with if first 2 hours of town.",
                    "label": 0
                },
                {
                    "sent": "So instead of letting having this kind of basic English usually use this desires expert net, which basically where the meanings of perverts, our senses of the words are organized in this one big three.",
                    "label": 0
                },
                {
                    "sent": "So roughly, we have 100 thousands of sensors, each senses a set of synonyms for each word, and we know that I don't know.",
                    "label": 0
                },
                {
                    "sent": "The hierarchy of the senses of the top level ones are very high level.",
                    "label": 0
                },
                {
                    "sent": "One in the bottom level are very concrete stuff, so one way would be to map the words into this census so the other way which actually is kind of side effectively interesting that this eigenvectors which are identified basically produce sort of set of synonyms for this particular domain, so maybe.",
                    "label": 0
                },
                {
                    "sent": "This set of basic English words.",
                    "label": 0
                },
                {
                    "sent": "Boolean wouldn't cover vocabulary.",
                    "label": 0
                },
                {
                    "sent": "Speech appeared in this very technical texts, so this is the problem.",
                    "label": 0
                },
                {
                    "sent": "So here we can.",
                    "label": 0
                },
                {
                    "sent": "Automatic means to identify this sort of.",
                    "label": 0
                },
                {
                    "sent": "Say people have met the grapple colocations between versions of this.",
                    "label": 0
                },
                {
                    "sent": "Please, if we talk about this, I connected spaces with because of eigenvectors and but basically effects impact this set of synonyms which are automatically identified.",
                    "label": 0
                },
                {
                    "sent": "So this is the way how we deal with this.",
                    "label": 0
                },
                {
                    "sent": "Can you find an item coming bedding dimensions of this?",
                    "label": 0
                },
                {
                    "sent": "These documents is mean you still asleep visualizations.",
                    "label": 0
                },
                {
                    "sent": "Thank you, I didn't try it.",
                    "label": 0
                },
                {
                    "sent": "Where we are aiming for two from it so we didn't really try anything else.",
                    "label": 0
                },
                {
                    "sent": "They just need to know what was in Coleman's office.",
                    "label": 0
                },
                {
                    "sent": "Is minimal inventing promotions.",
                    "label": 0
                },
                {
                    "sent": "Leslie here the goal was mainly this vision.",
                    "label": 0
                },
                {
                    "sent": "Another point of these, going from hundred to two, there are at least that's how much I understand that visible component method using chemical applications you apply to some system system that uses 20 descriptors and principal component with elevated only six ascension.",
                    "label": 0
                },
                {
                    "sent": "So at least they will know that you mention running.",
                    "label": 0
                },
                {
                    "sent": "Maybe you know something.",
                    "label": 0
                },
                {
                    "sent": "So this lattice mannequin this thing is very similar to principal component analysis and.",
                    "label": 0
                },
                {
                    "sent": "One thing we found here that so for using just principle component analysis, for example, it's a linear method.",
                    "label": 0
                },
                {
                    "sent": "Then it's not.",
                    "label": 0
                },
                {
                    "sent": "It doesn't capture enough information if you just put it on 2 dimensions, so.",
                    "label": 0
                },
                {
                    "sent": "It would be because it would be something nonlinear to in order to.",
                    "label": 0
                },
                {
                    "sent": "Capture as much information as possible because it mentions.",
                    "label": 0
                },
                {
                    "sent": "But these are size.",
                    "label": 0
                },
                {
                    "sent": "Is very very similar to this.",
                    "label": 0
                },
                {
                    "sent": "Even in the pilot fire plan, it would be easily to change it.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so all these tools which you saw here before now basically these are all within this so called text Garden software package and basically the actual single tools are the particular.",
                    "label": 0
                },
                {
                    "sent": "Is just set of a pipeline of individual tools like from here, so he could easily exchange.",
                    "label": 0
                },
                {
                    "sent": "PCA.",
                    "label": 0
                },
                {
                    "sent": "Just posted something.",
                    "label": 0
                },
                {
                    "sent": "Did you try send my countries today?",
                    "label": 0
                },
                {
                    "sent": "My kind of crazy 8 if I'm not incredibly say.",
                    "label": 0
                },
                {
                    "sent": "Any other comments?",
                    "label": 0
                },
                {
                    "sent": "OK then, thanks.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        }
    }
}