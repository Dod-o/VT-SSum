{
    "id": "kkldrxie6ffhxdk5xzwlsd3ozhuer2qj",
    "title": "Weighted Deduction as an Abstraction Level for AI",
    "info": {
        "author": [
            "Jason Eisner, Department of Computer Science, Johns Hopkins University"
        ],
        "published": "Sept. 18, 2009",
        "recorded": "July 2009",
        "category": [
            "Top->Computer Science->Artificial Intelligence"
        ]
    },
    "url": "http://videolectures.net/ilpmlgsrl09_eisner_wdal/",
    "segmentation": [
        [
            "Hi, I'm Jason and here are some of my students who also get credit for this work.",
            "I want to argue today that those of you who build systems and develop algorithms, what your algorithms might be doing is weighted deduction."
        ],
        [
            "So we've heard a lot over the past few days about statistical relational learning and it's alphabet soup and question is what all these formalisms have in common?",
            "So there are a lot of answers you could give here.",
            "My answer today is that they all took a lot of sweat to implement.",
            "There's a tremendous amount of collective labor that's going on in this audience to build all these wonderful things.",
            "Each of the letters in the soup was individually handcrafted by graduate student artisans and made to float.",
            "And so beautiful thing.",
            "Now that's probably not the answer you're expecting, so I'll give you another one, which is none of these formalisms is the last story.",
            "You may have thought one was, but then somebody ran into its limitations and came up with another one, so you could tell that none of this is perfect without ever using them, just from the fact that people keep developing them.",
            "Of course, these systems do have more in common with one another than they do with a web browser, for example.",
            "So they share logic.",
            "They share probability, but that makes me think that maybe there should be sharing some of this implementation as well.",
            "So the question is how to how to find the common ground among them that would help you implement the next one more."
        ],
        [
            "Quickly.",
            "This problem isn't limited to SRL.",
            "It's also true elsewhere and AI.",
            "Was I talking too loud before?",
            "Is this better?",
            "This better, it's also true elsewhere in artificial intelligence.",
            "Maybe in other areas too.",
            "I usually publish in the natural language processing community, where we're still doing inference and learning.",
            "But for other kinds of structured models, so our models tend to be various kinds of probabilistic grammars, and our algorithms generally involve dynamic programming or approximations to that."
        ],
        [
            "So let's look at some systems that I pulled down from the web.",
            "These were written by people I respect.",
            "They do a variety of things from language modeling which is trying to find the probability of a sequence of words, information extraction, parsing, machine translation, where I want you to look though is in the first few columns.",
            "So each of these systems which does a particular application is hundreds of files, 10s of thousands of lines of code, and even often 10s of thousands of comments.",
            "So there's a lot of work that goes into this, and that's because these are dealing with large scale noisy data.",
            "The models were complex, the models are also large, so you really have to do search approximations and a lot of software engineering just to give you a sense of where this kind of thing stands in the state of the art machine translation systems at University of Southern California.",
            "A system for translating between Arabic and English will have about half a billion rules, 500 million rules each, which each of which is capturing some little bit of English sentence, and the Arabic that it corresponds to.",
            "So you can imagine there's a lot that has to go into making these."
        ],
        [
            "Things run efficiently, so there's a bunch of problems that arise from the fact that these NLP systems are so big.",
            "The first is you can't just start working on machine translation and build assistant.",
            "You really have to join a team that already has a competitive system.",
            "And once you're there.",
            "You can't, you know.",
            "Just put in any idea that you like because the architecture of the system will make it painful.",
            "You may have an idea which is elegant algorithmically.",
            "It's just you have to tear up too much code to put it in.",
            "And when you do decide to put in some idea from from some other system.",
            "I particularly like this image.",
            "Thank you.",
            "Google Image search the.",
            "Interest.",
            "You can't just take the idea out of somebody else's system and reuse the code.",
            "The idea may be very clear from their paper, but in their code it's all tangled up with the rest of the implementation, and it's specialized to the rest of what they're doing.",
            "So in SRL, you know you may have some nice lifted inference in your assistant.",
            "I can't just take out the lifting module and put it into my system.",
            "I really have to think about how to specialize that to my domain and re implement it.",
            "So I think all of."
        ],
        [
            "This is bad.",
            "And my students and I as a result, often feel like this.",
            "So there's all this stuff that you know you did it in the last system and you're doing it again and spiritually.",
            "It's the same, but there are some little twists that are different.",
            "But when you find yourself doing anything twice in computer science, that means you've missed a level of abstraction."
        ],
        [
            "So the situation outside NLP is maybe a little bit better at president.",
            "These systems were still big.",
            "These are just a few random things I pulled down in computational biology, music analysis, graph layout.",
            "But these systems are still pretty big and they will get bigger.",
            "So if machine vision is like 30 or 40 communities, each of which is dealing with a single task, but people are starting to become interested in putting these together and doing global inference for things like scene analysis and then those systems are going to get large and hard to engineer.",
            "One reaction in the NLP community has often been to build toolkits which play much the same role that modeling languages do in the machine or modeling systems do in the machine learning commute."
        ],
        [
            "So here are some of the toolkits that have been built hidden Markov models, finite state machines, tree transducers, a bunch of other stuff.",
            "Well, these systems were also quite big."
        ],
        [
            "Then again, they don't do everything you want, so one tool that I use quite a lot and I love is a system for working with finite state machines done by the best people in the field.",
            "Runs like the wind, but here is a bunch of things that I want it to do that it doesn't do.",
            "OK, just because you know they targeted at a particular particular set of functions, all of these things we know how to do.",
            "In principle, we could write out the equations, but it would be a lot of work to get them into the system.",
            "So what is it that's common across different toolkit?"
        ],
        [
            "For different modeling languages, presumably there's some level of abstraction in computer science is always built as a stack of abstractions.",
            "We're already doing something here 'cause we're not building applications directly will build them on top of toolkits or on top of modeling languages, so what's under that?",
            "What shared by?",
            "OK, what shared by all the things at this level?",
            "So there's something declarative under here, and something procedural.",
            "So I want to argue that declaratively what's going on is something like weighted deduction.",
            "That weighted deduction could be expressed by weighted logic programs, and it's implemented by something like truth, maintenance on equations.",
            "And I'm going to propose you know particular formalism for writing this stuff down and executing it.",
            "The details of that are interesting, and I'm happy to discuss them, but this is this is kind of the high level picture.",
            "So I'm going to spend most of my time talking about the language and much less talking about the implementation."
        ],
        [
            "But I'm happy to answer questions, so let me be clear what the project is here.",
            "So when somebody has a toolkit or if they have, you know a system like alchemy for mark of logic networks, they are usually trying to get you to design your system in a particular way.",
            "They have a worldview and you're working within that worldview, and that's a great thing because it provides you with guidance Dave encapsulated exactly the right semantics for that approach and.",
            "It you know it's a good approach, and if it works for your problem, then it's going to be exactly up it to the problem.",
            "Dina is different.",
            "It's one level down.",
            "It's a language for expressing the at an abstract level, what the algorithms are doing, so it's still a declarative language because it doesn't express the order in which the computations are done, for example, but it does describe what the correct computations are.",
            "So you specify the data in the computations.",
            "It doesn't know whether their probabilities or not.",
            "It doesn't enforce, for example, of probabilistic semantics.",
            "It's one level lower you could build."
        ],
        [
            "Is on top.",
            "So there's a bunch more beyond this talk.",
            "The first of all this.",
            "The first warning really is that this is this is work in progress.",
            "We did build and release something in 2005 and then this work was on the back burner for a few years.",
            "Although we used this prototype a lot and now now we're working again.",
            "Card on the on the next version so copied on this email because I really would like input from this community.",
            "I started out trying to build something that would.",
            "Encapsulate the.",
            "Kinds of dynamic programming algorithms that are used in natural language.",
            "But eventually I realized that the IT seemed to be applicable to a much wider variety of problems that I knew about and I'd like to make sure that it works for your problems and I would just love to get people involved who have a background in the logic community.",
            "The people who are working on it now.",
            "Either from programming languages or machine learning NLP.",
            "Good."
        ],
        [
            "So I'm going to start with a quick sketch here.",
            "I'd like to take questions during the talk, actually, possibly even a little bit of discussion.",
            "During the talk.",
            "I'm not going to have enough time to cover everything that I'd ideally like to cover.",
            "This is only one hour is not to one hour, not two.",
            "So if you interrupt me with questions, you'll be doing me a favor and the rest of the audience of paper by preventing me from going too fast, yeah?",
            "Isn't it just?",
            "Software.",
            "No, it's really not feature creep actually.",
            "That I don't believe it's restricted.",
            "I mean there there are tackling relatively narrow problems using a single method.",
            "There may be some feature creep in that they have.",
            "So they had an old method and then they came up with a better method and they didn't rip the old method out, so I guess that's possible.",
            "OK, nonetheless it may be that on some workloads the old method works better.",
            "And you'd like the ability to choose among them.",
            "So I mentioned this finite state toolkit they actually have, I think, 17 different implementations of finite state machines, all done with template metaprogramming and so forth, because it matters whether you know you have your rocks or sparse or dense, and whether your you know what kind of way to have and whether the machine is deterministic and whether it's acyclic and whether it's epsilon free.",
            "So they share as much code as possible but there.",
            "Exactly what you want to use depends on your workload, and that's one reason that it's nice to have a compiler that will generate the appropriate code for you.",
            "So template metaprogramming is one way to do it, but that's generating very specific code for you.",
            "The compilers unrolling it.",
            "OK, so let me move."
        ],
        [
            "With a sketch of the language.",
            "So what you do in the languages you write equations and it probably won't come as a surprise to logic people to know that the equations will have.",
            "Well, OK, so we have this issue that there's two meanings of variable here.",
            "So what when I say variable, what I mean is a logical variable, not a variable in the equation.",
            "Let me give you an example.",
            "Here are a B&C are items.",
            "There are things that are being or terms that are being manipulated.",
            "These are not the variables so.",
            "This is a is an integer an A = B * C. Now this looks very familiar, but it doesn't mean what you think.",
            "This is not an assignment, it's a definition.",
            "This is a is defined as be time.",
            "See if B or C changes than a will change as well, OK?",
            "OK, so let's get a little bit more interesting here.",
            "Bees definition is spread out over 2 lines, so this is saying both X&Y are added in to be, so this means almost the same thing as B = X + y. I won't go into the difference right now, so it's a sum of two things.",
            "And why would you want this notation?",
            "Because maybe you have these structured terms, each of which has a value and you're going to add them all into C. And maybe you'd like to do.",
            "Yeah, something like a summation symbol.",
            "So now we're getting interesting.",
            "So C is the sum of Z of N for all N and this is the logic variable, so it's a sum of all the values that are defined as newsy values.",
            "Become as you prove values for Z of seven and Z of 200, and Z of things that aren't numbers at all.",
            "Those will get accumulated into see and if they change their values, change, then see will be updated.",
            "So this is just a pattern and basically giving you a summation symbol.",
            "I hinted that end doesn't have to be an integer, it could be any term."
        ],
        [
            "OK, so so let's get a little more interesting.",
            "Here we have scalar multiplication, so this is now pointwise multiplication of two vectors.",
            "So for every I AI is being defined as be of high time, see above.",
            "OK, pointwise multiplication.",
            "You might wonder how you do dot product.",
            "OK?",
            "Well, if we Levi off here then a is a sum overall be a vittime see of high I is free on the right hand side so we sum over it's possible values.",
            "And it's useful that this might not have to be integers.",
            "For example, you might have a sparse vector, or telling you how often different words appear in a query and another sparse vector telling you how many times words appear in a document.",
            "And this is how search engines work as they take a dot product of these sparse vectors.",
            "So it's nice if they don't have to be integers.",
            "OK, so if you get this one, you pretty much have everything.",
            "This is sparse matrix multiplication, so you want to define the element in matrix A at row and column K, and that means that I and K are bound on the right hand side.",
            "But Jay is still free, and so we're going to some overall JS, so this is just taking many dot products as we took a single dot product here.",
            "This author so far."
        ],
        [
            "OK, good, so you probably see now if you know Prolog, what we're up to.",
            "Prolog has horn clauses means there's one thing on the left, several things on the right, and if you prove these things then you can prove that an all we're doing here is replacing these by what I like to call Horn equations.",
            "So AIK is proved if by J&CJK is proved, but not only do we prove it, but we prove a value for it.",
            "And in this case it's a real number.",
            "In general values could be any term.",
            "So the definition of this comes from the values of other terms B * C is itself a term, and it has a value only if B&C do.",
            "This plus equals is maybe aggregating over zero or one or many things if it aggregates over 0 things, then this hasn't proved, so it has no value.",
            "Now you might expect that the identity that the value of nothing comes in would be 0.",
            "The identity for plus, but in fact if you want that, that's easy to write.",
            "You just say some zero into everything and then it's always proved with value 0.",
            "I and you can add additional values to the extent that beings here approved.",
            "So it turns out to be convenient to have the no value case as well.",
            "OK, so this is kind of like Prolog.",
            "We have nested terms, we can do lists it's Turing complete.",
            "It's unlike prologue and the terms have values.",
            "It's a hybrid of functional programming and logic programming, because the terms are evaluated in place.",
            "So you can think of this as a function which is defined by that we don't just do backtracking.",
            "Backtracking is a terrible idea for for many problems where in dynamic programming, for example, you have structure sharing and there's a type system in their static optimizations and stuff like that.",
            "Yes question.",
            "Logic programming.",
            "It's not actually like constraint logic programming, because each term has one value.",
            "Sorry, each variable has one value and there's no backtracking search to resolve it.",
            "However, you can easily implement constraint logic programming on top of this.",
            "For example, you can have boolean's telling you can this term have this value.",
            "So you can have booleans over that pair, or if you're doing something like downs propagation then you can have one value for the upper bound and one value for the lower bound on the range of that variable.",
            "So constraint propagation is.",
            "Is one thing that falls very naturally out of this framework actually?"
        ],
        [
            "OK, so I want to say just a couple more words about these aggregation operators, so we've seen plus equals.",
            "Let me add another one here, which is min equals.",
            "So instead of keeping running total that keeps a running minimum.",
            "This might be useful.",
            "For example, in Dijkstra's algorithm single Source shortest path.",
            "So if you have the start node, maybe is Brussels then the best path to the start node has weight 0, but if you want to get the best path to W, well, let's see.",
            "If we already have a path to V of wait 10.",
            "Of course, 10 and we have an edge from VW of costs 3.",
            "Then we have a path to W of cost 13, but there are many of these that we could go through.",
            "So we take the best path, minimizing over all of those.",
            "So this is Dijkstra's algorithm."
        ],
        [
            "So you can take any binary associative commutative operator and turn this into an aggregation operator.",
            "So here we have or equals and and equals over billions and prolog.",
            "Pure Prolog brother is just the fragment of Dinah, in which this is the only aggregation operator you have and the types of all terms or just unit.",
            "So if they prove they can only have one value, true.",
            "He said no back.",
            "I I'm just talking about the declarative semantics of the language, not the implementation.",
            "Right, there's no backtracking, so we don't have cut for example, so I'll show you in a minute how we get around the need for something like cut so every ground term has a single aggregation operator, so you can't mix these.",
            "You can't write one line with B plus equals and another line with the min equals some ground terms are open for writing, so they can take if you think about deductive databases at runtime, you may want to feed additional input into them and see what happens to the output to declare those terms as writable.",
            "Rules are defining values only for ground terms, so when you write something with variables in it, you can think of that as a template that expands over many rules, just as in same mark of logic networks you have.",
            "You've got power factors which expand over overall instantiation's.",
            "It would be funny in this case to write something like min equals because there is exactly 1 at most.",
            "One thing that you'd be minimizing over.",
            "So when there's only one one possible value to aggregate over, you can just write it as equals.",
            "So that's a simple definition.",
            "We saw that before, and you can even write this, although it will.",
            "This amounts to an assertion that at Convergence A of X will only be true for One X, so you'll get a runtime error.",
            "This amounts to an assertion of uniqueness, so.",
            "These are not associative and commutative.",
            "Here we have: equals and here are the order of.",
            "The program is important, so: equals is like is like override the last thing wins and this is particularly important if you want to be able to replace values of axioms at runtime.",
            "So you change the value of a fact.",
            "In this case it's being done not at runtime, but right in the program.",
            "So we say all birds fly.",
            "Oh, except we're going to override that and say that Penguins don't fly and Big Bird doesn't fly.",
            "You might not want to worry bout this ordering, so we also have a syntactic sugar where which basically translates into this were the most specific winds.",
            "So this says Fibbonaci 0 then first pinacci elements or zero and one and then thereafter.",
            "So these override this general rule which says fibbonaci of access financial of the two previous things.",
            "And note by the way, that these are structured terms.",
            "This is minus with two arguments X and one, but that evaluates in place, it's replaced by its value."
        ],
        [
            "OK, any questions?",
            "This is meant to be a right arrow.",
            "OK, so.",
            "There are many intellectual debts here, so in natural language processing there's been a lot of work on deductive parsing and weighted deductive parsing, where you have a bunch of words and you want to make them coherent two phrases and eventually into a sentence, and I'll show you how that plays out, and I know soon, but that was kind of my starting point.",
            "There was a tradition of deductive databases in the 80s and 90s.",
            "Not much work on that anymore, but I'm also indebted to that there's been a lot of work in theorem proving where you start with facts, and again you do some kind of forward chaining inference.",
            "And there's been a bunch of previous work, so Dinos, really a kind of hybrid functional programming and logic programming.",
            "There's been as you guys know, very well.",
            "A lot of work in probabilistic programming languages, some of the things we're doing for efficiency like mode system have been done elsewhere.",
            "Also, this business of outputs changing when inputs change have been pushed have been pushed quite hard in the functional programming world, about a car recently, and there's other stuff that's relevant also."
        ],
        [
            "OK, so now I'm going to show you some examples, but first I want to give you the big picture of why I think this is a good abstraction level.",
            "So what is it that we're doing in SRL, for example?",
            "Or an L?"
        ],
        [
            "So here's how I usually think about building a system.",
            "The system is going to deal with something like probabilistic context free grammars.",
            "So first I have to come up with the formalism and that, but the mathematical formalism isn't quite enough.",
            "We want to come up with some equations to compute.",
            "Results may be approximately given some input data, so this is a generative formalism, but we're not really going to get a parse by generating all possible trees and seeing which sentence matches your input sentence.",
            "You're going to do something bottom up where you are given the input sentence and just want to construct the trees for that.",
            "So some of you may recognize this as the formula for the inside probabilities of constituent.",
            "If you don't, that's fine, given these equations you want to come up with some way of actually computing the result sufficiently so you pick an execution order and then you have to worry under the hood about some engineering."
        ],
        [
            "OK, Donna is dealing with this level.",
            "You're writing down these equations and you write them down as these kind of variable template equations, horn equations.",
            "And the observation is that well, beyond our community, what most programs are doing.",
            "At least programs without side effects is computing some values from other values, and the order in which you do that is immaterial.",
            "So feedforward networks, dynamic programming, anything with message passing.",
            "You're just computing values from other values.",
            "OK, one thing you have to do to make this sufficient is to quickly figure out what influences what, so maybe you've got some big state space and reinforcement learning and you want to figure out quickly what moves are available to and what states you can get to.",
            "From here you're doing, you know Gibbs sampling or something, and you need to be able to compute the Markov blanket quickly, so.",
            "Unification."
        ],
        [
            "For example, as useful for this, the I should point out that these equation at the examples meant clear.",
            "These equations could be cyclic.",
            "Some programs also need to update the outputs of the inputs change.",
            "That is the value proposition for spreadsheets, and for Makefiles.",
            "It's also why people work on dynamic algorithms.",
            "So you mean you don't want to recompute things from scratch?",
            "So this kind of stuff happens in our community as well.",
            "If you think about, say, MCMC or DPL, or walks out or something, you're messing with one variable to flip it, or you assign it, and you want to see what happens as a consequence happens in constraint programming also.",
            "When you're doing training, you mess with the parameters and you need to see how that changes your objective function, or if you're doing cross validation, you take out each example intern.",
            "When that example is out, you see how that affects your objective function.",
            "You shouldn't have to make very many changes because your data didn't change very much, so you see how that affects your objective function, or you get a in approximation to that in to do that for you, and then you see how that new model does on that held out example."
        ],
        [
            "OK, so we'll come back to these execution strategies later."
        ],
        [
            "So what I'd like to do is by using these mechanisms is to support some of the common threads in NLP SRL knowledge representation and reasoning, data mining, graph mining and so on.",
            "So one thing that happens across these areas is pattern matching, so you're matching patterns against structure.",
            "You've got structured objects of some kind, and they represent things like, you know, states in a state space or or variables in a in a complicated.",
            "Unrolled model with exponentially many variables to.",
            "These are structured objects and you need to be able to structure them.",
            "There is message passing of some kind among the terms, and that's what we're implementing with these horn equations.",
            "So the easiest one is, you know, tag, you're it were approved.",
            "So now you're approved also, so that's just that's bottom up inference.",
            "Or if you're forward Channing, or if you're doing top down inference, backward chaining, it's oh, we got queried, and so now we have to query you as well.",
            "There's probabilistic inference, so in something like Prism you are trying to keep track of the total weight of all proofs of a proposition.",
            "So before someone asked about constraint programming, so our consistency is here, my domain has been reduced, so let's reduce your domain and the soft version of that is belief propagation.",
            "So my belief is updated.",
            "That should influence your belief.",
            "If you're doing something that's course defined, like like box propagation or any other course defined method is also true in downs propagation.",
            "As you get better and better estimates of some value then that sharpens the estimates of your neighbors values Gibbs sampling.",
            "You flip your value.",
            "Your neighbors have to flip.",
            "Sometimes you may just want to scan a lot of data.",
            "Or scan the scan, for example the proof trees that were imputed given some data and count up the number of times a particular rule or feature or shout out to the ML.",
            "Two people here are the number of times a sub graph gets hit, so you're looking for a particular configurations every time you prove that that that that sub graph exists.",
            "That's a little forward chaining proof to detect that right and you want to keep count of those anytime you've got dynamic programming, you can think of that as message passing.",
            "In fact, the forward backward algorithm is just belief propagation on a chain graph.",
            "And whenever you have dynamic algorithms, you're updating some input and now you want to update your intermediate quantities, and eventually your output.",
            "Good, so that's a long list.",
            "If you're getting messages from multiple sources, you have to be able to aggregate them.",
            "This shows up in all these domains.",
            "Finally, you may have some kind of default reasoning, so we've heard a lot over the last few days about lifted inference, which I think is primarily reasoning at runtime with non ground terms.",
            "So terms that contain variables before they shatter against data if you do it at compile time, that's program transformations.",
            "Where your reasoning about the program before you've seen any data, and when you've seen some data, then you say, well, ordinarily I would infer this variable from these variables, but oh, we're going to override that 'cause we actually observed this variable.",
            "So we're going to use this: equals operator to do something nonmonotonic override that conclusion for this particular variable for this particular instantiation of this variable, and then those exceptions will propagate through this influence graph of equations.",
            "So once you've shattered once you've shattered this, you may after that as well.",
            "So finally, you may want to look at the proof forest that you get out, and generally when you're training you want some automatic differentiation in there, and even the prototype supports that quite nicely.",
            "OK, let me pause again.",
            "If there are any questions or else I'll move on.",
            "OK."
        ],
        [
            "So I want to make 1 one final point here, which is that I said that before that Diana was agnostic about what the semantics of all these values are OK, and the reason is that even among the programs say that my students and I write, which is, you know, one lab what we use real numbers for, differs very widely.",
            "So real numbers are not the only thing you can use, but let's just look at those so.",
            "And in some systems, the real numbers are always probabilities, but they might be unnormalized probabilities.",
            "They might be log probabilities.",
            "You might be doing belief propagation, in which case there are approximate probabilities, so you're not enforcing a true probabilistic semantics the way something like probably would do.",
            "There might be strict bounds on probability.",
            "Is one place where this shows up is if you have in a star heuristic.",
            "You might also have inadmissible heuristics which are not strict bounds, but there are good approximations and you might try to learn these heuristics to be able to trade off accuracy and runtime.",
            "Some of the things that you're looking at, or just parameters of your model like feature weights or if you have to variationally approximate something, then their parameters of that approximation.",
            "Sometimes I said you're just counting things, so you want to know how often something happens in your data.",
            "That might be the strength with which a feature fires.",
            "If you're doing Gibbs sampling something like a Chinese restaurant process, you need to know how many customers are sitting at existing tables.",
            "You need to maintain that dynamically so these are maintaining integers or something.",
            "In the case of graphs, maybe you need to maintain degrees for the same reason when you're trying to do you know, edge prediction in graphs?",
            "If you're doing neural Nets, these things aren't probabilities.",
            "There activations we saw at least two papers here which were real numbers were utilities or preferences.",
            "You might want to take expectations over those utilities or risks.",
            "In order to do some kind of loss based training, sometimes you measure in training.",
            "You measure things like entropy or regularization.",
            "And finally you take derivatives so.",
            "This is why I don't want to say real numbers are always probabilities.",
            "You just need to be able to have some kind of equations relating real numbers."
        ],
        [
            "OK, so one more slide in this section.",
            "Sorry.",
            "Some of the common issues and implementation are you need to be able to store things efficiently so we have all these messages that might get computed, but you have to get them efficiently.",
            "That usually means doing unification and it also means when you have normalized or tabled computations or facts then you need to be able to index them so you can look them up quickly.",
            "Too much indexing can be if you index things that you're never going to retrieve, that's a waste.",
            "So you need to decide what to index and if things aren't indexed then you may have to do something like a database query because maybe you were doing a join and so query planning may come into play and I think a lot of what these big systems are doing is specialized implementations of these things which work well for a particular workload.",
            "One thing that's very important is deciding which messages to send and when, so you can do bottom up from the data that's forward chaining.",
            "Then you have a problem of which messages to pass first in the unweighted fragment, like Prolog.",
            "This order doesn't matter very much, but it can matter quite a lot in the way wedded fragment in backward chaining.",
            "Then you have to decide what to memorize and whether you memorize it forever.",
            "And then you have to worry about how to update your memos because they may become invalid.",
            "When the input changes, so there's there's a lot of hybrid strategies here.",
            "If I had more time, I'd give you a unified view of what all these strategies look like.",
            "Feel free to ask me about that, and then there's lots of tricks that have shown up in various places in the literature.",
            "If you know the state of the art and sat solving, this is one of the beautiful tricks, and it turns out it generalizes quite nicely.",
            "So we can put it in this framework.",
            "And yeah, people sometimes want to be able to do transformation on their transformations on their code, so it's nice to have a language like Prolog or Lisp for that matter, where your code looks like data and you can do.",
            "You can take your list of rules and be able to manipulate them in directly in the language at runtime if necessary, and you might want to do parallelization.",
            "That's still future work for us, but."
        ],
        [
            "I have some ideas.",
            "OK questions.",
            "Alright, so now I want to tell you a little bit first about about how to parse.",
            "So at a curiosity, how many people here know how to build a basic bottom up chart parser of any kind?",
            "Oh, good, a surprising number of people.",
            "OK, so for those of you who don't, I'm not going to argue that even if this language you know never gets implemented at all, it's still a great way to teach you parsing.",
            "And you know 60 seconds or something so you know it's a good mathematical notation for explaining the structure of."
        ],
        [
            "Algorithms, so this is the inside algorithm which figures out the probability of a sentence under a probabilistic context free grammar, and there's only three things here.",
            "One says that a word is a phrase, one says.",
            "If you have two phrases next to each other, there a phrase and one says you're building things up.",
            "Gradually, phrases next to phrases make bigger phrases.",
            "And finally, if you've got a phrase that covers your entire input sentence, you've gotta complete parse.",
            "So let's look at this a little more carefully.",
            "If you have a word W. From position I to position J in the sentence.",
            "Then you have a phrase of type X from position Ida position J.",
            "If your grammar says that X can rewrite as as that word W. So you've built up a word into a phrase of type X."
        ],
        [
            "Here you've got a phrase of type.",
            "Here you've got a phrase of type Y that stretches from I to some midpoint and another phrase of type Z saying noun phrase and another phrase of type Z's.",
            "For example, a verb phrase which stretches from that midpoint to J and that allows you to build in X from Y all the way to J, provided that X can rewrite as two parts, namely why NZ.",
            "So graphically, we're putting this this and this together.",
            "This is the grammar rule.",
            "These are the things we've already built bottom up, putting them together into that there may be many ways to build this, and so we're summing over all the ways of doing it.",
            "To get the total prob."
        ],
        [
            "And finally the.",
            "This here evaluate so if your sentence is of length 30, then if you have a phrase of type sentence from zero to 30, then you've reached your goal.",
            "So this is just a convention that if you have one output, you'll call it goal.",
            "OK, so in the prototype that we had a C++ API to this, and here's how it worked.",
            "The facts that come in from outside or you are the things that are underlined here are the words of the sentence.",
            "The length of the sentence and the rewrite rules in your grammar.",
            "And so here's a C interface.",
            "So here what we're doing is we're stating the facts that don't that aren't actually defined by the program, so these underlined axioms here.",
            "So we're putting them into our chart or database.",
            "So we say that the probability of this if you've got a sentence 70% of the time, it's a noun phrase followed by a verb phrase.",
            "We said Pierre is definitely a word that stretches from position 0 to position one.",
            "We read some more stuff in from standard input, and then when we do the query it does the computation on an as needed basis, and this their own pops out.",
            "Which is the value we wanted."
        ],
        [
            "OK, so I built visualized with some undergraduates.",
            "This can visualize very large or infinite graphs and things sort of come into view as you navigate through the graph with the keyboard.",
            "Here at the bottom we have.",
            "These are the facts that came in, so these blue things, or the grammar and this these pink things are the.",
            "These pink things are the.",
            "The words of the sentence, and here's the theorem that popped out at the top.",
            "Here we have some ambiguity.",
            "Here.",
            "We have a something which we built but didn't help lead us to A to approve.",
            "Here we have something which showed up in two different.",
            "Sorry this ambiguity there are two ways to build this, so we're summing over both of them.",
            "And here's something that we built in it.",
            "Participated in that proof, and it also participated in that proof.",
            "So this is showing why."
        ],
        [
            "Tabling or memos."
        ],
        [
            "It is useful.",
            "So I want to make a few other points about this before moving on.",
            "One is what I said so far is that the grammar rules are just facts which come from the outside world.",
            "But we could define define them in other ways.",
            "So here I'm defining every.",
            "Ability of the ways of rewriting X using a little conditional log linear model.",
            "So these are unnormalized probabilities.",
            "So the unnormalized probability of rewriting X as a left child Y Ana right child Z.",
            "So that's a rule in your grammar.",
            "We're going to multiply a few things together with times equals, so there are some weight that says does X like to have Y as its left child does act like tabs E as its right child do X&Y&Z like to be siblings?",
            "This one will only get multiplied in.",
            "In the case where the two siblings are identical, so maybe you learn that's a good thing or a bad thing.",
            "You multiply these together.",
            "These give you unnormalized probabilities.",
            "So now here we're summing over all Y&Z to get the total unnormalized probability of the rule of all rules that started X.",
            "And then if we divide through by that total probability, Now we have proper probabilities which just fit into this.",
            "So we've just written a little model directly within the language and you might trend these weights on data.",
            "Questions.",
            "OK, I'm going to take this example here, which I hope you understood question.",
            "And I I want to go through several variations very quickly."
        ],
        [
            "So if you're only trying to find the best parse, how would you do that little quiz?",
            "You should be able to figure it out.",
            "This is summing over all parses."
        ],
        [
            "Yeah, Max equals instead of plus equals."
        ],
        [
            "Right, good if you want to work in the log arhythmic domain.",
            "So then instead of if these are log probabilities instead of probabilities, you add them instead of multiplying them.",
            "If you want to go back to the inside algorithm, then you could.",
            "You could use this log plus operation, which basically exponentiates adds and takes the log again, although with.",
            "Other with less loss."
        ],
        [
            "Precision.",
            "Lattice parsing, so most parsers don't do this, but you may have.",
            "A finite state machine which describes all the hypothesis of a speech recognition system and you want to find the.",
            "You want to pick a particular path of that which has a good weight as a path, so the speech recognizer likes it, and it also has a good parse.",
            "So how would we change this program?",
            "To be able to parse this finite state automaton, which encodes an exponential number of strings.",
            "It's a trick question.",
            "We don't have to change the the program at all.",
            "We only have to change the input.",
            "So this originally we would have said the word Pierre goes from zero to one.",
            "But now well, Pierre goes from State 5 to state nine.",
            "It's also possible that it's the word P. The letter P followed by the word error.",
            "So instead of saying that PR goes from zero to one, we just say it goes from State 5 to State 9.",
            "Now instead of putting integers here or, we put objects which describe states in your machine.",
            "But it's exactly the same algorithm."
        ],
        [
            "I'll skip this."
        ],
        [
            "If you wanted to do not PCFG is but do global normalization so you're just doing weighted parsing and the goodness of a parse is the product of all the rules in the Paris, but nothing else.",
            "To sum to one again, these things aren't necessarily probabilities, so there's no change to the program.",
            "If you want to use fancy or kinds of grammars which pay closer attention to the words, or work with multiple parse sentence in its translation at once and get a single unified analysis which lines up the scent."
        ],
        [
            "With this translation, it's very similar to this program.",
            "You can manipulate it almost mechanically by saying instead of this having three subscripts, three arguments, it's going to have five arguments, so two positions in the English sentence, two positions in the Chinese sentence."
        ],
        [
            "OK, so let me just say a quick."
        ],
        [
            "Word about about this because it illustrates a more general point.",
            "So here this was a rule that we had in our original program, and as we saw, we could see it as taking this and getting that out of it.",
            "Turns out that we can get a little bit of an asymptotic speedup by going through this intermediate stage, where first we combine this piece with that.",
            "And then we combine the result with this and that's because we.",
            "So basically we turn this into 2 rules, one of which produces this intermediate thing, one of which produces this output.",
            "Now this original rule had six variables, but it should.",
            "These rules only sums over only is dealing with five variables at once to end up getting an asymptotically speed up.",
            "This is the classical folding transformation in logic programming, and this is really just a weighted variant of it, and it takes advantage of the distributivity of plus over times.",
            "So the general question.",
            "It is similar to dotted lists in say Early's algorithm, where you forget the part of the list that you've already matched.",
            "So here, once we've matched Z, all we remember is that there's a wide left and we forget that we've met City.",
            "So.",
            "Completion in.",
            "Yeah, let's save that till later.",
            "Actually, 'cause I want to.",
            "I want to talk a little more generally about this."
        ],
        [
            "So.",
            "In essence, what we've done here is, we've just taken this one of the summation symbols, and we've moved it further inside.",
            "And this is exactly what happens when you're doing variable elimination, for example.",
            "So also another example of that letter that's also a traditional thing to do in India."
        ],
        [
            "Best joins.",
            "OK, so the general point here is that we have a system of equations.",
            "Now you've all studied Gaussian elimination, so you know that there are lots of ways to rearrange a system of equations to make it easier to solve.",
            "In fact, a lot of linear algebra is about, you know, decomposing and rewriting systems of equations to make them faster or.",
            "Better condition, so if you transform from one to the other, it may be a win and there are a lot of tricks that I know from the world of parsing, for example, which can be generalized into these transformations.",
            "This is this.",
            "A really neat paper.",
            "It goes quite slowly and it doesn't assume you know anything about parsing, and it shows a number of things which are sort of analogous to lifted inference, although only at static time.",
            "Some of what you're doing is trying to do essentially what you're doing is, you know, transforming an algorithm from end to the fifth time to end cube time by delaying work and working for longer and a lifted domain before you've seen the input, so you can eliminate unity rule cycles and.",
            "You can, you can play some games where you speculate about what how certain variables are going to be instantiated.",
            "And do computation based on that speculation.",
            "In the left Dome."
        ],
        [
            "OK, so let me send."
        ],
        [
            "Buddy asked about all this algorithm.",
            "Here it is.",
            "It's about 6 lines and there's the magic templates transformation.",
            "If you know that from logic programming transforms from this into that.",
            "So you get that for free.",
            "That was actually noted more than 10 years ago, but it turns out that if you run the magic templates transformation one more time on this then you get something called the left corner filter, which is what you really need to get this run fast so it's nice to have these general transformations that you can use to rearrange your equations before you."
        ],
        [
            "And run them."
        ],
        [
            "OK, so I just want to point out that there is something a bunch of stuff that we were able to do with the prototype.",
            "These are all papers that came out of my lab and they all used.",
            "They all used on it for implementation.",
            "And I've been using it for teaching for awhile as well."
        ],
        [
            "OK, good, so I'd like.",
            "I'd like to give you some more examples and say a little bit about implementation, but let me just actually let me let me just take a little vote on who would like to hear more about which.",
            "So who would like the four things that I could talk about in the remaining 15 minutes in greater or lesser degrees?",
            "Or give you a few more details of a language.",
            "So like 10 slides simple slides I could give you some more practical examples.",
            "I could tell you a little about what's going on to actually run inference under the hood.",
            "Or I could talk a little more about program transformations, so would like to say more about vote as many times as you like.",
            "It would like to see more details of the language.",
            "OK, one that's interesting.",
            "OK, maybe I'll show you something anyway, but more more practical examples.",
            "Good, a lot of people implementation, so the inference algorithms.",
            "A lot of people and program transformations.",
            "OK yeah, so you know you can.",
            "You can stay late or something and we'll huddle up here during the break.",
            "Let me give you just."
        ],
        [
            "To give you a few details of the language just so you'll understand the example, so I'll skip some of this.",
            "You may have guessed that the basic objects are terms, as in Prolog, and I won't.",
            "I don't think I really need to say more about this, 'cause apparently you don't care, so I'll leave this slide up and you can go read it on videolectures.net."
        ],
        [
            "The.",
            "I do want to say a word about the semantics, so there's a fixpoint semantics which say basically you could update these equations to convergence, and if you if all of the left hand of the heads of all your rules are consistent with the bodies, then your valid and you can return.",
            "You might run forever, so then you shouldn't have written that program, it was a bad idea, the.",
            "There may be multiple fixed points, and in that case we don't give any guarantee because I think that's what killed the deductive database community was arguing about, which fixed point to get.",
            "I'm going to trust you to write a program where you'll actually get the fixed point that you want when you run it.",
            "So this is.",
            "You've got various terms in this in this diner base.",
            "It's so in Prolog, the semantics is basically the set of proved things, and here it's a map from proved things to their values, which are other terms.",
            "So one thing that I do want you to understand is that the database is only defining values for ground terms, and what these variables do is it lets us define values for infinitely many ground terms."
        ],
        [
            "So."
        ],
        [
            "I want to say one more thing that you'll need just to get the notation in the examples, which is that these Maps were actually first class objects, which is quite convenient for modular programming.",
            "So Edina base can appear as a subterm of another term, or as the value of another term.",
            "So here we've got two finite state transducers, and if we compose them we get another finite state transducer.",
            "So the definition of compose is taking two databases and producing another Dyna base if.",
            "Either of these changes then this.",
            "If any part of either of these changes, then this will change as well.",
            "We don't have to recompute the whole thing from scratch, only the relevant parts will be re computed.",
            "So we might say that FS T4 has a particular edge in this finite state machine and its weight is derived in part from the weight of some.",
            "It's reversed edge in FST 3.",
            "So in principle we could be shipping these done.",
            "I mean, we really do want to do this.",
            "We could be shipping these databases around.",
            "I could take some deductive database which had some mixture of data and an algorithm and so forth and send it to you.",
            "And then you can pull things out of it.",
            "Could be a website."
        ],
        [
            "This actually.",
            "Alright, so.",
            "I could say more about.",
            "About databases and.",
            "How do you create them and modify?"
        ],
        [
            "Them and so forth, but I."
        ],
        [
            "Skipping this"
        ],
        [
            "I as well as the subsequent things be."
        ],
        [
            "As you want to hear the exam."
        ],
        [
            "Good, OK, so now let's take a vote on these examples.",
            "So who wants to share more about shortest paths?",
            "Neural networks we should look at that one actually just 'cause it's different information retrieval.",
            "Intersection of finite state machines.",
            "OK.",
            "This is kind of course defined parsing, so it has something in common with lifted inference.",
            "This one is a little bit hard to understand, but I'm happy to go through it.",
            "It is still short OK. Smoothing of Markov models.",
            "OK, art consistency.",
            "OK, maybe a couple more people 'cause you know that one mini Max in game trays?",
            "OK, edit distance.",
            "OK, so a bunch of votes were edit distance, so let's I'll pick some water here.",
            "I didn't see a strong consensus for any of these."
        ],
        [
            "OK, so here is neural networks, so for any of these nodes, the input to a node we look at the output of its child.",
            "So summing over all children and we multiply that by the weight of the of the connection from that node to the child.",
            "So this is the input to a node is just a linear combination.",
            "Overall it's children.",
            "That's easy enough.",
            "OK, except there's one more thing it might be, you know getting some external input which is providing the providing the actual example that you're training the net on.",
            "So where's the nonlinearity?",
            "The output of a node is a sigmoid function of the input, so we can define the sigmoid function right?",
            "And I know their names.",
            "And you'll notice that this no longer has distribution semantics.",
            "So in the case of context free grammars for parsing, it was the case that the value of a of an item was the sum of the values of all of its proofs, but that's not the case here because we're passing through a sigmoid squashing function at every level.",
            "Yeah question.",
            "You're right.",
            "I haven't said anything here that says that these arcs can't be cyclic, and it will just iterate to convergence, which is actually the classic classical thing that was done in neural networks.",
            "You could tell it you could give it a convergence criterion.",
            "But and what's more, it will do back propagation around the converge loops, which is what's called backpropagation through time.",
            "So that's the automatic differentiation, and I think that was first proposed by Williams and Zipsor and like 89.",
            "OK, yeah we can take this offline.",
            "So if you want to measure the error, that's just the square difference between the output node output of nodes and their targets.",
            "But notice that this is only provable when there's a target defined for that node, so we wouldn't want to say that this is zero if it's not defined, it just doesn't.",
            "It has no value if there's no target to find, so it doesn't contribute to this sub.",
            "So this is 1 example where it's helpful to have the notion of no value.",
            "Doesn't need to approve.",
            "OK. Good.",
            "So let's see.",
            "Let's skip that one.",
            "So let's do something easier than vector space.",
            "I mean then.",
            "Then our consistency before we get there.",
            "Actually."
        ],
        [
            "Let's do finite state interest intersection.",
            "This isn't too bad, so so that you can read this.",
            "These are just constructors.",
            "There infects functors, so we have two databases representing finite state automata ANB, and we're going to find a new one with this name.",
            "OK, so this is A intersect B.",
            "And it states are going to be pairs of states in the original machine, so this is our pairing.",
            "Just think of this as meeting pair Q, R, just using syntactic sugar.",
            "So this says that the start state of the new machine is the power of the start states of the old machines.",
            "That Q cross R is a stop state in the new machine.",
            "If Q was a stop state in A&R was a stop state and B and then this is the interesting thing.",
            "This is saying that we have in arc from Q1 to.",
            "Are one sorry from the para Q1R1 to Q2R2 labeled by a letter.",
            "If we have the corresponding arcs from Q1 to Q2 and R1 to R2 in the old machines and the weight is given by by product rule, which is the standard thing to do.",
            "For reasons I won't go into and this generalizes to finite state transducers, so this will actually compute as I've written it will compute unreachable parts of the graph, but it's very easy to modify the program.",
            "So that it only computes things that are reachable from start, and in fact that's just another instance of the Magic templates transform."
        ],
        [
            "OK, so so let's do art consistency.",
            "So here is how our consistency works.",
            "For those of you who don't know it, XXYZ&T are all random variables.",
            "Maybe I shouldn't say random variables, they're all constraint variables.",
            "Each can be something from one to three, so X is required to be less than Y.",
            "That means it can't be 3 because three isn't less than anyway.",
            "Now, similarly similarly, why can't be one?",
            "Because that's not greater than any X.",
            "Well, given that, why is it can't be one?",
            "Z can't be one either.",
            "'cause one isn't equal to any Y that's left.",
            "OK, so this is a in agenda algorithm.",
            "It's basically you're just propagating updates, one is.",
            "Because let's say so 3 isn't less than anything in Z.",
            "So we can continue crossing these things out and eventually we can solve the whole problem just by propagation, no backtracking.",
            "OK, so so let's go through those.",
            "So we need to start out either by rule or by enumeration by defining some axioms.",
            "So first of all we say with the domains are, so a colon here is just a pairing term as it was in the last example.",
            "So this is saying a particular variable value pair is allowed at the start and then we say these are constraints this value.",
            "Of this variable is consistent with that value of that variable, and you can make these default to true or false or whatever you want.",
            "No, you say that a value is still possible for a variable if it was in the domain of that variable to begin with.",
            "And if this is a conjunction.",
            "So it's got to be in the domain to begin with and for every other variable which cares every other variable which asserts some kind of support, so some of them may not be able to prove support is either true or false, but for the ones which, which state?",
            "A preference variable to that states are preference.",
            "It must support that that value in that variable.",
            "And why does it do that?",
            "It does that so variable two supports that value of variable one.",
            "If there is some value that still value 2, that's still possible for variable two has not been crossed out yet, which is consistent with this value of variable one.",
            "OK, so this just iterate to convergence and that's our consistency and this will compile into the asymptotically optimal algorithm.",
            "If you just run forward chaining.",
            "Yes.",
            "Got it.",
            "OK, so.",
            "So let me say here's edit distance."
        ],
        [
            "I'm just going to flash these up quickly.",
            "We started at like 5 after or something 10 after.",
            "OK, then I better wrap up.",
            "OK, let me let me run over a few minutes if I may.",
            "OK, so we have.",
            "OK yeah, here are a couple of versions of edit distance for those of you who wanted to see it, sorry.",
            "This was the generalized Daystar parsing.",
            "I'm happy to talk to people afterwards."
        ],
        [
            "It's probably worth mentioning that you can do iterative update algorithms quite nicely by saying a updates as a function of B and vice versa.",
            "This is your initial condition, but as soon as you prove some value for B it overrides the initial condition.",
            "Using: equals OK, so.",
            "I guess I won't get to talk at all about the execution strategy, even though somebody wanted to hear a lot about it.",
            "So the the simplest strategy is forward chaining and.",
            "That's what the.",
            "That's what the prototype does, and there's a lot to get that to work, but the."
        ],
        [
            "So there's a number of issues in forward chaining in this more general circumstance where you're not just doing semiring weights on your programs.",
            "The including this is where the lifted inference stuff."
        ],
        [
            "One has to do with priorities and how you might compute the priorities directly within the program.",
            "So how you decide which updates to propagate next is also done by Donna Rules."
        ],
        [
            "It's very wasteful to do all your computation by forward chaining, and so sort of the interesting action at the moment is in mixing forward and backward chaining, and we do have a unified picture of how to do this.",
            "The interesting question is how to learn the right strategies on a particular workload, so I won't talk about."
        ],
        [
            "But I automatic differentiation, which essentially symbolically gets the gets computations of the algebraic derivative.",
            "OK.",
            "So I'll skip over the program transformation stuff.",
            "Here we've got variable elimination.",
            "There we just transform the program."
        ],
        [
            "OK, so here's my summary.",
            "It's the AI systems are currently pretty hard to write and modify, and in thinking about how to simplify our job in NLP systems, I think I inadvertently hit on a layer of abstraction.",
            "You know, as we generalized it to do just one more thing in NLP.",
            "Eventually we started to converge to something that looked like it was useful.",
            "Now, for almost all the systems that.",
            "That I'd like to build, or that I see other people building and I'm envious of.",
            "So the simple and powerful idea is that you're defining values from other values by weighted logic programming, and that there are lots of ways to try to bring these values into compute the values when you when you need to, and to bring the heads of rules into.",
            "What's the word?",
            "I want to make the heads of the rules line up with the bodies."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi, I'm Jason and here are some of my students who also get credit for this work.",
                    "label": 0
                },
                {
                    "sent": "I want to argue today that those of you who build systems and develop algorithms, what your algorithms might be doing is weighted deduction.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we've heard a lot over the past few days about statistical relational learning and it's alphabet soup and question is what all these formalisms have in common?",
                    "label": 1
                },
                {
                    "sent": "So there are a lot of answers you could give here.",
                    "label": 0
                },
                {
                    "sent": "My answer today is that they all took a lot of sweat to implement.",
                    "label": 1
                },
                {
                    "sent": "There's a tremendous amount of collective labor that's going on in this audience to build all these wonderful things.",
                    "label": 0
                },
                {
                    "sent": "Each of the letters in the soup was individually handcrafted by graduate student artisans and made to float.",
                    "label": 0
                },
                {
                    "sent": "And so beautiful thing.",
                    "label": 0
                },
                {
                    "sent": "Now that's probably not the answer you're expecting, so I'll give you another one, which is none of these formalisms is the last story.",
                    "label": 1
                },
                {
                    "sent": "You may have thought one was, but then somebody ran into its limitations and came up with another one, so you could tell that none of this is perfect without ever using them, just from the fact that people keep developing them.",
                    "label": 0
                },
                {
                    "sent": "Of course, these systems do have more in common with one another than they do with a web browser, for example.",
                    "label": 0
                },
                {
                    "sent": "So they share logic.",
                    "label": 0
                },
                {
                    "sent": "They share probability, but that makes me think that maybe there should be sharing some of this implementation as well.",
                    "label": 0
                },
                {
                    "sent": "So the question is how to how to find the common ground among them that would help you implement the next one more.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Quickly.",
                    "label": 0
                },
                {
                    "sent": "This problem isn't limited to SRL.",
                    "label": 1
                },
                {
                    "sent": "It's also true elsewhere and AI.",
                    "label": 0
                },
                {
                    "sent": "Was I talking too loud before?",
                    "label": 0
                },
                {
                    "sent": "Is this better?",
                    "label": 0
                },
                {
                    "sent": "This better, it's also true elsewhere in artificial intelligence.",
                    "label": 0
                },
                {
                    "sent": "Maybe in other areas too.",
                    "label": 0
                },
                {
                    "sent": "I usually publish in the natural language processing community, where we're still doing inference and learning.",
                    "label": 0
                },
                {
                    "sent": "But for other kinds of structured models, so our models tend to be various kinds of probabilistic grammars, and our algorithms generally involve dynamic programming or approximations to that.",
                    "label": 1
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's look at some systems that I pulled down from the web.",
                    "label": 0
                },
                {
                    "sent": "These were written by people I respect.",
                    "label": 0
                },
                {
                    "sent": "They do a variety of things from language modeling which is trying to find the probability of a sequence of words, information extraction, parsing, machine translation, where I want you to look though is in the first few columns.",
                    "label": 0
                },
                {
                    "sent": "So each of these systems which does a particular application is hundreds of files, 10s of thousands of lines of code, and even often 10s of thousands of comments.",
                    "label": 0
                },
                {
                    "sent": "So there's a lot of work that goes into this, and that's because these are dealing with large scale noisy data.",
                    "label": 0
                },
                {
                    "sent": "The models were complex, the models are also large, so you really have to do search approximations and a lot of software engineering just to give you a sense of where this kind of thing stands in the state of the art machine translation systems at University of Southern California.",
                    "label": 0
                },
                {
                    "sent": "A system for translating between Arabic and English will have about half a billion rules, 500 million rules each, which each of which is capturing some little bit of English sentence, and the Arabic that it corresponds to.",
                    "label": 0
                },
                {
                    "sent": "So you can imagine there's a lot that has to go into making these.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Things run efficiently, so there's a bunch of problems that arise from the fact that these NLP systems are so big.",
                    "label": 1
                },
                {
                    "sent": "The first is you can't just start working on machine translation and build assistant.",
                    "label": 0
                },
                {
                    "sent": "You really have to join a team that already has a competitive system.",
                    "label": 0
                },
                {
                    "sent": "And once you're there.",
                    "label": 0
                },
                {
                    "sent": "You can't, you know.",
                    "label": 0
                },
                {
                    "sent": "Just put in any idea that you like because the architecture of the system will make it painful.",
                    "label": 0
                },
                {
                    "sent": "You may have an idea which is elegant algorithmically.",
                    "label": 0
                },
                {
                    "sent": "It's just you have to tear up too much code to put it in.",
                    "label": 1
                },
                {
                    "sent": "And when you do decide to put in some idea from from some other system.",
                    "label": 0
                },
                {
                    "sent": "I particularly like this image.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Google Image search the.",
                    "label": 0
                },
                {
                    "sent": "Interest.",
                    "label": 0
                },
                {
                    "sent": "You can't just take the idea out of somebody else's system and reuse the code.",
                    "label": 0
                },
                {
                    "sent": "The idea may be very clear from their paper, but in their code it's all tangled up with the rest of the implementation, and it's specialized to the rest of what they're doing.",
                    "label": 0
                },
                {
                    "sent": "So in SRL, you know you may have some nice lifted inference in your assistant.",
                    "label": 0
                },
                {
                    "sent": "I can't just take out the lifting module and put it into my system.",
                    "label": 0
                },
                {
                    "sent": "I really have to think about how to specialize that to my domain and re implement it.",
                    "label": 0
                },
                {
                    "sent": "So I think all of.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is bad.",
                    "label": 0
                },
                {
                    "sent": "And my students and I as a result, often feel like this.",
                    "label": 0
                },
                {
                    "sent": "So there's all this stuff that you know you did it in the last system and you're doing it again and spiritually.",
                    "label": 0
                },
                {
                    "sent": "It's the same, but there are some little twists that are different.",
                    "label": 0
                },
                {
                    "sent": "But when you find yourself doing anything twice in computer science, that means you've missed a level of abstraction.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the situation outside NLP is maybe a little bit better at president.",
                    "label": 1
                },
                {
                    "sent": "These systems were still big.",
                    "label": 0
                },
                {
                    "sent": "These are just a few random things I pulled down in computational biology, music analysis, graph layout.",
                    "label": 1
                },
                {
                    "sent": "But these systems are still pretty big and they will get bigger.",
                    "label": 1
                },
                {
                    "sent": "So if machine vision is like 30 or 40 communities, each of which is dealing with a single task, but people are starting to become interested in putting these together and doing global inference for things like scene analysis and then those systems are going to get large and hard to engineer.",
                    "label": 0
                },
                {
                    "sent": "One reaction in the NLP community has often been to build toolkits which play much the same role that modeling languages do in the machine or modeling systems do in the machine learning commute.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here are some of the toolkits that have been built hidden Markov models, finite state machines, tree transducers, a bunch of other stuff.",
                    "label": 0
                },
                {
                    "sent": "Well, these systems were also quite big.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then again, they don't do everything you want, so one tool that I use quite a lot and I love is a system for working with finite state machines done by the best people in the field.",
                    "label": 1
                },
                {
                    "sent": "Runs like the wind, but here is a bunch of things that I want it to do that it doesn't do.",
                    "label": 0
                },
                {
                    "sent": "OK, just because you know they targeted at a particular particular set of functions, all of these things we know how to do.",
                    "label": 0
                },
                {
                    "sent": "In principle, we could write out the equations, but it would be a lot of work to get them into the system.",
                    "label": 1
                },
                {
                    "sent": "So what is it that's common across different toolkit?",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For different modeling languages, presumably there's some level of abstraction in computer science is always built as a stack of abstractions.",
                    "label": 1
                },
                {
                    "sent": "We're already doing something here 'cause we're not building applications directly will build them on top of toolkits or on top of modeling languages, so what's under that?",
                    "label": 0
                },
                {
                    "sent": "What shared by?",
                    "label": 1
                },
                {
                    "sent": "OK, what shared by all the things at this level?",
                    "label": 0
                },
                {
                    "sent": "So there's something declarative under here, and something procedural.",
                    "label": 0
                },
                {
                    "sent": "So I want to argue that declaratively what's going on is something like weighted deduction.",
                    "label": 0
                },
                {
                    "sent": "That weighted deduction could be expressed by weighted logic programs, and it's implemented by something like truth, maintenance on equations.",
                    "label": 1
                },
                {
                    "sent": "And I'm going to propose you know particular formalism for writing this stuff down and executing it.",
                    "label": 0
                },
                {
                    "sent": "The details of that are interesting, and I'm happy to discuss them, but this is this is kind of the high level picture.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to spend most of my time talking about the language and much less talking about the implementation.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But I'm happy to answer questions, so let me be clear what the project is here.",
                    "label": 0
                },
                {
                    "sent": "So when somebody has a toolkit or if they have, you know a system like alchemy for mark of logic networks, they are usually trying to get you to design your system in a particular way.",
                    "label": 1
                },
                {
                    "sent": "They have a worldview and you're working within that worldview, and that's a great thing because it provides you with guidance Dave encapsulated exactly the right semantics for that approach and.",
                    "label": 0
                },
                {
                    "sent": "It you know it's a good approach, and if it works for your problem, then it's going to be exactly up it to the problem.",
                    "label": 0
                },
                {
                    "sent": "Dina is different.",
                    "label": 0
                },
                {
                    "sent": "It's one level down.",
                    "label": 1
                },
                {
                    "sent": "It's a language for expressing the at an abstract level, what the algorithms are doing, so it's still a declarative language because it doesn't express the order in which the computations are done, for example, but it does describe what the correct computations are.",
                    "label": 0
                },
                {
                    "sent": "So you specify the data in the computations.",
                    "label": 0
                },
                {
                    "sent": "It doesn't know whether their probabilities or not.",
                    "label": 0
                },
                {
                    "sent": "It doesn't enforce, for example, of probabilistic semantics.",
                    "label": 0
                },
                {
                    "sent": "It's one level lower you could build.",
                    "label": 1
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is on top.",
                    "label": 0
                },
                {
                    "sent": "So there's a bunch more beyond this talk.",
                    "label": 1
                },
                {
                    "sent": "The first of all this.",
                    "label": 0
                },
                {
                    "sent": "The first warning really is that this is this is work in progress.",
                    "label": 0
                },
                {
                    "sent": "We did build and release something in 2005 and then this work was on the back burner for a few years.",
                    "label": 0
                },
                {
                    "sent": "Although we used this prototype a lot and now now we're working again.",
                    "label": 0
                },
                {
                    "sent": "Card on the on the next version so copied on this email because I really would like input from this community.",
                    "label": 0
                },
                {
                    "sent": "I started out trying to build something that would.",
                    "label": 0
                },
                {
                    "sent": "Encapsulate the.",
                    "label": 0
                },
                {
                    "sent": "Kinds of dynamic programming algorithms that are used in natural language.",
                    "label": 0
                },
                {
                    "sent": "But eventually I realized that the IT seemed to be applicable to a much wider variety of problems that I knew about and I'd like to make sure that it works for your problems and I would just love to get people involved who have a background in the logic community.",
                    "label": 0
                },
                {
                    "sent": "The people who are working on it now.",
                    "label": 0
                },
                {
                    "sent": "Either from programming languages or machine learning NLP.",
                    "label": 0
                },
                {
                    "sent": "Good.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I'm going to start with a quick sketch here.",
                    "label": 1
                },
                {
                    "sent": "I'd like to take questions during the talk, actually, possibly even a little bit of discussion.",
                    "label": 0
                },
                {
                    "sent": "During the talk.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to have enough time to cover everything that I'd ideally like to cover.",
                    "label": 0
                },
                {
                    "sent": "This is only one hour is not to one hour, not two.",
                    "label": 0
                },
                {
                    "sent": "So if you interrupt me with questions, you'll be doing me a favor and the rest of the audience of paper by preventing me from going too fast, yeah?",
                    "label": 0
                },
                {
                    "sent": "Isn't it just?",
                    "label": 0
                },
                {
                    "sent": "Software.",
                    "label": 0
                },
                {
                    "sent": "No, it's really not feature creep actually.",
                    "label": 0
                },
                {
                    "sent": "That I don't believe it's restricted.",
                    "label": 0
                },
                {
                    "sent": "I mean there there are tackling relatively narrow problems using a single method.",
                    "label": 0
                },
                {
                    "sent": "There may be some feature creep in that they have.",
                    "label": 0
                },
                {
                    "sent": "So they had an old method and then they came up with a better method and they didn't rip the old method out, so I guess that's possible.",
                    "label": 0
                },
                {
                    "sent": "OK, nonetheless it may be that on some workloads the old method works better.",
                    "label": 0
                },
                {
                    "sent": "And you'd like the ability to choose among them.",
                    "label": 0
                },
                {
                    "sent": "So I mentioned this finite state toolkit they actually have, I think, 17 different implementations of finite state machines, all done with template metaprogramming and so forth, because it matters whether you know you have your rocks or sparse or dense, and whether your you know what kind of way to have and whether the machine is deterministic and whether it's acyclic and whether it's epsilon free.",
                    "label": 0
                },
                {
                    "sent": "So they share as much code as possible but there.",
                    "label": 0
                },
                {
                    "sent": "Exactly what you want to use depends on your workload, and that's one reason that it's nice to have a compiler that will generate the appropriate code for you.",
                    "label": 0
                },
                {
                    "sent": "So template metaprogramming is one way to do it, but that's generating very specific code for you.",
                    "label": 0
                },
                {
                    "sent": "The compilers unrolling it.",
                    "label": 0
                },
                {
                    "sent": "OK, so let me move.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "With a sketch of the language.",
                    "label": 0
                },
                {
                    "sent": "So what you do in the languages you write equations and it probably won't come as a surprise to logic people to know that the equations will have.",
                    "label": 0
                },
                {
                    "sent": "Well, OK, so we have this issue that there's two meanings of variable here.",
                    "label": 0
                },
                {
                    "sent": "So what when I say variable, what I mean is a logical variable, not a variable in the equation.",
                    "label": 0
                },
                {
                    "sent": "Let me give you an example.",
                    "label": 0
                },
                {
                    "sent": "Here are a B&C are items.",
                    "label": 0
                },
                {
                    "sent": "There are things that are being or terms that are being manipulated.",
                    "label": 0
                },
                {
                    "sent": "These are not the variables so.",
                    "label": 0
                },
                {
                    "sent": "This is a is an integer an A = B * C. Now this looks very familiar, but it doesn't mean what you think.",
                    "label": 0
                },
                {
                    "sent": "This is not an assignment, it's a definition.",
                    "label": 0
                },
                {
                    "sent": "This is a is defined as be time.",
                    "label": 0
                },
                {
                    "sent": "See if B or C changes than a will change as well, OK?",
                    "label": 1
                },
                {
                    "sent": "OK, so let's get a little bit more interesting here.",
                    "label": 0
                },
                {
                    "sent": "Bees definition is spread out over 2 lines, so this is saying both X&Y are added in to be, so this means almost the same thing as B = X + y. I won't go into the difference right now, so it's a sum of two things.",
                    "label": 0
                },
                {
                    "sent": "And why would you want this notation?",
                    "label": 0
                },
                {
                    "sent": "Because maybe you have these structured terms, each of which has a value and you're going to add them all into C. And maybe you'd like to do.",
                    "label": 0
                },
                {
                    "sent": "Yeah, something like a summation symbol.",
                    "label": 0
                },
                {
                    "sent": "So now we're getting interesting.",
                    "label": 0
                },
                {
                    "sent": "So C is the sum of Z of N for all N and this is the logic variable, so it's a sum of all the values that are defined as newsy values.",
                    "label": 0
                },
                {
                    "sent": "Become as you prove values for Z of seven and Z of 200, and Z of things that aren't numbers at all.",
                    "label": 0
                },
                {
                    "sent": "Those will get accumulated into see and if they change their values, change, then see will be updated.",
                    "label": 0
                },
                {
                    "sent": "So this is just a pattern and basically giving you a summation symbol.",
                    "label": 0
                },
                {
                    "sent": "I hinted that end doesn't have to be an integer, it could be any term.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so so let's get a little more interesting.",
                    "label": 1
                },
                {
                    "sent": "Here we have scalar multiplication, so this is now pointwise multiplication of two vectors.",
                    "label": 1
                },
                {
                    "sent": "So for every I AI is being defined as be of high time, see above.",
                    "label": 0
                },
                {
                    "sent": "OK, pointwise multiplication.",
                    "label": 1
                },
                {
                    "sent": "You might wonder how you do dot product.",
                    "label": 0
                },
                {
                    "sent": "OK?",
                    "label": 0
                },
                {
                    "sent": "Well, if we Levi off here then a is a sum overall be a vittime see of high I is free on the right hand side so we sum over it's possible values.",
                    "label": 1
                },
                {
                    "sent": "And it's useful that this might not have to be integers.",
                    "label": 1
                },
                {
                    "sent": "For example, you might have a sparse vector, or telling you how often different words appear in a query and another sparse vector telling you how many times words appear in a document.",
                    "label": 0
                },
                {
                    "sent": "And this is how search engines work as they take a dot product of these sparse vectors.",
                    "label": 0
                },
                {
                    "sent": "So it's nice if they don't have to be integers.",
                    "label": 0
                },
                {
                    "sent": "OK, so if you get this one, you pretty much have everything.",
                    "label": 0
                },
                {
                    "sent": "This is sparse matrix multiplication, so you want to define the element in matrix A at row and column K, and that means that I and K are bound on the right hand side.",
                    "label": 0
                },
                {
                    "sent": "But Jay is still free, and so we're going to some overall JS, so this is just taking many dot products as we took a single dot product here.",
                    "label": 0
                },
                {
                    "sent": "This author so far.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, good, so you probably see now if you know Prolog, what we're up to.",
                    "label": 1
                },
                {
                    "sent": "Prolog has horn clauses means there's one thing on the left, several things on the right, and if you prove these things then you can prove that an all we're doing here is replacing these by what I like to call Horn equations.",
                    "label": 1
                },
                {
                    "sent": "So AIK is proved if by J&CJK is proved, but not only do we prove it, but we prove a value for it.",
                    "label": 1
                },
                {
                    "sent": "And in this case it's a real number.",
                    "label": 0
                },
                {
                    "sent": "In general values could be any term.",
                    "label": 0
                },
                {
                    "sent": "So the definition of this comes from the values of other terms B * C is itself a term, and it has a value only if B&C do.",
                    "label": 0
                },
                {
                    "sent": "This plus equals is maybe aggregating over zero or one or many things if it aggregates over 0 things, then this hasn't proved, so it has no value.",
                    "label": 1
                },
                {
                    "sent": "Now you might expect that the identity that the value of nothing comes in would be 0.",
                    "label": 0
                },
                {
                    "sent": "The identity for plus, but in fact if you want that, that's easy to write.",
                    "label": 0
                },
                {
                    "sent": "You just say some zero into everything and then it's always proved with value 0.",
                    "label": 0
                },
                {
                    "sent": "I and you can add additional values to the extent that beings here approved.",
                    "label": 0
                },
                {
                    "sent": "So it turns out to be convenient to have the no value case as well.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is kind of like Prolog.",
                    "label": 0
                },
                {
                    "sent": "We have nested terms, we can do lists it's Turing complete.",
                    "label": 0
                },
                {
                    "sent": "It's unlike prologue and the terms have values.",
                    "label": 1
                },
                {
                    "sent": "It's a hybrid of functional programming and logic programming, because the terms are evaluated in place.",
                    "label": 0
                },
                {
                    "sent": "So you can think of this as a function which is defined by that we don't just do backtracking.",
                    "label": 0
                },
                {
                    "sent": "Backtracking is a terrible idea for for many problems where in dynamic programming, for example, you have structure sharing and there's a type system in their static optimizations and stuff like that.",
                    "label": 0
                },
                {
                    "sent": "Yes question.",
                    "label": 0
                },
                {
                    "sent": "Logic programming.",
                    "label": 0
                },
                {
                    "sent": "It's not actually like constraint logic programming, because each term has one value.",
                    "label": 0
                },
                {
                    "sent": "Sorry, each variable has one value and there's no backtracking search to resolve it.",
                    "label": 0
                },
                {
                    "sent": "However, you can easily implement constraint logic programming on top of this.",
                    "label": 0
                },
                {
                    "sent": "For example, you can have boolean's telling you can this term have this value.",
                    "label": 0
                },
                {
                    "sent": "So you can have booleans over that pair, or if you're doing something like downs propagation then you can have one value for the upper bound and one value for the lower bound on the range of that variable.",
                    "label": 0
                },
                {
                    "sent": "So constraint propagation is.",
                    "label": 0
                },
                {
                    "sent": "Is one thing that falls very naturally out of this framework actually?",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so I want to say just a couple more words about these aggregation operators, so we've seen plus equals.",
                    "label": 1
                },
                {
                    "sent": "Let me add another one here, which is min equals.",
                    "label": 0
                },
                {
                    "sent": "So instead of keeping running total that keeps a running minimum.",
                    "label": 0
                },
                {
                    "sent": "This might be useful.",
                    "label": 0
                },
                {
                    "sent": "For example, in Dijkstra's algorithm single Source shortest path.",
                    "label": 0
                },
                {
                    "sent": "So if you have the start node, maybe is Brussels then the best path to the start node has weight 0, but if you want to get the best path to W, well, let's see.",
                    "label": 0
                },
                {
                    "sent": "If we already have a path to V of wait 10.",
                    "label": 0
                },
                {
                    "sent": "Of course, 10 and we have an edge from VW of costs 3.",
                    "label": 0
                },
                {
                    "sent": "Then we have a path to W of cost 13, but there are many of these that we could go through.",
                    "label": 0
                },
                {
                    "sent": "So we take the best path, minimizing over all of those.",
                    "label": 0
                },
                {
                    "sent": "So this is Dijkstra's algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So you can take any binary associative commutative operator and turn this into an aggregation operator.",
                    "label": 0
                },
                {
                    "sent": "So here we have or equals and and equals over billions and prolog.",
                    "label": 0
                },
                {
                    "sent": "Pure Prolog brother is just the fragment of Dinah, in which this is the only aggregation operator you have and the types of all terms or just unit.",
                    "label": 0
                },
                {
                    "sent": "So if they prove they can only have one value, true.",
                    "label": 0
                },
                {
                    "sent": "He said no back.",
                    "label": 0
                },
                {
                    "sent": "I I'm just talking about the declarative semantics of the language, not the implementation.",
                    "label": 0
                },
                {
                    "sent": "Right, there's no backtracking, so we don't have cut for example, so I'll show you in a minute how we get around the need for something like cut so every ground term has a single aggregation operator, so you can't mix these.",
                    "label": 1
                },
                {
                    "sent": "You can't write one line with B plus equals and another line with the min equals some ground terms are open for writing, so they can take if you think about deductive databases at runtime, you may want to feed additional input into them and see what happens to the output to declare those terms as writable.",
                    "label": 0
                },
                {
                    "sent": "Rules are defining values only for ground terms, so when you write something with variables in it, you can think of that as a template that expands over many rules, just as in same mark of logic networks you have.",
                    "label": 0
                },
                {
                    "sent": "You've got power factors which expand over overall instantiation's.",
                    "label": 0
                },
                {
                    "sent": "It would be funny in this case to write something like min equals because there is exactly 1 at most.",
                    "label": 0
                },
                {
                    "sent": "One thing that you'd be minimizing over.",
                    "label": 0
                },
                {
                    "sent": "So when there's only one one possible value to aggregate over, you can just write it as equals.",
                    "label": 0
                },
                {
                    "sent": "So that's a simple definition.",
                    "label": 0
                },
                {
                    "sent": "We saw that before, and you can even write this, although it will.",
                    "label": 0
                },
                {
                    "sent": "This amounts to an assertion that at Convergence A of X will only be true for One X, so you'll get a runtime error.",
                    "label": 0
                },
                {
                    "sent": "This amounts to an assertion of uniqueness, so.",
                    "label": 0
                },
                {
                    "sent": "These are not associative and commutative.",
                    "label": 0
                },
                {
                    "sent": "Here we have: equals and here are the order of.",
                    "label": 0
                },
                {
                    "sent": "The program is important, so: equals is like is like override the last thing wins and this is particularly important if you want to be able to replace values of axioms at runtime.",
                    "label": 1
                },
                {
                    "sent": "So you change the value of a fact.",
                    "label": 0
                },
                {
                    "sent": "In this case it's being done not at runtime, but right in the program.",
                    "label": 0
                },
                {
                    "sent": "So we say all birds fly.",
                    "label": 0
                },
                {
                    "sent": "Oh, except we're going to override that and say that Penguins don't fly and Big Bird doesn't fly.",
                    "label": 0
                },
                {
                    "sent": "You might not want to worry bout this ordering, so we also have a syntactic sugar where which basically translates into this were the most specific winds.",
                    "label": 0
                },
                {
                    "sent": "So this says Fibbonaci 0 then first pinacci elements or zero and one and then thereafter.",
                    "label": 0
                },
                {
                    "sent": "So these override this general rule which says fibbonaci of access financial of the two previous things.",
                    "label": 0
                },
                {
                    "sent": "And note by the way, that these are structured terms.",
                    "label": 0
                },
                {
                    "sent": "This is minus with two arguments X and one, but that evaluates in place, it's replaced by its value.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, any questions?",
                    "label": 0
                },
                {
                    "sent": "This is meant to be a right arrow.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "There are many intellectual debts here, so in natural language processing there's been a lot of work on deductive parsing and weighted deductive parsing, where you have a bunch of words and you want to make them coherent two phrases and eventually into a sentence, and I'll show you how that plays out, and I know soon, but that was kind of my starting point.",
                    "label": 1
                },
                {
                    "sent": "There was a tradition of deductive databases in the 80s and 90s.",
                    "label": 1
                },
                {
                    "sent": "Not much work on that anymore, but I'm also indebted to that there's been a lot of work in theorem proving where you start with facts, and again you do some kind of forward chaining inference.",
                    "label": 1
                },
                {
                    "sent": "And there's been a bunch of previous work, so Dinos, really a kind of hybrid functional programming and logic programming.",
                    "label": 0
                },
                {
                    "sent": "There's been as you guys know, very well.",
                    "label": 0
                },
                {
                    "sent": "A lot of work in probabilistic programming languages, some of the things we're doing for efficiency like mode system have been done elsewhere.",
                    "label": 1
                },
                {
                    "sent": "Also, this business of outputs changing when inputs change have been pushed have been pushed quite hard in the functional programming world, about a car recently, and there's other stuff that's relevant also.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so now I'm going to show you some examples, but first I want to give you the big picture of why I think this is a good abstraction level.",
                    "label": 1
                },
                {
                    "sent": "So what is it that we're doing in SRL, for example?",
                    "label": 0
                },
                {
                    "sent": "Or an L?",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's how I usually think about building a system.",
                    "label": 1
                },
                {
                    "sent": "The system is going to deal with something like probabilistic context free grammars.",
                    "label": 0
                },
                {
                    "sent": "So first I have to come up with the formalism and that, but the mathematical formalism isn't quite enough.",
                    "label": 0
                },
                {
                    "sent": "We want to come up with some equations to compute.",
                    "label": 1
                },
                {
                    "sent": "Results may be approximately given some input data, so this is a generative formalism, but we're not really going to get a parse by generating all possible trees and seeing which sentence matches your input sentence.",
                    "label": 0
                },
                {
                    "sent": "You're going to do something bottom up where you are given the input sentence and just want to construct the trees for that.",
                    "label": 0
                },
                {
                    "sent": "So some of you may recognize this as the formula for the inside probabilities of constituent.",
                    "label": 0
                },
                {
                    "sent": "If you don't, that's fine, given these equations you want to come up with some way of actually computing the result sufficiently so you pick an execution order and then you have to worry under the hood about some engineering.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, Donna is dealing with this level.",
                    "label": 0
                },
                {
                    "sent": "You're writing down these equations and you write them down as these kind of variable template equations, horn equations.",
                    "label": 0
                },
                {
                    "sent": "And the observation is that well, beyond our community, what most programs are doing.",
                    "label": 1
                },
                {
                    "sent": "At least programs without side effects is computing some values from other values, and the order in which you do that is immaterial.",
                    "label": 1
                },
                {
                    "sent": "So feedforward networks, dynamic programming, anything with message passing.",
                    "label": 0
                },
                {
                    "sent": "You're just computing values from other values.",
                    "label": 1
                },
                {
                    "sent": "OK, one thing you have to do to make this sufficient is to quickly figure out what influences what, so maybe you've got some big state space and reinforcement learning and you want to figure out quickly what moves are available to and what states you can get to.",
                    "label": 1
                },
                {
                    "sent": "From here you're doing, you know Gibbs sampling or something, and you need to be able to compute the Markov blanket quickly, so.",
                    "label": 0
                },
                {
                    "sent": "Unification.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For example, as useful for this, the I should point out that these equation at the examples meant clear.",
                    "label": 0
                },
                {
                    "sent": "These equations could be cyclic.",
                    "label": 1
                },
                {
                    "sent": "Some programs also need to update the outputs of the inputs change.",
                    "label": 1
                },
                {
                    "sent": "That is the value proposition for spreadsheets, and for Makefiles.",
                    "label": 0
                },
                {
                    "sent": "It's also why people work on dynamic algorithms.",
                    "label": 0
                },
                {
                    "sent": "So you mean you don't want to recompute things from scratch?",
                    "label": 0
                },
                {
                    "sent": "So this kind of stuff happens in our community as well.",
                    "label": 0
                },
                {
                    "sent": "If you think about, say, MCMC or DPL, or walks out or something, you're messing with one variable to flip it, or you assign it, and you want to see what happens as a consequence happens in constraint programming also.",
                    "label": 0
                },
                {
                    "sent": "When you're doing training, you mess with the parameters and you need to see how that changes your objective function, or if you're doing cross validation, you take out each example intern.",
                    "label": 0
                },
                {
                    "sent": "When that example is out, you see how that affects your objective function.",
                    "label": 0
                },
                {
                    "sent": "You shouldn't have to make very many changes because your data didn't change very much, so you see how that affects your objective function, or you get a in approximation to that in to do that for you, and then you see how that new model does on that held out example.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so we'll come back to these execution strategies later.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what I'd like to do is by using these mechanisms is to support some of the common threads in NLP SRL knowledge representation and reasoning, data mining, graph mining and so on.",
                    "label": 1
                },
                {
                    "sent": "So one thing that happens across these areas is pattern matching, so you're matching patterns against structure.",
                    "label": 0
                },
                {
                    "sent": "You've got structured objects of some kind, and they represent things like, you know, states in a state space or or variables in a in a complicated.",
                    "label": 0
                },
                {
                    "sent": "Unrolled model with exponentially many variables to.",
                    "label": 0
                },
                {
                    "sent": "These are structured objects and you need to be able to structure them.",
                    "label": 1
                },
                {
                    "sent": "There is message passing of some kind among the terms, and that's what we're implementing with these horn equations.",
                    "label": 0
                },
                {
                    "sent": "So the easiest one is, you know, tag, you're it were approved.",
                    "label": 1
                },
                {
                    "sent": "So now you're approved also, so that's just that's bottom up inference.",
                    "label": 1
                },
                {
                    "sent": "Or if you're forward Channing, or if you're doing top down inference, backward chaining, it's oh, we got queried, and so now we have to query you as well.",
                    "label": 0
                },
                {
                    "sent": "There's probabilistic inference, so in something like Prism you are trying to keep track of the total weight of all proofs of a proposition.",
                    "label": 1
                },
                {
                    "sent": "So before someone asked about constraint programming, so our consistency is here, my domain has been reduced, so let's reduce your domain and the soft version of that is belief propagation.",
                    "label": 0
                },
                {
                    "sent": "So my belief is updated.",
                    "label": 0
                },
                {
                    "sent": "That should influence your belief.",
                    "label": 0
                },
                {
                    "sent": "If you're doing something that's course defined, like like box propagation or any other course defined method is also true in downs propagation.",
                    "label": 0
                },
                {
                    "sent": "As you get better and better estimates of some value then that sharpens the estimates of your neighbors values Gibbs sampling.",
                    "label": 0
                },
                {
                    "sent": "You flip your value.",
                    "label": 0
                },
                {
                    "sent": "Your neighbors have to flip.",
                    "label": 0
                },
                {
                    "sent": "Sometimes you may just want to scan a lot of data.",
                    "label": 0
                },
                {
                    "sent": "Or scan the scan, for example the proof trees that were imputed given some data and count up the number of times a particular rule or feature or shout out to the ML.",
                    "label": 0
                },
                {
                    "sent": "Two people here are the number of times a sub graph gets hit, so you're looking for a particular configurations every time you prove that that that that sub graph exists.",
                    "label": 0
                },
                {
                    "sent": "That's a little forward chaining proof to detect that right and you want to keep count of those anytime you've got dynamic programming, you can think of that as message passing.",
                    "label": 0
                },
                {
                    "sent": "In fact, the forward backward algorithm is just belief propagation on a chain graph.",
                    "label": 0
                },
                {
                    "sent": "And whenever you have dynamic algorithms, you're updating some input and now you want to update your intermediate quantities, and eventually your output.",
                    "label": 0
                },
                {
                    "sent": "Good, so that's a long list.",
                    "label": 1
                },
                {
                    "sent": "If you're getting messages from multiple sources, you have to be able to aggregate them.",
                    "label": 0
                },
                {
                    "sent": "This shows up in all these domains.",
                    "label": 0
                },
                {
                    "sent": "Finally, you may have some kind of default reasoning, so we've heard a lot over the last few days about lifted inference, which I think is primarily reasoning at runtime with non ground terms.",
                    "label": 0
                },
                {
                    "sent": "So terms that contain variables before they shatter against data if you do it at compile time, that's program transformations.",
                    "label": 0
                },
                {
                    "sent": "Where your reasoning about the program before you've seen any data, and when you've seen some data, then you say, well, ordinarily I would infer this variable from these variables, but oh, we're going to override that 'cause we actually observed this variable.",
                    "label": 0
                },
                {
                    "sent": "So we're going to use this: equals operator to do something nonmonotonic override that conclusion for this particular variable for this particular instantiation of this variable, and then those exceptions will propagate through this influence graph of equations.",
                    "label": 0
                },
                {
                    "sent": "So once you've shattered once you've shattered this, you may after that as well.",
                    "label": 0
                },
                {
                    "sent": "So finally, you may want to look at the proof forest that you get out, and generally when you're training you want some automatic differentiation in there, and even the prototype supports that quite nicely.",
                    "label": 0
                },
                {
                    "sent": "OK, let me pause again.",
                    "label": 0
                },
                {
                    "sent": "If there are any questions or else I'll move on.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I want to make 1 one final point here, which is that I said that before that Diana was agnostic about what the semantics of all these values are OK, and the reason is that even among the programs say that my students and I write, which is, you know, one lab what we use real numbers for, differs very widely.",
                    "label": 0
                },
                {
                    "sent": "So real numbers are not the only thing you can use, but let's just look at those so.",
                    "label": 0
                },
                {
                    "sent": "And in some systems, the real numbers are always probabilities, but they might be unnormalized probabilities.",
                    "label": 0
                },
                {
                    "sent": "They might be log probabilities.",
                    "label": 0
                },
                {
                    "sent": "You might be doing belief propagation, in which case there are approximate probabilities, so you're not enforcing a true probabilistic semantics the way something like probably would do.",
                    "label": 0
                },
                {
                    "sent": "There might be strict bounds on probability.",
                    "label": 0
                },
                {
                    "sent": "Is one place where this shows up is if you have in a star heuristic.",
                    "label": 0
                },
                {
                    "sent": "You might also have inadmissible heuristics which are not strict bounds, but there are good approximations and you might try to learn these heuristics to be able to trade off accuracy and runtime.",
                    "label": 0
                },
                {
                    "sent": "Some of the things that you're looking at, or just parameters of your model like feature weights or if you have to variationally approximate something, then their parameters of that approximation.",
                    "label": 0
                },
                {
                    "sent": "Sometimes I said you're just counting things, so you want to know how often something happens in your data.",
                    "label": 0
                },
                {
                    "sent": "That might be the strength with which a feature fires.",
                    "label": 0
                },
                {
                    "sent": "If you're doing Gibbs sampling something like a Chinese restaurant process, you need to know how many customers are sitting at existing tables.",
                    "label": 0
                },
                {
                    "sent": "You need to maintain that dynamically so these are maintaining integers or something.",
                    "label": 0
                },
                {
                    "sent": "In the case of graphs, maybe you need to maintain degrees for the same reason when you're trying to do you know, edge prediction in graphs?",
                    "label": 0
                },
                {
                    "sent": "If you're doing neural Nets, these things aren't probabilities.",
                    "label": 0
                },
                {
                    "sent": "There activations we saw at least two papers here which were real numbers were utilities or preferences.",
                    "label": 0
                },
                {
                    "sent": "You might want to take expectations over those utilities or risks.",
                    "label": 0
                },
                {
                    "sent": "In order to do some kind of loss based training, sometimes you measure in training.",
                    "label": 0
                },
                {
                    "sent": "You measure things like entropy or regularization.",
                    "label": 0
                },
                {
                    "sent": "And finally you take derivatives so.",
                    "label": 0
                },
                {
                    "sent": "This is why I don't want to say real numbers are always probabilities.",
                    "label": 0
                },
                {
                    "sent": "You just need to be able to have some kind of equations relating real numbers.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so one more slide in this section.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "Some of the common issues and implementation are you need to be able to store things efficiently so we have all these messages that might get computed, but you have to get them efficiently.",
                    "label": 0
                },
                {
                    "sent": "That usually means doing unification and it also means when you have normalized or tabled computations or facts then you need to be able to index them so you can look them up quickly.",
                    "label": 0
                },
                {
                    "sent": "Too much indexing can be if you index things that you're never going to retrieve, that's a waste.",
                    "label": 0
                },
                {
                    "sent": "So you need to decide what to index and if things aren't indexed then you may have to do something like a database query because maybe you were doing a join and so query planning may come into play and I think a lot of what these big systems are doing is specialized implementations of these things which work well for a particular workload.",
                    "label": 0
                },
                {
                    "sent": "One thing that's very important is deciding which messages to send and when, so you can do bottom up from the data that's forward chaining.",
                    "label": 1
                },
                {
                    "sent": "Then you have a problem of which messages to pass first in the unweighted fragment, like Prolog.",
                    "label": 1
                },
                {
                    "sent": "This order doesn't matter very much, but it can matter quite a lot in the way wedded fragment in backward chaining.",
                    "label": 0
                },
                {
                    "sent": "Then you have to decide what to memorize and whether you memorize it forever.",
                    "label": 1
                },
                {
                    "sent": "And then you have to worry about how to update your memos because they may become invalid.",
                    "label": 0
                },
                {
                    "sent": "When the input changes, so there's there's a lot of hybrid strategies here.",
                    "label": 0
                },
                {
                    "sent": "If I had more time, I'd give you a unified view of what all these strategies look like.",
                    "label": 0
                },
                {
                    "sent": "Feel free to ask me about that, and then there's lots of tricks that have shown up in various places in the literature.",
                    "label": 0
                },
                {
                    "sent": "If you know the state of the art and sat solving, this is one of the beautiful tricks, and it turns out it generalizes quite nicely.",
                    "label": 0
                },
                {
                    "sent": "So we can put it in this framework.",
                    "label": 0
                },
                {
                    "sent": "And yeah, people sometimes want to be able to do transformation on their transformations on their code, so it's nice to have a language like Prolog or Lisp for that matter, where your code looks like data and you can do.",
                    "label": 0
                },
                {
                    "sent": "You can take your list of rules and be able to manipulate them in directly in the language at runtime if necessary, and you might want to do parallelization.",
                    "label": 0
                },
                {
                    "sent": "That's still future work for us, but.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I have some ideas.",
                    "label": 0
                },
                {
                    "sent": "OK questions.",
                    "label": 0
                },
                {
                    "sent": "Alright, so now I want to tell you a little bit first about about how to parse.",
                    "label": 0
                },
                {
                    "sent": "So at a curiosity, how many people here know how to build a basic bottom up chart parser of any kind?",
                    "label": 0
                },
                {
                    "sent": "Oh, good, a surprising number of people.",
                    "label": 0
                },
                {
                    "sent": "OK, so for those of you who don't, I'm not going to argue that even if this language you know never gets implemented at all, it's still a great way to teach you parsing.",
                    "label": 0
                },
                {
                    "sent": "And you know 60 seconds or something so you know it's a good mathematical notation for explaining the structure of.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Algorithms, so this is the inside algorithm which figures out the probability of a sentence under a probabilistic context free grammar, and there's only three things here.",
                    "label": 0
                },
                {
                    "sent": "One says that a word is a phrase, one says.",
                    "label": 0
                },
                {
                    "sent": "If you have two phrases next to each other, there a phrase and one says you're building things up.",
                    "label": 0
                },
                {
                    "sent": "Gradually, phrases next to phrases make bigger phrases.",
                    "label": 0
                },
                {
                    "sent": "And finally, if you've got a phrase that covers your entire input sentence, you've gotta complete parse.",
                    "label": 0
                },
                {
                    "sent": "So let's look at this a little more carefully.",
                    "label": 0
                },
                {
                    "sent": "If you have a word W. From position I to position J in the sentence.",
                    "label": 0
                },
                {
                    "sent": "Then you have a phrase of type X from position Ida position J.",
                    "label": 0
                },
                {
                    "sent": "If your grammar says that X can rewrite as as that word W. So you've built up a word into a phrase of type X.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here you've got a phrase of type.",
                    "label": 0
                },
                {
                    "sent": "Here you've got a phrase of type Y that stretches from I to some midpoint and another phrase of type Z saying noun phrase and another phrase of type Z's.",
                    "label": 0
                },
                {
                    "sent": "For example, a verb phrase which stretches from that midpoint to J and that allows you to build in X from Y all the way to J, provided that X can rewrite as two parts, namely why NZ.",
                    "label": 0
                },
                {
                    "sent": "So graphically, we're putting this this and this together.",
                    "label": 0
                },
                {
                    "sent": "This is the grammar rule.",
                    "label": 0
                },
                {
                    "sent": "These are the things we've already built bottom up, putting them together into that there may be many ways to build this, and so we're summing over all the ways of doing it.",
                    "label": 0
                },
                {
                    "sent": "To get the total prob.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And finally the.",
                    "label": 0
                },
                {
                    "sent": "This here evaluate so if your sentence is of length 30, then if you have a phrase of type sentence from zero to 30, then you've reached your goal.",
                    "label": 0
                },
                {
                    "sent": "So this is just a convention that if you have one output, you'll call it goal.",
                    "label": 0
                },
                {
                    "sent": "OK, so in the prototype that we had a C++ API to this, and here's how it worked.",
                    "label": 1
                },
                {
                    "sent": "The facts that come in from outside or you are the things that are underlined here are the words of the sentence.",
                    "label": 0
                },
                {
                    "sent": "The length of the sentence and the rewrite rules in your grammar.",
                    "label": 0
                },
                {
                    "sent": "And so here's a C interface.",
                    "label": 0
                },
                {
                    "sent": "So here what we're doing is we're stating the facts that don't that aren't actually defined by the program, so these underlined axioms here.",
                    "label": 1
                },
                {
                    "sent": "So we're putting them into our chart or database.",
                    "label": 0
                },
                {
                    "sent": "So we say that the probability of this if you've got a sentence 70% of the time, it's a noun phrase followed by a verb phrase.",
                    "label": 0
                },
                {
                    "sent": "We said Pierre is definitely a word that stretches from position 0 to position one.",
                    "label": 0
                },
                {
                    "sent": "We read some more stuff in from standard input, and then when we do the query it does the computation on an as needed basis, and this their own pops out.",
                    "label": 0
                },
                {
                    "sent": "Which is the value we wanted.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so I built visualized with some undergraduates.",
                    "label": 0
                },
                {
                    "sent": "This can visualize very large or infinite graphs and things sort of come into view as you navigate through the graph with the keyboard.",
                    "label": 0
                },
                {
                    "sent": "Here at the bottom we have.",
                    "label": 0
                },
                {
                    "sent": "These are the facts that came in, so these blue things, or the grammar and this these pink things are the.",
                    "label": 0
                },
                {
                    "sent": "These pink things are the.",
                    "label": 0
                },
                {
                    "sent": "The words of the sentence, and here's the theorem that popped out at the top.",
                    "label": 0
                },
                {
                    "sent": "Here we have some ambiguity.",
                    "label": 0
                },
                {
                    "sent": "Here.",
                    "label": 0
                },
                {
                    "sent": "We have a something which we built but didn't help lead us to A to approve.",
                    "label": 0
                },
                {
                    "sent": "Here we have something which showed up in two different.",
                    "label": 0
                },
                {
                    "sent": "Sorry this ambiguity there are two ways to build this, so we're summing over both of them.",
                    "label": 0
                },
                {
                    "sent": "And here's something that we built in it.",
                    "label": 0
                },
                {
                    "sent": "Participated in that proof, and it also participated in that proof.",
                    "label": 0
                },
                {
                    "sent": "So this is showing why.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Tabling or memos.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It is useful.",
                    "label": 0
                },
                {
                    "sent": "So I want to make a few other points about this before moving on.",
                    "label": 0
                },
                {
                    "sent": "One is what I said so far is that the grammar rules are just facts which come from the outside world.",
                    "label": 0
                },
                {
                    "sent": "But we could define define them in other ways.",
                    "label": 0
                },
                {
                    "sent": "So here I'm defining every.",
                    "label": 0
                },
                {
                    "sent": "Ability of the ways of rewriting X using a little conditional log linear model.",
                    "label": 0
                },
                {
                    "sent": "So these are unnormalized probabilities.",
                    "label": 0
                },
                {
                    "sent": "So the unnormalized probability of rewriting X as a left child Y Ana right child Z.",
                    "label": 0
                },
                {
                    "sent": "So that's a rule in your grammar.",
                    "label": 0
                },
                {
                    "sent": "We're going to multiply a few things together with times equals, so there are some weight that says does X like to have Y as its left child does act like tabs E as its right child do X&Y&Z like to be siblings?",
                    "label": 0
                },
                {
                    "sent": "This one will only get multiplied in.",
                    "label": 0
                },
                {
                    "sent": "In the case where the two siblings are identical, so maybe you learn that's a good thing or a bad thing.",
                    "label": 0
                },
                {
                    "sent": "You multiply these together.",
                    "label": 0
                },
                {
                    "sent": "These give you unnormalized probabilities.",
                    "label": 0
                },
                {
                    "sent": "So now here we're summing over all Y&Z to get the total unnormalized probability of the rule of all rules that started X.",
                    "label": 0
                },
                {
                    "sent": "And then if we divide through by that total probability, Now we have proper probabilities which just fit into this.",
                    "label": 0
                },
                {
                    "sent": "So we've just written a little model directly within the language and you might trend these weights on data.",
                    "label": 0
                },
                {
                    "sent": "Questions.",
                    "label": 0
                },
                {
                    "sent": "OK, I'm going to take this example here, which I hope you understood question.",
                    "label": 0
                },
                {
                    "sent": "And I I want to go through several variations very quickly.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if you're only trying to find the best parse, how would you do that little quiz?",
                    "label": 0
                },
                {
                    "sent": "You should be able to figure it out.",
                    "label": 0
                },
                {
                    "sent": "This is summing over all parses.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, Max equals instead of plus equals.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right, good if you want to work in the log arhythmic domain.",
                    "label": 0
                },
                {
                    "sent": "So then instead of if these are log probabilities instead of probabilities, you add them instead of multiplying them.",
                    "label": 0
                },
                {
                    "sent": "If you want to go back to the inside algorithm, then you could.",
                    "label": 0
                },
                {
                    "sent": "You could use this log plus operation, which basically exponentiates adds and takes the log again, although with.",
                    "label": 0
                },
                {
                    "sent": "Other with less loss.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Precision.",
                    "label": 0
                },
                {
                    "sent": "Lattice parsing, so most parsers don't do this, but you may have.",
                    "label": 0
                },
                {
                    "sent": "A finite state machine which describes all the hypothesis of a speech recognition system and you want to find the.",
                    "label": 0
                },
                {
                    "sent": "You want to pick a particular path of that which has a good weight as a path, so the speech recognizer likes it, and it also has a good parse.",
                    "label": 0
                },
                {
                    "sent": "So how would we change this program?",
                    "label": 0
                },
                {
                    "sent": "To be able to parse this finite state automaton, which encodes an exponential number of strings.",
                    "label": 0
                },
                {
                    "sent": "It's a trick question.",
                    "label": 0
                },
                {
                    "sent": "We don't have to change the the program at all.",
                    "label": 0
                },
                {
                    "sent": "We only have to change the input.",
                    "label": 0
                },
                {
                    "sent": "So this originally we would have said the word Pierre goes from zero to one.",
                    "label": 0
                },
                {
                    "sent": "But now well, Pierre goes from State 5 to state nine.",
                    "label": 0
                },
                {
                    "sent": "It's also possible that it's the word P. The letter P followed by the word error.",
                    "label": 0
                },
                {
                    "sent": "So instead of saying that PR goes from zero to one, we just say it goes from State 5 to State 9.",
                    "label": 0
                },
                {
                    "sent": "Now instead of putting integers here or, we put objects which describe states in your machine.",
                    "label": 0
                },
                {
                    "sent": "But it's exactly the same algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'll skip this.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If you wanted to do not PCFG is but do global normalization so you're just doing weighted parsing and the goodness of a parse is the product of all the rules in the Paris, but nothing else.",
                    "label": 0
                },
                {
                    "sent": "To sum to one again, these things aren't necessarily probabilities, so there's no change to the program.",
                    "label": 1
                },
                {
                    "sent": "If you want to use fancy or kinds of grammars which pay closer attention to the words, or work with multiple parse sentence in its translation at once and get a single unified analysis which lines up the scent.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With this translation, it's very similar to this program.",
                    "label": 0
                },
                {
                    "sent": "You can manipulate it almost mechanically by saying instead of this having three subscripts, three arguments, it's going to have five arguments, so two positions in the English sentence, two positions in the Chinese sentence.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so let me just say a quick.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Word about about this because it illustrates a more general point.",
                    "label": 0
                },
                {
                    "sent": "So here this was a rule that we had in our original program, and as we saw, we could see it as taking this and getting that out of it.",
                    "label": 0
                },
                {
                    "sent": "Turns out that we can get a little bit of an asymptotic speedup by going through this intermediate stage, where first we combine this piece with that.",
                    "label": 0
                },
                {
                    "sent": "And then we combine the result with this and that's because we.",
                    "label": 0
                },
                {
                    "sent": "So basically we turn this into 2 rules, one of which produces this intermediate thing, one of which produces this output.",
                    "label": 0
                },
                {
                    "sent": "Now this original rule had six variables, but it should.",
                    "label": 0
                },
                {
                    "sent": "These rules only sums over only is dealing with five variables at once to end up getting an asymptotically speed up.",
                    "label": 0
                },
                {
                    "sent": "This is the classical folding transformation in logic programming, and this is really just a weighted variant of it, and it takes advantage of the distributivity of plus over times.",
                    "label": 0
                },
                {
                    "sent": "So the general question.",
                    "label": 0
                },
                {
                    "sent": "It is similar to dotted lists in say Early's algorithm, where you forget the part of the list that you've already matched.",
                    "label": 0
                },
                {
                    "sent": "So here, once we've matched Z, all we remember is that there's a wide left and we forget that we've met City.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Completion in.",
                    "label": 0
                },
                {
                    "sent": "Yeah, let's save that till later.",
                    "label": 0
                },
                {
                    "sent": "Actually, 'cause I want to.",
                    "label": 0
                },
                {
                    "sent": "I want to talk a little more generally about this.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "In essence, what we've done here is, we've just taken this one of the summation symbols, and we've moved it further inside.",
                    "label": 0
                },
                {
                    "sent": "And this is exactly what happens when you're doing variable elimination, for example.",
                    "label": 0
                },
                {
                    "sent": "So also another example of that letter that's also a traditional thing to do in India.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Best joins.",
                    "label": 0
                },
                {
                    "sent": "OK, so the general point here is that we have a system of equations.",
                    "label": 0
                },
                {
                    "sent": "Now you've all studied Gaussian elimination, so you know that there are lots of ways to rearrange a system of equations to make it easier to solve.",
                    "label": 1
                },
                {
                    "sent": "In fact, a lot of linear algebra is about, you know, decomposing and rewriting systems of equations to make them faster or.",
                    "label": 1
                },
                {
                    "sent": "Better condition, so if you transform from one to the other, it may be a win and there are a lot of tricks that I know from the world of parsing, for example, which can be generalized into these transformations.",
                    "label": 0
                },
                {
                    "sent": "This is this.",
                    "label": 0
                },
                {
                    "sent": "A really neat paper.",
                    "label": 0
                },
                {
                    "sent": "It goes quite slowly and it doesn't assume you know anything about parsing, and it shows a number of things which are sort of analogous to lifted inference, although only at static time.",
                    "label": 0
                },
                {
                    "sent": "Some of what you're doing is trying to do essentially what you're doing is, you know, transforming an algorithm from end to the fifth time to end cube time by delaying work and working for longer and a lifted domain before you've seen the input, so you can eliminate unity rule cycles and.",
                    "label": 0
                },
                {
                    "sent": "You can, you can play some games where you speculate about what how certain variables are going to be instantiated.",
                    "label": 0
                },
                {
                    "sent": "And do computation based on that speculation.",
                    "label": 0
                },
                {
                    "sent": "In the left Dome.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so let me send.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Buddy asked about all this algorithm.",
                    "label": 0
                },
                {
                    "sent": "Here it is.",
                    "label": 0
                },
                {
                    "sent": "It's about 6 lines and there's the magic templates transformation.",
                    "label": 1
                },
                {
                    "sent": "If you know that from logic programming transforms from this into that.",
                    "label": 0
                },
                {
                    "sent": "So you get that for free.",
                    "label": 0
                },
                {
                    "sent": "That was actually noted more than 10 years ago, but it turns out that if you run the magic templates transformation one more time on this then you get something called the left corner filter, which is what you really need to get this run fast so it's nice to have these general transformations that you can use to rearrange your equations before you.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And run them.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so I just want to point out that there is something a bunch of stuff that we were able to do with the prototype.",
                    "label": 0
                },
                {
                    "sent": "These are all papers that came out of my lab and they all used.",
                    "label": 0
                },
                {
                    "sent": "They all used on it for implementation.",
                    "label": 0
                },
                {
                    "sent": "And I've been using it for teaching for awhile as well.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, good, so I'd like.",
                    "label": 0
                },
                {
                    "sent": "I'd like to give you some more examples and say a little bit about implementation, but let me just actually let me let me just take a little vote on who would like to hear more about which.",
                    "label": 0
                },
                {
                    "sent": "So who would like the four things that I could talk about in the remaining 15 minutes in greater or lesser degrees?",
                    "label": 0
                },
                {
                    "sent": "Or give you a few more details of a language.",
                    "label": 1
                },
                {
                    "sent": "So like 10 slides simple slides I could give you some more practical examples.",
                    "label": 0
                },
                {
                    "sent": "I could tell you a little about what's going on to actually run inference under the hood.",
                    "label": 0
                },
                {
                    "sent": "Or I could talk a little more about program transformations, so would like to say more about vote as many times as you like.",
                    "label": 0
                },
                {
                    "sent": "It would like to see more details of the language.",
                    "label": 0
                },
                {
                    "sent": "OK, one that's interesting.",
                    "label": 0
                },
                {
                    "sent": "OK, maybe I'll show you something anyway, but more more practical examples.",
                    "label": 0
                },
                {
                    "sent": "Good, a lot of people implementation, so the inference algorithms.",
                    "label": 0
                },
                {
                    "sent": "A lot of people and program transformations.",
                    "label": 0
                },
                {
                    "sent": "OK yeah, so you know you can.",
                    "label": 0
                },
                {
                    "sent": "You can stay late or something and we'll huddle up here during the break.",
                    "label": 0
                },
                {
                    "sent": "Let me give you just.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To give you a few details of the language just so you'll understand the example, so I'll skip some of this.",
                    "label": 1
                },
                {
                    "sent": "You may have guessed that the basic objects are terms, as in Prolog, and I won't.",
                    "label": 0
                },
                {
                    "sent": "I don't think I really need to say more about this, 'cause apparently you don't care, so I'll leave this slide up and you can go read it on videolectures.net.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "I do want to say a word about the semantics, so there's a fixpoint semantics which say basically you could update these equations to convergence, and if you if all of the left hand of the heads of all your rules are consistent with the bodies, then your valid and you can return.",
                    "label": 0
                },
                {
                    "sent": "You might run forever, so then you shouldn't have written that program, it was a bad idea, the.",
                    "label": 0
                },
                {
                    "sent": "There may be multiple fixed points, and in that case we don't give any guarantee because I think that's what killed the deductive database community was arguing about, which fixed point to get.",
                    "label": 0
                },
                {
                    "sent": "I'm going to trust you to write a program where you'll actually get the fixed point that you want when you run it.",
                    "label": 0
                },
                {
                    "sent": "So this is.",
                    "label": 0
                },
                {
                    "sent": "You've got various terms in this in this diner base.",
                    "label": 0
                },
                {
                    "sent": "It's so in Prolog, the semantics is basically the set of proved things, and here it's a map from proved things to their values, which are other terms.",
                    "label": 0
                },
                {
                    "sent": "So one thing that I do want you to understand is that the database is only defining values for ground terms, and what these variables do is it lets us define values for infinitely many ground terms.",
                    "label": 1
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I want to say one more thing that you'll need just to get the notation in the examples, which is that these Maps were actually first class objects, which is quite convenient for modular programming.",
                    "label": 0
                },
                {
                    "sent": "So Edina base can appear as a subterm of another term, or as the value of another term.",
                    "label": 1
                },
                {
                    "sent": "So here we've got two finite state transducers, and if we compose them we get another finite state transducer.",
                    "label": 0
                },
                {
                    "sent": "So the definition of compose is taking two databases and producing another Dyna base if.",
                    "label": 0
                },
                {
                    "sent": "Either of these changes then this.",
                    "label": 0
                },
                {
                    "sent": "If any part of either of these changes, then this will change as well.",
                    "label": 0
                },
                {
                    "sent": "We don't have to recompute the whole thing from scratch, only the relevant parts will be re computed.",
                    "label": 0
                },
                {
                    "sent": "So we might say that FS T4 has a particular edge in this finite state machine and its weight is derived in part from the weight of some.",
                    "label": 0
                },
                {
                    "sent": "It's reversed edge in FST 3.",
                    "label": 0
                },
                {
                    "sent": "So in principle we could be shipping these done.",
                    "label": 0
                },
                {
                    "sent": "I mean, we really do want to do this.",
                    "label": 0
                },
                {
                    "sent": "We could be shipping these databases around.",
                    "label": 0
                },
                {
                    "sent": "I could take some deductive database which had some mixture of data and an algorithm and so forth and send it to you.",
                    "label": 0
                },
                {
                    "sent": "And then you can pull things out of it.",
                    "label": 0
                },
                {
                    "sent": "Could be a website.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This actually.",
                    "label": 0
                },
                {
                    "sent": "Alright, so.",
                    "label": 0
                },
                {
                    "sent": "I could say more about.",
                    "label": 0
                },
                {
                    "sent": "About databases and.",
                    "label": 0
                },
                {
                    "sent": "How do you create them and modify?",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Them and so forth, but I.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Skipping this",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I as well as the subsequent things be.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As you want to hear the exam.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_62": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Good, OK, so now let's take a vote on these examples.",
                    "label": 0
                },
                {
                    "sent": "So who wants to share more about shortest paths?",
                    "label": 1
                },
                {
                    "sent": "Neural networks we should look at that one actually just 'cause it's different information retrieval.",
                    "label": 0
                },
                {
                    "sent": "Intersection of finite state machines.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "This is kind of course defined parsing, so it has something in common with lifted inference.",
                    "label": 0
                },
                {
                    "sent": "This one is a little bit hard to understand, but I'm happy to go through it.",
                    "label": 0
                },
                {
                    "sent": "It is still short OK. Smoothing of Markov models.",
                    "label": 0
                },
                {
                    "sent": "OK, art consistency.",
                    "label": 0
                },
                {
                    "sent": "OK, maybe a couple more people 'cause you know that one mini Max in game trays?",
                    "label": 0
                },
                {
                    "sent": "OK, edit distance.",
                    "label": 0
                },
                {
                    "sent": "OK, so a bunch of votes were edit distance, so let's I'll pick some water here.",
                    "label": 0
                },
                {
                    "sent": "I didn't see a strong consensus for any of these.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so here is neural networks, so for any of these nodes, the input to a node we look at the output of its child.",
                    "label": 1
                },
                {
                    "sent": "So summing over all children and we multiply that by the weight of the of the connection from that node to the child.",
                    "label": 1
                },
                {
                    "sent": "So this is the input to a node is just a linear combination.",
                    "label": 0
                },
                {
                    "sent": "Overall it's children.",
                    "label": 0
                },
                {
                    "sent": "That's easy enough.",
                    "label": 0
                },
                {
                    "sent": "OK, except there's one more thing it might be, you know getting some external input which is providing the providing the actual example that you're training the net on.",
                    "label": 0
                },
                {
                    "sent": "So where's the nonlinearity?",
                    "label": 0
                },
                {
                    "sent": "The output of a node is a sigmoid function of the input, so we can define the sigmoid function right?",
                    "label": 0
                },
                {
                    "sent": "And I know their names.",
                    "label": 0
                },
                {
                    "sent": "And you'll notice that this no longer has distribution semantics.",
                    "label": 1
                },
                {
                    "sent": "So in the case of context free grammars for parsing, it was the case that the value of a of an item was the sum of the values of all of its proofs, but that's not the case here because we're passing through a sigmoid squashing function at every level.",
                    "label": 1
                },
                {
                    "sent": "Yeah question.",
                    "label": 0
                },
                {
                    "sent": "You're right.",
                    "label": 0
                },
                {
                    "sent": "I haven't said anything here that says that these arcs can't be cyclic, and it will just iterate to convergence, which is actually the classic classical thing that was done in neural networks.",
                    "label": 0
                },
                {
                    "sent": "You could tell it you could give it a convergence criterion.",
                    "label": 0
                },
                {
                    "sent": "But and what's more, it will do back propagation around the converge loops, which is what's called backpropagation through time.",
                    "label": 0
                },
                {
                    "sent": "So that's the automatic differentiation, and I think that was first proposed by Williams and Zipsor and like 89.",
                    "label": 0
                },
                {
                    "sent": "OK, yeah we can take this offline.",
                    "label": 0
                },
                {
                    "sent": "So if you want to measure the error, that's just the square difference between the output node output of nodes and their targets.",
                    "label": 0
                },
                {
                    "sent": "But notice that this is only provable when there's a target defined for that node, so we wouldn't want to say that this is zero if it's not defined, it just doesn't.",
                    "label": 0
                },
                {
                    "sent": "It has no value if there's no target to find, so it doesn't contribute to this sub.",
                    "label": 0
                },
                {
                    "sent": "So this is 1 example where it's helpful to have the notion of no value.",
                    "label": 0
                },
                {
                    "sent": "Doesn't need to approve.",
                    "label": 0
                },
                {
                    "sent": "OK. Good.",
                    "label": 0
                },
                {
                    "sent": "So let's see.",
                    "label": 0
                },
                {
                    "sent": "Let's skip that one.",
                    "label": 0
                },
                {
                    "sent": "So let's do something easier than vector space.",
                    "label": 0
                },
                {
                    "sent": "I mean then.",
                    "label": 0
                },
                {
                    "sent": "Then our consistency before we get there.",
                    "label": 0
                },
                {
                    "sent": "Actually.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's do finite state interest intersection.",
                    "label": 0
                },
                {
                    "sent": "This isn't too bad, so so that you can read this.",
                    "label": 0
                },
                {
                    "sent": "These are just constructors.",
                    "label": 0
                },
                {
                    "sent": "There infects functors, so we have two databases representing finite state automata ANB, and we're going to find a new one with this name.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is A intersect B.",
                    "label": 0
                },
                {
                    "sent": "And it states are going to be pairs of states in the original machine, so this is our pairing.",
                    "label": 0
                },
                {
                    "sent": "Just think of this as meeting pair Q, R, just using syntactic sugar.",
                    "label": 0
                },
                {
                    "sent": "So this says that the start state of the new machine is the power of the start states of the old machines.",
                    "label": 0
                },
                {
                    "sent": "That Q cross R is a stop state in the new machine.",
                    "label": 0
                },
                {
                    "sent": "If Q was a stop state in A&R was a stop state and B and then this is the interesting thing.",
                    "label": 0
                },
                {
                    "sent": "This is saying that we have in arc from Q1 to.",
                    "label": 0
                },
                {
                    "sent": "Are one sorry from the para Q1R1 to Q2R2 labeled by a letter.",
                    "label": 0
                },
                {
                    "sent": "If we have the corresponding arcs from Q1 to Q2 and R1 to R2 in the old machines and the weight is given by by product rule, which is the standard thing to do.",
                    "label": 0
                },
                {
                    "sent": "For reasons I won't go into and this generalizes to finite state transducers, so this will actually compute as I've written it will compute unreachable parts of the graph, but it's very easy to modify the program.",
                    "label": 0
                },
                {
                    "sent": "So that it only computes things that are reachable from start, and in fact that's just another instance of the Magic templates transform.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so so let's do art consistency.",
                    "label": 0
                },
                {
                    "sent": "So here is how our consistency works.",
                    "label": 0
                },
                {
                    "sent": "For those of you who don't know it, XXYZ&T are all random variables.",
                    "label": 0
                },
                {
                    "sent": "Maybe I shouldn't say random variables, they're all constraint variables.",
                    "label": 0
                },
                {
                    "sent": "Each can be something from one to three, so X is required to be less than Y.",
                    "label": 0
                },
                {
                    "sent": "That means it can't be 3 because three isn't less than anyway.",
                    "label": 0
                },
                {
                    "sent": "Now, similarly similarly, why can't be one?",
                    "label": 0
                },
                {
                    "sent": "Because that's not greater than any X.",
                    "label": 0
                },
                {
                    "sent": "Well, given that, why is it can't be one?",
                    "label": 0
                },
                {
                    "sent": "Z can't be one either.",
                    "label": 0
                },
                {
                    "sent": "'cause one isn't equal to any Y that's left.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is a in agenda algorithm.",
                    "label": 0
                },
                {
                    "sent": "It's basically you're just propagating updates, one is.",
                    "label": 0
                },
                {
                    "sent": "Because let's say so 3 isn't less than anything in Z.",
                    "label": 0
                },
                {
                    "sent": "So we can continue crossing these things out and eventually we can solve the whole problem just by propagation, no backtracking.",
                    "label": 0
                },
                {
                    "sent": "OK, so so let's go through those.",
                    "label": 0
                },
                {
                    "sent": "So we need to start out either by rule or by enumeration by defining some axioms.",
                    "label": 0
                },
                {
                    "sent": "So first of all we say with the domains are, so a colon here is just a pairing term as it was in the last example.",
                    "label": 0
                },
                {
                    "sent": "So this is saying a particular variable value pair is allowed at the start and then we say these are constraints this value.",
                    "label": 0
                },
                {
                    "sent": "Of this variable is consistent with that value of that variable, and you can make these default to true or false or whatever you want.",
                    "label": 0
                },
                {
                    "sent": "No, you say that a value is still possible for a variable if it was in the domain of that variable to begin with.",
                    "label": 0
                },
                {
                    "sent": "And if this is a conjunction.",
                    "label": 0
                },
                {
                    "sent": "So it's got to be in the domain to begin with and for every other variable which cares every other variable which asserts some kind of support, so some of them may not be able to prove support is either true or false, but for the ones which, which state?",
                    "label": 0
                },
                {
                    "sent": "A preference variable to that states are preference.",
                    "label": 0
                },
                {
                    "sent": "It must support that that value in that variable.",
                    "label": 0
                },
                {
                    "sent": "And why does it do that?",
                    "label": 0
                },
                {
                    "sent": "It does that so variable two supports that value of variable one.",
                    "label": 0
                },
                {
                    "sent": "If there is some value that still value 2, that's still possible for variable two has not been crossed out yet, which is consistent with this value of variable one.",
                    "label": 0
                },
                {
                    "sent": "OK, so this just iterate to convergence and that's our consistency and this will compile into the asymptotically optimal algorithm.",
                    "label": 0
                },
                {
                    "sent": "If you just run forward chaining.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Got it.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "So let me say here's edit distance.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm just going to flash these up quickly.",
                    "label": 0
                },
                {
                    "sent": "We started at like 5 after or something 10 after.",
                    "label": 0
                },
                {
                    "sent": "OK, then I better wrap up.",
                    "label": 0
                },
                {
                    "sent": "OK, let me let me run over a few minutes if I may.",
                    "label": 0
                },
                {
                    "sent": "OK, so we have.",
                    "label": 0
                },
                {
                    "sent": "OK yeah, here are a couple of versions of edit distance for those of you who wanted to see it, sorry.",
                    "label": 0
                },
                {
                    "sent": "This was the generalized Daystar parsing.",
                    "label": 0
                },
                {
                    "sent": "I'm happy to talk to people afterwards.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's probably worth mentioning that you can do iterative update algorithms quite nicely by saying a updates as a function of B and vice versa.",
                    "label": 0
                },
                {
                    "sent": "This is your initial condition, but as soon as you prove some value for B it overrides the initial condition.",
                    "label": 0
                },
                {
                    "sent": "Using: equals OK, so.",
                    "label": 0
                },
                {
                    "sent": "I guess I won't get to talk at all about the execution strategy, even though somebody wanted to hear a lot about it.",
                    "label": 0
                },
                {
                    "sent": "So the the simplest strategy is forward chaining and.",
                    "label": 0
                },
                {
                    "sent": "That's what the.",
                    "label": 0
                },
                {
                    "sent": "That's what the prototype does, and there's a lot to get that to work, but the.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So there's a number of issues in forward chaining in this more general circumstance where you're not just doing semiring weights on your programs.",
                    "label": 0
                },
                {
                    "sent": "The including this is where the lifted inference stuff.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One has to do with priorities and how you might compute the priorities directly within the program.",
                    "label": 0
                },
                {
                    "sent": "So how you decide which updates to propagate next is also done by Donna Rules.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's very wasteful to do all your computation by forward chaining, and so sort of the interesting action at the moment is in mixing forward and backward chaining, and we do have a unified picture of how to do this.",
                    "label": 0
                },
                {
                    "sent": "The interesting question is how to learn the right strategies on a particular workload, so I won't talk about.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But I automatic differentiation, which essentially symbolically gets the gets computations of the algebraic derivative.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So I'll skip over the program transformation stuff.",
                    "label": 0
                },
                {
                    "sent": "Here we've got variable elimination.",
                    "label": 0
                },
                {
                    "sent": "There we just transform the program.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so here's my summary.",
                    "label": 0
                },
                {
                    "sent": "It's the AI systems are currently pretty hard to write and modify, and in thinking about how to simplify our job in NLP systems, I think I inadvertently hit on a layer of abstraction.",
                    "label": 1
                },
                {
                    "sent": "You know, as we generalized it to do just one more thing in NLP.",
                    "label": 0
                },
                {
                    "sent": "Eventually we started to converge to something that looked like it was useful.",
                    "label": 0
                },
                {
                    "sent": "Now, for almost all the systems that.",
                    "label": 0
                },
                {
                    "sent": "That I'd like to build, or that I see other people building and I'm envious of.",
                    "label": 1
                },
                {
                    "sent": "So the simple and powerful idea is that you're defining values from other values by weighted logic programming, and that there are lots of ways to try to bring these values into compute the values when you when you need to, and to bring the heads of rules into.",
                    "label": 0
                },
                {
                    "sent": "What's the word?",
                    "label": 0
                },
                {
                    "sent": "I want to make the heads of the rules line up with the bodies.",
                    "label": 0
                }
            ]
        }
    }
}