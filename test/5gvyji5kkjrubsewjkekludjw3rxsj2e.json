{
    "id": "5gvyji5kkjrubsewjkekludjw3rxsj2e",
    "title": "Convolutional Networks",
    "info": {
        "author": [
            "Honglak Lee, Department of Electrical Engineering and Computer Science, University of Michigan"
        ],
        "published": "Sept. 13, 2015",
        "recorded": "August 2015",
        "category": [
            "Top->Computer Science->Machine Learning->Deep Learning",
            "Top->Computer Science->Machine Learning->Reinforcement Learning",
            "Top->Computer Science->Machine Learning->Unsupervised Learning"
        ]
    },
    "url": "http://videolectures.net/deeplearning2015_lee_convolutional_networks/",
    "segmentation": [
        [
            "So I'm going to talk about Convolutional network.",
            "In fact this is a very broad topic.",
            "An also number of papers are like to be honest, like exploding these days, so I couldn't cover all the papers or so.",
            "I apologize if I mean I didn't cover some of the papers.",
            "I tried my best.",
            "And also I tried to give you some intuition about what's the convolutional network and also why it works and what it can be applied in different scenarios.",
            "So I'm going to talk first about unsupervised learning.",
            "So how do we learn unsupervised learning for convolutional net?"
        ],
        [
            "And then moving to supervised convolutional learning, which is more, I mean achieving state of the art results nowadays."
        ],
        [
            "Alright, so just as a brief recap, we talked about some unsupervised learning of maybe dictionaries or basis vector from images.",
            "So for example, the representation we are trying to learn is some kind of decomposition of maybe input patches such as representing this 14 by 14 Patch as some sparse combination of basis vectors.",
            "And basically this is sort of set up Gabor filters, Ann.",
            "You're representing dispatch as or some combination of edges.",
            "So we're talking about some kind of representation starting from pixels to maybe some composition of these.",
            "Combination of these edges."
        ],
        [
            "And we can go deeper by learning the second layer.",
            "So you learn the second layer as another, maybe combination of first layer features and this learn some composition of edges.",
            "So this is a basic idea behind.",
            "I mean what can be learned using this deep network?",
            "But yesterday I mostly talked about algorithm that applies to image patches.",
            "So let's say we have 14 by 14 pixels as an input image.",
            "Then first layer encodes this basis vector for for the same size Patch.",
            "Second layer is also the some combination of these edges but still limited to this 14 by 14.",
            "So."
        ],
        [
            "In this talk I'm going to go beyond these patches and how we can actually learn features that cover larger areas and also more higher level, higher level features.",
            "So suppose that we are given some input images like this an.",
            "If we see a bunch of images of faces, an bunch of images of cars we would like to find some maybe intermediate level features corresponding to maybe parts of faces or parts of cars and so on.",
            "But just going naively applying the Patch or just concatenating this big image into a long vector doesn't really apply.",
            "Where is here?",
            "We are trying to find some gradually bigger patches so you start from small Patch and go slightly bigger and slightly bigger an at the R. At the end you want to find some higher level features that cover object parts and full objects.",
            "So it doesn't really work by just applying Patch level model naively, so we need to think about some more scalable ways of doing this and also another interesting thing to remember is that images exhibit lots of spatial correlations, so we want to exploit some models and algorithms that can handle strong spatial correlations as well."
        ],
        [
            "So here is our basic intuition.",
            "So given the input image, we consider some filters and hear the filters can be basically some oriented edges, and in fact these are learned filters from the data and you can just learn it from unsupervised learning such as sparse coding, restricted Boltzmann machine or autoencoders as well.",
            "So suppose that you just apply some kind of filter matching.",
            "So you just basically do template matching with this filter one.",
            "With the image and then you are just doing sliding window of this filter across all the locations in the image and then you get filter response and in fact this is exactly the operation that I explained for the case of restricted Boltzmann machine cause.",
            "Yesterday I told you that the activation of hidden unit is simply just computed by inner product of the filter and the input data, and then if the inner product is high, you activate the hidden unit.",
            "If inner product is slow, you deactivate the hidden unit with high high probability.",
            "So here the white pixel means high chance of activation.",
            "Black means low chance of activation and so on.",
            "So this is the activation of this filter or this basis vector across all the different locations in the image.",
            "OK, and then you do the same thing for different filter and then you get a different response.",
            "An intuitively, this white response means where this specific filters are activated in the different locations of the image an for different filters we see different pattern.",
            "And these are activation can be viewed as a representation of the input image.",
            "So again we are starting from the pixel level and then we are moving into this quick fissions of these filters.",
            "Essentially this is some kind of athlete action or some HD composition that's also commonly used in computer vision.",
            "But deep learning or representation learning algorithm can also discover this type of decomposition as well.",
            "What's more interesting is going actually into higher layer so.",
            "For example, we can consider some naive way of.",
            "Stacking another layer of feature learning so you can do any kind of your favorite feature learning algorithm, such as autoencoder restricted, Boltzmann machine, sparse coding.",
            "The trick here is that it doesn't work very well if you just naively stack another layer.",
            "Of course it depends on different application, but for the case of maybe finding bigger feature, higher level features that cover larger area.",
            "It doesn't work very well.",
            "Be 'cause if you want to find bigger bigger patterns then you need to grow the receptive field size and that means that you need larger receptive field in the second layer an as you go higher and higher layers then the number of reset the number of hidden units or a number of input units for this higher layer will grow so it doesn't scale very well.",
            "So a better idea is to basically shrink the representation.",
            "So, given that you have this filter response.",
            "Then use a shrink by factor of two by two or three by three.",
            "Then you get a smaller sized activation.",
            "The main intuition is that this shrinked representation still keeps the some basic pattern an you can see.",
            "You can see that these are quite similar to each other and also this shrinked representation is more invariant to small perturbation of the input image.",
            "And then we can do feature learning.",
            "So in the case of unsupervised learning you are basically doing some.",
            "Taking some Patch and then finding some correlation between these first layer activations.",
            "An in convolutional case we are going to also allow the filter to move around to any location of the image.",
            "And at the end, if you see similar pattern over and over.",
            "So if you provide lots of face images, then the algorithm will discover there exist some local correlation of these first layer features.",
            "That kind of look like this, so it doesn't provide direct intuitive interpretation by looking at this activation, but it turns out that if you project back to the pixel level it shows some interesting patterns such as object parts.",
            "So this is a basic idea of how we can actually discover features even in an unsupervised way.",
            "So the basic idea here is that.",
            "If in unlabeled data, if there are lots of similar patterns over and over across different images, then the algorithm will try to find some basis vector in multiple levels."
        ],
        [
            "So this actually also resembles the idea that I'm going to also talk about, which is supervised version of Convolutional Network, but I'm going to talk more about that later, But in that case you do the same kind of operations such as doing convolution and then pulling over a small location and maybe taking the maximal or maximum or some other pooling operation, and then you can repeat this procedure in higher layers such as convolution and pooling.",
            "And so on.",
            "So I'm going to just talk about unsupervised learning version of this type of algorithm.",
            "So for that case it's going to focus on one layer and you can basically learn features without any labels and then you can move on to the second layer learning and so on.",
            "Alright, so."
        ],
        [
            "Here is a algorithm for learning this.",
            "Convolutional features.",
            "So this is exactly the same as the restricted Boltzmann machine I talked about yesterday.",
            "But the difference is that we have hidden unit that covers small area in the input image.",
            "So in this case I just show three by three as a filter size.",
            "And the filter is shared across all the locations.",
            "So if you have different filter, different filter matching different location then it correspond to different location in this hidden.",
            "Hidden Notes are group, so for each filter we have some kind of this 2D activation map where each point correspond to activating filter at different location.",
            "And again I talked.",
            "I told you that it's good activation of the hidden unit is simply determined by taking the inner product between the filter an input data input image an.",
            "Depending on the inner product you activate or deactivate.",
            "But here we also consider some pooling operation.",
            "So for example, we look at two by two near neighbors and then take the maximum.",
            "For the case of restricted Boltzmann machine, this is a probabilistic operation so.",
            "This hidden unit can be active or deactive, with some probability, and also we want to model this activation of pulling unit also using some probability.",
            "Ann for computational reason, we can just restric these hidden nodes to be active in a way that only one hidden unit is active across this pulling group.",
            "The reason is that it's actually there are exponential number of configurations.",
            "If you don't have this constraint an it's actually hard to enumerate all these possible cases.",
            "And also by doing this constraint it doesn't really lose that much because most of the time if you have some filter then it will be most well matched to a certain location.",
            "But probably if you shift it around it will be less matched.",
            "So just picking the best match is a reasonable way to approximate this problem.",
            "So.",
            "We can basically formulate this problem as a unsupervised learning problem."
        ],
        [
            "Or an so here.",
            "This corresponds to a extension of the restricted Boltzmann machine where.",
            "Here it's a.",
            "It's a little compact, but the basic idea is that you have filter W&K means Kate filter, so you convolve locate filter with the input image.",
            "And basically so taking inner product of the filter in all possible locations in the input image and depending on this inner product at different location you activate or deactivate the hidden units and there is some bias terms that represent some default activation of this hidden unit.",
            "And after that you apply some constraint so that only one of the hidden unit is active.",
            "So you have a constraint that for each cell corresponding to one pulling unit.",
            "Then the sum of these hidden unit should be one or zero.",
            "OK. An if you just do some influence in terms of calculating the hidden units or pulling units based on the input and also the filter, then it corresponds to taking the."
        ],
        [
            "Product and then taking the softmax as some kind of nonlinearity or pulling unit.",
            "So the basic idea here is that.",
            "Given the inner product, so you take the inner product of WK, some filter with some specific Patch corresponding to slightly different shifted location of the image.",
            "And then you will have different values for the inner product and you pick the basically the best match and that match will have the highest probability of activation.",
            "So if you just do some some simple calculation then you can easily see that the activation probability of activating certain hidden unit is taking the form of the softmax function.",
            "Where this IL represents the value of the inner product from bottom up.",
            "So you can basically do sampling very easily, so you just sample from the softmax function and then it only has five possibilities.",
            "So if none of the filters match, then you have basically all zero activation, including the pulling units.",
            "If some of the filter match, well well enough then it will activate one filter 1 hidden unit, but deactivate some other unit and so on.",
            "So this is how we can actually do inference for this.",
            "So for this network.",
            "So then given the input image, you can calculate the posterior of the hidden hidden units and also the pooling units.",
            "And let me see so.",
            "I'm going to go back."
        ],
        [
            "This slide, so in this case of since this is unsupervised learning algorithm, there is no label, which means that we are trying to maximize the likelihood and it turns out that what?",
            "What it does in learning is to 1st calculate this hidden activations and use the hidden activations to basically reconstruct the input image, so that's the essentially corresponding to the sampling step of PRV given H. So for the case of GBM, basically we do contrastive divergent's, meaning that given the image you calculate the hidden probabilities including the pooling layer and then you sample from this hidden units.",
            "And you can do this using softmax probabilities.",
            "And then given the sample the hidden units, then you reconstruct so then you repeat this multiple generations.",
            "So essentially computing this hidden unit activation and then sampling an reconstructing that corresponds to the one step of contrastive divergent.",
            "And you can repeat this multiple steps so you can sample hidden units and reconstruct sample hidden units.",
            "And we construct and that corresponds to CDK contrastive divergent with K steps.",
            "An also I should say that this type of concept where you do some encoding or calculating the hidden units and reconstructing and then at the end it corresponds to some kind of calculating or minimizing the difference between the original input and the.",
            "Reconstructed input for the case of restricted Boltzmann machines.",
            "It is basically following some approximate version of maximum likelihood, but intuitively it is doing some kind of inference and reconstruction, and at the end the gradient is somewhat similar to the reconstruction error.",
            "An similar intuition is right."
        ],
        [
            "Waited for other algorithms as well so."
        ],
        [
            "For the case of this convolutional version of RBM, you can basically do greedy training.",
            "So greedy training means.",
            "Here.",
            "You can basically train."
        ],
        [
            "One layer and learn the filters and you can just fix the first layer and compute the activation and then you can train another layer of convolutional RBM and then do this greedy layer layer wise training.",
            "Alright, and"
        ],
        [
            "Then you can do inference in a feedforward way, which is the same as the original deep belief network."
        ],
        [
            "So here's some illustration of filters learn by the model.",
            "So given the input image.",
            "You learn filters that look like edges.",
            "And then here is the activation.",
            "So essentially these are just convolved with the input image and take some sigmoid non or sigmoid.",
            "In fact is a softmax nonlinearity.",
            "Then you get the.",
            "This type of activation.",
            "And you can learn the second layer by just freezing this activation and learning another layer RBM.",
            "And here I show the visualization of the second layer filters projected back to the image.",
            "And here is the activation.",
            "An basically we can repeat this multiple times, so here we learn the combination of filters, secondary filters that correspond to the.",
            "The full object and here is some visualization of some activations.",
            "Alright, so this one nice thing about this type of algorithm is that it doesn't require labels, so as long as you have some kind of regular pattern in the image that's repeated over the training data, then you can try to discover this type of features without any labels.",
            "And."
        ],
        [
            "This can be used for discovering some features for natural images, so for the first layer it's just the keyboard filters, but in the second layer it tries to combine these Gabor filters in different combinations, yes.",
            "OK, so let me just go back to this."
        ],
        [
            "Slide, so maybe maybe I should just show you the.",
            "Actual.",
            "Maybe it's good to go back to the RBM influence that we covered yesterday, so.",
            "Hopefully.",
            "OK, so here is the.",
            "Simple version.",
            "Where we just have just GBM with just a small number of hidden units.",
            "So what we did yesterday is basically.",
            "Think about this energy function and the influence was.",
            "Basically taking the inner product so if you have a filter then you do filter times the input data so you take the inner product between W one and V. An if the inner product is high, you just activate with high probability, or if it's not large enough, you just set it to zero with high probability as well.",
            "So you do that for the same same way with the same way for different colors, different hidden units, so blue and green you get.",
            "You do basically some sort of independent influence.",
            "So it turns out that it is just calculating the hidden unit activation and it is basically taking the inner product an applying sigmoid nonlinearity.",
            "So that was because there is no constraint, so you just independent deactivate 1 hidden unit at a time and it just corresponds to a soft version or probabilistic version of this binary activation that actually correspond to sigmoid.",
            "So that's what we did yesterday.",
            "So maybe going back to.",
            "This convolutional RBM case.",
            "Hopefully.",
            "Let's see.",
            "Alright.",
            "OK, so.",
            "So in this case, the difference is that because we have."
        ],
        [
            "Of this constraint.",
            "So we have a constraint that the hidden units corresponding to the same pulling group should be activated in a way that only one can be active.",
            "So that basically."
        ],
        [
            "We are.",
            "Changes this activation function from the sigmoid to the softmax.",
            "OK, so in fact, if you only have 1 unit for one pulling group then this is exactly the same as sigmoid.",
            "But because you have multiple hidden units that are competing for activation, it is actually softmax.",
            "Yes.",
            "Yeah.",
            "This model, yeah.",
            "OK."
        ],
        [
            "Filters yeah, OK?",
            "Activate that's right, yeah?",
            "So first layer filters are, roughly speaking, basically to detecting edges.",
            "OK. An in the second layer, I mean it is basically.",
            "Very similar in the second layer as well.",
            "I mean if you see some repeated patterns then it will try to learn the filters and it will try to activate the filter so.",
            "ICA coefficients and apply ICA?",
            "So I think it maybe also is related to whether you do convolution or not.",
            "So in fact if you do the same thing without convolutional extension, it is actually difficult to learn these filters.",
            "The reason is that if you have the exactly the same pattern, or if it is shifted a little bit, if you just take the Patch then they are very different so.",
            "So either you learn a very redundant patches, redundant filters, or it's hard to learn a good filter, whereas for the convolutional version you can use the same filter but in a different location.",
            "So if the input pattern is shifted around then you can just shift the filters and activate it in a slightly different location, so you can use the same filter so it learns actually non redundant features.",
            "So that's one advantage of doing convolutional learning and also similar observation has been made in other papers such as Jan Mcluen's Paper at NIPS 2010.",
            "They also show some contrast between filters learn from the non convolutional version of their algorithm and convolutional version of their algorithm and show that convolutional learning gives you much more compact and non redundant filters.",
            "OK. Alright, so."
        ],
        [
            "Here is the hierarchical features for natural images.",
            "And we see that the second layer filters can find some kind of.",
            "Conjunction of edges."
        ],
        [
            "An you can also learn features corresponding to maybe different objects object categories.",
            "So here I use the same filters, just learn from the natural image but train for different object categories for the second and third layers and find some kind of hierarchical features.",
            "As the layers go up and it can be useful for several vision problems such as classification or verification or like alignment and so on, yes.",
            "So that's a great question.",
            "So visualization I use some heuristic where I clamp the hidden unit.",
            "And then just.",
            "Basically apply this.",
            "Some convolution is it's actually some so-called deconvolution.",
            "So maybe I should."
        ],
        [
            "Go back to this picture so if I fix the maybe 1 hidden unit here.",
            "I mean then if I say one as activation then it will basically activate this small region which is basically some maybe 10 by 10 Patch in this third layer activation.",
            "And then since it goes through so it's actually 10 by 10, that corresponds also 10 by 10 activation here.",
            "And since it goes through this Max pooling, I just apply basically some heuristic where you just resize this activation by two factor of two.",
            "So you have 10 by 10 Patch in this secondary activation an make it twice larger.",
            "And here from here to here it is actually a convolution operator so.",
            "Basically, I apply these so called deconvolution which means that you use this small Patch to activate the first layer activation here and then it since it also goes through the pooling operation, you just make it larger by factor of 2 and that's basically how we do visualization.",
            "I mean, that's just one way of doing it.",
            "But there are so many different ways to do that, so most recent ways of doing visualization is just taking the gradient descent.",
            "So in fact I haven't tried for this model, but you can just think about the image as a sum variable and you try to take the maybe top layer activation as output and users to simple gradient descent.",
            "So you just do gradient descent under some reasonable constraint such that.",
            "This, whatever hidden unit is maximized hidden in the activation, is maximized.",
            "Then very interesting it can find a good kind of pattern that also somewhat mimics or is kind of similar to this, and that's one way, but there are several different ways that have been proposed.",
            "For like how to visualize this deep network?",
            "Can you repeat the question?",
            "Yeah right yeah.",
            "OK, so."
        ],
        [
            "He also features that can be learned from the this convolutional learning of RBM's butt."
        ],
        [
            "In fact, it actually can be also done in a similar way for a different unsupervised learning as well.",
            "So here is a convolutional extension of sparse coding, so it was done by young raccoons group.",
            "So the basic idea is very similar, so you have some input image X and then the filter.",
            "Filter decay so DK here is a dictionary or filter and ZK is the activation.",
            "Or you can think about the OK.",
            "So the first term is about minimizing the reconstruction between the input and filter times.",
            "Basic filter convolved with the hidden unit activation an you sum over the all the filters.",
            "Then that's the summation of all the contribution of reconstruction from different filters.",
            "And you want this to be small.",
            "At the same time, there is a penalty corresponding to sparse sparsity, so you want the hidden units to be sparsely activated.",
            "So there is a L1 penalty for the Z and this second term is an interesting term.",
            "The main idea here is that it is actually difficult, fairly difficult to just do optimization when you have some some of continuous function plus L1 penalty.",
            "An in fact it is doable.",
            "It's it's a convex function, but it actually is very computationally expensive.",
            "So what was proposed here is to approximate this hidden unit activation as some kind of feedforward function.",
            "So you just take the.",
            "In our product with the filter and the input.",
            "So you basically calculate the match between the filter and the input data and then you go through nonlinearity.",
            "So in this paper they used some function that looks like this which is called a soft thresholding function.",
            "Intuitively speaking, if the activation is not big enough, then you just truncate to zero an.",
            "If it is big enough so it's over a certain threshold, then you activate it.",
            "At the end, this is still an approximation, so but it gives a reasonable initial initial starting point for the coefficient.",
            "So then basically you have a penalty term that corresponds to actual optimal ZC with this approximated version of the coefficient, which is done by simple like filter response followed by nonlinearity.",
            "And.",
            "So you want to find a good approximation of this filter activation and then also you learn the filters altogether.",
            "So at the end they still do this L1 optimization, so they try to minimize this whole objective function.",
            "By solving this whole I mean this objective, so you get the optimal Z and then basically in order to minimize this error you want to find good filter.",
            "So in fact this actually corresponds to, I mean very high level in very high level corresponds to basically some recognition unit in deep belief Nets.",
            "Recognition weights because it's approximating this activation using certain some different parameters.",
            "An then also you minimize the reconstruction error OK.",
            "So some more details is provided in the paper, and please look at this if you are more interested.",
            "And then here I'm showing the filters that are learned from this algorithm.",
            "So you learn the first layer filters that look like this so it learns some edges and also it learns some other filters corresponding to some dots and some blobs.",
            "And in the second layer they also find some combination of these filters.",
            "So.",
            "It's hard to interpret, but it's some combination that is more richer than the first layers.",
            "Any questions here?",
            "So underlying theme here is that for unsupervised learning algorithm you have some kind of approximate calculation of doing some or some probabilistic calculation corresponding to encoding and decoding.",
            "So in this case this corresponds to encoding function and this corresponding to decoding function.",
            "So you want to find the model so that you do some encoding to approximate this hidden activation and then do some decoding but at the same time you want to have a sparse activation.",
            "And maybe just going back to this convolutional RBM is to basically very similar story so.",
            "In that case, you do some encoding using this RBM activation function and then you do decoding implicitly using contrastive divergent an at the end.",
            "The gradient is like somewhat very reminiscent of reconstruction error.",
            "Ann is it is done in a technically different way, but intuition is very similar."
        ],
        [
            "And here is another version of convolutional learning called Deconvolutional Network.",
            "In fact, this is very similar to the just the version that I just showed, but in this case this doesn't have any encoding function, so you can think about this as a more like direct extension of convolutional sparse coding, because in sparse coding you don't have a encoding function, you usually have a decoding function only, so here.",
            "So in this case, why is the input image and see corresponds to different channel?",
            "So for the case of RGB, C would be 3.",
            "And then you have a filter.",
            "That corresponding to Kate filter here and then you are doing convolutions.",
            "So ZK is to coefficient.",
            "So here is the basically the same term.",
            "This time is exactly the same as the first term in the previous slide.",
            "So you have convolution with the filter when their hidden activation and you calculate the reconstruction error and then you want to minimize this reconstruction error.",
            "On top of that, you have a spicy penalty, so you want the hidden units to be sparsely activated.",
            "So it's pretty much the same objective as the previous one, but the difference is that it doesn't have an encoding function, so.",
            "I should say that there is.",
            "I mean intuition is very similar, but optimizing this this objective is a little bit different and also.",
            "In this, if you are more interested, you can take a look at this paper Zeiler and Fergus on deep convolutional network.",
            "They propose some efficient way of solving this using some iterative computation.",
            "But again, the story is very similar, so you somehow calculate the hidden in the activation and then you decode it back so that you minimize the reconstruction error.",
            "An here.",
            "These are the filters.",
            "Learn from the first layer so I'm showing filters, learn from different datasets, they are slightly different, but also shows fairly similar patterns.",
            "So in the first layer it finds some edge detector and in the second layer it finds some combinations.",
            "And in the third layer it finds some.",
            "Maybe slightly more, richer combination of the second layer filters.",
            "OK, so I'm going to move on to supervised learning of Convolutional Network.",
            "So before we move on any do you have any questions?",
            "Yes.",
            "So you can do.",
            "You can recursively apply this for multiple layers, so it was basically you learn the first layer and after learning the first layer you calculate this hidden coefficient ZK cki that corresponds to.",
            "A Kate filter at for the image and it will look like some kind of 2D activation map and you have bunch up to the activation map and you do the same learning.",
            "You just take this C as an input for the second layer and then you do the same learning and then it's basically recursion, yes."
        ],
        [
            "Previous one so it is.",
            "Yeah, I think it is basically the same.",
            "Same term, but here it is assuming that X is a 1 dimensional.",
            "To the sum image.",
            "So that's why you don't have a summation.",
            "But if you have multiple channels, so I mean if you have RGB image then you need to treat this as a 3 channel input image.",
            "Then you should have a sum over the channel and it should be summed over three times.",
            "And generally speaking you have multiple feature Maps.",
            "So for example you have here about.",
            "Approximately like 50.",
            "Yeah, something like 50 features here.",
            "So then, which means that?",
            "I mean, maybe it's good to go back."
        ],
        [
            "To this.",
            "Activation map here.",
            "So if you think about this type of activation, I'm just showing a activation map for one filter.",
            "So if you have one filter then you do convolution and then you have some filter map here, so different filter will have different feature map for sparse coding is the same thing.",
            "So if you have multiple filters so if you have filled 50 filters then you have 50 filter Maps that corresponding to the representation of the input image.",
            "So as you learn the second layer, basically you have input 2-D2D image that's has 50 channels, and then it's basically some kind of 3D matrix.",
            "So, generally speaking, the input can be viewed as a 3D matrix and then you do some convolution operation."
        ],
        [
            "Yes.",
            "Uh huh.",
            "Yeah, uh, huh.",
            "Right?",
            "There is also a convolutional version of autoencoders.",
            "I actually didn't put in the slide, but I think that I believe that the 1st paper is from the European schmidhuber's Group.",
            "They have 2011 paper on convolutional autoencoder.",
            "But they basically the idea is very similar.",
            "I mean, of course the actual objective function.",
            "And how do how they do inference is different.",
            "In their case are essentially it is.",
            "Doing some encoding functions.",
            "So given the input image X, you do encoding so you get some some nonlinearity followed by this convolution.",
            "That's the activation and then you just directly use this as a Z and then you do basically so called deconvolution that project back to the input image and then you minimize the reconstruction error.",
            "So in that case you don't have a sparsity as a sort of L1 penalty and so on.",
            "So it is actually simpler in terms of the actual feedforward or learning, but.",
            "Maybe there is some.",
            "Also, I think it probably requires some additional regularization or trick too.",
            "You do some sparse attempt to incorporate sparsity and so on, yeah?",
            "Uh huh.",
            "They show some good results on Cifar data set, I believe, so they I think they show some positive results on some image classification as well.",
            "But maybe very systematic comparison of different convolutional learning algorithm is not done yet.",
            "As far as I know, so it's hard to compare head to head among these algorithms.",
            "Are gram yeah.",
            "Earlier.",
            "That's right, yeah.",
            "Uh huh.",
            "That's right, right, right?",
            "Yeah, yeah.",
            "Yeah, this is also crisis paper as well.",
            "Yeah, right good yeah so.",
            "OK. Alright."
        ],
        [
            "So."
        ],
        [
            "Move on to supervised learning and that's actually."
        ],
        [
            "Really, driving the state of the art in computer vision these days, so probably this will be some focus of today's talk.",
            "So one of the most early success of Convolutional Network is basically young black ones work.",
            "And.",
            "This is the basic architecture, so given the input image, you basically do some convolution and then get the filter activation and then take the sum subsampling so you can take the Max or the average or some other pooling operations.",
            "So you do convolution and pooling and then convolution and pooling.",
            "So roughly speaking when you do convolution, the feature map has the same size roughly the same size as the input image.",
            "In fact, if you do some so-called valid convolution, then the feature map is size is slightly reduced about this size of the filter.",
            "So if you have N as a input, so let's say the length of these images N and the filter filter length is W, then the feature map is going to give you N -- W + 1 if you apply various so called valid convolution.",
            "But roughly speaking, since the filter size is small, the approximately these two are the same size.",
            "There are slightly different version of doing convolution, so there is also so called same convolution in Matlab notation, and then it is basically some padding some extra like pixels around this image, an so that the output of this feature map is the same size as the input image.",
            "So there are some details, but high level intuition is that the.",
            "The size of the filter map is going to be similar to the input image.",
            "An if you apply this subsampling then it will get reduced by some constant factor.",
            "So if you do 2 by two Max pooling, then this will be reduced by factor of two and so on.",
            "So basically you repeat this convolution and pooling convolution and pooling the difference between supervised versus unsupervised is that you don't actually try to reconstruct the input image users purely to the state four path.",
            "So the learning is driven by some classification or some discriminative objectives so.",
            "So at the end you do some convolution pooling, convolution pooling and at some point users concatenate all these intermediate feature activations as well, just along hidden vectors.",
            "And then you do some fully connected layers and at the end you have a classification layer.",
            "So for this particular network it is trying to classify the input image as one of the 10 classes.",
            "And it's used for the handwritten digit recognition, so the learning is driven by.",
            "Basically this class class label and you try to minimize the output layer so you have a for this case.",
            "In this case you have a softmax softmax layer and then you minimize the cross entropy between your softmax output with the actual class label and the error signal is back propagated through the whole network.",
            "To learn the weights.",
            "So that's how we can do supervised learning of Convolutional network, yes.",
            "Yeah.",
            "So yes, I mean based on this figure, yeah, it is basically 6 feature map right?",
            "And then you just shrink it by factor of 2?",
            "AS22SC3 how I see.",
            "So yes, I think basically the filter you have here, I think it's 10 by 10 filter, but 10 by 10 filter means that it actually covers the six channels.",
            "So the filter, the weight or weight matrix for this filter can be viewed as 10 by 10 by 6.",
            "OK, so 3D matrix.",
            "But convolution is done in 2D, but you have to sum over the channels OK. Any quest, any other questions here, yes.",
            "Gaussian connection.",
            "Yeah.",
            "So I think in this particular model probably they used the maybe squared loss.",
            "I'm not exactly sure I that's probably what it means.",
            "Gaussian connections, so I mean in some cases you just do.",
            "You represent the classification loss using just the squared error.",
            "So you have just output.",
            "And the label.",
            "And then you just calculate the L2 error or just take the square of this error component wise.",
            "And that's the loss for the case of classification.",
            "Probably actual softmax using the softmax as a final layer and then doing cross entropy actually works better.",
            "Makes slightly more sense for the case of classification but.",
            "Also, is it true that people use the square loss and sometimes it actually works quite well so?",
            "Yes.",
            "Yeah, it decreases the resolution, yes.",
            "Right?",
            "Passing through the location of the maximum.",
            "Arm.",
            "I'm not aware of the work that actually explicitly passed through that location of activation.",
            "But in fact, if you basically keep track of the active like switch units and so you can think about this subsampling as a sum, maybe taking the Max operation.",
            "I mean, for the case of Max, then you can just remember which which location was used was the maximum within this small region.",
            "So if you keep track of that, it implicitly remembers this.",
            "All this location information.",
            "So that can be actually possibly useful for reconstructing the image, or doing maybe other tasks that relates to maybe maybe segmentation and so on, but.",
            "I mean, if you remember, I mean implicitly if you take the maximum and then you can just remember 1000 where one correspond to the actual exact hidden unit that gets passed through as a maximum, and that's the implicit way of remembering the location.",
            "I mean, I think it's done in a different application.",
            "Most most of the time.",
            "If your goal is to just do classification an if it doesn't really matter where the pattern is in the input image, then there's no reason to remember that location.",
            "But if your goal is to maybe reconstruct or maybe some visualization of the image, then it is actually useful to go back.",
            "So also there is a work by Massillon Rd focus where they use the convolutional network.",
            "So do feedforward influence, but they actually go back to the input image.",
            "And basically do some deconvolution and to visualize the sum of some part of the image that corresponds to some activation of these hidden units.",
            "So it can be actually very useful for visualizing the convolutional network.",
            "Yes.",
            "Question.",
            "S4 and S2.",
            "From here to here.",
            "So are you saying that whether you should have connection from S2 to full connection?",
            "So yes, this is for classification.",
            "I mean.",
            "Across multiple.",
            "Oh, I see.",
            "Um?",
            "Yeah, I mean the basic idea is that I mean for this case users the you have some achieved.",
            "I mean learn some high level feature activation and then at some point you don't need a notion of spatial location.",
            "Or maybe I mean.",
            "The reason that you do convolution is that if you have some input pattern that's slightly shifted around, you want to detect this regardless of the small shifting.",
            "So this convolution pooling convolution pooling is useful way of achieving more invariant features, and it can be robust to some small variation of the pattern.",
            "At some point.",
            "I mean, if you assume that the input feature was approximately at the center of the image, then you don't need to repeat this convolution pooling over and over.",
            "So at some point it makes sense to just concatenate all these hidden units to long vector and that's why you use the fully connected layers.",
            "So.",
            "That answers your question.",
            "And I can talk offline.",
            "I mean yeah, if you have more questions.",
            "Alright, so yes.",
            "I don't think there is a very like systematic way of doing this, but most of the time you.",
            "Yeah, you just.",
            "I think so.",
            "Somehow transfer the network that actually works well and you do some variation.",
            "So in this case they use 5 by 5 filter for the first layer and.",
            "Let's see.",
            "Yeah, so roughly speaking, the filter size shouldn't be too large.",
            "I mean, so that's a kind of very high level rule of thumb and also the Max pooling.",
            "Usually you do by a factor of two or three at most, so you don't do too aggressive polling.",
            "So that's maybe how things are done.",
            "And also in most recent work people found that using very small filter is actually beneficial, so using the very small filter but go.",
            "Very deep that actually also mimics the similar.",
            "Actually, it approximates the any other type of bigger convolution, but actually it's better represented power and better classification results, so I'll talk a little bit about that later.",
            "Oh yes.",
            "OK, so."
        ],
        [
            "Move on so these are the kind of standard like way of constructing the convolutional network.",
            "So basically you do convolution an apply some nonlinearity and then do some pulling and then you have some feature map in.",
            "After this one layer calculation and then you repeat this multiple times and for the case of classification users to fully connected layers and then connect with the loss coming from the supervision and then do some backpropagation.",
            "So I'm going to talk a little bit more."
        ],
        [
            "Some of these operations, I mean this kind of recap of what I just talked about for the unsupervised learning, but hopefully it will be a good recap.",
            "So basically, given the input.",
            "Pixels you have some dictionary so you do some convolution and then you do some nonlinearity and then you do some pulling operation typically sum or average or maximum operation an the last step is optional.",
            "It's actually normalizing locali among these feature responses.",
            "But in the most recent work, people also show that it's not necessary to have this normalization step to achieve good results.",
            "So this can be viewed as an optional module, and then you can repeat this multiple times."
        ],
        [
            "So again, this is a very similar picture I showed previously, but just as a recap, we have a filter and then you can do convolution and you have a filter response an.",
            "Basically this is the output of corresponding to this specific filter.",
            "So if you have different filter then.",
            "You can do another convolution and then you will have a different feature map.",
            "So if you have maybe 20 filters then you have 20 feature map like this.",
            "OK, OK."
        ],
        [
            "And one important thing to do is to apply some nonlinearity, because if you don't apply nonlinearity then repeating this convolution multiple times is just still a linear operator, so adding this nonlinearity is important in making this feature active features to be more invariant anrich.",
            "And also the represented power up the network can be significantly increased, so the most popular way of doing nonlinearity is tangent age sigmoid or rectified linear.",
            "In particular, the rectified linear is actually just the activation function that look like this, which means that if the filter activation is less than zero, then you just truncate to 0 if it is larger than certain threshold then you just.",
            "Take that value.",
            "It is a very simple nonlinearity, but this type of nonlinearity has achieved the state of the art results in many vision benchmarks.",
            "So this is sort of used as a preferred option or used as a default.",
            "So that's one maybe.",
            "Difference between unsupervised learning versus supervised learning becausw.",
            "In supervised learning you can use any kind of nonlinearity and you can mix and match and so on.",
            "Yes.",
            "Right?",
            "Yeah, it's pretty much the same, yeah.",
            "I mean, there's I don't think there is a very special like difference between fully connected or convolutional layers.",
            "I mean, if you just just remember one thing, I should say that rectified linear works really well.",
            "So I think somehow also for some reason it's easier to train.",
            "So I think one difficulty of training supervised Convolutional network was also by partly due to maybe not using the good active nonlinearity function.",
            "So in the old days basically either tangent H or sigmoid was used and also the amount of amount of labeled data was not.",
            "Enough so for with all these combination it.",
            "I mean it was shown that it was not very easy to actually learn, train or supervised convolutional network.",
            "But I think the recent study shows that some kind of rectified linear nonlinearity is probably better than this other nonlinearities.",
            "It makes the learning easier.",
            "And of course there is another factor which is the existence of the huge labeled datasets, so.",
            "Yeah, I'm not aware of the actual.",
            "Like very systematic study of, you know, just teasing out the effect of tangent, a sigmoid rectified linear for the large scale image recognition benchmarks.",
            "But I think empirically rectified linear actually works better than the other nonlinearities.",
            "Yes, yes.",
            "Yeah.",
            "Why it was not used?",
            "Yeah, uh huh, yeah.",
            "I think it's just I mean that.",
            "I mean, it's hard to say since I didn't I was not at this time to try these things, but.",
            "I mean basically rectified linear.",
            "It was also more recently discovered.",
            "I don't know.",
            "I'm not sure if people really didn't think about it along time ago, but for some reason.",
            "I mean, there are some other like justification rectified linear in theory and also.",
            "In some recent study I mean people.",
            "Seriously, I didn't.",
            "I don't think people really seriously try rectified linear, so probably that's the reason.",
            "Like maybe I can say yeah, yes.",
            "Uh huh.",
            "That's that's probably also yeah.",
            "Yeah.",
            "Well.",
            "Yes.",
            "Yeah.",
            "Right, right?",
            "Probably you sure is a better person to answer discussion, yeah?",
            "Yeah, OK, so OK. Let's just move on."
        ],
        [
            "And then you do pooling so you can do maximum or some, so I mean it's very simple operation, you just take some local Max or local some and you shrink this feature map to smaller size of, still keeping some some essential information about this input data.",
            "An so."
        ],
        [
            "Let's see and then you can do some normalization, so this is sort of optional step.",
            "Nowadays, but the basic idea here is that you take the some point and then you look at some nearby region and then you take the sum squared sum.",
            "I mean squared activation and some some kind of average activation around this area, and then you either subtract or divide by this average activation nearby and then that allows you to have a more evenly contrasted activation map.",
            "So the main reason you do this is to somehow reduce the contrast.",
            "I mean here you may have a very high activation or very small activation in different locations.",
            "And also if you have very high activation, then it's also likely that nearby regions also will have a high activation.",
            "Whereas if you do some normalization then you can kind of reduce this like strong correlation between activations and also reduce the high contrast and so on."
        ],
        [
            "So it is a very reasonable idea, but also recent study shows that is not always necessary.",
            "So here are some applications.",
            "So it has been very well demonstrated that this convolutional network achieves excellent results on different type of digit recognition and text recognition tasks such as amnesty or Chinese characters, Arabic characters and traffic signs and House now."
        ],
        [
            "Hours and so on.",
            "More recently.",
            "CNN has been used for classifying images for image net this is."
        ],
        [
            "I won a important practical breakthrough for the convolutional neural Nets, so this was the model proposed by Alex Kryszewski, an alias with Giver and Jeff Hinton from University of Toronto.",
            "So it's just a very big convolutional network.",
            "You have 224 by 224 as an input image, and then you basically go through.",
            "It's the same same type of operation, convolution and pooling, convolution and pooling an.",
            "At some point you just take the this activation by concatenating and then put the fully connected layers and at the end you have a classification layer.",
            "So in this case the target is 1000 class so.",
            "You have 1000 softmax outputs and then you just have a softmax.",
            "Softmax Ann.",
            "You use the cross entropy to define the loss and then you just do back propagation.",
            "There are some some difference between the original CNN and this one where they use parallel GPU's so they have another kind of channel, another column of the CNS, that kind of go through in a two independent stream ways.",
            "But this just some minor variation.",
            "Essentially this is almost the same as the original CNN.",
            "But the difference is that it's much bigger.",
            "An also is train with much bigger data, so for the case of Imagenet it's 1,000,000 images.",
            "And also in order to make this I mean trained.",
            "Then you need a very high power in computational power.",
            "So Fortunately the GPU was available at this time.",
            "So basically they could train the model within a reasonable time.",
            "So, so this model achieved."
        ],
        [
            "1st place for the Imagenet competition in 2012.",
            "And back then, or there were some runner ups that didn't use the convolutional network and the gap was really big, so this was one transition point where people in computer vision community or convinced that CNN is actually the much better than some other like non deep learning approaches for this type of image recognition tasks an.",
            "Here are some."
        ],
        [
            "For more recent results.",
            "So in 2013 basically pretty much all the entries leading entries used, the CNS and the error rate reduced from like 16 to about 1111% and."
        ],
        [
            "Similar trends is repeated for the 2014 competition, so again the error rate cuts reduced almost by a factor of two and the winning entry was the work by Google.",
            "And I'm going to briefly talk about this visual Network and Google Net later.",
            "So yeah, but the trend is that we get very significant drops of the error rate every year, so I'm very curious how the results will turn out for this year's results."
        ],
        [
            "Alright, so.",
            "Here is some interesting study about how this learned representation looks like, so if you visualize the features so this is the embedding to just visualization purpose, so using the testing algorithm, so you just calculate the gist feature just feature.",
            "That's actually quite popular in computer vision to represent some scene and some context of the image.",
            "An different color represents different class.",
            "And we see that just using some low level handcrafted features, the IT doesn't provide good separation between different classes.",
            "And here is a also visualization of the first layer convolutional activation feature activations.",
            "It's called decaf one.",
            "It is so specific CNN implementation using CAFE and also there is a public publicly available feature and also CNN model called Decaf.",
            "So using the first layer CNN you get you still don't get a very good separation.",
            "However, if you visualize this top higher layer features then you see much clearer separation between different classes.",
            "So this suggests that the CNN actually learns some embedding that implicitly separates different classes in a fairly fairly.",
            "Fairly clear way, so this is giving some intuition why the CNN can be powerful for classification.",
            "On another, maybe intuition is that if you consider the image manifold, I mean we're talking about 1,000,000 images with thousand different classes, an even for the same class.",
            "If you look at pixel values of the two different images, they would like you know very different location if you just project into the Euclidean space.",
            "But basically what they're trying to show is that as you map to the higher layers, you can somehow learn some manifold so that similar examples from the similar classes mapped to close by locations in this higher layer manifold.",
            "So that's another intuition we get out of this figure."
        ],
        [
            "And here are some results on so-called domain adaptation.",
            "So the basic idea is that you just pre train the CNN features from the image net and then apply to different tasks different image datasets.",
            "So the basic idea is that different image sources or different image data set has slightly different statistics or patterns.",
            "So for example images from image NET.",
            "It's different from images from Amazon, or images from web Cam.",
            "I mean there are some different statistics of pixel values and camera conditions and resolutions and so on.",
            "Ideally we want to have a good feature that works well across all these datasets, So what they show in this paper is that CNN features is actually very good for domain adaptation, so see CNN features from image.",
            "Net can be applied well to maybe Amazon or webcam images as well."
        ],
        [
            "And here is some other results.",
            "So again, it's the same story.",
            "So you apply CNN features, train from Image net.",
            "And then apply to Caltech 101 and it shows very good generalization performance.",
            "Starting from just a small number of labeled image."
        ],
        [
            "And here is the similar results using CNN features and compared to some existing work on feature learning.",
            "And it shows much better generalization.",
            "OK."
        ],
        [
            "And here is a similar story.",
            "So this is some just a systematic evaluation of CNN features for different.",
            "Different tasks and again it shows that.",
            "It is significantly improve some previous state of the art that didn't use the CNS."
        ],
        [
            "Alright, I'm going to talk a little bit about most recent state of yes.",
            "Yeah.",
            "Uh-huh yeah."
        ],
        [
            "OK. OK.",
            "So yeah, this is the six layer features of the CNN.",
            "This is the seventh layer features of the CNN.",
            "It doesn't really tell that conclusive way.",
            "I mean, in this case, probably intuition is that I mean the performance is roughly the same.",
            "I mean, it's not really the case that.",
            "Seventh layer is significantly worse than the fixed layer.",
            "I mean, maybe the intuition is that for the fully these are the fully connected layers, so also more close to the classification for image net so.",
            "It's kind of saying that this top layer features are maybe slightly more accustomed to.",
            "Our custom to do class like Actual image net classification.",
            "So it may or may not be the best feature for transferring to the other tasks, but it's probably just like one study, one paper that shows this results.",
            "I think there are some other results where actually going deeper is actually a good thing, so I'm going to talk about that when I talk about this Fijian Google net results.",
            "OK, so.",
            "Let's just talk about the."
        ],
        [
            "More recent architectures.",
            "So here is a basically so called VGG network.",
            "So the basic idea here is that you can just do many many convolutions with small filters.",
            "So in fact, if you consider a 7 by 7 filter.",
            "Then it is actually very similar to just using a 2 three by three convolutions.",
            "OK.",
            "So if you do convert convolution with three by three and then take another convolution with three by three, then.",
            "And then basically the filter and you can actually just do some decomposition of large filter into multiple convolution with small filters.",
            "And on top of that you can also add nonlinearities such as rectified linear.",
            "So the basic idea is that if you just do one convolution with 7 by 7 filter.",
            "11 Maybe possible disadvantage is that it takes some more computational resource, so it is slower to do.",
            "Just do 7 by 7 convolution.",
            "Whereas if you just do three by three, convolution twice is actually computationally cheaper and another reason is that if you apply nonlinearity after each of these three by three convolution, then the this output is much more like nonlinear function compared to just applying 17 by 7 convolutions.",
            "So they're basically achieving some advantage by just thinking about convolution breaking convolution filters, large convolution filters into.",
            "A recursive like small convolutions and also adding this nonlinearity.",
            "So this is just one kind of like summary of what they do.",
            "So for example they in this case they apply this four convolutions with filter size 3.",
            "So you just apply three by three convolution nonlinearity rectified linear and then three by three rectified linear and so on.",
            "And right so for example.",
            "If you do this then it is for example this.",
            "This filter is equivalent to just.",
            "I mean in terms of receptive field size.",
            "It is similar to applying 11 by 11 convolution ones, but because they do this multiple times, it is computationally cheaper and also it achieves much richer like function mapping through this nonlinear nonlinear functions and their compositions.",
            "So that's the basic idea of this work.",
            "So, so in this case they have a very deep network, such as like 16 layers, But I mean, although it sounds a bit intimidating, I mean one reason that they have such big deep network is that because they are decomposing this sum one convolution into many small convolutions OK. Any questions here?",
            "So it turns out that this achieves much better results on image net classification.",
            "So compared to this so called Alex Net that I just showed before, this type of network actually is considered much better as a image features and also."
        ],
        [
            "For many different vision tasks.",
            "And here is another work by Google.",
            "The idea is actually very similar.",
            "So again, the basic idea is that.",
            "You apply small convolutions, an even one by one convolution an so the reason that you apply one by one convolution is that you actually apply some nonlinearity, so it is not just a linear function, it is some kind of adding some slight learning arities through this one by one convolution.",
            "An also one reason they just do this type of multiple sized convolution is that you somehow.",
            "Approximate the phobia in the visual cortex where I mean given the same location, you look at the one by one centered at this location, and then you look at three by three convolution and five by convolution.",
            "So it is basically looking at different slightly different context with different sized receptive field an at the end it just puts all together.",
            "So arguably this can be better than just using three by three convolution alone.",
            "OK.",
            "So this is yes.",
            "You don't plateau at some point, yeah, right?",
            "It'll plateau in some point, I mean.",
            "I think also for the.",
            "1st for this type of data set there are some errors in the labels.",
            "I mean the labels are not perfect, so at some point it'll it'll converge to like upper bound.",
            "Maybe I think we are getting very close.",
            "Right?",
            "Yeah, it's hard to say, I mean, but I think they tried many different architectures when they do this competition.",
            "So basically they're presenting pretty much the optimal structure, But another maybe issue is that it takes a long time to train this model, so it's actually hard to do very systematic evaluation or exploration of this architecture, so.",
            "Yeah, I think.",
            "I mean, so far the basic results people show is that a very deep network.",
            "But in essence I mean it's not necessarily really, really big or really deep, but it's more about maybe adding many small convolutions is better than using bigger convolution filters.",
            "And here is a slightly different story.",
            "But it's also saying that some kind of small convolutions with.",
            "Concatenating with different spatial context is actually better than no or single receptive field size and so on.",
            "So this is just one module of this Google Net and this is."
        ],
        [
            "So like just a whole diagram of what they did, so it's very.",
            "Fairly deep network, or, again, it's basically like just some recursive application of this module and.",
            "And in fact, these these two I mean the Google net and."
        ],
        [
            "Digital net achieved the state of the art results for this large scale image net classification so.",
            "So the Google net results is here and the vision that results are here.",
            "So these are roughly comperable.",
            "I mean, these two are actually much better than.",
            "Original kryszewski's like Alex net.",
            "So nowadays most of the like state of the art results are achieved by this network.",
            "So I mean basically you can use the features from the vision Net or Google Net for other tasks, so that's usually better than using the Alex net features.",
            "OK."
        ],
        [
            "So I'm going."
        ],
        [
            "To talk a little bit about some other vision applications.",
            "So this is actually used for object detection so.",
            "I mean, the basic story is that you apply this convolution pooling convolutional pooling and then at some point you just fully connect.",
            "So you do you have fully connected layers and then classification layer for this particular work.",
            "They actually do this so called multiscale convolution.",
            "So the basic idea is that users take the maybe subsampling.",
            "Users shrink the this feature map by half and then you just concatenate the input for this fully connected layer and the reason to do this is that.",
            "This feature map and this feature map takes slightly different spatial context, so through this subsampling you can keep a slightly larger spatial context, and concatenating together is actually turns out to be better than not using this side channels or side steps of this pathway."
        ],
        [
            "On an also more recently people have tried some different version of this.",
            "Different version of this CNN application, so where you use the so-called CNN as a feature extractor for the Patch, so in this case you first generate bunch of image regions so called bounding box proposals and then for each region you crop and then users resize to 224 or something that can be fit into the Alex net or Vision Network.",
            "And then you just train this part for classification, OK?",
            "So in the testing time you just generate bunch of candidate bounding boxes and then you just evaluate each of the bounding box to calculate the confidence score of as output for CNN and then you do some post processing and eventually you can find some bounding box of corresponding to specific object and this work is called our CNN or regions with CNN features an this achieved state of the art results on.",
            "Object detection so."
        ],
        [
            "That's another kind of breakthrough.",
            "Here is some work that I have done very recently where we can actually improve this.",
            "Our CNN by adding some.",
            "Additional search using Bayesian optimization.",
            "So for example, you can use the CNN with this bounding box proposal.",
            "But the drawback here is that if you make a mistake in proposing a bounding box, then if your bounding boxes are actually poor match to ground truth, then you are actually doomed to fail.",
            "So in this work what we do is basically given some local optimum where you can actually do some Bayesian optimization to search across the nearby region to find a better bounding box.",
            "That's likely to give you a high CNN score, and then you add it to the evaluate this CNN score.",
            "Then you can basically iteratively add multiple boxes around the local optimum and that actually gives a better.",
            "Results or object detection?"
        ],
        [
            "Another way of improving CNN detection is to use so-called structure loss.",
            "So the basic idea here is that instead of using classification loss, you can also add a loss that's reflecting the localization.",
            "So here the loss is not only just one or zero.",
            "It is also is a function of how this bounding box matches the ground truth, so this is a generally speaking on instance of structure prediction problem so."
        ],
        [
            "I can actually formulate this as a structural SVM where this is basically the loss function of the CNN.",
            "The top layer loss function, so it looks very similar to the support vector machine, but it has a structure loss here.",
            "It actually has two different objective.",
            "I mean three different constraint where the 1st first 2 constraint corresponds to a classification loss, which means that if you calculate the CNN features in our product with some weight then it should be good for classifying the existence or non existence of the object in the image.",
            "But the third constraint corresponds to basically the localization.",
            "So the ground truth score of the ground truth should be higher than.",
            "Pull up non ground truth examples or bounding boxes and that can also improve this object detection problems.",
            "So.",
            "OK, so maybe 2 minutes, 2 minutes or three minutes, OK?",
            "To me.",
            "Yeah.",
            "OK so I have three more slides for most.",
            "Is it OK?"
        ],
        [
            "OK, I'm here.",
            "Yeah, we have another application for segmentation.",
            "So I mean, yeah, I think I'm not going to go into details, but the basic idea is that you have CNN, but here you have multi scale mapping so using this different sized version of this feature map that can also reflect different size spatial context and at the end in this case you try to predict the pixel level class.",
            "Classification so and there are some additional machinery here that's used for aggregating these outputs, but for more detail you can take a look at this paper.",
            "So in general CNN is also very useful."
        ],
        [
            "Through segmentation problems and here are some also other applications where you can use it for tracking or pose estimation and also most recent work is most very exciting.",
            "Work is the caption generation by many many groups.",
            "And."
        ],
        [
            "And also I should say that the CNN's are used in many industrial applications.",
            "So for like for like face recognition, CNN is used to basically extract the features for comparing different face images to tell whether these are the same person or not.",
            "So this is actually done by Facebook.",
            "They achieve really good performance on face recognition.",
            "Um, yeah, so I should maybe."
        ],
        [
            "But here is some other work where you.",
            "You basically embed the CNN features an also the word embedding and then try to find some compatibility between these two.",
            "So then you can basically somehow do some multimodal learning.",
            "I believe Ross will talk more about multimodal learning later, but here is just one way of finding a joint embedding between the CNN and the word space."
        ],
        [
            "You can also do something similar for different type of features but.",
            "So I think I'm done here so."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I'm going to talk about Convolutional network.",
                    "label": 0
                },
                {
                    "sent": "In fact this is a very broad topic.",
                    "label": 0
                },
                {
                    "sent": "An also number of papers are like to be honest, like exploding these days, so I couldn't cover all the papers or so.",
                    "label": 0
                },
                {
                    "sent": "I apologize if I mean I didn't cover some of the papers.",
                    "label": 0
                },
                {
                    "sent": "I tried my best.",
                    "label": 0
                },
                {
                    "sent": "And also I tried to give you some intuition about what's the convolutional network and also why it works and what it can be applied in different scenarios.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to talk first about unsupervised learning.",
                    "label": 0
                },
                {
                    "sent": "So how do we learn unsupervised learning for convolutional net?",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then moving to supervised convolutional learning, which is more, I mean achieving state of the art results nowadays.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so just as a brief recap, we talked about some unsupervised learning of maybe dictionaries or basis vector from images.",
                    "label": 0
                },
                {
                    "sent": "So for example, the representation we are trying to learn is some kind of decomposition of maybe input patches such as representing this 14 by 14 Patch as some sparse combination of basis vectors.",
                    "label": 0
                },
                {
                    "sent": "And basically this is sort of set up Gabor filters, Ann.",
                    "label": 0
                },
                {
                    "sent": "You're representing dispatch as or some combination of edges.",
                    "label": 0
                },
                {
                    "sent": "So we're talking about some kind of representation starting from pixels to maybe some composition of these.",
                    "label": 0
                },
                {
                    "sent": "Combination of these edges.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we can go deeper by learning the second layer.",
                    "label": 0
                },
                {
                    "sent": "So you learn the second layer as another, maybe combination of first layer features and this learn some composition of edges.",
                    "label": 1
                },
                {
                    "sent": "So this is a basic idea behind.",
                    "label": 0
                },
                {
                    "sent": "I mean what can be learned using this deep network?",
                    "label": 0
                },
                {
                    "sent": "But yesterday I mostly talked about algorithm that applies to image patches.",
                    "label": 0
                },
                {
                    "sent": "So let's say we have 14 by 14 pixels as an input image.",
                    "label": 1
                },
                {
                    "sent": "Then first layer encodes this basis vector for for the same size Patch.",
                    "label": 0
                },
                {
                    "sent": "Second layer is also the some combination of these edges but still limited to this 14 by 14.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In this talk I'm going to go beyond these patches and how we can actually learn features that cover larger areas and also more higher level, higher level features.",
                    "label": 0
                },
                {
                    "sent": "So suppose that we are given some input images like this an.",
                    "label": 0
                },
                {
                    "sent": "If we see a bunch of images of faces, an bunch of images of cars we would like to find some maybe intermediate level features corresponding to maybe parts of faces or parts of cars and so on.",
                    "label": 0
                },
                {
                    "sent": "But just going naively applying the Patch or just concatenating this big image into a long vector doesn't really apply.",
                    "label": 0
                },
                {
                    "sent": "Where is here?",
                    "label": 0
                },
                {
                    "sent": "We are trying to find some gradually bigger patches so you start from small Patch and go slightly bigger and slightly bigger an at the R. At the end you want to find some higher level features that cover object parts and full objects.",
                    "label": 1
                },
                {
                    "sent": "So it doesn't really work by just applying Patch level model naively, so we need to think about some more scalable ways of doing this and also another interesting thing to remember is that images exhibit lots of spatial correlations, so we want to exploit some models and algorithms that can handle strong spatial correlations as well.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here is our basic intuition.",
                    "label": 0
                },
                {
                    "sent": "So given the input image, we consider some filters and hear the filters can be basically some oriented edges, and in fact these are learned filters from the data and you can just learn it from unsupervised learning such as sparse coding, restricted Boltzmann machine or autoencoders as well.",
                    "label": 0
                },
                {
                    "sent": "So suppose that you just apply some kind of filter matching.",
                    "label": 0
                },
                {
                    "sent": "So you just basically do template matching with this filter one.",
                    "label": 0
                },
                {
                    "sent": "With the image and then you are just doing sliding window of this filter across all the locations in the image and then you get filter response and in fact this is exactly the operation that I explained for the case of restricted Boltzmann machine cause.",
                    "label": 0
                },
                {
                    "sent": "Yesterday I told you that the activation of hidden unit is simply just computed by inner product of the filter and the input data, and then if the inner product is high, you activate the hidden unit.",
                    "label": 0
                },
                {
                    "sent": "If inner product is slow, you deactivate the hidden unit with high high probability.",
                    "label": 0
                },
                {
                    "sent": "So here the white pixel means high chance of activation.",
                    "label": 0
                },
                {
                    "sent": "Black means low chance of activation and so on.",
                    "label": 0
                },
                {
                    "sent": "So this is the activation of this filter or this basis vector across all the different locations in the image.",
                    "label": 0
                },
                {
                    "sent": "OK, and then you do the same thing for different filter and then you get a different response.",
                    "label": 0
                },
                {
                    "sent": "An intuitively, this white response means where this specific filters are activated in the different locations of the image an for different filters we see different pattern.",
                    "label": 0
                },
                {
                    "sent": "And these are activation can be viewed as a representation of the input image.",
                    "label": 0
                },
                {
                    "sent": "So again we are starting from the pixel level and then we are moving into this quick fissions of these filters.",
                    "label": 0
                },
                {
                    "sent": "Essentially this is some kind of athlete action or some HD composition that's also commonly used in computer vision.",
                    "label": 0
                },
                {
                    "sent": "But deep learning or representation learning algorithm can also discover this type of decomposition as well.",
                    "label": 0
                },
                {
                    "sent": "What's more interesting is going actually into higher layer so.",
                    "label": 0
                },
                {
                    "sent": "For example, we can consider some naive way of.",
                    "label": 0
                },
                {
                    "sent": "Stacking another layer of feature learning so you can do any kind of your favorite feature learning algorithm, such as autoencoder restricted, Boltzmann machine, sparse coding.",
                    "label": 0
                },
                {
                    "sent": "The trick here is that it doesn't work very well if you just naively stack another layer.",
                    "label": 0
                },
                {
                    "sent": "Of course it depends on different application, but for the case of maybe finding bigger feature, higher level features that cover larger area.",
                    "label": 0
                },
                {
                    "sent": "It doesn't work very well.",
                    "label": 0
                },
                {
                    "sent": "Be 'cause if you want to find bigger bigger patterns then you need to grow the receptive field size and that means that you need larger receptive field in the second layer an as you go higher and higher layers then the number of reset the number of hidden units or a number of input units for this higher layer will grow so it doesn't scale very well.",
                    "label": 0
                },
                {
                    "sent": "So a better idea is to basically shrink the representation.",
                    "label": 0
                },
                {
                    "sent": "So, given that you have this filter response.",
                    "label": 0
                },
                {
                    "sent": "Then use a shrink by factor of two by two or three by three.",
                    "label": 0
                },
                {
                    "sent": "Then you get a smaller sized activation.",
                    "label": 0
                },
                {
                    "sent": "The main intuition is that this shrinked representation still keeps the some basic pattern an you can see.",
                    "label": 0
                },
                {
                    "sent": "You can see that these are quite similar to each other and also this shrinked representation is more invariant to small perturbation of the input image.",
                    "label": 0
                },
                {
                    "sent": "And then we can do feature learning.",
                    "label": 0
                },
                {
                    "sent": "So in the case of unsupervised learning you are basically doing some.",
                    "label": 0
                },
                {
                    "sent": "Taking some Patch and then finding some correlation between these first layer activations.",
                    "label": 0
                },
                {
                    "sent": "An in convolutional case we are going to also allow the filter to move around to any location of the image.",
                    "label": 0
                },
                {
                    "sent": "And at the end, if you see similar pattern over and over.",
                    "label": 0
                },
                {
                    "sent": "So if you provide lots of face images, then the algorithm will discover there exist some local correlation of these first layer features.",
                    "label": 0
                },
                {
                    "sent": "That kind of look like this, so it doesn't provide direct intuitive interpretation by looking at this activation, but it turns out that if you project back to the pixel level it shows some interesting patterns such as object parts.",
                    "label": 0
                },
                {
                    "sent": "So this is a basic idea of how we can actually discover features even in an unsupervised way.",
                    "label": 0
                },
                {
                    "sent": "So the basic idea here is that.",
                    "label": 0
                },
                {
                    "sent": "If in unlabeled data, if there are lots of similar patterns over and over across different images, then the algorithm will try to find some basis vector in multiple levels.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this actually also resembles the idea that I'm going to also talk about, which is supervised version of Convolutional Network, but I'm going to talk more about that later, But in that case you do the same kind of operations such as doing convolution and then pulling over a small location and maybe taking the maximal or maximum or some other pooling operation, and then you can repeat this procedure in higher layers such as convolution and pooling.",
                    "label": 0
                },
                {
                    "sent": "And so on.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to just talk about unsupervised learning version of this type of algorithm.",
                    "label": 0
                },
                {
                    "sent": "So for that case it's going to focus on one layer and you can basically learn features without any labels and then you can move on to the second layer learning and so on.",
                    "label": 0
                },
                {
                    "sent": "Alright, so.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here is a algorithm for learning this.",
                    "label": 0
                },
                {
                    "sent": "Convolutional features.",
                    "label": 0
                },
                {
                    "sent": "So this is exactly the same as the restricted Boltzmann machine I talked about yesterday.",
                    "label": 0
                },
                {
                    "sent": "But the difference is that we have hidden unit that covers small area in the input image.",
                    "label": 0
                },
                {
                    "sent": "So in this case I just show three by three as a filter size.",
                    "label": 0
                },
                {
                    "sent": "And the filter is shared across all the locations.",
                    "label": 0
                },
                {
                    "sent": "So if you have different filter, different filter matching different location then it correspond to different location in this hidden.",
                    "label": 0
                },
                {
                    "sent": "Hidden Notes are group, so for each filter we have some kind of this 2D activation map where each point correspond to activating filter at different location.",
                    "label": 0
                },
                {
                    "sent": "And again I talked.",
                    "label": 0
                },
                {
                    "sent": "I told you that it's good activation of the hidden unit is simply determined by taking the inner product between the filter an input data input image an.",
                    "label": 1
                },
                {
                    "sent": "Depending on the inner product you activate or deactivate.",
                    "label": 0
                },
                {
                    "sent": "But here we also consider some pooling operation.",
                    "label": 0
                },
                {
                    "sent": "So for example, we look at two by two near neighbors and then take the maximum.",
                    "label": 0
                },
                {
                    "sent": "For the case of restricted Boltzmann machine, this is a probabilistic operation so.",
                    "label": 0
                },
                {
                    "sent": "This hidden unit can be active or deactive, with some probability, and also we want to model this activation of pulling unit also using some probability.",
                    "label": 0
                },
                {
                    "sent": "Ann for computational reason, we can just restric these hidden nodes to be active in a way that only one hidden unit is active across this pulling group.",
                    "label": 1
                },
                {
                    "sent": "The reason is that it's actually there are exponential number of configurations.",
                    "label": 0
                },
                {
                    "sent": "If you don't have this constraint an it's actually hard to enumerate all these possible cases.",
                    "label": 0
                },
                {
                    "sent": "And also by doing this constraint it doesn't really lose that much because most of the time if you have some filter then it will be most well matched to a certain location.",
                    "label": 0
                },
                {
                    "sent": "But probably if you shift it around it will be less matched.",
                    "label": 0
                },
                {
                    "sent": "So just picking the best match is a reasonable way to approximate this problem.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We can basically formulate this problem as a unsupervised learning problem.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or an so here.",
                    "label": 0
                },
                {
                    "sent": "This corresponds to a extension of the restricted Boltzmann machine where.",
                    "label": 0
                },
                {
                    "sent": "Here it's a.",
                    "label": 0
                },
                {
                    "sent": "It's a little compact, but the basic idea is that you have filter W&K means Kate filter, so you convolve locate filter with the input image.",
                    "label": 0
                },
                {
                    "sent": "And basically so taking inner product of the filter in all possible locations in the input image and depending on this inner product at different location you activate or deactivate the hidden units and there is some bias terms that represent some default activation of this hidden unit.",
                    "label": 0
                },
                {
                    "sent": "And after that you apply some constraint so that only one of the hidden unit is active.",
                    "label": 0
                },
                {
                    "sent": "So you have a constraint that for each cell corresponding to one pulling unit.",
                    "label": 0
                },
                {
                    "sent": "Then the sum of these hidden unit should be one or zero.",
                    "label": 0
                },
                {
                    "sent": "OK. An if you just do some influence in terms of calculating the hidden units or pulling units based on the input and also the filter, then it corresponds to taking the.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Product and then taking the softmax as some kind of nonlinearity or pulling unit.",
                    "label": 0
                },
                {
                    "sent": "So the basic idea here is that.",
                    "label": 0
                },
                {
                    "sent": "Given the inner product, so you take the inner product of WK, some filter with some specific Patch corresponding to slightly different shifted location of the image.",
                    "label": 0
                },
                {
                    "sent": "And then you will have different values for the inner product and you pick the basically the best match and that match will have the highest probability of activation.",
                    "label": 0
                },
                {
                    "sent": "So if you just do some some simple calculation then you can easily see that the activation probability of activating certain hidden unit is taking the form of the softmax function.",
                    "label": 0
                },
                {
                    "sent": "Where this IL represents the value of the inner product from bottom up.",
                    "label": 0
                },
                {
                    "sent": "So you can basically do sampling very easily, so you just sample from the softmax function and then it only has five possibilities.",
                    "label": 0
                },
                {
                    "sent": "So if none of the filters match, then you have basically all zero activation, including the pulling units.",
                    "label": 0
                },
                {
                    "sent": "If some of the filter match, well well enough then it will activate one filter 1 hidden unit, but deactivate some other unit and so on.",
                    "label": 0
                },
                {
                    "sent": "So this is how we can actually do inference for this.",
                    "label": 0
                },
                {
                    "sent": "So for this network.",
                    "label": 0
                },
                {
                    "sent": "So then given the input image, you can calculate the posterior of the hidden hidden units and also the pooling units.",
                    "label": 0
                },
                {
                    "sent": "And let me see so.",
                    "label": 0
                },
                {
                    "sent": "I'm going to go back.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This slide, so in this case of since this is unsupervised learning algorithm, there is no label, which means that we are trying to maximize the likelihood and it turns out that what?",
                    "label": 0
                },
                {
                    "sent": "What it does in learning is to 1st calculate this hidden activations and use the hidden activations to basically reconstruct the input image, so that's the essentially corresponding to the sampling step of PRV given H. So for the case of GBM, basically we do contrastive divergent's, meaning that given the image you calculate the hidden probabilities including the pooling layer and then you sample from this hidden units.",
                    "label": 0
                },
                {
                    "sent": "And you can do this using softmax probabilities.",
                    "label": 0
                },
                {
                    "sent": "And then given the sample the hidden units, then you reconstruct so then you repeat this multiple generations.",
                    "label": 0
                },
                {
                    "sent": "So essentially computing this hidden unit activation and then sampling an reconstructing that corresponds to the one step of contrastive divergent.",
                    "label": 0
                },
                {
                    "sent": "And you can repeat this multiple steps so you can sample hidden units and reconstruct sample hidden units.",
                    "label": 0
                },
                {
                    "sent": "And we construct and that corresponds to CDK contrastive divergent with K steps.",
                    "label": 0
                },
                {
                    "sent": "An also I should say that this type of concept where you do some encoding or calculating the hidden units and reconstructing and then at the end it corresponds to some kind of calculating or minimizing the difference between the original input and the.",
                    "label": 0
                },
                {
                    "sent": "Reconstructed input for the case of restricted Boltzmann machines.",
                    "label": 0
                },
                {
                    "sent": "It is basically following some approximate version of maximum likelihood, but intuitively it is doing some kind of inference and reconstruction, and at the end the gradient is somewhat similar to the reconstruction error.",
                    "label": 0
                },
                {
                    "sent": "An similar intuition is right.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Waited for other algorithms as well so.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For the case of this convolutional version of RBM, you can basically do greedy training.",
                    "label": 0
                },
                {
                    "sent": "So greedy training means.",
                    "label": 0
                },
                {
                    "sent": "Here.",
                    "label": 0
                },
                {
                    "sent": "You can basically train.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One layer and learn the filters and you can just fix the first layer and compute the activation and then you can train another layer of convolutional RBM and then do this greedy layer layer wise training.",
                    "label": 0
                },
                {
                    "sent": "Alright, and",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then you can do inference in a feedforward way, which is the same as the original deep belief network.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's some illustration of filters learn by the model.",
                    "label": 0
                },
                {
                    "sent": "So given the input image.",
                    "label": 0
                },
                {
                    "sent": "You learn filters that look like edges.",
                    "label": 0
                },
                {
                    "sent": "And then here is the activation.",
                    "label": 0
                },
                {
                    "sent": "So essentially these are just convolved with the input image and take some sigmoid non or sigmoid.",
                    "label": 0
                },
                {
                    "sent": "In fact is a softmax nonlinearity.",
                    "label": 0
                },
                {
                    "sent": "Then you get the.",
                    "label": 0
                },
                {
                    "sent": "This type of activation.",
                    "label": 0
                },
                {
                    "sent": "And you can learn the second layer by just freezing this activation and learning another layer RBM.",
                    "label": 0
                },
                {
                    "sent": "And here I show the visualization of the second layer filters projected back to the image.",
                    "label": 0
                },
                {
                    "sent": "And here is the activation.",
                    "label": 0
                },
                {
                    "sent": "An basically we can repeat this multiple times, so here we learn the combination of filters, secondary filters that correspond to the.",
                    "label": 0
                },
                {
                    "sent": "The full object and here is some visualization of some activations.",
                    "label": 0
                },
                {
                    "sent": "Alright, so this one nice thing about this type of algorithm is that it doesn't require labels, so as long as you have some kind of regular pattern in the image that's repeated over the training data, then you can try to discover this type of features without any labels.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This can be used for discovering some features for natural images, so for the first layer it's just the keyboard filters, but in the second layer it tries to combine these Gabor filters in different combinations, yes.",
                    "label": 0
                },
                {
                    "sent": "OK, so let me just go back to this.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Slide, so maybe maybe I should just show you the.",
                    "label": 0
                },
                {
                    "sent": "Actual.",
                    "label": 0
                },
                {
                    "sent": "Maybe it's good to go back to the RBM influence that we covered yesterday, so.",
                    "label": 0
                },
                {
                    "sent": "Hopefully.",
                    "label": 0
                },
                {
                    "sent": "OK, so here is the.",
                    "label": 0
                },
                {
                    "sent": "Simple version.",
                    "label": 0
                },
                {
                    "sent": "Where we just have just GBM with just a small number of hidden units.",
                    "label": 0
                },
                {
                    "sent": "So what we did yesterday is basically.",
                    "label": 0
                },
                {
                    "sent": "Think about this energy function and the influence was.",
                    "label": 0
                },
                {
                    "sent": "Basically taking the inner product so if you have a filter then you do filter times the input data so you take the inner product between W one and V. An if the inner product is high, you just activate with high probability, or if it's not large enough, you just set it to zero with high probability as well.",
                    "label": 0
                },
                {
                    "sent": "So you do that for the same same way with the same way for different colors, different hidden units, so blue and green you get.",
                    "label": 0
                },
                {
                    "sent": "You do basically some sort of independent influence.",
                    "label": 0
                },
                {
                    "sent": "So it turns out that it is just calculating the hidden unit activation and it is basically taking the inner product an applying sigmoid nonlinearity.",
                    "label": 0
                },
                {
                    "sent": "So that was because there is no constraint, so you just independent deactivate 1 hidden unit at a time and it just corresponds to a soft version or probabilistic version of this binary activation that actually correspond to sigmoid.",
                    "label": 0
                },
                {
                    "sent": "So that's what we did yesterday.",
                    "label": 0
                },
                {
                    "sent": "So maybe going back to.",
                    "label": 0
                },
                {
                    "sent": "This convolutional RBM case.",
                    "label": 0
                },
                {
                    "sent": "Hopefully.",
                    "label": 0
                },
                {
                    "sent": "Let's see.",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "So in this case, the difference is that because we have.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of this constraint.",
                    "label": 0
                },
                {
                    "sent": "So we have a constraint that the hidden units corresponding to the same pulling group should be activated in a way that only one can be active.",
                    "label": 0
                },
                {
                    "sent": "So that basically.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We are.",
                    "label": 0
                },
                {
                    "sent": "Changes this activation function from the sigmoid to the softmax.",
                    "label": 0
                },
                {
                    "sent": "OK, so in fact, if you only have 1 unit for one pulling group then this is exactly the same as sigmoid.",
                    "label": 0
                },
                {
                    "sent": "But because you have multiple hidden units that are competing for activation, it is actually softmax.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "This model, yeah.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Filters yeah, OK?",
                    "label": 0
                },
                {
                    "sent": "Activate that's right, yeah?",
                    "label": 0
                },
                {
                    "sent": "So first layer filters are, roughly speaking, basically to detecting edges.",
                    "label": 0
                },
                {
                    "sent": "OK. An in the second layer, I mean it is basically.",
                    "label": 0
                },
                {
                    "sent": "Very similar in the second layer as well.",
                    "label": 0
                },
                {
                    "sent": "I mean if you see some repeated patterns then it will try to learn the filters and it will try to activate the filter so.",
                    "label": 0
                },
                {
                    "sent": "ICA coefficients and apply ICA?",
                    "label": 0
                },
                {
                    "sent": "So I think it maybe also is related to whether you do convolution or not.",
                    "label": 0
                },
                {
                    "sent": "So in fact if you do the same thing without convolutional extension, it is actually difficult to learn these filters.",
                    "label": 0
                },
                {
                    "sent": "The reason is that if you have the exactly the same pattern, or if it is shifted a little bit, if you just take the Patch then they are very different so.",
                    "label": 0
                },
                {
                    "sent": "So either you learn a very redundant patches, redundant filters, or it's hard to learn a good filter, whereas for the convolutional version you can use the same filter but in a different location.",
                    "label": 0
                },
                {
                    "sent": "So if the input pattern is shifted around then you can just shift the filters and activate it in a slightly different location, so you can use the same filter so it learns actually non redundant features.",
                    "label": 0
                },
                {
                    "sent": "So that's one advantage of doing convolutional learning and also similar observation has been made in other papers such as Jan Mcluen's Paper at NIPS 2010.",
                    "label": 0
                },
                {
                    "sent": "They also show some contrast between filters learn from the non convolutional version of their algorithm and convolutional version of their algorithm and show that convolutional learning gives you much more compact and non redundant filters.",
                    "label": 0
                },
                {
                    "sent": "OK. Alright, so.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here is the hierarchical features for natural images.",
                    "label": 0
                },
                {
                    "sent": "And we see that the second layer filters can find some kind of.",
                    "label": 0
                },
                {
                    "sent": "Conjunction of edges.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "An you can also learn features corresponding to maybe different objects object categories.",
                    "label": 0
                },
                {
                    "sent": "So here I use the same filters, just learn from the natural image but train for different object categories for the second and third layers and find some kind of hierarchical features.",
                    "label": 0
                },
                {
                    "sent": "As the layers go up and it can be useful for several vision problems such as classification or verification or like alignment and so on, yes.",
                    "label": 0
                },
                {
                    "sent": "So that's a great question.",
                    "label": 0
                },
                {
                    "sent": "So visualization I use some heuristic where I clamp the hidden unit.",
                    "label": 0
                },
                {
                    "sent": "And then just.",
                    "label": 0
                },
                {
                    "sent": "Basically apply this.",
                    "label": 0
                },
                {
                    "sent": "Some convolution is it's actually some so-called deconvolution.",
                    "label": 0
                },
                {
                    "sent": "So maybe I should.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Go back to this picture so if I fix the maybe 1 hidden unit here.",
                    "label": 0
                },
                {
                    "sent": "I mean then if I say one as activation then it will basically activate this small region which is basically some maybe 10 by 10 Patch in this third layer activation.",
                    "label": 0
                },
                {
                    "sent": "And then since it goes through so it's actually 10 by 10, that corresponds also 10 by 10 activation here.",
                    "label": 0
                },
                {
                    "sent": "And since it goes through this Max pooling, I just apply basically some heuristic where you just resize this activation by two factor of two.",
                    "label": 0
                },
                {
                    "sent": "So you have 10 by 10 Patch in this secondary activation an make it twice larger.",
                    "label": 0
                },
                {
                    "sent": "And here from here to here it is actually a convolution operator so.",
                    "label": 0
                },
                {
                    "sent": "Basically, I apply these so called deconvolution which means that you use this small Patch to activate the first layer activation here and then it since it also goes through the pooling operation, you just make it larger by factor of 2 and that's basically how we do visualization.",
                    "label": 0
                },
                {
                    "sent": "I mean, that's just one way of doing it.",
                    "label": 0
                },
                {
                    "sent": "But there are so many different ways to do that, so most recent ways of doing visualization is just taking the gradient descent.",
                    "label": 0
                },
                {
                    "sent": "So in fact I haven't tried for this model, but you can just think about the image as a sum variable and you try to take the maybe top layer activation as output and users to simple gradient descent.",
                    "label": 0
                },
                {
                    "sent": "So you just do gradient descent under some reasonable constraint such that.",
                    "label": 0
                },
                {
                    "sent": "This, whatever hidden unit is maximized hidden in the activation, is maximized.",
                    "label": 0
                },
                {
                    "sent": "Then very interesting it can find a good kind of pattern that also somewhat mimics or is kind of similar to this, and that's one way, but there are several different ways that have been proposed.",
                    "label": 0
                },
                {
                    "sent": "For like how to visualize this deep network?",
                    "label": 0
                },
                {
                    "sent": "Can you repeat the question?",
                    "label": 0
                },
                {
                    "sent": "Yeah right yeah.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "He also features that can be learned from the this convolutional learning of RBM's butt.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In fact, it actually can be also done in a similar way for a different unsupervised learning as well.",
                    "label": 1
                },
                {
                    "sent": "So here is a convolutional extension of sparse coding, so it was done by young raccoons group.",
                    "label": 0
                },
                {
                    "sent": "So the basic idea is very similar, so you have some input image X and then the filter.",
                    "label": 0
                },
                {
                    "sent": "Filter decay so DK here is a dictionary or filter and ZK is the activation.",
                    "label": 0
                },
                {
                    "sent": "Or you can think about the OK.",
                    "label": 0
                },
                {
                    "sent": "So the first term is about minimizing the reconstruction between the input and filter times.",
                    "label": 0
                },
                {
                    "sent": "Basic filter convolved with the hidden unit activation an you sum over the all the filters.",
                    "label": 0
                },
                {
                    "sent": "Then that's the summation of all the contribution of reconstruction from different filters.",
                    "label": 0
                },
                {
                    "sent": "And you want this to be small.",
                    "label": 0
                },
                {
                    "sent": "At the same time, there is a penalty corresponding to sparse sparsity, so you want the hidden units to be sparsely activated.",
                    "label": 0
                },
                {
                    "sent": "So there is a L1 penalty for the Z and this second term is an interesting term.",
                    "label": 0
                },
                {
                    "sent": "The main idea here is that it is actually difficult, fairly difficult to just do optimization when you have some some of continuous function plus L1 penalty.",
                    "label": 0
                },
                {
                    "sent": "An in fact it is doable.",
                    "label": 0
                },
                {
                    "sent": "It's it's a convex function, but it actually is very computationally expensive.",
                    "label": 0
                },
                {
                    "sent": "So what was proposed here is to approximate this hidden unit activation as some kind of feedforward function.",
                    "label": 0
                },
                {
                    "sent": "So you just take the.",
                    "label": 0
                },
                {
                    "sent": "In our product with the filter and the input.",
                    "label": 0
                },
                {
                    "sent": "So you basically calculate the match between the filter and the input data and then you go through nonlinearity.",
                    "label": 0
                },
                {
                    "sent": "So in this paper they used some function that looks like this which is called a soft thresholding function.",
                    "label": 0
                },
                {
                    "sent": "Intuitively speaking, if the activation is not big enough, then you just truncate to zero an.",
                    "label": 0
                },
                {
                    "sent": "If it is big enough so it's over a certain threshold, then you activate it.",
                    "label": 0
                },
                {
                    "sent": "At the end, this is still an approximation, so but it gives a reasonable initial initial starting point for the coefficient.",
                    "label": 0
                },
                {
                    "sent": "So then basically you have a penalty term that corresponds to actual optimal ZC with this approximated version of the coefficient, which is done by simple like filter response followed by nonlinearity.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "So you want to find a good approximation of this filter activation and then also you learn the filters altogether.",
                    "label": 0
                },
                {
                    "sent": "So at the end they still do this L1 optimization, so they try to minimize this whole objective function.",
                    "label": 0
                },
                {
                    "sent": "By solving this whole I mean this objective, so you get the optimal Z and then basically in order to minimize this error you want to find good filter.",
                    "label": 0
                },
                {
                    "sent": "So in fact this actually corresponds to, I mean very high level in very high level corresponds to basically some recognition unit in deep belief Nets.",
                    "label": 0
                },
                {
                    "sent": "Recognition weights because it's approximating this activation using certain some different parameters.",
                    "label": 0
                },
                {
                    "sent": "An then also you minimize the reconstruction error OK.",
                    "label": 0
                },
                {
                    "sent": "So some more details is provided in the paper, and please look at this if you are more interested.",
                    "label": 0
                },
                {
                    "sent": "And then here I'm showing the filters that are learned from this algorithm.",
                    "label": 0
                },
                {
                    "sent": "So you learn the first layer filters that look like this so it learns some edges and also it learns some other filters corresponding to some dots and some blobs.",
                    "label": 0
                },
                {
                    "sent": "And in the second layer they also find some combination of these filters.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "It's hard to interpret, but it's some combination that is more richer than the first layers.",
                    "label": 0
                },
                {
                    "sent": "Any questions here?",
                    "label": 0
                },
                {
                    "sent": "So underlying theme here is that for unsupervised learning algorithm you have some kind of approximate calculation of doing some or some probabilistic calculation corresponding to encoding and decoding.",
                    "label": 0
                },
                {
                    "sent": "So in this case this corresponds to encoding function and this corresponding to decoding function.",
                    "label": 0
                },
                {
                    "sent": "So you want to find the model so that you do some encoding to approximate this hidden activation and then do some decoding but at the same time you want to have a sparse activation.",
                    "label": 0
                },
                {
                    "sent": "And maybe just going back to this convolutional RBM is to basically very similar story so.",
                    "label": 0
                },
                {
                    "sent": "In that case, you do some encoding using this RBM activation function and then you do decoding implicitly using contrastive divergent an at the end.",
                    "label": 0
                },
                {
                    "sent": "The gradient is like somewhat very reminiscent of reconstruction error.",
                    "label": 0
                },
                {
                    "sent": "Ann is it is done in a technically different way, but intuition is very similar.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here is another version of convolutional learning called Deconvolutional Network.",
                    "label": 0
                },
                {
                    "sent": "In fact, this is very similar to the just the version that I just showed, but in this case this doesn't have any encoding function, so you can think about this as a more like direct extension of convolutional sparse coding, because in sparse coding you don't have a encoding function, you usually have a decoding function only, so here.",
                    "label": 0
                },
                {
                    "sent": "So in this case, why is the input image and see corresponds to different channel?",
                    "label": 0
                },
                {
                    "sent": "So for the case of RGB, C would be 3.",
                    "label": 0
                },
                {
                    "sent": "And then you have a filter.",
                    "label": 0
                },
                {
                    "sent": "That corresponding to Kate filter here and then you are doing convolutions.",
                    "label": 0
                },
                {
                    "sent": "So ZK is to coefficient.",
                    "label": 0
                },
                {
                    "sent": "So here is the basically the same term.",
                    "label": 0
                },
                {
                    "sent": "This time is exactly the same as the first term in the previous slide.",
                    "label": 0
                },
                {
                    "sent": "So you have convolution with the filter when their hidden activation and you calculate the reconstruction error and then you want to minimize this reconstruction error.",
                    "label": 0
                },
                {
                    "sent": "On top of that, you have a spicy penalty, so you want the hidden units to be sparsely activated.",
                    "label": 0
                },
                {
                    "sent": "So it's pretty much the same objective as the previous one, but the difference is that it doesn't have an encoding function, so.",
                    "label": 0
                },
                {
                    "sent": "I should say that there is.",
                    "label": 0
                },
                {
                    "sent": "I mean intuition is very similar, but optimizing this this objective is a little bit different and also.",
                    "label": 0
                },
                {
                    "sent": "In this, if you are more interested, you can take a look at this paper Zeiler and Fergus on deep convolutional network.",
                    "label": 0
                },
                {
                    "sent": "They propose some efficient way of solving this using some iterative computation.",
                    "label": 0
                },
                {
                    "sent": "But again, the story is very similar, so you somehow calculate the hidden in the activation and then you decode it back so that you minimize the reconstruction error.",
                    "label": 0
                },
                {
                    "sent": "An here.",
                    "label": 0
                },
                {
                    "sent": "These are the filters.",
                    "label": 0
                },
                {
                    "sent": "Learn from the first layer so I'm showing filters, learn from different datasets, they are slightly different, but also shows fairly similar patterns.",
                    "label": 0
                },
                {
                    "sent": "So in the first layer it finds some edge detector and in the second layer it finds some combinations.",
                    "label": 0
                },
                {
                    "sent": "And in the third layer it finds some.",
                    "label": 0
                },
                {
                    "sent": "Maybe slightly more, richer combination of the second layer filters.",
                    "label": 0
                },
                {
                    "sent": "OK, so I'm going to move on to supervised learning of Convolutional Network.",
                    "label": 0
                },
                {
                    "sent": "So before we move on any do you have any questions?",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "So you can do.",
                    "label": 0
                },
                {
                    "sent": "You can recursively apply this for multiple layers, so it was basically you learn the first layer and after learning the first layer you calculate this hidden coefficient ZK cki that corresponds to.",
                    "label": 0
                },
                {
                    "sent": "A Kate filter at for the image and it will look like some kind of 2D activation map and you have bunch up to the activation map and you do the same learning.",
                    "label": 0
                },
                {
                    "sent": "You just take this C as an input for the second layer and then you do the same learning and then it's basically recursion, yes.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Previous one so it is.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I think it is basically the same.",
                    "label": 0
                },
                {
                    "sent": "Same term, but here it is assuming that X is a 1 dimensional.",
                    "label": 0
                },
                {
                    "sent": "To the sum image.",
                    "label": 0
                },
                {
                    "sent": "So that's why you don't have a summation.",
                    "label": 0
                },
                {
                    "sent": "But if you have multiple channels, so I mean if you have RGB image then you need to treat this as a 3 channel input image.",
                    "label": 0
                },
                {
                    "sent": "Then you should have a sum over the channel and it should be summed over three times.",
                    "label": 0
                },
                {
                    "sent": "And generally speaking you have multiple feature Maps.",
                    "label": 0
                },
                {
                    "sent": "So for example you have here about.",
                    "label": 0
                },
                {
                    "sent": "Approximately like 50.",
                    "label": 0
                },
                {
                    "sent": "Yeah, something like 50 features here.",
                    "label": 0
                },
                {
                    "sent": "So then, which means that?",
                    "label": 0
                },
                {
                    "sent": "I mean, maybe it's good to go back.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To this.",
                    "label": 0
                },
                {
                    "sent": "Activation map here.",
                    "label": 0
                },
                {
                    "sent": "So if you think about this type of activation, I'm just showing a activation map for one filter.",
                    "label": 0
                },
                {
                    "sent": "So if you have one filter then you do convolution and then you have some filter map here, so different filter will have different feature map for sparse coding is the same thing.",
                    "label": 0
                },
                {
                    "sent": "So if you have multiple filters so if you have filled 50 filters then you have 50 filter Maps that corresponding to the representation of the input image.",
                    "label": 0
                },
                {
                    "sent": "So as you learn the second layer, basically you have input 2-D2D image that's has 50 channels, and then it's basically some kind of 3D matrix.",
                    "label": 0
                },
                {
                    "sent": "So, generally speaking, the input can be viewed as a 3D matrix and then you do some convolution operation.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Uh huh.",
                    "label": 0
                },
                {
                    "sent": "Yeah, uh, huh.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "There is also a convolutional version of autoencoders.",
                    "label": 0
                },
                {
                    "sent": "I actually didn't put in the slide, but I think that I believe that the 1st paper is from the European schmidhuber's Group.",
                    "label": 0
                },
                {
                    "sent": "They have 2011 paper on convolutional autoencoder.",
                    "label": 0
                },
                {
                    "sent": "But they basically the idea is very similar.",
                    "label": 0
                },
                {
                    "sent": "I mean, of course the actual objective function.",
                    "label": 0
                },
                {
                    "sent": "And how do how they do inference is different.",
                    "label": 0
                },
                {
                    "sent": "In their case are essentially it is.",
                    "label": 0
                },
                {
                    "sent": "Doing some encoding functions.",
                    "label": 0
                },
                {
                    "sent": "So given the input image X, you do encoding so you get some some nonlinearity followed by this convolution.",
                    "label": 0
                },
                {
                    "sent": "That's the activation and then you just directly use this as a Z and then you do basically so called deconvolution that project back to the input image and then you minimize the reconstruction error.",
                    "label": 0
                },
                {
                    "sent": "So in that case you don't have a sparsity as a sort of L1 penalty and so on.",
                    "label": 0
                },
                {
                    "sent": "So it is actually simpler in terms of the actual feedforward or learning, but.",
                    "label": 0
                },
                {
                    "sent": "Maybe there is some.",
                    "label": 0
                },
                {
                    "sent": "Also, I think it probably requires some additional regularization or trick too.",
                    "label": 0
                },
                {
                    "sent": "You do some sparse attempt to incorporate sparsity and so on, yeah?",
                    "label": 0
                },
                {
                    "sent": "Uh huh.",
                    "label": 0
                },
                {
                    "sent": "They show some good results on Cifar data set, I believe, so they I think they show some positive results on some image classification as well.",
                    "label": 0
                },
                {
                    "sent": "But maybe very systematic comparison of different convolutional learning algorithm is not done yet.",
                    "label": 0
                },
                {
                    "sent": "As far as I know, so it's hard to compare head to head among these algorithms.",
                    "label": 0
                },
                {
                    "sent": "Are gram yeah.",
                    "label": 0
                },
                {
                    "sent": "Earlier.",
                    "label": 0
                },
                {
                    "sent": "That's right, yeah.",
                    "label": 0
                },
                {
                    "sent": "Uh huh.",
                    "label": 0
                },
                {
                    "sent": "That's right, right, right?",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah, this is also crisis paper as well.",
                    "label": 0
                },
                {
                    "sent": "Yeah, right good yeah so.",
                    "label": 0
                },
                {
                    "sent": "OK. Alright.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Move on to supervised learning and that's actually.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Really, driving the state of the art in computer vision these days, so probably this will be some focus of today's talk.",
                    "label": 0
                },
                {
                    "sent": "So one of the most early success of Convolutional Network is basically young black ones work.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "This is the basic architecture, so given the input image, you basically do some convolution and then get the filter activation and then take the sum subsampling so you can take the Max or the average or some other pooling operations.",
                    "label": 0
                },
                {
                    "sent": "So you do convolution and pooling and then convolution and pooling.",
                    "label": 0
                },
                {
                    "sent": "So roughly speaking when you do convolution, the feature map has the same size roughly the same size as the input image.",
                    "label": 0
                },
                {
                    "sent": "In fact, if you do some so-called valid convolution, then the feature map is size is slightly reduced about this size of the filter.",
                    "label": 0
                },
                {
                    "sent": "So if you have N as a input, so let's say the length of these images N and the filter filter length is W, then the feature map is going to give you N -- W + 1 if you apply various so called valid convolution.",
                    "label": 0
                },
                {
                    "sent": "But roughly speaking, since the filter size is small, the approximately these two are the same size.",
                    "label": 0
                },
                {
                    "sent": "There are slightly different version of doing convolution, so there is also so called same convolution in Matlab notation, and then it is basically some padding some extra like pixels around this image, an so that the output of this feature map is the same size as the input image.",
                    "label": 0
                },
                {
                    "sent": "So there are some details, but high level intuition is that the.",
                    "label": 0
                },
                {
                    "sent": "The size of the filter map is going to be similar to the input image.",
                    "label": 0
                },
                {
                    "sent": "An if you apply this subsampling then it will get reduced by some constant factor.",
                    "label": 0
                },
                {
                    "sent": "So if you do 2 by two Max pooling, then this will be reduced by factor of two and so on.",
                    "label": 0
                },
                {
                    "sent": "So basically you repeat this convolution and pooling convolution and pooling the difference between supervised versus unsupervised is that you don't actually try to reconstruct the input image users purely to the state four path.",
                    "label": 0
                },
                {
                    "sent": "So the learning is driven by some classification or some discriminative objectives so.",
                    "label": 0
                },
                {
                    "sent": "So at the end you do some convolution pooling, convolution pooling and at some point users concatenate all these intermediate feature activations as well, just along hidden vectors.",
                    "label": 0
                },
                {
                    "sent": "And then you do some fully connected layers and at the end you have a classification layer.",
                    "label": 0
                },
                {
                    "sent": "So for this particular network it is trying to classify the input image as one of the 10 classes.",
                    "label": 0
                },
                {
                    "sent": "And it's used for the handwritten digit recognition, so the learning is driven by.",
                    "label": 0
                },
                {
                    "sent": "Basically this class class label and you try to minimize the output layer so you have a for this case.",
                    "label": 0
                },
                {
                    "sent": "In this case you have a softmax softmax layer and then you minimize the cross entropy between your softmax output with the actual class label and the error signal is back propagated through the whole network.",
                    "label": 0
                },
                {
                    "sent": "To learn the weights.",
                    "label": 0
                },
                {
                    "sent": "So that's how we can do supervised learning of Convolutional network, yes.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "So yes, I mean based on this figure, yeah, it is basically 6 feature map right?",
                    "label": 0
                },
                {
                    "sent": "And then you just shrink it by factor of 2?",
                    "label": 0
                },
                {
                    "sent": "AS22SC3 how I see.",
                    "label": 0
                },
                {
                    "sent": "So yes, I think basically the filter you have here, I think it's 10 by 10 filter, but 10 by 10 filter means that it actually covers the six channels.",
                    "label": 0
                },
                {
                    "sent": "So the filter, the weight or weight matrix for this filter can be viewed as 10 by 10 by 6.",
                    "label": 0
                },
                {
                    "sent": "OK, so 3D matrix.",
                    "label": 0
                },
                {
                    "sent": "But convolution is done in 2D, but you have to sum over the channels OK. Any quest, any other questions here, yes.",
                    "label": 0
                },
                {
                    "sent": "Gaussian connection.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "So I think in this particular model probably they used the maybe squared loss.",
                    "label": 0
                },
                {
                    "sent": "I'm not exactly sure I that's probably what it means.",
                    "label": 0
                },
                {
                    "sent": "Gaussian connections, so I mean in some cases you just do.",
                    "label": 0
                },
                {
                    "sent": "You represent the classification loss using just the squared error.",
                    "label": 0
                },
                {
                    "sent": "So you have just output.",
                    "label": 0
                },
                {
                    "sent": "And the label.",
                    "label": 0
                },
                {
                    "sent": "And then you just calculate the L2 error or just take the square of this error component wise.",
                    "label": 0
                },
                {
                    "sent": "And that's the loss for the case of classification.",
                    "label": 0
                },
                {
                    "sent": "Probably actual softmax using the softmax as a final layer and then doing cross entropy actually works better.",
                    "label": 0
                },
                {
                    "sent": "Makes slightly more sense for the case of classification but.",
                    "label": 0
                },
                {
                    "sent": "Also, is it true that people use the square loss and sometimes it actually works quite well so?",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Yeah, it decreases the resolution, yes.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "Passing through the location of the maximum.",
                    "label": 0
                },
                {
                    "sent": "Arm.",
                    "label": 0
                },
                {
                    "sent": "I'm not aware of the work that actually explicitly passed through that location of activation.",
                    "label": 0
                },
                {
                    "sent": "But in fact, if you basically keep track of the active like switch units and so you can think about this subsampling as a sum, maybe taking the Max operation.",
                    "label": 0
                },
                {
                    "sent": "I mean, for the case of Max, then you can just remember which which location was used was the maximum within this small region.",
                    "label": 0
                },
                {
                    "sent": "So if you keep track of that, it implicitly remembers this.",
                    "label": 0
                },
                {
                    "sent": "All this location information.",
                    "label": 0
                },
                {
                    "sent": "So that can be actually possibly useful for reconstructing the image, or doing maybe other tasks that relates to maybe maybe segmentation and so on, but.",
                    "label": 0
                },
                {
                    "sent": "I mean, if you remember, I mean implicitly if you take the maximum and then you can just remember 1000 where one correspond to the actual exact hidden unit that gets passed through as a maximum, and that's the implicit way of remembering the location.",
                    "label": 0
                },
                {
                    "sent": "I mean, I think it's done in a different application.",
                    "label": 0
                },
                {
                    "sent": "Most most of the time.",
                    "label": 0
                },
                {
                    "sent": "If your goal is to just do classification an if it doesn't really matter where the pattern is in the input image, then there's no reason to remember that location.",
                    "label": 0
                },
                {
                    "sent": "But if your goal is to maybe reconstruct or maybe some visualization of the image, then it is actually useful to go back.",
                    "label": 0
                },
                {
                    "sent": "So also there is a work by Massillon Rd focus where they use the convolutional network.",
                    "label": 0
                },
                {
                    "sent": "So do feedforward influence, but they actually go back to the input image.",
                    "label": 0
                },
                {
                    "sent": "And basically do some deconvolution and to visualize the sum of some part of the image that corresponds to some activation of these hidden units.",
                    "label": 0
                },
                {
                    "sent": "So it can be actually very useful for visualizing the convolutional network.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Question.",
                    "label": 0
                },
                {
                    "sent": "S4 and S2.",
                    "label": 0
                },
                {
                    "sent": "From here to here.",
                    "label": 0
                },
                {
                    "sent": "So are you saying that whether you should have connection from S2 to full connection?",
                    "label": 0
                },
                {
                    "sent": "So yes, this is for classification.",
                    "label": 0
                },
                {
                    "sent": "I mean.",
                    "label": 0
                },
                {
                    "sent": "Across multiple.",
                    "label": 0
                },
                {
                    "sent": "Oh, I see.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Yeah, I mean the basic idea is that I mean for this case users the you have some achieved.",
                    "label": 0
                },
                {
                    "sent": "I mean learn some high level feature activation and then at some point you don't need a notion of spatial location.",
                    "label": 0
                },
                {
                    "sent": "Or maybe I mean.",
                    "label": 0
                },
                {
                    "sent": "The reason that you do convolution is that if you have some input pattern that's slightly shifted around, you want to detect this regardless of the small shifting.",
                    "label": 0
                },
                {
                    "sent": "So this convolution pooling convolution pooling is useful way of achieving more invariant features, and it can be robust to some small variation of the pattern.",
                    "label": 0
                },
                {
                    "sent": "At some point.",
                    "label": 0
                },
                {
                    "sent": "I mean, if you assume that the input feature was approximately at the center of the image, then you don't need to repeat this convolution pooling over and over.",
                    "label": 0
                },
                {
                    "sent": "So at some point it makes sense to just concatenate all these hidden units to long vector and that's why you use the fully connected layers.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "That answers your question.",
                    "label": 0
                },
                {
                    "sent": "And I can talk offline.",
                    "label": 0
                },
                {
                    "sent": "I mean yeah, if you have more questions.",
                    "label": 0
                },
                {
                    "sent": "Alright, so yes.",
                    "label": 0
                },
                {
                    "sent": "I don't think there is a very like systematic way of doing this, but most of the time you.",
                    "label": 0
                },
                {
                    "sent": "Yeah, you just.",
                    "label": 0
                },
                {
                    "sent": "I think so.",
                    "label": 0
                },
                {
                    "sent": "Somehow transfer the network that actually works well and you do some variation.",
                    "label": 0
                },
                {
                    "sent": "So in this case they use 5 by 5 filter for the first layer and.",
                    "label": 1
                },
                {
                    "sent": "Let's see.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so roughly speaking, the filter size shouldn't be too large.",
                    "label": 0
                },
                {
                    "sent": "I mean, so that's a kind of very high level rule of thumb and also the Max pooling.",
                    "label": 0
                },
                {
                    "sent": "Usually you do by a factor of two or three at most, so you don't do too aggressive polling.",
                    "label": 0
                },
                {
                    "sent": "So that's maybe how things are done.",
                    "label": 0
                },
                {
                    "sent": "And also in most recent work people found that using very small filter is actually beneficial, so using the very small filter but go.",
                    "label": 0
                },
                {
                    "sent": "Very deep that actually also mimics the similar.",
                    "label": 0
                },
                {
                    "sent": "Actually, it approximates the any other type of bigger convolution, but actually it's better represented power and better classification results, so I'll talk a little bit about that later.",
                    "label": 0
                },
                {
                    "sent": "Oh yes.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Move on so these are the kind of standard like way of constructing the convolutional network.",
                    "label": 0
                },
                {
                    "sent": "So basically you do convolution an apply some nonlinearity and then do some pulling and then you have some feature map in.",
                    "label": 0
                },
                {
                    "sent": "After this one layer calculation and then you repeat this multiple times and for the case of classification users to fully connected layers and then connect with the loss coming from the supervision and then do some backpropagation.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to talk a little bit more.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some of these operations, I mean this kind of recap of what I just talked about for the unsupervised learning, but hopefully it will be a good recap.",
                    "label": 0
                },
                {
                    "sent": "So basically, given the input.",
                    "label": 0
                },
                {
                    "sent": "Pixels you have some dictionary so you do some convolution and then you do some nonlinearity and then you do some pulling operation typically sum or average or maximum operation an the last step is optional.",
                    "label": 0
                },
                {
                    "sent": "It's actually normalizing locali among these feature responses.",
                    "label": 0
                },
                {
                    "sent": "But in the most recent work, people also show that it's not necessary to have this normalization step to achieve good results.",
                    "label": 0
                },
                {
                    "sent": "So this can be viewed as an optional module, and then you can repeat this multiple times.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So again, this is a very similar picture I showed previously, but just as a recap, we have a filter and then you can do convolution and you have a filter response an.",
                    "label": 0
                },
                {
                    "sent": "Basically this is the output of corresponding to this specific filter.",
                    "label": 0
                },
                {
                    "sent": "So if you have different filter then.",
                    "label": 0
                },
                {
                    "sent": "You can do another convolution and then you will have a different feature map.",
                    "label": 0
                },
                {
                    "sent": "So if you have maybe 20 filters then you have 20 feature map like this.",
                    "label": 0
                },
                {
                    "sent": "OK, OK.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And one important thing to do is to apply some nonlinearity, because if you don't apply nonlinearity then repeating this convolution multiple times is just still a linear operator, so adding this nonlinearity is important in making this feature active features to be more invariant anrich.",
                    "label": 0
                },
                {
                    "sent": "And also the represented power up the network can be significantly increased, so the most popular way of doing nonlinearity is tangent age sigmoid or rectified linear.",
                    "label": 0
                },
                {
                    "sent": "In particular, the rectified linear is actually just the activation function that look like this, which means that if the filter activation is less than zero, then you just truncate to 0 if it is larger than certain threshold then you just.",
                    "label": 0
                },
                {
                    "sent": "Take that value.",
                    "label": 0
                },
                {
                    "sent": "It is a very simple nonlinearity, but this type of nonlinearity has achieved the state of the art results in many vision benchmarks.",
                    "label": 0
                },
                {
                    "sent": "So this is sort of used as a preferred option or used as a default.",
                    "label": 0
                },
                {
                    "sent": "So that's one maybe.",
                    "label": 0
                },
                {
                    "sent": "Difference between unsupervised learning versus supervised learning becausw.",
                    "label": 0
                },
                {
                    "sent": "In supervised learning you can use any kind of nonlinearity and you can mix and match and so on.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "Yeah, it's pretty much the same, yeah.",
                    "label": 0
                },
                {
                    "sent": "I mean, there's I don't think there is a very special like difference between fully connected or convolutional layers.",
                    "label": 0
                },
                {
                    "sent": "I mean, if you just just remember one thing, I should say that rectified linear works really well.",
                    "label": 0
                },
                {
                    "sent": "So I think somehow also for some reason it's easier to train.",
                    "label": 0
                },
                {
                    "sent": "So I think one difficulty of training supervised Convolutional network was also by partly due to maybe not using the good active nonlinearity function.",
                    "label": 0
                },
                {
                    "sent": "So in the old days basically either tangent H or sigmoid was used and also the amount of amount of labeled data was not.",
                    "label": 0
                },
                {
                    "sent": "Enough so for with all these combination it.",
                    "label": 0
                },
                {
                    "sent": "I mean it was shown that it was not very easy to actually learn, train or supervised convolutional network.",
                    "label": 0
                },
                {
                    "sent": "But I think the recent study shows that some kind of rectified linear nonlinearity is probably better than this other nonlinearities.",
                    "label": 0
                },
                {
                    "sent": "It makes the learning easier.",
                    "label": 0
                },
                {
                    "sent": "And of course there is another factor which is the existence of the huge labeled datasets, so.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I'm not aware of the actual.",
                    "label": 0
                },
                {
                    "sent": "Like very systematic study of, you know, just teasing out the effect of tangent, a sigmoid rectified linear for the large scale image recognition benchmarks.",
                    "label": 0
                },
                {
                    "sent": "But I think empirically rectified linear actually works better than the other nonlinearities.",
                    "label": 0
                },
                {
                    "sent": "Yes, yes.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Why it was not used?",
                    "label": 0
                },
                {
                    "sent": "Yeah, uh huh, yeah.",
                    "label": 0
                },
                {
                    "sent": "I think it's just I mean that.",
                    "label": 0
                },
                {
                    "sent": "I mean, it's hard to say since I didn't I was not at this time to try these things, but.",
                    "label": 0
                },
                {
                    "sent": "I mean basically rectified linear.",
                    "label": 0
                },
                {
                    "sent": "It was also more recently discovered.",
                    "label": 0
                },
                {
                    "sent": "I don't know.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure if people really didn't think about it along time ago, but for some reason.",
                    "label": 0
                },
                {
                    "sent": "I mean, there are some other like justification rectified linear in theory and also.",
                    "label": 0
                },
                {
                    "sent": "In some recent study I mean people.",
                    "label": 0
                },
                {
                    "sent": "Seriously, I didn't.",
                    "label": 0
                },
                {
                    "sent": "I don't think people really seriously try rectified linear, so probably that's the reason.",
                    "label": 0
                },
                {
                    "sent": "Like maybe I can say yeah, yes.",
                    "label": 0
                },
                {
                    "sent": "Uh huh.",
                    "label": 0
                },
                {
                    "sent": "That's that's probably also yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Well.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Right, right?",
                    "label": 0
                },
                {
                    "sent": "Probably you sure is a better person to answer discussion, yeah?",
                    "label": 0
                },
                {
                    "sent": "Yeah, OK, so OK. Let's just move on.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then you do pooling so you can do maximum or some, so I mean it's very simple operation, you just take some local Max or local some and you shrink this feature map to smaller size of, still keeping some some essential information about this input data.",
                    "label": 0
                },
                {
                    "sent": "An so.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's see and then you can do some normalization, so this is sort of optional step.",
                    "label": 0
                },
                {
                    "sent": "Nowadays, but the basic idea here is that you take the some point and then you look at some nearby region and then you take the sum squared sum.",
                    "label": 0
                },
                {
                    "sent": "I mean squared activation and some some kind of average activation around this area, and then you either subtract or divide by this average activation nearby and then that allows you to have a more evenly contrasted activation map.",
                    "label": 0
                },
                {
                    "sent": "So the main reason you do this is to somehow reduce the contrast.",
                    "label": 0
                },
                {
                    "sent": "I mean here you may have a very high activation or very small activation in different locations.",
                    "label": 0
                },
                {
                    "sent": "And also if you have very high activation, then it's also likely that nearby regions also will have a high activation.",
                    "label": 0
                },
                {
                    "sent": "Whereas if you do some normalization then you can kind of reduce this like strong correlation between activations and also reduce the high contrast and so on.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So it is a very reasonable idea, but also recent study shows that is not always necessary.",
                    "label": 0
                },
                {
                    "sent": "So here are some applications.",
                    "label": 0
                },
                {
                    "sent": "So it has been very well demonstrated that this convolutional network achieves excellent results on different type of digit recognition and text recognition tasks such as amnesty or Chinese characters, Arabic characters and traffic signs and House now.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hours and so on.",
                    "label": 0
                },
                {
                    "sent": "More recently.",
                    "label": 0
                },
                {
                    "sent": "CNN has been used for classifying images for image net this is.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I won a important practical breakthrough for the convolutional neural Nets, so this was the model proposed by Alex Kryszewski, an alias with Giver and Jeff Hinton from University of Toronto.",
                    "label": 0
                },
                {
                    "sent": "So it's just a very big convolutional network.",
                    "label": 0
                },
                {
                    "sent": "You have 224 by 224 as an input image, and then you basically go through.",
                    "label": 0
                },
                {
                    "sent": "It's the same same type of operation, convolution and pooling, convolution and pooling an.",
                    "label": 0
                },
                {
                    "sent": "At some point you just take the this activation by concatenating and then put the fully connected layers and at the end you have a classification layer.",
                    "label": 0
                },
                {
                    "sent": "So in this case the target is 1000 class so.",
                    "label": 0
                },
                {
                    "sent": "You have 1000 softmax outputs and then you just have a softmax.",
                    "label": 0
                },
                {
                    "sent": "Softmax Ann.",
                    "label": 0
                },
                {
                    "sent": "You use the cross entropy to define the loss and then you just do back propagation.",
                    "label": 0
                },
                {
                    "sent": "There are some some difference between the original CNN and this one where they use parallel GPU's so they have another kind of channel, another column of the CNS, that kind of go through in a two independent stream ways.",
                    "label": 0
                },
                {
                    "sent": "But this just some minor variation.",
                    "label": 0
                },
                {
                    "sent": "Essentially this is almost the same as the original CNN.",
                    "label": 0
                },
                {
                    "sent": "But the difference is that it's much bigger.",
                    "label": 0
                },
                {
                    "sent": "An also is train with much bigger data, so for the case of Imagenet it's 1,000,000 images.",
                    "label": 0
                },
                {
                    "sent": "And also in order to make this I mean trained.",
                    "label": 0
                },
                {
                    "sent": "Then you need a very high power in computational power.",
                    "label": 0
                },
                {
                    "sent": "So Fortunately the GPU was available at this time.",
                    "label": 0
                },
                {
                    "sent": "So basically they could train the model within a reasonable time.",
                    "label": 0
                },
                {
                    "sent": "So, so this model achieved.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "1st place for the Imagenet competition in 2012.",
                    "label": 0
                },
                {
                    "sent": "And back then, or there were some runner ups that didn't use the convolutional network and the gap was really big, so this was one transition point where people in computer vision community or convinced that CNN is actually the much better than some other like non deep learning approaches for this type of image recognition tasks an.",
                    "label": 0
                },
                {
                    "sent": "Here are some.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For more recent results.",
                    "label": 0
                },
                {
                    "sent": "So in 2013 basically pretty much all the entries leading entries used, the CNS and the error rate reduced from like 16 to about 1111% and.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Similar trends is repeated for the 2014 competition, so again the error rate cuts reduced almost by a factor of two and the winning entry was the work by Google.",
                    "label": 0
                },
                {
                    "sent": "And I'm going to briefly talk about this visual Network and Google Net later.",
                    "label": 0
                },
                {
                    "sent": "So yeah, but the trend is that we get very significant drops of the error rate every year, so I'm very curious how the results will turn out for this year's results.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so.",
                    "label": 0
                },
                {
                    "sent": "Here is some interesting study about how this learned representation looks like, so if you visualize the features so this is the embedding to just visualization purpose, so using the testing algorithm, so you just calculate the gist feature just feature.",
                    "label": 0
                },
                {
                    "sent": "That's actually quite popular in computer vision to represent some scene and some context of the image.",
                    "label": 0
                },
                {
                    "sent": "An different color represents different class.",
                    "label": 0
                },
                {
                    "sent": "And we see that just using some low level handcrafted features, the IT doesn't provide good separation between different classes.",
                    "label": 0
                },
                {
                    "sent": "And here is a also visualization of the first layer convolutional activation feature activations.",
                    "label": 0
                },
                {
                    "sent": "It's called decaf one.",
                    "label": 0
                },
                {
                    "sent": "It is so specific CNN implementation using CAFE and also there is a public publicly available feature and also CNN model called Decaf.",
                    "label": 0
                },
                {
                    "sent": "So using the first layer CNN you get you still don't get a very good separation.",
                    "label": 0
                },
                {
                    "sent": "However, if you visualize this top higher layer features then you see much clearer separation between different classes.",
                    "label": 0
                },
                {
                    "sent": "So this suggests that the CNN actually learns some embedding that implicitly separates different classes in a fairly fairly.",
                    "label": 0
                },
                {
                    "sent": "Fairly clear way, so this is giving some intuition why the CNN can be powerful for classification.",
                    "label": 0
                },
                {
                    "sent": "On another, maybe intuition is that if you consider the image manifold, I mean we're talking about 1,000,000 images with thousand different classes, an even for the same class.",
                    "label": 0
                },
                {
                    "sent": "If you look at pixel values of the two different images, they would like you know very different location if you just project into the Euclidean space.",
                    "label": 0
                },
                {
                    "sent": "But basically what they're trying to show is that as you map to the higher layers, you can somehow learn some manifold so that similar examples from the similar classes mapped to close by locations in this higher layer manifold.",
                    "label": 0
                },
                {
                    "sent": "So that's another intuition we get out of this figure.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here are some results on so-called domain adaptation.",
                    "label": 0
                },
                {
                    "sent": "So the basic idea is that you just pre train the CNN features from the image net and then apply to different tasks different image datasets.",
                    "label": 0
                },
                {
                    "sent": "So the basic idea is that different image sources or different image data set has slightly different statistics or patterns.",
                    "label": 0
                },
                {
                    "sent": "So for example images from image NET.",
                    "label": 0
                },
                {
                    "sent": "It's different from images from Amazon, or images from web Cam.",
                    "label": 0
                },
                {
                    "sent": "I mean there are some different statistics of pixel values and camera conditions and resolutions and so on.",
                    "label": 0
                },
                {
                    "sent": "Ideally we want to have a good feature that works well across all these datasets, So what they show in this paper is that CNN features is actually very good for domain adaptation, so see CNN features from image.",
                    "label": 0
                },
                {
                    "sent": "Net can be applied well to maybe Amazon or webcam images as well.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here is some other results.",
                    "label": 0
                },
                {
                    "sent": "So again, it's the same story.",
                    "label": 0
                },
                {
                    "sent": "So you apply CNN features, train from Image net.",
                    "label": 0
                },
                {
                    "sent": "And then apply to Caltech 101 and it shows very good generalization performance.",
                    "label": 0
                },
                {
                    "sent": "Starting from just a small number of labeled image.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here is the similar results using CNN features and compared to some existing work on feature learning.",
                    "label": 0
                },
                {
                    "sent": "And it shows much better generalization.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here is a similar story.",
                    "label": 0
                },
                {
                    "sent": "So this is some just a systematic evaluation of CNN features for different.",
                    "label": 0
                },
                {
                    "sent": "Different tasks and again it shows that.",
                    "label": 0
                },
                {
                    "sent": "It is significantly improve some previous state of the art that didn't use the CNS.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, I'm going to talk a little bit about most recent state of yes.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Uh-huh yeah.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK. OK.",
                    "label": 0
                },
                {
                    "sent": "So yeah, this is the six layer features of the CNN.",
                    "label": 0
                },
                {
                    "sent": "This is the seventh layer features of the CNN.",
                    "label": 0
                },
                {
                    "sent": "It doesn't really tell that conclusive way.",
                    "label": 0
                },
                {
                    "sent": "I mean, in this case, probably intuition is that I mean the performance is roughly the same.",
                    "label": 0
                },
                {
                    "sent": "I mean, it's not really the case that.",
                    "label": 0
                },
                {
                    "sent": "Seventh layer is significantly worse than the fixed layer.",
                    "label": 0
                },
                {
                    "sent": "I mean, maybe the intuition is that for the fully these are the fully connected layers, so also more close to the classification for image net so.",
                    "label": 0
                },
                {
                    "sent": "It's kind of saying that this top layer features are maybe slightly more accustomed to.",
                    "label": 0
                },
                {
                    "sent": "Our custom to do class like Actual image net classification.",
                    "label": 0
                },
                {
                    "sent": "So it may or may not be the best feature for transferring to the other tasks, but it's probably just like one study, one paper that shows this results.",
                    "label": 0
                },
                {
                    "sent": "I think there are some other results where actually going deeper is actually a good thing, so I'm going to talk about that when I talk about this Fijian Google net results.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Let's just talk about the.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "More recent architectures.",
                    "label": 0
                },
                {
                    "sent": "So here is a basically so called VGG network.",
                    "label": 0
                },
                {
                    "sent": "So the basic idea here is that you can just do many many convolutions with small filters.",
                    "label": 0
                },
                {
                    "sent": "So in fact, if you consider a 7 by 7 filter.",
                    "label": 0
                },
                {
                    "sent": "Then it is actually very similar to just using a 2 three by three convolutions.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So if you do convert convolution with three by three and then take another convolution with three by three, then.",
                    "label": 0
                },
                {
                    "sent": "And then basically the filter and you can actually just do some decomposition of large filter into multiple convolution with small filters.",
                    "label": 0
                },
                {
                    "sent": "And on top of that you can also add nonlinearities such as rectified linear.",
                    "label": 0
                },
                {
                    "sent": "So the basic idea is that if you just do one convolution with 7 by 7 filter.",
                    "label": 0
                },
                {
                    "sent": "11 Maybe possible disadvantage is that it takes some more computational resource, so it is slower to do.",
                    "label": 0
                },
                {
                    "sent": "Just do 7 by 7 convolution.",
                    "label": 0
                },
                {
                    "sent": "Whereas if you just do three by three, convolution twice is actually computationally cheaper and another reason is that if you apply nonlinearity after each of these three by three convolution, then the this output is much more like nonlinear function compared to just applying 17 by 7 convolutions.",
                    "label": 0
                },
                {
                    "sent": "So they're basically achieving some advantage by just thinking about convolution breaking convolution filters, large convolution filters into.",
                    "label": 0
                },
                {
                    "sent": "A recursive like small convolutions and also adding this nonlinearity.",
                    "label": 0
                },
                {
                    "sent": "So this is just one kind of like summary of what they do.",
                    "label": 0
                },
                {
                    "sent": "So for example they in this case they apply this four convolutions with filter size 3.",
                    "label": 0
                },
                {
                    "sent": "So you just apply three by three convolution nonlinearity rectified linear and then three by three rectified linear and so on.",
                    "label": 0
                },
                {
                    "sent": "And right so for example.",
                    "label": 0
                },
                {
                    "sent": "If you do this then it is for example this.",
                    "label": 0
                },
                {
                    "sent": "This filter is equivalent to just.",
                    "label": 0
                },
                {
                    "sent": "I mean in terms of receptive field size.",
                    "label": 0
                },
                {
                    "sent": "It is similar to applying 11 by 11 convolution ones, but because they do this multiple times, it is computationally cheaper and also it achieves much richer like function mapping through this nonlinear nonlinear functions and their compositions.",
                    "label": 0
                },
                {
                    "sent": "So that's the basic idea of this work.",
                    "label": 0
                },
                {
                    "sent": "So, so in this case they have a very deep network, such as like 16 layers, But I mean, although it sounds a bit intimidating, I mean one reason that they have such big deep network is that because they are decomposing this sum one convolution into many small convolutions OK. Any questions here?",
                    "label": 0
                },
                {
                    "sent": "So it turns out that this achieves much better results on image net classification.",
                    "label": 0
                },
                {
                    "sent": "So compared to this so called Alex Net that I just showed before, this type of network actually is considered much better as a image features and also.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For many different vision tasks.",
                    "label": 0
                },
                {
                    "sent": "And here is another work by Google.",
                    "label": 0
                },
                {
                    "sent": "The idea is actually very similar.",
                    "label": 0
                },
                {
                    "sent": "So again, the basic idea is that.",
                    "label": 0
                },
                {
                    "sent": "You apply small convolutions, an even one by one convolution an so the reason that you apply one by one convolution is that you actually apply some nonlinearity, so it is not just a linear function, it is some kind of adding some slight learning arities through this one by one convolution.",
                    "label": 0
                },
                {
                    "sent": "An also one reason they just do this type of multiple sized convolution is that you somehow.",
                    "label": 0
                },
                {
                    "sent": "Approximate the phobia in the visual cortex where I mean given the same location, you look at the one by one centered at this location, and then you look at three by three convolution and five by convolution.",
                    "label": 0
                },
                {
                    "sent": "So it is basically looking at different slightly different context with different sized receptive field an at the end it just puts all together.",
                    "label": 0
                },
                {
                    "sent": "So arguably this can be better than just using three by three convolution alone.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So this is yes.",
                    "label": 0
                },
                {
                    "sent": "You don't plateau at some point, yeah, right?",
                    "label": 0
                },
                {
                    "sent": "It'll plateau in some point, I mean.",
                    "label": 0
                },
                {
                    "sent": "I think also for the.",
                    "label": 0
                },
                {
                    "sent": "1st for this type of data set there are some errors in the labels.",
                    "label": 0
                },
                {
                    "sent": "I mean the labels are not perfect, so at some point it'll it'll converge to like upper bound.",
                    "label": 0
                },
                {
                    "sent": "Maybe I think we are getting very close.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "Yeah, it's hard to say, I mean, but I think they tried many different architectures when they do this competition.",
                    "label": 0
                },
                {
                    "sent": "So basically they're presenting pretty much the optimal structure, But another maybe issue is that it takes a long time to train this model, so it's actually hard to do very systematic evaluation or exploration of this architecture, so.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I think.",
                    "label": 0
                },
                {
                    "sent": "I mean, so far the basic results people show is that a very deep network.",
                    "label": 0
                },
                {
                    "sent": "But in essence I mean it's not necessarily really, really big or really deep, but it's more about maybe adding many small convolutions is better than using bigger convolution filters.",
                    "label": 0
                },
                {
                    "sent": "And here is a slightly different story.",
                    "label": 0
                },
                {
                    "sent": "But it's also saying that some kind of small convolutions with.",
                    "label": 0
                },
                {
                    "sent": "Concatenating with different spatial context is actually better than no or single receptive field size and so on.",
                    "label": 0
                },
                {
                    "sent": "So this is just one module of this Google Net and this is.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So like just a whole diagram of what they did, so it's very.",
                    "label": 0
                },
                {
                    "sent": "Fairly deep network, or, again, it's basically like just some recursive application of this module and.",
                    "label": 0
                },
                {
                    "sent": "And in fact, these these two I mean the Google net and.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Digital net achieved the state of the art results for this large scale image net classification so.",
                    "label": 0
                },
                {
                    "sent": "So the Google net results is here and the vision that results are here.",
                    "label": 0
                },
                {
                    "sent": "So these are roughly comperable.",
                    "label": 0
                },
                {
                    "sent": "I mean, these two are actually much better than.",
                    "label": 0
                },
                {
                    "sent": "Original kryszewski's like Alex net.",
                    "label": 0
                },
                {
                    "sent": "So nowadays most of the like state of the art results are achieved by this network.",
                    "label": 0
                },
                {
                    "sent": "So I mean basically you can use the features from the vision Net or Google Net for other tasks, so that's usually better than using the Alex net features.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I'm going.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To talk a little bit about some other vision applications.",
                    "label": 0
                },
                {
                    "sent": "So this is actually used for object detection so.",
                    "label": 0
                },
                {
                    "sent": "I mean, the basic story is that you apply this convolution pooling convolutional pooling and then at some point you just fully connect.",
                    "label": 0
                },
                {
                    "sent": "So you do you have fully connected layers and then classification layer for this particular work.",
                    "label": 0
                },
                {
                    "sent": "They actually do this so called multiscale convolution.",
                    "label": 0
                },
                {
                    "sent": "So the basic idea is that users take the maybe subsampling.",
                    "label": 0
                },
                {
                    "sent": "Users shrink the this feature map by half and then you just concatenate the input for this fully connected layer and the reason to do this is that.",
                    "label": 0
                },
                {
                    "sent": "This feature map and this feature map takes slightly different spatial context, so through this subsampling you can keep a slightly larger spatial context, and concatenating together is actually turns out to be better than not using this side channels or side steps of this pathway.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On an also more recently people have tried some different version of this.",
                    "label": 0
                },
                {
                    "sent": "Different version of this CNN application, so where you use the so-called CNN as a feature extractor for the Patch, so in this case you first generate bunch of image regions so called bounding box proposals and then for each region you crop and then users resize to 224 or something that can be fit into the Alex net or Vision Network.",
                    "label": 0
                },
                {
                    "sent": "And then you just train this part for classification, OK?",
                    "label": 0
                },
                {
                    "sent": "So in the testing time you just generate bunch of candidate bounding boxes and then you just evaluate each of the bounding box to calculate the confidence score of as output for CNN and then you do some post processing and eventually you can find some bounding box of corresponding to specific object and this work is called our CNN or regions with CNN features an this achieved state of the art results on.",
                    "label": 0
                },
                {
                    "sent": "Object detection so.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's another kind of breakthrough.",
                    "label": 0
                },
                {
                    "sent": "Here is some work that I have done very recently where we can actually improve this.",
                    "label": 0
                },
                {
                    "sent": "Our CNN by adding some.",
                    "label": 0
                },
                {
                    "sent": "Additional search using Bayesian optimization.",
                    "label": 0
                },
                {
                    "sent": "So for example, you can use the CNN with this bounding box proposal.",
                    "label": 0
                },
                {
                    "sent": "But the drawback here is that if you make a mistake in proposing a bounding box, then if your bounding boxes are actually poor match to ground truth, then you are actually doomed to fail.",
                    "label": 0
                },
                {
                    "sent": "So in this work what we do is basically given some local optimum where you can actually do some Bayesian optimization to search across the nearby region to find a better bounding box.",
                    "label": 0
                },
                {
                    "sent": "That's likely to give you a high CNN score, and then you add it to the evaluate this CNN score.",
                    "label": 0
                },
                {
                    "sent": "Then you can basically iteratively add multiple boxes around the local optimum and that actually gives a better.",
                    "label": 0
                },
                {
                    "sent": "Results or object detection?",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another way of improving CNN detection is to use so-called structure loss.",
                    "label": 0
                },
                {
                    "sent": "So the basic idea here is that instead of using classification loss, you can also add a loss that's reflecting the localization.",
                    "label": 0
                },
                {
                    "sent": "So here the loss is not only just one or zero.",
                    "label": 0
                },
                {
                    "sent": "It is also is a function of how this bounding box matches the ground truth, so this is a generally speaking on instance of structure prediction problem so.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I can actually formulate this as a structural SVM where this is basically the loss function of the CNN.",
                    "label": 0
                },
                {
                    "sent": "The top layer loss function, so it looks very similar to the support vector machine, but it has a structure loss here.",
                    "label": 0
                },
                {
                    "sent": "It actually has two different objective.",
                    "label": 0
                },
                {
                    "sent": "I mean three different constraint where the 1st first 2 constraint corresponds to a classification loss, which means that if you calculate the CNN features in our product with some weight then it should be good for classifying the existence or non existence of the object in the image.",
                    "label": 0
                },
                {
                    "sent": "But the third constraint corresponds to basically the localization.",
                    "label": 0
                },
                {
                    "sent": "So the ground truth score of the ground truth should be higher than.",
                    "label": 0
                },
                {
                    "sent": "Pull up non ground truth examples or bounding boxes and that can also improve this object detection problems.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "OK, so maybe 2 minutes, 2 minutes or three minutes, OK?",
                    "label": 0
                },
                {
                    "sent": "To me.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "OK so I have three more slides for most.",
                    "label": 0
                },
                {
                    "sent": "Is it OK?",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, I'm here.",
                    "label": 0
                },
                {
                    "sent": "Yeah, we have another application for segmentation.",
                    "label": 0
                },
                {
                    "sent": "So I mean, yeah, I think I'm not going to go into details, but the basic idea is that you have CNN, but here you have multi scale mapping so using this different sized version of this feature map that can also reflect different size spatial context and at the end in this case you try to predict the pixel level class.",
                    "label": 0
                },
                {
                    "sent": "Classification so and there are some additional machinery here that's used for aggregating these outputs, but for more detail you can take a look at this paper.",
                    "label": 0
                },
                {
                    "sent": "So in general CNN is also very useful.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Through segmentation problems and here are some also other applications where you can use it for tracking or pose estimation and also most recent work is most very exciting.",
                    "label": 0
                },
                {
                    "sent": "Work is the caption generation by many many groups.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And also I should say that the CNN's are used in many industrial applications.",
                    "label": 0
                },
                {
                    "sent": "So for like for like face recognition, CNN is used to basically extract the features for comparing different face images to tell whether these are the same person or not.",
                    "label": 0
                },
                {
                    "sent": "So this is actually done by Facebook.",
                    "label": 0
                },
                {
                    "sent": "They achieve really good performance on face recognition.",
                    "label": 0
                },
                {
                    "sent": "Um, yeah, so I should maybe.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But here is some other work where you.",
                    "label": 0
                },
                {
                    "sent": "You basically embed the CNN features an also the word embedding and then try to find some compatibility between these two.",
                    "label": 0
                },
                {
                    "sent": "So then you can basically somehow do some multimodal learning.",
                    "label": 0
                },
                {
                    "sent": "I believe Ross will talk more about multimodal learning later, but here is just one way of finding a joint embedding between the CNN and the word space.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can also do something similar for different type of features but.",
                    "label": 0
                },
                {
                    "sent": "So I think I'm done here so.",
                    "label": 0
                }
            ]
        }
    }
}