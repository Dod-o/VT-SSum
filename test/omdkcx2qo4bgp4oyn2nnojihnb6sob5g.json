{
    "id": "omdkcx2qo4bgp4oyn2nnojihnb6sob5g",
    "title": "Crowdsourced Affinity: A Matter of Fact or Experience",
    "info": {
        "author": [
            "Chun Lu, S\u00e9page"
        ],
        "published": "July 10, 2017",
        "recorded": "May 2017",
        "category": [
            "Top->Computer Science->Big Data",
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/eswc2017_lu_crowdsourced_affinity/",
    "segmentation": [
        [
            "So good morning everyone and welcome to this presentation of the paper titled Crowdsourcing Affinity.",
            "A matter of fact or experience.",
            "My name is true and this is joint work with my colleagues at the same Patch company Milan Stankovic, Philip Radulovich and my PhD supervisor at University of Paris, Albin Philip Lobley."
        ],
        [
            "And if you ask me to summarize in one sentence, what this paper really does, I would answer that this paper is about the comparison of the usage of knowledge graph and folksonomy for user entity affinity assessment with two studies within the travel destination recommendation scenario.",
            "So."
        ],
        [
            "During this presentation, our first to give a introduction about the notion of a user entity affinity, and then I will provide an comparison between knowledge Graph and folksonomy.",
            "After that I will present a first gold standard study, a semantic affinity framework, a second qualitative user study and I will conclude my talk with with some takeaway messages."
        ],
        [
            "So to user affinity, user entity Affinity is the likelihood of a user to be attracted by an entity or to perform an action related to an entity.",
            "In our case, an entity can be a book, a film or an artist, and an action might be click purchase like or share, and this notion has a big impact from both economic and user experience point of view.",
            "In many user centric information systems.",
            "It is crucial for predicting the CTR.",
            "The click through rate, which is very central to the online advertising industry and in exploratory search systems.",
            "It is leveraged to retrieve interesting entities that might satisfy a users fuzzy intention.",
            "It is proper to recommend the systems which are designed to mitigate the information overload by suggesting entities in affinity with the user."
        ],
        [
            "So how to assess the affinity?",
            "There are many families of techniques among which the content based one, this family of approaches hypothesize that users would have higher affinity with entities which are similar to the ones with which they had the positive interactions in the past.",
            "So as we can see, the entity similarity is very important to this family of techniques.",
            "And this family of techniques has been boosted in recent years by the emergence of knowledge, graphs and focus on a mix.",
            "Because these two database data spaces provide large amount of data about entities which allowed to compute the similarity between entities."
        ],
        [
            "Zero knowledge graph and folksonomy.",
            "Zero knowledge proof and folksonomy are respectively the milestones of semantic web and social web on the semantic Web.",
            "People contribute to the creation of a large public knowledge graph like DB pedia.",
            "And we can data while on the social web, people annotate and categorize entities with freely chosen chosen tags called tags which form the folksonomies.",
            "And despite this shade, crowdsourcing and collaborative trade, the encoded data are different in both nature and instructor knowledge graphs encode factual data with a formal ontology, while folksonomy encodes experience data with a loose structure that we give a concrete example in the movie domain.",
            "To illustrate their differences.",
            "So on DB Pedia, the film Jumanji is connected to facts.",
            "Like Robin Williams, but with the property staring while in the folksonomy of users of movie lines.",
            "The same film is abundantly tagged with nostalgic and not funny, natural disaster etc.",
            "Even though this folksonomy tags do not are not unless formally structured, they reflect the experience that different users had with this movie.",
            "And that's a sort of Inter subjectivity.",
            "That which is lacking in the factual knowledge graph."
        ],
        [
            "So, given this common points and differences between knowledge graph and folksonomies, our main research question is the following.",
            "Which data space contributes better to the user entity affinity assessment?",
            "We made a comprehensive study of the literature and this question is unanswered.",
            "While both Dataspaces today proliferate on the web, for example, we can observe the growth of the number of datasets on the link data in linked open data cloud and more and more usage of Twitter hashtags and tags on Instagram.",
            "Flickr and Amanda Lee.",
            "We think that it is necessary today to shed some light on this on their comparative performance on the user entity of initial assessment task.",
            "So in this paper we conducted two experiments within a travel destination recommendation scenario.",
            "The first one is a gold standard study and the second one is a user study."
        ],
        [
            "Why do we choose the travel domain?",
            "Because web is today one of the most important sources for travel, inspiration and purchase.",
            "More than 80% of people do travel planning online.",
            "However, travelers feel bogged down by the myriad of options they feel overwhelmed and are obliged to spend a lot of time browsing on multiple websites before booking a trip.",
            "I think many of us have the same experience and 68% of travelers.",
            "Making searching online without having a clear travel destination in mind, recommender systems can help travelers find more efficiently the destinations in affinity with them."
        ],
        [
            "Now I'm going to present the first gold standard study according to our best knowledge, there is no publicly available and widely used.",
            "The data set for the evaluation of travel destination recommender systems.",
            "This is why we built our own data set.",
            "We took the existing data set, which is why FCC 100M.",
            "This data set contains 100 million of geotagged photos and videos published on the Flickr platform.",
            "We process it in such a way that.",
            "The final data set contains 3878 users with travel sequences.",
            "A travel sequence is a list of cities that a user has visited in the past in a chronological order.",
            "For example, the sequence Munich, Stockholm NYC means that this user has visited cities in the chronological order.",
            "And we have a 705 distinct cities, and in average each user has five point 27 cities in their sequence."
        ],
        [
            "As far As for the car folksonomy, we cross the data from the website of a collaborative travel platform where users are invited to attack cities after.",
            "After their trips there.",
            "So in the data set we have 234 tags.",
            "For example kayaking, grateful wine and people watching and obviously people watching is an important travel activity for some people, and these tags are applied on more than 26,000 cities.",
            "In 154 countries.",
            "And we contacted TF IDF scoring on this data set in such a way that each city is associated with a list of tags, and each tag is associated associated with a TF IDF score.",
            "And the similarity between cities contact is calculated with the cosine measure."
        ],
        [
            "As for the for the Knowledge Graph part, we manually selected some inbound and outbound properties that we show in this table.",
            "For example, birthplace, location and inbound properties and East part of Country Time Zone.",
            "Mayor in outbound properties.",
            "So for each of the 705 cities that in our evaluation data set, we run sparkle queries with all these selected properties.",
            "Then we eliminate it knows.",
            "Or resources which are linked to only one city.",
            "Because this restore this nodes and resource resources do not contribute to the similarity calculation between 2 cities.",
            "And finally, the similarity measure was Jacquard measure."
        ],
        [
            "So to ensure a fair affecting environment for comparing them with the common affinity prediction algorithm, given a user profile containing a list of cities that the user has visited in the past, the affinity score is of a candidate city is calculated with this formula, which is the average sum of pairwise similarity with each city in the user profile.",
            "We used all but end protocol which is aligned with common practices of offline.",
            "Experiments in the recommendations assist recommender system community.",
            "There is a we set until one because different from the movie domain using music domain in the travel domain.",
            "In our data set, the user profile is relatively is relatively poor.",
            "We only have 5.27 cities per profile.",
            "As for the number of recommendations and there is no standard about the number of recommendations that should be computed.",
            "So we made a limited choice based on our past research work.",
            "Based on our experience with the clients of the same Patch company and also some several popular travel websites like Expedia, TripAdvisor, Kayak, etc.",
            "The number of recommendations depends on the different contexts and in recommendation or advertising banner.",
            "The number of recommendations is usually limited while in the inspirational browsing environment.",
            "More cities are usually displayed.",
            "For this reasons, we decided to compute top 1020 and 30 recommendations and to see how our two approaches the Knowledge Graph and folksonomy approaches perform in different configurations."
        ],
        [
            "In this scenario, the affinity assessment capacity can be most reflected by the accuracy of the recommendations to measure the currency, we use the two metrics success and mean reciprocal rank.",
            "The success metric calculates the number of users for whom the candidate approaches recommend City starting affinity with the users divided by the total number of users and the mean reciprocal rank shows how early the ground truth appears in the recommendation list currently.",
            "Their recommendation system community has a growing interest in generating diverse and novel recommendations, even at the expense of the accuracy.",
            "So apart from our main focus, we are also interested in observing how the approaches perform on these two quality dimensions similar to the SWC 2014 challenge on Elodie enabled book recommendation.",
            "We consider the intra least diversity with respect to two DB pedia.",
            "Properties which are DBO country and this city subject.",
            "We calculated novelty with respect to the capacity of recommending longtail cities following the power law distribution.",
            "We consider that 80% less popular cities as long tail cities we use DP that Pagerank value as the popularity index."
        ],
        [
            "So here the results of the first experiment.",
            "We can observe a net advantage of Knowledge graph approach over folksonomy approach in terms of success and mean reciprocal rank, higher scores on success and an mean reciprocal rank reflected the capacity of a system to detect the cities in high affinity with the user.",
            "And to keep them better rankings in the list, recommendations produced by the focus on me approach, I generally more diverse and novel than those produced by the Knowledge Graph approach, and this complementarity between these two approaches motivated us to develop a some."
        ],
        [
            "I think the framework to harvest the respective advantages of these two data spaces so this framework integrates aggregates, enriches and cleans entity data from knowledge graphs and folksonomies and the end of these pipeline and affinity graph is generated."
        ],
        [
            "So in addition to the recommendation usage, by using this constructed affinity graph, we can we have the possibility to explain the recommendations in a content based style.",
            "For example, one can recommend the city of Lubiana because because of the feature capitals in Europe.",
            "So what we do is that given the user profile containing a list of entities, list of cities we search in the affinity graph.",
            "The most common features shared by the cities.",
            "Since features are linked to entities explicitly with different properties we have, we have the control on the diversity of the features to display to the user.",
            "So we developed diversity function which maximizes the number of properties of the displayed.",
            "Teach us."
        ],
        [
            "To assess the usefulness and efficiency of the proposed semantic affinity framework, we conducted a qualitative user study which is complementary to the first qualitative evaluation on the gold standard data set.",
            "So in this study, the aim is to compare the three approaches.",
            "The affinity Graph Approach AG with Cajun folk, which were already compared in the first experiment and this time on two tasks, recommendation and explanation.",
            "We use the following protocol.",
            "Firstly, participants put themselves into the scenario of looking for the destination for their next trip, and they were free to choose to plan for a weekend trip or a long holiday.",
            "And Secondly, they went to the evaluation interface, where they could visualize the 705 cities to reduce the buyers towards cities showing on the top of the page we the presentation order of the cities was randomized.",
            "And Thirdly, they chose several cities that appealed to them at first glance.",
            "And fourthly, they submitted their choice choices and got three sets of top five highest discord cities generated by the three candidate approaches accompanied by 5 semantic concept semantic entities to explain recommendations.",
            "And in this figure we show an example of how these recommendations and explanations where it's presented.",
            "So in this example, the user has submitted Rome, Florence, an Amsterdam and the system explains that.",
            "This user might like clothing, food, David Hunt, Italy and history, and This is why the system recommends these five cities to Hug Island Naples Milan touring.",
            "And so to finally, this participant rated respectively.",
            "The recommendations and explanations as a whole in A5 level Likert scale on different quality dimensions.",
            "So relevance, diversity, novelty for the recommendation, and the relevance diversity in interesting ways for the explanations.",
            "So finally 37 people persist.",
            "Participate in our study, they have between 25 to 30.",
            "8 years old and we used the percentage of positive ratings, so four or five as our metric."
        ],
        [
            "So here are the results for the second user study, so the results on the recommendations are in line with the results obtained in our first experiment.",
            "The cage approach is clearly better accuracy than the focal approach, and the folk has more advantage on diversity and novelty in AG obtains.",
            "Indeed, balanced and good scores on 3 dimensions.",
            "And I'm going to present a little discuss a little more about Explonation part, which is not covered in the first experiment.",
            "So the results showed that explanations provided by folk were the most are appreciated.",
            "Because our we think that our folksonomy.",
            "Data set was crowd sourced by by the Travelers, so it is by nature and more relevant, highly relevant, and it covers different travel aspects.",
            "For example, food, activity, transport, etc.",
            "So the explination of capacity of AG was boosted by the inclusion of the features from the folksonomy which allowed it to outperform the cage approach.",
            "We're only knowledge graph features were used to explain the recommendations.",
            "And we found that participants were generally sceptical towards knowledge graph features.",
            "For example, some users found that the features are too general.",
            "For example, we explained it some some recommendations, waste category DCDC Ledger.",
            "And actually this this feature comes from the construction of the affinity graph, which is the one on one hop category enrichment.",
            "So to solve this this general generality problem, we might use the DB pedia category tree, since in the DB pedia category tree we know exactly level of the categories, so we can define a threshold above which the categories or the related concepts are considered to be too general for explanation task.",
            "And some other users found some found some features difficult to understand.",
            "For example, in this case, China Record Corporation.",
            "Actually this this user got this explanation because he's admitted Shanghai, Shenzhen and Beijing, and in this case and this China Record Corporation is linked to all these three cities by the property DBO location.",
            "Actually, we picked this DBO location property because it allows to capture some.",
            "Interesting links, for example, it can link 2 cities via a television series.",
            "However, these properties also used by entities having the type having the class DBO company.",
            "So this problem we might need some additional engineering efforts, for example blacklisting certain ontology classes."
        ],
        [
            "OK, let me conclude this talk so this work is about the comparison of the usage of knowledge Graph, an folksonomy for user entity affinity assessment with two studies within the travel destination, destination recommendation scenario and our main findings are that by using the Knowledge Graph we can yield a better accuracy in the Affinity assessment task, while folksonomy allow us to yield a better diversity.",
            "And novelty we proposed a semantic affinity framework to harvest the respective advantages of post data spaces and by using the affinity graph we can yield equitable performance for those recommendation and explination tasks.",
            "And this is all for my presentation.",
            "Thank you."
        ],
        [
            "For attention.",
            "Hi, thank you for interesting talk.",
            "Could you tell more about how you process your gold standard evaluation data set, ghost and data set OK.",
            "I will go back to the slide, so actually this data set was constructed during the previous previous work that we presented at equal conference.",
            "So since there isn't publicly available data set, we constructed our own one and in this in this why why FCC 100M?",
            "Each photo is associated with Geo Geo coordinates and Geo coordinates are associated with.",
            "Precision score we only took the school Geo coordinates with the highest.",
            "Precision score and then we had internal travel knowledge graph where we which each city is associated to the points of interest in this city and.",
            "Each point of interest is associated also with Geo coordinates, so we map each photo to this.",
            "And point of interest in this knowledge graph and we sorted this.",
            "Photos and we construct.",
            "We constituted this sequence travel sequences.",
            "Hi, very nice talk here.",
            "So very nice talk.",
            "One question.",
            "We found that selecting different properties for computing semantics here similarities or if you want different features may significantly change the performance recommendation favoring accuracy versus novelty or different measures, right?",
            "So my question is, did you try to use different features in the experiments to see if the feature sets selected may have an impact on those two measures?",
            "I'm referring to the first experiment in particular.",
            "Yeah, I understand.",
            "A short answer is no we haven't.",
            "And I agree that the feature the property selection can influence the performance of our system on this different quality.",
            "Dimensions and we.",
            "We have done some work.",
            "On this on, using the Knowledge Graph to compute the similarity, but we are not focused in this being paid in this paper on measuring the difference caused by the feature property selection.",
            "Yeah, along the same lines on the one hand side you used TF IDF and cosign on the other hand side you use binary one hot encoding and Jack are so all these maybe influences there and it's hard to say it's due to the knowledge graph versus the folksonomy.",
            "If you have so many variants on both sides.",
            "Just just another short remark for circumventing this problem of selecting particular properties and neglecting others.",
            "I wonder whether you have considered using embeddings there instead, because this is exactly for this task of finding similar entities which are close in the embedding space.",
            "OK, so there are two questions there, so the first question was about it.",
            "Two different similarity measures which are used in two in knowledge graph and folksonomy.",
            "Actually we used.",
            "We for the Knowledge Graph actually we used no no.",
            "For the folksonomy we use the Jaccard measure.",
            "And we and we didn't report this report because at least the results that we have that we reported are the best performance results of these two approaches.",
            "And for the second question, which is, do we consider using embeddings?",
            "Actually, I know this work conducted by realized by by the student from your group.",
            "Actually, I read that paper and yes why not?",
            "But I need to.",
            "I need to reread that paper to see how to.",
            "How to use it in this case?",
            "But I'm interested in in going the exact direction too.",
            "Of course.",
            "More questions.",
            "Since we have time, I have one question as well.",
            "So did you look at the recency of the picture so you crawled from this from this data set in any of your recommendations strategies did time in which people were posting an there.",
            "The tags that were made maybe differ in terms of time.",
            "There were several years before that, and the new tags appear.",
            "Did you take in consideration the time frame?",
            "In the folksonomy.",
            "Actually we didn't have access to this time information.",
            "We only data that we could.",
            "We could get was only on this particular city.",
            "There are these attacks which are applied on this city and how many people at applied these attacks on these cities.",
            "So we didn't know the time that this attacks has have been applied.",
            "OK, do you think time would have mattered?",
            "That there would be any difference in the way the folksonomy was gathered.",
            "In terms of tags for a city five years ago and now I suppose yes, but I cannot give you a satisfying answer.",
            "I need to think more about it.",
            "OK, thanks.",
            "Last chance for question, otherwise we got thank you very much thanks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So good morning everyone and welcome to this presentation of the paper titled Crowdsourcing Affinity.",
                    "label": 0
                },
                {
                    "sent": "A matter of fact or experience.",
                    "label": 0
                },
                {
                    "sent": "My name is true and this is joint work with my colleagues at the same Patch company Milan Stankovic, Philip Radulovich and my PhD supervisor at University of Paris, Albin Philip Lobley.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And if you ask me to summarize in one sentence, what this paper really does, I would answer that this paper is about the comparison of the usage of knowledge graph and folksonomy for user entity affinity assessment with two studies within the travel destination recommendation scenario.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "During this presentation, our first to give a introduction about the notion of a user entity affinity, and then I will provide an comparison between knowledge Graph and folksonomy.",
                    "label": 0
                },
                {
                    "sent": "After that I will present a first gold standard study, a semantic affinity framework, a second qualitative user study and I will conclude my talk with with some takeaway messages.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So to user affinity, user entity Affinity is the likelihood of a user to be attracted by an entity or to perform an action related to an entity.",
                    "label": 0
                },
                {
                    "sent": "In our case, an entity can be a book, a film or an artist, and an action might be click purchase like or share, and this notion has a big impact from both economic and user experience point of view.",
                    "label": 0
                },
                {
                    "sent": "In many user centric information systems.",
                    "label": 0
                },
                {
                    "sent": "It is crucial for predicting the CTR.",
                    "label": 0
                },
                {
                    "sent": "The click through rate, which is very central to the online advertising industry and in exploratory search systems.",
                    "label": 0
                },
                {
                    "sent": "It is leveraged to retrieve interesting entities that might satisfy a users fuzzy intention.",
                    "label": 0
                },
                {
                    "sent": "It is proper to recommend the systems which are designed to mitigate the information overload by suggesting entities in affinity with the user.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how to assess the affinity?",
                    "label": 0
                },
                {
                    "sent": "There are many families of techniques among which the content based one, this family of approaches hypothesize that users would have higher affinity with entities which are similar to the ones with which they had the positive interactions in the past.",
                    "label": 0
                },
                {
                    "sent": "So as we can see, the entity similarity is very important to this family of techniques.",
                    "label": 0
                },
                {
                    "sent": "And this family of techniques has been boosted in recent years by the emergence of knowledge, graphs and focus on a mix.",
                    "label": 0
                },
                {
                    "sent": "Because these two database data spaces provide large amount of data about entities which allowed to compute the similarity between entities.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Zero knowledge graph and folksonomy.",
                    "label": 0
                },
                {
                    "sent": "Zero knowledge proof and folksonomy are respectively the milestones of semantic web and social web on the semantic Web.",
                    "label": 0
                },
                {
                    "sent": "People contribute to the creation of a large public knowledge graph like DB pedia.",
                    "label": 0
                },
                {
                    "sent": "And we can data while on the social web, people annotate and categorize entities with freely chosen chosen tags called tags which form the folksonomies.",
                    "label": 0
                },
                {
                    "sent": "And despite this shade, crowdsourcing and collaborative trade, the encoded data are different in both nature and instructor knowledge graphs encode factual data with a formal ontology, while folksonomy encodes experience data with a loose structure that we give a concrete example in the movie domain.",
                    "label": 0
                },
                {
                    "sent": "To illustrate their differences.",
                    "label": 0
                },
                {
                    "sent": "So on DB Pedia, the film Jumanji is connected to facts.",
                    "label": 0
                },
                {
                    "sent": "Like Robin Williams, but with the property staring while in the folksonomy of users of movie lines.",
                    "label": 0
                },
                {
                    "sent": "The same film is abundantly tagged with nostalgic and not funny, natural disaster etc.",
                    "label": 0
                },
                {
                    "sent": "Even though this folksonomy tags do not are not unless formally structured, they reflect the experience that different users had with this movie.",
                    "label": 0
                },
                {
                    "sent": "And that's a sort of Inter subjectivity.",
                    "label": 0
                },
                {
                    "sent": "That which is lacking in the factual knowledge graph.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So, given this common points and differences between knowledge graph and folksonomies, our main research question is the following.",
                    "label": 0
                },
                {
                    "sent": "Which data space contributes better to the user entity affinity assessment?",
                    "label": 0
                },
                {
                    "sent": "We made a comprehensive study of the literature and this question is unanswered.",
                    "label": 0
                },
                {
                    "sent": "While both Dataspaces today proliferate on the web, for example, we can observe the growth of the number of datasets on the link data in linked open data cloud and more and more usage of Twitter hashtags and tags on Instagram.",
                    "label": 0
                },
                {
                    "sent": "Flickr and Amanda Lee.",
                    "label": 0
                },
                {
                    "sent": "We think that it is necessary today to shed some light on this on their comparative performance on the user entity of initial assessment task.",
                    "label": 0
                },
                {
                    "sent": "So in this paper we conducted two experiments within a travel destination recommendation scenario.",
                    "label": 0
                },
                {
                    "sent": "The first one is a gold standard study and the second one is a user study.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Why do we choose the travel domain?",
                    "label": 0
                },
                {
                    "sent": "Because web is today one of the most important sources for travel, inspiration and purchase.",
                    "label": 0
                },
                {
                    "sent": "More than 80% of people do travel planning online.",
                    "label": 0
                },
                {
                    "sent": "However, travelers feel bogged down by the myriad of options they feel overwhelmed and are obliged to spend a lot of time browsing on multiple websites before booking a trip.",
                    "label": 0
                },
                {
                    "sent": "I think many of us have the same experience and 68% of travelers.",
                    "label": 0
                },
                {
                    "sent": "Making searching online without having a clear travel destination in mind, recommender systems can help travelers find more efficiently the destinations in affinity with them.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now I'm going to present the first gold standard study according to our best knowledge, there is no publicly available and widely used.",
                    "label": 0
                },
                {
                    "sent": "The data set for the evaluation of travel destination recommender systems.",
                    "label": 0
                },
                {
                    "sent": "This is why we built our own data set.",
                    "label": 0
                },
                {
                    "sent": "We took the existing data set, which is why FCC 100M.",
                    "label": 0
                },
                {
                    "sent": "This data set contains 100 million of geotagged photos and videos published on the Flickr platform.",
                    "label": 0
                },
                {
                    "sent": "We process it in such a way that.",
                    "label": 0
                },
                {
                    "sent": "The final data set contains 3878 users with travel sequences.",
                    "label": 0
                },
                {
                    "sent": "A travel sequence is a list of cities that a user has visited in the past in a chronological order.",
                    "label": 0
                },
                {
                    "sent": "For example, the sequence Munich, Stockholm NYC means that this user has visited cities in the chronological order.",
                    "label": 0
                },
                {
                    "sent": "And we have a 705 distinct cities, and in average each user has five point 27 cities in their sequence.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As far As for the car folksonomy, we cross the data from the website of a collaborative travel platform where users are invited to attack cities after.",
                    "label": 0
                },
                {
                    "sent": "After their trips there.",
                    "label": 0
                },
                {
                    "sent": "So in the data set we have 234 tags.",
                    "label": 0
                },
                {
                    "sent": "For example kayaking, grateful wine and people watching and obviously people watching is an important travel activity for some people, and these tags are applied on more than 26,000 cities.",
                    "label": 0
                },
                {
                    "sent": "In 154 countries.",
                    "label": 0
                },
                {
                    "sent": "And we contacted TF IDF scoring on this data set in such a way that each city is associated with a list of tags, and each tag is associated associated with a TF IDF score.",
                    "label": 0
                },
                {
                    "sent": "And the similarity between cities contact is calculated with the cosine measure.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As for the for the Knowledge Graph part, we manually selected some inbound and outbound properties that we show in this table.",
                    "label": 0
                },
                {
                    "sent": "For example, birthplace, location and inbound properties and East part of Country Time Zone.",
                    "label": 0
                },
                {
                    "sent": "Mayor in outbound properties.",
                    "label": 0
                },
                {
                    "sent": "So for each of the 705 cities that in our evaluation data set, we run sparkle queries with all these selected properties.",
                    "label": 0
                },
                {
                    "sent": "Then we eliminate it knows.",
                    "label": 0
                },
                {
                    "sent": "Or resources which are linked to only one city.",
                    "label": 0
                },
                {
                    "sent": "Because this restore this nodes and resource resources do not contribute to the similarity calculation between 2 cities.",
                    "label": 0
                },
                {
                    "sent": "And finally, the similarity measure was Jacquard measure.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So to ensure a fair affecting environment for comparing them with the common affinity prediction algorithm, given a user profile containing a list of cities that the user has visited in the past, the affinity score is of a candidate city is calculated with this formula, which is the average sum of pairwise similarity with each city in the user profile.",
                    "label": 0
                },
                {
                    "sent": "We used all but end protocol which is aligned with common practices of offline.",
                    "label": 0
                },
                {
                    "sent": "Experiments in the recommendations assist recommender system community.",
                    "label": 0
                },
                {
                    "sent": "There is a we set until one because different from the movie domain using music domain in the travel domain.",
                    "label": 0
                },
                {
                    "sent": "In our data set, the user profile is relatively is relatively poor.",
                    "label": 0
                },
                {
                    "sent": "We only have 5.27 cities per profile.",
                    "label": 0
                },
                {
                    "sent": "As for the number of recommendations and there is no standard about the number of recommendations that should be computed.",
                    "label": 0
                },
                {
                    "sent": "So we made a limited choice based on our past research work.",
                    "label": 0
                },
                {
                    "sent": "Based on our experience with the clients of the same Patch company and also some several popular travel websites like Expedia, TripAdvisor, Kayak, etc.",
                    "label": 0
                },
                {
                    "sent": "The number of recommendations depends on the different contexts and in recommendation or advertising banner.",
                    "label": 0
                },
                {
                    "sent": "The number of recommendations is usually limited while in the inspirational browsing environment.",
                    "label": 0
                },
                {
                    "sent": "More cities are usually displayed.",
                    "label": 0
                },
                {
                    "sent": "For this reasons, we decided to compute top 1020 and 30 recommendations and to see how our two approaches the Knowledge Graph and folksonomy approaches perform in different configurations.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In this scenario, the affinity assessment capacity can be most reflected by the accuracy of the recommendations to measure the currency, we use the two metrics success and mean reciprocal rank.",
                    "label": 1
                },
                {
                    "sent": "The success metric calculates the number of users for whom the candidate approaches recommend City starting affinity with the users divided by the total number of users and the mean reciprocal rank shows how early the ground truth appears in the recommendation list currently.",
                    "label": 0
                },
                {
                    "sent": "Their recommendation system community has a growing interest in generating diverse and novel recommendations, even at the expense of the accuracy.",
                    "label": 0
                },
                {
                    "sent": "So apart from our main focus, we are also interested in observing how the approaches perform on these two quality dimensions similar to the SWC 2014 challenge on Elodie enabled book recommendation.",
                    "label": 0
                },
                {
                    "sent": "We consider the intra least diversity with respect to two DB pedia.",
                    "label": 0
                },
                {
                    "sent": "Properties which are DBO country and this city subject.",
                    "label": 0
                },
                {
                    "sent": "We calculated novelty with respect to the capacity of recommending longtail cities following the power law distribution.",
                    "label": 0
                },
                {
                    "sent": "We consider that 80% less popular cities as long tail cities we use DP that Pagerank value as the popularity index.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here the results of the first experiment.",
                    "label": 0
                },
                {
                    "sent": "We can observe a net advantage of Knowledge graph approach over folksonomy approach in terms of success and mean reciprocal rank, higher scores on success and an mean reciprocal rank reflected the capacity of a system to detect the cities in high affinity with the user.",
                    "label": 0
                },
                {
                    "sent": "And to keep them better rankings in the list, recommendations produced by the focus on me approach, I generally more diverse and novel than those produced by the Knowledge Graph approach, and this complementarity between these two approaches motivated us to develop a some.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I think the framework to harvest the respective advantages of these two data spaces so this framework integrates aggregates, enriches and cleans entity data from knowledge graphs and folksonomies and the end of these pipeline and affinity graph is generated.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in addition to the recommendation usage, by using this constructed affinity graph, we can we have the possibility to explain the recommendations in a content based style.",
                    "label": 0
                },
                {
                    "sent": "For example, one can recommend the city of Lubiana because because of the feature capitals in Europe.",
                    "label": 0
                },
                {
                    "sent": "So what we do is that given the user profile containing a list of entities, list of cities we search in the affinity graph.",
                    "label": 0
                },
                {
                    "sent": "The most common features shared by the cities.",
                    "label": 0
                },
                {
                    "sent": "Since features are linked to entities explicitly with different properties we have, we have the control on the diversity of the features to display to the user.",
                    "label": 0
                },
                {
                    "sent": "So we developed diversity function which maximizes the number of properties of the displayed.",
                    "label": 0
                },
                {
                    "sent": "Teach us.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To assess the usefulness and efficiency of the proposed semantic affinity framework, we conducted a qualitative user study which is complementary to the first qualitative evaluation on the gold standard data set.",
                    "label": 0
                },
                {
                    "sent": "So in this study, the aim is to compare the three approaches.",
                    "label": 0
                },
                {
                    "sent": "The affinity Graph Approach AG with Cajun folk, which were already compared in the first experiment and this time on two tasks, recommendation and explanation.",
                    "label": 0
                },
                {
                    "sent": "We use the following protocol.",
                    "label": 0
                },
                {
                    "sent": "Firstly, participants put themselves into the scenario of looking for the destination for their next trip, and they were free to choose to plan for a weekend trip or a long holiday.",
                    "label": 0
                },
                {
                    "sent": "And Secondly, they went to the evaluation interface, where they could visualize the 705 cities to reduce the buyers towards cities showing on the top of the page we the presentation order of the cities was randomized.",
                    "label": 0
                },
                {
                    "sent": "And Thirdly, they chose several cities that appealed to them at first glance.",
                    "label": 0
                },
                {
                    "sent": "And fourthly, they submitted their choice choices and got three sets of top five highest discord cities generated by the three candidate approaches accompanied by 5 semantic concept semantic entities to explain recommendations.",
                    "label": 0
                },
                {
                    "sent": "And in this figure we show an example of how these recommendations and explanations where it's presented.",
                    "label": 0
                },
                {
                    "sent": "So in this example, the user has submitted Rome, Florence, an Amsterdam and the system explains that.",
                    "label": 0
                },
                {
                    "sent": "This user might like clothing, food, David Hunt, Italy and history, and This is why the system recommends these five cities to Hug Island Naples Milan touring.",
                    "label": 0
                },
                {
                    "sent": "And so to finally, this participant rated respectively.",
                    "label": 0
                },
                {
                    "sent": "The recommendations and explanations as a whole in A5 level Likert scale on different quality dimensions.",
                    "label": 0
                },
                {
                    "sent": "So relevance, diversity, novelty for the recommendation, and the relevance diversity in interesting ways for the explanations.",
                    "label": 0
                },
                {
                    "sent": "So finally 37 people persist.",
                    "label": 0
                },
                {
                    "sent": "Participate in our study, they have between 25 to 30.",
                    "label": 0
                },
                {
                    "sent": "8 years old and we used the percentage of positive ratings, so four or five as our metric.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here are the results for the second user study, so the results on the recommendations are in line with the results obtained in our first experiment.",
                    "label": 0
                },
                {
                    "sent": "The cage approach is clearly better accuracy than the focal approach, and the folk has more advantage on diversity and novelty in AG obtains.",
                    "label": 0
                },
                {
                    "sent": "Indeed, balanced and good scores on 3 dimensions.",
                    "label": 0
                },
                {
                    "sent": "And I'm going to present a little discuss a little more about Explonation part, which is not covered in the first experiment.",
                    "label": 0
                },
                {
                    "sent": "So the results showed that explanations provided by folk were the most are appreciated.",
                    "label": 0
                },
                {
                    "sent": "Because our we think that our folksonomy.",
                    "label": 0
                },
                {
                    "sent": "Data set was crowd sourced by by the Travelers, so it is by nature and more relevant, highly relevant, and it covers different travel aspects.",
                    "label": 0
                },
                {
                    "sent": "For example, food, activity, transport, etc.",
                    "label": 0
                },
                {
                    "sent": "So the explination of capacity of AG was boosted by the inclusion of the features from the folksonomy which allowed it to outperform the cage approach.",
                    "label": 0
                },
                {
                    "sent": "We're only knowledge graph features were used to explain the recommendations.",
                    "label": 0
                },
                {
                    "sent": "And we found that participants were generally sceptical towards knowledge graph features.",
                    "label": 0
                },
                {
                    "sent": "For example, some users found that the features are too general.",
                    "label": 0
                },
                {
                    "sent": "For example, we explained it some some recommendations, waste category DCDC Ledger.",
                    "label": 0
                },
                {
                    "sent": "And actually this this feature comes from the construction of the affinity graph, which is the one on one hop category enrichment.",
                    "label": 0
                },
                {
                    "sent": "So to solve this this general generality problem, we might use the DB pedia category tree, since in the DB pedia category tree we know exactly level of the categories, so we can define a threshold above which the categories or the related concepts are considered to be too general for explanation task.",
                    "label": 0
                },
                {
                    "sent": "And some other users found some found some features difficult to understand.",
                    "label": 0
                },
                {
                    "sent": "For example, in this case, China Record Corporation.",
                    "label": 0
                },
                {
                    "sent": "Actually this this user got this explanation because he's admitted Shanghai, Shenzhen and Beijing, and in this case and this China Record Corporation is linked to all these three cities by the property DBO location.",
                    "label": 0
                },
                {
                    "sent": "Actually, we picked this DBO location property because it allows to capture some.",
                    "label": 0
                },
                {
                    "sent": "Interesting links, for example, it can link 2 cities via a television series.",
                    "label": 0
                },
                {
                    "sent": "However, these properties also used by entities having the type having the class DBO company.",
                    "label": 0
                },
                {
                    "sent": "So this problem we might need some additional engineering efforts, for example blacklisting certain ontology classes.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, let me conclude this talk so this work is about the comparison of the usage of knowledge Graph, an folksonomy for user entity affinity assessment with two studies within the travel destination, destination recommendation scenario and our main findings are that by using the Knowledge Graph we can yield a better accuracy in the Affinity assessment task, while folksonomy allow us to yield a better diversity.",
                    "label": 0
                },
                {
                    "sent": "And novelty we proposed a semantic affinity framework to harvest the respective advantages of post data spaces and by using the affinity graph we can yield equitable performance for those recommendation and explination tasks.",
                    "label": 0
                },
                {
                    "sent": "And this is all for my presentation.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For attention.",
                    "label": 0
                },
                {
                    "sent": "Hi, thank you for interesting talk.",
                    "label": 0
                },
                {
                    "sent": "Could you tell more about how you process your gold standard evaluation data set, ghost and data set OK.",
                    "label": 0
                },
                {
                    "sent": "I will go back to the slide, so actually this data set was constructed during the previous previous work that we presented at equal conference.",
                    "label": 0
                },
                {
                    "sent": "So since there isn't publicly available data set, we constructed our own one and in this in this why why FCC 100M?",
                    "label": 0
                },
                {
                    "sent": "Each photo is associated with Geo Geo coordinates and Geo coordinates are associated with.",
                    "label": 0
                },
                {
                    "sent": "Precision score we only took the school Geo coordinates with the highest.",
                    "label": 0
                },
                {
                    "sent": "Precision score and then we had internal travel knowledge graph where we which each city is associated to the points of interest in this city and.",
                    "label": 0
                },
                {
                    "sent": "Each point of interest is associated also with Geo coordinates, so we map each photo to this.",
                    "label": 0
                },
                {
                    "sent": "And point of interest in this knowledge graph and we sorted this.",
                    "label": 0
                },
                {
                    "sent": "Photos and we construct.",
                    "label": 0
                },
                {
                    "sent": "We constituted this sequence travel sequences.",
                    "label": 0
                },
                {
                    "sent": "Hi, very nice talk here.",
                    "label": 0
                },
                {
                    "sent": "So very nice talk.",
                    "label": 0
                },
                {
                    "sent": "One question.",
                    "label": 0
                },
                {
                    "sent": "We found that selecting different properties for computing semantics here similarities or if you want different features may significantly change the performance recommendation favoring accuracy versus novelty or different measures, right?",
                    "label": 0
                },
                {
                    "sent": "So my question is, did you try to use different features in the experiments to see if the feature sets selected may have an impact on those two measures?",
                    "label": 0
                },
                {
                    "sent": "I'm referring to the first experiment in particular.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I understand.",
                    "label": 0
                },
                {
                    "sent": "A short answer is no we haven't.",
                    "label": 0
                },
                {
                    "sent": "And I agree that the feature the property selection can influence the performance of our system on this different quality.",
                    "label": 0
                },
                {
                    "sent": "Dimensions and we.",
                    "label": 0
                },
                {
                    "sent": "We have done some work.",
                    "label": 0
                },
                {
                    "sent": "On this on, using the Knowledge Graph to compute the similarity, but we are not focused in this being paid in this paper on measuring the difference caused by the feature property selection.",
                    "label": 0
                },
                {
                    "sent": "Yeah, along the same lines on the one hand side you used TF IDF and cosign on the other hand side you use binary one hot encoding and Jack are so all these maybe influences there and it's hard to say it's due to the knowledge graph versus the folksonomy.",
                    "label": 0
                },
                {
                    "sent": "If you have so many variants on both sides.",
                    "label": 0
                },
                {
                    "sent": "Just just another short remark for circumventing this problem of selecting particular properties and neglecting others.",
                    "label": 0
                },
                {
                    "sent": "I wonder whether you have considered using embeddings there instead, because this is exactly for this task of finding similar entities which are close in the embedding space.",
                    "label": 0
                },
                {
                    "sent": "OK, so there are two questions there, so the first question was about it.",
                    "label": 0
                },
                {
                    "sent": "Two different similarity measures which are used in two in knowledge graph and folksonomy.",
                    "label": 0
                },
                {
                    "sent": "Actually we used.",
                    "label": 0
                },
                {
                    "sent": "We for the Knowledge Graph actually we used no no.",
                    "label": 0
                },
                {
                    "sent": "For the folksonomy we use the Jaccard measure.",
                    "label": 0
                },
                {
                    "sent": "And we and we didn't report this report because at least the results that we have that we reported are the best performance results of these two approaches.",
                    "label": 0
                },
                {
                    "sent": "And for the second question, which is, do we consider using embeddings?",
                    "label": 0
                },
                {
                    "sent": "Actually, I know this work conducted by realized by by the student from your group.",
                    "label": 0
                },
                {
                    "sent": "Actually, I read that paper and yes why not?",
                    "label": 0
                },
                {
                    "sent": "But I need to.",
                    "label": 0
                },
                {
                    "sent": "I need to reread that paper to see how to.",
                    "label": 0
                },
                {
                    "sent": "How to use it in this case?",
                    "label": 0
                },
                {
                    "sent": "But I'm interested in in going the exact direction too.",
                    "label": 0
                },
                {
                    "sent": "Of course.",
                    "label": 0
                },
                {
                    "sent": "More questions.",
                    "label": 0
                },
                {
                    "sent": "Since we have time, I have one question as well.",
                    "label": 0
                },
                {
                    "sent": "So did you look at the recency of the picture so you crawled from this from this data set in any of your recommendations strategies did time in which people were posting an there.",
                    "label": 0
                },
                {
                    "sent": "The tags that were made maybe differ in terms of time.",
                    "label": 0
                },
                {
                    "sent": "There were several years before that, and the new tags appear.",
                    "label": 0
                },
                {
                    "sent": "Did you take in consideration the time frame?",
                    "label": 0
                },
                {
                    "sent": "In the folksonomy.",
                    "label": 0
                },
                {
                    "sent": "Actually we didn't have access to this time information.",
                    "label": 0
                },
                {
                    "sent": "We only data that we could.",
                    "label": 0
                },
                {
                    "sent": "We could get was only on this particular city.",
                    "label": 0
                },
                {
                    "sent": "There are these attacks which are applied on this city and how many people at applied these attacks on these cities.",
                    "label": 0
                },
                {
                    "sent": "So we didn't know the time that this attacks has have been applied.",
                    "label": 0
                },
                {
                    "sent": "OK, do you think time would have mattered?",
                    "label": 0
                },
                {
                    "sent": "That there would be any difference in the way the folksonomy was gathered.",
                    "label": 0
                },
                {
                    "sent": "In terms of tags for a city five years ago and now I suppose yes, but I cannot give you a satisfying answer.",
                    "label": 0
                },
                {
                    "sent": "I need to think more about it.",
                    "label": 0
                },
                {
                    "sent": "OK, thanks.",
                    "label": 0
                },
                {
                    "sent": "Last chance for question, otherwise we got thank you very much thanks.",
                    "label": 0
                }
            ]
        }
    }
}