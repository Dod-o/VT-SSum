{
    "id": "ig2k26v5dialgcmtyraidd2ejdkqewvy",
    "title": "Fast Algorithms for Informed Source Separation",
    "info": {
        "author": [
            "Augustin Lef\u00e8vre, Universit\u00e9 catholique de Louvain"
        ],
        "published": "Aug. 26, 2013",
        "recorded": "July 2013",
        "category": [
            "Top->Computer Science->Machine Learning->Kernel Methods->Support Vector Machines",
            "Top->Computer Science->Optimization Methods",
            "Top->Computer Science->Compressed Sensing",
            "Top->Computer Science->Machine Learning->Regularization"
        ]
    },
    "url": "http://videolectures.net/roks2013_lefevre_methods/",
    "segmentation": [
        [
            "Sorry, I'm a postdoc at you, still run quite close from here.",
            "Man, this is not written on the slide, but this is a joint work with constantly now and you end up still.",
            "From the economic econometrics and Operations research development at receiver and children absolute, the Mathematical engineering Department in movement.",
            "And I will talk about the forms of separation.",
            "So first let me."
        ],
        [
            "Explain in details with it consistent so.",
            "So separation consists in from a given signal that is observed and that is a.",
            "A mixture of two or more unknown signals we want to recover the original source signals.",
            "So how do we do that?",
            "Take several steps and the main step I will talk about in this talk is the algorithm.",
            "But there are preliminary and post processing steps, so the first consist in computing a time frequency representation of the mixed signal."
        ],
        [
            "OK, so that's.",
            "The presentation of the mixed signal.",
            "So that's the simplest form is the waveform.",
            "So I remember that assuming that is recorded at at microphone with the microphone, it's a membrane vibrating, so it's vibrating around its equilibrium position.",
            "So here you can see as a function of time the displacement of the membrane of the microphone.",
            "So that's called a waveform, and this way from is displayed in the time domain.",
            "So the first step."
        ],
        [
            "This is computing time frequency representation of this signal, and it consists in.",
            "So looking at short snips of the signal, so here is the snip that goes from when T equals when H is equal to 1.",
            "So that's a.",
            "That's a shift, H is, H is a shift parameter, and we need shifted by zero.",
            "We take the first F samples of X.",
            "With each sample by windowing function and apply a transform of this shopping of the signal.",
            "And we do this for each for each end.",
            "So that means that the short time for transform can be seen as a matrix.",
            "Each column of this matrix corresponds to the free transform of a window of the signal and then.",
            "And indicates how much we have shifted, each each window of the signal."
        ],
        [
            "And then we take a.",
            "Spell measures to remove face information, and so this result in a negative matrix and so on.",
            "The abscissa there is time on the frequency axis on the ordinates is the frequency axis and the color code indicates the the magnitude of the coefficients.",
            "So in blue there's a small magnitude and really small magnitude.",
            "So the first thing you can see here is the time frequency.",
            "Presentation of this audio signal is very sparse.",
            "There are very few red dots and a lot of blue dots.",
            "Is also very redundant, so a lot of the columns of this matrix look like each other.",
            "And the reason why they sparsity is very much related to the nature of the signal.",
            "So these are music signals, and for many instruments the vibrations can be described by how many structure.",
            "And this structure here is evidence.",
            "For instance, when you look at this column, there are very few.",
            "Very few nonzero magnitude coefficients, and those are equally spaced in frequency.",
            "So this is very much related to the model of a string vibrating that you must be familiar with from.",
            "Education in physics.",
            "So that's the first step.",
            "Computing a time frequency transform then."
        ],
        [
            "Computing estimates of the spectrum of each box from this mixture using an algorithm that they will talk about."
        ],
        [
            "Estimating the complex spectrum with shocks given the complexity which shows given the spectrogram."
        ],
        [
            "And inviting that back to.",
            "We form signals.",
            "So let's, uh, that's the, that's an overview of how source separation works and.",
            "So I will now talk about the the the most important step of this procedure, which is the algorithm that recovers the spectrogram of the sources from the spectrogram of the mixture."
        ],
        [
            "Um?",
            "So.",
            "The the first methods that were applied to two single channel source separation, well negative matrix factorization methods which are unsupervised methods to represent matrices.",
            "And lately there have been a lot of contribution in adding more information to NMF because.",
            "It was observed that only using an unsupervised procedure was not enough, and.",
            "There was need to control the output of this unsupervised algorithm, so.",
            "Those contributions fall in the category of informed source separation, and today I will talk about annotated annotation, inform source separation.",
            "So the idea is that since the spectrum of which shocks is parse, it means that when we look at the spectrum of the mixture that have displayed in black and white, actually there are lots of points where you can make detections like for instance here are displayed in green detections of voice signal.",
            "And in red, where it's difficult just to see it from the back, but in red it's the detection of the main instruments, and so the principle is that if we are able to make a lot of those detections that would help to control the output of NF.",
            "So we're going to use those detections as additional constraints so."
        ],
        [
            "Let's now look at this more formally.",
            "So an MF would consist in.",
            "Approximating the observed spectral run.",
            "By a sum of low rank matrices.",
            "So here there is 1 product of matrices for each source and the source is indexed by G. So if if there were only the objective function here and and this constraint that the.",
            "The product is low rank.",
            "This would be classical NMF with the Euclidean norm to measure the similarity between the between the input and the mother.",
            "Yeah, so here it's Lauren constraint plus non negativity.",
            "So the both matrices should should have all negative coefficients.",
            "Um?",
            "And so this was the.",
            "So this was the first algorithm used to use for source separation for single channel source separation.",
            "And then now we're going to look at additional constraints in the form of equality here, so.",
            "Um?",
            "Matrix M is a mask, binary mask.",
            "So if there is a zero in EM, it means we let the let this call it free and if there is a one in the entry of MG it means we impose a constraint.",
            "So it's on both side of the equality and when M is equal to 1, that means that we constrain this coefficient one coefficient of this product to be equal to some target desired target.",
            "So coming back to this example for instance.",
            "So this means that if if the red, that would mean that we will impose that one of the source is equal to the observed.",
            "Mixture and the other is 0.",
            "I'm.",
            "So when we mark is that we where do we need?",
            "The negativity constraint is because we have we have taken.",
            "The observed spectrum is a negative and we need non negative estimate of the spectrograms todo todo masking.",
            "So that's the step that goes from having a spectrogram to estimating a complexity.",
            "I'm.",
            "And so This is why you report nearby on the negativity, and animal does something a little bit stronger.",
            "It requires the negativity of both factors of the product, whereas we need negativity of the product.",
            "And so I'm at his hand, so I want to extend that.",
            "But there will be a very good talk by Nicholas this too.",
            "Examine this this fact and we will consider instead in this case.",
            "So one reason why it is hard is because it's it's nonconvex.",
            "So here if you look at the this problem, if you fix either one of these one of these days, it's the objective function is convex and those equality constraints are also convex because linear equality constraints.",
            "But if you want to estimate both DNA jointly, it becomes an convex.",
            "So."
        ],
        [
            "We have been looking at the data.",
            "Reformulation of this well?",
            "Instead of imposing that.",
            "Every system is quickly lowering.",
            "We will only use a penalty term that promotes lowering solutions, so this penalty term is the new kernel.",
            "I'm so we keep the same dissimilarity measure between the input and the model.",
            "We promote sparsity by using a nuclear norm penalty, and we keep the same equality constraints and require no negativity of the spectrum, so that's all that we need.",
            "So here for the so the I guess most of you are familiar with the definition of the nuclear norm, but I will introduce some notations so.",
            "We will, we will.",
            "We will look here at the SVD of each short term.",
            "So here.",
            "Yeah, there should be a XG industry I've ever met.",
            "G, but there should be X GPG synergy to G&P Sigma Q transpose is this video of X where PRP&Q are orthogonal matrices and Sigma is diagonal matrix with the negative diagonal coefficients and the diagonal coefficients at the senior value.",
            "And then you can.",
            "Um is just the sum of the singular values.",
            "So when this thing was this problem is that it's now it's convex because the objective function is convex and the constraints are two.",
            "And instead of having to sell it, and if we will, as we will see, we will make repeated calls to SVD to compute the nuclear norm and additional things such as subgradient."
        ],
        [
            "So let's not talk about algorithms for this formulation.",
            "Um the the.",
            "The the the most I guess efficient approach to solving this problem would be to reformulate this nonsmooth problem would be to reformulate it as a as smooth as a screen problem.",
            "So there are examples of this, so.",
            "In another work, well, if you're if instead of.",
            "If instead of a."
        ],
        [
            "Showing some dissimilarity between the model and input you enforce exact equality."
        ],
        [
            "In this case, the problem can be viewed as minimizing a nuclear norm subjects to constraints.",
            "So here the constraints are annotations plus the fact that the spectral spectrum of the mixture should be equal to the sum of the spectrogram of each source.",
            "And in this case it has been shown that this can be reformulated to a linear program with.",
            "With the inequality constraints in the form of.",
            "Semidefinite constraint.",
            "So here the matrix should be.",
            "This matrix should be a positive semidefinite.",
            "And once you have this formulation, you can use an Intel open server which is very fast, which is a very fast convergence rate.",
            "However, using an entire openserver will require manipulating matrices of bigger size for from for the type of application we have, because here on the size of the input matrix which is F * N is approximately equal to the number of samples that we recorded, and there are typically four.",
            "Or do they have?",
            "10,000 samples every second.",
            "So this means 10 to the Power, 5 for the size of the matrix, and manipulating.",
            "There's even the option in this case would be of size 10 to the power 10, which is too large for typical desktop computer.",
            "So."
        ],
        [
            "So um, went down the two that we looked at first with subgradient descent, which is the most simple method in this case.",
            "So I guess most of you are familiar with these notions, But so the objective function is convex, so and it's defined every element that needs directional derivatives in a regular action.",
            "And, um.",
            "Sub brilliance generalize the gradient in the sense that.",
            "If the function F was differentiable, then the directional derivative seen as a function of the direction would be simply linear, and it would be equal to the gradient.",
            "Scandal with the with the direction.",
            "But when the function is normal differentiable, you can still define generalized notion of subgradient, that is.",
            "A linear under approximation of the directional derivative.",
            "So here the scaffolding that we use is defined as this.",
            "So we subgradients matrices of the same type as the X matrix.",
            "So there is one matrix for each source and we simply take the classical scalar product for matrices and some that are all matrices.",
            "Um, then projected gradient descent consists in estimating a subgradient of the function going in the opposite direction and projecting on the constraint.",
            "So in our case projecting on the constraint is projecting on the set of negativity constraints and a set of equality constraints.",
            "So it's very simple.",
            "Um, one thing that is very different between cebrian dissent and the differential.",
            "Billion percent is that you cannot always have this end of the cost function.",
            "So here I have a display.",
            "The one typical example where the the function as two pieces, each of the pieces are quadratic, and by looking at the so these are the level sets and by looking at the operational of direction to the level sets, you can put 2.",
            "So the action to directions that are offering little level sets and the convex Hull of this is the sub gradient of the function at this point.",
            "So in this case we would just take this subgradient going the opposite direction and as you can see.",
            "It every point on this help line stays out of the sublevel set of F, so that means that there will never be dissent from any choice of the step size.",
            "Um?",
            "So the conclusion is that choosing step size is a is difficult in subgradient descent, however.",
            "We can guarantee decent of the cost function, but we can still guarantee that the the the next step that will be closer to the solution.",
            "And that is if we choose a specific rule folder when once one specific wouldn't, we can choose to ensure this is to have a step size that decreases the square root of the number of iterations.",
            "So here T is the operation.",
            "So if we choose such a step size, then the distance to the optimal solution will decrease to zero eventually.",
            "So we."
        ],
        [
            "Bloodbath and we compare that to an F. So here there are two.",
            "So here we don't display the objective function we we display.",
            "I display a measure of quality of the resources, so it's just a distraction here and high on the software distortion ratio, the better the quality of the sources.",
            "So here is the cloud computing time.",
            "And here the quality of the solution as you can.",
            "So in green we have our formulation, the complex formulation, the.",
            "Which is labeled LONICH and MF stands for his own label.",
            "So here I have there you can notice that there are several red lines, so each one corresponds to an initial point of animals.",
            "Since it's nonconvex, you can not do better than try several and keep the one that has the lowest objective function.",
            "And as you can see, even at earlier iterations of formulation retrieves better for their encouraging, and so we looked at.",
            "We wanted to look at.",
            "Other algorithms that would be able to find solutions of better quality for fixed.",
            "Additional budget.",
            "Honesty."
        ],
        [
            "To look at is what the effect of the.",
            "You can non penalty on the on the solution, so here I've taken 1 random audio signal and I display the truxedo value profile of the sources and then look at the source one and source would be different profile but.",
            "When you're looking at one, is already interesting, and so for values of values of Lambda you can look at the singular value profile of the of the approximate solutions to the optimization problem, and as you can see, as Lambda increases the well, you never get exact zeros, but this is the first.",
            "This is in log scale, so you never get exact 0, but as you can see, there's quite a wide range between the singular values and if you fix.",
            "Level so if you count the number of singular values that are less than a given threshold, as you can see as Lambda increases the number, the number of singular values that are less than a given threshold increases.",
            "So this is the expected effect, and it's nice.",
            "So those were encouraging, and we.",
            "So we then looked at the grains and that might be faster so."
        ],
        [
            "I will also roll faster so I can explain those.",
            "So the smoothing technique in one slide.",
            "Consists in replacing the in our case.",
            "In our case, consistent replacing the objective function which is non smooth by a smooth function that is a good approximation of the original 1.",
            "So in this case, since the quadratic term is already differentiable, we only pick a smooth approximation of the nuclear norm, and that's done.",
            "Follows.",
            "So as you can see in this inequality, for new equals zero, we get exactly the original problem.",
            "So yeah, and we apply accelerated accelerated gradient descent.",
            "So when U equals zero there is the algorithm will be very slow, but we have exactly optimize the original problem before lunch menu.",
            "The algorithm will go faster because the Lipschitz constant of the corresponding objective function becomes smaller.",
            "But these solutions will be inaccurate.",
            "And."
        ],
        [
            "So you can compare that precisely.",
            "So if you you can compare subgradient and the smooth smooth plus acceleration based on the original objective function so."
        ],
        [
            "That's the objective function.",
            "And as you can see, for several values of new there is a compromise.",
            "So if if new is too small.",
            "We are the algorithm is to slowly we get solutions of not in a good quality Inn, limited CPU time and as it increases well we converge faster but the quality is also lower, so there's a always a compromise it."
        ],
        [
            "Definitely goes faster than the subgradient descent.",
            "Also, we can see that acceleration really brings something.",
            "Um?"
        ],
        [
            "So in conclusion, so there I presented formulation of source separation that takes into account simple equality constraints.",
            "And as we can see, with even with a simple optimization technique, we get good results that are.",
            "As good as a MF, and probably by finding better algorithm, we can.",
            "We can find algorithms that are faster and in future work we will consider more complex constraints such As for instance that the source is symmetric classified correctly.",
            "So this this could be incorporated as a inequality constraints.",
            "Thank you for attention and maybe if we have time we can listen to samples of the social.",
            "OK, if you if any one of you wants to listen to the samples I have for every proportion of annotation and four 5 tracks I have results comparing NMF and Subgradients or I don't want to take.",
            "Thank you.",
            "OK so I have exactly 1 simple so we can listen to the mix.",
            "My heart is with one ring and one.",
            "Love is hard to find.",
            "I have looked on the sound so that there is no distortion, so let's listen.",
            "Awareness is also one of the sources, so this is the true source for.",
            "Do you compliment?",
            "OK, this is recovered by NF.",
            "This is.",
            "So it's difficult to compare.",
            "This separation is not reflective, so this is an open problem and there are still a lot of things to do, but as we can see both in both contributions, the with the main message is that the fact that there are annotation makes that this is already.",
            "Good enough quality, so the annotations make most of the job.",
            "There are two algorithms, both of them do something and they are quite compareable.",
            "But I think the fact that there is a convex framework would allow to incorporate more complex constraints more easily and to look at the several algorithms that have been proposed in the optimization community.",
            "So that's why I was happy to present this work in an optimization workshop.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sorry, I'm a postdoc at you, still run quite close from here.",
                    "label": 0
                },
                {
                    "sent": "Man, this is not written on the slide, but this is a joint work with constantly now and you end up still.",
                    "label": 0
                },
                {
                    "sent": "From the economic econometrics and Operations research development at receiver and children absolute, the Mathematical engineering Department in movement.",
                    "label": 0
                },
                {
                    "sent": "And I will talk about the forms of separation.",
                    "label": 0
                },
                {
                    "sent": "So first let me.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Explain in details with it consistent so.",
                    "label": 0
                },
                {
                    "sent": "So separation consists in from a given signal that is observed and that is a.",
                    "label": 1
                },
                {
                    "sent": "A mixture of two or more unknown signals we want to recover the original source signals.",
                    "label": 0
                },
                {
                    "sent": "So how do we do that?",
                    "label": 0
                },
                {
                    "sent": "Take several steps and the main step I will talk about in this talk is the algorithm.",
                    "label": 1
                },
                {
                    "sent": "But there are preliminary and post processing steps, so the first consist in computing a time frequency representation of the mixed signal.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so that's.",
                    "label": 0
                },
                {
                    "sent": "The presentation of the mixed signal.",
                    "label": 0
                },
                {
                    "sent": "So that's the simplest form is the waveform.",
                    "label": 0
                },
                {
                    "sent": "So I remember that assuming that is recorded at at microphone with the microphone, it's a membrane vibrating, so it's vibrating around its equilibrium position.",
                    "label": 0
                },
                {
                    "sent": "So here you can see as a function of time the displacement of the membrane of the microphone.",
                    "label": 0
                },
                {
                    "sent": "So that's called a waveform, and this way from is displayed in the time domain.",
                    "label": 0
                },
                {
                    "sent": "So the first step.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is computing time frequency representation of this signal, and it consists in.",
                    "label": 0
                },
                {
                    "sent": "So looking at short snips of the signal, so here is the snip that goes from when T equals when H is equal to 1.",
                    "label": 0
                },
                {
                    "sent": "So that's a.",
                    "label": 0
                },
                {
                    "sent": "That's a shift, H is, H is a shift parameter, and we need shifted by zero.",
                    "label": 0
                },
                {
                    "sent": "We take the first F samples of X.",
                    "label": 0
                },
                {
                    "sent": "With each sample by windowing function and apply a transform of this shopping of the signal.",
                    "label": 0
                },
                {
                    "sent": "And we do this for each for each end.",
                    "label": 0
                },
                {
                    "sent": "So that means that the short time for transform can be seen as a matrix.",
                    "label": 1
                },
                {
                    "sent": "Each column of this matrix corresponds to the free transform of a window of the signal and then.",
                    "label": 0
                },
                {
                    "sent": "And indicates how much we have shifted, each each window of the signal.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we take a.",
                    "label": 0
                },
                {
                    "sent": "Spell measures to remove face information, and so this result in a negative matrix and so on.",
                    "label": 0
                },
                {
                    "sent": "The abscissa there is time on the frequency axis on the ordinates is the frequency axis and the color code indicates the the magnitude of the coefficients.",
                    "label": 0
                },
                {
                    "sent": "So in blue there's a small magnitude and really small magnitude.",
                    "label": 0
                },
                {
                    "sent": "So the first thing you can see here is the time frequency.",
                    "label": 0
                },
                {
                    "sent": "Presentation of this audio signal is very sparse.",
                    "label": 0
                },
                {
                    "sent": "There are very few red dots and a lot of blue dots.",
                    "label": 0
                },
                {
                    "sent": "Is also very redundant, so a lot of the columns of this matrix look like each other.",
                    "label": 0
                },
                {
                    "sent": "And the reason why they sparsity is very much related to the nature of the signal.",
                    "label": 0
                },
                {
                    "sent": "So these are music signals, and for many instruments the vibrations can be described by how many structure.",
                    "label": 0
                },
                {
                    "sent": "And this structure here is evidence.",
                    "label": 0
                },
                {
                    "sent": "For instance, when you look at this column, there are very few.",
                    "label": 0
                },
                {
                    "sent": "Very few nonzero magnitude coefficients, and those are equally spaced in frequency.",
                    "label": 0
                },
                {
                    "sent": "So this is very much related to the model of a string vibrating that you must be familiar with from.",
                    "label": 0
                },
                {
                    "sent": "Education in physics.",
                    "label": 0
                },
                {
                    "sent": "So that's the first step.",
                    "label": 0
                },
                {
                    "sent": "Computing a time frequency transform then.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Computing estimates of the spectrum of each box from this mixture using an algorithm that they will talk about.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Estimating the complex spectrum with shocks given the complexity which shows given the spectrogram.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And inviting that back to.",
                    "label": 0
                },
                {
                    "sent": "We form signals.",
                    "label": 0
                },
                {
                    "sent": "So let's, uh, that's the, that's an overview of how source separation works and.",
                    "label": 0
                },
                {
                    "sent": "So I will now talk about the the the most important step of this procedure, which is the algorithm that recovers the spectrogram of the sources from the spectrogram of the mixture.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The the first methods that were applied to two single channel source separation, well negative matrix factorization methods which are unsupervised methods to represent matrices.",
                    "label": 0
                },
                {
                    "sent": "And lately there have been a lot of contribution in adding more information to NMF because.",
                    "label": 0
                },
                {
                    "sent": "It was observed that only using an unsupervised procedure was not enough, and.",
                    "label": 0
                },
                {
                    "sent": "There was need to control the output of this unsupervised algorithm, so.",
                    "label": 0
                },
                {
                    "sent": "Those contributions fall in the category of informed source separation, and today I will talk about annotated annotation, inform source separation.",
                    "label": 1
                },
                {
                    "sent": "So the idea is that since the spectrum of which shocks is parse, it means that when we look at the spectrum of the mixture that have displayed in black and white, actually there are lots of points where you can make detections like for instance here are displayed in green detections of voice signal.",
                    "label": 0
                },
                {
                    "sent": "And in red, where it's difficult just to see it from the back, but in red it's the detection of the main instruments, and so the principle is that if we are able to make a lot of those detections that would help to control the output of NF.",
                    "label": 0
                },
                {
                    "sent": "So we're going to use those detections as additional constraints so.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's now look at this more formally.",
                    "label": 0
                },
                {
                    "sent": "So an MF would consist in.",
                    "label": 0
                },
                {
                    "sent": "Approximating the observed spectral run.",
                    "label": 0
                },
                {
                    "sent": "By a sum of low rank matrices.",
                    "label": 0
                },
                {
                    "sent": "So here there is 1 product of matrices for each source and the source is indexed by G. So if if there were only the objective function here and and this constraint that the.",
                    "label": 0
                },
                {
                    "sent": "The product is low rank.",
                    "label": 0
                },
                {
                    "sent": "This would be classical NMF with the Euclidean norm to measure the similarity between the between the input and the mother.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so here it's Lauren constraint plus non negativity.",
                    "label": 0
                },
                {
                    "sent": "So the both matrices should should have all negative coefficients.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And so this was the.",
                    "label": 0
                },
                {
                    "sent": "So this was the first algorithm used to use for source separation for single channel source separation.",
                    "label": 0
                },
                {
                    "sent": "And then now we're going to look at additional constraints in the form of equality here, so.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Matrix M is a mask, binary mask.",
                    "label": 0
                },
                {
                    "sent": "So if there is a zero in EM, it means we let the let this call it free and if there is a one in the entry of MG it means we impose a constraint.",
                    "label": 0
                },
                {
                    "sent": "So it's on both side of the equality and when M is equal to 1, that means that we constrain this coefficient one coefficient of this product to be equal to some target desired target.",
                    "label": 0
                },
                {
                    "sent": "So coming back to this example for instance.",
                    "label": 0
                },
                {
                    "sent": "So this means that if if the red, that would mean that we will impose that one of the source is equal to the observed.",
                    "label": 0
                },
                {
                    "sent": "Mixture and the other is 0.",
                    "label": 0
                },
                {
                    "sent": "I'm.",
                    "label": 0
                },
                {
                    "sent": "So when we mark is that we where do we need?",
                    "label": 0
                },
                {
                    "sent": "The negativity constraint is because we have we have taken.",
                    "label": 0
                },
                {
                    "sent": "The observed spectrum is a negative and we need non negative estimate of the spectrograms todo todo masking.",
                    "label": 0
                },
                {
                    "sent": "So that's the step that goes from having a spectrogram to estimating a complexity.",
                    "label": 0
                },
                {
                    "sent": "I'm.",
                    "label": 0
                },
                {
                    "sent": "And so This is why you report nearby on the negativity, and animal does something a little bit stronger.",
                    "label": 0
                },
                {
                    "sent": "It requires the negativity of both factors of the product, whereas we need negativity of the product.",
                    "label": 0
                },
                {
                    "sent": "And so I'm at his hand, so I want to extend that.",
                    "label": 0
                },
                {
                    "sent": "But there will be a very good talk by Nicholas this too.",
                    "label": 0
                },
                {
                    "sent": "Examine this this fact and we will consider instead in this case.",
                    "label": 0
                },
                {
                    "sent": "So one reason why it is hard is because it's it's nonconvex.",
                    "label": 0
                },
                {
                    "sent": "So here if you look at the this problem, if you fix either one of these one of these days, it's the objective function is convex and those equality constraints are also convex because linear equality constraints.",
                    "label": 0
                },
                {
                    "sent": "But if you want to estimate both DNA jointly, it becomes an convex.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We have been looking at the data.",
                    "label": 0
                },
                {
                    "sent": "Reformulation of this well?",
                    "label": 0
                },
                {
                    "sent": "Instead of imposing that.",
                    "label": 0
                },
                {
                    "sent": "Every system is quickly lowering.",
                    "label": 0
                },
                {
                    "sent": "We will only use a penalty term that promotes lowering solutions, so this penalty term is the new kernel.",
                    "label": 0
                },
                {
                    "sent": "I'm so we keep the same dissimilarity measure between the input and the model.",
                    "label": 0
                },
                {
                    "sent": "We promote sparsity by using a nuclear norm penalty, and we keep the same equality constraints and require no negativity of the spectrum, so that's all that we need.",
                    "label": 0
                },
                {
                    "sent": "So here for the so the I guess most of you are familiar with the definition of the nuclear norm, but I will introduce some notations so.",
                    "label": 0
                },
                {
                    "sent": "We will, we will.",
                    "label": 0
                },
                {
                    "sent": "We will look here at the SVD of each short term.",
                    "label": 0
                },
                {
                    "sent": "So here.",
                    "label": 0
                },
                {
                    "sent": "Yeah, there should be a XG industry I've ever met.",
                    "label": 0
                },
                {
                    "sent": "G, but there should be X GPG synergy to G&P Sigma Q transpose is this video of X where PRP&Q are orthogonal matrices and Sigma is diagonal matrix with the negative diagonal coefficients and the diagonal coefficients at the senior value.",
                    "label": 0
                },
                {
                    "sent": "And then you can.",
                    "label": 0
                },
                {
                    "sent": "Um is just the sum of the singular values.",
                    "label": 0
                },
                {
                    "sent": "So when this thing was this problem is that it's now it's convex because the objective function is convex and the constraints are two.",
                    "label": 0
                },
                {
                    "sent": "And instead of having to sell it, and if we will, as we will see, we will make repeated calls to SVD to compute the nuclear norm and additional things such as subgradient.",
                    "label": 1
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's not talk about algorithms for this formulation.",
                    "label": 0
                },
                {
                    "sent": "Um the the.",
                    "label": 0
                },
                {
                    "sent": "The the the most I guess efficient approach to solving this problem would be to reformulate this nonsmooth problem would be to reformulate it as a as smooth as a screen problem.",
                    "label": 0
                },
                {
                    "sent": "So there are examples of this, so.",
                    "label": 0
                },
                {
                    "sent": "In another work, well, if you're if instead of.",
                    "label": 0
                },
                {
                    "sent": "If instead of a.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Showing some dissimilarity between the model and input you enforce exact equality.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In this case, the problem can be viewed as minimizing a nuclear norm subjects to constraints.",
                    "label": 0
                },
                {
                    "sent": "So here the constraints are annotations plus the fact that the spectral spectrum of the mixture should be equal to the sum of the spectrogram of each source.",
                    "label": 0
                },
                {
                    "sent": "And in this case it has been shown that this can be reformulated to a linear program with.",
                    "label": 0
                },
                {
                    "sent": "With the inequality constraints in the form of.",
                    "label": 1
                },
                {
                    "sent": "Semidefinite constraint.",
                    "label": 0
                },
                {
                    "sent": "So here the matrix should be.",
                    "label": 0
                },
                {
                    "sent": "This matrix should be a positive semidefinite.",
                    "label": 1
                },
                {
                    "sent": "And once you have this formulation, you can use an Intel open server which is very fast, which is a very fast convergence rate.",
                    "label": 0
                },
                {
                    "sent": "However, using an entire openserver will require manipulating matrices of bigger size for from for the type of application we have, because here on the size of the input matrix which is F * N is approximately equal to the number of samples that we recorded, and there are typically four.",
                    "label": 0
                },
                {
                    "sent": "Or do they have?",
                    "label": 0
                },
                {
                    "sent": "10,000 samples every second.",
                    "label": 1
                },
                {
                    "sent": "So this means 10 to the Power, 5 for the size of the matrix, and manipulating.",
                    "label": 0
                },
                {
                    "sent": "There's even the option in this case would be of size 10 to the power 10, which is too large for typical desktop computer.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So um, went down the two that we looked at first with subgradient descent, which is the most simple method in this case.",
                    "label": 0
                },
                {
                    "sent": "So I guess most of you are familiar with these notions, But so the objective function is convex, so and it's defined every element that needs directional derivatives in a regular action.",
                    "label": 1
                },
                {
                    "sent": "And, um.",
                    "label": 1
                },
                {
                    "sent": "Sub brilliance generalize the gradient in the sense that.",
                    "label": 0
                },
                {
                    "sent": "If the function F was differentiable, then the directional derivative seen as a function of the direction would be simply linear, and it would be equal to the gradient.",
                    "label": 0
                },
                {
                    "sent": "Scandal with the with the direction.",
                    "label": 0
                },
                {
                    "sent": "But when the function is normal differentiable, you can still define generalized notion of subgradient, that is.",
                    "label": 0
                },
                {
                    "sent": "A linear under approximation of the directional derivative.",
                    "label": 0
                },
                {
                    "sent": "So here the scaffolding that we use is defined as this.",
                    "label": 0
                },
                {
                    "sent": "So we subgradients matrices of the same type as the X matrix.",
                    "label": 0
                },
                {
                    "sent": "So there is one matrix for each source and we simply take the classical scalar product for matrices and some that are all matrices.",
                    "label": 0
                },
                {
                    "sent": "Um, then projected gradient descent consists in estimating a subgradient of the function going in the opposite direction and projecting on the constraint.",
                    "label": 0
                },
                {
                    "sent": "So in our case projecting on the constraint is projecting on the set of negativity constraints and a set of equality constraints.",
                    "label": 0
                },
                {
                    "sent": "So it's very simple.",
                    "label": 0
                },
                {
                    "sent": "Um, one thing that is very different between cebrian dissent and the differential.",
                    "label": 0
                },
                {
                    "sent": "Billion percent is that you cannot always have this end of the cost function.",
                    "label": 0
                },
                {
                    "sent": "So here I have a display.",
                    "label": 0
                },
                {
                    "sent": "The one typical example where the the function as two pieces, each of the pieces are quadratic, and by looking at the so these are the level sets and by looking at the operational of direction to the level sets, you can put 2.",
                    "label": 0
                },
                {
                    "sent": "So the action to directions that are offering little level sets and the convex Hull of this is the sub gradient of the function at this point.",
                    "label": 0
                },
                {
                    "sent": "So in this case we would just take this subgradient going the opposite direction and as you can see.",
                    "label": 0
                },
                {
                    "sent": "It every point on this help line stays out of the sublevel set of F, so that means that there will never be dissent from any choice of the step size.",
                    "label": 1
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So the conclusion is that choosing step size is a is difficult in subgradient descent, however.",
                    "label": 0
                },
                {
                    "sent": "We can guarantee decent of the cost function, but we can still guarantee that the the the next step that will be closer to the solution.",
                    "label": 0
                },
                {
                    "sent": "And that is if we choose a specific rule folder when once one specific wouldn't, we can choose to ensure this is to have a step size that decreases the square root of the number of iterations.",
                    "label": 0
                },
                {
                    "sent": "So here T is the operation.",
                    "label": 0
                },
                {
                    "sent": "So if we choose such a step size, then the distance to the optimal solution will decrease to zero eventually.",
                    "label": 0
                },
                {
                    "sent": "So we.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Bloodbath and we compare that to an F. So here there are two.",
                    "label": 0
                },
                {
                    "sent": "So here we don't display the objective function we we display.",
                    "label": 0
                },
                {
                    "sent": "I display a measure of quality of the resources, so it's just a distraction here and high on the software distortion ratio, the better the quality of the sources.",
                    "label": 1
                },
                {
                    "sent": "So here is the cloud computing time.",
                    "label": 0
                },
                {
                    "sent": "And here the quality of the solution as you can.",
                    "label": 1
                },
                {
                    "sent": "So in green we have our formulation, the complex formulation, the.",
                    "label": 0
                },
                {
                    "sent": "Which is labeled LONICH and MF stands for his own label.",
                    "label": 0
                },
                {
                    "sent": "So here I have there you can notice that there are several red lines, so each one corresponds to an initial point of animals.",
                    "label": 0
                },
                {
                    "sent": "Since it's nonconvex, you can not do better than try several and keep the one that has the lowest objective function.",
                    "label": 0
                },
                {
                    "sent": "And as you can see, even at earlier iterations of formulation retrieves better for their encouraging, and so we looked at.",
                    "label": 0
                },
                {
                    "sent": "We wanted to look at.",
                    "label": 0
                },
                {
                    "sent": "Other algorithms that would be able to find solutions of better quality for fixed.",
                    "label": 0
                },
                {
                    "sent": "Additional budget.",
                    "label": 0
                },
                {
                    "sent": "Honesty.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To look at is what the effect of the.",
                    "label": 0
                },
                {
                    "sent": "You can non penalty on the on the solution, so here I've taken 1 random audio signal and I display the truxedo value profile of the sources and then look at the source one and source would be different profile but.",
                    "label": 0
                },
                {
                    "sent": "When you're looking at one, is already interesting, and so for values of values of Lambda you can look at the singular value profile of the of the approximate solutions to the optimization problem, and as you can see, as Lambda increases the well, you never get exact zeros, but this is the first.",
                    "label": 1
                },
                {
                    "sent": "This is in log scale, so you never get exact 0, but as you can see, there's quite a wide range between the singular values and if you fix.",
                    "label": 0
                },
                {
                    "sent": "Level so if you count the number of singular values that are less than a given threshold, as you can see as Lambda increases the number, the number of singular values that are less than a given threshold increases.",
                    "label": 1
                },
                {
                    "sent": "So this is the expected effect, and it's nice.",
                    "label": 0
                },
                {
                    "sent": "So those were encouraging, and we.",
                    "label": 0
                },
                {
                    "sent": "So we then looked at the grains and that might be faster so.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I will also roll faster so I can explain those.",
                    "label": 0
                },
                {
                    "sent": "So the smoothing technique in one slide.",
                    "label": 1
                },
                {
                    "sent": "Consists in replacing the in our case.",
                    "label": 0
                },
                {
                    "sent": "In our case, consistent replacing the objective function which is non smooth by a smooth function that is a good approximation of the original 1.",
                    "label": 0
                },
                {
                    "sent": "So in this case, since the quadratic term is already differentiable, we only pick a smooth approximation of the nuclear norm, and that's done.",
                    "label": 0
                },
                {
                    "sent": "Follows.",
                    "label": 0
                },
                {
                    "sent": "So as you can see in this inequality, for new equals zero, we get exactly the original problem.",
                    "label": 0
                },
                {
                    "sent": "So yeah, and we apply accelerated accelerated gradient descent.",
                    "label": 1
                },
                {
                    "sent": "So when U equals zero there is the algorithm will be very slow, but we have exactly optimize the original problem before lunch menu.",
                    "label": 0
                },
                {
                    "sent": "The algorithm will go faster because the Lipschitz constant of the corresponding objective function becomes smaller.",
                    "label": 0
                },
                {
                    "sent": "But these solutions will be inaccurate.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So you can compare that precisely.",
                    "label": 0
                },
                {
                    "sent": "So if you you can compare subgradient and the smooth smooth plus acceleration based on the original objective function so.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's the objective function.",
                    "label": 0
                },
                {
                    "sent": "And as you can see, for several values of new there is a compromise.",
                    "label": 0
                },
                {
                    "sent": "So if if new is too small.",
                    "label": 0
                },
                {
                    "sent": "We are the algorithm is to slowly we get solutions of not in a good quality Inn, limited CPU time and as it increases well we converge faster but the quality is also lower, so there's a always a compromise it.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Definitely goes faster than the subgradient descent.",
                    "label": 0
                },
                {
                    "sent": "Also, we can see that acceleration really brings something.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in conclusion, so there I presented formulation of source separation that takes into account simple equality constraints.",
                    "label": 1
                },
                {
                    "sent": "And as we can see, with even with a simple optimization technique, we get good results that are.",
                    "label": 1
                },
                {
                    "sent": "As good as a MF, and probably by finding better algorithm, we can.",
                    "label": 1
                },
                {
                    "sent": "We can find algorithms that are faster and in future work we will consider more complex constraints such As for instance that the source is symmetric classified correctly.",
                    "label": 0
                },
                {
                    "sent": "So this this could be incorporated as a inequality constraints.",
                    "label": 0
                },
                {
                    "sent": "Thank you for attention and maybe if we have time we can listen to samples of the social.",
                    "label": 0
                },
                {
                    "sent": "OK, if you if any one of you wants to listen to the samples I have for every proportion of annotation and four 5 tracks I have results comparing NMF and Subgradients or I don't want to take.",
                    "label": 1
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "OK so I have exactly 1 simple so we can listen to the mix.",
                    "label": 0
                },
                {
                    "sent": "My heart is with one ring and one.",
                    "label": 0
                },
                {
                    "sent": "Love is hard to find.",
                    "label": 0
                },
                {
                    "sent": "I have looked on the sound so that there is no distortion, so let's listen.",
                    "label": 0
                },
                {
                    "sent": "Awareness is also one of the sources, so this is the true source for.",
                    "label": 0
                },
                {
                    "sent": "Do you compliment?",
                    "label": 0
                },
                {
                    "sent": "OK, this is recovered by NF.",
                    "label": 0
                },
                {
                    "sent": "This is.",
                    "label": 0
                },
                {
                    "sent": "So it's difficult to compare.",
                    "label": 1
                },
                {
                    "sent": "This separation is not reflective, so this is an open problem and there are still a lot of things to do, but as we can see both in both contributions, the with the main message is that the fact that there are annotation makes that this is already.",
                    "label": 0
                },
                {
                    "sent": "Good enough quality, so the annotations make most of the job.",
                    "label": 0
                },
                {
                    "sent": "There are two algorithms, both of them do something and they are quite compareable.",
                    "label": 0
                },
                {
                    "sent": "But I think the fact that there is a convex framework would allow to incorporate more complex constraints more easily and to look at the several algorithms that have been proposed in the optimization community.",
                    "label": 0
                },
                {
                    "sent": "So that's why I was happy to present this work in an optimization workshop.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}