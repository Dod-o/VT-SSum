{
    "id": "444gi5wdkrc7jnlfape5dlxoowwit5cg",
    "title": "Factor Graphs for Fast and Scalable 3D Reconstruction and Mapping",
    "info": {
        "author": [
            "Frank Dellaert, College of Computing, Georgia Institute of Technology"
        ],
        "published": "April 3, 2014",
        "recorded": "September 2013",
        "category": [
            "Top->Computer Science->Computer Vision",
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/bmvc2013_dellaert_factor_graphs/",
    "segmentation": [
        [
            "OK, well thank you for inviting me.",
            "I'm very honored to give this talk.",
            "So before I start, I'm sure there's."
        ],
        [
            "Couple of Masters student in the room that are looking where to do their pH D an.",
            "We started a PhD program in Robotics a couple of years ago in Georgia Tech and applications are due December 15.",
            "OK, so you're all very welcome.",
            "We actually just graduated our first couple of students and one of our students.",
            "My check Mark just became assistant professor at University of Washington, so.",
            "It's an exciting program, so if you want to become faculty in North America, this is one of the ways to do it, OK?",
            "Alright.",
            "Well, so actually during my graduate."
        ],
        [
            "Karere I did something on the side which which which is Monte Carlo localization which is applying a particle filter too.",
            "Robot localization, I really just took the work from Isard and Blake and applied it to robot localization and it turns out that this is my most impactful piece of work ever and I'll tell you why, OK, any undergrad can program this up in 10 minutes.",
            "OK so here is 1 lesson I learned is you know nobody looks at my PhD teases actually, but this thing is so simple and so impactful precisely because it's so simple.",
            "So here's a lesson for aspiring grad students.",
            "Don't make your stuff too complicated, you know if it's really easy to implement, it will have a lot of impact.",
            "So I started out in robotics and so this work also led through another student in Sebastian Translab."
        ],
        [
            "2 running particle filters an entire trajectory's, so there's a problem in robotics called simultaneous localization and mapping where you were not only trying to localize the robot, but at the same time build a map of the environment, and so if you run a particle filter, not just some location, but on the entire trajectory, you can optimize the map for each particle and see how good it is, and that's in the weight of the particle, so that's the idea behind fast slam.",
            "Which which which is still influential in robotics these days.",
            "Now that's all with two delays words.",
            "So the state of the art back then was the sick laser range finders that have 2D.",
            "You know, given occurs enough to the laser points and I wanted to show this video from Ryan Eustice."
        ],
        [
            "Who kindly shared a lot of his work with me that I'll show in this talk.",
            "So this is the campus of.",
            "University of Michigan.",
            "But created with 3D Lidar point clouds.",
            "OK, so this is a robot going around and creating point clouds from 3D LIDAR measurements.",
            "So that's that's robot mapping in 2013 vastly large.",
            "Clouds of 3D points.",
            "But you don't need lasers to do that, actually, so one of the very cool things that happened in computer vision in the last 10 years is that the ideas that were developed in the 80s and 90s on 3D reconstruction structure from motion really took off in a new way in large part."
        ],
        [
            "Do the work of Noah Snavely at University of Washington.",
            "Steve side so so noise now at Cornell actually and photo tourism and Photosynth are sort of direct.",
            "Results of his work and he's famous for doing things like."
        ],
        [
            "You Google for images safe of Dubrovnik, so these are his images is his work so just want to stress that and you get maybe 10,000 images back.",
            "Then the genius of number was two very robustly.",
            "Do the correspondence of wide baseline correspondence between images."
        ],
        [
            "Build a 3D point cloud completely from images.",
            "Which which is, you know, as impressive as this 3D Lidar point cloud, right?",
            "And so each of these in frustums here is one of the cameras, not the images, that Noah took.",
            "These are all images taken by tourists while walking around in Dubrovnik, and so that's you know, amazingly, inspiring work.",
            "But it's just 3D.",
            "OK, so when I came to Georgia Tech, I got together with a student grant Schindler."
        ],
        [
            "And we decided to sort of bridge this towards 4 dimensional mapping.",
            "So the idea was that we took a collection of historical images.",
            "In this case is from Atlanta.",
            "And in this case, we did the correspondence manually, but we could build a 3D model of Atlanta with little time slider at the bottom, and so we could scrub through time and go and see the city actually appear and disappear as we scrub through time.",
            "So Atlanta is pretty cool, because in fact it was burned to the ground by Sherman in sort of the 1860s at the end of the Civil War.",
            "So you can really see the city which is now 5.4 million people.",
            "Sort of rise up from nothing.",
            "Now grant.",
            "Moved out."
        ],
        [
            "And he did something really cool.",
            "One of the side projects.",
            "Again, side projects are really important for grad students.",
            "Is this app he made is called Tri Mentionable, which is a 3D scanning app for the phone, so he's now doing that, but I told him, look, you know before you graduate and go off and do your iPhone app.",
            "Nobody cares about Atlanta, right?",
            "Atlanta, it's you know you have Coca Cola and you have Georgia Tech and you know."
        ],
        [
            "Um?",
            "So first to New York and then you can graduate and it has to be fully automatic or manual clicking on building.",
            "So inspired by the work of Noah etc.",
            "He did this fully, automatically segmented out the buildings, did his analysis of time, which you can do by gross occlusions.",
            "I could build a 4D browser of lohrmann."
        ],
        [
            "Atom.",
            "So, so here's a couple of images.",
            "We have a lot of images from the 1920s, nineteen 30s, and also a lot near, you know, when.",
            "Granted this work.",
            "Turns out it's quite hard to find images without rights of New York.",
            "So it's in between that.",
            "There is also a reason why it's lower Manhattan.",
            "I don't know whether people here ever visited New York.",
            "Probably half of you definitely did so, so everybody visits the Statue of Liberty in New York, right?",
            "That's one of the big tourist attractions, so they then take the boat back to Battery Park.",
            "And on the way they take pictures of lower Manhattan.",
            "So that's why there's a lot of them, even back in the 1920s, nineteen 30s."
        ],
        [
            "Alright so so, but I'm I'm here so this is the inspiration.",
            "You know this large scale 3D mapping, large scale 3D reconstruction, but I'm here to tell you actually about my secret weapon."
        ],
        [
            "Which I've developed.",
            "Try to understand in the last 10 years so there's ten years of work of me very slowly understanding connections between different and disparate subfields of engineering, and I'm going to tell it all.",
            "OK, so you don't have to go through this 10 years of slogging through the connections.",
            "It's about factor graphs and I'll make the connection between factor graphs.",
            "I'll tell you what they are and then I'll make connections with sparse linear algebra, and then I'll give you sort of a compendium of things that we did once we understood that connection, the last bit is a new preconditioning method that we applied to structure from motion and also catch some future directions.",
            "But before I do, I."
        ],
        [
            "Acknowledge the people that made all this possible, so there's a bunch of my students and postdocs and some alumni that I singled out here that have contributed heavily to this talk.",
            "And there's also a number of people from MIT, Michigan, Toronto and Freiburg that contributed movies and snippets of their work.",
            "That I'm going to show off, so not everything that I'm showing here is our work.",
            "It's also work that was inspired by the things that we that we brought out.",
            "Of course, you know we're sponsored by various funding agencies, and I'll talk a little bit about that as well.",
            "Well, start with something very, very boring."
        ],
        [
            "Which is Boolean satisfiability.",
            "You're all envisioned, probably because you know you didn't like that stuff.",
            "I mean, look, you know, come on in, it's boring, right?",
            "It's a formula it you don't even know what's going on, and so it's what is going on is there is a bunch of variables and you have to give an assignment true or false for each of these variables to make this Boolean formula through?",
            "Well, it turns out it's actually much more exciting than it looks.",
            "So here's a graph, OK?",
            "And all of a sudden you see that there is actually 5 variables.",
            "It was not very easy to figure that out from that.",
            "And each of these factor nodes is a Boolean formula and it is connected only to the variables that play in that formula.",
            "Alright, so you you have you have variables.",
            "You have factors and this is a factor graph, right?",
            "And this gives you a graphical representation of what the problem is that you're trying to solve.",
            "OK, so so another you know a subbranch from spound."
        ],
        [
            "Artificial intelligence is actually constraint satisfaction.",
            "It's also a big topic in graph theory, so so for example, the graph coloring problem is if you have a bunch of provinces in a country.",
            "In this case Japan."
        ],
        [
            "And you would like to color them such that no province neighboring province has the same color.",
            "You would create variables and then these factors here would say, well, you're not supposed to give any of these provinces the same color.",
            "Again, the problem is very apparent.",
            "The structure of the problem becomes very apparent once you phrase it as a factor graph.",
            "So this is discrete and the factors are also discrete, sore one or zero, it's allowed or it's not allowed."
        ],
        [
            "In graphical models, I'm very I'm very sure that all of you are familiar with Bayes networks, so Bayes networks are these graphical models is the most famous graphical model where now the variables are typically discreet as well.",
            "But these these these variables have conditional probability densities on them or distributions, meaning this is now continuous as a probability, and so it's actually trivial.",
            "To convert this to this different graphical model, which is a factor graph for now, each of these, for example, this is the probability of smoking or non smoking.",
            "This is the famous Asian Network.",
            "This factor would say, well you know 5050 for smoking.",
            "OK so it's quite easy to convert any base network or by the way if you're into segmentation or image image denoising, any mark of random field is better represented as a factor graph.",
            "Then as a market random field OK.",
            "So this is still discrete variables, but in robotics, an instructive promotion."
        ],
        [
            "What we have is continuous variables.",
            "So now we have continuous variables for example.",
            "So here is a Markov chain which is the location of the robot at time zero time.",
            "One time two and they are linked by these probabilistic constraints which are derived from odometry.",
            "The robot moves, it gets a measurement, it's a noisy measurement.",
            "So here is a probabilistic constraint between zero and one at the same time the robot sees a bunch of landmarks and every landmark is unknown.",
            "We don't know where it is, but there's a.",
            "Every measurement induces a probabilistic constraint between the pose and the landmark right?",
            "Now, this is still fairly abstract.",
            "Let me show you a small example."
        ],
        [
            "So here's a small example of a little robot.",
            "Which is kind of cute, right?",
            "It's like a little spider feeling its way, and so this is a fairly old graphic from back when my daughter was still excited by the stuff I did.",
            "You know she's 14 now.",
            "It's there's no all hope is lost.",
            "Well, you know we saw this this little robot.",
            "The idea is well, we would like to know where the rabbit was and very all the things that are that it saw again.",
            "You will see that factor graphs when you show the graph.",
            "The structure of the problem becomes completely."
        ],
        [
            "Parents.",
            "So here is a factor graph associated with this problem.",
            "So we have the the Markov chain backbone and then each landmark is seen a number of times from several locations and for example this one.",
            "We already know that this one is not going to be determined because it's only seen from one location, but here where you have all these dense connections will get very good information on the trajectory on the landmarks.",
            "So you can see the structure of the problem.",
            "OK, these are these are continuous and non linear by the way so."
        ],
        [
            "So each the densities that are induced by solving these factor graph.",
            "Are typically non linear and so we linearize in a nonlinear optimization fashion.",
            "Al talk about about the mostly linear factor graphs, but you should know that this goes into a big nonlinear Levenberg Marquardt style optimization.",
            "And if I."
        ],
        [
            "Structure from motion.",
            "This is a movie made by by my student, young John John.",
            "This is Chicago and these are actually images taken by Grand, Junior and so you see this is sort of the graph of connectivity between all the 3D points and the cameras, but really it's also the structure of the factor graph, right?",
            "Good so OK, so so at least I hope that I convinced you now that factor graphs are very cool way to look at the structure of the problem and see in one glance.",
            "Oh that's interesting.",
            "That's the information I have.",
            "Those are the connections.",
            "And also maybe this is sort of the difficulty of the problem if very dense vector graph might be a very difficult problem.",
            "Very sparse linear like structure is easy and that would be a great intuition if you have that intuition.",
            "In fact, I will.",
            "I will show you."
        ],
        [
            "So.",
            "How to compute and do inference in factor graphs?",
            "And I'll also show.",
            "Hopefully the connection with linear algebra and so you already know this algorithm actually from secondary school.",
            "In Britain, but 85% of you is not from Britain anyway, so so you know the."
        ],
        [
            "The thing before high school, probably you learn about this algorithm First United Connection with with the The boring Old way to do structure from motion and slam is you calculate this large sparse Jacobian matrix, which is the derivative of each of your constraints with respect to each of your variables.",
            "It's a large sparse matrix, but the structure of that matrix is exactly the factor graph.",
            "Every factor here is a row in the matrix.",
            "Every variable here is a column in the matrix.",
            "Alright, so so this one I put you is way more intuitive than this one.",
            "Right now, but we have to.",
            "We have to pay homage and."
        ],
        [
            "You know how do you normally solve these large linear systems?",
            "Well, what you do is you take this big curbing a."
        ],
        [
            "And you form what is known as the system of normal equations and you solve it by inverting the Hessian A transpose A.",
            "But nobody does that by inversion.",
            "You do it by factoring the matrix.",
            "So this big hashing, which is a square symmetric matrix, is factored into an upper triangular matrix R. And once you have that matrix, this is something very crucial.",
            "You can do back substitution on your variables and you have the solution.",
            "OK, so this is something to understand that once you are here, you have solved the problem and you can go to the next nonlinear iteration and so the only thing we need to know is how to factor this into that.",
            "Now."
        ],
        [
            "You know, if you ask a linear algebra person, how do you do that?",
            "Well, they'll tell you.",
            "Well, you can either fax or a transpose a directly using Cholesky factorization, or you can do it on a directly using QR factorization.",
            "Good, well great, you know.",
            "We type that into Matlab and you're done right.",
            "Yes, yes, you're done, but I wasn't done.",
            "I wanted to know what happened inside OK and this is the connection I want to make.",
            "I will tell you what QR factorization is, even though if you read the sparse linear algebra books it's really boring.",
            "OK, but it's really actually exciting.",
            "I want to, you know, give you the inside."
        ],
        [
            "Also, that looking at the sparse structure, so here is a little slam problem and here is our matrix.",
            "It's sparse, but it doesn't tell you much, except that it's sparse.",
            "Here's here's another."
        ],
        [
            "Sample.",
            "It's a sparser environment at MIT.",
            "This is an infinite corridor, and the R matrix is very sparse.",
            "Environment is very sparse, but you don't get a lot of intuition from this.",
            "That is because there is none to be gotten.",
            "OK, so matrixes are very clumsy ways of writing down graphs.",
            "OK. And so I will tell you about."
        ],
        [
            "This algorithm, which is is the elimination algorithm.",
            "But before I do, I'll do a little detour.",
            "If I would ask you what is the coolest science fiction?",
            "Propulsion mechanism in you know what would it be?",
            "The warp drive.",
            "see I got the same question, yes, but the one that you actually could actually do.",
            "You know that there is 1 actually working.",
            "The ion drive.",
            "The ion propulsion system.",
            "So there is a spacecraft at this moment that is flying.",
            "You know somewhere in the solar system with an ion propulsion drive.",
            "This will come back to the talk in a minute.",
            "It's taking this long detour and it'll stop on the way.",
            "I'm a little planetoid called Vesta, which must have been the inspiration behind the Microsoft operating system.",
            "Which is a little planetoid, but it's real.",
            "Target is actually another planetoid called Sarah's, and Sarah's was, you know.",
            "150 years ago I guess was was at the same level of Pluto.",
            "It was a planet, it was just discovered.",
            "It was the hottest scientific object of its time and inspired Gause to develop linearly squares and the elimination algorithm.",
            "OK and Don, which is the spacecraft, will reach Sarah's in 2015, so will have a gas revival in two years.",
            "OK, so let me now tell you about Gaussians.",
            "Idea, which is the elimination algorithm in which you already learned about in secondary school.",
            "You take a factor graph, so here's a little factor graph.",
            "You can also write it down in a boring old sparse linear algebra way, so I did that for you.",
            "OK, so if you like linear algebra, you can follow along on this side.",
            "You take this vector graph and you say, let's let's eliminate one variable at a time.",
            "Let's make the problem simpler.",
            "OK, instead of looking at 5 variables, let's just look at L1, which is the land."
        ],
        [
            "Mark up here now looking at all the factors connected to L1.",
            "You will find that it's only connected to certain other variables which are called the separator of L1.",
            "In Degraff, these two variables separate L1 from everything else in the graph.",
            "Not a big deal now right?",
            "There's only two other variables left, but in general there's a million OK.",
            "So so, so that induces a small joint probability distribution on L1 and separator.",
            "And any joint distribution can be factored.",
            "In a."
        ],
        [
            "In a conditional and the smaller joint on the separator.",
            "So a conditional we already know how to represent.",
            "Actually that's a little Bayes, not fragmente, so here we now have a base node on L1 which depends on its separator and we also have to pay a price.",
            "The prices that we now have a joint density on X1 and X2.",
            "They are not correlated and they might not have been correlated before.",
            "OK.",
            "This is by the way you can do this with systems of linear equations and then you have gas Jordan elimination.",
            "OK, so you will induce you will solve for one variable and you now have a new equation on the variables that you that you touched in the process.",
            "What happened in the sparse linear algebra case is that all the nonzeros in the L1 column disappeared, because now it's just a function of X1 and X2 and it has no more constraints on it.",
            "Good so you keep doing this in some ordering will do L2 next."
        ],
        [
            "Which induces a factor on X3.",
            "Getting out all the nonzeros disappear in the L2 column and you keep doing this OK."
        ],
        [
            "Until."
        ],
        [
            "So."
        ],
        [
            "What you reaches this stage where now the factor graph has been transformed into another density trans representation, which is the base in that.",
            "At the same time, by the way.",
            "The sparse matrix here became a sparse upper triangular matrix.",
            "OK, but that's the cool thing, right?",
            "That's that's boring, right?",
            "This is arbitrary, or it doesn't tell you anything, but this is a Bayes net, which is now the solution to your problem.",
            "OK, so QR factorization I just gave you QR factorization, but the cool way takes a factor graph and transforms into a Bayes net.",
            "And the Bayes net has a structure which is."
        ],
        [
            "Which has a matrix which is upper triangular which just means there is no operator.",
            "Angular just means directed acyclic.",
            "OK, which is a base network is a DAG.",
            "Alright, let's see this at work on a couple of more interesting graphs or here."
        ],
        [
            "Is a little movie made by my student young.",
            "The answer here is a circle, an elimination each way.",
            "And here is the resulting Bayes net.",
            "Or here is a planar graph.",
            "These are some."
        ],
        [
            "Set examples and you get elimination eating away, and here is the Bayes net that results.",
            "OK. Good so so two things that I told you is.",
            "You know, factor graphs are cool, right?",
            "And even QR factorization is cool.",
            "OK, it takes a factor graph, turns it into a Bayes net, and it was invented by.",
            "Buy gas well, the Chinese will say no.",
            "No 2000 years ago we did it.",
            "Which is true, but they did it for three variables.",
            "Is a cow or horse and a pig, and there's a little recipe on how to figure out the weight of each when you put them two at a time on a scale, which is a small little sensor Fusion problem.",
            "2000 year old?",
            "Here is a recipe, but Gauss reinvented it.",
            "And being Western centric, we called it Gaussian elimination.",
            "Alright, so once you have this connection between sparse linear algebra and graphical models OK, and also realize that it's much bigger than sparse linear algebra, remember I I talked about Boolean satisfiability constraint satisfaction, you know.",
            "Mark of random fields.",
            "All of these can use the same algorithm to do inference so so.",
            "So sparse linear algebra is really the very special case of this story.",
            "When you have linear constraints on Gaussian noise, OK?"
        ],
        [
            "You have this connection, though there is a whole lot of things that you are now inspired to do OK. You broke open the QR factorization buksan.",
            "So in the last five years."
        ],
        [
            "We've built a tool box which really does a large scale optimization.",
            "It's called GSM for Georgia Tech smoothing and mapping 'cause it was mostly applied to robotics in the beginning, but now we do structure from motion and in fact it also solves sudokus, so the same algorithm template it in a different way will solve a sudoku.",
            "So there is some C++ and you just create this factor graph very quickly.",
            "And I'm going to call optimize.",
            "And there's a whole MATLAB toolbox on top so you can do it in MATLAB if you'd like.",
            "Now, one of the things that you quickly realize and sparse linear algebra people definitely did is."
        ],
        [
            "That the elimination ordering in which you eliminate these variables is crucial.",
            "OK, that's the secret.",
            "That's the problem actually.",
            "So finding this optimal ordering.",
            "So here is the one that is really nice.",
            "It leads to a fairly sparse graph, another ordering in the same graph can lead you to a fully dense Bayes network.",
            "And that's the difference between 10 milliseconds or an hour.",
            "Even large graphs, I mean literally it's that stark.",
            "OK, you can be very, very unlucky in choosing an ordering.",
            "And as with all good things in life, the optimal ordering is NP hard.",
            "OK to find it.",
            "But there is some very good heuristics.",
            "For example, here is."
        ],
        [
            "What is called approximate minimum degree where you pick a node to be illuminated which has sort of the smallest degree in the graph that is left.",
            "And it does something reasonable, OK?",
            "Another very very nice heuristic is, well, let's divide and conquer.",
            "If you have a big graph, let's cut it into pieces and solve each of the pieces and so it's."
        ],
        [
            "This is what happens here.",
            "So we cut sandwich first.",
            "Do this piece and then this piece and then this piece and then this piece.",
            "And in fact one of my colleagues, Dick Lipton.",
            "Prove the theorem that in planar graphs you can always cut it with a separator that is only size square root of N, which then leads to a full elimination algorithm which has limited which is has an upper bound of order N to the 1.5 in terms of solving and he did it with charge and it's a famous result in finite element methods.",
            "OK, but finding these separators themselves is NP hard OK.",
            "Nevertheless, these things we applied also for."
        ],
        [
            "Doctor promotion this is work by Kinny who's not about Microsoft Research and so here is the Saint Peters Basilica datasets.",
            "City of Ricks, alisky.",
            "And so he cut up this large graph into different pieces and then solves each one separately and then you can do that out of course, so you can sort of load in a part of the graph, solve it, put it back to disk, and then load the next one.",
            "So now you can be very large structure from motion problems, sort of on a single core computer by leading them in one of the time one at a time.",
            "Now you can do this recursively.",
            "So actually Dick Lipton's result was about."
        ],
        [
            "Recursive Lee cutting a graph.",
            "So this is the nested dissection algorithm and icing.",
            "Also, I'm just going to run this again.",
            "Is that the problems are independent so we can solve each of these little subtrees that create that is created in parallel.",
            "OK, so you don't have to wait for one side to be done before you can solve the other side.",
            "So I also actually this is very recent work when he was still, you know."
        ],
        [
            "When he was already at Microsoft, we did a variant of search for Motion, which is called hyper structure from Motion, where we take the hypergraph reflector graph and recursively cut it up.",
            "So this is the Grand Canal datasets, again courtesy of UW guys, and solve each of the small pieces.",
            "Put some together, you know, solve them, put them together, and then finally put the whole thing together.",
            "So that's sort of a an alternative to the bundler way of.",
            "Of adding one frame at a time or one image at a time.",
            "So so.",
            "So we did some things in computer."
        ],
        [
            "Vision in robotics.",
            "Alot of people are starting to adopt factor graphs, sort of computational substrate.",
            "So here's some work by Tim Barfoot at the University of Washington.",
            "They do a lot of space robotics so they have this Mars yard somewhere in Canada.",
            "And they have a Rover that makes sort of explorations in this Mars Yard, and they they use GSM for example to to solve their Maps.",
            "But I want to highlight the work of my former student."
        ],
        [
            "Michael Kiss so the.",
            "Let me let me just show you this this when Michael was graduating this robotics data set was still a little bit challenging.",
            "Now it's sort of a trivial data set.",
            "But but the he Michael is inspired by the fact that you know if you have a factor graph and you are robot and you're building this factor graph, it grows and grows and grows and keeps growing and you have to solve this entire factor graph every time.",
            "And the question was can we do this?",
            "Incrementally, can we reuse the results from before to do less work?",
            "And in fact there is incremental factorization methods in linear algebra that Michael applied in his thesis, so here."
        ],
        [
            "Michael and this is the main idea behind this.",
            "You have an upper triangular matrix and if you add a couple of constraints or factors, it turns out that the only things that will change when you put these factors into R is a small piece at the very bottom.",
            "OK, and so Michael took this idea and published incremental smoothing and mapping back in 2008.",
            "And that's been quite successful, but it's still use this matrix paradigm.",
            "So I was still finding out these connections between graphs and matrices, and I couldn't convince Michael it was only when he got to MIT.",
            "So so Michael is a research scientist for John Leonard at MIT now, but just accepted a position at Carnegie Mellon's assistant research professor.",
            "So he's going there.",
            "The you know it's only after you got a mighty that I convinced him.",
            "Let's look at what this incremental factorization means in graphs.",
            "OK, now it turns out that if you take a large factor graph.",
            "And factorize it into a Bayes network that Bayes network has a very definite structure.",
            "You can discover the cliques in that base network.",
            "And you can create a tree of cliques, and that's called a clique tree and in machine learning is actually known as junction tree.",
            "So what happens is really you're creating a junction tree when you solve this.",
            "And as you do this incrementally, you can edit this junction tree so that only the small parts you just rearrange it a little bit, and so with very little computation you can continue to keep your solution alive, so allow show and movie.",
            "Of this junction tree, and this is literally what goes on in our code you will see a snapshot of our code as it is doing, solving an incremental smoothing and mapping problem.",
            "OK, the data set is courtesy of adults and at from Michigan."
        ],
        [
            "So synthetic data set, so here's the tree.",
            "Right and only the Reds clicks at the very top in an exploration scenario will be re computed.",
            "These great leaks are all conditions that are pointing down towards the pass and are never to be changed.",
            "OK, it's only also when you close a loop.",
            "There might be some flash of red when a lot of variables have to be re illuminated, but most of the time.",
            "I say 99% of the time, you know when you're not closing loops, things are just constant time.",
            "It's pretty amazing.",
            "So we just published last year in GRR and this is sort of a collaboration with with MIT, but it's built into into GT Sam.",
            "So again, after awhile it becomes a little bit unwieldy, but this is simply dumping the data structures from GSM into a graph is visualization and I'm showing them on the screen.",
            "And I'm really proud of this, because this is, I think, the state of the art in sort of incremental inference in graphical models, OK?",
            "Alright.",
            "It turns out that Michael when he."
        ],
        [
            "MIT created a C++ implementation of I Sam."
        ],
        [
            "And it actually has a lot of impact, so so one of the sort of scanner mouse which actually does slam as you scan over a document, uses I Sam inside.",
            "OK, there is these little spheres MIT spheres that are up in the space station that are using ICEM to help localize themselves, and one of the cool."
        ],
        [
            "Projects that Michael did with, in conjunction with the University of Michigan is to do ship Hull inspection for the Navy, so they have these small underwater Rovers.",
            "And they map things like the bottom of."
        ],
        [
            "Aircraft carriers, so I'll show this movie from Ryan uses at the University of Michigan, but this is collaboration with Michael, which is, which is why they are using ICEM inside.",
            "One of the very cool things about this movie is that this has been mapped a couple of times.",
            "This the underside of this ship and the second time the Rover goes around it goes up from under the surface has a little Periscope and does the loop closures by doing scene recognition based on the previous.",
            "The patterns on the side of the ship with the Periscope isn't that amazing.",
            "Cool, you know.",
            "So this is very recent.",
            "I'm really showing you sort of cutting edge of what goes on in robotics here and so this is from August 2013.",
            "Which is last month.",
            "So.",
            "Alright, I'll just show you this a little bit.",
            "You still have the problem that you're creating these very long trajectories as you go, and so you know trajectory is keep growing up in complexity.",
            "You could argue that the environment stays is constant in complexity here.",
            "This room is static.",
            "Once you've seen everything, it stays the same.",
            "OK, there is dynamic objects etc, but but what is actually growing complexity constantly is if you take a camera.",
            "Through this environment many, many times, the complexity of that trajectory grows unboundedly, so one of the things that Michael work Tom is to enable long-term visual mapping.",
            "So this is inspired by."
        ],
        [
            "His advisor at MIT, John Leonard, who is really interested in this lifelong mapping where they think datasets of this is very cool.",
            "Building the status center at MIT.",
            "I hear it's leaky as hell though, so don't be too jealous.",
            "You know it's Gary likes, likes, looks and not necessarily.",
            "Waterproof roofs.",
            "But they took a data set here over a period of six months, traveled 11 kilometers and have 630,000 frames that they want to.",
            "Integrates."
        ],
        [
            "So here Michael John used I Sam to create.",
            "A pose graph, so graph on the poses.",
            "The very cool thing here is that they actually go up and down with the elevator, but they as a closed loops later even though they don't see anything in the elevator except for their accelerometer readings, they can build a consistent 3D model nevertheless.",
            "But they they use a technique where they.",
            "They don't add every pause into the graph.",
            "Instead, if the pause is close enough to oppose that you have already seen, they just add relative constraints between pauses that they've already seen, so that's what they call a reduced post graph, and so the result of all this is a 10th floor map of the status."
        ],
        [
            "Center right, I think they couldn't get into the bigger basement here.",
            "They probably didn't have permissions to go into the loading dock, but here this is a status center map, so this is a six month 11 kilometer data set.",
            "Ryan used.",
            "This is at the University of Michigan and here this robot with a 3D lighter.",
            "And he did 25 mapping runs over 15 months.",
            "And logged about 150."
        ],
        [
            "Yes, so he has a sort of competing reduced post graph method.",
            "Here is a movie of what's happening, so this is the factor graph as it is growing overtime.",
            "So it's 25 mapping sessions.",
            "And he uses a child, you tree approximation, which to two clicks in this graph to get a much lower complexity graph that can be kept sort of in reasonable computational time.",
            "As you do, it is very long term mapping efforts so that work has appeared at a workshop, but it's actually only going to appear at Iris in Japan this fall.",
            "So again, this is very novel work.",
            "This is not my work, they use this factor graph, so I just wanted to show you what people are doing with factor graphs.",
            "Cool."
        ],
        [
            "So I do want to tell you about one last idea that we developed in the last couple of years and is more focused on computer vision.",
            "This is work by my student young DM.",
            "Where we we will be first developed in robotics and applied it to computer vision.",
            "So let me let me show you this.",
            "My hope is that I'm going to demystify one last linear algebra technique that you've heard about and never really wanted to understand.",
            "You know, if your linear algebra class was any like mine, it could turn you off to linear algebra for the rest of your life, and it nearly did for me.",
            "And I only discovered later in life how cool all this stuff was, but I had a very old professor and he was not interested in actually making us excited about this stuff.",
            "Plus it he used may tricias."
        ],
        [
            "So here is a graph OK. Anne, it's of a city, and so take a moment to tell your neighbor which city this is.",
            "Meet your neighbor.",
            "Tell your neighbor which city this is.",
            "Oh, come on, talk talk.",
            "Oh hint hint, it's not Paris.",
            "It's not London.",
            "OK. All right outer hint.",
            "This is a thing called the Forbidden City.",
            "Alright, OK good, so this is actually a sort of an open street map.",
            "We got it from Openstreetmap and build a factor graph.",
            "It it it's Beijing.",
            "And of course, Beijing doesn't have an Eiffel Tower.",
            "But if it had an Eiffel Tower."
        ],
        [
            "Would be very very useful.",
            "Because you see an Eiffel Tower has this nice property that you can see it from many places.",
            "An if you're lost in the city and you look around, you know if you see the Eiffel Tower like at least you're oriented in the world, right?",
            "So it provides very strong orientation constraints.",
            "Unfortunately, it is very useful property for mapping and localization, and you know Google might be interested in mapping Beijing.",
            "Right is also detrimental to gas.",
            "Gas is idea of eliminating one variable at a time and the reason is that once you eliminate a variable, you create a clique.",
            "And that click is the size of the separator.",
            "So now you create a new factor, disconnected all these variables that were that separator and the nasty thing about Eiffel Towers.",
            "So I called this the Eiffel Tower problem.",
            "Is that it is connected to many many many variables in your graph and that will basically make elimination grind to a halt.",
            "So either you eliminate the Avatar last, which you can do, or you come up with some other technique.",
            "This is by the way, Eiffel Tower is not to be taken literally.",
            "If you do structure for motion with a camera that has a single calibration, OK, that collaboration is connected to all the camera and all the measurements in the graph.",
            "And so when you eliminate those calibration parameters you have an Eiffel Tower problem on your hand, right?",
            "So so elimination is a direct method.",
            "It does a direct factorization of your problem so."
        ],
        [
            "So another ways to do it iteratively to use conjugate gradient, say to serve down the gradient of your objective function, but that can be very slow to converge.",
            "So and why is it slow to converge?",
            "Well, because this objective function and it can be long and narrow, which by the way, the narrowness of it is the largest eigenvalue divided by the smallest eigenvalue is called the condition number.",
            "OK, so the game is to have an objective function that has small condition number, IE the best objective function is spherical and for which an iterative method converges in one step.",
            "So we decided to look into using direct methods."
        ],
        [
            "Subgraphs this is inspired by the graphical nature of this problem.",
            "We took Beijing.",
            "We started a little spanning tree, started at the Forbidden City as the root, and ran a spanning tree all around Beijing.",
            "This is a tree by the way.",
            "This is the matrix that corresponds to this tree, but you wouldn't know it's a tree.",
            "From looking at this OK, you can only see that you know when you look at the graph in detail, But it turns out that trees with an elimination algorithm are trivial.",
            "It's like a knife through butter.",
            "OK, it's order N in terms of solving it, so we take this whole problem, which is fairly complex and dense because of all these loop closures.",
            "And we solve.",
            "We take the spanning tree.",
            "We solve that using the direct method, but then use it as a preconditioner for the hard part that's left in the hard part.",
            "Or all the loop closures.",
            "OK, and the effect of this of you is taking a sub graph which communicates globally throughout the graph.",
            "Is that all the remaining variables?",
            "OK, so all the remaining constraints are actually fairly uncorrelated once you take out this global information, what happen?"
        ],
        [
            "This is that you take a very long and skinny with objective function with small large condition number and turn it into something that's almost vertical and that is what preconditioning is.",
            "OK, it's just reparametrization of your variables using constraints that are long term.",
            "Global.",
            "So I asked young Young to create an animation to make that really visible.",
            "So here is that."
        ],
        [
            "Same factor graph of that little robot that could.",
            "And this is the solution of all the variables.",
            "I pinned it down in the middle.",
            "I just gave a hard constraint in the middle and what I asked young man to do is take the largest eigenvector mean associate with the largest eigenvalue and put a sine wave to it.",
            "So now you can see that variables.",
            "Here and here are very correlated.",
            "If this moves up that goes down and vice versa, and that's detrimental to iterative methods, OK?",
            "But if."
        ],
        [
            "Take a spanning tree.",
            "And solve it.",
            "It's really easy to solve.",
            "What you see is that this correlation is also there in the spanning tree.",
            "In fact, this long long range correlation is almost exactly the same correlation as you got for the entire problem.",
            "So what you do is you take the entire problem, you solve the spanning tree an you take that correlation out of the problem, so you precondition.",
            "So what we're doing is repair and tries.",
            "In terms of the difference to the solution from this spanning tree and what you get now."
        ],
        [
            "When you is a condition number that is much much smaller OK and there is almost no correlation left in this graph.",
            "So that's the intuition behind preconditioning.",
            "So we applied this to large scale structure for motion problems."
        ],
        [
            "At I CV 2011, we were briefly the fastest circular motion method out there.",
            "But then Samir Agrawal and their gene and the geniuses at Google outdid us.",
            "But here is a sort of intuition for structure from motion, so here's the Chicago data set.",
            "Again, this actually is a solution of the sub graph.",
            "That young young creates, so it's sort of a fuzzy version of Chicago.",
            "Most of the information and most of the correlation is there, though, so if you use this as a preconditioner for the full problem again, it becomes much, much better conditions."
        ],
        [
            "Same on the famous Notre Dame datasets, from from Noah.",
            "Or in some ear."
        ],
        [
            "Venice datasets, so you get these fuzzy versions which have most like 99% of the information.",
            "Is there already.",
            "Everything else is sort of topping off.",
            "And topping off is easily done using conjugate gradient.",
            "So if you look at the condition numbers."
        ],
        [
            "Of a couple of really good and large datasets, this is from RCB paper.",
            "You will see that this condition numbers decrease drastically."
        ],
        [
            "Good so so factor graphs are cool.",
            "Gauss was a genius and you already know the algorithm.",
            "It fails when you have Eiffel Towers where Eiffel Tower is a more generic term than just Eiffel Tower.",
            "But but you can then use these elimination methods as preconditioners.",
            "Some future directions and I'll stop.",
            "We're working we're running GSM is downloadable for free.",
            "If you're wondering about the license, it's not GPL, it's it's BSD you can do with it whatever you want, OK, but internally we're running with GSM 3."
        ],
        [
            "Which is brought to you by DARPA, which is a defense agency in.",
            "In the US, and they want something that's really fast and can run in embedded mode, and we're doing they're giving US data sets that I can talk to you about, but are very, very challenging.",
            "OK with lots of different sensors, and so I think we published a plug and play sensor.",
            "Paradigm for which factor graphs are actually ideally suited and our play is very interested.",
            "And one of the things that they're paying us to do is actually make GTM faster, more reliable, more robust, and so it will be a fully multithreaded.",
            "He will do all these subtrees in parallel on multiple cores and still have the Matlab toolbox etc, so.",
            "So again, there is.",
            "You know there's some ear has a solver for structure from motion, which is awesome.",
            "OK, which is called Sarah's.",
            "OK, this is the planet from gaseous planet.",
            "But we do.",
            "We do not only search for motion, but also submitting a mapping and even sudokus, alright?",
            "That's one of the things that."
        ],
        [
            "That DARPA, trosa does, is is the problem of very long term navigation.",
            "So you know what if you would fly for seven days without GPS?",
            "OK, one of the things that happens is that you lose your numerical accuracy.",
            "There is so much uncertainty at the end of this long Markov chain.",
            "If you don't do any loop closures that you everything blows up, and so we're looking into backbone methods, sort of a.",
            "A mix between direct and preconditioning to get rid of that blow up, and I think there's a lot of promise here for robotics.",
            "Another is."
        ],
        [
            "Can we completely eliminate the front end?",
            "All this correspondence hunting in structure for motion and robotics is one of the things that make it problematic.",
            "An idea of adults and is.",
            "Well, who needs correspondence if instead of using Gaussian densities and quadratic errors, you use robust error metrics, maybe you don't even need to have a front end, you just throw all your constraints in in a big soup and whether they are correct or not, you'll have the optimizer figured that out, so he used that small Intel data set that I showed before.",
            "And here is the standard Gaussian noise model an if you have outliers here, 100 errors, it goes, it goes to hell.",
            "But if you use robust error metrics like called M estimators, you're tolerant and you just don't care.",
            "And then finally something that I'm looking at with my students and postdocs."
        ],
        [
            "Now is also how to do distributed mapping over multiple robots.",
            "Actually, this is not the final slide.",
            "Here is a final slide.",
            "We've done a lot of mapping in robots and with cameras, but we're not really controlling these robots as they fly or drive or."
        ],
        [
            "Swim.",
            "And it turns out that there is a paradigm in control called model predictive control which is really trajectory optimization and I was looking at that.",
            "I'm saying, hey, that's interesting.",
            "GT Sam is very good at optimizing trajectories, so could we role in model predictive control into GSM in a seamless 11 factor graph based framework?",
            "And so that's that's the future for me is.",
            "So how can we roll in model predicted control into the whole thing?",
            "I guess I will."
        ],
        [
            "Stop there, alright thank you.",
            "Yeah, I've two question actually.",
            "One is from your last slide here, something with the geometric with Lee algebra.",
            "And do you usually algebra?",
            "Yes, I didn't even mention this but but but yes, I'm sort of just like Tom.",
            "Actually a little bit obsessed with Lee Groups and Lee Algebra.",
            "And so GD Sam.",
            "Can take actually can take any manifold object and we're doing optimization on.",
            "For Lee groups the Li algebra, but in general the tangent plane of these of these spaces.",
            "So yeah, Lee algebra is sort of core built into GTA San.",
            "Is it?",
            "Or a covariance estimation?",
            "Or is there any?",
            "Why are you interested actually?",
            "Oh, the reason is, you know, solely algebra asserted the nicest way of taking care of things that like in rotation matrix has 9 numbers in it.",
            "But that's really it is only three degrees freedom.",
            "So you look at this as a League group and then do optimization on the algebra at anytime is simply simply the way you should do it, and you get covariances on the Lee Group on the algebra actually so.",
            "You know it's.",
            "Does it give any advantages?",
            "It's the right thing to do, that's you know.",
            "Also, the lease Ledger lies presenting better.",
            "The others.",
            "Say all this errors all the covariances.",
            "I'm not sure whether it provides any real great advantages except getting rid of over parameterizations, which people tend to do if sort of the first thing to try is overparameterized and optimizing that, and then you get.",
            "Sub optimal solutions.",
            "That's right, but I'll be happy to talk a lot about Lee groups and Liagre offline.",
            "My second question is, you talk about Mahatma.",
            "You organize your graphs.",
            "But yeah, for organizing your graphs with different methods, do you?",
            "My first check how your problems looks like and then you reorganize the graph or you start different methods and see which one is better.",
            "Um?",
            "So the time comes with this, you know, heuristics built in, like you know, cutting grass into pieces or approximate minimum degree and they work for a large variety of problems.",
            "But it's true that you can beat NP completeness by taking domain knowledge and building that into your ordering heuristics, and so for example, if there are structural motion people in the room.",
            "A big trick that's all that's even in hardly in system book is the sure compliment you first get rid of all your landmarks by doing a sure compliment on this.",
            "And it turns out OK.",
            "The way I view the sure compliment is it simply an elimination choice you eliminate first your landmarks and then your cameras and you automatically recover the sure compliment so there could be better orderings.",
            "Actually then justice sure compliment ordering.",
            "So so yeah, trick that you can play papers that still need to be written.",
            "Or if you have domain knowledge about a very specific problem.",
            "Think about what the best ordering is for these problems and creates orderings and optimization schemes tailor made for your problem.",
            "For subgraph for preconditioning, does it matter which choice of spanning tree you use?",
            "Is?",
            "There are some spanning trees better than others?",
            "Yeah, yeah, that's a great question.",
            "It turns out that you know we.",
            "I truly invented this.",
            "OK, I truly invented this idea of using a sub graph as a preconditioner, but then I discovered that in the last 10 years.",
            "In the theory community in computer science, they've been looking at something called support graph theory, where they have exactly the same idea.",
            "OK, so like, damn, you know I could have gotten some prize or something, but no, no.",
            "But it turns out that the condition numbers of these original problems live up here, and when you throw in a subtree, it goes down very very quickly.",
            "Now you could go down even deeper, and the theory people are interested in.",
            "So what is the optimal sub graph there?",
            "And they came up in something called low stretch spanning trees.",
            "Low stretches is a proxy for how good the spanning tree is.",
            "Really, how you know how good it is at communicating information through the graph.",
            "And so young young uses loss thread.",
            "This idea of low stretch spanning trees in his ICD paper.",
            "So he does assure compliment Rick finds a low stretch spanning tree in the camera matrix or the camera graph and then adds a little bit of edges to the points back.",
            "And now he has a complete spanning tree.",
            "Cycle.",
            "Exactly exactly so.",
            "So when you have a cycle, long cycles are bad.",
            "They stretch the graph out.",
            "That's right exactly.",
            "Yeah, great intuition.",
            "Thank you.",
            "Yes, I hope so.",
            "Factories are cool.",
            "Download GT Sam alright."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, well thank you for inviting me.",
                    "label": 0
                },
                {
                    "sent": "I'm very honored to give this talk.",
                    "label": 0
                },
                {
                    "sent": "So before I start, I'm sure there's.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Couple of Masters student in the room that are looking where to do their pH D an.",
                    "label": 0
                },
                {
                    "sent": "We started a PhD program in Robotics a couple of years ago in Georgia Tech and applications are due December 15.",
                    "label": 0
                },
                {
                    "sent": "OK, so you're all very welcome.",
                    "label": 0
                },
                {
                    "sent": "We actually just graduated our first couple of students and one of our students.",
                    "label": 0
                },
                {
                    "sent": "My check Mark just became assistant professor at University of Washington, so.",
                    "label": 0
                },
                {
                    "sent": "It's an exciting program, so if you want to become faculty in North America, this is one of the ways to do it, OK?",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                },
                {
                    "sent": "Well, so actually during my graduate.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Karere I did something on the side which which which is Monte Carlo localization which is applying a particle filter too.",
                    "label": 1
                },
                {
                    "sent": "Robot localization, I really just took the work from Isard and Blake and applied it to robot localization and it turns out that this is my most impactful piece of work ever and I'll tell you why, OK, any undergrad can program this up in 10 minutes.",
                    "label": 0
                },
                {
                    "sent": "OK so here is 1 lesson I learned is you know nobody looks at my PhD teases actually, but this thing is so simple and so impactful precisely because it's so simple.",
                    "label": 0
                },
                {
                    "sent": "So here's a lesson for aspiring grad students.",
                    "label": 0
                },
                {
                    "sent": "Don't make your stuff too complicated, you know if it's really easy to implement, it will have a lot of impact.",
                    "label": 0
                },
                {
                    "sent": "So I started out in robotics and so this work also led through another student in Sebastian Translab.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "2 running particle filters an entire trajectory's, so there's a problem in robotics called simultaneous localization and mapping where you were not only trying to localize the robot, but at the same time build a map of the environment, and so if you run a particle filter, not just some location, but on the entire trajectory, you can optimize the map for each particle and see how good it is, and that's in the weight of the particle, so that's the idea behind fast slam.",
                    "label": 1
                },
                {
                    "sent": "Which which which is still influential in robotics these days.",
                    "label": 0
                },
                {
                    "sent": "Now that's all with two delays words.",
                    "label": 0
                },
                {
                    "sent": "So the state of the art back then was the sick laser range finders that have 2D.",
                    "label": 0
                },
                {
                    "sent": "You know, given occurs enough to the laser points and I wanted to show this video from Ryan Eustice.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Who kindly shared a lot of his work with me that I'll show in this talk.",
                    "label": 0
                },
                {
                    "sent": "So this is the campus of.",
                    "label": 0
                },
                {
                    "sent": "University of Michigan.",
                    "label": 0
                },
                {
                    "sent": "But created with 3D Lidar point clouds.",
                    "label": 1
                },
                {
                    "sent": "OK, so this is a robot going around and creating point clouds from 3D LIDAR measurements.",
                    "label": 0
                },
                {
                    "sent": "So that's that's robot mapping in 2013 vastly large.",
                    "label": 0
                },
                {
                    "sent": "Clouds of 3D points.",
                    "label": 0
                },
                {
                    "sent": "But you don't need lasers to do that, actually, so one of the very cool things that happened in computer vision in the last 10 years is that the ideas that were developed in the 80s and 90s on 3D reconstruction structure from motion really took off in a new way in large part.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Do the work of Noah Snavely at University of Washington.",
                    "label": 0
                },
                {
                    "sent": "Steve side so so noise now at Cornell actually and photo tourism and Photosynth are sort of direct.",
                    "label": 0
                },
                {
                    "sent": "Results of his work and he's famous for doing things like.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You Google for images safe of Dubrovnik, so these are his images is his work so just want to stress that and you get maybe 10,000 images back.",
                    "label": 0
                },
                {
                    "sent": "Then the genius of number was two very robustly.",
                    "label": 0
                },
                {
                    "sent": "Do the correspondence of wide baseline correspondence between images.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Build a 3D point cloud completely from images.",
                    "label": 0
                },
                {
                    "sent": "Which which is, you know, as impressive as this 3D Lidar point cloud, right?",
                    "label": 0
                },
                {
                    "sent": "And so each of these in frustums here is one of the cameras, not the images, that Noah took.",
                    "label": 0
                },
                {
                    "sent": "These are all images taken by tourists while walking around in Dubrovnik, and so that's you know, amazingly, inspiring work.",
                    "label": 0
                },
                {
                    "sent": "But it's just 3D.",
                    "label": 0
                },
                {
                    "sent": "OK, so when I came to Georgia Tech, I got together with a student grant Schindler.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we decided to sort of bridge this towards 4 dimensional mapping.",
                    "label": 0
                },
                {
                    "sent": "So the idea was that we took a collection of historical images.",
                    "label": 0
                },
                {
                    "sent": "In this case is from Atlanta.",
                    "label": 0
                },
                {
                    "sent": "And in this case, we did the correspondence manually, but we could build a 3D model of Atlanta with little time slider at the bottom, and so we could scrub through time and go and see the city actually appear and disappear as we scrub through time.",
                    "label": 0
                },
                {
                    "sent": "So Atlanta is pretty cool, because in fact it was burned to the ground by Sherman in sort of the 1860s at the end of the Civil War.",
                    "label": 0
                },
                {
                    "sent": "So you can really see the city which is now 5.4 million people.",
                    "label": 0
                },
                {
                    "sent": "Sort of rise up from nothing.",
                    "label": 0
                },
                {
                    "sent": "Now grant.",
                    "label": 0
                },
                {
                    "sent": "Moved out.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And he did something really cool.",
                    "label": 0
                },
                {
                    "sent": "One of the side projects.",
                    "label": 0
                },
                {
                    "sent": "Again, side projects are really important for grad students.",
                    "label": 0
                },
                {
                    "sent": "Is this app he made is called Tri Mentionable, which is a 3D scanning app for the phone, so he's now doing that, but I told him, look, you know before you graduate and go off and do your iPhone app.",
                    "label": 0
                },
                {
                    "sent": "Nobody cares about Atlanta, right?",
                    "label": 0
                },
                {
                    "sent": "Atlanta, it's you know you have Coca Cola and you have Georgia Tech and you know.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So first to New York and then you can graduate and it has to be fully automatic or manual clicking on building.",
                    "label": 0
                },
                {
                    "sent": "So inspired by the work of Noah etc.",
                    "label": 0
                },
                {
                    "sent": "He did this fully, automatically segmented out the buildings, did his analysis of time, which you can do by gross occlusions.",
                    "label": 0
                },
                {
                    "sent": "I could build a 4D browser of lohrmann.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Atom.",
                    "label": 0
                },
                {
                    "sent": "So, so here's a couple of images.",
                    "label": 0
                },
                {
                    "sent": "We have a lot of images from the 1920s, nineteen 30s, and also a lot near, you know, when.",
                    "label": 0
                },
                {
                    "sent": "Granted this work.",
                    "label": 0
                },
                {
                    "sent": "Turns out it's quite hard to find images without rights of New York.",
                    "label": 0
                },
                {
                    "sent": "So it's in between that.",
                    "label": 0
                },
                {
                    "sent": "There is also a reason why it's lower Manhattan.",
                    "label": 0
                },
                {
                    "sent": "I don't know whether people here ever visited New York.",
                    "label": 0
                },
                {
                    "sent": "Probably half of you definitely did so, so everybody visits the Statue of Liberty in New York, right?",
                    "label": 0
                },
                {
                    "sent": "That's one of the big tourist attractions, so they then take the boat back to Battery Park.",
                    "label": 0
                },
                {
                    "sent": "And on the way they take pictures of lower Manhattan.",
                    "label": 0
                },
                {
                    "sent": "So that's why there's a lot of them, even back in the 1920s, nineteen 30s.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright so so, but I'm I'm here so this is the inspiration.",
                    "label": 0
                },
                {
                    "sent": "You know this large scale 3D mapping, large scale 3D reconstruction, but I'm here to tell you actually about my secret weapon.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Which I've developed.",
                    "label": 0
                },
                {
                    "sent": "Try to understand in the last 10 years so there's ten years of work of me very slowly understanding connections between different and disparate subfields of engineering, and I'm going to tell it all.",
                    "label": 0
                },
                {
                    "sent": "OK, so you don't have to go through this 10 years of slogging through the connections.",
                    "label": 0
                },
                {
                    "sent": "It's about factor graphs and I'll make the connection between factor graphs.",
                    "label": 1
                },
                {
                    "sent": "I'll tell you what they are and then I'll make connections with sparse linear algebra, and then I'll give you sort of a compendium of things that we did once we understood that connection, the last bit is a new preconditioning method that we applied to structure from motion and also catch some future directions.",
                    "label": 0
                },
                {
                    "sent": "But before I do, I.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Acknowledge the people that made all this possible, so there's a bunch of my students and postdocs and some alumni that I singled out here that have contributed heavily to this talk.",
                    "label": 0
                },
                {
                    "sent": "And there's also a number of people from MIT, Michigan, Toronto and Freiburg that contributed movies and snippets of their work.",
                    "label": 0
                },
                {
                    "sent": "That I'm going to show off, so not everything that I'm showing here is our work.",
                    "label": 0
                },
                {
                    "sent": "It's also work that was inspired by the things that we that we brought out.",
                    "label": 0
                },
                {
                    "sent": "Of course, you know we're sponsored by various funding agencies, and I'll talk a little bit about that as well.",
                    "label": 0
                },
                {
                    "sent": "Well, start with something very, very boring.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which is Boolean satisfiability.",
                    "label": 0
                },
                {
                    "sent": "You're all envisioned, probably because you know you didn't like that stuff.",
                    "label": 0
                },
                {
                    "sent": "I mean, look, you know, come on in, it's boring, right?",
                    "label": 0
                },
                {
                    "sent": "It's a formula it you don't even know what's going on, and so it's what is going on is there is a bunch of variables and you have to give an assignment true or false for each of these variables to make this Boolean formula through?",
                    "label": 0
                },
                {
                    "sent": "Well, it turns out it's actually much more exciting than it looks.",
                    "label": 0
                },
                {
                    "sent": "So here's a graph, OK?",
                    "label": 0
                },
                {
                    "sent": "And all of a sudden you see that there is actually 5 variables.",
                    "label": 0
                },
                {
                    "sent": "It was not very easy to figure that out from that.",
                    "label": 0
                },
                {
                    "sent": "And each of these factor nodes is a Boolean formula and it is connected only to the variables that play in that formula.",
                    "label": 0
                },
                {
                    "sent": "Alright, so you you have you have variables.",
                    "label": 0
                },
                {
                    "sent": "You have factors and this is a factor graph, right?",
                    "label": 0
                },
                {
                    "sent": "And this gives you a graphical representation of what the problem is that you're trying to solve.",
                    "label": 0
                },
                {
                    "sent": "OK, so so another you know a subbranch from spound.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Artificial intelligence is actually constraint satisfaction.",
                    "label": 1
                },
                {
                    "sent": "It's also a big topic in graph theory, so so for example, the graph coloring problem is if you have a bunch of provinces in a country.",
                    "label": 0
                },
                {
                    "sent": "In this case Japan.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And you would like to color them such that no province neighboring province has the same color.",
                    "label": 0
                },
                {
                    "sent": "You would create variables and then these factors here would say, well, you're not supposed to give any of these provinces the same color.",
                    "label": 0
                },
                {
                    "sent": "Again, the problem is very apparent.",
                    "label": 0
                },
                {
                    "sent": "The structure of the problem becomes very apparent once you phrase it as a factor graph.",
                    "label": 0
                },
                {
                    "sent": "So this is discrete and the factors are also discrete, sore one or zero, it's allowed or it's not allowed.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In graphical models, I'm very I'm very sure that all of you are familiar with Bayes networks, so Bayes networks are these graphical models is the most famous graphical model where now the variables are typically discreet as well.",
                    "label": 1
                },
                {
                    "sent": "But these these these variables have conditional probability densities on them or distributions, meaning this is now continuous as a probability, and so it's actually trivial.",
                    "label": 0
                },
                {
                    "sent": "To convert this to this different graphical model, which is a factor graph for now, each of these, for example, this is the probability of smoking or non smoking.",
                    "label": 1
                },
                {
                    "sent": "This is the famous Asian Network.",
                    "label": 0
                },
                {
                    "sent": "This factor would say, well you know 5050 for smoking.",
                    "label": 0
                },
                {
                    "sent": "OK so it's quite easy to convert any base network or by the way if you're into segmentation or image image denoising, any mark of random field is better represented as a factor graph.",
                    "label": 0
                },
                {
                    "sent": "Then as a market random field OK.",
                    "label": 0
                },
                {
                    "sent": "So this is still discrete variables, but in robotics, an instructive promotion.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What we have is continuous variables.",
                    "label": 0
                },
                {
                    "sent": "So now we have continuous variables for example.",
                    "label": 0
                },
                {
                    "sent": "So here is a Markov chain which is the location of the robot at time zero time.",
                    "label": 0
                },
                {
                    "sent": "One time two and they are linked by these probabilistic constraints which are derived from odometry.",
                    "label": 0
                },
                {
                    "sent": "The robot moves, it gets a measurement, it's a noisy measurement.",
                    "label": 0
                },
                {
                    "sent": "So here is a probabilistic constraint between zero and one at the same time the robot sees a bunch of landmarks and every landmark is unknown.",
                    "label": 0
                },
                {
                    "sent": "We don't know where it is, but there's a.",
                    "label": 0
                },
                {
                    "sent": "Every measurement induces a probabilistic constraint between the pose and the landmark right?",
                    "label": 0
                },
                {
                    "sent": "Now, this is still fairly abstract.",
                    "label": 0
                },
                {
                    "sent": "Let me show you a small example.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's a small example of a little robot.",
                    "label": 0
                },
                {
                    "sent": "Which is kind of cute, right?",
                    "label": 0
                },
                {
                    "sent": "It's like a little spider feeling its way, and so this is a fairly old graphic from back when my daughter was still excited by the stuff I did.",
                    "label": 0
                },
                {
                    "sent": "You know she's 14 now.",
                    "label": 0
                },
                {
                    "sent": "It's there's no all hope is lost.",
                    "label": 0
                },
                {
                    "sent": "Well, you know we saw this this little robot.",
                    "label": 0
                },
                {
                    "sent": "The idea is well, we would like to know where the rabbit was and very all the things that are that it saw again.",
                    "label": 0
                },
                {
                    "sent": "You will see that factor graphs when you show the graph.",
                    "label": 1
                },
                {
                    "sent": "The structure of the problem becomes completely.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Parents.",
                    "label": 0
                },
                {
                    "sent": "So here is a factor graph associated with this problem.",
                    "label": 1
                },
                {
                    "sent": "So we have the the Markov chain backbone and then each landmark is seen a number of times from several locations and for example this one.",
                    "label": 0
                },
                {
                    "sent": "We already know that this one is not going to be determined because it's only seen from one location, but here where you have all these dense connections will get very good information on the trajectory on the landmarks.",
                    "label": 0
                },
                {
                    "sent": "So you can see the structure of the problem.",
                    "label": 0
                },
                {
                    "sent": "OK, these are these are continuous and non linear by the way so.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So each the densities that are induced by solving these factor graph.",
                    "label": 1
                },
                {
                    "sent": "Are typically non linear and so we linearize in a nonlinear optimization fashion.",
                    "label": 1
                },
                {
                    "sent": "Al talk about about the mostly linear factor graphs, but you should know that this goes into a big nonlinear Levenberg Marquardt style optimization.",
                    "label": 0
                },
                {
                    "sent": "And if I.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Structure from motion.",
                    "label": 0
                },
                {
                    "sent": "This is a movie made by by my student, young John John.",
                    "label": 0
                },
                {
                    "sent": "This is Chicago and these are actually images taken by Grand, Junior and so you see this is sort of the graph of connectivity between all the 3D points and the cameras, but really it's also the structure of the factor graph, right?",
                    "label": 0
                },
                {
                    "sent": "Good so OK, so so at least I hope that I convinced you now that factor graphs are very cool way to look at the structure of the problem and see in one glance.",
                    "label": 0
                },
                {
                    "sent": "Oh that's interesting.",
                    "label": 0
                },
                {
                    "sent": "That's the information I have.",
                    "label": 0
                },
                {
                    "sent": "Those are the connections.",
                    "label": 0
                },
                {
                    "sent": "And also maybe this is sort of the difficulty of the problem if very dense vector graph might be a very difficult problem.",
                    "label": 0
                },
                {
                    "sent": "Very sparse linear like structure is easy and that would be a great intuition if you have that intuition.",
                    "label": 0
                },
                {
                    "sent": "In fact, I will.",
                    "label": 0
                },
                {
                    "sent": "I will show you.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "How to compute and do inference in factor graphs?",
                    "label": 1
                },
                {
                    "sent": "And I'll also show.",
                    "label": 0
                },
                {
                    "sent": "Hopefully the connection with linear algebra and so you already know this algorithm actually from secondary school.",
                    "label": 0
                },
                {
                    "sent": "In Britain, but 85% of you is not from Britain anyway, so so you know the.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The thing before high school, probably you learn about this algorithm First United Connection with with the The boring Old way to do structure from motion and slam is you calculate this large sparse Jacobian matrix, which is the derivative of each of your constraints with respect to each of your variables.",
                    "label": 0
                },
                {
                    "sent": "It's a large sparse matrix, but the structure of that matrix is exactly the factor graph.",
                    "label": 0
                },
                {
                    "sent": "Every factor here is a row in the matrix.",
                    "label": 0
                },
                {
                    "sent": "Every variable here is a column in the matrix.",
                    "label": 0
                },
                {
                    "sent": "Alright, so so this one I put you is way more intuitive than this one.",
                    "label": 0
                },
                {
                    "sent": "Right now, but we have to.",
                    "label": 0
                },
                {
                    "sent": "We have to pay homage and.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You know how do you normally solve these large linear systems?",
                    "label": 0
                },
                {
                    "sent": "Well, what you do is you take this big curbing a.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And you form what is known as the system of normal equations and you solve it by inverting the Hessian A transpose A.",
                    "label": 0
                },
                {
                    "sent": "But nobody does that by inversion.",
                    "label": 0
                },
                {
                    "sent": "You do it by factoring the matrix.",
                    "label": 0
                },
                {
                    "sent": "So this big hashing, which is a square symmetric matrix, is factored into an upper triangular matrix R. And once you have that matrix, this is something very crucial.",
                    "label": 0
                },
                {
                    "sent": "You can do back substitution on your variables and you have the solution.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is something to understand that once you are here, you have solved the problem and you can go to the next nonlinear iteration and so the only thing we need to know is how to factor this into that.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You know, if you ask a linear algebra person, how do you do that?",
                    "label": 0
                },
                {
                    "sent": "Well, they'll tell you.",
                    "label": 0
                },
                {
                    "sent": "Well, you can either fax or a transpose a directly using Cholesky factorization, or you can do it on a directly using QR factorization.",
                    "label": 0
                },
                {
                    "sent": "Good, well great, you know.",
                    "label": 0
                },
                {
                    "sent": "We type that into Matlab and you're done right.",
                    "label": 0
                },
                {
                    "sent": "Yes, yes, you're done, but I wasn't done.",
                    "label": 0
                },
                {
                    "sent": "I wanted to know what happened inside OK and this is the connection I want to make.",
                    "label": 0
                },
                {
                    "sent": "I will tell you what QR factorization is, even though if you read the sparse linear algebra books it's really boring.",
                    "label": 0
                },
                {
                    "sent": "OK, but it's really actually exciting.",
                    "label": 0
                },
                {
                    "sent": "I want to, you know, give you the inside.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Also, that looking at the sparse structure, so here is a little slam problem and here is our matrix.",
                    "label": 0
                },
                {
                    "sent": "It's sparse, but it doesn't tell you much, except that it's sparse.",
                    "label": 0
                },
                {
                    "sent": "Here's here's another.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sample.",
                    "label": 0
                },
                {
                    "sent": "It's a sparser environment at MIT.",
                    "label": 0
                },
                {
                    "sent": "This is an infinite corridor, and the R matrix is very sparse.",
                    "label": 0
                },
                {
                    "sent": "Environment is very sparse, but you don't get a lot of intuition from this.",
                    "label": 0
                },
                {
                    "sent": "That is because there is none to be gotten.",
                    "label": 0
                },
                {
                    "sent": "OK, so matrixes are very clumsy ways of writing down graphs.",
                    "label": 0
                },
                {
                    "sent": "OK. And so I will tell you about.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This algorithm, which is is the elimination algorithm.",
                    "label": 0
                },
                {
                    "sent": "But before I do, I'll do a little detour.",
                    "label": 0
                },
                {
                    "sent": "If I would ask you what is the coolest science fiction?",
                    "label": 0
                },
                {
                    "sent": "Propulsion mechanism in you know what would it be?",
                    "label": 0
                },
                {
                    "sent": "The warp drive.",
                    "label": 0
                },
                {
                    "sent": "see I got the same question, yes, but the one that you actually could actually do.",
                    "label": 0
                },
                {
                    "sent": "You know that there is 1 actually working.",
                    "label": 0
                },
                {
                    "sent": "The ion drive.",
                    "label": 0
                },
                {
                    "sent": "The ion propulsion system.",
                    "label": 0
                },
                {
                    "sent": "So there is a spacecraft at this moment that is flying.",
                    "label": 0
                },
                {
                    "sent": "You know somewhere in the solar system with an ion propulsion drive.",
                    "label": 0
                },
                {
                    "sent": "This will come back to the talk in a minute.",
                    "label": 0
                },
                {
                    "sent": "It's taking this long detour and it'll stop on the way.",
                    "label": 0
                },
                {
                    "sent": "I'm a little planetoid called Vesta, which must have been the inspiration behind the Microsoft operating system.",
                    "label": 0
                },
                {
                    "sent": "Which is a little planetoid, but it's real.",
                    "label": 0
                },
                {
                    "sent": "Target is actually another planetoid called Sarah's, and Sarah's was, you know.",
                    "label": 0
                },
                {
                    "sent": "150 years ago I guess was was at the same level of Pluto.",
                    "label": 0
                },
                {
                    "sent": "It was a planet, it was just discovered.",
                    "label": 0
                },
                {
                    "sent": "It was the hottest scientific object of its time and inspired Gause to develop linearly squares and the elimination algorithm.",
                    "label": 0
                },
                {
                    "sent": "OK and Don, which is the spacecraft, will reach Sarah's in 2015, so will have a gas revival in two years.",
                    "label": 0
                },
                {
                    "sent": "OK, so let me now tell you about Gaussians.",
                    "label": 0
                },
                {
                    "sent": "Idea, which is the elimination algorithm in which you already learned about in secondary school.",
                    "label": 0
                },
                {
                    "sent": "You take a factor graph, so here's a little factor graph.",
                    "label": 0
                },
                {
                    "sent": "You can also write it down in a boring old sparse linear algebra way, so I did that for you.",
                    "label": 0
                },
                {
                    "sent": "OK, so if you like linear algebra, you can follow along on this side.",
                    "label": 0
                },
                {
                    "sent": "You take this vector graph and you say, let's let's eliminate one variable at a time.",
                    "label": 1
                },
                {
                    "sent": "Let's make the problem simpler.",
                    "label": 0
                },
                {
                    "sent": "OK, instead of looking at 5 variables, let's just look at L1, which is the land.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Mark up here now looking at all the factors connected to L1.",
                    "label": 0
                },
                {
                    "sent": "You will find that it's only connected to certain other variables which are called the separator of L1.",
                    "label": 0
                },
                {
                    "sent": "In Degraff, these two variables separate L1 from everything else in the graph.",
                    "label": 0
                },
                {
                    "sent": "Not a big deal now right?",
                    "label": 0
                },
                {
                    "sent": "There's only two other variables left, but in general there's a million OK.",
                    "label": 0
                },
                {
                    "sent": "So so, so that induces a small joint probability distribution on L1 and separator.",
                    "label": 0
                },
                {
                    "sent": "And any joint distribution can be factored.",
                    "label": 0
                },
                {
                    "sent": "In a.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In a conditional and the smaller joint on the separator.",
                    "label": 0
                },
                {
                    "sent": "So a conditional we already know how to represent.",
                    "label": 0
                },
                {
                    "sent": "Actually that's a little Bayes, not fragmente, so here we now have a base node on L1 which depends on its separator and we also have to pay a price.",
                    "label": 0
                },
                {
                    "sent": "The prices that we now have a joint density on X1 and X2.",
                    "label": 0
                },
                {
                    "sent": "They are not correlated and they might not have been correlated before.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "This is by the way you can do this with systems of linear equations and then you have gas Jordan elimination.",
                    "label": 0
                },
                {
                    "sent": "OK, so you will induce you will solve for one variable and you now have a new equation on the variables that you that you touched in the process.",
                    "label": 0
                },
                {
                    "sent": "What happened in the sparse linear algebra case is that all the nonzeros in the L1 column disappeared, because now it's just a function of X1 and X2 and it has no more constraints on it.",
                    "label": 0
                },
                {
                    "sent": "Good so you keep doing this in some ordering will do L2 next.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which induces a factor on X3.",
                    "label": 0
                },
                {
                    "sent": "Getting out all the nonzeros disappear in the L2 column and you keep doing this OK.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Until.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What you reaches this stage where now the factor graph has been transformed into another density trans representation, which is the base in that.",
                    "label": 0
                },
                {
                    "sent": "At the same time, by the way.",
                    "label": 0
                },
                {
                    "sent": "The sparse matrix here became a sparse upper triangular matrix.",
                    "label": 0
                },
                {
                    "sent": "OK, but that's the cool thing, right?",
                    "label": 0
                },
                {
                    "sent": "That's that's boring, right?",
                    "label": 0
                },
                {
                    "sent": "This is arbitrary, or it doesn't tell you anything, but this is a Bayes net, which is now the solution to your problem.",
                    "label": 0
                },
                {
                    "sent": "OK, so QR factorization I just gave you QR factorization, but the cool way takes a factor graph and transforms into a Bayes net.",
                    "label": 0
                },
                {
                    "sent": "And the Bayes net has a structure which is.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which has a matrix which is upper triangular which just means there is no operator.",
                    "label": 0
                },
                {
                    "sent": "Angular just means directed acyclic.",
                    "label": 0
                },
                {
                    "sent": "OK, which is a base network is a DAG.",
                    "label": 0
                },
                {
                    "sent": "Alright, let's see this at work on a couple of more interesting graphs or here.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is a little movie made by my student young.",
                    "label": 0
                },
                {
                    "sent": "The answer here is a circle, an elimination each way.",
                    "label": 0
                },
                {
                    "sent": "And here is the resulting Bayes net.",
                    "label": 0
                },
                {
                    "sent": "Or here is a planar graph.",
                    "label": 0
                },
                {
                    "sent": "These are some.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Set examples and you get elimination eating away, and here is the Bayes net that results.",
                    "label": 0
                },
                {
                    "sent": "OK. Good so so two things that I told you is.",
                    "label": 0
                },
                {
                    "sent": "You know, factor graphs are cool, right?",
                    "label": 1
                },
                {
                    "sent": "And even QR factorization is cool.",
                    "label": 0
                },
                {
                    "sent": "OK, it takes a factor graph, turns it into a Bayes net, and it was invented by.",
                    "label": 0
                },
                {
                    "sent": "Buy gas well, the Chinese will say no.",
                    "label": 0
                },
                {
                    "sent": "No 2000 years ago we did it.",
                    "label": 0
                },
                {
                    "sent": "Which is true, but they did it for three variables.",
                    "label": 0
                },
                {
                    "sent": "Is a cow or horse and a pig, and there's a little recipe on how to figure out the weight of each when you put them two at a time on a scale, which is a small little sensor Fusion problem.",
                    "label": 0
                },
                {
                    "sent": "2000 year old?",
                    "label": 0
                },
                {
                    "sent": "Here is a recipe, but Gauss reinvented it.",
                    "label": 0
                },
                {
                    "sent": "And being Western centric, we called it Gaussian elimination.",
                    "label": 0
                },
                {
                    "sent": "Alright, so once you have this connection between sparse linear algebra and graphical models OK, and also realize that it's much bigger than sparse linear algebra, remember I I talked about Boolean satisfiability constraint satisfaction, you know.",
                    "label": 0
                },
                {
                    "sent": "Mark of random fields.",
                    "label": 0
                },
                {
                    "sent": "All of these can use the same algorithm to do inference so so.",
                    "label": 0
                },
                {
                    "sent": "So sparse linear algebra is really the very special case of this story.",
                    "label": 0
                },
                {
                    "sent": "When you have linear constraints on Gaussian noise, OK?",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You have this connection, though there is a whole lot of things that you are now inspired to do OK. You broke open the QR factorization buksan.",
                    "label": 0
                },
                {
                    "sent": "So in the last five years.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We've built a tool box which really does a large scale optimization.",
                    "label": 0
                },
                {
                    "sent": "It's called GSM for Georgia Tech smoothing and mapping 'cause it was mostly applied to robotics in the beginning, but now we do structure from motion and in fact it also solves sudokus, so the same algorithm template it in a different way will solve a sudoku.",
                    "label": 0
                },
                {
                    "sent": "So there is some C++ and you just create this factor graph very quickly.",
                    "label": 0
                },
                {
                    "sent": "And I'm going to call optimize.",
                    "label": 0
                },
                {
                    "sent": "And there's a whole MATLAB toolbox on top so you can do it in MATLAB if you'd like.",
                    "label": 0
                },
                {
                    "sent": "Now, one of the things that you quickly realize and sparse linear algebra people definitely did is.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That the elimination ordering in which you eliminate these variables is crucial.",
                    "label": 0
                },
                {
                    "sent": "OK, that's the secret.",
                    "label": 0
                },
                {
                    "sent": "That's the problem actually.",
                    "label": 0
                },
                {
                    "sent": "So finding this optimal ordering.",
                    "label": 0
                },
                {
                    "sent": "So here is the one that is really nice.",
                    "label": 0
                },
                {
                    "sent": "It leads to a fairly sparse graph, another ordering in the same graph can lead you to a fully dense Bayes network.",
                    "label": 0
                },
                {
                    "sent": "And that's the difference between 10 milliseconds or an hour.",
                    "label": 0
                },
                {
                    "sent": "Even large graphs, I mean literally it's that stark.",
                    "label": 0
                },
                {
                    "sent": "OK, you can be very, very unlucky in choosing an ordering.",
                    "label": 0
                },
                {
                    "sent": "And as with all good things in life, the optimal ordering is NP hard.",
                    "label": 0
                },
                {
                    "sent": "OK to find it.",
                    "label": 0
                },
                {
                    "sent": "But there is some very good heuristics.",
                    "label": 0
                },
                {
                    "sent": "For example, here is.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What is called approximate minimum degree where you pick a node to be illuminated which has sort of the smallest degree in the graph that is left.",
                    "label": 1
                },
                {
                    "sent": "And it does something reasonable, OK?",
                    "label": 0
                },
                {
                    "sent": "Another very very nice heuristic is, well, let's divide and conquer.",
                    "label": 0
                },
                {
                    "sent": "If you have a big graph, let's cut it into pieces and solve each of the pieces and so it's.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is what happens here.",
                    "label": 0
                },
                {
                    "sent": "So we cut sandwich first.",
                    "label": 0
                },
                {
                    "sent": "Do this piece and then this piece and then this piece and then this piece.",
                    "label": 0
                },
                {
                    "sent": "And in fact one of my colleagues, Dick Lipton.",
                    "label": 0
                },
                {
                    "sent": "Prove the theorem that in planar graphs you can always cut it with a separator that is only size square root of N, which then leads to a full elimination algorithm which has limited which is has an upper bound of order N to the 1.5 in terms of solving and he did it with charge and it's a famous result in finite element methods.",
                    "label": 0
                },
                {
                    "sent": "OK, but finding these separators themselves is NP hard OK.",
                    "label": 0
                },
                {
                    "sent": "Nevertheless, these things we applied also for.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Doctor promotion this is work by Kinny who's not about Microsoft Research and so here is the Saint Peters Basilica datasets.",
                    "label": 1
                },
                {
                    "sent": "City of Ricks, alisky.",
                    "label": 0
                },
                {
                    "sent": "And so he cut up this large graph into different pieces and then solves each one separately and then you can do that out of course, so you can sort of load in a part of the graph, solve it, put it back to disk, and then load the next one.",
                    "label": 0
                },
                {
                    "sent": "So now you can be very large structure from motion problems, sort of on a single core computer by leading them in one of the time one at a time.",
                    "label": 0
                },
                {
                    "sent": "Now you can do this recursively.",
                    "label": 0
                },
                {
                    "sent": "So actually Dick Lipton's result was about.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Recursive Lee cutting a graph.",
                    "label": 0
                },
                {
                    "sent": "So this is the nested dissection algorithm and icing.",
                    "label": 1
                },
                {
                    "sent": "Also, I'm just going to run this again.",
                    "label": 0
                },
                {
                    "sent": "Is that the problems are independent so we can solve each of these little subtrees that create that is created in parallel.",
                    "label": 0
                },
                {
                    "sent": "OK, so you don't have to wait for one side to be done before you can solve the other side.",
                    "label": 0
                },
                {
                    "sent": "So I also actually this is very recent work when he was still, you know.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "When he was already at Microsoft, we did a variant of search for Motion, which is called hyper structure from Motion, where we take the hypergraph reflector graph and recursively cut it up.",
                    "label": 0
                },
                {
                    "sent": "So this is the Grand Canal datasets, again courtesy of UW guys, and solve each of the small pieces.",
                    "label": 0
                },
                {
                    "sent": "Put some together, you know, solve them, put them together, and then finally put the whole thing together.",
                    "label": 0
                },
                {
                    "sent": "So that's sort of a an alternative to the bundler way of.",
                    "label": 0
                },
                {
                    "sent": "Of adding one frame at a time or one image at a time.",
                    "label": 0
                },
                {
                    "sent": "So so.",
                    "label": 0
                },
                {
                    "sent": "So we did some things in computer.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Vision in robotics.",
                    "label": 0
                },
                {
                    "sent": "Alot of people are starting to adopt factor graphs, sort of computational substrate.",
                    "label": 0
                },
                {
                    "sent": "So here's some work by Tim Barfoot at the University of Washington.",
                    "label": 1
                },
                {
                    "sent": "They do a lot of space robotics so they have this Mars yard somewhere in Canada.",
                    "label": 0
                },
                {
                    "sent": "And they have a Rover that makes sort of explorations in this Mars Yard, and they they use GSM for example to to solve their Maps.",
                    "label": 0
                },
                {
                    "sent": "But I want to highlight the work of my former student.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Michael Kiss so the.",
                    "label": 0
                },
                {
                    "sent": "Let me let me just show you this this when Michael was graduating this robotics data set was still a little bit challenging.",
                    "label": 0
                },
                {
                    "sent": "Now it's sort of a trivial data set.",
                    "label": 0
                },
                {
                    "sent": "But but the he Michael is inspired by the fact that you know if you have a factor graph and you are robot and you're building this factor graph, it grows and grows and grows and keeps growing and you have to solve this entire factor graph every time.",
                    "label": 0
                },
                {
                    "sent": "And the question was can we do this?",
                    "label": 0
                },
                {
                    "sent": "Incrementally, can we reuse the results from before to do less work?",
                    "label": 0
                },
                {
                    "sent": "And in fact there is incremental factorization methods in linear algebra that Michael applied in his thesis, so here.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Michael and this is the main idea behind this.",
                    "label": 0
                },
                {
                    "sent": "You have an upper triangular matrix and if you add a couple of constraints or factors, it turns out that the only things that will change when you put these factors into R is a small piece at the very bottom.",
                    "label": 0
                },
                {
                    "sent": "OK, and so Michael took this idea and published incremental smoothing and mapping back in 2008.",
                    "label": 1
                },
                {
                    "sent": "And that's been quite successful, but it's still use this matrix paradigm.",
                    "label": 0
                },
                {
                    "sent": "So I was still finding out these connections between graphs and matrices, and I couldn't convince Michael it was only when he got to MIT.",
                    "label": 0
                },
                {
                    "sent": "So so Michael is a research scientist for John Leonard at MIT now, but just accepted a position at Carnegie Mellon's assistant research professor.",
                    "label": 0
                },
                {
                    "sent": "So he's going there.",
                    "label": 0
                },
                {
                    "sent": "The you know it's only after you got a mighty that I convinced him.",
                    "label": 0
                },
                {
                    "sent": "Let's look at what this incremental factorization means in graphs.",
                    "label": 0
                },
                {
                    "sent": "OK, now it turns out that if you take a large factor graph.",
                    "label": 0
                },
                {
                    "sent": "And factorize it into a Bayes network that Bayes network has a very definite structure.",
                    "label": 0
                },
                {
                    "sent": "You can discover the cliques in that base network.",
                    "label": 0
                },
                {
                    "sent": "And you can create a tree of cliques, and that's called a clique tree and in machine learning is actually known as junction tree.",
                    "label": 0
                },
                {
                    "sent": "So what happens is really you're creating a junction tree when you solve this.",
                    "label": 0
                },
                {
                    "sent": "And as you do this incrementally, you can edit this junction tree so that only the small parts you just rearrange it a little bit, and so with very little computation you can continue to keep your solution alive, so allow show and movie.",
                    "label": 0
                },
                {
                    "sent": "Of this junction tree, and this is literally what goes on in our code you will see a snapshot of our code as it is doing, solving an incremental smoothing and mapping problem.",
                    "label": 0
                },
                {
                    "sent": "OK, the data set is courtesy of adults and at from Michigan.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So synthetic data set, so here's the tree.",
                    "label": 0
                },
                {
                    "sent": "Right and only the Reds clicks at the very top in an exploration scenario will be re computed.",
                    "label": 0
                },
                {
                    "sent": "These great leaks are all conditions that are pointing down towards the pass and are never to be changed.",
                    "label": 0
                },
                {
                    "sent": "OK, it's only also when you close a loop.",
                    "label": 0
                },
                {
                    "sent": "There might be some flash of red when a lot of variables have to be re illuminated, but most of the time.",
                    "label": 0
                },
                {
                    "sent": "I say 99% of the time, you know when you're not closing loops, things are just constant time.",
                    "label": 0
                },
                {
                    "sent": "It's pretty amazing.",
                    "label": 0
                },
                {
                    "sent": "So we just published last year in GRR and this is sort of a collaboration with with MIT, but it's built into into GT Sam.",
                    "label": 0
                },
                {
                    "sent": "So again, after awhile it becomes a little bit unwieldy, but this is simply dumping the data structures from GSM into a graph is visualization and I'm showing them on the screen.",
                    "label": 0
                },
                {
                    "sent": "And I'm really proud of this, because this is, I think, the state of the art in sort of incremental inference in graphical models, OK?",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                },
                {
                    "sent": "It turns out that Michael when he.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "MIT created a C++ implementation of I Sam.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And it actually has a lot of impact, so so one of the sort of scanner mouse which actually does slam as you scan over a document, uses I Sam inside.",
                    "label": 0
                },
                {
                    "sent": "OK, there is these little spheres MIT spheres that are up in the space station that are using ICEM to help localize themselves, and one of the cool.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Projects that Michael did with, in conjunction with the University of Michigan is to do ship Hull inspection for the Navy, so they have these small underwater Rovers.",
                    "label": 0
                },
                {
                    "sent": "And they map things like the bottom of.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Aircraft carriers, so I'll show this movie from Ryan uses at the University of Michigan, but this is collaboration with Michael, which is, which is why they are using ICEM inside.",
                    "label": 1
                },
                {
                    "sent": "One of the very cool things about this movie is that this has been mapped a couple of times.",
                    "label": 0
                },
                {
                    "sent": "This the underside of this ship and the second time the Rover goes around it goes up from under the surface has a little Periscope and does the loop closures by doing scene recognition based on the previous.",
                    "label": 0
                },
                {
                    "sent": "The patterns on the side of the ship with the Periscope isn't that amazing.",
                    "label": 0
                },
                {
                    "sent": "Cool, you know.",
                    "label": 0
                },
                {
                    "sent": "So this is very recent.",
                    "label": 0
                },
                {
                    "sent": "I'm really showing you sort of cutting edge of what goes on in robotics here and so this is from August 2013.",
                    "label": 0
                },
                {
                    "sent": "Which is last month.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Alright, I'll just show you this a little bit.",
                    "label": 0
                },
                {
                    "sent": "You still have the problem that you're creating these very long trajectories as you go, and so you know trajectory is keep growing up in complexity.",
                    "label": 0
                },
                {
                    "sent": "You could argue that the environment stays is constant in complexity here.",
                    "label": 0
                },
                {
                    "sent": "This room is static.",
                    "label": 0
                },
                {
                    "sent": "Once you've seen everything, it stays the same.",
                    "label": 0
                },
                {
                    "sent": "OK, there is dynamic objects etc, but but what is actually growing complexity constantly is if you take a camera.",
                    "label": 0
                },
                {
                    "sent": "Through this environment many, many times, the complexity of that trajectory grows unboundedly, so one of the things that Michael work Tom is to enable long-term visual mapping.",
                    "label": 0
                },
                {
                    "sent": "So this is inspired by.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "His advisor at MIT, John Leonard, who is really interested in this lifelong mapping where they think datasets of this is very cool.",
                    "label": 0
                },
                {
                    "sent": "Building the status center at MIT.",
                    "label": 0
                },
                {
                    "sent": "I hear it's leaky as hell though, so don't be too jealous.",
                    "label": 0
                },
                {
                    "sent": "You know it's Gary likes, likes, looks and not necessarily.",
                    "label": 0
                },
                {
                    "sent": "Waterproof roofs.",
                    "label": 0
                },
                {
                    "sent": "But they took a data set here over a period of six months, traveled 11 kilometers and have 630,000 frames that they want to.",
                    "label": 0
                },
                {
                    "sent": "Integrates.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here Michael John used I Sam to create.",
                    "label": 0
                },
                {
                    "sent": "A pose graph, so graph on the poses.",
                    "label": 1
                },
                {
                    "sent": "The very cool thing here is that they actually go up and down with the elevator, but they as a closed loops later even though they don't see anything in the elevator except for their accelerometer readings, they can build a consistent 3D model nevertheless.",
                    "label": 0
                },
                {
                    "sent": "But they they use a technique where they.",
                    "label": 0
                },
                {
                    "sent": "They don't add every pause into the graph.",
                    "label": 0
                },
                {
                    "sent": "Instead, if the pause is close enough to oppose that you have already seen, they just add relative constraints between pauses that they've already seen, so that's what they call a reduced post graph, and so the result of all this is a 10th floor map of the status.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Center right, I think they couldn't get into the bigger basement here.",
                    "label": 0
                },
                {
                    "sent": "They probably didn't have permissions to go into the loading dock, but here this is a status center map, so this is a six month 11 kilometer data set.",
                    "label": 0
                },
                {
                    "sent": "Ryan used.",
                    "label": 0
                },
                {
                    "sent": "This is at the University of Michigan and here this robot with a 3D lighter.",
                    "label": 0
                },
                {
                    "sent": "And he did 25 mapping runs over 15 months.",
                    "label": 0
                },
                {
                    "sent": "And logged about 150.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yes, so he has a sort of competing reduced post graph method.",
                    "label": 0
                },
                {
                    "sent": "Here is a movie of what's happening, so this is the factor graph as it is growing overtime.",
                    "label": 0
                },
                {
                    "sent": "So it's 25 mapping sessions.",
                    "label": 0
                },
                {
                    "sent": "And he uses a child, you tree approximation, which to two clicks in this graph to get a much lower complexity graph that can be kept sort of in reasonable computational time.",
                    "label": 0
                },
                {
                    "sent": "As you do, it is very long term mapping efforts so that work has appeared at a workshop, but it's actually only going to appear at Iris in Japan this fall.",
                    "label": 0
                },
                {
                    "sent": "So again, this is very novel work.",
                    "label": 0
                },
                {
                    "sent": "This is not my work, they use this factor graph, so I just wanted to show you what people are doing with factor graphs.",
                    "label": 0
                },
                {
                    "sent": "Cool.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I do want to tell you about one last idea that we developed in the last couple of years and is more focused on computer vision.",
                    "label": 0
                },
                {
                    "sent": "This is work by my student young DM.",
                    "label": 0
                },
                {
                    "sent": "Where we we will be first developed in robotics and applied it to computer vision.",
                    "label": 0
                },
                {
                    "sent": "So let me let me show you this.",
                    "label": 0
                },
                {
                    "sent": "My hope is that I'm going to demystify one last linear algebra technique that you've heard about and never really wanted to understand.",
                    "label": 0
                },
                {
                    "sent": "You know, if your linear algebra class was any like mine, it could turn you off to linear algebra for the rest of your life, and it nearly did for me.",
                    "label": 0
                },
                {
                    "sent": "And I only discovered later in life how cool all this stuff was, but I had a very old professor and he was not interested in actually making us excited about this stuff.",
                    "label": 0
                },
                {
                    "sent": "Plus it he used may tricias.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here is a graph OK. Anne, it's of a city, and so take a moment to tell your neighbor which city this is.",
                    "label": 0
                },
                {
                    "sent": "Meet your neighbor.",
                    "label": 0
                },
                {
                    "sent": "Tell your neighbor which city this is.",
                    "label": 0
                },
                {
                    "sent": "Oh, come on, talk talk.",
                    "label": 0
                },
                {
                    "sent": "Oh hint hint, it's not Paris.",
                    "label": 0
                },
                {
                    "sent": "It's not London.",
                    "label": 0
                },
                {
                    "sent": "OK. All right outer hint.",
                    "label": 0
                },
                {
                    "sent": "This is a thing called the Forbidden City.",
                    "label": 0
                },
                {
                    "sent": "Alright, OK good, so this is actually a sort of an open street map.",
                    "label": 0
                },
                {
                    "sent": "We got it from Openstreetmap and build a factor graph.",
                    "label": 0
                },
                {
                    "sent": "It it it's Beijing.",
                    "label": 0
                },
                {
                    "sent": "And of course, Beijing doesn't have an Eiffel Tower.",
                    "label": 0
                },
                {
                    "sent": "But if it had an Eiffel Tower.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Would be very very useful.",
                    "label": 0
                },
                {
                    "sent": "Because you see an Eiffel Tower has this nice property that you can see it from many places.",
                    "label": 0
                },
                {
                    "sent": "An if you're lost in the city and you look around, you know if you see the Eiffel Tower like at least you're oriented in the world, right?",
                    "label": 0
                },
                {
                    "sent": "So it provides very strong orientation constraints.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately, it is very useful property for mapping and localization, and you know Google might be interested in mapping Beijing.",
                    "label": 0
                },
                {
                    "sent": "Right is also detrimental to gas.",
                    "label": 0
                },
                {
                    "sent": "Gas is idea of eliminating one variable at a time and the reason is that once you eliminate a variable, you create a clique.",
                    "label": 0
                },
                {
                    "sent": "And that click is the size of the separator.",
                    "label": 0
                },
                {
                    "sent": "So now you create a new factor, disconnected all these variables that were that separator and the nasty thing about Eiffel Towers.",
                    "label": 0
                },
                {
                    "sent": "So I called this the Eiffel Tower problem.",
                    "label": 0
                },
                {
                    "sent": "Is that it is connected to many many many variables in your graph and that will basically make elimination grind to a halt.",
                    "label": 0
                },
                {
                    "sent": "So either you eliminate the Avatar last, which you can do, or you come up with some other technique.",
                    "label": 0
                },
                {
                    "sent": "This is by the way, Eiffel Tower is not to be taken literally.",
                    "label": 0
                },
                {
                    "sent": "If you do structure for motion with a camera that has a single calibration, OK, that collaboration is connected to all the camera and all the measurements in the graph.",
                    "label": 0
                },
                {
                    "sent": "And so when you eliminate those calibration parameters you have an Eiffel Tower problem on your hand, right?",
                    "label": 0
                },
                {
                    "sent": "So so elimination is a direct method.",
                    "label": 0
                },
                {
                    "sent": "It does a direct factorization of your problem so.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So another ways to do it iteratively to use conjugate gradient, say to serve down the gradient of your objective function, but that can be very slow to converge.",
                    "label": 1
                },
                {
                    "sent": "So and why is it slow to converge?",
                    "label": 0
                },
                {
                    "sent": "Well, because this objective function and it can be long and narrow, which by the way, the narrowness of it is the largest eigenvalue divided by the smallest eigenvalue is called the condition number.",
                    "label": 1
                },
                {
                    "sent": "OK, so the game is to have an objective function that has small condition number, IE the best objective function is spherical and for which an iterative method converges in one step.",
                    "label": 1
                },
                {
                    "sent": "So we decided to look into using direct methods.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Subgraphs this is inspired by the graphical nature of this problem.",
                    "label": 0
                },
                {
                    "sent": "We took Beijing.",
                    "label": 0
                },
                {
                    "sent": "We started a little spanning tree, started at the Forbidden City as the root, and ran a spanning tree all around Beijing.",
                    "label": 0
                },
                {
                    "sent": "This is a tree by the way.",
                    "label": 0
                },
                {
                    "sent": "This is the matrix that corresponds to this tree, but you wouldn't know it's a tree.",
                    "label": 0
                },
                {
                    "sent": "From looking at this OK, you can only see that you know when you look at the graph in detail, But it turns out that trees with an elimination algorithm are trivial.",
                    "label": 0
                },
                {
                    "sent": "It's like a knife through butter.",
                    "label": 0
                },
                {
                    "sent": "OK, it's order N in terms of solving it, so we take this whole problem, which is fairly complex and dense because of all these loop closures.",
                    "label": 1
                },
                {
                    "sent": "And we solve.",
                    "label": 0
                },
                {
                    "sent": "We take the spanning tree.",
                    "label": 0
                },
                {
                    "sent": "We solve that using the direct method, but then use it as a preconditioner for the hard part that's left in the hard part.",
                    "label": 1
                },
                {
                    "sent": "Or all the loop closures.",
                    "label": 0
                },
                {
                    "sent": "OK, and the effect of this of you is taking a sub graph which communicates globally throughout the graph.",
                    "label": 0
                },
                {
                    "sent": "Is that all the remaining variables?",
                    "label": 0
                },
                {
                    "sent": "OK, so all the remaining constraints are actually fairly uncorrelated once you take out this global information, what happen?",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is that you take a very long and skinny with objective function with small large condition number and turn it into something that's almost vertical and that is what preconditioning is.",
                    "label": 0
                },
                {
                    "sent": "OK, it's just reparametrization of your variables using constraints that are long term.",
                    "label": 0
                },
                {
                    "sent": "Global.",
                    "label": 0
                },
                {
                    "sent": "So I asked young Young to create an animation to make that really visible.",
                    "label": 0
                },
                {
                    "sent": "So here is that.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Same factor graph of that little robot that could.",
                    "label": 0
                },
                {
                    "sent": "And this is the solution of all the variables.",
                    "label": 0
                },
                {
                    "sent": "I pinned it down in the middle.",
                    "label": 0
                },
                {
                    "sent": "I just gave a hard constraint in the middle and what I asked young man to do is take the largest eigenvector mean associate with the largest eigenvalue and put a sine wave to it.",
                    "label": 0
                },
                {
                    "sent": "So now you can see that variables.",
                    "label": 0
                },
                {
                    "sent": "Here and here are very correlated.",
                    "label": 0
                },
                {
                    "sent": "If this moves up that goes down and vice versa, and that's detrimental to iterative methods, OK?",
                    "label": 0
                },
                {
                    "sent": "But if.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Take a spanning tree.",
                    "label": 0
                },
                {
                    "sent": "And solve it.",
                    "label": 0
                },
                {
                    "sent": "It's really easy to solve.",
                    "label": 0
                },
                {
                    "sent": "What you see is that this correlation is also there in the spanning tree.",
                    "label": 0
                },
                {
                    "sent": "In fact, this long long range correlation is almost exactly the same correlation as you got for the entire problem.",
                    "label": 0
                },
                {
                    "sent": "So what you do is you take the entire problem, you solve the spanning tree an you take that correlation out of the problem, so you precondition.",
                    "label": 0
                },
                {
                    "sent": "So what we're doing is repair and tries.",
                    "label": 0
                },
                {
                    "sent": "In terms of the difference to the solution from this spanning tree and what you get now.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "When you is a condition number that is much much smaller OK and there is almost no correlation left in this graph.",
                    "label": 0
                },
                {
                    "sent": "So that's the intuition behind preconditioning.",
                    "label": 0
                },
                {
                    "sent": "So we applied this to large scale structure for motion problems.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At I CV 2011, we were briefly the fastest circular motion method out there.",
                    "label": 0
                },
                {
                    "sent": "But then Samir Agrawal and their gene and the geniuses at Google outdid us.",
                    "label": 0
                },
                {
                    "sent": "But here is a sort of intuition for structure from motion, so here's the Chicago data set.",
                    "label": 0
                },
                {
                    "sent": "Again, this actually is a solution of the sub graph.",
                    "label": 0
                },
                {
                    "sent": "That young young creates, so it's sort of a fuzzy version of Chicago.",
                    "label": 0
                },
                {
                    "sent": "Most of the information and most of the correlation is there, though, so if you use this as a preconditioner for the full problem again, it becomes much, much better conditions.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Same on the famous Notre Dame datasets, from from Noah.",
                    "label": 0
                },
                {
                    "sent": "Or in some ear.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Venice datasets, so you get these fuzzy versions which have most like 99% of the information.",
                    "label": 0
                },
                {
                    "sent": "Is there already.",
                    "label": 0
                },
                {
                    "sent": "Everything else is sort of topping off.",
                    "label": 0
                },
                {
                    "sent": "And topping off is easily done using conjugate gradient.",
                    "label": 0
                },
                {
                    "sent": "So if you look at the condition numbers.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of a couple of really good and large datasets, this is from RCB paper.",
                    "label": 0
                },
                {
                    "sent": "You will see that this condition numbers decrease drastically.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Good so so factor graphs are cool.",
                    "label": 1
                },
                {
                    "sent": "Gauss was a genius and you already know the algorithm.",
                    "label": 0
                },
                {
                    "sent": "It fails when you have Eiffel Towers where Eiffel Tower is a more generic term than just Eiffel Tower.",
                    "label": 0
                },
                {
                    "sent": "But but you can then use these elimination methods as preconditioners.",
                    "label": 0
                },
                {
                    "sent": "Some future directions and I'll stop.",
                    "label": 1
                },
                {
                    "sent": "We're working we're running GSM is downloadable for free.",
                    "label": 0
                },
                {
                    "sent": "If you're wondering about the license, it's not GPL, it's it's BSD you can do with it whatever you want, OK, but internally we're running with GSM 3.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Which is brought to you by DARPA, which is a defense agency in.",
                    "label": 1
                },
                {
                    "sent": "In the US, and they want something that's really fast and can run in embedded mode, and we're doing they're giving US data sets that I can talk to you about, but are very, very challenging.",
                    "label": 0
                },
                {
                    "sent": "OK with lots of different sensors, and so I think we published a plug and play sensor.",
                    "label": 0
                },
                {
                    "sent": "Paradigm for which factor graphs are actually ideally suited and our play is very interested.",
                    "label": 0
                },
                {
                    "sent": "And one of the things that they're paying us to do is actually make GTM faster, more reliable, more robust, and so it will be a fully multithreaded.",
                    "label": 0
                },
                {
                    "sent": "He will do all these subtrees in parallel on multiple cores and still have the Matlab toolbox etc, so.",
                    "label": 0
                },
                {
                    "sent": "So again, there is.",
                    "label": 0
                },
                {
                    "sent": "You know there's some ear has a solver for structure from motion, which is awesome.",
                    "label": 0
                },
                {
                    "sent": "OK, which is called Sarah's.",
                    "label": 0
                },
                {
                    "sent": "OK, this is the planet from gaseous planet.",
                    "label": 0
                },
                {
                    "sent": "But we do.",
                    "label": 0
                },
                {
                    "sent": "We do not only search for motion, but also submitting a mapping and even sudokus, alright?",
                    "label": 0
                },
                {
                    "sent": "That's one of the things that.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That DARPA, trosa does, is is the problem of very long term navigation.",
                    "label": 0
                },
                {
                    "sent": "So you know what if you would fly for seven days without GPS?",
                    "label": 0
                },
                {
                    "sent": "OK, one of the things that happens is that you lose your numerical accuracy.",
                    "label": 0
                },
                {
                    "sent": "There is so much uncertainty at the end of this long Markov chain.",
                    "label": 0
                },
                {
                    "sent": "If you don't do any loop closures that you everything blows up, and so we're looking into backbone methods, sort of a.",
                    "label": 0
                },
                {
                    "sent": "A mix between direct and preconditioning to get rid of that blow up, and I think there's a lot of promise here for robotics.",
                    "label": 0
                },
                {
                    "sent": "Another is.",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Can we completely eliminate the front end?",
                    "label": 0
                },
                {
                    "sent": "All this correspondence hunting in structure for motion and robotics is one of the things that make it problematic.",
                    "label": 0
                },
                {
                    "sent": "An idea of adults and is.",
                    "label": 0
                },
                {
                    "sent": "Well, who needs correspondence if instead of using Gaussian densities and quadratic errors, you use robust error metrics, maybe you don't even need to have a front end, you just throw all your constraints in in a big soup and whether they are correct or not, you'll have the optimizer figured that out, so he used that small Intel data set that I showed before.",
                    "label": 1
                },
                {
                    "sent": "And here is the standard Gaussian noise model an if you have outliers here, 100 errors, it goes, it goes to hell.",
                    "label": 1
                },
                {
                    "sent": "But if you use robust error metrics like called M estimators, you're tolerant and you just don't care.",
                    "label": 0
                },
                {
                    "sent": "And then finally something that I'm looking at with my students and postdocs.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now is also how to do distributed mapping over multiple robots.",
                    "label": 0
                },
                {
                    "sent": "Actually, this is not the final slide.",
                    "label": 0
                },
                {
                    "sent": "Here is a final slide.",
                    "label": 0
                },
                {
                    "sent": "We've done a lot of mapping in robots and with cameras, but we're not really controlling these robots as they fly or drive or.",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Swim.",
                    "label": 0
                },
                {
                    "sent": "And it turns out that there is a paradigm in control called model predictive control which is really trajectory optimization and I was looking at that.",
                    "label": 0
                },
                {
                    "sent": "I'm saying, hey, that's interesting.",
                    "label": 0
                },
                {
                    "sent": "GT Sam is very good at optimizing trajectories, so could we role in model predictive control into GSM in a seamless 11 factor graph based framework?",
                    "label": 0
                },
                {
                    "sent": "And so that's that's the future for me is.",
                    "label": 0
                },
                {
                    "sent": "So how can we roll in model predicted control into the whole thing?",
                    "label": 0
                },
                {
                    "sent": "I guess I will.",
                    "label": 0
                }
            ]
        },
        "clip_80": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Stop there, alright thank you.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I've two question actually.",
                    "label": 0
                },
                {
                    "sent": "One is from your last slide here, something with the geometric with Lee algebra.",
                    "label": 0
                },
                {
                    "sent": "And do you usually algebra?",
                    "label": 0
                },
                {
                    "sent": "Yes, I didn't even mention this but but but yes, I'm sort of just like Tom.",
                    "label": 0
                },
                {
                    "sent": "Actually a little bit obsessed with Lee Groups and Lee Algebra.",
                    "label": 0
                },
                {
                    "sent": "And so GD Sam.",
                    "label": 0
                },
                {
                    "sent": "Can take actually can take any manifold object and we're doing optimization on.",
                    "label": 0
                },
                {
                    "sent": "For Lee groups the Li algebra, but in general the tangent plane of these of these spaces.",
                    "label": 0
                },
                {
                    "sent": "So yeah, Lee algebra is sort of core built into GTA San.",
                    "label": 0
                },
                {
                    "sent": "Is it?",
                    "label": 0
                },
                {
                    "sent": "Or a covariance estimation?",
                    "label": 0
                },
                {
                    "sent": "Or is there any?",
                    "label": 0
                },
                {
                    "sent": "Why are you interested actually?",
                    "label": 0
                },
                {
                    "sent": "Oh, the reason is, you know, solely algebra asserted the nicest way of taking care of things that like in rotation matrix has 9 numbers in it.",
                    "label": 0
                },
                {
                    "sent": "But that's really it is only three degrees freedom.",
                    "label": 0
                },
                {
                    "sent": "So you look at this as a League group and then do optimization on the algebra at anytime is simply simply the way you should do it, and you get covariances on the Lee Group on the algebra actually so.",
                    "label": 0
                },
                {
                    "sent": "You know it's.",
                    "label": 0
                },
                {
                    "sent": "Does it give any advantages?",
                    "label": 0
                },
                {
                    "sent": "It's the right thing to do, that's you know.",
                    "label": 0
                },
                {
                    "sent": "Also, the lease Ledger lies presenting better.",
                    "label": 0
                },
                {
                    "sent": "The others.",
                    "label": 0
                },
                {
                    "sent": "Say all this errors all the covariances.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure whether it provides any real great advantages except getting rid of over parameterizations, which people tend to do if sort of the first thing to try is overparameterized and optimizing that, and then you get.",
                    "label": 0
                },
                {
                    "sent": "Sub optimal solutions.",
                    "label": 0
                },
                {
                    "sent": "That's right, but I'll be happy to talk a lot about Lee groups and Liagre offline.",
                    "label": 0
                },
                {
                    "sent": "My second question is, you talk about Mahatma.",
                    "label": 0
                },
                {
                    "sent": "You organize your graphs.",
                    "label": 0
                },
                {
                    "sent": "But yeah, for organizing your graphs with different methods, do you?",
                    "label": 0
                },
                {
                    "sent": "My first check how your problems looks like and then you reorganize the graph or you start different methods and see which one is better.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So the time comes with this, you know, heuristics built in, like you know, cutting grass into pieces or approximate minimum degree and they work for a large variety of problems.",
                    "label": 0
                },
                {
                    "sent": "But it's true that you can beat NP completeness by taking domain knowledge and building that into your ordering heuristics, and so for example, if there are structural motion people in the room.",
                    "label": 0
                },
                {
                    "sent": "A big trick that's all that's even in hardly in system book is the sure compliment you first get rid of all your landmarks by doing a sure compliment on this.",
                    "label": 0
                },
                {
                    "sent": "And it turns out OK.",
                    "label": 0
                },
                {
                    "sent": "The way I view the sure compliment is it simply an elimination choice you eliminate first your landmarks and then your cameras and you automatically recover the sure compliment so there could be better orderings.",
                    "label": 0
                },
                {
                    "sent": "Actually then justice sure compliment ordering.",
                    "label": 0
                },
                {
                    "sent": "So so yeah, trick that you can play papers that still need to be written.",
                    "label": 0
                },
                {
                    "sent": "Or if you have domain knowledge about a very specific problem.",
                    "label": 0
                },
                {
                    "sent": "Think about what the best ordering is for these problems and creates orderings and optimization schemes tailor made for your problem.",
                    "label": 0
                },
                {
                    "sent": "For subgraph for preconditioning, does it matter which choice of spanning tree you use?",
                    "label": 0
                },
                {
                    "sent": "Is?",
                    "label": 0
                },
                {
                    "sent": "There are some spanning trees better than others?",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah, that's a great question.",
                    "label": 0
                },
                {
                    "sent": "It turns out that you know we.",
                    "label": 0
                },
                {
                    "sent": "I truly invented this.",
                    "label": 0
                },
                {
                    "sent": "OK, I truly invented this idea of using a sub graph as a preconditioner, but then I discovered that in the last 10 years.",
                    "label": 0
                },
                {
                    "sent": "In the theory community in computer science, they've been looking at something called support graph theory, where they have exactly the same idea.",
                    "label": 0
                },
                {
                    "sent": "OK, so like, damn, you know I could have gotten some prize or something, but no, no.",
                    "label": 0
                },
                {
                    "sent": "But it turns out that the condition numbers of these original problems live up here, and when you throw in a subtree, it goes down very very quickly.",
                    "label": 0
                },
                {
                    "sent": "Now you could go down even deeper, and the theory people are interested in.",
                    "label": 0
                },
                {
                    "sent": "So what is the optimal sub graph there?",
                    "label": 0
                },
                {
                    "sent": "And they came up in something called low stretch spanning trees.",
                    "label": 0
                },
                {
                    "sent": "Low stretches is a proxy for how good the spanning tree is.",
                    "label": 0
                },
                {
                    "sent": "Really, how you know how good it is at communicating information through the graph.",
                    "label": 0
                },
                {
                    "sent": "And so young young uses loss thread.",
                    "label": 0
                },
                {
                    "sent": "This idea of low stretch spanning trees in his ICD paper.",
                    "label": 0
                },
                {
                    "sent": "So he does assure compliment Rick finds a low stretch spanning tree in the camera matrix or the camera graph and then adds a little bit of edges to the points back.",
                    "label": 0
                },
                {
                    "sent": "And now he has a complete spanning tree.",
                    "label": 0
                },
                {
                    "sent": "Cycle.",
                    "label": 0
                },
                {
                    "sent": "Exactly exactly so.",
                    "label": 0
                },
                {
                    "sent": "So when you have a cycle, long cycles are bad.",
                    "label": 0
                },
                {
                    "sent": "They stretch the graph out.",
                    "label": 0
                },
                {
                    "sent": "That's right exactly.",
                    "label": 0
                },
                {
                    "sent": "Yeah, great intuition.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Yes, I hope so.",
                    "label": 0
                },
                {
                    "sent": "Factories are cool.",
                    "label": 0
                },
                {
                    "sent": "Download GT Sam alright.",
                    "label": 0
                }
            ]
        }
    }
}