{
    "id": "ugfnr6teyzpmh4bedjejfqlpif5xyunt",
    "title": "Tradeoffs in online learning under partial information feedback",
    "info": {
        "author": [
            "Csaba Szepesv\u00e1ri, Department of Computing Science, University of Alberta"
        ],
        "published": "Jan. 16, 2013",
        "recorded": "December 2012",
        "category": [
            "Top->Computer Science->Machine Learning->On-line Learning"
        ]
    },
    "url": "http://videolectures.net/nipsworkshops2012_szepesvari_feedback/",
    "segmentation": [
        [
            "So welcome everyone.",
            "The best fire from."
        ],
        [
            "New way and this is joint work with on Russian Tosh, Gabor Bartock, polio, chulani, an unregistered, David Parland vids.",
            "Oh God.",
            "Bunch of students and bunch of senior colleagues that I was very happy to work with.",
            "On this topic."
        ],
        [
            "So I'm planning to talk about learning this partial information, feedback, training of exploration and exploitation.",
            "And talking about computational issues that arise if you're getting into some of these problems.",
            "And also learning with delayed feedback.",
            "So they jump in."
        ],
        [
            "So I'd like to start with passion monitoring and with an example.",
            "So imagine that, well, you are the learner trying to set an item.",
            "Maybe the item is, you know, just some commodity.",
            "Like video camera and you're trying to set the price of the item.",
            "OK, so you're trying to set this on, let's say on the website so customers coming to your website.",
            "Maybe it's an ID process, maybe it's like who knows what.",
            "And they have some.",
            "Price in their minds and you're trying to set the price.",
            "If you overprice or underprice depending on that, you're going to get this binary feedback signal whether you sold or not OK, what is missing here and what the learner is really interested in is to maximize the revenue right?",
            "And so to be able to tell whether you're maximizing the revenue you would need need to need to know.",
            "Maybe the price that the customer had in mind, right?",
            "So if you had the price.",
            "Then you kind of losing the difference between what the customer had in mind and your price, and if you overprice then the temp remains with you on the top you are going to pay some storage costs.",
            "So here is a simplified setting.",
            "For the dynamic pricing case, so you can capture this with the loss matrix so you are the role player, the learner is low player.",
            "Selecting one of these prices zero 10 or 20 and the customer coming to the website environment is going to pick some other prices and then depending on how you're picking the prices there is some loss that the learner suffers.",
            "And the feedback signal or the feedback matrix is just a binary matrix.",
            "So if you go with your price above the price of the customer, then you are going to sell.",
            "It's a plus, otherwise it's minus.",
            "And but if you're under pricing, then and the customer, let's say you're choosing this row, so you choose $10, the customers choosing $20, then you're going to lose $10 'cause you could have priced higher.",
            "So the question is, how efficiently can you learn in this situation in order to be able to measure efficiency, one measure that you could use is regret.",
            "So you take the losses that you are suffering at your choice of actions and opponents choice of price.",
            "So it is your choice.",
            "JFT is the opponent choice.",
            "And you compare this, let's say in a stochastic situation when the opponent is playing a stochastic policy with the best price.",
            "That, or with the best possible laws that you could have gotten if you have chosen the best price in high side.",
            "And you know you want to keep this regret low and the question is how low can you keep this regret in bandit problems?",
            "We got used to the idea that in full information problems swear that the regrets going growing at the rate of root T in some other problems, we know that the regret might be growing faster and the question is if I give you these two matrices, the last matrix and the feedback matrix, what is the rate of growth of the regret?",
            "How do we determine this on a case by case basis?",
            "Do we need to develop a solution for each game or not?"
        ],
        [
            "Right, so this is talking about the basic tradeoff between information acquisition costs and prediction accuracy, right?",
            "So you have to.",
            "Reason about which action to choose?",
            "Do you want to choose an action to gain some information or you go with your choice with the choice that seems to be the best given all the knowledge that you have.",
            "Alright, so after Y as you were playing this game, you might learn something about Apanas distribution and then whether you want to choose the action that is currently the best in terms of the losses or whether you will not explore something at the fashion and at what age you should do that.",
            "So what's the Prince?"
        ],
        [
            "This way of doing that, right?",
            "So the solution to this problem boils down to the following things.",
            "So you start with the probability distribution over over the opponents choices.",
            "The outcomes I'm going to call those outcomes and so that gives you the probability simplex and given the last match loss matrix.",
            "What you can do is that you can partition the probability simplex into this convex sets such that within each cell particulare action of yours is the best possible choice.",
            "OK, so in this cell are all the probability distributions for the opponent such that action #4 is the best one?",
            "OK, so this is solely determined by the loss matrix, so the last matrix imposing this structure and the probability simplex.",
            "And if you look at this partitioning, you can abstract away the details of the partitioning.",
            "What is important about this partitioning is which actions are neighbors to each other.",
            "So from this graph or from this cell, the composition, you can see that one and two and one and three are neighbors, three and four, and two and four are neighbors.",
            "I missed two and three, that's alright.",
            "Correct, yeah I had a different figure before and then it was great.",
            "Thank you.",
            "But at least someone is not sleeping.",
            "OK, so where is the feedback structure right?",
            "Whereas the feedback structure come in?",
            "So in order to explain how the feedback structure is going to influence how you should play the game, I need some notation.",
            "So let's say the opponent has M choices and all the losses are between zero and one.",
            "So you have this vector LFI for action.",
            "I OK that gives all the losses for the opponent.",
            "OK, so that's just the way of like talking about the rows of the.",
            "Las matrix OK, so let's say the opponent is is playing according this distribution P star.",
            "OK, so if the opponent is playing at distribution so that somewhere here in this outcome space, but that induces a distribution an the feedbacks that you're going to see the different feedback signals pass and minus is how probable is to see a plus versus how probabilities C minus.",
            "So it's clear that this relationship can be encoded with the matrix, right?",
            "We call that the signal matches because that encodes the structure of the feedback.",
            "That you're going to receive, right?",
            "So then, what is important is that, well, in order if you want to play a game like this or any game, what's important is to decide whether you should play action I or action J, right?",
            "So if you can design it for every pair of actions and you should be fine.",
            "So just take a pair of actions inj and this is the regret if you would be paid if you would be playing action chain instead of action I I believe.",
            "Right, so switching from I to J.",
            "This is the revenue that you would be able to get and so if the following relationship holds, there exists two vectors V1 and V2 such that this last difference can be expressed in this form.",
            "Then you have a chance of estimating this loss difference and if you know this last difference then from that point on you know you can reason with different ways.",
            "So for example, if you know the last differences for all the actions, then you can quickly figure out which action is the best.",
            "OK, so the key is going to be one of the key elements is going to be whether you can figure out this last differences.",
            "Whether this V1 and V2 vectors exist and this is just a linear algebra relationship, you can sort of simplify this peace studies.",
            "This has to hold for any P star, so we won and we 2 cannot depend on P star.",
            "And so that's just a constraint.",
            "And whether the Li minus edgy vector is lying in the span of some mages.",
            "OK, so if this holds actually, but turns out that going back to the structure that we have extracted from the last matrix.",
            "So if it it holds for all pairs of I&J in this graph.",
            "So Paris I&J, which are neighbors in this graph, that Ally minus LJ lies in the span of this appropriate matrix.",
            "Just stacking SI&J on the top of each other.",
            "Then we say that the game is locally observable, yes?",
            "Sigh, OK.",
            "It seems when you're playing an action, I actualize what the yeah yeah, then the symbols that you see you could assign different values to.",
            "Yeah, so unify the.",
            "You have to use a unified off, but actually it's well.",
            "It actually doesn't really matter which you can choose a different alphabet.",
            "OI yeah, different distribution would that?",
            "Would that affect the possibility of getting this window?",
            "No.",
            "It doesn't really matter.",
            "It's it's really about the information that you're collecting, like how much you can reason back from this distribution to be star.",
            "OK, but it's all like here.",
            "The important thing is that everything has to be relative, just two losses.",
            "OK.",
            "But for the sake of simplicity, you can think about that for all the rows like you're sharing the symbols as much as you can, but.",
            "So I guess it's obvious if their zeros and ones, but for big around that doesn't matter, doesn't matter.",
            "One choice of symbols, sure, like you can.",
            "You can permit things right?",
            "It's a permutation.",
            "OK. Alright, so again so you have this neighborhood structure and so for each neighbors in this graph, it holds that allion alignment said J is in the span of this step signal matrices.",
            "Then we say that the program the problem is locally observable.",
            "OK.",
            "Right?",
            "OK, so that's connecting up the feedback structure with the last structure, and that's basically all what we need to."
        ],
        [
            "Able to prove this theorem that says that no matter what kind of feedback matrix an last matrix you give to us, it's going to belong to one of the four categories, one of four categories.",
            "Either it's a trivial game or hopeless game to do that, trivial to classify, or it's kind of behaving the same as a bandit game.",
            "So we call these games easy or full information for that matter, or it could be a harder game.",
            "And there is nothing in between, so these exponents.",
            "If you are ordering them on the 01 interval, what you're going to see is that, like 0 is possible, one is possible, 1/2 is possible, 2 third is possible.",
            "This interval is empty.",
            "That interval is empty on this interval is empty.",
            "So by the way.",
            "So there was a bunch of previous work works.",
            "And of course people started with full information games and Wolf can littlestone environment were the one who said that OK for full information games you are going to have this exponent.",
            "At 1/2 and then for the bandits, overran coworkers figured out the same thing.",
            "The model is due to Pico Boney and Shinde hardware who had some cool ideas about this observability so we were recycling one of their a few other ideas and Nicole and Gabor figured out that this interval is basically empty and they pushed on their upper bounds to 2/3.",
            "And So what we figured out is basically that this interval is empty, so that's kind of for the contribution here.",
            "OK, so that that is a full characterization of all these games in the stochastic setting, and then it turns out that the same characterization actually applies in the adversary setting, and that is recent work by Adele Foster and Sasha Rakhlin, which was published at AI Stats Alright."
        ],
        [
            "So that's good so far.",
            "So there is dynamic pricing.",
            "How does it look?",
            "OK?",
            "So if you do the calculation with dynamic pricing then what you see is that you're going to have click, so every action is going to be a neighbor of every other action, so it's hard to depict this in higher dimensions.",
            "So if you have just three choices, then this is the picture that you are going to have.",
            "And what this entails is that the non consecutive pairs affections.",
            "Well if you look at the feedback structure, then you, like every action is a neighbor in this graph, right?",
            "And the prices are ordered right?",
            "And the prices which are not neighbors in this ordering but neighbors in the graph, and many of them they are not local observable.",
            "You need to use some other action to figure out the difference between the two.",
            "So there's the structure of the game for dynamic pricing, and then that tells that the regrets going to grow at the rate of three to the 2/3.",
            "Actually, that's the exact rate of growth of the regret.",
            "So that's kind of a disappointing answer, yes.",
            "Can you repeat?",
            "What are the actions?",
            "Excellent, actually the price.",
            "Yeah, you're setting one of the prices like so why?",
            "So if you have 1020 and 30 by 30 is number of 10.",
            "Well it sort of comes back like that's kind of showing the situation here.",
            "It's like there are certain distributions that like kind of unnatural distributions.",
            "If you are thinking about it that prefer one and three, and I just don't prefer to.",
            "OK.",
            "So it's kind of bimodal distributions or all kind of crazy stuff.",
            "So it's some kind of where customers that winning by four 103 but not for two.",
            "Yeah, something like that.",
            "Yeah, so if you start to think about it then you can see that, for example, if you would have some unimodal distributions with nice decaying things, then this is not going to happen at all.",
            "OK, so the question is how strange that is distributions and thanks for the question.",
            "That's actually what we were wondering about.",
            "Whether whether this game is necessary that hard in your life, right?",
            "So it's kind of disappointing that you can.",
            "Only only learn at this slow rate.",
            "And so this distributions, I would think that they are sort of strange and."
        ],
        [
            "The question then, whether you can develop an algorithm that is able to, you know, just add up to the distribution of the."
        ],
        [
            "Opponent, so if the opponent is playing somewhere here or somewhere there or somewhere here or somewhere there.",
            "Further away from this danger zone.",
            "Right then, can you get an algorithm that not knowing whether opponents playing is still going to get you know, good regret rate?",
            "Maybe Ruthie regret rate.",
            "So for example if you would eliminate part of this strategy space, can you get a route to regret rate?",
            "So that's like imposing some constraints and the environment.",
            "Of course, you don't know if the environment is going to play like that, so you can't just build this into your algorithm, so you need to adapt to weather the opponents playing B9 or malignant strategy."
        ],
        [
            "And it turns out that it is possible to do this, so we have actually just done that.",
            "So you need to have a more deliberate strategy for for doing this, But if you're doing this, then this just shows that this graph shows what happens if you're playing this dining pricing game.",
            "So the Y axis is a minimax regret.",
            "Lower values is better, and this is time if you're playing with our strategy values, you're playing with the strategy that conservatively sings at the opponent is going to play.",
            "Worse case distribution.",
            "OK, you see that?",
            "Well, the regret is much lower.",
            "Ann just studied this on an individual opponent strategy as well and put some confidence intervals and you can see that the differences could be pretty big.",
            "Alright."
        ],
        [
            "So.",
            "You can not only tradeoff these two things, but you can do it in at adaptive fashion, at least in this case.",
            "Right?"
        ],
        [
            "So I'd like to so the next topic I like to talk about is prediction with side information.",
            "OK, so in this setting so you have the learner, the environment and you have a feedback mechanism and it's going to be partial monitoring still.",
            "So right now when you are selling an item, the customer comes to your web page, then some information is revealed about the customer.",
            "OK, so maybe there are some cookies?",
            "Sorry but not and how to use that information to minimize the regret.",
            "So here is the situation.",
            "He's learning setting.",
            "So the environment is going to revert to you assign information vector and that could be chosen in adversary or fashion and at the same time the environment is going to choose an outcome from some distribution.",
            "So maybe this distribution belongs to a parametric family of distributions, but you don't know the parameter OK?",
            "Anne.",
            "As usually in partial monitoring games, well after you choose your action, you suffer loss.",
            "You're going to get a feedback, so you're not going to see the last again, and you're not going to see the outcome, so you're not going to see why FT so all you got to see is the feedback, so it's in some sense and actually generalization of the previous framework.",
            "OK, so the question is, what can you say in this case and how?"
        ],
        [
            "To learn so before going there we should talk about what we are comparing yourself or South with.",
            "OK, so here is the regret.",
            "It looks a little bit more complicated than before hand, so let me explain the parts.",
            "So this is just the total loss of the learner, so that's fine.",
            "And static predictors.",
            "So what we want to compete with is this static predictors, so they take the site information and given the site information they choose an action, they choose one of the actions, so you know the learner sees the side information.",
            "That's what he sees at the beginning.",
            "Then he has to choose an action.",
            "So we're going to compete with these guys.",
            "And if you take any of those, then this is just the expected total loss that you would suffer if you choose that.",
            "Static predictor from the beginning of time and you're going to choose the best static predictor in hindsight, and then you compare two quantities and that's your regret."
        ],
        [
            "So the question is, what can you say?",
            "And so this is the scary slide huge algorithm, but I'm going to take it apart for you.",
            "It's pretty simple actually.",
            "So the key is that you are trying to model the.",
            "Distribution over the outcomes that imposes distributions over.",
            "The things that you are observing the feedbacks.",
            "So from your model, so this is an abstract algorithm.",
            "This is an algorithm scheme that's going to work for many different settings.",
            "From your model, you ask what is given the site information, what is the likely feedback distribution?",
            "That's going to be QIT ODA.",
            "And you are also going to ask the mother to supply some confidence intervals for this.",
            "Distribution and then you start to reason about whether it is worse switching from one action to another by calculating this regret.",
            "Expected regret quantities for pairs of actions in the neighborhood graph that you're going to have.",
            "OK, and then you're going to eliminate the actions that are are suboptimal OK. And So what changes compared to the previous game?",
            "If you're thinking about is that depending on the side information, peace studies at a different location in the simplex, so you have to reason about these different situations.",
            "But the neighborhood graph is the same, and so it's kind of the same mesh thing that's going to apply here.",
            "So given all this, you're going to eliminate the actions that are clearly suboptimal, so taking into account their confidences and then.",
            "Both of the prospective actions that that remain you select the least known action.",
            "And the reason for doing that is that you want to learn about those actions, right?",
            "So if you have an action for which the confidence interval is really high, you want to learn about that action.",
            "And that's actually a crucial part of the algorithm.",
            "So you're going to choose that action.",
            "After that, you observe the outcome, and then you can update your statistiques."
        ],
        [
            "So what can we say about this algorithm?",
            "So this is a metal algorithm, a template.",
            "So we start with this assumption and later on we show that in particle settings this assumption can be satisfied in particle choices of these parametric distribution family.",
            "So the assumption just says that you have a learning mechanism.",
            "So if you want this is kind of a reduction that is able to supply you these confidence intervals for the feedback distributions over the feedbacks.",
            "We say sequence of confidences and some norm.",
            "OK, and then the theorem goes that says that the expected regret can be decomposed into two parts.",
            "One comes from your confidence intervals failing and you're going to be very conservative in estimating the regret coming from that and the other is going to come from how tight your confidence intervals are.",
            "So what you see here is that in the regret bond, the width of the confidence intervals are going to appear OK, so this kind of an abstract result.",
            "We don't know if this is good or not.",
            "It's going to hinge upon whether you have a good underlying learning mechanism that for small deltas.",
            "Can you give can give you small confidence intervals so just to give you a hint.",
            "So what you want to do is that you want to choose this to something like 1 / T squared or something.",
            "That sums to a small number.",
            "Of course the confidence are going to explore this function of that, but we know that usually that explosion is not that bad, it's logarithm of.",
            "One over that of T so we don't really have to worry about that part.",
            "We have to worry about how like the statistical accuracy.",
            "So if you can learn sort of at a rate of one over root tea, then like you know you're summing up one over root test.",
            "You should be fine, so that's kind of the cheer stuff of the result, yes.",
            "So in your definition of regret, you compared to all functions from X2, yeah.",
            "Even in the full information case, it is impossible to obtain.",
            "Now video video, it's implicit, so the reason is yeah, if you go back to the regret definition."
        ],
        [
            "So the reason is that we are working with this parametric families and and we are choosing like the parametric family is going to govern this choice, so that's implicitly parameterized.",
            "Is the family so not going to compete with other functions?",
            "You have a different function for injecting.",
            "Suppose X is just, you know, all the natural numbers.",
            "Yeah, well OK so so that's about like how fast you can learn about the theater star distribution.",
            "So let's say you have full information given XD you want to learn about this distribution?",
            "So what the situation that you are describing an tears that you have countably infinitely many parameters to estimate.",
            "You can't do anything.",
            "So it all boils down.",
            "So that's why the other result is just the reduction result.",
            "All boys done.",
            "Whether this."
        ],
        [
            "This learner that you should supply the confidence intervals is able to supply confidence intervals that are decaying fast.",
            "So if you want to go nonparametric then you won't get the one over root two rate here, but you would get some verse written.",
            "And of course if the parametric distribution family is so big that you can't even say anything about that, it's done so that kind of explains the mystery.",
            "Thanks for the question alright."
        ],
        [
            "Yeah.",
            "So for example, a simple case, so this parametric distribution model could be a multinomial logistic regression model.",
            "In that case you can prove a regret bound like this based on the previous result that we had."
        ],
        [
            "So some other open problems before I discuss some other things.",
            "So in the adversary setting, we don't know whether you can have similar adaptive algorithms that we have for the stochastic setting.",
            "And we don't have currently results for prediction with side information.",
            "And in the stochastic setting in this logistic regression case, it would be interesting to see whether you can have a lower complexity algorithm for prediction, because this could be just way too much if you know your dimension is large, than this is not feasible to run.",
            "Another direction for for further research is considered large action spaces like Co Metro sets, and we know that in some cases it's possible to avoid the commercial explosions.",
            "So the question is, to what extent would transfer to your setting so that closes this part of the presentation."
        ],
        [
            "Next part is closely related, so we are still going to learn with partial information feedback, but it's a little bit different model.",
            "So we call this framework the online probing framework.",
            "And the framework works like this.",
            "So this is prediction with side information.",
            "So you have some feature vector and there is an unknown label and that shouldn't be there.",
            "So the learner starts with not observing the feature vectors but the learner present past information has to reason about which feature vectors he wishes to observe.",
            "OK, so in this case the learner has chosen these two feature values and based on the two feature values the learner is going to make a prediction.",
            "In this case the prediction is 0.",
            "And then a loss is going to be computed.",
            "In this case, let's say it's a binary loss, so the loss is going to be just one.",
            "OK, so the loss is not necessarily revealed to the learner, so next the learner has the choice of.",
            "Seeing the label and if the learner chooses to see the label, then he's going to gain information about his choice.",
            "Choose his choices.",
            "Otherwise, he's not going to gain any information.",
            "About whether the prediction was good or not.",
            "And so in this model, the.",
            "Observing the features is not for free, and observing the labels is not for free, but there are costs associated to them, so those are those things over C1 to C6 and in this particular setting, or in this particular case, the learner has chosen to observe these things, so that's up to that cost.",
            "Plus there is a loss of unity, so the total cost for the learner for this round is going to be this number.",
            "OK, so there's the."
        ],
        [
            "OK, So what do we want to compete with?",
            "So here is here is the regret.",
            "So what are the quantities in the regret?",
            "So first, so there is a sequence of loss functions that are chosen, and so the learner is predicting something.",
            "So that's the loss that the learner is going to suffer due to that and the learner is going to choose a subset of the features to observe, and each of them is.",
            "Right, so there is a cost to observing the features and so that makes up the total loss of the learner.",
            "I know what do we want to compete with.",
            "So first of all, the company doesn't need to see the label right?",
            "So we're just competing with static mappings that are mapping from site information to predictions and so there is no way you can put in the cost of the labels.",
            "So you can't really force.",
            "The best choice, in hindsight to look at the neighbors, the labels.",
            "So given any function F. You take a look at what features that function is going to need.",
            "So think about you know linear functions and some zero coefficients.",
            "Then you can omit a lot of features maybe, and so the competitor is going to pay a price for observing those features too.",
            "And of course the competition is going to suffer prediction losses fast, so so you want to compete with the best predictor in hindsight and difference again, is."
        ],
        [
            "Is the regret so in this case you are also trading off the acquisition costs like a direct acquisition cost for the information concerning the feature values.",
            "So that's kind of the novel element here and."
        ],
        [
            "So the question is, what can you do?",
            "So in one setting a simple setting is when or simple node shouldn't say that.",
            "One setting is when all the labor costs are zero, and then naturally the learner is going to choose to see the label in every time step because it's for free.",
            "So we took away one aspect of the problem."
        ],
        [
            "And so in this case you can start really general and so for example, you can say that let's assume only that the losses are Lipschitz with respect to some metric in the outcome space, and so notation is that for using a predictor F you need this features and.",
            "And the as a small observation is that if you're using, if you decide to use some predictor and you're going to need some features for that predictor, than every other predictor that needs a subset of those features, you can avoid its underlying loss because you got to see the the label, so it was free.",
            "So the problem has this interesting information structure.",
            "This lattice structure.",
            "So depending on what predictors you are choosing, you can immediately see that you have to sort of reasonable.",
            "What you want to see?",
            "And so this leads to this graph where so you have this predictors in the nodes of the graph, and so the edges are going to tie you for which other predictors you're going to get the last information at the same time.",
            "If you're choosing one of these predictors.",
            "So if you choose something about choosing a predictor in order to be able to use this predictor, and the example provided, provided you didn't see the side information, you need to add the features.",
            "So if you're asking those features, then for any other predictor that uses subset of those features.",
            "You can also avoid the loss of that predictor like the loss on that example.",
            "OK, so this leads to this graph and actually turns out that this is just if you're concentrating on this simple case, then let's say you have a finite F and this is special case of a model that was studied by Cheyenne Omar in 2011 and they call this value upside side observations and they have a general result that goes like this.",
            "So they allowed the graphs to variety, and they're competing with a finite set F. And so yeah, they have this graphs, and that's the regret they have and high is there the clique number of the graph.",
            "And so in our case, in the worst case, the click number is going to be 2 to the D, and that's quite very some I would say.",
            "But anyways, so that's the result that you can derive.",
            "No, it appears that they have also proven lower bounds.",
            "In your case the lower bonds are going to match these two to the factors in the worst case sort of there is nothing that you could do about this factor over there what you can.",
            "Hope doing is that.",
            "Well, maybe you know you have to choose.",
            "I think functions that do not require that many features because otherwise it's just going to be there.",
            "So it's sort of too expensive to explore all the subsets of the features, yes?",
            "GT is this.",
            "Oh, that's it.",
            "That's OK.",
            "So if you generalize this then you could say that every time step a graph is announced to you and the graph is telling you which other for which other nodes in the graph you're going to see the feedback.",
            "Yeah, that's GT.",
            "So it's just a small observation that in this case is the problem.",
            "The uses to their problem, and therefore you can just use the regret results."
        ],
        [
            "So of course you can go further than that.",
            "Usual covering tricks, you can derive bonds for Lipschitz losses using cover covering numbers.",
            "For example if you have linear predictors, then you're going to arrive at a regret bond that looks like this, so you still are going to have the two to the D factor, but other than that the regret kind of behaves the usual fashion.",
            "It's root tea ish.",
            "So.",
            "That's alright, but it's a little bit disappointing, right?",
            "So you have these two to the D. Whether you can do any any better.",
            "In the worst case we know you can't do any better.",
            "So what can we do so things that we're trying to do?",
            "In those cases we try to impose some additional structure on the problem to see whether you can do any better, right?",
            "So one such."
        ],
        [
            "Factor is to think about what happens in linear regression with quadratic losses, so that's a beautiful structure, right?",
            "So you have linearity, you have quality losses.",
            "So what I'm talking, what am I talking about?",
            "So the loss is going to be just the squared loss, and so the linear prediction is just takes the inner product between the weight vector of your choice and the side information, and so the nice structure that comes out of this is that you can expand this right?",
            "So you are going to have a quadratic term.",
            "As a function of your W and you have linear term plus you have a constant.",
            "If you're expanding the loss and the idea in this case is just too well.",
            "The key of these algorithms is whether you are able to estimate in an efficient fashion the loss.",
            "Buying using some randomization maybe?",
            "And so if you're looking at this loss, you try to estimate it.",
            "What is the unknown here?",
            "So you know, WS of course, and you got to see the labels, so YT.",
            "So that's the real value number in this case, so that's not unknown.",
            "XT is going to be in, there are no, so you try to estimate the site information and this underlying matrix and the underlying vector, and so.",
            "After thinking about this a little bit, it's not not hard to come up is unbiased estimate of these quantities.",
            "So let's say that you're choosing a vector with some probability from some finite set.",
            "So let's say we still do some discretization of the weight space.",
            "Then you can define what is the probability of observing a particle feature under this probability distribution, and what is the probability of observing a pair of features OK, and what you can do is that you can estimate the individual components.",
            "Of the feature vector.",
            "By dividing this with this probability.",
            "This product, which is just the indicator whether you have observed the feature and.",
            "And the site information.",
            "And of course, if you chose not to observe some feature, then this is just going to be a big O and otherwise what happens is that you just divide with this probability OK and you can do the same with this author product matrix.",
            "So this matrix is just the outer product of xtian XDXD transpose.",
            "It's a product that product.",
            "So to estimate the individual elements you do the same with this pairs of probabilities.",
            "So you're just debiasing the.",
            "The information that you have and these are unbiased estimates, so it seems that that you can gain maybe way more information in this setting, because right now, well, you have the loss for any WF your interest OK?",
            "OK.",
            "So if you throw this in this idea in an basean, this idea is actually I have seen her hand in the work of cheese a Bianchi and I'll when they were talking about this in a different setting.",
            "When you have this budget prediction problems.",
            "Then you throw in this criticism."
        ],
        [
            "And then just discretization to the horizon and use an exponential weights algorithm on and.",
            "On the top of everything.",
            "Then you can derive this bond.",
            "So the nice thing about this bond this regret bound is that it's scarce polynomial Indy in particle, it's gets really nicely with the dimension D, so the other quantities are, you know, just the sum bonds and do an arm of the weight vectors and the norm of the site information vectors and the limits bounds on how big the labels, how big values delivers can take.",
            "And there are some other quantities appearing, but the main thing here is that you reduce like you manage to reuse the exponential dependence on the.",
            "So it seems that structure really does help, and you can prove a matching lower bond up to constant factors.",
            "So that's very nice.",
            "On the other hand, yes.",
            "Independent from the dimension, because you've got two different right?",
            "Right so.",
            "So for example, yeah, so for example, if you depending on what norm you choose, right?",
            "So I mean like.",
            "Sure, like it's, that's why I'm showing this expression because, but it's a question of like which boss you like to sing about.",
            "We were thinking about Dua boards then, then it's not a problem, but you know, if the situation is more nasty than it's not so nice.",
            "So if the board at your weight vectors are coming from and is not the door board to the board at the site information is coming from, then you are going to suffer a penalty.",
            "That is the ratio between you know the.",
            "Alright, so it may or may not depend on the dimension.",
            "You can make it as large as the.",
            "That's a good point.",
            "So.",
            "This is all nice, but remember that in order to get this result we had to discretize and you're discretizing and then it's going to be like T to the D or what not.",
            "Where is that?",
            "You have to keep track of an.",
            "So the question is whether you can do this computation efficient manner and we were trying to do this and.",
            "Say that we have some ideas, but this remains an open question up to now."
        ],
        [
            "OK, So what happens when the labels are costly so when the labels are costly, in some situation in some way the situation is is simpler.",
            "So we already are overpaying.",
            "I.",
            "So because the competitor doesn't have to pay for the labels and we have to pay for the labels.",
            "And this then is in some sense just more complicated instance of what is known as label efficient prediction from the expert setting.",
            "And then you can realize that you can as well decide for seeing all the features because it's just entered the constant that you are paying in your regret, and so somehow if you have, the label is costly than the game is not so interesting and you can actually in this case use an exponential weights algorithm and and flip a coin every time step.",
            "We say well adjusted probability to decide whether you want to.",
            "See the feedback I guess.",
            "And you can implement the whole algorithm efficiently for the linear regression case.",
            "So going to have an efficient algorithm in this case.",
            "But the regret is going to scale with T to the 2/3, and in this case we have matching lower bound.",
            "That shows that you cannot go below that, and that's exactly because you're already paying too much for the label.",
            "The competitors do not really have to pay for the label.",
            "So that's all fine."
        ],
        [
            "What we see in this case so that the slide that explains why we're talking about monetary does is that it seems that like there is a tradeoff between computation costs here and these other two things, prediction accuracy and information acquisition cost.",
            "And so we see that like on one hand, if you are, if you're willing to give a prediction accuracy, then you can boil down to this simple coin flipping argutum, at least in the linear regression keys and get a regret bond that scarce like T to the two third.",
            "But if you want to get the Ruthie regret bond than we currently don't know if that is possible to do in a computation efficient manner.",
            "We believe that it should be possible to do."
        ],
        [
            "Alright, so that leads to these open problems.",
            "So one of the problems is what do you have trackable?",
            "Can you design tractable algorithms for regression when you're competing with small subsets of features?",
            "And and what is exactly the?"
        ],
        [
            "The tradeoff between these two things, so the last thing that I like to talk about is that, like, imagine that you're trying to scale this up and put this on servers, so the service is serving the customers and so the customers arriving at at this web servers and there's a high frequency interaction going on, so the engineers in the company that you're working for a very variety of you touching this server so they don't allow you to do that.",
            "They are going to download some batch of data after that.",
            "Hi, maybe you know every minute or every half an hour or what not to your server so to the production servers and then you can retrain your models and then you can upload the retrain models to the server.",
            "So what you're going to see here is that there could be that there will be some delays right?",
            "So the interaction is happening at high frequency.",
            "Your model updates are happening at the lower frequency.",
            "Is this going to influence in a very harsh manner that the regret that you're going to suffer?",
            "So that's an interesting question."
        ],
        [
            "And so here is.",
            "Here is a simplified model for studying this question.",
            "So let's assume that the delays that you're suffering at random and there are I ID.",
            "So you have the learner chooses an action that goes to the environment and the environment is going to give a feedback to the learner that is, in every time step a sequence of Rivard and timestamp pairs.",
            "So everything is timestamped here.",
            "So when you're sending an action, then you put the time stamp on it, and then it carries with that and then.",
            "Information that is coming back, carriers that time steps so that you can identify which action the information that you are receiving belong to.",
            "So here is so you got the rewards and you get this time stamps and then the learner can update whatever is strategies and the process continue."
        ],
        [
            "Potentially this sequence could be empty and many, many cases it's just going to be empty, so the learner is not receiving information.",
            "So in that case K is going to be one.",
            "So in this case a different trade authorizes.",
            "The development, deployment cost, convenience, maintenance cost versus prediction accuracy right so the reason we do this is because of convene."
        ],
        [
            "Yes, right?",
            "It turns out that well, of course people have studied learning with delayed information in the past, and what we figured what was missing is.",
            "What is the penalty that you have to pay?",
            "If you are learning under, this delays when there is no style information and there is bandit feedback.",
            "And of course you could say, well that's stupid because side information is more than no sign information and you see that the penalty is going to be additive here.",
            "The penalty is going to be multiplicative.",
            "There are some matching lower bonds here and there in the literature."
        ],
        [
            "For the full information case and so results are just this so.",
            "In the stochastic setting, when there is no site information, then the penalty that you are going to pay in the regret is just additive and it's chaos with the expected number of the Maxim of the delays up to a certain time stamp.",
            "So we don't really like this Maxim here, but we don't know if it's possible to remove that.",
            "And in the adversary case the penalty is going to be multiplicative and its gases square root of the same quantity.",
            "So that's."
        ],
        [
            "Result and so.",
            "I'm going to show very quickly how we are going to achieve this in that versus setting.",
            "This is a reduction and there was a paper by Weinberger, an ordentlich where they did something similar for the keys.",
            "When the delays are fixed an known so you know that you're going to suffer a constant delay, your feedback, and they they propose that particle thing and that you can generalize.",
            "And here is how it goes.",
            "So this is the machine that we are building.",
            "And it is just going to instant it.",
            "This learning machines and number of number of learning machine.",
            "So there are two Q is basically that the machines which are ready and the machines which are still waiting for feedback for the machines that are still waiting for feedback.",
            "So these numbers denote the timestamps for which they are waiting the feedback form.",
            "OK, so the interaction goes by picking the machine at the beginning of the queue.",
            "It doesn't really matter which, and that's going to suggest an action.",
            "OK, so the machine suggests an action."
        ],
        [
            "And then it's moved to the queue where you have the machines waiting for feedback.",
            "And that Q is reorganized and it receives the time step of the current time.",
            "OK, so that was how we produce an action.",
            "If this queue was empty, then the controller would just pen and you knew machine.",
            "So then the feedback arrives and the feedback is for particle timestamps.",
            "So we have these two rewards in this case that arrived and you give the rewards to the machines that are waiting for that particular event.",
            "So you see that reward one is for this machine and rewards two is for that other machine.",
            "OK."
        ],
        [
            "So give them those rewards.",
            "And no, they are not waiting anymore so they can be moved to the other queue.",
            "And this is how the process continues and the key observation here is the number of machines that are waiting can be upper bounded by well T + 1 and so the minimum of T + 1 and the maximum delay that occurs between one and T. And so if you do that then after a short cock."
        ],
        [
            "Addition, you can you can get the regret bond that that I've shown to you an so here.",
            "I also have some open questions.",
            "So let's say the delayes do not depend.",
            "So in the previous case the delays didn't depend on the action that you're choosing, so it's kind of a network setting and the days were assumed to be I ID.",
            "And the problem is this Max.",
            "There is that this could grow in a log rhythmic fashion, right?",
            "So if you take this.",
            "Maxim and then you take the expectation can grow with N, so it could be hiding a logarithmically fashion.",
            "The advantage compared to the previous bond is that if the delays are upper bounded then of course is not going to grow right.",
            "So then you are going to just get the upper bound you are getting closer to the upper bound as time goes by.",
            "So can we replace this expectation with just the expectation of the delay?",
            "So so I don't know.",
            "Alright, so we don't currently have lower bounds for the stochastic setting and we have just done extension to partial monitoring and prediction with side information, so that's not not open anymore so we can do that."
        ],
        [
            "Alright, so with that I'd like to conclude.",
            "So my conclusion is that the other few tradeoffs that we can handle Valve and some tradeoffs require very delicate tuning.",
            "As you can see from the graph.",
            "And there are many challenging problems that remain.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So welcome everyone.",
                    "label": 0
                },
                {
                    "sent": "The best fire from.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "New way and this is joint work with on Russian Tosh, Gabor Bartock, polio, chulani, an unregistered, David Parland vids.",
                    "label": 0
                },
                {
                    "sent": "Oh God.",
                    "label": 0
                },
                {
                    "sent": "Bunch of students and bunch of senior colleagues that I was very happy to work with.",
                    "label": 0
                },
                {
                    "sent": "On this topic.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I'm planning to talk about learning this partial information, feedback, training of exploration and exploitation.",
                    "label": 1
                },
                {
                    "sent": "And talking about computational issues that arise if you're getting into some of these problems.",
                    "label": 0
                },
                {
                    "sent": "And also learning with delayed feedback.",
                    "label": 1
                },
                {
                    "sent": "So they jump in.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I'd like to start with passion monitoring and with an example.",
                    "label": 1
                },
                {
                    "sent": "So imagine that, well, you are the learner trying to set an item.",
                    "label": 0
                },
                {
                    "sent": "Maybe the item is, you know, just some commodity.",
                    "label": 0
                },
                {
                    "sent": "Like video camera and you're trying to set the price of the item.",
                    "label": 0
                },
                {
                    "sent": "OK, so you're trying to set this on, let's say on the website so customers coming to your website.",
                    "label": 0
                },
                {
                    "sent": "Maybe it's an ID process, maybe it's like who knows what.",
                    "label": 0
                },
                {
                    "sent": "And they have some.",
                    "label": 0
                },
                {
                    "sent": "Price in their minds and you're trying to set the price.",
                    "label": 0
                },
                {
                    "sent": "If you overprice or underprice depending on that, you're going to get this binary feedback signal whether you sold or not OK, what is missing here and what the learner is really interested in is to maximize the revenue right?",
                    "label": 0
                },
                {
                    "sent": "And so to be able to tell whether you're maximizing the revenue you would need need to need to know.",
                    "label": 0
                },
                {
                    "sent": "Maybe the price that the customer had in mind, right?",
                    "label": 0
                },
                {
                    "sent": "So if you had the price.",
                    "label": 0
                },
                {
                    "sent": "Then you kind of losing the difference between what the customer had in mind and your price, and if you overprice then the temp remains with you on the top you are going to pay some storage costs.",
                    "label": 0
                },
                {
                    "sent": "So here is a simplified setting.",
                    "label": 0
                },
                {
                    "sent": "For the dynamic pricing case, so you can capture this with the loss matrix so you are the role player, the learner is low player.",
                    "label": 1
                },
                {
                    "sent": "Selecting one of these prices zero 10 or 20 and the customer coming to the website environment is going to pick some other prices and then depending on how you're picking the prices there is some loss that the learner suffers.",
                    "label": 0
                },
                {
                    "sent": "And the feedback signal or the feedback matrix is just a binary matrix.",
                    "label": 0
                },
                {
                    "sent": "So if you go with your price above the price of the customer, then you are going to sell.",
                    "label": 0
                },
                {
                    "sent": "It's a plus, otherwise it's minus.",
                    "label": 0
                },
                {
                    "sent": "And but if you're under pricing, then and the customer, let's say you're choosing this row, so you choose $10, the customers choosing $20, then you're going to lose $10 'cause you could have priced higher.",
                    "label": 0
                },
                {
                    "sent": "So the question is, how efficiently can you learn in this situation in order to be able to measure efficiency, one measure that you could use is regret.",
                    "label": 0
                },
                {
                    "sent": "So you take the losses that you are suffering at your choice of actions and opponents choice of price.",
                    "label": 1
                },
                {
                    "sent": "So it is your choice.",
                    "label": 0
                },
                {
                    "sent": "JFT is the opponent choice.",
                    "label": 0
                },
                {
                    "sent": "And you compare this, let's say in a stochastic situation when the opponent is playing a stochastic policy with the best price.",
                    "label": 0
                },
                {
                    "sent": "That, or with the best possible laws that you could have gotten if you have chosen the best price in high side.",
                    "label": 0
                },
                {
                    "sent": "And you know you want to keep this regret low and the question is how low can you keep this regret in bandit problems?",
                    "label": 0
                },
                {
                    "sent": "We got used to the idea that in full information problems swear that the regrets going growing at the rate of root T in some other problems, we know that the regret might be growing faster and the question is if I give you these two matrices, the last matrix and the feedback matrix, what is the rate of growth of the regret?",
                    "label": 0
                },
                {
                    "sent": "How do we determine this on a case by case basis?",
                    "label": 0
                },
                {
                    "sent": "Do we need to develop a solution for each game or not?",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right, so this is talking about the basic tradeoff between information acquisition costs and prediction accuracy, right?",
                    "label": 1
                },
                {
                    "sent": "So you have to.",
                    "label": 0
                },
                {
                    "sent": "Reason about which action to choose?",
                    "label": 0
                },
                {
                    "sent": "Do you want to choose an action to gain some information or you go with your choice with the choice that seems to be the best given all the knowledge that you have.",
                    "label": 0
                },
                {
                    "sent": "Alright, so after Y as you were playing this game, you might learn something about Apanas distribution and then whether you want to choose the action that is currently the best in terms of the losses or whether you will not explore something at the fashion and at what age you should do that.",
                    "label": 0
                },
                {
                    "sent": "So what's the Prince?",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This way of doing that, right?",
                    "label": 0
                },
                {
                    "sent": "So the solution to this problem boils down to the following things.",
                    "label": 1
                },
                {
                    "sent": "So you start with the probability distribution over over the opponents choices.",
                    "label": 1
                },
                {
                    "sent": "The outcomes I'm going to call those outcomes and so that gives you the probability simplex and given the last match loss matrix.",
                    "label": 0
                },
                {
                    "sent": "What you can do is that you can partition the probability simplex into this convex sets such that within each cell particulare action of yours is the best possible choice.",
                    "label": 0
                },
                {
                    "sent": "OK, so in this cell are all the probability distributions for the opponent such that action #4 is the best one?",
                    "label": 0
                },
                {
                    "sent": "OK, so this is solely determined by the loss matrix, so the last matrix imposing this structure and the probability simplex.",
                    "label": 0
                },
                {
                    "sent": "And if you look at this partitioning, you can abstract away the details of the partitioning.",
                    "label": 0
                },
                {
                    "sent": "What is important about this partitioning is which actions are neighbors to each other.",
                    "label": 0
                },
                {
                    "sent": "So from this graph or from this cell, the composition, you can see that one and two and one and three are neighbors, three and four, and two and four are neighbors.",
                    "label": 0
                },
                {
                    "sent": "I missed two and three, that's alright.",
                    "label": 0
                },
                {
                    "sent": "Correct, yeah I had a different figure before and then it was great.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "But at least someone is not sleeping.",
                    "label": 0
                },
                {
                    "sent": "OK, so where is the feedback structure right?",
                    "label": 0
                },
                {
                    "sent": "Whereas the feedback structure come in?",
                    "label": 0
                },
                {
                    "sent": "So in order to explain how the feedback structure is going to influence how you should play the game, I need some notation.",
                    "label": 0
                },
                {
                    "sent": "So let's say the opponent has M choices and all the losses are between zero and one.",
                    "label": 1
                },
                {
                    "sent": "So you have this vector LFI for action.",
                    "label": 0
                },
                {
                    "sent": "I OK that gives all the losses for the opponent.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's just the way of like talking about the rows of the.",
                    "label": 0
                },
                {
                    "sent": "Las matrix OK, so let's say the opponent is is playing according this distribution P star.",
                    "label": 0
                },
                {
                    "sent": "OK, so if the opponent is playing at distribution so that somewhere here in this outcome space, but that induces a distribution an the feedbacks that you're going to see the different feedback signals pass and minus is how probable is to see a plus versus how probabilities C minus.",
                    "label": 0
                },
                {
                    "sent": "So it's clear that this relationship can be encoded with the matrix, right?",
                    "label": 1
                },
                {
                    "sent": "We call that the signal matches because that encodes the structure of the feedback.",
                    "label": 1
                },
                {
                    "sent": "That you're going to receive, right?",
                    "label": 0
                },
                {
                    "sent": "So then, what is important is that, well, in order if you want to play a game like this or any game, what's important is to decide whether you should play action I or action J, right?",
                    "label": 0
                },
                {
                    "sent": "So if you can design it for every pair of actions and you should be fine.",
                    "label": 0
                },
                {
                    "sent": "So just take a pair of actions inj and this is the regret if you would be paid if you would be playing action chain instead of action I I believe.",
                    "label": 0
                },
                {
                    "sent": "Right, so switching from I to J.",
                    "label": 0
                },
                {
                    "sent": "This is the revenue that you would be able to get and so if the following relationship holds, there exists two vectors V1 and V2 such that this last difference can be expressed in this form.",
                    "label": 0
                },
                {
                    "sent": "Then you have a chance of estimating this loss difference and if you know this last difference then from that point on you know you can reason with different ways.",
                    "label": 0
                },
                {
                    "sent": "So for example, if you know the last differences for all the actions, then you can quickly figure out which action is the best.",
                    "label": 0
                },
                {
                    "sent": "OK, so the key is going to be one of the key elements is going to be whether you can figure out this last differences.",
                    "label": 0
                },
                {
                    "sent": "Whether this V1 and V2 vectors exist and this is just a linear algebra relationship, you can sort of simplify this peace studies.",
                    "label": 0
                },
                {
                    "sent": "This has to hold for any P star, so we won and we 2 cannot depend on P star.",
                    "label": 0
                },
                {
                    "sent": "And so that's just a constraint.",
                    "label": 0
                },
                {
                    "sent": "And whether the Li minus edgy vector is lying in the span of some mages.",
                    "label": 0
                },
                {
                    "sent": "OK, so if this holds actually, but turns out that going back to the structure that we have extracted from the last matrix.",
                    "label": 0
                },
                {
                    "sent": "So if it it holds for all pairs of I&J in this graph.",
                    "label": 0
                },
                {
                    "sent": "So Paris I&J, which are neighbors in this graph, that Ally minus LJ lies in the span of this appropriate matrix.",
                    "label": 0
                },
                {
                    "sent": "Just stacking SI&J on the top of each other.",
                    "label": 0
                },
                {
                    "sent": "Then we say that the game is locally observable, yes?",
                    "label": 0
                },
                {
                    "sent": "Sigh, OK.",
                    "label": 0
                },
                {
                    "sent": "It seems when you're playing an action, I actualize what the yeah yeah, then the symbols that you see you could assign different values to.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so unify the.",
                    "label": 0
                },
                {
                    "sent": "You have to use a unified off, but actually it's well.",
                    "label": 0
                },
                {
                    "sent": "It actually doesn't really matter which you can choose a different alphabet.",
                    "label": 0
                },
                {
                    "sent": "OI yeah, different distribution would that?",
                    "label": 0
                },
                {
                    "sent": "Would that affect the possibility of getting this window?",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "It doesn't really matter.",
                    "label": 0
                },
                {
                    "sent": "It's it's really about the information that you're collecting, like how much you can reason back from this distribution to be star.",
                    "label": 0
                },
                {
                    "sent": "OK, but it's all like here.",
                    "label": 0
                },
                {
                    "sent": "The important thing is that everything has to be relative, just two losses.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "But for the sake of simplicity, you can think about that for all the rows like you're sharing the symbols as much as you can, but.",
                    "label": 0
                },
                {
                    "sent": "So I guess it's obvious if their zeros and ones, but for big around that doesn't matter, doesn't matter.",
                    "label": 0
                },
                {
                    "sent": "One choice of symbols, sure, like you can.",
                    "label": 0
                },
                {
                    "sent": "You can permit things right?",
                    "label": 0
                },
                {
                    "sent": "It's a permutation.",
                    "label": 0
                },
                {
                    "sent": "OK. Alright, so again so you have this neighborhood structure and so for each neighbors in this graph, it holds that allion alignment said J is in the span of this step signal matrices.",
                    "label": 0
                },
                {
                    "sent": "Then we say that the program the problem is locally observable.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "OK, so that's connecting up the feedback structure with the last structure, and that's basically all what we need to.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Able to prove this theorem that says that no matter what kind of feedback matrix an last matrix you give to us, it's going to belong to one of the four categories, one of four categories.",
                    "label": 0
                },
                {
                    "sent": "Either it's a trivial game or hopeless game to do that, trivial to classify, or it's kind of behaving the same as a bandit game.",
                    "label": 0
                },
                {
                    "sent": "So we call these games easy or full information for that matter, or it could be a harder game.",
                    "label": 0
                },
                {
                    "sent": "And there is nothing in between, so these exponents.",
                    "label": 0
                },
                {
                    "sent": "If you are ordering them on the 01 interval, what you're going to see is that, like 0 is possible, one is possible, 1/2 is possible, 2 third is possible.",
                    "label": 0
                },
                {
                    "sent": "This interval is empty.",
                    "label": 0
                },
                {
                    "sent": "That interval is empty on this interval is empty.",
                    "label": 0
                },
                {
                    "sent": "So by the way.",
                    "label": 0
                },
                {
                    "sent": "So there was a bunch of previous work works.",
                    "label": 0
                },
                {
                    "sent": "And of course people started with full information games and Wolf can littlestone environment were the one who said that OK for full information games you are going to have this exponent.",
                    "label": 0
                },
                {
                    "sent": "At 1/2 and then for the bandits, overran coworkers figured out the same thing.",
                    "label": 0
                },
                {
                    "sent": "The model is due to Pico Boney and Shinde hardware who had some cool ideas about this observability so we were recycling one of their a few other ideas and Nicole and Gabor figured out that this interval is basically empty and they pushed on their upper bounds to 2/3.",
                    "label": 0
                },
                {
                    "sent": "And So what we figured out is basically that this interval is empty, so that's kind of for the contribution here.",
                    "label": 0
                },
                {
                    "sent": "OK, so that that is a full characterization of all these games in the stochastic setting, and then it turns out that the same characterization actually applies in the adversary setting, and that is recent work by Adele Foster and Sasha Rakhlin, which was published at AI Stats Alright.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So that's good so far.",
                    "label": 0
                },
                {
                    "sent": "So there is dynamic pricing.",
                    "label": 0
                },
                {
                    "sent": "How does it look?",
                    "label": 0
                },
                {
                    "sent": "OK?",
                    "label": 0
                },
                {
                    "sent": "So if you do the calculation with dynamic pricing then what you see is that you're going to have click, so every action is going to be a neighbor of every other action, so it's hard to depict this in higher dimensions.",
                    "label": 0
                },
                {
                    "sent": "So if you have just three choices, then this is the picture that you are going to have.",
                    "label": 0
                },
                {
                    "sent": "And what this entails is that the non consecutive pairs affections.",
                    "label": 0
                },
                {
                    "sent": "Well if you look at the feedback structure, then you, like every action is a neighbor in this graph, right?",
                    "label": 0
                },
                {
                    "sent": "And the prices are ordered right?",
                    "label": 0
                },
                {
                    "sent": "And the prices which are not neighbors in this ordering but neighbors in the graph, and many of them they are not local observable.",
                    "label": 1
                },
                {
                    "sent": "You need to use some other action to figure out the difference between the two.",
                    "label": 0
                },
                {
                    "sent": "So there's the structure of the game for dynamic pricing, and then that tells that the regrets going to grow at the rate of three to the 2/3.",
                    "label": 1
                },
                {
                    "sent": "Actually, that's the exact rate of growth of the regret.",
                    "label": 0
                },
                {
                    "sent": "So that's kind of a disappointing answer, yes.",
                    "label": 0
                },
                {
                    "sent": "Can you repeat?",
                    "label": 0
                },
                {
                    "sent": "What are the actions?",
                    "label": 0
                },
                {
                    "sent": "Excellent, actually the price.",
                    "label": 0
                },
                {
                    "sent": "Yeah, you're setting one of the prices like so why?",
                    "label": 0
                },
                {
                    "sent": "So if you have 1020 and 30 by 30 is number of 10.",
                    "label": 0
                },
                {
                    "sent": "Well it sort of comes back like that's kind of showing the situation here.",
                    "label": 1
                },
                {
                    "sent": "It's like there are certain distributions that like kind of unnatural distributions.",
                    "label": 0
                },
                {
                    "sent": "If you are thinking about it that prefer one and three, and I just don't prefer to.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So it's kind of bimodal distributions or all kind of crazy stuff.",
                    "label": 0
                },
                {
                    "sent": "So it's some kind of where customers that winning by four 103 but not for two.",
                    "label": 0
                },
                {
                    "sent": "Yeah, something like that.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so if you start to think about it then you can see that, for example, if you would have some unimodal distributions with nice decaying things, then this is not going to happen at all.",
                    "label": 0
                },
                {
                    "sent": "OK, so the question is how strange that is distributions and thanks for the question.",
                    "label": 0
                },
                {
                    "sent": "That's actually what we were wondering about.",
                    "label": 0
                },
                {
                    "sent": "Whether whether this game is necessary that hard in your life, right?",
                    "label": 0
                },
                {
                    "sent": "So it's kind of disappointing that you can.",
                    "label": 0
                },
                {
                    "sent": "Only only learn at this slow rate.",
                    "label": 0
                },
                {
                    "sent": "And so this distributions, I would think that they are sort of strange and.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The question then, whether you can develop an algorithm that is able to, you know, just add up to the distribution of the.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Opponent, so if the opponent is playing somewhere here or somewhere there or somewhere here or somewhere there.",
                    "label": 0
                },
                {
                    "sent": "Further away from this danger zone.",
                    "label": 0
                },
                {
                    "sent": "Right then, can you get an algorithm that not knowing whether opponents playing is still going to get you know, good regret rate?",
                    "label": 0
                },
                {
                    "sent": "Maybe Ruthie regret rate.",
                    "label": 0
                },
                {
                    "sent": "So for example if you would eliminate part of this strategy space, can you get a route to regret rate?",
                    "label": 0
                },
                {
                    "sent": "So that's like imposing some constraints and the environment.",
                    "label": 0
                },
                {
                    "sent": "Of course, you don't know if the environment is going to play like that, so you can't just build this into your algorithm, so you need to adapt to weather the opponents playing B9 or malignant strategy.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And it turns out that it is possible to do this, so we have actually just done that.",
                    "label": 0
                },
                {
                    "sent": "So you need to have a more deliberate strategy for for doing this, But if you're doing this, then this just shows that this graph shows what happens if you're playing this dining pricing game.",
                    "label": 0
                },
                {
                    "sent": "So the Y axis is a minimax regret.",
                    "label": 0
                },
                {
                    "sent": "Lower values is better, and this is time if you're playing with our strategy values, you're playing with the strategy that conservatively sings at the opponent is going to play.",
                    "label": 0
                },
                {
                    "sent": "Worse case distribution.",
                    "label": 0
                },
                {
                    "sent": "OK, you see that?",
                    "label": 0
                },
                {
                    "sent": "Well, the regret is much lower.",
                    "label": 0
                },
                {
                    "sent": "Ann just studied this on an individual opponent strategy as well and put some confidence intervals and you can see that the differences could be pretty big.",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "You can not only tradeoff these two things, but you can do it in at adaptive fashion, at least in this case.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I'd like to so the next topic I like to talk about is prediction with side information.",
                    "label": 1
                },
                {
                    "sent": "OK, so in this setting so you have the learner, the environment and you have a feedback mechanism and it's going to be partial monitoring still.",
                    "label": 0
                },
                {
                    "sent": "So right now when you are selling an item, the customer comes to your web page, then some information is revealed about the customer.",
                    "label": 0
                },
                {
                    "sent": "OK, so maybe there are some cookies?",
                    "label": 0
                },
                {
                    "sent": "Sorry but not and how to use that information to minimize the regret.",
                    "label": 0
                },
                {
                    "sent": "So here is the situation.",
                    "label": 0
                },
                {
                    "sent": "He's learning setting.",
                    "label": 0
                },
                {
                    "sent": "So the environment is going to revert to you assign information vector and that could be chosen in adversary or fashion and at the same time the environment is going to choose an outcome from some distribution.",
                    "label": 0
                },
                {
                    "sent": "So maybe this distribution belongs to a parametric family of distributions, but you don't know the parameter OK?",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "As usually in partial monitoring games, well after you choose your action, you suffer loss.",
                    "label": 0
                },
                {
                    "sent": "You're going to get a feedback, so you're not going to see the last again, and you're not going to see the outcome, so you're not going to see why FT so all you got to see is the feedback, so it's in some sense and actually generalization of the previous framework.",
                    "label": 0
                },
                {
                    "sent": "OK, so the question is, what can you say in this case and how?",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To learn so before going there we should talk about what we are comparing yourself or South with.",
                    "label": 0
                },
                {
                    "sent": "OK, so here is the regret.",
                    "label": 0
                },
                {
                    "sent": "It looks a little bit more complicated than before hand, so let me explain the parts.",
                    "label": 0
                },
                {
                    "sent": "So this is just the total loss of the learner, so that's fine.",
                    "label": 0
                },
                {
                    "sent": "And static predictors.",
                    "label": 0
                },
                {
                    "sent": "So what we want to compete with is this static predictors, so they take the site information and given the site information they choose an action, they choose one of the actions, so you know the learner sees the side information.",
                    "label": 0
                },
                {
                    "sent": "That's what he sees at the beginning.",
                    "label": 0
                },
                {
                    "sent": "Then he has to choose an action.",
                    "label": 0
                },
                {
                    "sent": "So we're going to compete with these guys.",
                    "label": 0
                },
                {
                    "sent": "And if you take any of those, then this is just the expected total loss that you would suffer if you choose that.",
                    "label": 0
                },
                {
                    "sent": "Static predictor from the beginning of time and you're going to choose the best static predictor in hindsight, and then you compare two quantities and that's your regret.",
                    "label": 1
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the question is, what can you say?",
                    "label": 0
                },
                {
                    "sent": "And so this is the scary slide huge algorithm, but I'm going to take it apart for you.",
                    "label": 0
                },
                {
                    "sent": "It's pretty simple actually.",
                    "label": 0
                },
                {
                    "sent": "So the key is that you are trying to model the.",
                    "label": 0
                },
                {
                    "sent": "Distribution over the outcomes that imposes distributions over.",
                    "label": 1
                },
                {
                    "sent": "The things that you are observing the feedbacks.",
                    "label": 0
                },
                {
                    "sent": "So from your model, so this is an abstract algorithm.",
                    "label": 0
                },
                {
                    "sent": "This is an algorithm scheme that's going to work for many different settings.",
                    "label": 0
                },
                {
                    "sent": "From your model, you ask what is given the site information, what is the likely feedback distribution?",
                    "label": 0
                },
                {
                    "sent": "That's going to be QIT ODA.",
                    "label": 0
                },
                {
                    "sent": "And you are also going to ask the mother to supply some confidence intervals for this.",
                    "label": 0
                },
                {
                    "sent": "Distribution and then you start to reason about whether it is worse switching from one action to another by calculating this regret.",
                    "label": 1
                },
                {
                    "sent": "Expected regret quantities for pairs of actions in the neighborhood graph that you're going to have.",
                    "label": 0
                },
                {
                    "sent": "OK, and then you're going to eliminate the actions that are are suboptimal OK. And So what changes compared to the previous game?",
                    "label": 0
                },
                {
                    "sent": "If you're thinking about is that depending on the side information, peace studies at a different location in the simplex, so you have to reason about these different situations.",
                    "label": 0
                },
                {
                    "sent": "But the neighborhood graph is the same, and so it's kind of the same mesh thing that's going to apply here.",
                    "label": 0
                },
                {
                    "sent": "So given all this, you're going to eliminate the actions that are clearly suboptimal, so taking into account their confidences and then.",
                    "label": 0
                },
                {
                    "sent": "Both of the prospective actions that that remain you select the least known action.",
                    "label": 1
                },
                {
                    "sent": "And the reason for doing that is that you want to learn about those actions, right?",
                    "label": 0
                },
                {
                    "sent": "So if you have an action for which the confidence interval is really high, you want to learn about that action.",
                    "label": 0
                },
                {
                    "sent": "And that's actually a crucial part of the algorithm.",
                    "label": 0
                },
                {
                    "sent": "So you're going to choose that action.",
                    "label": 0
                },
                {
                    "sent": "After that, you observe the outcome, and then you can update your statistiques.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what can we say about this algorithm?",
                    "label": 0
                },
                {
                    "sent": "So this is a metal algorithm, a template.",
                    "label": 0
                },
                {
                    "sent": "So we start with this assumption and later on we show that in particle settings this assumption can be satisfied in particle choices of these parametric distribution family.",
                    "label": 0
                },
                {
                    "sent": "So the assumption just says that you have a learning mechanism.",
                    "label": 0
                },
                {
                    "sent": "So if you want this is kind of a reduction that is able to supply you these confidence intervals for the feedback distributions over the feedbacks.",
                    "label": 0
                },
                {
                    "sent": "We say sequence of confidences and some norm.",
                    "label": 0
                },
                {
                    "sent": "OK, and then the theorem goes that says that the expected regret can be decomposed into two parts.",
                    "label": 0
                },
                {
                    "sent": "One comes from your confidence intervals failing and you're going to be very conservative in estimating the regret coming from that and the other is going to come from how tight your confidence intervals are.",
                    "label": 0
                },
                {
                    "sent": "So what you see here is that in the regret bond, the width of the confidence intervals are going to appear OK, so this kind of an abstract result.",
                    "label": 1
                },
                {
                    "sent": "We don't know if this is good or not.",
                    "label": 0
                },
                {
                    "sent": "It's going to hinge upon whether you have a good underlying learning mechanism that for small deltas.",
                    "label": 0
                },
                {
                    "sent": "Can you give can give you small confidence intervals so just to give you a hint.",
                    "label": 0
                },
                {
                    "sent": "So what you want to do is that you want to choose this to something like 1 / T squared or something.",
                    "label": 0
                },
                {
                    "sent": "That sums to a small number.",
                    "label": 0
                },
                {
                    "sent": "Of course the confidence are going to explore this function of that, but we know that usually that explosion is not that bad, it's logarithm of.",
                    "label": 0
                },
                {
                    "sent": "One over that of T so we don't really have to worry about that part.",
                    "label": 0
                },
                {
                    "sent": "We have to worry about how like the statistical accuracy.",
                    "label": 0
                },
                {
                    "sent": "So if you can learn sort of at a rate of one over root tea, then like you know you're summing up one over root test.",
                    "label": 0
                },
                {
                    "sent": "You should be fine, so that's kind of the cheer stuff of the result, yes.",
                    "label": 0
                },
                {
                    "sent": "So in your definition of regret, you compared to all functions from X2, yeah.",
                    "label": 0
                },
                {
                    "sent": "Even in the full information case, it is impossible to obtain.",
                    "label": 0
                },
                {
                    "sent": "Now video video, it's implicit, so the reason is yeah, if you go back to the regret definition.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the reason is that we are working with this parametric families and and we are choosing like the parametric family is going to govern this choice, so that's implicitly parameterized.",
                    "label": 0
                },
                {
                    "sent": "Is the family so not going to compete with other functions?",
                    "label": 0
                },
                {
                    "sent": "You have a different function for injecting.",
                    "label": 0
                },
                {
                    "sent": "Suppose X is just, you know, all the natural numbers.",
                    "label": 0
                },
                {
                    "sent": "Yeah, well OK so so that's about like how fast you can learn about the theater star distribution.",
                    "label": 0
                },
                {
                    "sent": "So let's say you have full information given XD you want to learn about this distribution?",
                    "label": 0
                },
                {
                    "sent": "So what the situation that you are describing an tears that you have countably infinitely many parameters to estimate.",
                    "label": 0
                },
                {
                    "sent": "You can't do anything.",
                    "label": 0
                },
                {
                    "sent": "So it all boils down.",
                    "label": 0
                },
                {
                    "sent": "So that's why the other result is just the reduction result.",
                    "label": 0
                },
                {
                    "sent": "All boys done.",
                    "label": 0
                },
                {
                    "sent": "Whether this.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This learner that you should supply the confidence intervals is able to supply confidence intervals that are decaying fast.",
                    "label": 1
                },
                {
                    "sent": "So if you want to go nonparametric then you won't get the one over root two rate here, but you would get some verse written.",
                    "label": 0
                },
                {
                    "sent": "And of course if the parametric distribution family is so big that you can't even say anything about that, it's done so that kind of explains the mystery.",
                    "label": 0
                },
                {
                    "sent": "Thanks for the question alright.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "So for example, a simple case, so this parametric distribution model could be a multinomial logistic regression model.",
                    "label": 0
                },
                {
                    "sent": "In that case you can prove a regret bound like this based on the previous result that we had.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So some other open problems before I discuss some other things.",
                    "label": 0
                },
                {
                    "sent": "So in the adversary setting, we don't know whether you can have similar adaptive algorithms that we have for the stochastic setting.",
                    "label": 0
                },
                {
                    "sent": "And we don't have currently results for prediction with side information.",
                    "label": 1
                },
                {
                    "sent": "And in the stochastic setting in this logistic regression case, it would be interesting to see whether you can have a lower complexity algorithm for prediction, because this could be just way too much if you know your dimension is large, than this is not feasible to run.",
                    "label": 0
                },
                {
                    "sent": "Another direction for for further research is considered large action spaces like Co Metro sets, and we know that in some cases it's possible to avoid the commercial explosions.",
                    "label": 0
                },
                {
                    "sent": "So the question is, to what extent would transfer to your setting so that closes this part of the presentation.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Next part is closely related, so we are still going to learn with partial information feedback, but it's a little bit different model.",
                    "label": 0
                },
                {
                    "sent": "So we call this framework the online probing framework.",
                    "label": 1
                },
                {
                    "sent": "And the framework works like this.",
                    "label": 0
                },
                {
                    "sent": "So this is prediction with side information.",
                    "label": 0
                },
                {
                    "sent": "So you have some feature vector and there is an unknown label and that shouldn't be there.",
                    "label": 0
                },
                {
                    "sent": "So the learner starts with not observing the feature vectors but the learner present past information has to reason about which feature vectors he wishes to observe.",
                    "label": 0
                },
                {
                    "sent": "OK, so in this case the learner has chosen these two feature values and based on the two feature values the learner is going to make a prediction.",
                    "label": 0
                },
                {
                    "sent": "In this case the prediction is 0.",
                    "label": 0
                },
                {
                    "sent": "And then a loss is going to be computed.",
                    "label": 0
                },
                {
                    "sent": "In this case, let's say it's a binary loss, so the loss is going to be just one.",
                    "label": 0
                },
                {
                    "sent": "OK, so the loss is not necessarily revealed to the learner, so next the learner has the choice of.",
                    "label": 0
                },
                {
                    "sent": "Seeing the label and if the learner chooses to see the label, then he's going to gain information about his choice.",
                    "label": 0
                },
                {
                    "sent": "Choose his choices.",
                    "label": 0
                },
                {
                    "sent": "Otherwise, he's not going to gain any information.",
                    "label": 0
                },
                {
                    "sent": "About whether the prediction was good or not.",
                    "label": 0
                },
                {
                    "sent": "And so in this model, the.",
                    "label": 0
                },
                {
                    "sent": "Observing the features is not for free, and observing the labels is not for free, but there are costs associated to them, so those are those things over C1 to C6 and in this particular setting, or in this particular case, the learner has chosen to observe these things, so that's up to that cost.",
                    "label": 0
                },
                {
                    "sent": "Plus there is a loss of unity, so the total cost for the learner for this round is going to be this number.",
                    "label": 1
                },
                {
                    "sent": "OK, so there's the.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, So what do we want to compete with?",
                    "label": 0
                },
                {
                    "sent": "So here is here is the regret.",
                    "label": 0
                },
                {
                    "sent": "So what are the quantities in the regret?",
                    "label": 0
                },
                {
                    "sent": "So first, so there is a sequence of loss functions that are chosen, and so the learner is predicting something.",
                    "label": 0
                },
                {
                    "sent": "So that's the loss that the learner is going to suffer due to that and the learner is going to choose a subset of the features to observe, and each of them is.",
                    "label": 0
                },
                {
                    "sent": "Right, so there is a cost to observing the features and so that makes up the total loss of the learner.",
                    "label": 0
                },
                {
                    "sent": "I know what do we want to compete with.",
                    "label": 0
                },
                {
                    "sent": "So first of all, the company doesn't need to see the label right?",
                    "label": 1
                },
                {
                    "sent": "So we're just competing with static mappings that are mapping from site information to predictions and so there is no way you can put in the cost of the labels.",
                    "label": 0
                },
                {
                    "sent": "So you can't really force.",
                    "label": 0
                },
                {
                    "sent": "The best choice, in hindsight to look at the neighbors, the labels.",
                    "label": 0
                },
                {
                    "sent": "So given any function F. You take a look at what features that function is going to need.",
                    "label": 0
                },
                {
                    "sent": "So think about you know linear functions and some zero coefficients.",
                    "label": 0
                },
                {
                    "sent": "Then you can omit a lot of features maybe, and so the competitor is going to pay a price for observing those features too.",
                    "label": 0
                },
                {
                    "sent": "And of course the competition is going to suffer prediction losses fast, so so you want to compete with the best predictor in hindsight and difference again, is.",
                    "label": 1
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is the regret so in this case you are also trading off the acquisition costs like a direct acquisition cost for the information concerning the feature values.",
                    "label": 0
                },
                {
                    "sent": "So that's kind of the novel element here and.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the question is, what can you do?",
                    "label": 0
                },
                {
                    "sent": "So in one setting a simple setting is when or simple node shouldn't say that.",
                    "label": 0
                },
                {
                    "sent": "One setting is when all the labor costs are zero, and then naturally the learner is going to choose to see the label in every time step because it's for free.",
                    "label": 1
                },
                {
                    "sent": "So we took away one aspect of the problem.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so in this case you can start really general and so for example, you can say that let's assume only that the losses are Lipschitz with respect to some metric in the outcome space, and so notation is that for using a predictor F you need this features and.",
                    "label": 0
                },
                {
                    "sent": "And the as a small observation is that if you're using, if you decide to use some predictor and you're going to need some features for that predictor, than every other predictor that needs a subset of those features, you can avoid its underlying loss because you got to see the the label, so it was free.",
                    "label": 0
                },
                {
                    "sent": "So the problem has this interesting information structure.",
                    "label": 0
                },
                {
                    "sent": "This lattice structure.",
                    "label": 0
                },
                {
                    "sent": "So depending on what predictors you are choosing, you can immediately see that you have to sort of reasonable.",
                    "label": 0
                },
                {
                    "sent": "What you want to see?",
                    "label": 0
                },
                {
                    "sent": "And so this leads to this graph where so you have this predictors in the nodes of the graph, and so the edges are going to tie you for which other predictors you're going to get the last information at the same time.",
                    "label": 0
                },
                {
                    "sent": "If you're choosing one of these predictors.",
                    "label": 0
                },
                {
                    "sent": "So if you choose something about choosing a predictor in order to be able to use this predictor, and the example provided, provided you didn't see the side information, you need to add the features.",
                    "label": 1
                },
                {
                    "sent": "So if you're asking those features, then for any other predictor that uses subset of those features.",
                    "label": 1
                },
                {
                    "sent": "You can also avoid the loss of that predictor like the loss on that example.",
                    "label": 0
                },
                {
                    "sent": "OK, so this leads to this graph and actually turns out that this is just if you're concentrating on this simple case, then let's say you have a finite F and this is special case of a model that was studied by Cheyenne Omar in 2011 and they call this value upside side observations and they have a general result that goes like this.",
                    "label": 0
                },
                {
                    "sent": "So they allowed the graphs to variety, and they're competing with a finite set F. And so yeah, they have this graphs, and that's the regret they have and high is there the clique number of the graph.",
                    "label": 0
                },
                {
                    "sent": "And so in our case, in the worst case, the click number is going to be 2 to the D, and that's quite very some I would say.",
                    "label": 0
                },
                {
                    "sent": "But anyways, so that's the result that you can derive.",
                    "label": 0
                },
                {
                    "sent": "No, it appears that they have also proven lower bounds.",
                    "label": 0
                },
                {
                    "sent": "In your case the lower bonds are going to match these two to the factors in the worst case sort of there is nothing that you could do about this factor over there what you can.",
                    "label": 0
                },
                {
                    "sent": "Hope doing is that.",
                    "label": 0
                },
                {
                    "sent": "Well, maybe you know you have to choose.",
                    "label": 0
                },
                {
                    "sent": "I think functions that do not require that many features because otherwise it's just going to be there.",
                    "label": 0
                },
                {
                    "sent": "So it's sort of too expensive to explore all the subsets of the features, yes?",
                    "label": 0
                },
                {
                    "sent": "GT is this.",
                    "label": 0
                },
                {
                    "sent": "Oh, that's it.",
                    "label": 0
                },
                {
                    "sent": "That's OK.",
                    "label": 0
                },
                {
                    "sent": "So if you generalize this then you could say that every time step a graph is announced to you and the graph is telling you which other for which other nodes in the graph you're going to see the feedback.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that's GT.",
                    "label": 0
                },
                {
                    "sent": "So it's just a small observation that in this case is the problem.",
                    "label": 0
                },
                {
                    "sent": "The uses to their problem, and therefore you can just use the regret results.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So of course you can go further than that.",
                    "label": 0
                },
                {
                    "sent": "Usual covering tricks, you can derive bonds for Lipschitz losses using cover covering numbers.",
                    "label": 1
                },
                {
                    "sent": "For example if you have linear predictors, then you're going to arrive at a regret bond that looks like this, so you still are going to have the two to the D factor, but other than that the regret kind of behaves the usual fashion.",
                    "label": 0
                },
                {
                    "sent": "It's root tea ish.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "That's alright, but it's a little bit disappointing, right?",
                    "label": 0
                },
                {
                    "sent": "So you have these two to the D. Whether you can do any any better.",
                    "label": 0
                },
                {
                    "sent": "In the worst case we know you can't do any better.",
                    "label": 0
                },
                {
                    "sent": "So what can we do so things that we're trying to do?",
                    "label": 0
                },
                {
                    "sent": "In those cases we try to impose some additional structure on the problem to see whether you can do any better, right?",
                    "label": 0
                },
                {
                    "sent": "So one such.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Factor is to think about what happens in linear regression with quadratic losses, so that's a beautiful structure, right?",
                    "label": 1
                },
                {
                    "sent": "So you have linearity, you have quality losses.",
                    "label": 0
                },
                {
                    "sent": "So what I'm talking, what am I talking about?",
                    "label": 0
                },
                {
                    "sent": "So the loss is going to be just the squared loss, and so the linear prediction is just takes the inner product between the weight vector of your choice and the side information, and so the nice structure that comes out of this is that you can expand this right?",
                    "label": 0
                },
                {
                    "sent": "So you are going to have a quadratic term.",
                    "label": 0
                },
                {
                    "sent": "As a function of your W and you have linear term plus you have a constant.",
                    "label": 0
                },
                {
                    "sent": "If you're expanding the loss and the idea in this case is just too well.",
                    "label": 0
                },
                {
                    "sent": "The key of these algorithms is whether you are able to estimate in an efficient fashion the loss.",
                    "label": 0
                },
                {
                    "sent": "Buying using some randomization maybe?",
                    "label": 0
                },
                {
                    "sent": "And so if you're looking at this loss, you try to estimate it.",
                    "label": 0
                },
                {
                    "sent": "What is the unknown here?",
                    "label": 0
                },
                {
                    "sent": "So you know, WS of course, and you got to see the labels, so YT.",
                    "label": 0
                },
                {
                    "sent": "So that's the real value number in this case, so that's not unknown.",
                    "label": 0
                },
                {
                    "sent": "XT is going to be in, there are no, so you try to estimate the site information and this underlying matrix and the underlying vector, and so.",
                    "label": 0
                },
                {
                    "sent": "After thinking about this a little bit, it's not not hard to come up is unbiased estimate of these quantities.",
                    "label": 0
                },
                {
                    "sent": "So let's say that you're choosing a vector with some probability from some finite set.",
                    "label": 1
                },
                {
                    "sent": "So let's say we still do some discretization of the weight space.",
                    "label": 0
                },
                {
                    "sent": "Then you can define what is the probability of observing a particle feature under this probability distribution, and what is the probability of observing a pair of features OK, and what you can do is that you can estimate the individual components.",
                    "label": 0
                },
                {
                    "sent": "Of the feature vector.",
                    "label": 0
                },
                {
                    "sent": "By dividing this with this probability.",
                    "label": 0
                },
                {
                    "sent": "This product, which is just the indicator whether you have observed the feature and.",
                    "label": 0
                },
                {
                    "sent": "And the site information.",
                    "label": 0
                },
                {
                    "sent": "And of course, if you chose not to observe some feature, then this is just going to be a big O and otherwise what happens is that you just divide with this probability OK and you can do the same with this author product matrix.",
                    "label": 0
                },
                {
                    "sent": "So this matrix is just the outer product of xtian XDXD transpose.",
                    "label": 0
                },
                {
                    "sent": "It's a product that product.",
                    "label": 0
                },
                {
                    "sent": "So to estimate the individual elements you do the same with this pairs of probabilities.",
                    "label": 0
                },
                {
                    "sent": "So you're just debiasing the.",
                    "label": 0
                },
                {
                    "sent": "The information that you have and these are unbiased estimates, so it seems that that you can gain maybe way more information in this setting, because right now, well, you have the loss for any WF your interest OK?",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So if you throw this in this idea in an basean, this idea is actually I have seen her hand in the work of cheese a Bianchi and I'll when they were talking about this in a different setting.",
                    "label": 0
                },
                {
                    "sent": "When you have this budget prediction problems.",
                    "label": 0
                },
                {
                    "sent": "Then you throw in this criticism.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then just discretization to the horizon and use an exponential weights algorithm on and.",
                    "label": 1
                },
                {
                    "sent": "On the top of everything.",
                    "label": 0
                },
                {
                    "sent": "Then you can derive this bond.",
                    "label": 0
                },
                {
                    "sent": "So the nice thing about this bond this regret bound is that it's scarce polynomial Indy in particle, it's gets really nicely with the dimension D, so the other quantities are, you know, just the sum bonds and do an arm of the weight vectors and the norm of the site information vectors and the limits bounds on how big the labels, how big values delivers can take.",
                    "label": 0
                },
                {
                    "sent": "And there are some other quantities appearing, but the main thing here is that you reduce like you manage to reuse the exponential dependence on the.",
                    "label": 0
                },
                {
                    "sent": "So it seems that structure really does help, and you can prove a matching lower bond up to constant factors.",
                    "label": 0
                },
                {
                    "sent": "So that's very nice.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, yes.",
                    "label": 0
                },
                {
                    "sent": "Independent from the dimension, because you've got two different right?",
                    "label": 0
                },
                {
                    "sent": "Right so.",
                    "label": 0
                },
                {
                    "sent": "So for example, yeah, so for example, if you depending on what norm you choose, right?",
                    "label": 0
                },
                {
                    "sent": "So I mean like.",
                    "label": 0
                },
                {
                    "sent": "Sure, like it's, that's why I'm showing this expression because, but it's a question of like which boss you like to sing about.",
                    "label": 0
                },
                {
                    "sent": "We were thinking about Dua boards then, then it's not a problem, but you know, if the situation is more nasty than it's not so nice.",
                    "label": 0
                },
                {
                    "sent": "So if the board at your weight vectors are coming from and is not the door board to the board at the site information is coming from, then you are going to suffer a penalty.",
                    "label": 0
                },
                {
                    "sent": "That is the ratio between you know the.",
                    "label": 0
                },
                {
                    "sent": "Alright, so it may or may not depend on the dimension.",
                    "label": 0
                },
                {
                    "sent": "You can make it as large as the.",
                    "label": 0
                },
                {
                    "sent": "That's a good point.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "This is all nice, but remember that in order to get this result we had to discretize and you're discretizing and then it's going to be like T to the D or what not.",
                    "label": 0
                },
                {
                    "sent": "Where is that?",
                    "label": 0
                },
                {
                    "sent": "You have to keep track of an.",
                    "label": 0
                },
                {
                    "sent": "So the question is whether you can do this computation efficient manner and we were trying to do this and.",
                    "label": 0
                },
                {
                    "sent": "Say that we have some ideas, but this remains an open question up to now.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, So what happens when the labels are costly so when the labels are costly, in some situation in some way the situation is is simpler.",
                    "label": 0
                },
                {
                    "sent": "So we already are overpaying.",
                    "label": 1
                },
                {
                    "sent": "I.",
                    "label": 0
                },
                {
                    "sent": "So because the competitor doesn't have to pay for the labels and we have to pay for the labels.",
                    "label": 0
                },
                {
                    "sent": "And this then is in some sense just more complicated instance of what is known as label efficient prediction from the expert setting.",
                    "label": 0
                },
                {
                    "sent": "And then you can realize that you can as well decide for seeing all the features because it's just entered the constant that you are paying in your regret, and so somehow if you have, the label is costly than the game is not so interesting and you can actually in this case use an exponential weights algorithm and and flip a coin every time step.",
                    "label": 1
                },
                {
                    "sent": "We say well adjusted probability to decide whether you want to.",
                    "label": 0
                },
                {
                    "sent": "See the feedback I guess.",
                    "label": 0
                },
                {
                    "sent": "And you can implement the whole algorithm efficiently for the linear regression case.",
                    "label": 0
                },
                {
                    "sent": "So going to have an efficient algorithm in this case.",
                    "label": 0
                },
                {
                    "sent": "But the regret is going to scale with T to the 2/3, and in this case we have matching lower bound.",
                    "label": 0
                },
                {
                    "sent": "That shows that you cannot go below that, and that's exactly because you're already paying too much for the label.",
                    "label": 1
                },
                {
                    "sent": "The competitors do not really have to pay for the label.",
                    "label": 0
                },
                {
                    "sent": "So that's all fine.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What we see in this case so that the slide that explains why we're talking about monetary does is that it seems that like there is a tradeoff between computation costs here and these other two things, prediction accuracy and information acquisition cost.",
                    "label": 1
                },
                {
                    "sent": "And so we see that like on one hand, if you are, if you're willing to give a prediction accuracy, then you can boil down to this simple coin flipping argutum, at least in the linear regression keys and get a regret bond that scarce like T to the two third.",
                    "label": 0
                },
                {
                    "sent": "But if you want to get the Ruthie regret bond than we currently don't know if that is possible to do in a computation efficient manner.",
                    "label": 0
                },
                {
                    "sent": "We believe that it should be possible to do.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, so that leads to these open problems.",
                    "label": 0
                },
                {
                    "sent": "So one of the problems is what do you have trackable?",
                    "label": 0
                },
                {
                    "sent": "Can you design tractable algorithms for regression when you're competing with small subsets of features?",
                    "label": 1
                },
                {
                    "sent": "And and what is exactly the?",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The tradeoff between these two things, so the last thing that I like to talk about is that, like, imagine that you're trying to scale this up and put this on servers, so the service is serving the customers and so the customers arriving at at this web servers and there's a high frequency interaction going on, so the engineers in the company that you're working for a very variety of you touching this server so they don't allow you to do that.",
                    "label": 0
                },
                {
                    "sent": "They are going to download some batch of data after that.",
                    "label": 0
                },
                {
                    "sent": "Hi, maybe you know every minute or every half an hour or what not to your server so to the production servers and then you can retrain your models and then you can upload the retrain models to the server.",
                    "label": 0
                },
                {
                    "sent": "So what you're going to see here is that there could be that there will be some delays right?",
                    "label": 0
                },
                {
                    "sent": "So the interaction is happening at high frequency.",
                    "label": 1
                },
                {
                    "sent": "Your model updates are happening at the lower frequency.",
                    "label": 0
                },
                {
                    "sent": "Is this going to influence in a very harsh manner that the regret that you're going to suffer?",
                    "label": 0
                },
                {
                    "sent": "So that's an interesting question.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so here is.",
                    "label": 0
                },
                {
                    "sent": "Here is a simplified model for studying this question.",
                    "label": 1
                },
                {
                    "sent": "So let's assume that the delays that you're suffering at random and there are I ID.",
                    "label": 0
                },
                {
                    "sent": "So you have the learner chooses an action that goes to the environment and the environment is going to give a feedback to the learner that is, in every time step a sequence of Rivard and timestamp pairs.",
                    "label": 0
                },
                {
                    "sent": "So everything is timestamped here.",
                    "label": 0
                },
                {
                    "sent": "So when you're sending an action, then you put the time stamp on it, and then it carries with that and then.",
                    "label": 0
                },
                {
                    "sent": "Information that is coming back, carriers that time steps so that you can identify which action the information that you are receiving belong to.",
                    "label": 0
                },
                {
                    "sent": "So here is so you got the rewards and you get this time stamps and then the learner can update whatever is strategies and the process continue.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Potentially this sequence could be empty and many, many cases it's just going to be empty, so the learner is not receiving information.",
                    "label": 0
                },
                {
                    "sent": "So in that case K is going to be one.",
                    "label": 0
                },
                {
                    "sent": "So in this case a different trade authorizes.",
                    "label": 0
                },
                {
                    "sent": "The development, deployment cost, convenience, maintenance cost versus prediction accuracy right so the reason we do this is because of convene.",
                    "label": 1
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yes, right?",
                    "label": 0
                },
                {
                    "sent": "It turns out that well, of course people have studied learning with delayed information in the past, and what we figured what was missing is.",
                    "label": 0
                },
                {
                    "sent": "What is the penalty that you have to pay?",
                    "label": 0
                },
                {
                    "sent": "If you are learning under, this delays when there is no style information and there is bandit feedback.",
                    "label": 0
                },
                {
                    "sent": "And of course you could say, well that's stupid because side information is more than no sign information and you see that the penalty is going to be additive here.",
                    "label": 0
                },
                {
                    "sent": "The penalty is going to be multiplicative.",
                    "label": 0
                },
                {
                    "sent": "There are some matching lower bonds here and there in the literature.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For the full information case and so results are just this so.",
                    "label": 0
                },
                {
                    "sent": "In the stochastic setting, when there is no site information, then the penalty that you are going to pay in the regret is just additive and it's chaos with the expected number of the Maxim of the delays up to a certain time stamp.",
                    "label": 0
                },
                {
                    "sent": "So we don't really like this Maxim here, but we don't know if it's possible to remove that.",
                    "label": 0
                },
                {
                    "sent": "And in the adversary case the penalty is going to be multiplicative and its gases square root of the same quantity.",
                    "label": 0
                },
                {
                    "sent": "So that's.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Result and so.",
                    "label": 0
                },
                {
                    "sent": "I'm going to show very quickly how we are going to achieve this in that versus setting.",
                    "label": 0
                },
                {
                    "sent": "This is a reduction and there was a paper by Weinberger, an ordentlich where they did something similar for the keys.",
                    "label": 0
                },
                {
                    "sent": "When the delays are fixed an known so you know that you're going to suffer a constant delay, your feedback, and they they propose that particle thing and that you can generalize.",
                    "label": 0
                },
                {
                    "sent": "And here is how it goes.",
                    "label": 0
                },
                {
                    "sent": "So this is the machine that we are building.",
                    "label": 0
                },
                {
                    "sent": "And it is just going to instant it.",
                    "label": 0
                },
                {
                    "sent": "This learning machines and number of number of learning machine.",
                    "label": 0
                },
                {
                    "sent": "So there are two Q is basically that the machines which are ready and the machines which are still waiting for feedback for the machines that are still waiting for feedback.",
                    "label": 1
                },
                {
                    "sent": "So these numbers denote the timestamps for which they are waiting the feedback form.",
                    "label": 0
                },
                {
                    "sent": "OK, so the interaction goes by picking the machine at the beginning of the queue.",
                    "label": 0
                },
                {
                    "sent": "It doesn't really matter which, and that's going to suggest an action.",
                    "label": 0
                },
                {
                    "sent": "OK, so the machine suggests an action.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then it's moved to the queue where you have the machines waiting for feedback.",
                    "label": 1
                },
                {
                    "sent": "And that Q is reorganized and it receives the time step of the current time.",
                    "label": 0
                },
                {
                    "sent": "OK, so that was how we produce an action.",
                    "label": 0
                },
                {
                    "sent": "If this queue was empty, then the controller would just pen and you knew machine.",
                    "label": 0
                },
                {
                    "sent": "So then the feedback arrives and the feedback is for particle timestamps.",
                    "label": 0
                },
                {
                    "sent": "So we have these two rewards in this case that arrived and you give the rewards to the machines that are waiting for that particular event.",
                    "label": 0
                },
                {
                    "sent": "So you see that reward one is for this machine and rewards two is for that other machine.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So give them those rewards.",
                    "label": 0
                },
                {
                    "sent": "And no, they are not waiting anymore so they can be moved to the other queue.",
                    "label": 0
                },
                {
                    "sent": "And this is how the process continues and the key observation here is the number of machines that are waiting can be upper bounded by well T + 1 and so the minimum of T + 1 and the maximum delay that occurs between one and T. And so if you do that then after a short cock.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Addition, you can you can get the regret bond that that I've shown to you an so here.",
                    "label": 0
                },
                {
                    "sent": "I also have some open questions.",
                    "label": 1
                },
                {
                    "sent": "So let's say the delayes do not depend.",
                    "label": 0
                },
                {
                    "sent": "So in the previous case the delays didn't depend on the action that you're choosing, so it's kind of a network setting and the days were assumed to be I ID.",
                    "label": 0
                },
                {
                    "sent": "And the problem is this Max.",
                    "label": 0
                },
                {
                    "sent": "There is that this could grow in a log rhythmic fashion, right?",
                    "label": 0
                },
                {
                    "sent": "So if you take this.",
                    "label": 0
                },
                {
                    "sent": "Maxim and then you take the expectation can grow with N, so it could be hiding a logarithmically fashion.",
                    "label": 0
                },
                {
                    "sent": "The advantage compared to the previous bond is that if the delays are upper bounded then of course is not going to grow right.",
                    "label": 0
                },
                {
                    "sent": "So then you are going to just get the upper bound you are getting closer to the upper bound as time goes by.",
                    "label": 0
                },
                {
                    "sent": "So can we replace this expectation with just the expectation of the delay?",
                    "label": 0
                },
                {
                    "sent": "So so I don't know.",
                    "label": 0
                },
                {
                    "sent": "Alright, so we don't currently have lower bounds for the stochastic setting and we have just done extension to partial monitoring and prediction with side information, so that's not not open anymore so we can do that.",
                    "label": 1
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, so with that I'd like to conclude.",
                    "label": 0
                },
                {
                    "sent": "So my conclusion is that the other few tradeoffs that we can handle Valve and some tradeoffs require very delicate tuning.",
                    "label": 1
                },
                {
                    "sent": "As you can see from the graph.",
                    "label": 1
                },
                {
                    "sent": "And there are many challenging problems that remain.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}