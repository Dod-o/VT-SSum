{
    "id": "h4atyrm4xjhd5k36dxacygfd3j3yneij",
    "title": "WWT: A system for query-driven relation extraction from the semi-structured web",
    "info": {
        "author": [
            "Sunita Sarawagi, Indian Institute of Technology Madras"
        ],
        "published": "June 7, 2010",
        "recorded": "May 2010",
        "category": [
            "Top->Computer Science->Information Extraction"
        ]
    },
    "url": "http://videolectures.net/akbc2010_sarawagi_wwt/",
    "segmentation": [
        [
            "A second talk on tables and in fact this is work is inspired by the web tables work.",
            "It came at a point where I have been.",
            "I've been working with publications and addresses for four years.",
            "Five years applying really humid statistical machine, learning on literally solved datasets.",
            "So this was very exciting.",
            "You know, left poor interesting domains and topics, and it's certainly much more relevant and really OK.",
            "But in my style there is going to be a lot of statistical machine learning, so much so that some of you might just be running out screaming for coffee.",
            "You can only hope is to interrupt me with questions."
        ],
        [
            "So they say, you know, if I'm also looking at this semi structured web which comprises tables and lists and other regular pages.",
            "So anything which can give me sets of multi attribute records is of interest to me, but we're not looking at the deep web order form form based input, but that also implies that our data tends to be more noisy.",
            "We're like looking at mom and pop tables so they're not necessarily machine generated.",
            "Tables and they're kind of scattered all over in individual home pages, so we also face the problem that I don't talks about.",
            "We don't know what this record sources about, so we may have all of this traditional problems and."
        ],
        [
            "So we are so we have this system which you're calling WWT for worldwide tables and currently we support two kinds of queries, so we return tables answers and you can get to those tables.",
            "Tables are also relations in the database lingo and you can get to those tables either by giving some examples of relationships that you're after, so you could give us a names of people and the concepts that they are famous for.",
            "Leave information you can ask by keyword queries, but there is one more very crucial difference and I think it's actually a very important difference.",
            "So we actually somehow feel that there is only a small kind of semantic leap for a user to be typing keyboards in two text boxes or three text boxes rather than in one textbox and just buy this one difference that you will be typing.",
            "Keywords describing the columns of whatever tables that you want.",
            "You can certainly get lot more power so you can so you don't have to really make the assumptions that a table is only about one subject.",
            "You can describe all the columns that you want by their individual keywords and you will get."
        ],
        [
            "The tables such.",
            "So our goal is to return tables like this."
        ],
        [
            "We will do this through a system which does faster.",
            "We have an offline call of the web.",
            "We're not Google.",
            "We are academics, so we have 1/2 billion offline crawl of the web from which we did a person extracted anything which looked like they could be offering record sources and we face the problems that allows group has solved of you know how to identify what tables actually are relational table as it comes presentation tables.",
            "And then we'll also be extracting.",
            "At this time, the lists and anything which looks like record data that is harder.",
            "So we currently just base it on heuristics.",
            "And then we do a bit of annotations.",
            "If there is an existing ontology.",
            "So currently we use Yahoo.",
            "So if there is an existing ontology, will use the ontology to do as many annotations as we can.",
            "But otherwise, because we don't really know schema or really just.",
            "This is so many isolated, unrelated tables, we don't break our heads about understanding what tables and lists are trying to say before we actually get some interested user.",
            "So we just stash those tables or lists.",
            "Just does documents we just scratch them into collection of keywords and put them in a Lucene index.",
            "That's all that we do it in the offline phase and then later when user poses a query of the type, the two types that I mentioned that we will be doing a little bit of type will kind of lightweight course rent type attachment to the columns would just maybe say whether it looks like a short string or a number or a date.",
            "This can be extensible and.",
            "Then we'll put the index, get a set of matching sources, and then we done this extractor.",
            "This is where my old world comes in.",
            "I applied statistical machine learning for doing these extractions and then we do the standard deduplication and ranking.",
            "So, so here you know these two problems which before we started work on this.",
            "I have been thinking for for five years but the time it was a very different problem because you knew what schema you are after.",
            "So you had a trading place.",
            "Then you knew the set of attributes and therefore you could design features which were suitable to that domain, whereas here we don't know whether we're going to ask.",
            "We're good whether we're going to see a table query about movie actors and the roles that they play it, or it's going to be about oilfield disasters along with date of the disaster.",
            "So that's all domain independent, so that raises new sets of challenges, so there are many interesting pieces in this machinery.",
            "But I'm going to talk today about just two of these pieces.",
            "The extractor and the annotator, so in in view of the team of this workshop.",
            "So fast."
        ],
        [
            "About the extractor and in this part, I'm going to concentrate on the content query so this is a query you know for people who can interpret well and good for others who cannot.",
            "This is how the computer will also look at it, it's just.",
            "Assist you know grid of three by two, which has some sets of strings and now we do our index probe and we could get some arbitrary set of lists.",
            "So these are, say maybe three sources that we have obtained and now we will use our extractor module and essentially this is the first time that we are trying to understand or interpret that raw source.",
            "So here we have done an alignment of this source with respect to very lightly specified schema of the user.",
            "So now that this individual sources are oriented as per the users sort of example specified schema, we have a collection of sources and on that we do the consolidation and duplication.",
            "So now I'm just going to expand on this extraction bot.",
            "So I am wondering about the approach how you chose this approach right to say I could given queries by example by example, I could I could take a different view right so I could somehow take each of those roles and turn into a query and search for documents that have answers to that query, and Furthermore has some write a bit of regular stretch with the hits for the query kind of formal regular structure?",
            "So, for instance, a search for the Grand Prix more while skiing for 1008.",
            "I might find that one of those roses.",
            "One of those things is this, oh, I see they hit here.",
            "So now he's just some regular structure.",
            "Sticker prices.",
            "You could do that.",
            "On demand, rather than trying to extract the tables.",
            "In the absence of knowledge of what it is that I'm looking so actually we don't really extract tables, we extract anything which is regular.",
            "So we would also extract maybe pages, but so there is some false negatives that we might hit.",
            "So yes, so you could if you had the refs in lots of machines you could do the regularity.",
            "You know you could first just put the index on the web crawl.",
            "What the tradeoff between these still exist machines?",
            "Or visit or no, it's not a big issue.",
            "I think it will equally well work in Google kind of infrastructure.",
            "It will be there is no need to do an offline first call of the regular structure.",
            "It's just something that we do and I don't think we are hit by it too much.",
            "I don't think we have too much false negatives, but it's not something that I'm really strict about either way, so."
        ],
        [
            "OK.",
            "So now you know it's so so then Mississippi zoom into this extraction problem.",
            "So what are the two issues which I found different in this problem compared to what I've been done?",
            "But I've been doing in the past.",
            "First is of course that we have basically almost no supervision, so just the 2 three example query rules that the user has provided and that too it's in an indirect manner.",
            "We just have a small.",
            "So like a mini database, there has been a lot of work and I myself have done a lot of work in doing extractions in the presence of databases.",
            "But then we have always been assuming that the databases are huge here.",
            "Even our database is tiny so on the one hand you want very robust techniques for labeling your unstructured lists and again as we have been assuming that the machines are pages are regular structures are not machine generated, so we want to use statistical learning techniques and rule based or Apple based.",
            "Techniques we did not think would be robust for our kind of sources.",
            "So on the one hand you need to label data, but so you want to because you have so few critters you want to squeeze as much as you can out of the query rows.",
            "But on the other hand, because you have so little labeled data, if you do wrong matching of your unlabeled subsequences to what you think are structured matches in the query, then you will get a very wrong model.",
            "Because your training and you know if you just have one or two label records, then you don't want to get any wrong labeling.",
            "So there is a very tight rope that you have to walk on and we have in.",
            "This will be 2009 paper described.",
            "The details of the system and the main thing the main one sentence idea is that we use a library of similarity functions for each.",
            "You know we do this lightweight typing of the columns in the query and based on that if we see that OK, this is a short text or this is a long text or if this is a date.",
            "We have we choose from a bag of library of similarity functions.",
            "The right kind of similarity function, and then we do a segmentation of that unstructured record so as to maximize similarity to the query rows.",
            "After doing a bit of matching.",
            "So that sort of is fine, and then we could independently train each source, but then more recently we have been working on this alternative approach where we want to do joint training over multiple TXT records.",
            "So this is one thing which is very different and exciting about this new scenario that you actually have to build multiple models, and although you have very little supervision but you actually have a lot of redundancy so there is a lot of overlap.",
            "Across sources, so that brings out an interesting machine learning problem."
        ],
        [
            "Extraction, so this is unpublished to work, something that we've just like.",
            "We are working on it for submission, so our goal is to, you know, we have this individual sources, and because each source has its own style, we have to train a separate model.",
            "We cannot build a single model over all the sources, but there is overlap across the sources in the overlap is partial, so some set of some set of words in one source will be overlapping with some sort of words in another source.",
            "So in this example, these are all exact matches, but we also consider it approximate match.",
            "And so now we still have this kind of overlaps.",
            "What are the ways in which you can exploit them?",
            "So."
        ],
        [
            "But in the past people have been using collective inference techniques to exploit overlap.",
            "So in collective inference methods you train individual models.",
            "But you do inference.",
            "Finally, when you actually come to the labeling, you do the labeling jointly so as to enforce agreement in the shared parts.",
            "Now, but that only gives you benefit among the records which contain overlapping text with some other source.",
            "But if you, when you're really in this resource constraint, and in the situation you really would like to again exploit the overlapped in the best possible manner and you get lot more leverage by training features from the overlapping text, which will generalize to other records.",
            "So therefore collective training is better than collective inference.",
            "Now collective training you could always do it in a lightweight manner, like you know what God was also presenting like you start from some set of seed labeled data.",
            "And then you extract more labeled data, use that label data to label more records, and you do this thing in a loop.",
            "But there is always, you know, by now computer scientists understand that there's this can always give rise to concept drift and you don't know when you will be cascading errors.",
            "This is what we had written about in the LDP 2009 paper.",
            "But we understand that there are problems with this approach."
        ],
        [
            "So now we have actually a joint training approach which."
        ],
        [
            "Start suspended so you have less data sources.",
            "Each source has a small amount of labeled data, let's call it Li, and there is a lot of unlabeled.",
            "The set of records in each source.",
            "And as I mentioned earlier, each source has its own feature set because some of it might be list with anchor text, text in tags.",
            "Some of it might be a table with two columns and in one of the columns you have two attributes, so each has its own set of features and the overlap is expressed as.",
            "What I'm be going calling is this letter A.",
            "This is agreement set.",
            "The agreement set consists of clicks and clicks are nothing but the snippet of overlapping text that I showed you earlier.",
            "And now.",
            "So I'm not necessarily they could be also in the labeled data, but for label data we already know the label, so we ignore them.",
            "And because OK, so the other thing is because the label data for all the sources come from the same query record.",
            "So if some snippet is labeled in one source, it would also be labeled in the other source.",
            "So it's not like you have label today, so.",
            "And now we will train this CRF models so this training is a joint training formulation.",
            "So each model has its own set of parameters which we are calling as WI, and we have the usual term of maximizing the likelihood over the labeled data in each source, summing up overall sources.",
            "So this is the usual CRF conditional likelihood maximization.",
            "But then for the agreement set we have this additional term which will maximize the probability of the different sources agreeing on the set of common segments.",
            "Yes.",
            "Then the overlap between all the yes, it's actually over all the sources, so that's what makes it."
        ],
        [
            "Mention."
        ],
        [
            "And.",
            "Actually, it can be very arbitrary.",
            "No, actually we have seen later when you've seen the experiments.",
            "So this is the file you know, so I can defer related to alone thing.",
            "So initially you were in 2003 going and asking for data from people.",
            "Now we have a rich amount of data so we have like 60 sources, 60 queries each query.",
            "We have lists from 20 different sources with all kinds of variety of overlap.",
            "So I guess I'm just concerned that one particular source didn't have a lot of information and like strength is set a. Yeah, I think yeah, so did you know that there are many different patterns of overlap?",
            "Some queries you will have a lot of overlap, so here is an example of an agreement set.",
            "So suppose if you think of these three sentences coming from three different sources that red, blue and green source, and here we have identified these clicks.",
            "So this click involves source one and two.",
            "This third, second click involves all three sources, so on and so forth.",
            "So this is what is the input."
        ],
        [
            "So now we're going back to the formulation.",
            "So we have this agreement.",
            "Likelihood that we have to maximize, so I'll just elaborate a bit more on that that term, so here.",
            "So this is the likelihood term returning shortage sorted form, and now this agreement term you need to look at a bit more carefully, so this submission is going over all possible labels that you can assign to text.",
            "It appears in the agreement set somewhere in the agreement set.",
            "I know OK, so because the different sources trained there, all one model, the probability of a particular labeling is equal to the product of the probability of the individual sources, right?",
            "So you have there for this product are so each source has its probability term.",
            "But because of this submission where the agreement set in this agreement set is shared across different sources, this term is actually very very non trivial to compute.",
            "So how do you side?",
            "So this is based on heuristics, and it could be noisy and this is 1 very important issue which decides which can which has impact on.",
            "You know how exactly you should be computing this specific example, yes."
        ],
        [
            "So what can you decide?",
            "You here's the thing, so he's definitely so.",
            "This is basically all possible dominating.",
            "Dominating clicks at each click consists of a sequence of words and the set of sources from which it comes for in which that sequence appears, and it has to be normal, dominating both in terms of the set of sources it covers and the size of the segment.",
            "So.",
            "It also has to do with the labeling that you know, so there is no labeling.",
            "It's just a set of words, because this is over unlabeled data.",
            "So we recognize.",
            "Establishing created this graph purely on unlabeled, yes.",
            "So a simple heuristic would just be to create a click out of every word which up repeats, but that can give rise too many wrong clicks.",
            "So we do a bit of so far.",
            "We have a sort of a graph regularised.",
            "Yes it is a semi supervised learning approach, yes.",
            "That's right, it's just that the regularization is not over the whole instance, but over a part of the instance and you supplied to structured models.",
            "So there are computational issues and intractability issues, but otherwise it's semi supervised learning.",
            "Parts of it.",
            "And also you can think of it as multiview learning is just that, but we're doing multiple learning over the green part, so it's like for this shared part you can get.",
            "View of its label from either source, the context in which it resides in source one or in Source 2.",
            "So."
        ],
        [
            "So yes, so it's actually does.",
            "It does overlap with many related concepts in machine learning, but you know if you look at, you know when you apply these concepts in the context of structure models, where there is partial overlap.",
            "There are some interesting new issues that we have faced which we have not seen at just elsewhere, so so this time is actually the interesting part of this work, so it's actually not neither convex nor."
        ],
        [
            "Given its injectable so so now so so, here are two interesting things I'm going to talk about this work, so one is.",
            "So you can compute this term.",
            "Through this process 1st I'm going to just describe the process without motivating why really?",
            "So what so you have from each source?",
            "Essentially the dependency graph of each source is a chain.",
            "If you're using normal 1st order CRF's and now what we're going to do is based on this agreement set, we're going to fuse together the nodes across the different sources for any variable which is shared across more than one source, and we get this graph structure.",
            "Let's call this suffused graph.",
            "Now I'm going to claim that."
        ],
        [
            "The stone that we are trying to evaluate.",
            "Can actually be written as the difference of the log partition function.",
            "With appropriately defined potentials over the fused graph.",
            "Minus the sum of the log partition functions of the individual chains.",
            "So actually I have not told you how how we define the potentials, but these diffused graph essentially counts the number of ways in which the different sources can agree.",
            "Right, so this gives you the agreement.",
            "The numerator of this term, and this gives you the denominator.",
            "And this is actually what you have to evaluate.",
            "So when you interpret it as a log partition function over a suitably defined graphical model, then you have lot more handle into the problem and once you will also interpret it this way, then it's also easy to define the gradient of the problem, it's just the expectation of the individual features of each of the sources with respect to this fused graph.",
            "And this is the.",
            "Old style expectation.",
            "So we looked at."
        ],
        [
            "After this approach, which is the natural way you know based on the objective that we wrote, this is the competition that you would have to do.",
            "And but it just turns out that in general, because of the arbitrary pattern of overlap, the first graph might be just wait, not detectable.",
            "It's just you know you started with nice chains, but the moment you fuse together some arbitrary set of clicks from multiple sources, you can get something very very arbitrary, and computing the log partition function.",
            "Of this used graph can in general be very complex and we tried many approximation techniques.",
            "So this was only one set of run vein which you can solve this problem, But then the second approach."
        ],
        [
            "Is actually the question the objective to say that look, you know we're trying to enforce agreement over the entire set of clicks.",
            "But really, what the user wants is to enforce as much agreement as possible, and perhaps if we assume some kind of independence among the agreements of individual clicks, let's say to start with, then we might get much more tractable problem.",
            "So that's what this is.",
            "The second approach.",
            "So first let me know."
        ],
        [
            "Debate with an example.",
            "So here we had our original set of four clicks.",
            "Suppose for each of the clicks we independently try to enforce agreement.",
            "Then the fuse graph that we would be getting would be this really kind of manageable set of star graphs.",
            "So they are fused in one location, but otherwise these are all small tree with graphs and inside each one of them you could tractably compute all the terms that are of interest to you.",
            "So this is sort of like taking this.",
            "Giant agreement term and breaking it as the sum of it.",
            "So you have these agreements that you decompose that agreement set into smaller tractable sets, and then you just enforce independent agreement in each of the sets.",
            "So this is the second approach.",
            "And it turns out that the second approach."
        ],
        [
            "Because it gives us exact inference and also you know usually when you start with your clicks.",
            "Since you have obtained through some algorithm, they're not guaranteed to be perfect leaks, so you might have some errors in there.",
            "You might say match off the one source with off the in another source where they might be actually belonging to two different sets of attributes.",
            "So if you compute a giant fuse graph, then a mistake in one of the clicks is going to influence other clicks, because if you compute a group independent agreement, not only do you get tractability, you also get a bit of an error tolerance.",
            "Now I've not proved it theoretically, but so little bit very nice, but so this is now.",
            "We do these experiments on these kinds of queries and."
        ],
        [
            "So we have hand labeled queries over, so this is the method that we followed.",
            "We started with Wikipedia tables and these are some samples of table topics that we looked at.",
            "the TV series oil Spills Movie Awards.",
            "You know, scientific names of species and for each of these we searched on the web."
        ],
        [
            "We got many, many sources.",
            "We were restricting ourselves to lists in this case and so we had 58 queries and for each of these 58 queries by searching the web, excluding Wikipedia.",
            "That is my concern.",
            "I was round tables on the web and people copy Wikipedia.",
            "Yes, yeah no, no.",
            "So it can actually.",
            "Another reason we actually have a temporal mismatch.",
            "So Wikipedia is current Wikipedia and the web corpus that we have is as of 2006.",
            "So you know there are.",
            "There's not too many.",
            "Yeah, so the end OK.",
            "So the other reason why for this particular did workload.",
            "There is no get.",
            "There is absolutely guaranteed to be new.",
            "Overlap is because our sources are lists and Wikipedia our queries tables.",
            "But these are lists, right?",
            "I mean if you copy a table from Wikipedia, why would you convert it through this list said so?",
            "So we have this say around 2:20 HTML list sources from this half billion crawl of the web, and this consists of very different set of characteristics of data and we take three labeled records as the query set and we measure F1 accuracy and this is what?"
        ],
        [
            "You seem so in this first graph.",
            "Here I am showing a difference in F1 accuracy with respect to the baseline, which just does independent training for each source, and I'm comparing three different approaches.",
            "The first blue approach is joint training approach that I mentioned.",
            "The red approach is what we had written about in the VLDB paper where we do this.",
            "We hardly able once or sandwich transfer the labeling to the next source, so this is what we're calling as a staged approach.",
            "And this green is doing collective inference.",
            "So in general you of course you put in present charts.",
            "You know I sometimes get bored presenting this is these.",
            "Are they all predictable?",
            "So anyway so.",
            "But the good thing is that you know the collective influence is not that bad.",
            "You know it gives us 86% with this joint training.",
            "It gives us 87.5%.",
            "But staged can be quite bad in some of the queries.",
            "And."
        ],
        [
            "Now this is what I find interesting.",
            "It has a nontrivial story to say, so this is, you know, comparing.",
            "So if we have grouped 58 queries through some means into some ten groups like this, and here you see accuracy numbers of the baseline and this red set of numbers.",
            "These are two different ways of decomposing your agreement set into attractable graphs, and this green numbers are various methods of approximating the fused graph, which is actually solving the original objective.",
            "And this one because I said this problem is also related to multiview learning.",
            "So here we are comparing with the previous approach on multiple alone and we find that in general the decomposition based approach, even though we we make this independence assumptions, they perform much better.",
            "You know for parameter estimation then the approximation based approach because they don't compute the gradient reliably and the trainer gets confused and so now.",
            "But of course what will be interesting is to try MCMC also will try factory on this and see how it works."
        ],
        [
            "So.",
            "So this is that equals about the collective training part, so you know.",
            "So basically in the web scenario, when you are trying to do online query time extractions you are in this world where you have very little supervision but you have a lot of redundancy.",
            "So this collective training mechanism is a paradigm to be thought of seriously for this kind of world.",
            "But I must warn you at this point that running time is currently.",
            "Sort of fish with the baseline takes the time X, then the collective approach will currently take 5X and we're working towards speeding it up and you can see obvious ways in which perhaps you can speed up, but there are some known of these approaches, also battery.",
            "So, so the chat running time issue is there and of course the main challenge is how to deal with the intractability of the likelihood and the interesting observations which somewhat surprised me is that it's better to start a priori with a simpler model than to start with more accurate model and then be stumped by the intractability of the model."
        ],
        [
            "And then the second part of the talk.",
            "So I'm going to guess.",
            "20 minutes.",
            "Yeah, so when I ask you question earlier and now is thinking about what you're saying.",
            "Like you guys realize that maybe what I had in mind and what you're doing is somewhat different.",
            "OK, because you actually.",
            "Like the game.",
            "We doing collective training trains but doing training.",
            "Yes we have to do collective influence could imagine and a different view where you really don't need enforce agreement that we were using.",
            "Just the agreement graph is regularize.",
            "So you just kind of put the penalty on disagree.",
            "But even if you use the regularizers you would if you want to solve for the.",
            "Now, of course it depends on whether the regularizer is square regularizer.",
            "Suppose if you scale distance it gives rise to better manageable terms.",
            "Even then you will have the gradient will require collective inference.",
            "Great.",
            "'cause you're not depending on OK, so you know the PR regularization math method that I presented in this lights that is basically doing regularizer and that is in fact there we use them Whereas in this case even though our method of objective is on convex, we go ahead and do gradient descent anyway and that's like 10 times slower.",
            "Yes, OK. OK, so any other questions?",
            "Not in this."
        ],
        [
            "By description, this actually will write a lot to Alan stock, so we're looking at answering keyword queries, but the difference is that we have keywords over multiple columns.",
            "All the columns that you want to see in the answer you describe them with keyboards, and now we are going to go after the tables.",
            "So now the main question as Alan mentioned also is how do you get to the tables which are relevant?",
            "Some cases you are lucky you might be able to get to the tables based on match.",
            "In the header of the table, some of the tables have headers, but there are many tables which have nonsensical headers.",
            "This is in fact Wikipedia table and it has these headers which do not help you get to the table, and there are tables without any headers.",
            "And yes, you can use the context, so Alan was US history and I was asking you can use the context to get to the tables, but then you have this problem of you don't know what word in the context is relevant and stuff like that."
        ],
        [
            "So now so the basic idea.",
            "It's like this.",
            "The natural thing that smart people think about is using ontology to do the annotations of the table.",
            "So we also want to do the annotation.",
            "So given an ontology about chemical elements, if we annotate, we will do well and then we actually this part.",
            "I'm not going to go into details, but here also we use graphical models.",
            "So finally what we have is a set of tables which we got obtained through the index probe from the query and four.",
            "Each table we will be trying to label the columns based on clues that we combine from the text around the table so the text around the table will be used will be assigning potentials to all columns of the table because we don't know which column it is talking about an from the header of the table, we actually do a bit of header, so sometimes they're useful, so we'd combine it from the header and then from the ontology labels and then based on the overlap of the different table contents we have also.",
            "A bit of regularization or similar."
        ],
        [
            "The constraint on the."
        ],
        [
            "Labels that they can take and we solve it using a joint labeling approach, which I'm not going to talk about.",
            "Instead, I'm going to concentrate on the problem of annotate."
        ],
        [
            "Game tables.",
            "So this is the problem.",
            "I'll talk about for the next 10 minutes.",
            "So you have a table and this is a arbitrary table on the web and you have an ontology.",
            "We use Yahoo.",
            "It could be The Dirty ontology that alone has created.",
            "Can be any ontology and the ontology has a type hierarchy and at the bottom we have a set of entities and both the type nodes and the entity nodes are attached with strings which described the node and these are the lemmas so so you could have.",
            "Typically there are lemmas attached only with the entity nodes, but sometimes you also have lemmas attached with the type nodes.",
            "And so this is our catalog.",
            "OK, and in addition to this type of graph, it's not really a tree.",
            "We also have relationships for some set of entities, so you could have like a set of relations, like in Jago.",
            "For example, there are hundred order relationships.",
            "Now our goal is to align this table with respect to an existing ontology and we do three kinds of annotations.",
            "So we'll take the cells of the table and annotated with links to the entity nodes in the.",
            "Catalog and we would take the type, the headers or the columns of the table and annotated with type nodes.",
            "And we will take pairs of columns and we will annotate this with relational label and currently we are only looking at binary relations, so this is the task."
        ],
        [
            "Now there are the many challenges to doing this task.",
            "Of course there is a lot of ambiguity.",
            "Many noisy mentions Jago, you know, all these ontologies.",
            "They're inherently multi labeled and the most difficult of the challenges we faced is that the ontologies are incomplete so therefore things like least common and sisters do not work when you want to generalize from entity labels to type notes, because there are many links which are missing.",
            "So like in Yahoo.",
            "Gerhard, the link from universities in Toronto to University in Ontario is missing the link from Satyajit Ray.",
            "Indian film directors is missing so this may missing links."
        ],
        [
            "So so so so you know there were some questions about why can't you use this clue?",
            "Why can't you use that clue?",
            "Here we have a model where we combine all kinds of clothes to do this, joint labeling of entity type in relationships in a table.",
            "So we are collectively labeling biographical model.",
            "So the set of variables that we have are the entity labels which are attached to each cell.",
            "So our column see the type labels which are attached to each column and then between pair of columns we have the relationship labels.",
            "And we define potentials over this set of variables as follows.",
            "So for entities we define potentials which are basically derived from weighted features which capture all kinds of similarities between the contents that you see in the table and the lemmas which are attached with the catalog.",
            "Similarly, between for the type nodes.",
            "If there is, if the table has a header and if the table has meaningful context or caption, we will use it to define various kinds of similarity functions.",
            "Features which can then be used to provide clues to doing type annotations of columns.",
            "So another very interesting potential that we feature that we define here is to reward labeling.",
            "Do not generalize too much so we penalize types which are.",
            "To higher up.",
            "So we want to keep things as specific as possible, while as far as the entity nodes allow specificity."
        ],
        [
            "And then we have a potential coupling entity and type notes.",
            "So these are again driven by features.",
            "So now, so this is the part where we do something special to handle missing links.",
            "So if you are trying to propose to label a column with type label TC where a cell of that column you are labeling with DRC, then there are three cases that can arise.",
            "Either there is a path from the entity node to the type node in the ontology, for example linear code, there is a path from Einstein's to physicist, so in such cases we will define a feature which is equal to the inverse of the distance between them.",
            "So this kind of penalizes over generalization.",
            "And you could also define more features which are inverse functions of the distance between them.",
            "And if there is a sort of an entity in that column to which the type has no path.",
            "For example, if you have a cell content which is Julius Plucker, and there is no path from Julius Plucker to German physicist, then does it mean that you cannot name this column?",
            "German physicist, even if all other entity nodes point to German physicists, you can, because we make use of, we understand that the ontologies might be having missing links, so we use this feature, which is.",
            "Basically, you know, we look at the parents of this entity, which actually exists in the ontology, and look at how many of those.",
            "The how many children of that parent actually overlap with German physicist?",
            "So we see in the ontology that Gerard Julius Plucker is a mathematician, and many mathematicians are physicians physicists.",
            "So therefore we will attach a non 0 feature value to this coupling.",
            "On the other hand, if in that table cell you have Newton and if Newton has a parent called English physicist, because English physicist did not.",
            "Coker with German physicist, this will be given no reward, you know, and therefore that column will most likely not be labeled German physicist and also in order to back off from labeling.",
            "This is a very very hard task in all web domains.",
            "We also look at how many introduce, not at all appear in the catalog.",
            "And there is a constant feature value assigned to it.",
            "This allows us to back off when we fail."
        ],
        [
            "Similarly, we have potentials coupling relations and type types in the obvious ways.",
            "There's not too many surprises here."
        ],
        [
            "And finally we have this collective inference task where suppose if you have this table with three types, three columns and this three entity rows, then will be.",
            "Each circle here denotes a variable and based on the potentials that I have defined, you have this dependency graph.",
            "And you get something complicated, so we do approximate inference."
        ],
        [
            "And by the way, we train those potentials using Max margin learning.",
            "So this is a data set, we are if we have manually labeled 450 tables and we also automatically from Wikipedia, because many Wikipedia tables contain links to entity nodes, we got some partially labeled tables directly from Wikipedia and here you are seeing accuracy for these three kinds of labeling tasks, entity types and relationships for these two different datasets, the manually labeled data set and for the automatic label data set we only had entity labels, not the type and relationship labels.",
            "And we see that we do quite well on the entity annotations, and we're comparing with least Homan and sister and majority based labels.",
            "So basically it's saying that joint labeling myself.",
            "But for type annotations, we're not doing very well, and one of the reasons is that we are very, very strict in measuring this accuracy.",
            "So if you call.",
            "Column which is German physicist.",
            "If you call it physicist will still give a error of 0 error of one.",
            "We don't give partial credit, so very often we are off by one.",
            "Invest in quite County test full letter so.",
            "So this is a type accuracy, therefore is low and relationship.",
            "We don't have too much data on the relationship labeling, so these numbers are a bit pretty.",
            "I would think the relationship numbers."
        ],
        [
            "And now here is just a small workload to illustrate why this is a useful thing to do.",
            "So we use the annotated data to answer queries of the form where you specify a type.",
            "You say I am interested in answers of type movies and where I have this relationship directed by between a person entity which has elema George Clooney.",
            "So you can try to answer this query without any of the annotations using obvious heuristics and you or you could use the annotations that we just talked about and we had this workload of this five relations acted in directed language, produced en route and we created 40 queries per relation and our ground truth was DB pedia and we find the usual boring graphs in the sense that more information helps."
        ],
        [
            "So this is basically was a description of WWT.",
            "You know this and I was like personally very surprised to find so much information over so just semi structured 2006 web cloud.",
            "You know?",
            "In fact in our query when we started with the Wikipedia tables which were the recent Wikipedia dump, we were able to augment the Wikipedia tables with 25% more rows.",
            "This is like manually it has been verified.",
            "So there is in fact you can also augment Wikipedia tables from the web if you are doing it in high quality enough manner and the main things which are different in our system, we try to do a lot of the work online use because of perhaps my personal bias.",
            "Lot of statistical learning and the one which the part which I found interesting is that you have to do all of these things in open domain kind of way.",
            "You cannot assume anything about the schema.",
            "And these are the different kinds of statistical learning models that we have found.",
            "To be able to use fruitfully in the system.",
            "Thank you questions.",
            "Questions.",
            "Make sure you label a column German physicists.",
            "What if there are three French philosophers?"
        ],
        [
            "What would be the semantics of that?",
            "I'm asking myself too, so Chilean or watch this very, you know, based on training data.",
            "So we label we have all these features will train, and when the model says back off, generalize will generalize.",
            "So.",
            "Table.",
            "A bunch of German physicists but also have a bunch of them.",
            "Who lives longer French philosopher or German physicist?",
            "They have two of them, both in the table is the table about French German physicist.",
            "No, it's actually, you know, we our semantics of multi labeling.",
            "So when we label a column with a particular type, our semantics is that each and every entity is of that type.",
            "So we don't so multi labeling for us is A and so when we label something is German physicist.",
            "That means that it means that every cell is both a German and a physicist.",
            "It does not mean that some of them are German, some of them are physicist.",
            "Tiff.",
            "You might even have tables where there's a row that has no further pretty role for a sub sub header or something like that.",
            "Yeah, so that that role won't sign into.",
            "You have only a German physicist and you have a row saying you know these.",
            "These guys are from the Frankfurt area, so if it is 1 out of 25, we will call a German physicist, but it's 3 out of 10.",
            "We will say it's famous personality.",
            "Yes.",
            "Yeah, we could climb up to person or entity here.",
            "Yep.",
            "The way you interpret tables and on the web compared to what a long day?",
            "So it seems to me that along kind of implicitly postulated a table is primarily about wine entity class, and then all the columns are attributes of that fact, whereas you, according to your labeling, you think of each column at the class events and then you have emotions.",
            "Ships embedded in the table and I wonder whether what could be the possible impact on the ability.",
            "For example, if you have a table which have like movies and actors, but then there's another table which has only actors and yet another which has only movies.",
            "Does this give you a better handle on collective learning and maybe a lot of users that angle?",
            "Yeah, you know I agree with alone that 95% of the tables are about one subject and properties of the subject, but you know we are academics, so we go after that.",
            "The more interesting tables.",
            "And I know what he's doing is actually more useful.",
            "Yeah, so.",
            "Made up on the fly.",
            "Yeah.",
            "Function other than HTML like parsing tables on PS and often.",
            "Video video, yeah, you could do that, yes?",
            "How would you hold you?",
            "Yes, actually this work.",
            "You know there's some, but I don't remember his name now.",
            "But in the World Wide Web 2007 there is this work where they talk about how to sort of use visual clues to construct tables out of any arbitrary document format.",
            "So yes, that could be an input, so we have not dwell too much on actually getting the same structure from the raw sources, and those could just be sort of additional plugins.",
            "To the system.",
            "I do have an engineer working on trying to think about it, yes.",
            "Not the kind of work you want to do with you, yes.",
            "Programming and come up with something that's neat.",
            "You know there is, especially if your goal is to actually make search better than you want it because there's a lot of data in PDF, and I think some of them started yet might be easier to get the caption and you have references to everybody, right?",
            "So creators public.",
            "It keep it.",
            "This has been, you know there has been a lot of work in this document processing Community lot, so maybe there's a lot of detailed work.",
            "If you care, you can look at it.",
            "Sup.",
            "Yeah yeah, OK.",
            "Thanks again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A second talk on tables and in fact this is work is inspired by the web tables work.",
                    "label": 0
                },
                {
                    "sent": "It came at a point where I have been.",
                    "label": 0
                },
                {
                    "sent": "I've been working with publications and addresses for four years.",
                    "label": 0
                },
                {
                    "sent": "Five years applying really humid statistical machine, learning on literally solved datasets.",
                    "label": 0
                },
                {
                    "sent": "So this was very exciting.",
                    "label": 0
                },
                {
                    "sent": "You know, left poor interesting domains and topics, and it's certainly much more relevant and really OK.",
                    "label": 0
                },
                {
                    "sent": "But in my style there is going to be a lot of statistical machine learning, so much so that some of you might just be running out screaming for coffee.",
                    "label": 0
                },
                {
                    "sent": "You can only hope is to interrupt me with questions.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So they say, you know, if I'm also looking at this semi structured web which comprises tables and lists and other regular pages.",
                    "label": 0
                },
                {
                    "sent": "So anything which can give me sets of multi attribute records is of interest to me, but we're not looking at the deep web order form form based input, but that also implies that our data tends to be more noisy.",
                    "label": 0
                },
                {
                    "sent": "We're like looking at mom and pop tables so they're not necessarily machine generated.",
                    "label": 0
                },
                {
                    "sent": "Tables and they're kind of scattered all over in individual home pages, so we also face the problem that I don't talks about.",
                    "label": 0
                },
                {
                    "sent": "We don't know what this record sources about, so we may have all of this traditional problems and.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we are so we have this system which you're calling WWT for worldwide tables and currently we support two kinds of queries, so we return tables answers and you can get to those tables.",
                    "label": 0
                },
                {
                    "sent": "Tables are also relations in the database lingo and you can get to those tables either by giving some examples of relationships that you're after, so you could give us a names of people and the concepts that they are famous for.",
                    "label": 0
                },
                {
                    "sent": "Leave information you can ask by keyword queries, but there is one more very crucial difference and I think it's actually a very important difference.",
                    "label": 0
                },
                {
                    "sent": "So we actually somehow feel that there is only a small kind of semantic leap for a user to be typing keyboards in two text boxes or three text boxes rather than in one textbox and just buy this one difference that you will be typing.",
                    "label": 0
                },
                {
                    "sent": "Keywords describing the columns of whatever tables that you want.",
                    "label": 0
                },
                {
                    "sent": "You can certainly get lot more power so you can so you don't have to really make the assumptions that a table is only about one subject.",
                    "label": 0
                },
                {
                    "sent": "You can describe all the columns that you want by their individual keywords and you will get.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The tables such.",
                    "label": 0
                },
                {
                    "sent": "So our goal is to return tables like this.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We will do this through a system which does faster.",
                    "label": 0
                },
                {
                    "sent": "We have an offline call of the web.",
                    "label": 0
                },
                {
                    "sent": "We're not Google.",
                    "label": 0
                },
                {
                    "sent": "We are academics, so we have 1/2 billion offline crawl of the web from which we did a person extracted anything which looked like they could be offering record sources and we face the problems that allows group has solved of you know how to identify what tables actually are relational table as it comes presentation tables.",
                    "label": 0
                },
                {
                    "sent": "And then we'll also be extracting.",
                    "label": 0
                },
                {
                    "sent": "At this time, the lists and anything which looks like record data that is harder.",
                    "label": 0
                },
                {
                    "sent": "So we currently just base it on heuristics.",
                    "label": 0
                },
                {
                    "sent": "And then we do a bit of annotations.",
                    "label": 0
                },
                {
                    "sent": "If there is an existing ontology.",
                    "label": 0
                },
                {
                    "sent": "So currently we use Yahoo.",
                    "label": 0
                },
                {
                    "sent": "So if there is an existing ontology, will use the ontology to do as many annotations as we can.",
                    "label": 0
                },
                {
                    "sent": "But otherwise, because we don't really know schema or really just.",
                    "label": 0
                },
                {
                    "sent": "This is so many isolated, unrelated tables, we don't break our heads about understanding what tables and lists are trying to say before we actually get some interested user.",
                    "label": 0
                },
                {
                    "sent": "So we just stash those tables or lists.",
                    "label": 0
                },
                {
                    "sent": "Just does documents we just scratch them into collection of keywords and put them in a Lucene index.",
                    "label": 0
                },
                {
                    "sent": "That's all that we do it in the offline phase and then later when user poses a query of the type, the two types that I mentioned that we will be doing a little bit of type will kind of lightweight course rent type attachment to the columns would just maybe say whether it looks like a short string or a number or a date.",
                    "label": 0
                },
                {
                    "sent": "This can be extensible and.",
                    "label": 0
                },
                {
                    "sent": "Then we'll put the index, get a set of matching sources, and then we done this extractor.",
                    "label": 0
                },
                {
                    "sent": "This is where my old world comes in.",
                    "label": 0
                },
                {
                    "sent": "I applied statistical machine learning for doing these extractions and then we do the standard deduplication and ranking.",
                    "label": 0
                },
                {
                    "sent": "So, so here you know these two problems which before we started work on this.",
                    "label": 0
                },
                {
                    "sent": "I have been thinking for for five years but the time it was a very different problem because you knew what schema you are after.",
                    "label": 0
                },
                {
                    "sent": "So you had a trading place.",
                    "label": 0
                },
                {
                    "sent": "Then you knew the set of attributes and therefore you could design features which were suitable to that domain, whereas here we don't know whether we're going to ask.",
                    "label": 0
                },
                {
                    "sent": "We're good whether we're going to see a table query about movie actors and the roles that they play it, or it's going to be about oilfield disasters along with date of the disaster.",
                    "label": 0
                },
                {
                    "sent": "So that's all domain independent, so that raises new sets of challenges, so there are many interesting pieces in this machinery.",
                    "label": 0
                },
                {
                    "sent": "But I'm going to talk today about just two of these pieces.",
                    "label": 0
                },
                {
                    "sent": "The extractor and the annotator, so in in view of the team of this workshop.",
                    "label": 0
                },
                {
                    "sent": "So fast.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "About the extractor and in this part, I'm going to concentrate on the content query so this is a query you know for people who can interpret well and good for others who cannot.",
                    "label": 0
                },
                {
                    "sent": "This is how the computer will also look at it, it's just.",
                    "label": 0
                },
                {
                    "sent": "Assist you know grid of three by two, which has some sets of strings and now we do our index probe and we could get some arbitrary set of lists.",
                    "label": 0
                },
                {
                    "sent": "So these are, say maybe three sources that we have obtained and now we will use our extractor module and essentially this is the first time that we are trying to understand or interpret that raw source.",
                    "label": 0
                },
                {
                    "sent": "So here we have done an alignment of this source with respect to very lightly specified schema of the user.",
                    "label": 0
                },
                {
                    "sent": "So now that this individual sources are oriented as per the users sort of example specified schema, we have a collection of sources and on that we do the consolidation and duplication.",
                    "label": 0
                },
                {
                    "sent": "So now I'm just going to expand on this extraction bot.",
                    "label": 0
                },
                {
                    "sent": "So I am wondering about the approach how you chose this approach right to say I could given queries by example by example, I could I could take a different view right so I could somehow take each of those roles and turn into a query and search for documents that have answers to that query, and Furthermore has some write a bit of regular stretch with the hits for the query kind of formal regular structure?",
                    "label": 0
                },
                {
                    "sent": "So, for instance, a search for the Grand Prix more while skiing for 1008.",
                    "label": 0
                },
                {
                    "sent": "I might find that one of those roses.",
                    "label": 0
                },
                {
                    "sent": "One of those things is this, oh, I see they hit here.",
                    "label": 0
                },
                {
                    "sent": "So now he's just some regular structure.",
                    "label": 0
                },
                {
                    "sent": "Sticker prices.",
                    "label": 0
                },
                {
                    "sent": "You could do that.",
                    "label": 0
                },
                {
                    "sent": "On demand, rather than trying to extract the tables.",
                    "label": 0
                },
                {
                    "sent": "In the absence of knowledge of what it is that I'm looking so actually we don't really extract tables, we extract anything which is regular.",
                    "label": 0
                },
                {
                    "sent": "So we would also extract maybe pages, but so there is some false negatives that we might hit.",
                    "label": 0
                },
                {
                    "sent": "So yes, so you could if you had the refs in lots of machines you could do the regularity.",
                    "label": 0
                },
                {
                    "sent": "You know you could first just put the index on the web crawl.",
                    "label": 0
                },
                {
                    "sent": "What the tradeoff between these still exist machines?",
                    "label": 0
                },
                {
                    "sent": "Or visit or no, it's not a big issue.",
                    "label": 0
                },
                {
                    "sent": "I think it will equally well work in Google kind of infrastructure.",
                    "label": 0
                },
                {
                    "sent": "It will be there is no need to do an offline first call of the regular structure.",
                    "label": 0
                },
                {
                    "sent": "It's just something that we do and I don't think we are hit by it too much.",
                    "label": 0
                },
                {
                    "sent": "I don't think we have too much false negatives, but it's not something that I'm really strict about either way, so.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So now you know it's so so then Mississippi zoom into this extraction problem.",
                    "label": 0
                },
                {
                    "sent": "So what are the two issues which I found different in this problem compared to what I've been done?",
                    "label": 0
                },
                {
                    "sent": "But I've been doing in the past.",
                    "label": 0
                },
                {
                    "sent": "First is of course that we have basically almost no supervision, so just the 2 three example query rules that the user has provided and that too it's in an indirect manner.",
                    "label": 0
                },
                {
                    "sent": "We just have a small.",
                    "label": 0
                },
                {
                    "sent": "So like a mini database, there has been a lot of work and I myself have done a lot of work in doing extractions in the presence of databases.",
                    "label": 0
                },
                {
                    "sent": "But then we have always been assuming that the databases are huge here.",
                    "label": 0
                },
                {
                    "sent": "Even our database is tiny so on the one hand you want very robust techniques for labeling your unstructured lists and again as we have been assuming that the machines are pages are regular structures are not machine generated, so we want to use statistical learning techniques and rule based or Apple based.",
                    "label": 1
                },
                {
                    "sent": "Techniques we did not think would be robust for our kind of sources.",
                    "label": 0
                },
                {
                    "sent": "So on the one hand you need to label data, but so you want to because you have so few critters you want to squeeze as much as you can out of the query rows.",
                    "label": 0
                },
                {
                    "sent": "But on the other hand, because you have so little labeled data, if you do wrong matching of your unlabeled subsequences to what you think are structured matches in the query, then you will get a very wrong model.",
                    "label": 0
                },
                {
                    "sent": "Because your training and you know if you just have one or two label records, then you don't want to get any wrong labeling.",
                    "label": 0
                },
                {
                    "sent": "So there is a very tight rope that you have to walk on and we have in.",
                    "label": 0
                },
                {
                    "sent": "This will be 2009 paper described.",
                    "label": 0
                },
                {
                    "sent": "The details of the system and the main thing the main one sentence idea is that we use a library of similarity functions for each.",
                    "label": 0
                },
                {
                    "sent": "You know we do this lightweight typing of the columns in the query and based on that if we see that OK, this is a short text or this is a long text or if this is a date.",
                    "label": 0
                },
                {
                    "sent": "We have we choose from a bag of library of similarity functions.",
                    "label": 1
                },
                {
                    "sent": "The right kind of similarity function, and then we do a segmentation of that unstructured record so as to maximize similarity to the query rows.",
                    "label": 0
                },
                {
                    "sent": "After doing a bit of matching.",
                    "label": 0
                },
                {
                    "sent": "So that sort of is fine, and then we could independently train each source, but then more recently we have been working on this alternative approach where we want to do joint training over multiple TXT records.",
                    "label": 0
                },
                {
                    "sent": "So this is one thing which is very different and exciting about this new scenario that you actually have to build multiple models, and although you have very little supervision but you actually have a lot of redundancy so there is a lot of overlap.",
                    "label": 0
                },
                {
                    "sent": "Across sources, so that brings out an interesting machine learning problem.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Extraction, so this is unpublished to work, something that we've just like.",
                    "label": 0
                },
                {
                    "sent": "We are working on it for submission, so our goal is to, you know, we have this individual sources, and because each source has its own style, we have to train a separate model.",
                    "label": 0
                },
                {
                    "sent": "We cannot build a single model over all the sources, but there is overlap across the sources in the overlap is partial, so some set of some set of words in one source will be overlapping with some sort of words in another source.",
                    "label": 0
                },
                {
                    "sent": "So in this example, these are all exact matches, but we also consider it approximate match.",
                    "label": 0
                },
                {
                    "sent": "And so now we still have this kind of overlaps.",
                    "label": 0
                },
                {
                    "sent": "What are the ways in which you can exploit them?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But in the past people have been using collective inference techniques to exploit overlap.",
                    "label": 0
                },
                {
                    "sent": "So in collective inference methods you train individual models.",
                    "label": 1
                },
                {
                    "sent": "But you do inference.",
                    "label": 0
                },
                {
                    "sent": "Finally, when you actually come to the labeling, you do the labeling jointly so as to enforce agreement in the shared parts.",
                    "label": 0
                },
                {
                    "sent": "Now, but that only gives you benefit among the records which contain overlapping text with some other source.",
                    "label": 0
                },
                {
                    "sent": "But if you, when you're really in this resource constraint, and in the situation you really would like to again exploit the overlapped in the best possible manner and you get lot more leverage by training features from the overlapping text, which will generalize to other records.",
                    "label": 0
                },
                {
                    "sent": "So therefore collective training is better than collective inference.",
                    "label": 0
                },
                {
                    "sent": "Now collective training you could always do it in a lightweight manner, like you know what God was also presenting like you start from some set of seed labeled data.",
                    "label": 0
                },
                {
                    "sent": "And then you extract more labeled data, use that label data to label more records, and you do this thing in a loop.",
                    "label": 0
                },
                {
                    "sent": "But there is always, you know, by now computer scientists understand that there's this can always give rise to concept drift and you don't know when you will be cascading errors.",
                    "label": 0
                },
                {
                    "sent": "This is what we had written about in the LDP 2009 paper.",
                    "label": 0
                },
                {
                    "sent": "But we understand that there are problems with this approach.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now we have actually a joint training approach which.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Start suspended so you have less data sources.",
                    "label": 0
                },
                {
                    "sent": "Each source has a small amount of labeled data, let's call it Li, and there is a lot of unlabeled.",
                    "label": 0
                },
                {
                    "sent": "The set of records in each source.",
                    "label": 0
                },
                {
                    "sent": "And as I mentioned earlier, each source has its own feature set because some of it might be list with anchor text, text in tags.",
                    "label": 0
                },
                {
                    "sent": "Some of it might be a table with two columns and in one of the columns you have two attributes, so each has its own set of features and the overlap is expressed as.",
                    "label": 0
                },
                {
                    "sent": "What I'm be going calling is this letter A.",
                    "label": 0
                },
                {
                    "sent": "This is agreement set.",
                    "label": 0
                },
                {
                    "sent": "The agreement set consists of clicks and clicks are nothing but the snippet of overlapping text that I showed you earlier.",
                    "label": 0
                },
                {
                    "sent": "And now.",
                    "label": 0
                },
                {
                    "sent": "So I'm not necessarily they could be also in the labeled data, but for label data we already know the label, so we ignore them.",
                    "label": 0
                },
                {
                    "sent": "And because OK, so the other thing is because the label data for all the sources come from the same query record.",
                    "label": 0
                },
                {
                    "sent": "So if some snippet is labeled in one source, it would also be labeled in the other source.",
                    "label": 0
                },
                {
                    "sent": "So it's not like you have label today, so.",
                    "label": 0
                },
                {
                    "sent": "And now we will train this CRF models so this training is a joint training formulation.",
                    "label": 0
                },
                {
                    "sent": "So each model has its own set of parameters which we are calling as WI, and we have the usual term of maximizing the likelihood over the labeled data in each source, summing up overall sources.",
                    "label": 0
                },
                {
                    "sent": "So this is the usual CRF conditional likelihood maximization.",
                    "label": 0
                },
                {
                    "sent": "But then for the agreement set we have this additional term which will maximize the probability of the different sources agreeing on the set of common segments.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Then the overlap between all the yes, it's actually over all the sources, so that's what makes it.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Mention.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Actually, it can be very arbitrary.",
                    "label": 0
                },
                {
                    "sent": "No, actually we have seen later when you've seen the experiments.",
                    "label": 0
                },
                {
                    "sent": "So this is the file you know, so I can defer related to alone thing.",
                    "label": 0
                },
                {
                    "sent": "So initially you were in 2003 going and asking for data from people.",
                    "label": 0
                },
                {
                    "sent": "Now we have a rich amount of data so we have like 60 sources, 60 queries each query.",
                    "label": 0
                },
                {
                    "sent": "We have lists from 20 different sources with all kinds of variety of overlap.",
                    "label": 0
                },
                {
                    "sent": "So I guess I'm just concerned that one particular source didn't have a lot of information and like strength is set a. Yeah, I think yeah, so did you know that there are many different patterns of overlap?",
                    "label": 0
                },
                {
                    "sent": "Some queries you will have a lot of overlap, so here is an example of an agreement set.",
                    "label": 0
                },
                {
                    "sent": "So suppose if you think of these three sentences coming from three different sources that red, blue and green source, and here we have identified these clicks.",
                    "label": 0
                },
                {
                    "sent": "So this click involves source one and two.",
                    "label": 0
                },
                {
                    "sent": "This third, second click involves all three sources, so on and so forth.",
                    "label": 0
                },
                {
                    "sent": "So this is what is the input.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now we're going back to the formulation.",
                    "label": 0
                },
                {
                    "sent": "So we have this agreement.",
                    "label": 0
                },
                {
                    "sent": "Likelihood that we have to maximize, so I'll just elaborate a bit more on that that term, so here.",
                    "label": 0
                },
                {
                    "sent": "So this is the likelihood term returning shortage sorted form, and now this agreement term you need to look at a bit more carefully, so this submission is going over all possible labels that you can assign to text.",
                    "label": 0
                },
                {
                    "sent": "It appears in the agreement set somewhere in the agreement set.",
                    "label": 1
                },
                {
                    "sent": "I know OK, so because the different sources trained there, all one model, the probability of a particular labeling is equal to the product of the probability of the individual sources, right?",
                    "label": 0
                },
                {
                    "sent": "So you have there for this product are so each source has its probability term.",
                    "label": 1
                },
                {
                    "sent": "But because of this submission where the agreement set in this agreement set is shared across different sources, this term is actually very very non trivial to compute.",
                    "label": 0
                },
                {
                    "sent": "So how do you side?",
                    "label": 0
                },
                {
                    "sent": "So this is based on heuristics, and it could be noisy and this is 1 very important issue which decides which can which has impact on.",
                    "label": 0
                },
                {
                    "sent": "You know how exactly you should be computing this specific example, yes.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what can you decide?",
                    "label": 0
                },
                {
                    "sent": "You here's the thing, so he's definitely so.",
                    "label": 0
                },
                {
                    "sent": "This is basically all possible dominating.",
                    "label": 0
                },
                {
                    "sent": "Dominating clicks at each click consists of a sequence of words and the set of sources from which it comes for in which that sequence appears, and it has to be normal, dominating both in terms of the set of sources it covers and the size of the segment.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "It also has to do with the labeling that you know, so there is no labeling.",
                    "label": 0
                },
                {
                    "sent": "It's just a set of words, because this is over unlabeled data.",
                    "label": 0
                },
                {
                    "sent": "So we recognize.",
                    "label": 0
                },
                {
                    "sent": "Establishing created this graph purely on unlabeled, yes.",
                    "label": 0
                },
                {
                    "sent": "So a simple heuristic would just be to create a click out of every word which up repeats, but that can give rise too many wrong clicks.",
                    "label": 0
                },
                {
                    "sent": "So we do a bit of so far.",
                    "label": 0
                },
                {
                    "sent": "We have a sort of a graph regularised.",
                    "label": 0
                },
                {
                    "sent": "Yes it is a semi supervised learning approach, yes.",
                    "label": 0
                },
                {
                    "sent": "That's right, it's just that the regularization is not over the whole instance, but over a part of the instance and you supplied to structured models.",
                    "label": 0
                },
                {
                    "sent": "So there are computational issues and intractability issues, but otherwise it's semi supervised learning.",
                    "label": 0
                },
                {
                    "sent": "Parts of it.",
                    "label": 0
                },
                {
                    "sent": "And also you can think of it as multiview learning is just that, but we're doing multiple learning over the green part, so it's like for this shared part you can get.",
                    "label": 0
                },
                {
                    "sent": "View of its label from either source, the context in which it resides in source one or in Source 2.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So yes, so it's actually does.",
                    "label": 0
                },
                {
                    "sent": "It does overlap with many related concepts in machine learning, but you know if you look at, you know when you apply these concepts in the context of structure models, where there is partial overlap.",
                    "label": 0
                },
                {
                    "sent": "There are some interesting new issues that we have faced which we have not seen at just elsewhere, so so this time is actually the interesting part of this work, so it's actually not neither convex nor.",
                    "label": 1
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Given its injectable so so now so so, here are two interesting things I'm going to talk about this work, so one is.",
                    "label": 0
                },
                {
                    "sent": "So you can compute this term.",
                    "label": 0
                },
                {
                    "sent": "Through this process 1st I'm going to just describe the process without motivating why really?",
                    "label": 0
                },
                {
                    "sent": "So what so you have from each source?",
                    "label": 0
                },
                {
                    "sent": "Essentially the dependency graph of each source is a chain.",
                    "label": 0
                },
                {
                    "sent": "If you're using normal 1st order CRF's and now what we're going to do is based on this agreement set, we're going to fuse together the nodes across the different sources for any variable which is shared across more than one source, and we get this graph structure.",
                    "label": 0
                },
                {
                    "sent": "Let's call this suffused graph.",
                    "label": 0
                },
                {
                    "sent": "Now I'm going to claim that.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The stone that we are trying to evaluate.",
                    "label": 0
                },
                {
                    "sent": "Can actually be written as the difference of the log partition function.",
                    "label": 1
                },
                {
                    "sent": "With appropriately defined potentials over the fused graph.",
                    "label": 0
                },
                {
                    "sent": "Minus the sum of the log partition functions of the individual chains.",
                    "label": 0
                },
                {
                    "sent": "So actually I have not told you how how we define the potentials, but these diffused graph essentially counts the number of ways in which the different sources can agree.",
                    "label": 0
                },
                {
                    "sent": "Right, so this gives you the agreement.",
                    "label": 0
                },
                {
                    "sent": "The numerator of this term, and this gives you the denominator.",
                    "label": 0
                },
                {
                    "sent": "And this is actually what you have to evaluate.",
                    "label": 0
                },
                {
                    "sent": "So when you interpret it as a log partition function over a suitably defined graphical model, then you have lot more handle into the problem and once you will also interpret it this way, then it's also easy to define the gradient of the problem, it's just the expectation of the individual features of each of the sources with respect to this fused graph.",
                    "label": 0
                },
                {
                    "sent": "And this is the.",
                    "label": 0
                },
                {
                    "sent": "Old style expectation.",
                    "label": 0
                },
                {
                    "sent": "So we looked at.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "After this approach, which is the natural way you know based on the objective that we wrote, this is the competition that you would have to do.",
                    "label": 0
                },
                {
                    "sent": "And but it just turns out that in general, because of the arbitrary pattern of overlap, the first graph might be just wait, not detectable.",
                    "label": 0
                },
                {
                    "sent": "It's just you know you started with nice chains, but the moment you fuse together some arbitrary set of clicks from multiple sources, you can get something very very arbitrary, and computing the log partition function.",
                    "label": 0
                },
                {
                    "sent": "Of this used graph can in general be very complex and we tried many approximation techniques.",
                    "label": 0
                },
                {
                    "sent": "So this was only one set of run vein which you can solve this problem, But then the second approach.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is actually the question the objective to say that look, you know we're trying to enforce agreement over the entire set of clicks.",
                    "label": 0
                },
                {
                    "sent": "But really, what the user wants is to enforce as much agreement as possible, and perhaps if we assume some kind of independence among the agreements of individual clicks, let's say to start with, then we might get much more tractable problem.",
                    "label": 0
                },
                {
                    "sent": "So that's what this is.",
                    "label": 0
                },
                {
                    "sent": "The second approach.",
                    "label": 0
                },
                {
                    "sent": "So first let me know.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Debate with an example.",
                    "label": 0
                },
                {
                    "sent": "So here we had our original set of four clicks.",
                    "label": 0
                },
                {
                    "sent": "Suppose for each of the clicks we independently try to enforce agreement.",
                    "label": 0
                },
                {
                    "sent": "Then the fuse graph that we would be getting would be this really kind of manageable set of star graphs.",
                    "label": 0
                },
                {
                    "sent": "So they are fused in one location, but otherwise these are all small tree with graphs and inside each one of them you could tractably compute all the terms that are of interest to you.",
                    "label": 0
                },
                {
                    "sent": "So this is sort of like taking this.",
                    "label": 0
                },
                {
                    "sent": "Giant agreement term and breaking it as the sum of it.",
                    "label": 0
                },
                {
                    "sent": "So you have these agreements that you decompose that agreement set into smaller tractable sets, and then you just enforce independent agreement in each of the sets.",
                    "label": 0
                },
                {
                    "sent": "So this is the second approach.",
                    "label": 0
                },
                {
                    "sent": "And it turns out that the second approach.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Because it gives us exact inference and also you know usually when you start with your clicks.",
                    "label": 0
                },
                {
                    "sent": "Since you have obtained through some algorithm, they're not guaranteed to be perfect leaks, so you might have some errors in there.",
                    "label": 0
                },
                {
                    "sent": "You might say match off the one source with off the in another source where they might be actually belonging to two different sets of attributes.",
                    "label": 0
                },
                {
                    "sent": "So if you compute a giant fuse graph, then a mistake in one of the clicks is going to influence other clicks, because if you compute a group independent agreement, not only do you get tractability, you also get a bit of an error tolerance.",
                    "label": 0
                },
                {
                    "sent": "Now I've not proved it theoretically, but so little bit very nice, but so this is now.",
                    "label": 0
                },
                {
                    "sent": "We do these experiments on these kinds of queries and.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we have hand labeled queries over, so this is the method that we followed.",
                    "label": 0
                },
                {
                    "sent": "We started with Wikipedia tables and these are some samples of table topics that we looked at.",
                    "label": 0
                },
                {
                    "sent": "the TV series oil Spills Movie Awards.",
                    "label": 1
                },
                {
                    "sent": "You know, scientific names of species and for each of these we searched on the web.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We got many, many sources.",
                    "label": 0
                },
                {
                    "sent": "We were restricting ourselves to lists in this case and so we had 58 queries and for each of these 58 queries by searching the web, excluding Wikipedia.",
                    "label": 0
                },
                {
                    "sent": "That is my concern.",
                    "label": 0
                },
                {
                    "sent": "I was round tables on the web and people copy Wikipedia.",
                    "label": 0
                },
                {
                    "sent": "Yes, yeah no, no.",
                    "label": 0
                },
                {
                    "sent": "So it can actually.",
                    "label": 0
                },
                {
                    "sent": "Another reason we actually have a temporal mismatch.",
                    "label": 0
                },
                {
                    "sent": "So Wikipedia is current Wikipedia and the web corpus that we have is as of 2006.",
                    "label": 0
                },
                {
                    "sent": "So you know there are.",
                    "label": 0
                },
                {
                    "sent": "There's not too many.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so the end OK.",
                    "label": 0
                },
                {
                    "sent": "So the other reason why for this particular did workload.",
                    "label": 0
                },
                {
                    "sent": "There is no get.",
                    "label": 0
                },
                {
                    "sent": "There is absolutely guaranteed to be new.",
                    "label": 0
                },
                {
                    "sent": "Overlap is because our sources are lists and Wikipedia our queries tables.",
                    "label": 0
                },
                {
                    "sent": "But these are lists, right?",
                    "label": 0
                },
                {
                    "sent": "I mean if you copy a table from Wikipedia, why would you convert it through this list said so?",
                    "label": 0
                },
                {
                    "sent": "So we have this say around 2:20 HTML list sources from this half billion crawl of the web, and this consists of very different set of characteristics of data and we take three labeled records as the query set and we measure F1 accuracy and this is what?",
                    "label": 1
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You seem so in this first graph.",
                    "label": 0
                },
                {
                    "sent": "Here I am showing a difference in F1 accuracy with respect to the baseline, which just does independent training for each source, and I'm comparing three different approaches.",
                    "label": 0
                },
                {
                    "sent": "The first blue approach is joint training approach that I mentioned.",
                    "label": 0
                },
                {
                    "sent": "The red approach is what we had written about in the VLDB paper where we do this.",
                    "label": 0
                },
                {
                    "sent": "We hardly able once or sandwich transfer the labeling to the next source, so this is what we're calling as a staged approach.",
                    "label": 0
                },
                {
                    "sent": "And this green is doing collective inference.",
                    "label": 1
                },
                {
                    "sent": "So in general you of course you put in present charts.",
                    "label": 0
                },
                {
                    "sent": "You know I sometimes get bored presenting this is these.",
                    "label": 0
                },
                {
                    "sent": "Are they all predictable?",
                    "label": 0
                },
                {
                    "sent": "So anyway so.",
                    "label": 0
                },
                {
                    "sent": "But the good thing is that you know the collective influence is not that bad.",
                    "label": 1
                },
                {
                    "sent": "You know it gives us 86% with this joint training.",
                    "label": 0
                },
                {
                    "sent": "It gives us 87.5%.",
                    "label": 0
                },
                {
                    "sent": "But staged can be quite bad in some of the queries.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now this is what I find interesting.",
                    "label": 0
                },
                {
                    "sent": "It has a nontrivial story to say, so this is, you know, comparing.",
                    "label": 0
                },
                {
                    "sent": "So if we have grouped 58 queries through some means into some ten groups like this, and here you see accuracy numbers of the baseline and this red set of numbers.",
                    "label": 0
                },
                {
                    "sent": "These are two different ways of decomposing your agreement set into attractable graphs, and this green numbers are various methods of approximating the fused graph, which is actually solving the original objective.",
                    "label": 0
                },
                {
                    "sent": "And this one because I said this problem is also related to multiview learning.",
                    "label": 0
                },
                {
                    "sent": "So here we are comparing with the previous approach on multiple alone and we find that in general the decomposition based approach, even though we we make this independence assumptions, they perform much better.",
                    "label": 0
                },
                {
                    "sent": "You know for parameter estimation then the approximation based approach because they don't compute the gradient reliably and the trainer gets confused and so now.",
                    "label": 0
                },
                {
                    "sent": "But of course what will be interesting is to try MCMC also will try factory on this and see how it works.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So this is that equals about the collective training part, so you know.",
                    "label": 1
                },
                {
                    "sent": "So basically in the web scenario, when you are trying to do online query time extractions you are in this world where you have very little supervision but you have a lot of redundancy.",
                    "label": 1
                },
                {
                    "sent": "So this collective training mechanism is a paradigm to be thought of seriously for this kind of world.",
                    "label": 0
                },
                {
                    "sent": "But I must warn you at this point that running time is currently.",
                    "label": 0
                },
                {
                    "sent": "Sort of fish with the baseline takes the time X, then the collective approach will currently take 5X and we're working towards speeding it up and you can see obvious ways in which perhaps you can speed up, but there are some known of these approaches, also battery.",
                    "label": 0
                },
                {
                    "sent": "So, so the chat running time issue is there and of course the main challenge is how to deal with the intractability of the likelihood and the interesting observations which somewhat surprised me is that it's better to start a priori with a simpler model than to start with more accurate model and then be stumped by the intractability of the model.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then the second part of the talk.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to guess.",
                    "label": 0
                },
                {
                    "sent": "20 minutes.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so when I ask you question earlier and now is thinking about what you're saying.",
                    "label": 0
                },
                {
                    "sent": "Like you guys realize that maybe what I had in mind and what you're doing is somewhat different.",
                    "label": 0
                },
                {
                    "sent": "OK, because you actually.",
                    "label": 0
                },
                {
                    "sent": "Like the game.",
                    "label": 0
                },
                {
                    "sent": "We doing collective training trains but doing training.",
                    "label": 0
                },
                {
                    "sent": "Yes we have to do collective influence could imagine and a different view where you really don't need enforce agreement that we were using.",
                    "label": 0
                },
                {
                    "sent": "Just the agreement graph is regularize.",
                    "label": 0
                },
                {
                    "sent": "So you just kind of put the penalty on disagree.",
                    "label": 0
                },
                {
                    "sent": "But even if you use the regularizers you would if you want to solve for the.",
                    "label": 0
                },
                {
                    "sent": "Now, of course it depends on whether the regularizer is square regularizer.",
                    "label": 0
                },
                {
                    "sent": "Suppose if you scale distance it gives rise to better manageable terms.",
                    "label": 0
                },
                {
                    "sent": "Even then you will have the gradient will require collective inference.",
                    "label": 0
                },
                {
                    "sent": "Great.",
                    "label": 0
                },
                {
                    "sent": "'cause you're not depending on OK, so you know the PR regularization math method that I presented in this lights that is basically doing regularizer and that is in fact there we use them Whereas in this case even though our method of objective is on convex, we go ahead and do gradient descent anyway and that's like 10 times slower.",
                    "label": 0
                },
                {
                    "sent": "Yes, OK. OK, so any other questions?",
                    "label": 0
                },
                {
                    "sent": "Not in this.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "By description, this actually will write a lot to Alan stock, so we're looking at answering keyword queries, but the difference is that we have keywords over multiple columns.",
                    "label": 0
                },
                {
                    "sent": "All the columns that you want to see in the answer you describe them with keyboards, and now we are going to go after the tables.",
                    "label": 0
                },
                {
                    "sent": "So now the main question as Alan mentioned also is how do you get to the tables which are relevant?",
                    "label": 0
                },
                {
                    "sent": "Some cases you are lucky you might be able to get to the tables based on match.",
                    "label": 0
                },
                {
                    "sent": "In the header of the table, some of the tables have headers, but there are many tables which have nonsensical headers.",
                    "label": 0
                },
                {
                    "sent": "This is in fact Wikipedia table and it has these headers which do not help you get to the table, and there are tables without any headers.",
                    "label": 0
                },
                {
                    "sent": "And yes, you can use the context, so Alan was US history and I was asking you can use the context to get to the tables, but then you have this problem of you don't know what word in the context is relevant and stuff like that.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now so the basic idea.",
                    "label": 0
                },
                {
                    "sent": "It's like this.",
                    "label": 0
                },
                {
                    "sent": "The natural thing that smart people think about is using ontology to do the annotations of the table.",
                    "label": 0
                },
                {
                    "sent": "So we also want to do the annotation.",
                    "label": 0
                },
                {
                    "sent": "So given an ontology about chemical elements, if we annotate, we will do well and then we actually this part.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to go into details, but here also we use graphical models.",
                    "label": 0
                },
                {
                    "sent": "So finally what we have is a set of tables which we got obtained through the index probe from the query and four.",
                    "label": 0
                },
                {
                    "sent": "Each table we will be trying to label the columns based on clues that we combine from the text around the table so the text around the table will be used will be assigning potentials to all columns of the table because we don't know which column it is talking about an from the header of the table, we actually do a bit of header, so sometimes they're useful, so we'd combine it from the header and then from the ontology labels and then based on the overlap of the different table contents we have also.",
                    "label": 0
                },
                {
                    "sent": "A bit of regularization or similar.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The constraint on the.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Labels that they can take and we solve it using a joint labeling approach, which I'm not going to talk about.",
                    "label": 0
                },
                {
                    "sent": "Instead, I'm going to concentrate on the problem of annotate.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Game tables.",
                    "label": 0
                },
                {
                    "sent": "So this is the problem.",
                    "label": 0
                },
                {
                    "sent": "I'll talk about for the next 10 minutes.",
                    "label": 0
                },
                {
                    "sent": "So you have a table and this is a arbitrary table on the web and you have an ontology.",
                    "label": 0
                },
                {
                    "sent": "We use Yahoo.",
                    "label": 0
                },
                {
                    "sent": "It could be The Dirty ontology that alone has created.",
                    "label": 0
                },
                {
                    "sent": "Can be any ontology and the ontology has a type hierarchy and at the bottom we have a set of entities and both the type nodes and the entity nodes are attached with strings which described the node and these are the lemmas so so you could have.",
                    "label": 1
                },
                {
                    "sent": "Typically there are lemmas attached only with the entity nodes, but sometimes you also have lemmas attached with the type nodes.",
                    "label": 0
                },
                {
                    "sent": "And so this is our catalog.",
                    "label": 0
                },
                {
                    "sent": "OK, and in addition to this type of graph, it's not really a tree.",
                    "label": 0
                },
                {
                    "sent": "We also have relationships for some set of entities, so you could have like a set of relations, like in Jago.",
                    "label": 0
                },
                {
                    "sent": "For example, there are hundred order relationships.",
                    "label": 0
                },
                {
                    "sent": "Now our goal is to align this table with respect to an existing ontology and we do three kinds of annotations.",
                    "label": 0
                },
                {
                    "sent": "So we'll take the cells of the table and annotated with links to the entity nodes in the.",
                    "label": 0
                },
                {
                    "sent": "Catalog and we would take the type, the headers or the columns of the table and annotated with type nodes.",
                    "label": 0
                },
                {
                    "sent": "And we will take pairs of columns and we will annotate this with relational label and currently we are only looking at binary relations, so this is the task.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now there are the many challenges to doing this task.",
                    "label": 0
                },
                {
                    "sent": "Of course there is a lot of ambiguity.",
                    "label": 0
                },
                {
                    "sent": "Many noisy mentions Jago, you know, all these ontologies.",
                    "label": 0
                },
                {
                    "sent": "They're inherently multi labeled and the most difficult of the challenges we faced is that the ontologies are incomplete so therefore things like least common and sisters do not work when you want to generalize from entity labels to type notes, because there are many links which are missing.",
                    "label": 0
                },
                {
                    "sent": "So like in Yahoo.",
                    "label": 0
                },
                {
                    "sent": "Gerhard, the link from universities in Toronto to University in Ontario is missing the link from Satyajit Ray.",
                    "label": 1
                },
                {
                    "sent": "Indian film directors is missing so this may missing links.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So so so so you know there were some questions about why can't you use this clue?",
                    "label": 0
                },
                {
                    "sent": "Why can't you use that clue?",
                    "label": 0
                },
                {
                    "sent": "Here we have a model where we combine all kinds of clothes to do this, joint labeling of entity type in relationships in a table.",
                    "label": 0
                },
                {
                    "sent": "So we are collectively labeling biographical model.",
                    "label": 0
                },
                {
                    "sent": "So the set of variables that we have are the entity labels which are attached to each cell.",
                    "label": 0
                },
                {
                    "sent": "So our column see the type labels which are attached to each column and then between pair of columns we have the relationship labels.",
                    "label": 0
                },
                {
                    "sent": "And we define potentials over this set of variables as follows.",
                    "label": 0
                },
                {
                    "sent": "So for entities we define potentials which are basically derived from weighted features which capture all kinds of similarities between the contents that you see in the table and the lemmas which are attached with the catalog.",
                    "label": 0
                },
                {
                    "sent": "Similarly, between for the type nodes.",
                    "label": 0
                },
                {
                    "sent": "If there is, if the table has a header and if the table has meaningful context or caption, we will use it to define various kinds of similarity functions.",
                    "label": 0
                },
                {
                    "sent": "Features which can then be used to provide clues to doing type annotations of columns.",
                    "label": 0
                },
                {
                    "sent": "So another very interesting potential that we feature that we define here is to reward labeling.",
                    "label": 0
                },
                {
                    "sent": "Do not generalize too much so we penalize types which are.",
                    "label": 0
                },
                {
                    "sent": "To higher up.",
                    "label": 0
                },
                {
                    "sent": "So we want to keep things as specific as possible, while as far as the entity nodes allow specificity.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then we have a potential coupling entity and type notes.",
                    "label": 0
                },
                {
                    "sent": "So these are again driven by features.",
                    "label": 0
                },
                {
                    "sent": "So now, so this is the part where we do something special to handle missing links.",
                    "label": 0
                },
                {
                    "sent": "So if you are trying to propose to label a column with type label TC where a cell of that column you are labeling with DRC, then there are three cases that can arise.",
                    "label": 0
                },
                {
                    "sent": "Either there is a path from the entity node to the type node in the ontology, for example linear code, there is a path from Einstein's to physicist, so in such cases we will define a feature which is equal to the inverse of the distance between them.",
                    "label": 0
                },
                {
                    "sent": "So this kind of penalizes over generalization.",
                    "label": 0
                },
                {
                    "sent": "And you could also define more features which are inverse functions of the distance between them.",
                    "label": 0
                },
                {
                    "sent": "And if there is a sort of an entity in that column to which the type has no path.",
                    "label": 0
                },
                {
                    "sent": "For example, if you have a cell content which is Julius Plucker, and there is no path from Julius Plucker to German physicist, then does it mean that you cannot name this column?",
                    "label": 0
                },
                {
                    "sent": "German physicist, even if all other entity nodes point to German physicists, you can, because we make use of, we understand that the ontologies might be having missing links, so we use this feature, which is.",
                    "label": 0
                },
                {
                    "sent": "Basically, you know, we look at the parents of this entity, which actually exists in the ontology, and look at how many of those.",
                    "label": 0
                },
                {
                    "sent": "The how many children of that parent actually overlap with German physicist?",
                    "label": 1
                },
                {
                    "sent": "So we see in the ontology that Gerard Julius Plucker is a mathematician, and many mathematicians are physicians physicists.",
                    "label": 1
                },
                {
                    "sent": "So therefore we will attach a non 0 feature value to this coupling.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, if in that table cell you have Newton and if Newton has a parent called English physicist, because English physicist did not.",
                    "label": 0
                },
                {
                    "sent": "Coker with German physicist, this will be given no reward, you know, and therefore that column will most likely not be labeled German physicist and also in order to back off from labeling.",
                    "label": 0
                },
                {
                    "sent": "This is a very very hard task in all web domains.",
                    "label": 0
                },
                {
                    "sent": "We also look at how many introduce, not at all appear in the catalog.",
                    "label": 0
                },
                {
                    "sent": "And there is a constant feature value assigned to it.",
                    "label": 0
                },
                {
                    "sent": "This allows us to back off when we fail.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Similarly, we have potentials coupling relations and type types in the obvious ways.",
                    "label": 0
                },
                {
                    "sent": "There's not too many surprises here.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And finally we have this collective inference task where suppose if you have this table with three types, three columns and this three entity rows, then will be.",
                    "label": 0
                },
                {
                    "sent": "Each circle here denotes a variable and based on the potentials that I have defined, you have this dependency graph.",
                    "label": 0
                },
                {
                    "sent": "And you get something complicated, so we do approximate inference.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And by the way, we train those potentials using Max margin learning.",
                    "label": 0
                },
                {
                    "sent": "So this is a data set, we are if we have manually labeled 450 tables and we also automatically from Wikipedia, because many Wikipedia tables contain links to entity nodes, we got some partially labeled tables directly from Wikipedia and here you are seeing accuracy for these three kinds of labeling tasks, entity types and relationships for these two different datasets, the manually labeled data set and for the automatic label data set we only had entity labels, not the type and relationship labels.",
                    "label": 1
                },
                {
                    "sent": "And we see that we do quite well on the entity annotations, and we're comparing with least Homan and sister and majority based labels.",
                    "label": 0
                },
                {
                    "sent": "So basically it's saying that joint labeling myself.",
                    "label": 0
                },
                {
                    "sent": "But for type annotations, we're not doing very well, and one of the reasons is that we are very, very strict in measuring this accuracy.",
                    "label": 0
                },
                {
                    "sent": "So if you call.",
                    "label": 0
                },
                {
                    "sent": "Column which is German physicist.",
                    "label": 0
                },
                {
                    "sent": "If you call it physicist will still give a error of 0 error of one.",
                    "label": 0
                },
                {
                    "sent": "We don't give partial credit, so very often we are off by one.",
                    "label": 0
                },
                {
                    "sent": "Invest in quite County test full letter so.",
                    "label": 0
                },
                {
                    "sent": "So this is a type accuracy, therefore is low and relationship.",
                    "label": 0
                },
                {
                    "sent": "We don't have too much data on the relationship labeling, so these numbers are a bit pretty.",
                    "label": 0
                },
                {
                    "sent": "I would think the relationship numbers.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And now here is just a small workload to illustrate why this is a useful thing to do.",
                    "label": 0
                },
                {
                    "sent": "So we use the annotated data to answer queries of the form where you specify a type.",
                    "label": 0
                },
                {
                    "sent": "You say I am interested in answers of type movies and where I have this relationship directed by between a person entity which has elema George Clooney.",
                    "label": 0
                },
                {
                    "sent": "So you can try to answer this query without any of the annotations using obvious heuristics and you or you could use the annotations that we just talked about and we had this workload of this five relations acted in directed language, produced en route and we created 40 queries per relation and our ground truth was DB pedia and we find the usual boring graphs in the sense that more information helps.",
                    "label": 1
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is basically was a description of WWT.",
                    "label": 0
                },
                {
                    "sent": "You know this and I was like personally very surprised to find so much information over so just semi structured 2006 web cloud.",
                    "label": 0
                },
                {
                    "sent": "You know?",
                    "label": 0
                },
                {
                    "sent": "In fact in our query when we started with the Wikipedia tables which were the recent Wikipedia dump, we were able to augment the Wikipedia tables with 25% more rows.",
                    "label": 0
                },
                {
                    "sent": "This is like manually it has been verified.",
                    "label": 0
                },
                {
                    "sent": "So there is in fact you can also augment Wikipedia tables from the web if you are doing it in high quality enough manner and the main things which are different in our system, we try to do a lot of the work online use because of perhaps my personal bias.",
                    "label": 0
                },
                {
                    "sent": "Lot of statistical learning and the one which the part which I found interesting is that you have to do all of these things in open domain kind of way.",
                    "label": 0
                },
                {
                    "sent": "You cannot assume anything about the schema.",
                    "label": 0
                },
                {
                    "sent": "And these are the different kinds of statistical learning models that we have found.",
                    "label": 0
                },
                {
                    "sent": "To be able to use fruitfully in the system.",
                    "label": 0
                },
                {
                    "sent": "Thank you questions.",
                    "label": 0
                },
                {
                    "sent": "Questions.",
                    "label": 0
                },
                {
                    "sent": "Make sure you label a column German physicists.",
                    "label": 0
                },
                {
                    "sent": "What if there are three French philosophers?",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What would be the semantics of that?",
                    "label": 0
                },
                {
                    "sent": "I'm asking myself too, so Chilean or watch this very, you know, based on training data.",
                    "label": 0
                },
                {
                    "sent": "So we label we have all these features will train, and when the model says back off, generalize will generalize.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Table.",
                    "label": 0
                },
                {
                    "sent": "A bunch of German physicists but also have a bunch of them.",
                    "label": 0
                },
                {
                    "sent": "Who lives longer French philosopher or German physicist?",
                    "label": 0
                },
                {
                    "sent": "They have two of them, both in the table is the table about French German physicist.",
                    "label": 0
                },
                {
                    "sent": "No, it's actually, you know, we our semantics of multi labeling.",
                    "label": 0
                },
                {
                    "sent": "So when we label a column with a particular type, our semantics is that each and every entity is of that type.",
                    "label": 0
                },
                {
                    "sent": "So we don't so multi labeling for us is A and so when we label something is German physicist.",
                    "label": 0
                },
                {
                    "sent": "That means that it means that every cell is both a German and a physicist.",
                    "label": 0
                },
                {
                    "sent": "It does not mean that some of them are German, some of them are physicist.",
                    "label": 0
                },
                {
                    "sent": "Tiff.",
                    "label": 0
                },
                {
                    "sent": "You might even have tables where there's a row that has no further pretty role for a sub sub header or something like that.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so that that role won't sign into.",
                    "label": 0
                },
                {
                    "sent": "You have only a German physicist and you have a row saying you know these.",
                    "label": 0
                },
                {
                    "sent": "These guys are from the Frankfurt area, so if it is 1 out of 25, we will call a German physicist, but it's 3 out of 10.",
                    "label": 0
                },
                {
                    "sent": "We will say it's famous personality.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Yeah, we could climb up to person or entity here.",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "The way you interpret tables and on the web compared to what a long day?",
                    "label": 0
                },
                {
                    "sent": "So it seems to me that along kind of implicitly postulated a table is primarily about wine entity class, and then all the columns are attributes of that fact, whereas you, according to your labeling, you think of each column at the class events and then you have emotions.",
                    "label": 0
                },
                {
                    "sent": "Ships embedded in the table and I wonder whether what could be the possible impact on the ability.",
                    "label": 0
                },
                {
                    "sent": "For example, if you have a table which have like movies and actors, but then there's another table which has only actors and yet another which has only movies.",
                    "label": 0
                },
                {
                    "sent": "Does this give you a better handle on collective learning and maybe a lot of users that angle?",
                    "label": 0
                },
                {
                    "sent": "Yeah, you know I agree with alone that 95% of the tables are about one subject and properties of the subject, but you know we are academics, so we go after that.",
                    "label": 0
                },
                {
                    "sent": "The more interesting tables.",
                    "label": 0
                },
                {
                    "sent": "And I know what he's doing is actually more useful.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so.",
                    "label": 0
                },
                {
                    "sent": "Made up on the fly.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Function other than HTML like parsing tables on PS and often.",
                    "label": 0
                },
                {
                    "sent": "Video video, yeah, you could do that, yes?",
                    "label": 0
                },
                {
                    "sent": "How would you hold you?",
                    "label": 0
                },
                {
                    "sent": "Yes, actually this work.",
                    "label": 0
                },
                {
                    "sent": "You know there's some, but I don't remember his name now.",
                    "label": 0
                },
                {
                    "sent": "But in the World Wide Web 2007 there is this work where they talk about how to sort of use visual clues to construct tables out of any arbitrary document format.",
                    "label": 0
                },
                {
                    "sent": "So yes, that could be an input, so we have not dwell too much on actually getting the same structure from the raw sources, and those could just be sort of additional plugins.",
                    "label": 0
                },
                {
                    "sent": "To the system.",
                    "label": 0
                },
                {
                    "sent": "I do have an engineer working on trying to think about it, yes.",
                    "label": 0
                },
                {
                    "sent": "Not the kind of work you want to do with you, yes.",
                    "label": 0
                },
                {
                    "sent": "Programming and come up with something that's neat.",
                    "label": 0
                },
                {
                    "sent": "You know there is, especially if your goal is to actually make search better than you want it because there's a lot of data in PDF, and I think some of them started yet might be easier to get the caption and you have references to everybody, right?",
                    "label": 0
                },
                {
                    "sent": "So creators public.",
                    "label": 0
                },
                {
                    "sent": "It keep it.",
                    "label": 0
                },
                {
                    "sent": "This has been, you know there has been a lot of work in this document processing Community lot, so maybe there's a lot of detailed work.",
                    "label": 0
                },
                {
                    "sent": "If you care, you can look at it.",
                    "label": 0
                },
                {
                    "sent": "Sup.",
                    "label": 0
                },
                {
                    "sent": "Yeah yeah, OK.",
                    "label": 0
                },
                {
                    "sent": "Thanks again.",
                    "label": 0
                }
            ]
        }
    }
}