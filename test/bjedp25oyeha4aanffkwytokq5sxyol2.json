{
    "id": "bjedp25oyeha4aanffkwytokq5sxyol2",
    "title": "Artificial Intelligence: Techniques, Trends and Applications",
    "info": {
        "author": [
            "Marko Robnik \u0160ikonja, Fakulteta za ra\u010dunalni\u0161tvo in informatiko, Univerza v Ljubljani"
        ],
        "published": "May 18, 2020",
        "recorded": "February 2020",
        "category": [
            "Top->Computer Science",
            "Top->Computer Science->Artificial Intelligence",
            "Top->Social Sciences"
        ]
    },
    "url": "http://videolectures.net/AIindustrySeminar2019_robnik_sikonja_artificial/",
    "segmentation": [
        [
            "So we start with an overview of AI, recent trends, techniques, applications."
        ],
        [
            "So what we're going to talk about will be mostly, let's say, artificial Intelligence, View 2 recent deep neural networks which will present to some of the selected applications, and Meanwhile we also mentioned the trends which are going on.",
            "So if we."
        ],
        [
            "Look at the AI in the media.",
            "There are lots of, let's say hype around AI, so we're able to destroy us where they take.",
            "Our jobs will be still necessary with driver crisis since will be necessary when we need doctors.",
            "Will you manually troubles developed?",
            "Maybe we'll have to become cyborgs and, well, lots of talk about artificial general intelligence and technological singularity web, which will take over eventually.",
            "So not surprisingly, there's.",
            "Lots of media groups who guide us in this direction.",
            "So for example."
        ],
        [
            "It's but it's traditional in the area of AI, so we have like from the 1965 Herbert Simon, one of the proponents of AI who set machine will be capable between 20 years of doing anywhere command can do well.",
            "Lucky he just said the men, not women.",
            "But anyway in 70s Marvel win scheme.",
            "Actually one of the creators of neural networks said that country to 8 years we have a machine that will be like capable or general intelligence of an average human being.",
            "And we have this recent components.",
            "You are surely know, but which do have some, let's say conflict of interest in that areas.",
            "So."
        ],
        [
            "What actually is a I?",
            "I assume that because you are here, you are interested in a little bit deeper than general public that you are maybe even working within the area of AI.",
            "So there's been a lot of research in AI and also in applications.",
            "So AI is coming from the computer science, neurology, math, psychology, and then we actually we did some general methods which are applicable in many areas of industry, science, society.",
            "Like machine learning, data mining data science.",
            "Recently another buzzword, natural language processing vision vision is really catching on and lots of things are going on in robotics in evolutionary computation, which is sort of like general techniques for optimization industry.",
            "Maybe reinforcement learning sort of self learning for many industrial controllers and then we have planning, reasoning, multi agent systems and lots of tons of applications in many areas.",
            "So this recent trends which we are seeing and this hype is actually the result of, let's say, revival of deep neural networks.",
            "So let's see."
        ],
        [
            "Deep neural networks are and how they work, so the basic idea is that you have like some brain analogy and newer cell in the brain looks like this is like a newer cell and you have some input, or dendrites which receive some, let's say excitations.",
            "And when this cell is excited enough it sends a signal to its excellence with output output and then excite other cells are the neurons.",
            "Which is a sort of similar to what we have in artificial neural network which has an input weighted input and then some of those inputs together.",
            "And if that sum exceeds certain crash holds then we send the output signal.",
            "So you can imagine that if this is like a visual neuron and this is, these are the signals coming from the from the I, then if there's a let's say a bear appearing here, then this signal will react this new and react strongly and send like.",
            "Danger similar to other neurons.",
            "Of course, the single neuron isn't really much important.",
            "That's why we connect the neurons into networks.",
            "So many cells connected together, typically organized in layers for the computational reason, but unlike brain, right?",
            "What we learn this newer networks is by an algorithm called error back propagation, which actually means that once we have an output and if that output is not correct, we propagated out backwards and and actually the knowledge of this network is stored in this weights.",
            "So we collect these traits and so long we repeat this process so so long that these weights are correctly set and the network outputs the correct output.",
            "So I'm sure you."
        ],
        [
            "Pretty much know about that, so around 2009 that was really revival of what is now called deep learning, which means deep neural networks at that time already.",
            "Let's say 20 years old.",
            "But what was new was that suddenly we large datasets became available and also the computational power grow immensely with the GPU.",
            "So graphical processing unit coming from their games, but they eventually contain it's thousands of processors.",
            "Which can simultaneously parallel process this.",
            "This newer cells and this made things practically important.",
            "Well, since this was happening in 2009 and here now in 2020.",
            "In between there were many bright new ideas and deep learning actually did is responsible for many of the great applications which are seeing today.",
            "So."
        ],
        [
            "So why this neural networks work and how they work and why they're better than standard machine learning approaches, so we can see on this simple example, let's suppose that we want to recognize what is in this image.",
            "Let's say a card.",
            "So what the newer network processes?",
            "So in the first layers, it actually recognized not much, not much, let's say intelligence.",
            "It recognize the, let's say Carlo area, so a little bit of edges.",
            "But in the next layer, let's in the middle layer of features they would recognize like edges and circles and.",
            "A little bit more higher level knowledge and eventually on those higher in the next layer.",
            "Further layers before the output you will see like things like the Hives and Biggs and some parts of the images which we then eventually classify into a call.",
            "So why is this better than standard machine learning approaches?",
            "Because actually we built the representation.",
            "So if we humans see the picture like the pixels pixel don't have much of a meaning for us, but we eventually construct those features into more higher level features like.",
            "Beaks and edges, and so on and in the neural networks.",
            "That happens automatically, so we don't need to do it manually, and so it was done before before the.",
            "Let's say this deep neural network hype.",
            "OK, so."
        ],
        [
            "So this is the reason why they work and they really work.",
            "I mean they produced lots of success stories.",
            "For example, this image classification is now let's say on the level of humans for many things in medical domain, practically there's no recognition without the without these machines and lots of success in games like Poker Go in Robotics, in speech recognition we're having almost superhuman performance in some areas.",
            "Driving costs, intelligence costs, video tracking and so on, so."
        ],
        [
            "So there of course some weaknesses which we have to mention it, which are important for many applications in SoC.",
            "For example, a trained neural network thinks that this is Robin.",
            "This is cheetah that this is a Penguin, starfish, remote controller, and so on.",
            "So why this happens?",
            "Because if we know the the trained weights, remember we have the weights or actually the knowledge of the neural networks.",
            "We can tweak the input so that it fools that trained networks.",
            "And that's that's problematic for example, especially in this case, for example, we."
        ],
        [
            "Have a picture which is banana right?",
            "And the classifier is like almost 100% certain that this really is banana.",
            "But once we put the sticker sort of a sticker like this on this picture, now the network tries to think that this is a poster with almost 100% probability and it's worse.",
            "We can put the same sticker on this J picture and now it thinks that it's toasted again with high probability.",
            "So maybe this is not so.",
            "Maybe this is important?",
            "That's safer self driving car.",
            "If somebody would put the sticker on the traffic sign but not so much in the last industrial environment where the image Ng is much more controlled but we have to be aware."
        ],
        [
            "Where that data sets which we prepare have to be of the of the correct, let's say variance for example.",
            "This we have intentionally, let's say changed dramatically changed pictures like this is a school bus and the neural network is almost 100% sure that this is a school bus.",
            "But once we do some geometrical tweaking, this becomes garbage.",
            "Truck punching back or snow plow and this might be a problematic but reminds us of the weaknesses and of the fragility of this approach.",
            "Which has to be of course sold with the proper data set.",
            "OK, so."
        ],
        [
            "If we could go to the let's say the main areas of where the junior networks are really successful, that would be vision and sequences like text.",
            "So envision.",
            "The main idea is probably convolutional neural networks, which are currently the most successful approach.",
            "What does it does it?",
            "Actually we have a small filter which traverses the image and reportes results to one level above.",
            "And what is great about this idea is that basically we don't know we don't have to specify these filters in advance.",
            "We actually learn them.",
            "We learn what sort of filter we need for, let's say for medical images.",
            "What sort of filters we need for, let's say, traffic, images and so on so.",
            "And this is actually the reason why imaging is so successful."
        ],
        [
            "So for example, an example fracture detection with deep neural networks, so this is for example, one application which was very successful.",
            "For example on this image even the, let's say the orthopedist health problems to see the fracture.",
            "But deep neural network trains with 10s of thousands of, let's say images annotated by human experts.",
            "Bye bye.",
            "That's a professional.",
            "Doctors actually can detect this fracture and so this caps for example.",
            "People in emergency room which don't have these expertise to really quickly detect fractures.",
            "So for example, there might be a fracture here for untrained people and but the neural network, equipped with the knowledge from the specialist can detect that.",
            "So there."
        ],
        [
            "Any similar applications, for example in medicine, all sorts of imaging has now, let's say superhuman performance for many things, and we read that in the in the popular press as well, and then there are also many industrial applications.",
            "So for example surface anomaly detection or damage detection, different measuring systems for example, this is 1 applications we did in our Department."
        ],
        [
            "Of hive detection.",
            "So the damage which is caused by the hive on the car.",
            "So many similar applications actually, and for another thing."
        ],
        [
            "For example, in visual tracking, so for many things like sport, people and so on, where on the on the video you have to detect the person and many different areas.",
            "As well, riots, security systems and so on exactly every year there's like a worldwide competition of visual tracking, which is which is going on which people actually from the faculty of Computer and Information Science.",
            "Actually the group of professor might take Winston are doing.",
            "So."
        ],
        [
            "In computer vision, the trends, if I mentioned them, lots of applications, lots of new things in pattern recognition combined with machine learning in robotics, in video analysis and also in combining images and text so deep neural networks have this capability that they project image ingane text into the same, let's say space and then actually image in context becomes the same.",
            "Let's say representation have the same representation.",
            "Also lots of biometrics and applications in many areas.",
            "For example."
        ],
        [
            "Another area where deep learning is really successful would be sequences.",
            "For example, you might see think that this is like a typical Electro cardio cardio gram for the hard bit and it is a sort of.",
            "But this is audiogram so actually if you put the sound recorder like a microphone on the chest you get more or less very similar results.",
            "Then you would have you Electro cardio gram so and this actually is like a proof why speech is speech recognition is so successful.",
            "This cost in the signals we can we actually find really valid valid signal and varied patterns.",
            "So speech text text is also sequence right?",
            "We read text sequentially, so it's sort of a sequence.",
            "So and the ideas which are here, let's say wake two XI recurrent neural networks and Transformers network recently with the attention mechanism."
        ],
        [
            "So this is grouped under the area which is called semantic language technologies and actually is part of everyday communication in most of developed countries like we communicate with our mobile devices, we perform all sorts of intelligence search.",
            "We use digital assistants like Alexa and others, intelligence software intelligence costs maybe not yet self driving cars will see about that.",
            "Electronic toys, household appliances.",
            "Machine translation we're using automatic summarization question answering, writing aids and so on.",
            "So of course we want to communicate with these devices in many different languages, including serve in an.",
            "So there's actually in worldwide.",
            "There's a strong need to cover this lowest source languages with what is called cross lingual technologies.",
            "So if."
        ],
        [
            "Want to see how this text will work?",
            "How can your networks process the text?",
            "We need to come to the term which is quote embeddings.",
            "It means how to basically prepare the text into the numeric form so that newer networks will be able to process them because you remember, neural networks can only process the numerical input.",
            "So basically we train the neural networks on what is called the language model and then words become numerical vectors.",
            "For example of dimension 200 or 700.",
            "So in that numerical space, we want to preserve the semantic properties of the text.",
            "For example, things like Banana and Mango should be much closer in that numerical spec space.",
            "Then for example Doc, which is much different, right?",
            "So that's the idea.",
            "So we have to train the neural networks so that it transform word into semantically equivalent space.",
            "And once we have that then then all these applications which I mentioned before would actually be possible."
        ],
        [
            "So, like this one from the semantic technologies.",
            "So they set this embeddings, which should capture share relational meaning.",
            "For example, the difference between vectors of kink and men should be approximately the same as the difference between woman and the Queen, and the same is true for the pace in France and Italy and Rome and so on.",
            "So many of these semantic relationship have to be preserved, and they are preserved the way we train this neural networks."
        ],
        [
            "So this brings us also to cross lingual embeddings, 'cause once we have this embeddings, all the words form a sort of a cloud in this high dimensional space.",
            "And it turns out that different languages have different spaces, but they can be aligned so many for example.",
            "So in cloud of words can be aligned with the English cloud of words and that that actually enables that we do a translation between one cloud to another and use an English model for the SUV in, so that's what is going on recently with this cross lingual embeddings.",
            "So there's."
        ],
        [
            "One project which we are part of together with the Ocean Steven Institute and the Group of Professor another large which actually scored in bed.",
            "Yeah and actually researchers and do practical applications in this cross lingual embedding for less represented languages, especially for the media industry."
        ],
        [
            "So a few trends in language processing so.",
            "Now actually now we have.",
            "I mean recent plans.",
            "Let's say wait within the last year or last two years is that we have now huge pre trained neural language models and huge means that they are trained on terabytes of data.",
            "So that means that we are actually capable of capturing many many different relations in language with this like neural networks like Transformers for example there's a model code multilingual Bert which supports 100.",
            "Whole language is by training on 104 Wikipedias and it needs no.",
            "I mean it can be directly applied to many different languages.",
            "Let's say things like hate speech detection or common filtering and so on.",
            "All these things can be done on the learning several languages at once and then applying it on another or some other languages.",
            "So for example, we sent model, so this is really going fast on recent XMR was actually trained on 2 1/2 terabytes of text.",
            "So of course that was possible by Giants of, let's say of processing like Facebook and Google.",
            "These are, but they're publishing this result.",
            "I mean, they are freely available and anybody can use them.",
            "So for solving for example, they also exist.",
            "This source of model.",
            "This source of embeddings, like more burdens on some of them, for example L1.",
            "But we produced within the project which I mentioned.",
            "They are publicly available on the website, like in SI.",
            "So.",
            "Speaking about trends, there's a recent tender of Ministry of Culture and serve in which will actually produce lots of resources for Serbian language.",
            "For example, sufficient number of recordings.",
            "So the speech recognition will be publicly available and speech generation with public available and lots of these technologies which I mentioned like summarization, question, answering and so on are supposed to be solved within that project.",
            "So in two years hope, let's hope."
        ],
        [
            "So another trend which I have to mention is so-called explainable AI.",
            "So what we have today with this neural networks we have actually.",
            "We can model Switcher back boxes so we don't know what's going on inside them.",
            "I mean similar to what we don't know what is happening inside the human brains.",
            "So what to do?",
            "So there are actually many areas we are very much concerned with the transparency of the models like medicine, law consultancy, public services and so on.",
            "And this actually this legal obligation under the EU General Data Protection Regulation that once you have let's say model which decides about a human being.",
            "It has to be explained.",
            "It has to be able to explain it.",
            "Its decision so that has left actually two lots of interesting explainable AI.",
            "So for example one of them."
        ],
        [
            "Methods which was produced in that.",
            "I mean it's possible to explain neural networks, so one of the methods was example the research effort of our group.",
            "It actually treats what is called perturbation based explanation.",
            "It actually trees the features.",
            "For example we have prediction based on the information ABC.",
            "Now we take the information about a away.",
            "We see we get some another prediction and that prediction is the contribution of a.",
            "So this idea has led to many.",
            "Let's say methods actual quote, population methods, which can explain also neural networks.",
            "So for example."
        ],
        [
            "This is an example, so we have a model here that's probabilistic radio based neural networks and it was predicting the cancer recurrence.",
            "So this neural network said there's 80% of cancer recurrence, but in fact there wasn't cancer recurrence.",
            "So the reason why this networks was so sure about it was for example, some of the lymph nodes and we can actually get these contributions of each of the features that say menopause and so on.",
            "We can get them from the neural network and explain that.",
            "So this is for example phonology."
        ],
        [
            "So a few general trends in AI.",
            "So as I said, what is going on?",
            "We have lots of these new architectures for deep neural networks like recently this this transformer networks, which seem to be more efficient than previous networks but require even more data.",
            "So we need we are getting new semantic resources and architectures.",
            "Also for less resource languages, serve in new representations of symbolic knowledge.",
            "These are mainly embeddings, so everything is now embedded into some numerical space with neural networks.",
            "Process them lots of cross lingual technology transfer learning is happening.",
            "That means that one problem is merged with some other problems so that they they actually the knowledge from one problem or the representation from one.",
            "Knowledge is transferred to another one.",
            "That means if you have more than one problem which are similar, why not train them together so huge tent is injecting knowledge into this new architectures, for example general knowledge and common sense reasoning.",
            "Integration of models between within areas and text like.",
            "Text and images.",
            "So all these are really trends which are coming and all there already some applications, although maybe not in industrial context."
        ],
        [
            "So a few conclusions on my talk, so there will be new exciting possibility to extract information from Image Ng, sound, text, Graphs, Time series, spectronic, health records and so on.",
            "So actually we are actually we are.",
            "Do we do live in exciting times for artificial intelligence.",
            "So there are also new methodological, ethical, social dilemmas.",
            "What to do with this?",
            "I will this increasing power and as a society we have to discuss about that.",
            "This also we have to mention that there are some limitations, so the knowledge we have in this neural network is fragile.",
            "It's partial knowledge because currently we have no models for it's a broader and general knowledge and intelligence.",
            "For example, chess is an example which was sold by computers.",
            "Nobody nowadays tells that this is intelligent because we have changed the definition of intelligence, right?",
            "Because of that so.",
            "But what we have to be aware that, like in the Middle Ages, when people were trying to look out of their limited word, we're sort of now trying to pick out pick in actually into our brain and see what's going on.",
            "And this brings us to whole, whole New World, which we cannot maybe know what to do with.",
            "So thanks.",
            "So your talk was very trendy in the sense that really, it mostly covered neural networks and kind of sub symbolic learning, and even the explanations that you propose to address were again explaining the decisions of neural networks.",
            "So do you think that the more classical knowledge based approaches to artificial intelligence are dead or they still to play some role?",
            "Yeah, definitely they're not dead.",
            "They're actually only viable.",
            "I would say becausw through the neural networks.",
            "We're coming to a certain barriers to a certain, let's say actually recent trends show that we want to integrate with what I mentioned.",
            "We want to integrate all sorts of new knowledge into deep neural network.",
            "We want to integrate common sense reasoning we want, and we have to be aware that all these texts and so on are still in the symbolic form.",
            "So the majority of human knowledge is stored in the symbolic form and.",
            "Somehow we need symbolic reasoning.",
            "We need logical reasoning which has to be integrated into this, let's say human.",
            "That sucks at newer architectures, so if we think of.",
            "For example, the mouse can see very well and the mouse can hear well, well, but we don't say it's intelligent, right?",
            "It's very good neural network processing, speech and text and so on.",
            "But it's not intelligence, so we have a whole layer here cortex, which was developed specifically for logical reasoning, and actually nowadays artificial intelligence hasn't touched much lot about it, so there's lots of work waiting for us."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we start with an overview of AI, recent trends, techniques, applications.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what we're going to talk about will be mostly, let's say, artificial Intelligence, View 2 recent deep neural networks which will present to some of the selected applications, and Meanwhile we also mentioned the trends which are going on.",
                    "label": 0
                },
                {
                    "sent": "So if we.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Look at the AI in the media.",
                    "label": 0
                },
                {
                    "sent": "There are lots of, let's say hype around AI, so we're able to destroy us where they take.",
                    "label": 0
                },
                {
                    "sent": "Our jobs will be still necessary with driver crisis since will be necessary when we need doctors.",
                    "label": 1
                },
                {
                    "sent": "Will you manually troubles developed?",
                    "label": 1
                },
                {
                    "sent": "Maybe we'll have to become cyborgs and, well, lots of talk about artificial general intelligence and technological singularity web, which will take over eventually.",
                    "label": 0
                },
                {
                    "sent": "So not surprisingly, there's.",
                    "label": 0
                },
                {
                    "sent": "Lots of media groups who guide us in this direction.",
                    "label": 0
                },
                {
                    "sent": "So for example.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It's but it's traditional in the area of AI, so we have like from the 1965 Herbert Simon, one of the proponents of AI who set machine will be capable between 20 years of doing anywhere command can do well.",
                    "label": 0
                },
                {
                    "sent": "Lucky he just said the men, not women.",
                    "label": 0
                },
                {
                    "sent": "But anyway in 70s Marvel win scheme.",
                    "label": 0
                },
                {
                    "sent": "Actually one of the creators of neural networks said that country to 8 years we have a machine that will be like capable or general intelligence of an average human being.",
                    "label": 1
                },
                {
                    "sent": "And we have this recent components.",
                    "label": 0
                },
                {
                    "sent": "You are surely know, but which do have some, let's say conflict of interest in that areas.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What actually is a I?",
                    "label": 0
                },
                {
                    "sent": "I assume that because you are here, you are interested in a little bit deeper than general public that you are maybe even working within the area of AI.",
                    "label": 0
                },
                {
                    "sent": "So there's been a lot of research in AI and also in applications.",
                    "label": 0
                },
                {
                    "sent": "So AI is coming from the computer science, neurology, math, psychology, and then we actually we did some general methods which are applicable in many areas of industry, science, society.",
                    "label": 1
                },
                {
                    "sent": "Like machine learning, data mining data science.",
                    "label": 1
                },
                {
                    "sent": "Recently another buzzword, natural language processing vision vision is really catching on and lots of things are going on in robotics in evolutionary computation, which is sort of like general techniques for optimization industry.",
                    "label": 0
                },
                {
                    "sent": "Maybe reinforcement learning sort of self learning for many industrial controllers and then we have planning, reasoning, multi agent systems and lots of tons of applications in many areas.",
                    "label": 0
                },
                {
                    "sent": "So this recent trends which we are seeing and this hype is actually the result of, let's say, revival of deep neural networks.",
                    "label": 0
                },
                {
                    "sent": "So let's see.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Deep neural networks are and how they work, so the basic idea is that you have like some brain analogy and newer cell in the brain looks like this is like a newer cell and you have some input, or dendrites which receive some, let's say excitations.",
                    "label": 1
                },
                {
                    "sent": "And when this cell is excited enough it sends a signal to its excellence with output output and then excite other cells are the neurons.",
                    "label": 1
                },
                {
                    "sent": "Which is a sort of similar to what we have in artificial neural network which has an input weighted input and then some of those inputs together.",
                    "label": 0
                },
                {
                    "sent": "And if that sum exceeds certain crash holds then we send the output signal.",
                    "label": 0
                },
                {
                    "sent": "So you can imagine that if this is like a visual neuron and this is, these are the signals coming from the from the I, then if there's a let's say a bear appearing here, then this signal will react this new and react strongly and send like.",
                    "label": 0
                },
                {
                    "sent": "Danger similar to other neurons.",
                    "label": 0
                },
                {
                    "sent": "Of course, the single neuron isn't really much important.",
                    "label": 0
                },
                {
                    "sent": "That's why we connect the neurons into networks.",
                    "label": 0
                },
                {
                    "sent": "So many cells connected together, typically organized in layers for the computational reason, but unlike brain, right?",
                    "label": 0
                },
                {
                    "sent": "What we learn this newer networks is by an algorithm called error back propagation, which actually means that once we have an output and if that output is not correct, we propagated out backwards and and actually the knowledge of this network is stored in this weights.",
                    "label": 0
                },
                {
                    "sent": "So we collect these traits and so long we repeat this process so so long that these weights are correctly set and the network outputs the correct output.",
                    "label": 0
                },
                {
                    "sent": "So I'm sure you.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Pretty much know about that, so around 2009 that was really revival of what is now called deep learning, which means deep neural networks at that time already.",
                    "label": 1
                },
                {
                    "sent": "Let's say 20 years old.",
                    "label": 0
                },
                {
                    "sent": "But what was new was that suddenly we large datasets became available and also the computational power grow immensely with the GPU.",
                    "label": 0
                },
                {
                    "sent": "So graphical processing unit coming from their games, but they eventually contain it's thousands of processors.",
                    "label": 0
                },
                {
                    "sent": "Which can simultaneously parallel process this.",
                    "label": 0
                },
                {
                    "sent": "This newer cells and this made things practically important.",
                    "label": 0
                },
                {
                    "sent": "Well, since this was happening in 2009 and here now in 2020.",
                    "label": 0
                },
                {
                    "sent": "In between there were many bright new ideas and deep learning actually did is responsible for many of the great applications which are seeing today.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So why this neural networks work and how they work and why they're better than standard machine learning approaches, so we can see on this simple example, let's suppose that we want to recognize what is in this image.",
                    "label": 0
                },
                {
                    "sent": "Let's say a card.",
                    "label": 0
                },
                {
                    "sent": "So what the newer network processes?",
                    "label": 0
                },
                {
                    "sent": "So in the first layers, it actually recognized not much, not much, let's say intelligence.",
                    "label": 0
                },
                {
                    "sent": "It recognize the, let's say Carlo area, so a little bit of edges.",
                    "label": 0
                },
                {
                    "sent": "But in the next layer, let's in the middle layer of features they would recognize like edges and circles and.",
                    "label": 0
                },
                {
                    "sent": "A little bit more higher level knowledge and eventually on those higher in the next layer.",
                    "label": 0
                },
                {
                    "sent": "Further layers before the output you will see like things like the Hives and Biggs and some parts of the images which we then eventually classify into a call.",
                    "label": 0
                },
                {
                    "sent": "So why is this better than standard machine learning approaches?",
                    "label": 1
                },
                {
                    "sent": "Because actually we built the representation.",
                    "label": 0
                },
                {
                    "sent": "So if we humans see the picture like the pixels pixel don't have much of a meaning for us, but we eventually construct those features into more higher level features like.",
                    "label": 0
                },
                {
                    "sent": "Beaks and edges, and so on and in the neural networks.",
                    "label": 0
                },
                {
                    "sent": "That happens automatically, so we don't need to do it manually, and so it was done before before the.",
                    "label": 0
                },
                {
                    "sent": "Let's say this deep neural network hype.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is the reason why they work and they really work.",
                    "label": 0
                },
                {
                    "sent": "I mean they produced lots of success stories.",
                    "label": 0
                },
                {
                    "sent": "For example, this image classification is now let's say on the level of humans for many things in medical domain, practically there's no recognition without the without these machines and lots of success in games like Poker Go in Robotics, in speech recognition we're having almost superhuman performance in some areas.",
                    "label": 0
                },
                {
                    "sent": "Driving costs, intelligence costs, video tracking and so on, so.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So there of course some weaknesses which we have to mention it, which are important for many applications in SoC.",
                    "label": 0
                },
                {
                    "sent": "For example, a trained neural network thinks that this is Robin.",
                    "label": 0
                },
                {
                    "sent": "This is cheetah that this is a Penguin, starfish, remote controller, and so on.",
                    "label": 0
                },
                {
                    "sent": "So why this happens?",
                    "label": 0
                },
                {
                    "sent": "Because if we know the the trained weights, remember we have the weights or actually the knowledge of the neural networks.",
                    "label": 0
                },
                {
                    "sent": "We can tweak the input so that it fools that trained networks.",
                    "label": 0
                },
                {
                    "sent": "And that's that's problematic for example, especially in this case, for example, we.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Have a picture which is banana right?",
                    "label": 0
                },
                {
                    "sent": "And the classifier is like almost 100% certain that this really is banana.",
                    "label": 0
                },
                {
                    "sent": "But once we put the sticker sort of a sticker like this on this picture, now the network tries to think that this is a poster with almost 100% probability and it's worse.",
                    "label": 0
                },
                {
                    "sent": "We can put the same sticker on this J picture and now it thinks that it's toasted again with high probability.",
                    "label": 0
                },
                {
                    "sent": "So maybe this is not so.",
                    "label": 0
                },
                {
                    "sent": "Maybe this is important?",
                    "label": 0
                },
                {
                    "sent": "That's safer self driving car.",
                    "label": 0
                },
                {
                    "sent": "If somebody would put the sticker on the traffic sign but not so much in the last industrial environment where the image Ng is much more controlled but we have to be aware.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Where that data sets which we prepare have to be of the of the correct, let's say variance for example.",
                    "label": 0
                },
                {
                    "sent": "This we have intentionally, let's say changed dramatically changed pictures like this is a school bus and the neural network is almost 100% sure that this is a school bus.",
                    "label": 0
                },
                {
                    "sent": "But once we do some geometrical tweaking, this becomes garbage.",
                    "label": 0
                },
                {
                    "sent": "Truck punching back or snow plow and this might be a problematic but reminds us of the weaknesses and of the fragility of this approach.",
                    "label": 0
                },
                {
                    "sent": "Which has to be of course sold with the proper data set.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If we could go to the let's say the main areas of where the junior networks are really successful, that would be vision and sequences like text.",
                    "label": 0
                },
                {
                    "sent": "So envision.",
                    "label": 0
                },
                {
                    "sent": "The main idea is probably convolutional neural networks, which are currently the most successful approach.",
                    "label": 1
                },
                {
                    "sent": "What does it does it?",
                    "label": 0
                },
                {
                    "sent": "Actually we have a small filter which traverses the image and reportes results to one level above.",
                    "label": 0
                },
                {
                    "sent": "And what is great about this idea is that basically we don't know we don't have to specify these filters in advance.",
                    "label": 0
                },
                {
                    "sent": "We actually learn them.",
                    "label": 0
                },
                {
                    "sent": "We learn what sort of filter we need for, let's say for medical images.",
                    "label": 0
                },
                {
                    "sent": "What sort of filters we need for, let's say, traffic, images and so on so.",
                    "label": 0
                },
                {
                    "sent": "And this is actually the reason why imaging is so successful.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for example, an example fracture detection with deep neural networks, so this is for example, one application which was very successful.",
                    "label": 1
                },
                {
                    "sent": "For example on this image even the, let's say the orthopedist health problems to see the fracture.",
                    "label": 1
                },
                {
                    "sent": "But deep neural network trains with 10s of thousands of, let's say images annotated by human experts.",
                    "label": 0
                },
                {
                    "sent": "Bye bye.",
                    "label": 0
                },
                {
                    "sent": "That's a professional.",
                    "label": 0
                },
                {
                    "sent": "Doctors actually can detect this fracture and so this caps for example.",
                    "label": 0
                },
                {
                    "sent": "People in emergency room which don't have these expertise to really quickly detect fractures.",
                    "label": 0
                },
                {
                    "sent": "So for example, there might be a fracture here for untrained people and but the neural network, equipped with the knowledge from the specialist can detect that.",
                    "label": 0
                },
                {
                    "sent": "So there.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Any similar applications, for example in medicine, all sorts of imaging has now, let's say superhuman performance for many things, and we read that in the in the popular press as well, and then there are also many industrial applications.",
                    "label": 0
                },
                {
                    "sent": "So for example surface anomaly detection or damage detection, different measuring systems for example, this is 1 applications we did in our Department.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of hive detection.",
                    "label": 0
                },
                {
                    "sent": "So the damage which is caused by the hive on the car.",
                    "label": 0
                },
                {
                    "sent": "So many similar applications actually, and for another thing.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For example, in visual tracking, so for many things like sport, people and so on, where on the on the video you have to detect the person and many different areas.",
                    "label": 0
                },
                {
                    "sent": "As well, riots, security systems and so on exactly every year there's like a worldwide competition of visual tracking, which is which is going on which people actually from the faculty of Computer and Information Science.",
                    "label": 0
                },
                {
                    "sent": "Actually the group of professor might take Winston are doing.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In computer vision, the trends, if I mentioned them, lots of applications, lots of new things in pattern recognition combined with machine learning in robotics, in video analysis and also in combining images and text so deep neural networks have this capability that they project image ingane text into the same, let's say space and then actually image in context becomes the same.",
                    "label": 1
                },
                {
                    "sent": "Let's say representation have the same representation.",
                    "label": 0
                },
                {
                    "sent": "Also lots of biometrics and applications in many areas.",
                    "label": 0
                },
                {
                    "sent": "For example.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Another area where deep learning is really successful would be sequences.",
                    "label": 1
                },
                {
                    "sent": "For example, you might see think that this is like a typical Electro cardio cardio gram for the hard bit and it is a sort of.",
                    "label": 0
                },
                {
                    "sent": "But this is audiogram so actually if you put the sound recorder like a microphone on the chest you get more or less very similar results.",
                    "label": 0
                },
                {
                    "sent": "Then you would have you Electro cardio gram so and this actually is like a proof why speech is speech recognition is so successful.",
                    "label": 0
                },
                {
                    "sent": "This cost in the signals we can we actually find really valid valid signal and varied patterns.",
                    "label": 0
                },
                {
                    "sent": "So speech text text is also sequence right?",
                    "label": 1
                },
                {
                    "sent": "We read text sequentially, so it's sort of a sequence.",
                    "label": 0
                },
                {
                    "sent": "So and the ideas which are here, let's say wake two XI recurrent neural networks and Transformers network recently with the attention mechanism.",
                    "label": 1
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is grouped under the area which is called semantic language technologies and actually is part of everyday communication in most of developed countries like we communicate with our mobile devices, we perform all sorts of intelligence search.",
                    "label": 1
                },
                {
                    "sent": "We use digital assistants like Alexa and others, intelligence software intelligence costs maybe not yet self driving cars will see about that.",
                    "label": 0
                },
                {
                    "sent": "Electronic toys, household appliances.",
                    "label": 1
                },
                {
                    "sent": "Machine translation we're using automatic summarization question answering, writing aids and so on.",
                    "label": 0
                },
                {
                    "sent": "So of course we want to communicate with these devices in many different languages, including serve in an.",
                    "label": 0
                },
                {
                    "sent": "So there's actually in worldwide.",
                    "label": 0
                },
                {
                    "sent": "There's a strong need to cover this lowest source languages with what is called cross lingual technologies.",
                    "label": 0
                },
                {
                    "sent": "So if.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Want to see how this text will work?",
                    "label": 0
                },
                {
                    "sent": "How can your networks process the text?",
                    "label": 0
                },
                {
                    "sent": "We need to come to the term which is quote embeddings.",
                    "label": 0
                },
                {
                    "sent": "It means how to basically prepare the text into the numeric form so that newer networks will be able to process them because you remember, neural networks can only process the numerical input.",
                    "label": 0
                },
                {
                    "sent": "So basically we train the neural networks on what is called the language model and then words become numerical vectors.",
                    "label": 1
                },
                {
                    "sent": "For example of dimension 200 or 700.",
                    "label": 0
                },
                {
                    "sent": "So in that numerical space, we want to preserve the semantic properties of the text.",
                    "label": 0
                },
                {
                    "sent": "For example, things like Banana and Mango should be much closer in that numerical spec space.",
                    "label": 0
                },
                {
                    "sent": "Then for example Doc, which is much different, right?",
                    "label": 0
                },
                {
                    "sent": "So that's the idea.",
                    "label": 0
                },
                {
                    "sent": "So we have to train the neural networks so that it transform word into semantically equivalent space.",
                    "label": 0
                },
                {
                    "sent": "And once we have that then then all these applications which I mentioned before would actually be possible.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, like this one from the semantic technologies.",
                    "label": 0
                },
                {
                    "sent": "So they set this embeddings, which should capture share relational meaning.",
                    "label": 1
                },
                {
                    "sent": "For example, the difference between vectors of kink and men should be approximately the same as the difference between woman and the Queen, and the same is true for the pace in France and Italy and Rome and so on.",
                    "label": 0
                },
                {
                    "sent": "So many of these semantic relationship have to be preserved, and they are preserved the way we train this neural networks.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this brings us also to cross lingual embeddings, 'cause once we have this embeddings, all the words form a sort of a cloud in this high dimensional space.",
                    "label": 1
                },
                {
                    "sent": "And it turns out that different languages have different spaces, but they can be aligned so many for example.",
                    "label": 0
                },
                {
                    "sent": "So in cloud of words can be aligned with the English cloud of words and that that actually enables that we do a translation between one cloud to another and use an English model for the SUV in, so that's what is going on recently with this cross lingual embeddings.",
                    "label": 0
                },
                {
                    "sent": "So there's.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One project which we are part of together with the Ocean Steven Institute and the Group of Professor another large which actually scored in bed.",
                    "label": 0
                },
                {
                    "sent": "Yeah and actually researchers and do practical applications in this cross lingual embedding for less represented languages, especially for the media industry.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So a few trends in language processing so.",
                    "label": 1
                },
                {
                    "sent": "Now actually now we have.",
                    "label": 0
                },
                {
                    "sent": "I mean recent plans.",
                    "label": 0
                },
                {
                    "sent": "Let's say wait within the last year or last two years is that we have now huge pre trained neural language models and huge means that they are trained on terabytes of data.",
                    "label": 1
                },
                {
                    "sent": "So that means that we are actually capable of capturing many many different relations in language with this like neural networks like Transformers for example there's a model code multilingual Bert which supports 100.",
                    "label": 0
                },
                {
                    "sent": "Whole language is by training on 104 Wikipedias and it needs no.",
                    "label": 0
                },
                {
                    "sent": "I mean it can be directly applied to many different languages.",
                    "label": 0
                },
                {
                    "sent": "Let's say things like hate speech detection or common filtering and so on.",
                    "label": 0
                },
                {
                    "sent": "All these things can be done on the learning several languages at once and then applying it on another or some other languages.",
                    "label": 0
                },
                {
                    "sent": "So for example, we sent model, so this is really going fast on recent XMR was actually trained on 2 1/2 terabytes of text.",
                    "label": 0
                },
                {
                    "sent": "So of course that was possible by Giants of, let's say of processing like Facebook and Google.",
                    "label": 0
                },
                {
                    "sent": "These are, but they're publishing this result.",
                    "label": 0
                },
                {
                    "sent": "I mean, they are freely available and anybody can use them.",
                    "label": 0
                },
                {
                    "sent": "So for solving for example, they also exist.",
                    "label": 0
                },
                {
                    "sent": "This source of model.",
                    "label": 0
                },
                {
                    "sent": "This source of embeddings, like more burdens on some of them, for example L1.",
                    "label": 0
                },
                {
                    "sent": "But we produced within the project which I mentioned.",
                    "label": 0
                },
                {
                    "sent": "They are publicly available on the website, like in SI.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Speaking about trends, there's a recent tender of Ministry of Culture and serve in which will actually produce lots of resources for Serbian language.",
                    "label": 0
                },
                {
                    "sent": "For example, sufficient number of recordings.",
                    "label": 0
                },
                {
                    "sent": "So the speech recognition will be publicly available and speech generation with public available and lots of these technologies which I mentioned like summarization, question, answering and so on are supposed to be solved within that project.",
                    "label": 0
                },
                {
                    "sent": "So in two years hope, let's hope.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So another trend which I have to mention is so-called explainable AI.",
                    "label": 0
                },
                {
                    "sent": "So what we have today with this neural networks we have actually.",
                    "label": 0
                },
                {
                    "sent": "We can model Switcher back boxes so we don't know what's going on inside them.",
                    "label": 0
                },
                {
                    "sent": "I mean similar to what we don't know what is happening inside the human brains.",
                    "label": 0
                },
                {
                    "sent": "So what to do?",
                    "label": 0
                },
                {
                    "sent": "So there are actually many areas we are very much concerned with the transparency of the models like medicine, law consultancy, public services and so on.",
                    "label": 1
                },
                {
                    "sent": "And this actually this legal obligation under the EU General Data Protection Regulation that once you have let's say model which decides about a human being.",
                    "label": 0
                },
                {
                    "sent": "It has to be explained.",
                    "label": 0
                },
                {
                    "sent": "It has to be able to explain it.",
                    "label": 0
                },
                {
                    "sent": "Its decision so that has left actually two lots of interesting explainable AI.",
                    "label": 0
                },
                {
                    "sent": "So for example one of them.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Methods which was produced in that.",
                    "label": 0
                },
                {
                    "sent": "I mean it's possible to explain neural networks, so one of the methods was example the research effort of our group.",
                    "label": 1
                },
                {
                    "sent": "It actually treats what is called perturbation based explanation.",
                    "label": 0
                },
                {
                    "sent": "It actually trees the features.",
                    "label": 1
                },
                {
                    "sent": "For example we have prediction based on the information ABC.",
                    "label": 0
                },
                {
                    "sent": "Now we take the information about a away.",
                    "label": 1
                },
                {
                    "sent": "We see we get some another prediction and that prediction is the contribution of a.",
                    "label": 0
                },
                {
                    "sent": "So this idea has led to many.",
                    "label": 0
                },
                {
                    "sent": "Let's say methods actual quote, population methods, which can explain also neural networks.",
                    "label": 0
                },
                {
                    "sent": "So for example.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is an example, so we have a model here that's probabilistic radio based neural networks and it was predicting the cancer recurrence.",
                    "label": 0
                },
                {
                    "sent": "So this neural network said there's 80% of cancer recurrence, but in fact there wasn't cancer recurrence.",
                    "label": 1
                },
                {
                    "sent": "So the reason why this networks was so sure about it was for example, some of the lymph nodes and we can actually get these contributions of each of the features that say menopause and so on.",
                    "label": 0
                },
                {
                    "sent": "We can get them from the neural network and explain that.",
                    "label": 0
                },
                {
                    "sent": "So this is for example phonology.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So a few general trends in AI.",
                    "label": 0
                },
                {
                    "sent": "So as I said, what is going on?",
                    "label": 0
                },
                {
                    "sent": "We have lots of these new architectures for deep neural networks like recently this this transformer networks, which seem to be more efficient than previous networks but require even more data.",
                    "label": 0
                },
                {
                    "sent": "So we need we are getting new semantic resources and architectures.",
                    "label": 1
                },
                {
                    "sent": "Also for less resource languages, serve in new representations of symbolic knowledge.",
                    "label": 0
                },
                {
                    "sent": "These are mainly embeddings, so everything is now embedded into some numerical space with neural networks.",
                    "label": 0
                },
                {
                    "sent": "Process them lots of cross lingual technology transfer learning is happening.",
                    "label": 0
                },
                {
                    "sent": "That means that one problem is merged with some other problems so that they they actually the knowledge from one problem or the representation from one.",
                    "label": 0
                },
                {
                    "sent": "Knowledge is transferred to another one.",
                    "label": 0
                },
                {
                    "sent": "That means if you have more than one problem which are similar, why not train them together so huge tent is injecting knowledge into this new architectures, for example general knowledge and common sense reasoning.",
                    "label": 0
                },
                {
                    "sent": "Integration of models between within areas and text like.",
                    "label": 1
                },
                {
                    "sent": "Text and images.",
                    "label": 0
                },
                {
                    "sent": "So all these are really trends which are coming and all there already some applications, although maybe not in industrial context.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So a few conclusions on my talk, so there will be new exciting possibility to extract information from Image Ng, sound, text, Graphs, Time series, spectronic, health records and so on.",
                    "label": 1
                },
                {
                    "sent": "So actually we are actually we are.",
                    "label": 0
                },
                {
                    "sent": "Do we do live in exciting times for artificial intelligence.",
                    "label": 0
                },
                {
                    "sent": "So there are also new methodological, ethical, social dilemmas.",
                    "label": 1
                },
                {
                    "sent": "What to do with this?",
                    "label": 0
                },
                {
                    "sent": "I will this increasing power and as a society we have to discuss about that.",
                    "label": 0
                },
                {
                    "sent": "This also we have to mention that there are some limitations, so the knowledge we have in this neural network is fragile.",
                    "label": 0
                },
                {
                    "sent": "It's partial knowledge because currently we have no models for it's a broader and general knowledge and intelligence.",
                    "label": 1
                },
                {
                    "sent": "For example, chess is an example which was sold by computers.",
                    "label": 0
                },
                {
                    "sent": "Nobody nowadays tells that this is intelligent because we have changed the definition of intelligence, right?",
                    "label": 0
                },
                {
                    "sent": "Because of that so.",
                    "label": 0
                },
                {
                    "sent": "But what we have to be aware that, like in the Middle Ages, when people were trying to look out of their limited word, we're sort of now trying to pick out pick in actually into our brain and see what's going on.",
                    "label": 0
                },
                {
                    "sent": "And this brings us to whole, whole New World, which we cannot maybe know what to do with.",
                    "label": 0
                },
                {
                    "sent": "So thanks.",
                    "label": 0
                },
                {
                    "sent": "So your talk was very trendy in the sense that really, it mostly covered neural networks and kind of sub symbolic learning, and even the explanations that you propose to address were again explaining the decisions of neural networks.",
                    "label": 0
                },
                {
                    "sent": "So do you think that the more classical knowledge based approaches to artificial intelligence are dead or they still to play some role?",
                    "label": 0
                },
                {
                    "sent": "Yeah, definitely they're not dead.",
                    "label": 0
                },
                {
                    "sent": "They're actually only viable.",
                    "label": 0
                },
                {
                    "sent": "I would say becausw through the neural networks.",
                    "label": 0
                },
                {
                    "sent": "We're coming to a certain barriers to a certain, let's say actually recent trends show that we want to integrate with what I mentioned.",
                    "label": 0
                },
                {
                    "sent": "We want to integrate all sorts of new knowledge into deep neural network.",
                    "label": 0
                },
                {
                    "sent": "We want to integrate common sense reasoning we want, and we have to be aware that all these texts and so on are still in the symbolic form.",
                    "label": 0
                },
                {
                    "sent": "So the majority of human knowledge is stored in the symbolic form and.",
                    "label": 0
                },
                {
                    "sent": "Somehow we need symbolic reasoning.",
                    "label": 0
                },
                {
                    "sent": "We need logical reasoning which has to be integrated into this, let's say human.",
                    "label": 0
                },
                {
                    "sent": "That sucks at newer architectures, so if we think of.",
                    "label": 0
                },
                {
                    "sent": "For example, the mouse can see very well and the mouse can hear well, well, but we don't say it's intelligent, right?",
                    "label": 0
                },
                {
                    "sent": "It's very good neural network processing, speech and text and so on.",
                    "label": 0
                },
                {
                    "sent": "But it's not intelligence, so we have a whole layer here cortex, which was developed specifically for logical reasoning, and actually nowadays artificial intelligence hasn't touched much lot about it, so there's lots of work waiting for us.",
                    "label": 0
                }
            ]
        }
    }
}