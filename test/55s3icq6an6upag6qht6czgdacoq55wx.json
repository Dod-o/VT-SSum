{
    "id": "55s3icq6an6upag6qht6czgdacoq55wx",
    "title": "Eliminating the Back-Tracking Step in the Longest Common Subsequence (LCSS) Algorithm for Video Sequence Matching",
    "info": {
        "author": [
            "Werner Bailer, Institute of Information Systems & Information Management, Joanneum Research"
        ],
        "published": "Dec. 18, 2008",
        "recorded": "December 2008",
        "category": [
            "Top->Computer Science->Visual Computing"
        ]
    },
    "url": "http://videolectures.net/samt08_bailer_ebts/",
    "segmentation": [
        [
            "Thank you very much for the opportunity to present my work here is to re mentioned already.",
            "The title is a bit bulky and as it's about eliminating one step in an algorithm, it's basically an optimization.",
            "So as we've heard today, context is everything.",
            "So I will spend some time to tell you about the algorithm and why we're doing it and then briefly go to the."
        ],
        [
            "Optimization so.",
            "The motivation is detecting repeated content in videos so I don't have to say too much about that because you'll hurt Ellen stock this morning.",
            "So if you have unstructured video with repeated things like repeat, it takes or similar problems and use video, we want to eliminate that kind of redundancy.",
            "So the core problem is when are two video clips similar, so it's basically to determine.",
            "What is the distance between two clips and then I will talk about the distance measure we've proposed about one year ago and the optimization step, which is actually the core topic of that paper, and then I will show you what we're doing with that."
        ],
        [
            "So for measuring the distance between video sequence, what do we need?",
            "Distance can be expressed in terms of different kinds of features, so we have to support different types of features.",
            "They can have discrete values or continuous values.",
            "They can be scholars or vectors, and they it might be possible to use simple distance function like Euclidean distance between them, but that might also be a quite complex type of distance functions between quite specific descriptors we need to support partial matching because it might one.",
            "Repetition might just be a part of the whole sequence.",
            "There can be different timing of sequences.",
            "There can be gaps and insertions like when you think of the actual retaking.",
            "In one instance, the extra might do something in between, or something might fall down, but they keep running and you want to see that something before that and after that is similar and there is a minimum length of useful match.",
            "So if we find one similar frame well we would not consider that as a retake.",
            "So when we look at approaches there is one class of approaches like just looking at keyframes.",
            "And when we think about using the sequence, there is dynamic time warping, which is basically a way of aligning sequences with finding a shortest match for each instant, and there is something coming from string editing which has that concept of inserting something, replacing something or deleting something."
        ],
        [
            "And that's what we're using.",
            "We have an algorithm which is based on the longest common subsequence matching algorithm, which is a variant of the string edit distance.",
            "So basically we build a matching metrics of the two sequences.",
            "And then you find matching the longest sequence with a backtracking step in the original algorithm, when you think about strings, each element is string is out of a discrete set of values, so they are either equal or day or not so.",
            "Determine equality of elements in the sequence is quite trivial.",
            "There has been work by locals and others who proposed applying that algorithm for 2D trajectories where they basically use a Euclidean distance between coordinates in 2D space and they introduce some threshold for the similarity.",
            "So for the distance and some offset, so if something is at the same position but very much later, it's still not similar."
        ],
        [
            "So how do we adopt that two videos?",
            "So instead of having 2D coordinates, we have sequences of feature vectors which can be made out of arbitrary features.",
            "And each separate feature in that will be matched with a quite specific distance function.",
            "The absolute temporal distance is irrelevant, because if something in the beginning of the video is a similar clip, and on the other tape it's at the end, that's still fine.",
            "It's still a similar video.",
            "But we have to consider that minimum length.",
            "And there is the concept of gaps, so if we find the useful match of one minute and for half a second, something is different.",
            "It's still a useful measure, not something that there are two separate things that are matching.",
            "So actually it turns out that that gap constraint changes a lot when we build it into the algorithm, so the longest common subsequence, which is basically the outcome of the algorithm, might not be the solution, because if in the longest matching sequence there is a big gap in it, it's not useful for our case, but all sufficiently long sequences that do not have these gaps are useful solutions.",
            "So this is basically the idea, and the similarity value is then.",
            "Just determined by the length of the match over the minimum of the length, because if you think about that, the minimum of the two sequences is the maximum length we could get in theory.",
            "So how does it look like?",
            "This is a kind of?"
        ],
        [
            "For example, instead of feature vectors, we just consider 1 dimensional sequences.",
            "So you see one sequence at the top and one to the left.",
            "Those are two sequences of values we want to match and assume 0.5 is our similarity threshold.",
            "Three is our length threshold, and we assume gaps of 1 S that metrics with all these values is basically what the traditional string matching approaches would give you.",
            "So every time you encounter such a value that is larger than the value.",
            "Left Button and left above it, we found a match and we increase that value and we end up with one value in the lower right corner and from there we can backtrack and basically any any backtracking yields a valid solution.",
            "So here the one shown in black.",
            "This is what you would typically get from the longest common subsequence algorithm.",
            "But if we look closer we said we want to have a gap of at most one element.",
            "So for this one.",
            "We have a match here and the next match we get is here because those two elements are not matching, so we have a gap of two which wildlights our constraints.",
            "So the longest sequence here is not a solution, but instead the two shown in Gray.",
            "They have the same length and they do not have this gap, so they're valid solutions.",
            "Now what you see is of course we have now two solutions, and they're partly overlapping.",
            "So."
        ],
        [
            "So to give you an idea of what that means in Unreal videos, this is a example on one of the track videos, so we have the video on both axes and.",
            "The blocks you see are basically made up by shots or sub shots, so that's why we get uniform values there, and this scale gives you the similarity value, so blue is not similar and the red one would be very similar.",
            "So you see, the retakes are typically subsequently on the tape, so you see in a temporal neighborhood we get these kind of matches, and we get quite different matches like the one in the beginning are just matching a bit.",
            "While we here get quite reliable matches.",
            "And that kind of result also helps us.",
            "Then if we want to build clusters of repeated content, because we can do a hierarchical clustering starting by these very reliable matches and then go down and avoid overlaps in the clusters."
        ],
        [
            "So for the optimization now.",
            "The problem we've seen before is actually we would have to do this backtracking step here for all the values that end in a sufficiently long sequence, so this increases the complexity of the algorithm a lot.",
            "But on the other hand, we can quit early if we encounter something that is has a large gap.",
            "So what we do is we keep a number of informations while building that sequence, like what the last matches in.",
            "In every line or every column, it doesn't make a difference.",
            "And then when we account and you match like 2 here we only have to look up in a in a range that is below our gap, here shown by the yellow area and every match we find in there is a sequence we can continue everything.",
            "This is that is outside can be discarded and this brings the complexity quite down a bit for doing this matching step.",
            "So I want to show you now what we're doing with that."
        ],
        [
            "Now starting the things I had them started before and I was not sure if it was having all these things opened it cause the trouble with the beamers.",
            "I'm starting it now.",
            "This is actually one of the summaries we generated for the trek with 2007 competition.",
            "And here we've used that algorithm to cluster that takes and as kind of decoration is L likes to call these things we show here the number of alternative takes that are also there for this sequence.",
            "So I just show you that video now.",
            "So you see here that this is basically also something that more or less continues from before, but as there was that incident with the umbrella that took quite a long time, we missed that one.",
            "So what we do then here is for each of those clusters of similar takes, we've taken a clip that has a lot of overlap with other things, so tries seems to represent that cluster well, and this is then the clip we include here.",
            "Another application of that information is in interactive video browsing.",
            "So it takes a bit to load and then I have to switch here to another data set because this one doesn't have retake information with it.",
            "So basically what you see here, if I scaled it down a bit, this is a video browsing tool using keyframes as visualization.",
            "So we basically start here with keyframes taken out of longer segments of the video, but it's just a random subset to give an overview and then the idea is you have here a list of automatically extracted features that you can use to cluster that content, and this is a way of narrowing down.",
            "And find a path through all that data and one of the features we've included here is retake information.",
            "So if I cluster by that you see here already, there are everything that is is coded in the same color is assumed to be the same.",
            "Take if assuming a bit.",
            "You see, we have here.",
            "That scene was the policeman standing here.",
            "We have that scene with those people coming down the street.",
            "Oh yeah, if I have to mouse over here, you see the the temporal context for for each of those keyframes and you also see here.",
            "Here is something that that obviously should be in that same cluster here, and we have the same situation here for for that street you see here that the guy with the red shirt is actually the director of this movie, and so he walks through it.",
            "It's basically the same setting is setting up the scene, but it's.",
            "Different kind of action taking place, so we put that into a separate cluster.",
            "So if we go further down here, you see all the different kinds of videos we we have in the truck with set what we get here is a is a by product which is quite nice in that one production.",
            "This is casualty.",
            "It's A kind of hospital series, they use that certain type of clapperboard.",
            "So we get all these things because the action is always the same.",
            "Moving it in, having it there for a short moment and taking it out and it's visually similar.",
            "So we get all that.",
            "The same types of clapperboard.",
            "Clustered as well and we get similar things here for the.",
            "For the other productions, as you see.",
            "So basically on that that kind of data we can get to to accuracy of something like 50 to 70%.",
            "It strongly depends on the segmentation in the input.",
            "This is also something Ellen mentioned this morning in one shot.",
            "We might have a number of different takes, so if we do not separate them well, it's rather it's rather under segmentation.",
            "It's a problem here.",
            "If we.",
            "Over segment we might still group them together later, but if we have two large snippets we find something similar and say, well, these two takes are similar, but in fact there might be one more take inside which then spoils the result.",
            "Yeah, so basically that's what I wanted to show.",
            "Thank you, and if you have questions.",
            "Anyway.",
            "Yes, at least for this task.",
            "I used to do other tasks as well, but it's quite a lot of work to do track with tasks."
        ],
        [
            "So I'm doing the summarization things now and other colleagues are doing like the high level feature extraction and search things.",
            "So thanks again here number 1, two and three of the poster session at their ability to enroll in this year's college."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you very much for the opportunity to present my work here is to re mentioned already.",
                    "label": 0
                },
                {
                    "sent": "The title is a bit bulky and as it's about eliminating one step in an algorithm, it's basically an optimization.",
                    "label": 0
                },
                {
                    "sent": "So as we've heard today, context is everything.",
                    "label": 0
                },
                {
                    "sent": "So I will spend some time to tell you about the algorithm and why we're doing it and then briefly go to the.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Optimization so.",
                    "label": 0
                },
                {
                    "sent": "The motivation is detecting repeated content in videos so I don't have to say too much about that because you'll hurt Ellen stock this morning.",
                    "label": 1
                },
                {
                    "sent": "So if you have unstructured video with repeated things like repeat, it takes or similar problems and use video, we want to eliminate that kind of redundancy.",
                    "label": 0
                },
                {
                    "sent": "So the core problem is when are two video clips similar, so it's basically to determine.",
                    "label": 1
                },
                {
                    "sent": "What is the distance between two clips and then I will talk about the distance measure we've proposed about one year ago and the optimization step, which is actually the core topic of that paper, and then I will show you what we're doing with that.",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for measuring the distance between video sequence, what do we need?",
                    "label": 0
                },
                {
                    "sent": "Distance can be expressed in terms of different kinds of features, so we have to support different types of features.",
                    "label": 0
                },
                {
                    "sent": "They can have discrete values or continuous values.",
                    "label": 1
                },
                {
                    "sent": "They can be scholars or vectors, and they it might be possible to use simple distance function like Euclidean distance between them, but that might also be a quite complex type of distance functions between quite specific descriptors we need to support partial matching because it might one.",
                    "label": 1
                },
                {
                    "sent": "Repetition might just be a part of the whole sequence.",
                    "label": 1
                },
                {
                    "sent": "There can be different timing of sequences.",
                    "label": 0
                },
                {
                    "sent": "There can be gaps and insertions like when you think of the actual retaking.",
                    "label": 0
                },
                {
                    "sent": "In one instance, the extra might do something in between, or something might fall down, but they keep running and you want to see that something before that and after that is similar and there is a minimum length of useful match.",
                    "label": 0
                },
                {
                    "sent": "So if we find one similar frame well we would not consider that as a retake.",
                    "label": 0
                },
                {
                    "sent": "So when we look at approaches there is one class of approaches like just looking at keyframes.",
                    "label": 0
                },
                {
                    "sent": "And when we think about using the sequence, there is dynamic time warping, which is basically a way of aligning sequences with finding a shortest match for each instant, and there is something coming from string editing which has that concept of inserting something, replacing something or deleting something.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And that's what we're using.",
                    "label": 0
                },
                {
                    "sent": "We have an algorithm which is based on the longest common subsequence matching algorithm, which is a variant of the string edit distance.",
                    "label": 1
                },
                {
                    "sent": "So basically we build a matching metrics of the two sequences.",
                    "label": 0
                },
                {
                    "sent": "And then you find matching the longest sequence with a backtracking step in the original algorithm, when you think about strings, each element is string is out of a discrete set of values, so they are either equal or day or not so.",
                    "label": 0
                },
                {
                    "sent": "Determine equality of elements in the sequence is quite trivial.",
                    "label": 1
                },
                {
                    "sent": "There has been work by locals and others who proposed applying that algorithm for 2D trajectories where they basically use a Euclidean distance between coordinates in 2D space and they introduce some threshold for the similarity.",
                    "label": 0
                },
                {
                    "sent": "So for the distance and some offset, so if something is at the same position but very much later, it's still not similar.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how do we adopt that two videos?",
                    "label": 0
                },
                {
                    "sent": "So instead of having 2D coordinates, we have sequences of feature vectors which can be made out of arbitrary features.",
                    "label": 1
                },
                {
                    "sent": "And each separate feature in that will be matched with a quite specific distance function.",
                    "label": 1
                },
                {
                    "sent": "The absolute temporal distance is irrelevant, because if something in the beginning of the video is a similar clip, and on the other tape it's at the end, that's still fine.",
                    "label": 1
                },
                {
                    "sent": "It's still a similar video.",
                    "label": 0
                },
                {
                    "sent": "But we have to consider that minimum length.",
                    "label": 0
                },
                {
                    "sent": "And there is the concept of gaps, so if we find the useful match of one minute and for half a second, something is different.",
                    "label": 0
                },
                {
                    "sent": "It's still a useful measure, not something that there are two separate things that are matching.",
                    "label": 0
                },
                {
                    "sent": "So actually it turns out that that gap constraint changes a lot when we build it into the algorithm, so the longest common subsequence, which is basically the outcome of the algorithm, might not be the solution, because if in the longest matching sequence there is a big gap in it, it's not useful for our case, but all sufficiently long sequences that do not have these gaps are useful solutions.",
                    "label": 1
                },
                {
                    "sent": "So this is basically the idea, and the similarity value is then.",
                    "label": 0
                },
                {
                    "sent": "Just determined by the length of the match over the minimum of the length, because if you think about that, the minimum of the two sequences is the maximum length we could get in theory.",
                    "label": 0
                },
                {
                    "sent": "So how does it look like?",
                    "label": 0
                },
                {
                    "sent": "This is a kind of?",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For example, instead of feature vectors, we just consider 1 dimensional sequences.",
                    "label": 0
                },
                {
                    "sent": "So you see one sequence at the top and one to the left.",
                    "label": 0
                },
                {
                    "sent": "Those are two sequences of values we want to match and assume 0.5 is our similarity threshold.",
                    "label": 0
                },
                {
                    "sent": "Three is our length threshold, and we assume gaps of 1 S that metrics with all these values is basically what the traditional string matching approaches would give you.",
                    "label": 0
                },
                {
                    "sent": "So every time you encounter such a value that is larger than the value.",
                    "label": 0
                },
                {
                    "sent": "Left Button and left above it, we found a match and we increase that value and we end up with one value in the lower right corner and from there we can backtrack and basically any any backtracking yields a valid solution.",
                    "label": 0
                },
                {
                    "sent": "So here the one shown in black.",
                    "label": 0
                },
                {
                    "sent": "This is what you would typically get from the longest common subsequence algorithm.",
                    "label": 0
                },
                {
                    "sent": "But if we look closer we said we want to have a gap of at most one element.",
                    "label": 0
                },
                {
                    "sent": "So for this one.",
                    "label": 0
                },
                {
                    "sent": "We have a match here and the next match we get is here because those two elements are not matching, so we have a gap of two which wildlights our constraints.",
                    "label": 0
                },
                {
                    "sent": "So the longest sequence here is not a solution, but instead the two shown in Gray.",
                    "label": 0
                },
                {
                    "sent": "They have the same length and they do not have this gap, so they're valid solutions.",
                    "label": 0
                },
                {
                    "sent": "Now what you see is of course we have now two solutions, and they're partly overlapping.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So to give you an idea of what that means in Unreal videos, this is a example on one of the track videos, so we have the video on both axes and.",
                    "label": 0
                },
                {
                    "sent": "The blocks you see are basically made up by shots or sub shots, so that's why we get uniform values there, and this scale gives you the similarity value, so blue is not similar and the red one would be very similar.",
                    "label": 0
                },
                {
                    "sent": "So you see, the retakes are typically subsequently on the tape, so you see in a temporal neighborhood we get these kind of matches, and we get quite different matches like the one in the beginning are just matching a bit.",
                    "label": 0
                },
                {
                    "sent": "While we here get quite reliable matches.",
                    "label": 0
                },
                {
                    "sent": "And that kind of result also helps us.",
                    "label": 0
                },
                {
                    "sent": "Then if we want to build clusters of repeated content, because we can do a hierarchical clustering starting by these very reliable matches and then go down and avoid overlaps in the clusters.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for the optimization now.",
                    "label": 0
                },
                {
                    "sent": "The problem we've seen before is actually we would have to do this backtracking step here for all the values that end in a sufficiently long sequence, so this increases the complexity of the algorithm a lot.",
                    "label": 0
                },
                {
                    "sent": "But on the other hand, we can quit early if we encounter something that is has a large gap.",
                    "label": 0
                },
                {
                    "sent": "So what we do is we keep a number of informations while building that sequence, like what the last matches in.",
                    "label": 0
                },
                {
                    "sent": "In every line or every column, it doesn't make a difference.",
                    "label": 0
                },
                {
                    "sent": "And then when we account and you match like 2 here we only have to look up in a in a range that is below our gap, here shown by the yellow area and every match we find in there is a sequence we can continue everything.",
                    "label": 0
                },
                {
                    "sent": "This is that is outside can be discarded and this brings the complexity quite down a bit for doing this matching step.",
                    "label": 0
                },
                {
                    "sent": "So I want to show you now what we're doing with that.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now starting the things I had them started before and I was not sure if it was having all these things opened it cause the trouble with the beamers.",
                    "label": 0
                },
                {
                    "sent": "I'm starting it now.",
                    "label": 0
                },
                {
                    "sent": "This is actually one of the summaries we generated for the trek with 2007 competition.",
                    "label": 0
                },
                {
                    "sent": "And here we've used that algorithm to cluster that takes and as kind of decoration is L likes to call these things we show here the number of alternative takes that are also there for this sequence.",
                    "label": 0
                },
                {
                    "sent": "So I just show you that video now.",
                    "label": 0
                },
                {
                    "sent": "So you see here that this is basically also something that more or less continues from before, but as there was that incident with the umbrella that took quite a long time, we missed that one.",
                    "label": 0
                },
                {
                    "sent": "So what we do then here is for each of those clusters of similar takes, we've taken a clip that has a lot of overlap with other things, so tries seems to represent that cluster well, and this is then the clip we include here.",
                    "label": 0
                },
                {
                    "sent": "Another application of that information is in interactive video browsing.",
                    "label": 0
                },
                {
                    "sent": "So it takes a bit to load and then I have to switch here to another data set because this one doesn't have retake information with it.",
                    "label": 0
                },
                {
                    "sent": "So basically what you see here, if I scaled it down a bit, this is a video browsing tool using keyframes as visualization.",
                    "label": 1
                },
                {
                    "sent": "So we basically start here with keyframes taken out of longer segments of the video, but it's just a random subset to give an overview and then the idea is you have here a list of automatically extracted features that you can use to cluster that content, and this is a way of narrowing down.",
                    "label": 0
                },
                {
                    "sent": "And find a path through all that data and one of the features we've included here is retake information.",
                    "label": 0
                },
                {
                    "sent": "So if I cluster by that you see here already, there are everything that is is coded in the same color is assumed to be the same.",
                    "label": 0
                },
                {
                    "sent": "Take if assuming a bit.",
                    "label": 0
                },
                {
                    "sent": "You see, we have here.",
                    "label": 0
                },
                {
                    "sent": "That scene was the policeman standing here.",
                    "label": 0
                },
                {
                    "sent": "We have that scene with those people coming down the street.",
                    "label": 0
                },
                {
                    "sent": "Oh yeah, if I have to mouse over here, you see the the temporal context for for each of those keyframes and you also see here.",
                    "label": 0
                },
                {
                    "sent": "Here is something that that obviously should be in that same cluster here, and we have the same situation here for for that street you see here that the guy with the red shirt is actually the director of this movie, and so he walks through it.",
                    "label": 0
                },
                {
                    "sent": "It's basically the same setting is setting up the scene, but it's.",
                    "label": 0
                },
                {
                    "sent": "Different kind of action taking place, so we put that into a separate cluster.",
                    "label": 0
                },
                {
                    "sent": "So if we go further down here, you see all the different kinds of videos we we have in the truck with set what we get here is a is a by product which is quite nice in that one production.",
                    "label": 0
                },
                {
                    "sent": "This is casualty.",
                    "label": 0
                },
                {
                    "sent": "It's A kind of hospital series, they use that certain type of clapperboard.",
                    "label": 0
                },
                {
                    "sent": "So we get all these things because the action is always the same.",
                    "label": 0
                },
                {
                    "sent": "Moving it in, having it there for a short moment and taking it out and it's visually similar.",
                    "label": 0
                },
                {
                    "sent": "So we get all that.",
                    "label": 0
                },
                {
                    "sent": "The same types of clapperboard.",
                    "label": 0
                },
                {
                    "sent": "Clustered as well and we get similar things here for the.",
                    "label": 0
                },
                {
                    "sent": "For the other productions, as you see.",
                    "label": 0
                },
                {
                    "sent": "So basically on that that kind of data we can get to to accuracy of something like 50 to 70%.",
                    "label": 0
                },
                {
                    "sent": "It strongly depends on the segmentation in the input.",
                    "label": 0
                },
                {
                    "sent": "This is also something Ellen mentioned this morning in one shot.",
                    "label": 0
                },
                {
                    "sent": "We might have a number of different takes, so if we do not separate them well, it's rather it's rather under segmentation.",
                    "label": 0
                },
                {
                    "sent": "It's a problem here.",
                    "label": 0
                },
                {
                    "sent": "If we.",
                    "label": 0
                },
                {
                    "sent": "Over segment we might still group them together later, but if we have two large snippets we find something similar and say, well, these two takes are similar, but in fact there might be one more take inside which then spoils the result.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so basically that's what I wanted to show.",
                    "label": 0
                },
                {
                    "sent": "Thank you, and if you have questions.",
                    "label": 0
                },
                {
                    "sent": "Anyway.",
                    "label": 0
                },
                {
                    "sent": "Yes, at least for this task.",
                    "label": 0
                },
                {
                    "sent": "I used to do other tasks as well, but it's quite a lot of work to do track with tasks.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I'm doing the summarization things now and other colleagues are doing like the high level feature extraction and search things.",
                    "label": 0
                },
                {
                    "sent": "So thanks again here number 1, two and three of the poster session at their ability to enroll in this year's college.",
                    "label": 0
                }
            ]
        }
    }
}