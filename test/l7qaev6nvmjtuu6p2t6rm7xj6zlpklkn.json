{
    "id": "l7qaev6nvmjtuu6p2t6rm7xj6zlpklkn",
    "title": "The Conditionally Independent Voice Model",
    "info": {
        "author": [
            "Christopher Raphael, School of Informatics and Computing, Indiana University"
        ],
        "published": "Dec. 29, 2007",
        "recorded": "December 2007",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/mbc07_raphael_civ/",
    "segmentation": [
        [
            "Well, first I begin with an apology.",
            "I realize I disappoint some people here.",
            "I don't have my oboe.",
            "I don't have the orchestra and for that matter, this talk is very unusual for me and that there's no audio in it at all.",
            "I hope that will be OK.",
            "I just thought I would talk about something completely different from what I often do.",
            "They, the conditionally independent voice model.",
            "This is work that I'm doing with two students of mine too.",
            "Good students.",
            "Gabby Teodoro an Eric Nichols.",
            "In one sense, this is really two talks that are sort of gently alighted, although I think you'll see a natural connection between the two.",
            "I hope so, at least.",
            "So the beginning of this talk.",
            "It's motivated by something that might be familiar to a number of people here.",
            "I don't know if anyone.",
            "Has ever had the experience of trying to model music, symbolic music, and starting with a single voice of music and finding well, single voices like a sequence and their natural modeling and analysis techniques that we get from mathematics and statistics to handle sequences.",
            "And this all works very nicely, and then we try and extend this to a more general model for music, polyphonic music and if we do this just in a purely straightforward way.",
            "Just by making my state space bigger, taking the cross product of the model with itself, if you will.",
            "Oh, there's just this exponential explosion.",
            "The number of parameters is your model just becomes horrid, the recognition problems become hard.",
            "It just doesn't generalize in a very natural way.",
            "My hope is this might be something that is familiar to people an I'm talking about a technique that I'd like to propose for well.",
            "It's called here breaking the logjam.",
            "Maybe that's.",
            "That might be a little bit too.",
            "Too ambitious, but at least something that might help a little bit.",
            "I get the whole thing on there.",
            "There we go.",
            "So well, here's a caricature of the idea.",
            "I hope you'll forgive this and not find it really silly, but so I have.",
            "I'm thinking of music in terms of voices, and here I have my 4 voices here.",
            "These are my 4 singers here down at the bottom.",
            "I don't know if you can recognize any of them, doesn't really matter and there are different pictures and by the different pictures I mean they cannot hear each other.",
            "They're in separate rooms, have no knowledge of what the others are going to do.",
            "And they're going to sing this Carol together, say good King Wenceslas, because this is my favorite.",
            "It doesn't really matter so much what it is.",
            "And of course you know they start off, and since their operating independently of one another, it's a total disaster.",
            "We can't possibly have any musical sense there.",
            "They won't be together in time or inflection or imbalance or in any way that's musically relevant.",
            "This is not so surprising.",
            "They are all if you will marching to their different drummers.",
            "So the idea of the model here is I'm."
        ],
        [
            "To give them a common drummer, there he is.",
            "He's from a little bit different world and the idea is now they can't hear one another, but they can all hear the drummer.",
            "This is the essential idea of the model.",
            "Is this notion of conditional independence?",
            "Everybody hears the drummer so everything that is important for the inner relationship of parts in the musical model comes through this other part that they hear.",
            "This is a very informal way of looking at it.",
            "It's a little bit silly, but."
        ],
        [
            "There it is.",
            "So I gradually get a little bit more and more specific.",
            "Can you see this?",
            "OK, well I can do that.",
            "I hope I don't start to lose it when I do let's see what happens.",
            "Here's the next level up.",
            "That doesn't help much, does.",
            "No, that that doesn't magnify the image.",
            "When I do that though, it just expands.",
            "Here's another 50% and now OK. Now I will expand this and let's try this.",
            "I might have to scroll a little bit to.",
            "Well, I'm gonna have to go down one.",
            "It's all explain it.",
            "I'm sorry about this.",
            "If you can't see everything you need to.",
            "So it's presented in sort of this formal way.",
            "It begins with, whereas these are my assumptions so, well.",
            "I'm imagining the music is composed of voices.",
            "Of course, this isn't always true, but this is the kind of music that I'm looking at now.",
            "Supposes it's composed of voices, and my thinking is each of these voices has got something that it tends to do, and it's something that I can model rather easily, like, oh, the baseline shows me simple things about the chord structure, an.",
            "Maybe I have a melody which prefers some combination of corn tones and odd chord tones.",
            "I don't know what it does, or maybe one part is the Chuck Chuck of the boom Chuck Chuck have all these separate parts that knows something about what they do.",
            "They have what I'm calling internal logic logic just to that separate voice.",
            "And of course it would be ridiculous for me to suppose that these voices evolve independently, like.",
            "Idea on my previous slide, the singers in the different rooms that would be a terrible idea.",
            "So the notion here is being really specific about the kind of dependence there is between the voices.",
            "So the idea is that they evolved together because they know about these shared attributes of the music.",
            "There's some harmonic structure that the music has, and the voices all know about that harmonic structure and maybe a rhythmic structure of phrase structure.",
            "This is known to all of them.",
            "So if you will, there's this thing that they know about and they respond to one another.",
            "Not directly, but because they both inherit this same information.",
            "This is the idea of conditionally independent voices, so still getting more more specific.",
            "I imagine I have this driving process, this is, I'm sorry.",
            "Can you make it better?",
            "I have this driving process.",
            "This is a Markov chain that describes what the voices need to know about the music, and I'll have a couple examples coming up, but maybe it's a process describing how harmony evolves over each measure.",
            "And I model the voices also as Markov chains, but they are no longer independent of one another.",
            "They are conditionally independent.",
            "The only thing that they know about is their own internal evolution, and this higher level driving process.",
            "I call it that they all inherit.",
            "So this is how they communicate with one another.",
            "So in essence I've been really explicit about how the models depend.",
            "All dependents between the voices happens through this driving process.",
            "So here are a couple examples.",
            "My thinking is I don't know if you'll agree, but I think this is rather general idea that might have a lot of applications.",
            "Will see.",
            "One thing that I'm going to talk about today is this first one pitch spelling.",
            "So here I've got a collection of voices I'm interested in recovering pitch spelling from MIDI F# or G flat, and I model each voice as being.",
            "You'll see more specifically in a minute, but it's a Markov chain.",
            "And the Markov change chains for each voice are conditionally independent given some global structure and hear what this is going to be as a functional harmonic analysis of the music measure by measure.",
            "So I'll talk about that.",
            "I'm not going to talk about the next two, but these are just an attempt to convince you that the idea might be a little bit more general.",
            "So the next one is about expressive inflection of music, automatic expressive inflection of music.",
            "So in this case, I've got some guiding or steering or driving process that encapsulates the overall expressive intent of the performance so that that would contain places of relaxation, places of emphasis, places where I move freely without emphasis.",
            "These are these are prosodic things.",
            "Maybe there might be things about musical affect also, I'm not sure exactly what an given that information.",
            "Now I allow the each individual voice to evolve independently, just given this shared information.",
            "Or the last example?",
            "It's about composition I suppose.",
            "Maybe more ambitious.",
            "I'm going to actually compose the music from this model.",
            "Well, the ragatz of the music, the notes in the rhythms, so my collection of voices are now Markov chains of notes and rhythm that evolve independently, conditionally, independently from one another given something shared, which I've called rather vaguely hear my overall musical plan.",
            "So that would need to have a lot of stuff in it.",
            "Things about what's going on with the harmony phrase structure maybe larger things with structure.",
            "Oh, I'm not sure what all it would have, and I'm not really thinking of this as being a model for generating Brahms or Mozart.",
            "Or maybe not even the Spice Girls, but there's still, I think, interesting applications for something I have in mind.",
            "Maybe something like computer games am model for generating music for computer games.",
            "Where the nature of the music evolves according to some game state that's changing, so the music needs to be composed on the fly because I won't know what the states are ahead of time.",
            "Or if you don't like that idea, maybe some sort of improvisatory music system.",
            "So somehow I separate the roles of the voices only depending on this global structure that they all know."
        ],
        [
            "OK, so now I'm going to talk more specifically about the.",
            "The note spelling.",
            "I'll Scroll down when I need to in a minute so.",
            "Here the goal is I have this collection of mini pitches like I get from a MIDI file and of course MIDI doesn't distinguish between the different spellings of notes.",
            "Is it a flat?",
            "Is it G#?",
            "And I want to fix this up.",
            "I want to spell things correctly, so admittedly, I mean it's a somewhat modest problem compared to, you know, some of the huge problems in this wonderful field.",
            "I'd still like to convince you, you ought to care about it a little bit.",
            "I don't know if people have ever had this experience of importing a MIDI file into their score writing program and seeing just this utter hash of note spellings.",
            "I find this very aggravating.",
            "'cause it makes the music hard for me to read, but maybe even a larger goal than that.",
            "Omidi's become the de facto standard symbolic representation.",
            "It's just what there's the most of now.",
            "And of course we're interested in moving Tord more expressive symbolic representations.",
            "Things that are more score like.",
            "And the natural way to do this is to take what we have and pull ourselves up by our bootstraps.",
            "We'd like to move all of this MIDI data gradually to more, more expressive things that knows about voice and knows about pitch, spelling, and knows more precisely about rhythm and other things indicated in scores.",
            "So there are basically two ideas that have been incorporated into this approach to pitch spelling.",
            "And the first, I think everyone will probably agree on this.",
            "This is this.",
            "I call this the vertical notion I had to spell notes according to the ambient key.",
            "All the folks who have worked in this at least have some nod in that direction, even if no ambient key or temporary key is identified.",
            "So you know if the music's indeed major, I should have some preference for F# over G flat.",
            "That's what I mean by horizontal, and then maybe more controversial.",
            "Is this notion of did I call that horizontal that was vertical?",
            "Maybe more controversial?",
            "Is this notion of horizontal motion?",
            "So that's something that happens in an individual voice, so a note.",
            "Indicated with a sharp tends to move up, F# tends to move up to G where the flat tells me I'm I'm tending to move down.",
            "A flat tends to move down to G. Oh, there's.",
            "The this doesn't come totally out of the blue.",
            "You can read about it in at rimsky.",
            "Korsakoff's got a treatise from Harmony Treatise from the 19th century that discuss is this.",
            "Presumably this was in the air before then.",
            "Some music theorists don't like this idea at all.",
            "Think of it as sort of a surrogate for deeper ideas, and I'm OK with that.",
            "It's fine if this is just a surrogate, it's something that fits really naturally into my computational framework, and I'm going to include it even if it isn't sort of the deepest way one can look at the problem.",
            "So here it is in a little bit more detail, here's the model, so I've got a Markov chain for key.",
            "So every measure has got a tonic Anna mode 12 possible tonics, two possible modes here, minor and major.",
            "That's this process on top.",
            "This is the driving process that guides everything.",
            "And that will evolve in in a way like you'd expect.",
            "I mean, most importantly the key.",
            "This measure tends to be like the key the previous measure.",
            "If it's going to modulate, probably it's going to go someplace close, like somewhere near on the circle of fifths.",
            "Or maybe a parallel or a relative relation.",
            "Something like that.",
            "Nothing, nothing too complicated.",
            "And given that model, I'm going to describe the models for the individual voices, so I called these the soul fedge models.",
            "So here are the states here.",
            "The states in each of these models are, well, the seven scale degrees, one through 7, and if you will, there are two choices for the various black nodes, so I might call them something sharp or something plus one flat.",
            "These are my states with the notion that, well, OK, I'll have lots of interesting transition structure, but maybe most importantly is incorporating this notion of motion.",
            "The sharps tend to move up.",
            "The flats tend to move down, and that's the difference between say two sharpen 3 flat.",
            "What they tend to do as Markov chains.",
            "So it's not indicated in this picture just because it makes a total mass.",
            "If I do it, but every one of these.",
            "Driving process variables.",
            "The key variables is connected to every other variable in the same measure.",
            "It just makes this hash of lines, so I didn't draw it.",
            "The black variables that I haven't described yet.",
            "These are the observable MIDI note numbers.",
            "So the idea here in generating these is if I know the soul fedge variable an I know the key, I know exactly deterministically what at least the pitch class of the MIDI variable would be.",
            "So like if the key is D and the note is 3, well that's F#.",
            "So I don't know.",
            "I guess that's six or something like that, something which MoD 12 is 6.",
            "The MIDI pitch MoD 12 is 6.",
            "That's what I'll know.",
            "Deterministic Lee.",
            "So there it is.",
            "That's my model."
        ],
        [
            "And I want to talk a little bit about computation with this model.",
            "What I'm interested in doing is finding the most likely configuration of all the hidden variables, because I'm interested in doing pitch spelling.",
            "An I suppose this could fit rather straightforwardly into the Bayesian belief network methodology.",
            "I haven't done it that way.",
            "I've done the computation a little bit more directly with really a variation on dynamic programming here, just with an expanded notion of state.",
            "So the idea I dropped all the observable variables here.",
            "The MIDI pitches 'cause they just clutter things.",
            "Then you don't really need them for this discussion, so for.",
            "Each measure I take the variable which gives me the key of that measure an the first soul fedge variable of every voice, and I make a big vector out of that.",
            "That's sort of like a possible state for the first measure and 2nd measure, etc.",
            "And it's not a very difficult thing to compute what the most probable path is to, say, a configuration here to a configuration here.",
            "That's just solving a bunch of independent dynamic programming.",
            "Problem so I can figure out what the most likely transition is from a state here to a state here and I can do the usual dynamic programming thing where you know I find the most likely path and I traced back to get my my hidden variables.",
            "I'm not going to describe that in any detail and having done that then I've got the pitch spelling already.",
            "So if I've learned, say for instance that this key is D major.",
            "Ann this soul Fedge variable is 3.",
            "Well then the node is F# and I would spell it that way.",
            "And if instead I've learned that this key variables D flat major and this soul fedge variables flat six, well in D flat, the six scale degrees already be flat.",
            "I've already got a flat and I added another flat from my soul fedge variable.",
            "It was six flat, so I get B double flat there.",
            "That's the idea.",
            "For high recover, the spelling from this interpretation."
        ],
        [
            "Here are some results on this.",
            "This is compared with the.",
            "There's just only one database that I know about that is got any significant information on pitch spelling.",
            "It's derived by Dave Meredith from the CCAR H database variety of classical.",
            "This the first second movement of Beethoven's First Symphony, so it's more like classical music and before broke with pitch spelling information.",
            "Number of competing methods.",
            "I just have to say in fairness, there problems with all the experiments here, just the corpus is so small.",
            "So in all cases there's been a little bit of training on the test data.",
            "I think probably in all cases it's not really all that significant 'cause the parameterisations of the models are small.",
            "I just want to mention that all of these results are a little bit in question.",
            "You can ignore them if you like.",
            "We're in blue here and we actually haven't done too badly in the classical type composers we did really.",
            "Not not badly at all, and it's it's a little bit VIX mix, but a pretty good showing in the others and overall results were really quite good.",
            "I suppose one can take that for what it's worth.",
            "I'm not really sure, but I think it's a certainly a plausable showing.",
            "This is mentioned about a couple of things we had trouble with.",
            "Our notion of horizontal motion.",
            "It's so local it knows that notes resolved to neighbors within one step.",
            "So for instance, so you can see it.",
            "If I point down the screen, C sharp resolves to D, La La da da da Di Maria.",
            "I'm fine there, but I just add this one other note there, Murray Hall and I'm sunk already this.",
            "Was a simple problem that we had trouble with.",
            "Oh course, that's not how Maria goes.",
            "What do you Da da da Lorda?",
            "Come on, I don't know anyone know that?",
            "La Di da di da da da da da da da Da I just love this so I have to sing it la da da da da da Da.",
            "Alright, hold on what is that?",
            "This is the end of IE to the last scene of Ieda, Radha Mason Eater, entombed together.",
            "They sing what?",
            "Ido.",
            "Ido Valide Piante goodbye Vale of Tears Goodbye Cruel World it's quite touching alright.",
            "Well, OK we didn't do so well on that.",
            "There are other things that we had a little bit of trouble with.",
            "Our notion of the harmonic state was so simple, just having the notion of key, and I think this might have been a little bit problematic.",
            "For instance, this case came up a lot with German augmented 6th chords.",
            "So like in C major at something that you'd spell as a flat in the Bay CE flat F#.",
            "Up in the treble.",
            "Usually mostly this works OK for us.",
            "What happens is they flatten the F#.",
            "They resolve outward to make an octave.",
            "Just like our model says, they're supposed to.",
            "That's terrific.",
            "They both do what their accidental say they would do.",
            "The weird thing is that the E flat, well usually what happens with the augmented 6 chord, is that goes to 164, so the E flat ends up going up to East.",
            "It's not supposed to do that according to our Model E flat supposed to go down, but maybe it does.",
            "This is really the same problem as before.",
            "Usually what happens after that is the 164 goes to the dominant, so the E flat that went up to Y then goes down to D where at.",
            "Along so maybe this is just another example of that delayed resolution.",
            "I'm not sure there were other things that came up with having two too simple a notion of the harmonic state.",
            "OK."
        ],
        [
            "So I want to talk about what happens with training the model here, if you like."
        ],
        [
            "You can think of this model just as being a Markov chain, whoops."
        ],
        [
            "Just a regular hidden Markov model.",
            "I guess it's really what I wanted to say.",
            "You have to change things around a little bit.",
            "We Add all these dummy variables.",
            "So here is the composite rhythm, so I'm going to put all of these dummy variables in all the other parts so they move along at the rate of the composite rhythm, and the notion is each dummy variable will just inherit what its predecessor has deterministically.",
            "So in that case I have just.",
            "Our regular Markov chain, if I think of the States as being these vectors an I can write the whole."
        ],
        [
            "Oh whole model out is.",
            "It's a big hidden Markov model and I can do the usual usual things that one does for training the hidden Markov model like the Baum Welch algorithm.",
            "This is, this is what we did, among other things.",
            "Well my student, I'm trying to convince him of the importance of automatically training models.",
            "He's a very bright student, but he comes from a different world and these experiments didn't help.",
            "I think in making my case upon training the model with Baum Welch, what happened is actually we got worse results both on training and test.",
            "Given the results were quite good in both cases it was a minor degradation.",
            "But the results even got worse on what we trained on.",
            "This is of course a little bit surprising at first.",
            "Maybe it's not really so surprising if you think about it.",
            "The basic problem, I believe is the training is not trying to optimize the criterion that we really care so much about here.",
            "What is that OK?",
            "So what's Baum Welch doing?",
            "It maximizes the marginal probability of the data given your choice of parameters, so it's maximum likelihood estimation.",
            "An maximum likelihood estimation has not lots of nice theoretical properties, but what we really care about is performance on the training set.",
            "We'd like to have an algorithm that minimizes the number of errors that we commit.",
            "On the training set, and that's just simply not what we're trying to do with Baum Welch, I think that's what the problem is and this is where I start to move to phase two of my talk.",
            "I want to look at a different way of trying to handle the training."
        ],
        [
            "So.",
            "Here, um.",
            "Here what I'm gonna do is, well, OK so.",
            "If I have my my pitch spelling task well, I can think of pitch.",
            "Spelling is being hidden Markov model problem.",
            "Like I said before and if I have a hidden Markov model problem, I can think of that as at least the recognition part of it.",
            "If I'm interested in the most likely posterior path, that's a dynamic programming problem, so I can think of this as a problem trying to find the best path through this trellis here and what I mean by best path is every arc in my trellis has got some score associated with it and.",
            "The score of a path is the sum of all the scores that you encounter as you traverse the path.",
            "So that's something that we can do pretty easily with dynamic programming and the way I want to phrase the training problem now is I've got some training parameter Theta Theta is vector valued and my notion is that each arc is going to have a score which is an affine function of my parameter linear plus constant affine function of my vector here.",
            "I'm.",
            "So.",
            "Well, maybe you can think of a couple examples of that that might be meaningful here.",
            "Maybe I've got a fixed data model that measures how good the data agrees with the current state and a fixed prior model that describes how well the sequence evolves.",
            "Is it a reasonable sequence?",
            "And I could think of my parameter, my parameter in a really simple sense, as describing the tradeoff between these two.",
            "Models, or maybe I've got a collection of features that I'm looking at and my parameter is awaiting of the features.",
            "If you think about this, or actually there's a whole host of really interesting ways that you can express this way.",
            "It's a, it's a quite simple thing.",
            "Of course, to fix a parameter value.",
            "If I fix a parameter value, then each arc has got some fixed score and I can do dynamic programming.",
            "But what I'm going to do here?",
            "That's a little bit different than maybe you haven't seen before.",
            "I hadn't is.",
            "I'm going to simultaneously do dynamic programming for all different values of my parameter at the same time simultaneous dynamic programming.",
            "That's sort of an odd thing."
        ],
        [
            "So here's how this goes.",
            "I keep putting this this trellis picture up on these slides to remind me what's going on.",
            "If I if I say, fix some node in the trellis here, I'll just point to one fix this node right here, and I consider a path that goes to that node, say this one that runs along the top well, what that path does is as I go through all the arcs on that path.",
            "There's an app find function that I see for each of my parameter Theta.",
            "Now find function of Theta.",
            "But I see for each arc along that path, so the cost of that total path is the sum of all of these efine functions that I traverse.",
            "So it's again, ah, fine, that's great.",
            "So that's what I've written out here.",
            "There's the score.",
            "The Sky Discord is the score of my path \u03c0.",
            "Is this affine function in my parameter, and for that matter, if I look at all of the different paths to that node that I was pointing to before, there are quite a few of 'em.",
            "Now the number of paths that get their increases exponentially as I move through my trellis, but the number of paths there are quite a few.",
            "But if I want to figure out the optimal score of getting to that node.",
            "I've gotta maximize overall the paths that come there, so I've got this maximum.",
            "Overall, these affine functions, so this is starting to look a little bit like this stuff from Palm DP's now here.",
            "Each one of these paths is represented by one of these lines.",
            "There's an affine function associated with each path I'm imagining here.",
            "That is just one dimensional so I can visualize it.",
            "And you'll see some of these paths correspond to affine functions like this one here that isn't optimal for any value of Theta, so I could just boot that one out the door.",
            "That's like a dynamic programming cut off if you will.",
            "No loss for just kicking that one in the trash and just retaining the purple ones here.",
            "So some of the paths don't don't contribute at all to the maximal score that I'm trying to compute, so I discard them.",
            "I forget about all of their progeny.",
            "That's sort of the fundamental idea that gives this a chance to work here."
        ],
        [
            "So here's a picture of what's going on in.",
            "In two dimensions, it gets hard to visualize pretty quickly.",
            "Now that is 2 dimensional.",
            "When I look at one of these Maxima of affine functions, I get it sort of like this bowl shape with all these different facets on it.",
            "These are facets.",
            "Each one of these facets is a region where the boundary is a fine.",
            "And every one of these regions also has got a distinct path through the trellis.",
            "That leads me to that region.",
            "So that's the picture in 2 dimensions it gets, it gets harder and harder to visualize.",
            "I'm not going to really try to do it beyond then."
        ],
        [
            "So how does the dynamic programming algorithm work?",
            "I just sort of wanted to describe this briefly.",
            "It's sort of an interesting thing.",
            "So imagine I'm at a particular trellis node here, and I want to figure out what the optimal score is to that particular trellis node will have to reach up here a bit.",
            "Well, there are two predecessors of this, and I've got optimal scores for each one of these.",
            "Each one of these optimal score functions.",
            "It's one of these maximum of affine functions here, so each of these get extended by their arc.",
            "That just means I add in another FYI.",
            "Function and now I've got twice as many affine functions altogether in this urn, and I want to go through this process of kicking out the ones that are not going to contribute at all.",
            "And that's sort of an interesting algorithm.",
            "I just oh the folks in Palm DP's they have a different way of doing this.",
            "They do it with linear programming.",
            "I'm not going to do it that way, just describe it very briefly.",
            "I just pick some point at random and I go through all my efine functions.",
            "I find which one is the biggest was a fine function number one.",
            "And then I move in some arbitrary direction.",
            "So I'm just going to move to the left.",
            "Here I keep moving and moving until I bump into another one.",
            "I just bumped into function #2 here.",
            "This arc here describes the intersection of function one and function 2.",
            "So then I move along that arc until I bump into a third one.",
            "Right there, that's the intersection of three and that becomes a vertex in this graph that I'm trying to construct.",
            "I construct the collection of.",
            "Functions that I'm going to keep in the end that are maximal someplace by creating this graph structure and what I have to do now is explore all the arcs that come out of here.",
            "If I drop one of these constraints, I dropped three, I get the Ark 1, two and I explore along this this constraint until I meet another function that was number 4 here.",
            "And if I drop two, I move along Arc 1 three and I get to 135.",
            "And similarly I can explore all the arcs coming out of here until they terminate in other vertices.",
            "I do the same.",
            "This is recursive procedure, so I do the same for all the others here when I drop the drop constraint one I go in the direction 2, four.",
            "Maybe that just takes me out to Infinity.",
            "I never meet another constraint in that direction.",
            "Oh, here I find another vertex.",
            "I explore one of these vertex that one of these lines coming out of it.",
            "I come back to something I've already seen before so you just keep exploring all the edges that come out of a vertex until you either go off into Infinity or come back to something that you've already explored before.",
            "And that's the basic algorithm there that is that."
        ],
        [
            "Rhythm.",
            "So you're sort of a picture of how the dynamic programming evolves.",
            "This is my I call this my my DP search tree.",
            "It's sort of.",
            "It's like a Christmas tree.",
            "I did it in red and green down there at the bottom.",
            "Here.",
            "What what one essentially has to do is follow all paths through the trellis.",
            "So I started the trellis here.",
            "This is got five possible states.",
            "Well, I just drew three of am here, so I've got three possible progeny, and each of these states has got three more progeny and three more in three more.",
            "And you have this exponential explosion, or at least you would if it weren't for this thinning property, as we saw some of the possible partial paths can't contribute to the optimal solution, so I'm just.",
            "Throw in these ones out.",
            "I don't need to consider them, I just continue to explore the paths that have some chance of figuring into the optimal solution, and the hope is that one can actually carry this out.",
            "I'll probably there will be still a little bit more pruning that's necessary to make this work, but one hopes one can carry this through all the way through the trellis."
        ],
        [
            "At which point you'll get a picture like the following.",
            "So here.",
            "So again, now I'm thinking of data is being 2 dimensional.",
            "So I've got this collection of regions in my parameter space in my Theta space and remember each one of these regions corresponds to a particular path that led to that region.",
            "Most of 'em got thrown away.",
            "Most paths never survived.",
            "And what I could do if I have actually have labeled data that tells me what the true answer is for every one of those paths I could count up the number of errors that it made.",
            "Here I made 105 errors here.",
            "I made 726 errors and as I move over here, I found a particular region where the path that led me there had a lower number of errors.",
            "So I've I've looked for all values of my parameter.",
            "I've done the dynamic programming simultaneously.",
            "This is the idea and this seems to be the preferred region, so maybe I'd take my parameter Theta right in the middle of that.",
            "So this is this is a new paradigm for training.",
            "A recognition system that's based on dynamic programming.",
            "In some sense we completely forget about the probabilistic roots that lead to this.",
            "There's no hidden Markov model or anything like that.",
            "I have a recognition problem that I'm trying to phrase as dynamic programming, and I'm trying to optimize the scores.",
            "I'm trying to tweak the scores of the arcs so that they lead me to the solution that I desire.",
            "The probabilistic stuff is just completely absent from the heart of this machine array.",
            "This is the idea that I want to present.",
            "So, well, that's actually yet for my talk.",
            "I just had one."
        ],
        [
            "Closing slide.",
            "I hope this isn't bad form for me to.",
            "Say this, we're hiring now, so I can't think of a better way for me to advertise so many terrific people in this room.",
            "We're having an open rank search.",
            "Come look at us.",
            "OK, thank you.",
            "Just fine.",
            "Wait, I'm not quite quite sure I understand the question, so you're talking about training how?",
            "As I understood, the motivation was if you do the regulation.",
            "Right?",
            "About marginal.",
            "Find Victoria pass.",
            "Oh yeah.",
            "Right?",
            "Yeah, I've tried this before.",
            "I guess I've always sort of viewed this as a poor man's Baum Welch algorithm.",
            "I mean, in my experience it this works well when the posterior mask is just clustered very densely on a small number of of states in the graph.",
            "I've tried this in other problems I haven't had particularly good luck with it.",
            "Although you know I'm confessing that.",
            "I don't always have great luck with Baum Welch either.",
            "I I'm familiar with problems where it's just absolutely terrific and times when it just falls flat and it usually depends on how how much information correct information I've built into the model in the 1st place.",
            "No, I haven't tried that.",
            "I mean, I actually haven't successfully yet implemented the thing that I really most believe in, But that's a great idea.",
            "Could be anyway.",
            "This procedure was related to that particular procedure.",
            "Well, I guess I I don't think so.",
            "I think what you're describing is it's sort of like a very local type of search.",
            "You begin with the choice of your parameter, Theta.",
            "You look at the path that that generates.",
            "You iterate and you get a new Theta as a function of that, and presumably that converges someplace.",
            "Here I'm searching globally over Theta, so in theory, well, you know if this could actually be done.",
            "I'd be searching globally over Theta so you know me.",
            "I'm really big believer in global search.",
            "I know you've never bought this Thailand, but.",
            "I do, I just think search spaces like this are just so fraught with local detail of Maxima and minima.",
            "One needs to take a broader view of the search technique, but we can take that offline.",
            "Tell us how you find this.",
            "Program.",
            "What OK what I have and what I have not succeeded in proving is that what I'm proposing is computationally feasible.",
            "I've described an algorithm which if you can actually can compute it, it does show you.",
            "What?",
            "It shows you the collection of paths that are optimal for some parameter.",
            "Most won't be optimal for any parameter.",
            "The hope is there will be a small collection that are optimal for some parameter and you would choose among those according to which does best on a labeled sample so.",
            "I suppose that's my notion of optimality.",
            "I'm looking for the configuration of parameters that gives me the best score on this training sample that I have, so it is optimal.",
            "In that sense, you might not believe in that sense of optimality.",
            "Sorry.",
            "Yes, yes of course.",
            "Space is simple enough.",
            "Makes sense.",
            "I'm not, I'm not quite sure I understand what you mean by simple enough.",
            "OK, well I guess OK, so the hope is if the.",
            "I'm only imagining this to be computationally feasible in cases where the dimension of Theta is not so large.",
            "Maybe we'll be able to do it in would be very lucky to do this for a 10 dimensional parameter, probably can do it for a 5 dimensional one, so I'm thinking that the parameter is low enough dimensional so there isn't really a big problem with overfitting and this should generalize reasonably well.",
            "I understand from a learning theory perspective that's that's.",
            "A rather naive thing to say, but this is the viewpoint that I have."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well, first I begin with an apology.",
                    "label": 0
                },
                {
                    "sent": "I realize I disappoint some people here.",
                    "label": 0
                },
                {
                    "sent": "I don't have my oboe.",
                    "label": 0
                },
                {
                    "sent": "I don't have the orchestra and for that matter, this talk is very unusual for me and that there's no audio in it at all.",
                    "label": 0
                },
                {
                    "sent": "I hope that will be OK.",
                    "label": 0
                },
                {
                    "sent": "I just thought I would talk about something completely different from what I often do.",
                    "label": 0
                },
                {
                    "sent": "They, the conditionally independent voice model.",
                    "label": 1
                },
                {
                    "sent": "This is work that I'm doing with two students of mine too.",
                    "label": 0
                },
                {
                    "sent": "Good students.",
                    "label": 1
                },
                {
                    "sent": "Gabby Teodoro an Eric Nichols.",
                    "label": 0
                },
                {
                    "sent": "In one sense, this is really two talks that are sort of gently alighted, although I think you'll see a natural connection between the two.",
                    "label": 0
                },
                {
                    "sent": "I hope so, at least.",
                    "label": 0
                },
                {
                    "sent": "So the beginning of this talk.",
                    "label": 0
                },
                {
                    "sent": "It's motivated by something that might be familiar to a number of people here.",
                    "label": 0
                },
                {
                    "sent": "I don't know if anyone.",
                    "label": 0
                },
                {
                    "sent": "Has ever had the experience of trying to model music, symbolic music, and starting with a single voice of music and finding well, single voices like a sequence and their natural modeling and analysis techniques that we get from mathematics and statistics to handle sequences.",
                    "label": 0
                },
                {
                    "sent": "And this all works very nicely, and then we try and extend this to a more general model for music, polyphonic music and if we do this just in a purely straightforward way.",
                    "label": 0
                },
                {
                    "sent": "Just by making my state space bigger, taking the cross product of the model with itself, if you will.",
                    "label": 0
                },
                {
                    "sent": "Oh, there's just this exponential explosion.",
                    "label": 0
                },
                {
                    "sent": "The number of parameters is your model just becomes horrid, the recognition problems become hard.",
                    "label": 0
                },
                {
                    "sent": "It just doesn't generalize in a very natural way.",
                    "label": 0
                },
                {
                    "sent": "My hope is this might be something that is familiar to people an I'm talking about a technique that I'd like to propose for well.",
                    "label": 0
                },
                {
                    "sent": "It's called here breaking the logjam.",
                    "label": 0
                },
                {
                    "sent": "Maybe that's.",
                    "label": 0
                },
                {
                    "sent": "That might be a little bit too.",
                    "label": 0
                },
                {
                    "sent": "Too ambitious, but at least something that might help a little bit.",
                    "label": 0
                },
                {
                    "sent": "I get the whole thing on there.",
                    "label": 0
                },
                {
                    "sent": "There we go.",
                    "label": 0
                },
                {
                    "sent": "So well, here's a caricature of the idea.",
                    "label": 0
                },
                {
                    "sent": "I hope you'll forgive this and not find it really silly, but so I have.",
                    "label": 0
                },
                {
                    "sent": "I'm thinking of music in terms of voices, and here I have my 4 voices here.",
                    "label": 0
                },
                {
                    "sent": "These are my 4 singers here down at the bottom.",
                    "label": 0
                },
                {
                    "sent": "I don't know if you can recognize any of them, doesn't really matter and there are different pictures and by the different pictures I mean they cannot hear each other.",
                    "label": 0
                },
                {
                    "sent": "They're in separate rooms, have no knowledge of what the others are going to do.",
                    "label": 0
                },
                {
                    "sent": "And they're going to sing this Carol together, say good King Wenceslas, because this is my favorite.",
                    "label": 0
                },
                {
                    "sent": "It doesn't really matter so much what it is.",
                    "label": 0
                },
                {
                    "sent": "And of course you know they start off, and since their operating independently of one another, it's a total disaster.",
                    "label": 0
                },
                {
                    "sent": "We can't possibly have any musical sense there.",
                    "label": 0
                },
                {
                    "sent": "They won't be together in time or inflection or imbalance or in any way that's musically relevant.",
                    "label": 0
                },
                {
                    "sent": "This is not so surprising.",
                    "label": 0
                },
                {
                    "sent": "They are all if you will marching to their different drummers.",
                    "label": 0
                },
                {
                    "sent": "So the idea of the model here is I'm.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To give them a common drummer, there he is.",
                    "label": 0
                },
                {
                    "sent": "He's from a little bit different world and the idea is now they can't hear one another, but they can all hear the drummer.",
                    "label": 0
                },
                {
                    "sent": "This is the essential idea of the model.",
                    "label": 0
                },
                {
                    "sent": "Is this notion of conditional independence?",
                    "label": 0
                },
                {
                    "sent": "Everybody hears the drummer so everything that is important for the inner relationship of parts in the musical model comes through this other part that they hear.",
                    "label": 0
                },
                {
                    "sent": "This is a very informal way of looking at it.",
                    "label": 0
                },
                {
                    "sent": "It's a little bit silly, but.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There it is.",
                    "label": 0
                },
                {
                    "sent": "So I gradually get a little bit more and more specific.",
                    "label": 0
                },
                {
                    "sent": "Can you see this?",
                    "label": 0
                },
                {
                    "sent": "OK, well I can do that.",
                    "label": 0
                },
                {
                    "sent": "I hope I don't start to lose it when I do let's see what happens.",
                    "label": 0
                },
                {
                    "sent": "Here's the next level up.",
                    "label": 0
                },
                {
                    "sent": "That doesn't help much, does.",
                    "label": 0
                },
                {
                    "sent": "No, that that doesn't magnify the image.",
                    "label": 0
                },
                {
                    "sent": "When I do that though, it just expands.",
                    "label": 0
                },
                {
                    "sent": "Here's another 50% and now OK. Now I will expand this and let's try this.",
                    "label": 0
                },
                {
                    "sent": "I might have to scroll a little bit to.",
                    "label": 0
                },
                {
                    "sent": "Well, I'm gonna have to go down one.",
                    "label": 0
                },
                {
                    "sent": "It's all explain it.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry about this.",
                    "label": 0
                },
                {
                    "sent": "If you can't see everything you need to.",
                    "label": 0
                },
                {
                    "sent": "So it's presented in sort of this formal way.",
                    "label": 0
                },
                {
                    "sent": "It begins with, whereas these are my assumptions so, well.",
                    "label": 0
                },
                {
                    "sent": "I'm imagining the music is composed of voices.",
                    "label": 0
                },
                {
                    "sent": "Of course, this isn't always true, but this is the kind of music that I'm looking at now.",
                    "label": 0
                },
                {
                    "sent": "Supposes it's composed of voices, and my thinking is each of these voices has got something that it tends to do, and it's something that I can model rather easily, like, oh, the baseline shows me simple things about the chord structure, an.",
                    "label": 0
                },
                {
                    "sent": "Maybe I have a melody which prefers some combination of corn tones and odd chord tones.",
                    "label": 0
                },
                {
                    "sent": "I don't know what it does, or maybe one part is the Chuck Chuck of the boom Chuck Chuck have all these separate parts that knows something about what they do.",
                    "label": 0
                },
                {
                    "sent": "They have what I'm calling internal logic logic just to that separate voice.",
                    "label": 0
                },
                {
                    "sent": "And of course it would be ridiculous for me to suppose that these voices evolve independently, like.",
                    "label": 0
                },
                {
                    "sent": "Idea on my previous slide, the singers in the different rooms that would be a terrible idea.",
                    "label": 0
                },
                {
                    "sent": "So the notion here is being really specific about the kind of dependence there is between the voices.",
                    "label": 0
                },
                {
                    "sent": "So the idea is that they evolved together because they know about these shared attributes of the music.",
                    "label": 0
                },
                {
                    "sent": "There's some harmonic structure that the music has, and the voices all know about that harmonic structure and maybe a rhythmic structure of phrase structure.",
                    "label": 0
                },
                {
                    "sent": "This is known to all of them.",
                    "label": 0
                },
                {
                    "sent": "So if you will, there's this thing that they know about and they respond to one another.",
                    "label": 0
                },
                {
                    "sent": "Not directly, but because they both inherit this same information.",
                    "label": 0
                },
                {
                    "sent": "This is the idea of conditionally independent voices, so still getting more more specific.",
                    "label": 0
                },
                {
                    "sent": "I imagine I have this driving process, this is, I'm sorry.",
                    "label": 0
                },
                {
                    "sent": "Can you make it better?",
                    "label": 0
                },
                {
                    "sent": "I have this driving process.",
                    "label": 0
                },
                {
                    "sent": "This is a Markov chain that describes what the voices need to know about the music, and I'll have a couple examples coming up, but maybe it's a process describing how harmony evolves over each measure.",
                    "label": 0
                },
                {
                    "sent": "And I model the voices also as Markov chains, but they are no longer independent of one another.",
                    "label": 0
                },
                {
                    "sent": "They are conditionally independent.",
                    "label": 0
                },
                {
                    "sent": "The only thing that they know about is their own internal evolution, and this higher level driving process.",
                    "label": 0
                },
                {
                    "sent": "I call it that they all inherit.",
                    "label": 0
                },
                {
                    "sent": "So this is how they communicate with one another.",
                    "label": 0
                },
                {
                    "sent": "So in essence I've been really explicit about how the models depend.",
                    "label": 0
                },
                {
                    "sent": "All dependents between the voices happens through this driving process.",
                    "label": 0
                },
                {
                    "sent": "So here are a couple examples.",
                    "label": 0
                },
                {
                    "sent": "My thinking is I don't know if you'll agree, but I think this is rather general idea that might have a lot of applications.",
                    "label": 0
                },
                {
                    "sent": "Will see.",
                    "label": 0
                },
                {
                    "sent": "One thing that I'm going to talk about today is this first one pitch spelling.",
                    "label": 0
                },
                {
                    "sent": "So here I've got a collection of voices I'm interested in recovering pitch spelling from MIDI F# or G flat, and I model each voice as being.",
                    "label": 0
                },
                {
                    "sent": "You'll see more specifically in a minute, but it's a Markov chain.",
                    "label": 1
                },
                {
                    "sent": "And the Markov change chains for each voice are conditionally independent given some global structure and hear what this is going to be as a functional harmonic analysis of the music measure by measure.",
                    "label": 1
                },
                {
                    "sent": "So I'll talk about that.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to talk about the next two, but these are just an attempt to convince you that the idea might be a little bit more general.",
                    "label": 0
                },
                {
                    "sent": "So the next one is about expressive inflection of music, automatic expressive inflection of music.",
                    "label": 0
                },
                {
                    "sent": "So in this case, I've got some guiding or steering or driving process that encapsulates the overall expressive intent of the performance so that that would contain places of relaxation, places of emphasis, places where I move freely without emphasis.",
                    "label": 0
                },
                {
                    "sent": "These are these are prosodic things.",
                    "label": 0
                },
                {
                    "sent": "Maybe there might be things about musical affect also, I'm not sure exactly what an given that information.",
                    "label": 0
                },
                {
                    "sent": "Now I allow the each individual voice to evolve independently, just given this shared information.",
                    "label": 0
                },
                {
                    "sent": "Or the last example?",
                    "label": 0
                },
                {
                    "sent": "It's about composition I suppose.",
                    "label": 0
                },
                {
                    "sent": "Maybe more ambitious.",
                    "label": 0
                },
                {
                    "sent": "I'm going to actually compose the music from this model.",
                    "label": 0
                },
                {
                    "sent": "Well, the ragatz of the music, the notes in the rhythms, so my collection of voices are now Markov chains of notes and rhythm that evolve independently, conditionally, independently from one another given something shared, which I've called rather vaguely hear my overall musical plan.",
                    "label": 1
                },
                {
                    "sent": "So that would need to have a lot of stuff in it.",
                    "label": 0
                },
                {
                    "sent": "Things about what's going on with the harmony phrase structure maybe larger things with structure.",
                    "label": 0
                },
                {
                    "sent": "Oh, I'm not sure what all it would have, and I'm not really thinking of this as being a model for generating Brahms or Mozart.",
                    "label": 0
                },
                {
                    "sent": "Or maybe not even the Spice Girls, but there's still, I think, interesting applications for something I have in mind.",
                    "label": 0
                },
                {
                    "sent": "Maybe something like computer games am model for generating music for computer games.",
                    "label": 0
                },
                {
                    "sent": "Where the nature of the music evolves according to some game state that's changing, so the music needs to be composed on the fly because I won't know what the states are ahead of time.",
                    "label": 0
                },
                {
                    "sent": "Or if you don't like that idea, maybe some sort of improvisatory music system.",
                    "label": 0
                },
                {
                    "sent": "So somehow I separate the roles of the voices only depending on this global structure that they all know.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so now I'm going to talk more specifically about the.",
                    "label": 0
                },
                {
                    "sent": "The note spelling.",
                    "label": 0
                },
                {
                    "sent": "I'll Scroll down when I need to in a minute so.",
                    "label": 0
                },
                {
                    "sent": "Here the goal is I have this collection of mini pitches like I get from a MIDI file and of course MIDI doesn't distinguish between the different spellings of notes.",
                    "label": 0
                },
                {
                    "sent": "Is it a flat?",
                    "label": 0
                },
                {
                    "sent": "Is it G#?",
                    "label": 0
                },
                {
                    "sent": "And I want to fix this up.",
                    "label": 0
                },
                {
                    "sent": "I want to spell things correctly, so admittedly, I mean it's a somewhat modest problem compared to, you know, some of the huge problems in this wonderful field.",
                    "label": 0
                },
                {
                    "sent": "I'd still like to convince you, you ought to care about it a little bit.",
                    "label": 0
                },
                {
                    "sent": "I don't know if people have ever had this experience of importing a MIDI file into their score writing program and seeing just this utter hash of note spellings.",
                    "label": 0
                },
                {
                    "sent": "I find this very aggravating.",
                    "label": 0
                },
                {
                    "sent": "'cause it makes the music hard for me to read, but maybe even a larger goal than that.",
                    "label": 0
                },
                {
                    "sent": "Omidi's become the de facto standard symbolic representation.",
                    "label": 0
                },
                {
                    "sent": "It's just what there's the most of now.",
                    "label": 0
                },
                {
                    "sent": "And of course we're interested in moving Tord more expressive symbolic representations.",
                    "label": 0
                },
                {
                    "sent": "Things that are more score like.",
                    "label": 0
                },
                {
                    "sent": "And the natural way to do this is to take what we have and pull ourselves up by our bootstraps.",
                    "label": 0
                },
                {
                    "sent": "We'd like to move all of this MIDI data gradually to more, more expressive things that knows about voice and knows about pitch, spelling, and knows more precisely about rhythm and other things indicated in scores.",
                    "label": 0
                },
                {
                    "sent": "So there are basically two ideas that have been incorporated into this approach to pitch spelling.",
                    "label": 0
                },
                {
                    "sent": "And the first, I think everyone will probably agree on this.",
                    "label": 0
                },
                {
                    "sent": "This is this.",
                    "label": 0
                },
                {
                    "sent": "I call this the vertical notion I had to spell notes according to the ambient key.",
                    "label": 1
                },
                {
                    "sent": "All the folks who have worked in this at least have some nod in that direction, even if no ambient key or temporary key is identified.",
                    "label": 0
                },
                {
                    "sent": "So you know if the music's indeed major, I should have some preference for F# over G flat.",
                    "label": 0
                },
                {
                    "sent": "That's what I mean by horizontal, and then maybe more controversial.",
                    "label": 0
                },
                {
                    "sent": "Is this notion of did I call that horizontal that was vertical?",
                    "label": 0
                },
                {
                    "sent": "Maybe more controversial?",
                    "label": 0
                },
                {
                    "sent": "Is this notion of horizontal motion?",
                    "label": 0
                },
                {
                    "sent": "So that's something that happens in an individual voice, so a note.",
                    "label": 0
                },
                {
                    "sent": "Indicated with a sharp tends to move up, F# tends to move up to G where the flat tells me I'm I'm tending to move down.",
                    "label": 0
                },
                {
                    "sent": "A flat tends to move down to G. Oh, there's.",
                    "label": 0
                },
                {
                    "sent": "The this doesn't come totally out of the blue.",
                    "label": 0
                },
                {
                    "sent": "You can read about it in at rimsky.",
                    "label": 0
                },
                {
                    "sent": "Korsakoff's got a treatise from Harmony Treatise from the 19th century that discuss is this.",
                    "label": 0
                },
                {
                    "sent": "Presumably this was in the air before then.",
                    "label": 0
                },
                {
                    "sent": "Some music theorists don't like this idea at all.",
                    "label": 0
                },
                {
                    "sent": "Think of it as sort of a surrogate for deeper ideas, and I'm OK with that.",
                    "label": 0
                },
                {
                    "sent": "It's fine if this is just a surrogate, it's something that fits really naturally into my computational framework, and I'm going to include it even if it isn't sort of the deepest way one can look at the problem.",
                    "label": 0
                },
                {
                    "sent": "So here it is in a little bit more detail, here's the model, so I've got a Markov chain for key.",
                    "label": 0
                },
                {
                    "sent": "So every measure has got a tonic Anna mode 12 possible tonics, two possible modes here, minor and major.",
                    "label": 0
                },
                {
                    "sent": "That's this process on top.",
                    "label": 0
                },
                {
                    "sent": "This is the driving process that guides everything.",
                    "label": 0
                },
                {
                    "sent": "And that will evolve in in a way like you'd expect.",
                    "label": 0
                },
                {
                    "sent": "I mean, most importantly the key.",
                    "label": 0
                },
                {
                    "sent": "This measure tends to be like the key the previous measure.",
                    "label": 0
                },
                {
                    "sent": "If it's going to modulate, probably it's going to go someplace close, like somewhere near on the circle of fifths.",
                    "label": 0
                },
                {
                    "sent": "Or maybe a parallel or a relative relation.",
                    "label": 0
                },
                {
                    "sent": "Something like that.",
                    "label": 0
                },
                {
                    "sent": "Nothing, nothing too complicated.",
                    "label": 0
                },
                {
                    "sent": "And given that model, I'm going to describe the models for the individual voices, so I called these the soul fedge models.",
                    "label": 0
                },
                {
                    "sent": "So here are the states here.",
                    "label": 0
                },
                {
                    "sent": "The states in each of these models are, well, the seven scale degrees, one through 7, and if you will, there are two choices for the various black nodes, so I might call them something sharp or something plus one flat.",
                    "label": 0
                },
                {
                    "sent": "These are my states with the notion that, well, OK, I'll have lots of interesting transition structure, but maybe most importantly is incorporating this notion of motion.",
                    "label": 1
                },
                {
                    "sent": "The sharps tend to move up.",
                    "label": 0
                },
                {
                    "sent": "The flats tend to move down, and that's the difference between say two sharpen 3 flat.",
                    "label": 0
                },
                {
                    "sent": "What they tend to do as Markov chains.",
                    "label": 0
                },
                {
                    "sent": "So it's not indicated in this picture just because it makes a total mass.",
                    "label": 0
                },
                {
                    "sent": "If I do it, but every one of these.",
                    "label": 0
                },
                {
                    "sent": "Driving process variables.",
                    "label": 0
                },
                {
                    "sent": "The key variables is connected to every other variable in the same measure.",
                    "label": 0
                },
                {
                    "sent": "It just makes this hash of lines, so I didn't draw it.",
                    "label": 1
                },
                {
                    "sent": "The black variables that I haven't described yet.",
                    "label": 0
                },
                {
                    "sent": "These are the observable MIDI note numbers.",
                    "label": 0
                },
                {
                    "sent": "So the idea here in generating these is if I know the soul fedge variable an I know the key, I know exactly deterministically what at least the pitch class of the MIDI variable would be.",
                    "label": 0
                },
                {
                    "sent": "So like if the key is D and the note is 3, well that's F#.",
                    "label": 0
                },
                {
                    "sent": "So I don't know.",
                    "label": 0
                },
                {
                    "sent": "I guess that's six or something like that, something which MoD 12 is 6.",
                    "label": 0
                },
                {
                    "sent": "The MIDI pitch MoD 12 is 6.",
                    "label": 0
                },
                {
                    "sent": "That's what I'll know.",
                    "label": 0
                },
                {
                    "sent": "Deterministic Lee.",
                    "label": 0
                },
                {
                    "sent": "So there it is.",
                    "label": 0
                },
                {
                    "sent": "That's my model.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And I want to talk a little bit about computation with this model.",
                    "label": 0
                },
                {
                    "sent": "What I'm interested in doing is finding the most likely configuration of all the hidden variables, because I'm interested in doing pitch spelling.",
                    "label": 1
                },
                {
                    "sent": "An I suppose this could fit rather straightforwardly into the Bayesian belief network methodology.",
                    "label": 0
                },
                {
                    "sent": "I haven't done it that way.",
                    "label": 0
                },
                {
                    "sent": "I've done the computation a little bit more directly with really a variation on dynamic programming here, just with an expanded notion of state.",
                    "label": 0
                },
                {
                    "sent": "So the idea I dropped all the observable variables here.",
                    "label": 1
                },
                {
                    "sent": "The MIDI pitches 'cause they just clutter things.",
                    "label": 0
                },
                {
                    "sent": "Then you don't really need them for this discussion, so for.",
                    "label": 0
                },
                {
                    "sent": "Each measure I take the variable which gives me the key of that measure an the first soul fedge variable of every voice, and I make a big vector out of that.",
                    "label": 0
                },
                {
                    "sent": "That's sort of like a possible state for the first measure and 2nd measure, etc.",
                    "label": 0
                },
                {
                    "sent": "And it's not a very difficult thing to compute what the most probable path is to, say, a configuration here to a configuration here.",
                    "label": 0
                },
                {
                    "sent": "That's just solving a bunch of independent dynamic programming.",
                    "label": 0
                },
                {
                    "sent": "Problem so I can figure out what the most likely transition is from a state here to a state here and I can do the usual dynamic programming thing where you know I find the most likely path and I traced back to get my my hidden variables.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to describe that in any detail and having done that then I've got the pitch spelling already.",
                    "label": 0
                },
                {
                    "sent": "So if I've learned, say for instance that this key is D major.",
                    "label": 0
                },
                {
                    "sent": "Ann this soul Fedge variable is 3.",
                    "label": 0
                },
                {
                    "sent": "Well then the node is F# and I would spell it that way.",
                    "label": 0
                },
                {
                    "sent": "And if instead I've learned that this key variables D flat major and this soul fedge variables flat six, well in D flat, the six scale degrees already be flat.",
                    "label": 0
                },
                {
                    "sent": "I've already got a flat and I added another flat from my soul fedge variable.",
                    "label": 0
                },
                {
                    "sent": "It was six flat, so I get B double flat there.",
                    "label": 0
                },
                {
                    "sent": "That's the idea.",
                    "label": 0
                },
                {
                    "sent": "For high recover, the spelling from this interpretation.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here are some results on this.",
                    "label": 0
                },
                {
                    "sent": "This is compared with the.",
                    "label": 0
                },
                {
                    "sent": "There's just only one database that I know about that is got any significant information on pitch spelling.",
                    "label": 0
                },
                {
                    "sent": "It's derived by Dave Meredith from the CCAR H database variety of classical.",
                    "label": 0
                },
                {
                    "sent": "This the first second movement of Beethoven's First Symphony, so it's more like classical music and before broke with pitch spelling information.",
                    "label": 0
                },
                {
                    "sent": "Number of competing methods.",
                    "label": 0
                },
                {
                    "sent": "I just have to say in fairness, there problems with all the experiments here, just the corpus is so small.",
                    "label": 0
                },
                {
                    "sent": "So in all cases there's been a little bit of training on the test data.",
                    "label": 0
                },
                {
                    "sent": "I think probably in all cases it's not really all that significant 'cause the parameterisations of the models are small.",
                    "label": 0
                },
                {
                    "sent": "I just want to mention that all of these results are a little bit in question.",
                    "label": 0
                },
                {
                    "sent": "You can ignore them if you like.",
                    "label": 0
                },
                {
                    "sent": "We're in blue here and we actually haven't done too badly in the classical type composers we did really.",
                    "label": 0
                },
                {
                    "sent": "Not not badly at all, and it's it's a little bit VIX mix, but a pretty good showing in the others and overall results were really quite good.",
                    "label": 0
                },
                {
                    "sent": "I suppose one can take that for what it's worth.",
                    "label": 0
                },
                {
                    "sent": "I'm not really sure, but I think it's a certainly a plausable showing.",
                    "label": 0
                },
                {
                    "sent": "This is mentioned about a couple of things we had trouble with.",
                    "label": 0
                },
                {
                    "sent": "Our notion of horizontal motion.",
                    "label": 0
                },
                {
                    "sent": "It's so local it knows that notes resolved to neighbors within one step.",
                    "label": 0
                },
                {
                    "sent": "So for instance, so you can see it.",
                    "label": 0
                },
                {
                    "sent": "If I point down the screen, C sharp resolves to D, La La da da da Di Maria.",
                    "label": 0
                },
                {
                    "sent": "I'm fine there, but I just add this one other note there, Murray Hall and I'm sunk already this.",
                    "label": 0
                },
                {
                    "sent": "Was a simple problem that we had trouble with.",
                    "label": 0
                },
                {
                    "sent": "Oh course, that's not how Maria goes.",
                    "label": 0
                },
                {
                    "sent": "What do you Da da da Lorda?",
                    "label": 0
                },
                {
                    "sent": "Come on, I don't know anyone know that?",
                    "label": 0
                },
                {
                    "sent": "La Di da di da da da da da da da Da I just love this so I have to sing it la da da da da da Da.",
                    "label": 0
                },
                {
                    "sent": "Alright, hold on what is that?",
                    "label": 0
                },
                {
                    "sent": "This is the end of IE to the last scene of Ieda, Radha Mason Eater, entombed together.",
                    "label": 0
                },
                {
                    "sent": "They sing what?",
                    "label": 0
                },
                {
                    "sent": "Ido.",
                    "label": 0
                },
                {
                    "sent": "Ido Valide Piante goodbye Vale of Tears Goodbye Cruel World it's quite touching alright.",
                    "label": 0
                },
                {
                    "sent": "Well, OK we didn't do so well on that.",
                    "label": 0
                },
                {
                    "sent": "There are other things that we had a little bit of trouble with.",
                    "label": 0
                },
                {
                    "sent": "Our notion of the harmonic state was so simple, just having the notion of key, and I think this might have been a little bit problematic.",
                    "label": 0
                },
                {
                    "sent": "For instance, this case came up a lot with German augmented 6th chords.",
                    "label": 1
                },
                {
                    "sent": "So like in C major at something that you'd spell as a flat in the Bay CE flat F#.",
                    "label": 0
                },
                {
                    "sent": "Up in the treble.",
                    "label": 0
                },
                {
                    "sent": "Usually mostly this works OK for us.",
                    "label": 0
                },
                {
                    "sent": "What happens is they flatten the F#.",
                    "label": 0
                },
                {
                    "sent": "They resolve outward to make an octave.",
                    "label": 0
                },
                {
                    "sent": "Just like our model says, they're supposed to.",
                    "label": 0
                },
                {
                    "sent": "That's terrific.",
                    "label": 0
                },
                {
                    "sent": "They both do what their accidental say they would do.",
                    "label": 0
                },
                {
                    "sent": "The weird thing is that the E flat, well usually what happens with the augmented 6 chord, is that goes to 164, so the E flat ends up going up to East.",
                    "label": 0
                },
                {
                    "sent": "It's not supposed to do that according to our Model E flat supposed to go down, but maybe it does.",
                    "label": 0
                },
                {
                    "sent": "This is really the same problem as before.",
                    "label": 0
                },
                {
                    "sent": "Usually what happens after that is the 164 goes to the dominant, so the E flat that went up to Y then goes down to D where at.",
                    "label": 0
                },
                {
                    "sent": "Along so maybe this is just another example of that delayed resolution.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure there were other things that came up with having two too simple a notion of the harmonic state.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I want to talk about what happens with training the model here, if you like.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can think of this model just as being a Markov chain, whoops.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just a regular hidden Markov model.",
                    "label": 0
                },
                {
                    "sent": "I guess it's really what I wanted to say.",
                    "label": 0
                },
                {
                    "sent": "You have to change things around a little bit.",
                    "label": 0
                },
                {
                    "sent": "We Add all these dummy variables.",
                    "label": 0
                },
                {
                    "sent": "So here is the composite rhythm, so I'm going to put all of these dummy variables in all the other parts so they move along at the rate of the composite rhythm, and the notion is each dummy variable will just inherit what its predecessor has deterministically.",
                    "label": 0
                },
                {
                    "sent": "So in that case I have just.",
                    "label": 0
                },
                {
                    "sent": "Our regular Markov chain, if I think of the States as being these vectors an I can write the whole.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Oh whole model out is.",
                    "label": 0
                },
                {
                    "sent": "It's a big hidden Markov model and I can do the usual usual things that one does for training the hidden Markov model like the Baum Welch algorithm.",
                    "label": 0
                },
                {
                    "sent": "This is, this is what we did, among other things.",
                    "label": 0
                },
                {
                    "sent": "Well my student, I'm trying to convince him of the importance of automatically training models.",
                    "label": 0
                },
                {
                    "sent": "He's a very bright student, but he comes from a different world and these experiments didn't help.",
                    "label": 0
                },
                {
                    "sent": "I think in making my case upon training the model with Baum Welch, what happened is actually we got worse results both on training and test.",
                    "label": 1
                },
                {
                    "sent": "Given the results were quite good in both cases it was a minor degradation.",
                    "label": 0
                },
                {
                    "sent": "But the results even got worse on what we trained on.",
                    "label": 0
                },
                {
                    "sent": "This is of course a little bit surprising at first.",
                    "label": 0
                },
                {
                    "sent": "Maybe it's not really so surprising if you think about it.",
                    "label": 0
                },
                {
                    "sent": "The basic problem, I believe is the training is not trying to optimize the criterion that we really care so much about here.",
                    "label": 0
                },
                {
                    "sent": "What is that OK?",
                    "label": 0
                },
                {
                    "sent": "So what's Baum Welch doing?",
                    "label": 0
                },
                {
                    "sent": "It maximizes the marginal probability of the data given your choice of parameters, so it's maximum likelihood estimation.",
                    "label": 0
                },
                {
                    "sent": "An maximum likelihood estimation has not lots of nice theoretical properties, but what we really care about is performance on the training set.",
                    "label": 0
                },
                {
                    "sent": "We'd like to have an algorithm that minimizes the number of errors that we commit.",
                    "label": 0
                },
                {
                    "sent": "On the training set, and that's just simply not what we're trying to do with Baum Welch, I think that's what the problem is and this is where I start to move to phase two of my talk.",
                    "label": 0
                },
                {
                    "sent": "I want to look at a different way of trying to handle the training.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Here, um.",
                    "label": 0
                },
                {
                    "sent": "Here what I'm gonna do is, well, OK so.",
                    "label": 0
                },
                {
                    "sent": "If I have my my pitch spelling task well, I can think of pitch.",
                    "label": 1
                },
                {
                    "sent": "Spelling is being hidden Markov model problem.",
                    "label": 0
                },
                {
                    "sent": "Like I said before and if I have a hidden Markov model problem, I can think of that as at least the recognition part of it.",
                    "label": 0
                },
                {
                    "sent": "If I'm interested in the most likely posterior path, that's a dynamic programming problem, so I can think of this as a problem trying to find the best path through this trellis here and what I mean by best path is every arc in my trellis has got some score associated with it and.",
                    "label": 0
                },
                {
                    "sent": "The score of a path is the sum of all the scores that you encounter as you traverse the path.",
                    "label": 0
                },
                {
                    "sent": "So that's something that we can do pretty easily with dynamic programming and the way I want to phrase the training problem now is I've got some training parameter Theta Theta is vector valued and my notion is that each arc is going to have a score which is an affine function of my parameter linear plus constant affine function of my vector here.",
                    "label": 0
                },
                {
                    "sent": "I'm.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Well, maybe you can think of a couple examples of that that might be meaningful here.",
                    "label": 0
                },
                {
                    "sent": "Maybe I've got a fixed data model that measures how good the data agrees with the current state and a fixed prior model that describes how well the sequence evolves.",
                    "label": 0
                },
                {
                    "sent": "Is it a reasonable sequence?",
                    "label": 0
                },
                {
                    "sent": "And I could think of my parameter, my parameter in a really simple sense, as describing the tradeoff between these two.",
                    "label": 0
                },
                {
                    "sent": "Models, or maybe I've got a collection of features that I'm looking at and my parameter is awaiting of the features.",
                    "label": 0
                },
                {
                    "sent": "If you think about this, or actually there's a whole host of really interesting ways that you can express this way.",
                    "label": 0
                },
                {
                    "sent": "It's a, it's a quite simple thing.",
                    "label": 0
                },
                {
                    "sent": "Of course, to fix a parameter value.",
                    "label": 1
                },
                {
                    "sent": "If I fix a parameter value, then each arc has got some fixed score and I can do dynamic programming.",
                    "label": 0
                },
                {
                    "sent": "But what I'm going to do here?",
                    "label": 0
                },
                {
                    "sent": "That's a little bit different than maybe you haven't seen before.",
                    "label": 0
                },
                {
                    "sent": "I hadn't is.",
                    "label": 0
                },
                {
                    "sent": "I'm going to simultaneously do dynamic programming for all different values of my parameter at the same time simultaneous dynamic programming.",
                    "label": 0
                },
                {
                    "sent": "That's sort of an odd thing.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's how this goes.",
                    "label": 0
                },
                {
                    "sent": "I keep putting this this trellis picture up on these slides to remind me what's going on.",
                    "label": 0
                },
                {
                    "sent": "If I if I say, fix some node in the trellis here, I'll just point to one fix this node right here, and I consider a path that goes to that node, say this one that runs along the top well, what that path does is as I go through all the arcs on that path.",
                    "label": 1
                },
                {
                    "sent": "There's an app find function that I see for each of my parameter Theta.",
                    "label": 1
                },
                {
                    "sent": "Now find function of Theta.",
                    "label": 0
                },
                {
                    "sent": "But I see for each arc along that path, so the cost of that total path is the sum of all of these efine functions that I traverse.",
                    "label": 0
                },
                {
                    "sent": "So it's again, ah, fine, that's great.",
                    "label": 0
                },
                {
                    "sent": "So that's what I've written out here.",
                    "label": 1
                },
                {
                    "sent": "There's the score.",
                    "label": 0
                },
                {
                    "sent": "The Sky Discord is the score of my path \u03c0.",
                    "label": 0
                },
                {
                    "sent": "Is this affine function in my parameter, and for that matter, if I look at all of the different paths to that node that I was pointing to before, there are quite a few of 'em.",
                    "label": 0
                },
                {
                    "sent": "Now the number of paths that get their increases exponentially as I move through my trellis, but the number of paths there are quite a few.",
                    "label": 0
                },
                {
                    "sent": "But if I want to figure out the optimal score of getting to that node.",
                    "label": 0
                },
                {
                    "sent": "I've gotta maximize overall the paths that come there, so I've got this maximum.",
                    "label": 0
                },
                {
                    "sent": "Overall, these affine functions, so this is starting to look a little bit like this stuff from Palm DP's now here.",
                    "label": 0
                },
                {
                    "sent": "Each one of these paths is represented by one of these lines.",
                    "label": 0
                },
                {
                    "sent": "There's an affine function associated with each path I'm imagining here.",
                    "label": 0
                },
                {
                    "sent": "That is just one dimensional so I can visualize it.",
                    "label": 0
                },
                {
                    "sent": "And you'll see some of these paths correspond to affine functions like this one here that isn't optimal for any value of Theta, so I could just boot that one out the door.",
                    "label": 0
                },
                {
                    "sent": "That's like a dynamic programming cut off if you will.",
                    "label": 0
                },
                {
                    "sent": "No loss for just kicking that one in the trash and just retaining the purple ones here.",
                    "label": 1
                },
                {
                    "sent": "So some of the paths don't don't contribute at all to the maximal score that I'm trying to compute, so I discard them.",
                    "label": 0
                },
                {
                    "sent": "I forget about all of their progeny.",
                    "label": 0
                },
                {
                    "sent": "That's sort of the fundamental idea that gives this a chance to work here.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's a picture of what's going on in.",
                    "label": 0
                },
                {
                    "sent": "In two dimensions, it gets hard to visualize pretty quickly.",
                    "label": 0
                },
                {
                    "sent": "Now that is 2 dimensional.",
                    "label": 0
                },
                {
                    "sent": "When I look at one of these Maxima of affine functions, I get it sort of like this bowl shape with all these different facets on it.",
                    "label": 1
                },
                {
                    "sent": "These are facets.",
                    "label": 0
                },
                {
                    "sent": "Each one of these facets is a region where the boundary is a fine.",
                    "label": 0
                },
                {
                    "sent": "And every one of these regions also has got a distinct path through the trellis.",
                    "label": 0
                },
                {
                    "sent": "That leads me to that region.",
                    "label": 0
                },
                {
                    "sent": "So that's the picture in 2 dimensions it gets, it gets harder and harder to visualize.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to really try to do it beyond then.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how does the dynamic programming algorithm work?",
                    "label": 1
                },
                {
                    "sent": "I just sort of wanted to describe this briefly.",
                    "label": 0
                },
                {
                    "sent": "It's sort of an interesting thing.",
                    "label": 0
                },
                {
                    "sent": "So imagine I'm at a particular trellis node here, and I want to figure out what the optimal score is to that particular trellis node will have to reach up here a bit.",
                    "label": 0
                },
                {
                    "sent": "Well, there are two predecessors of this, and I've got optimal scores for each one of these.",
                    "label": 0
                },
                {
                    "sent": "Each one of these optimal score functions.",
                    "label": 0
                },
                {
                    "sent": "It's one of these maximum of affine functions here, so each of these get extended by their arc.",
                    "label": 0
                },
                {
                    "sent": "That just means I add in another FYI.",
                    "label": 0
                },
                {
                    "sent": "Function and now I've got twice as many affine functions altogether in this urn, and I want to go through this process of kicking out the ones that are not going to contribute at all.",
                    "label": 0
                },
                {
                    "sent": "And that's sort of an interesting algorithm.",
                    "label": 0
                },
                {
                    "sent": "I just oh the folks in Palm DP's they have a different way of doing this.",
                    "label": 0
                },
                {
                    "sent": "They do it with linear programming.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to do it that way, just describe it very briefly.",
                    "label": 0
                },
                {
                    "sent": "I just pick some point at random and I go through all my efine functions.",
                    "label": 0
                },
                {
                    "sent": "I find which one is the biggest was a fine function number one.",
                    "label": 0
                },
                {
                    "sent": "And then I move in some arbitrary direction.",
                    "label": 0
                },
                {
                    "sent": "So I'm just going to move to the left.",
                    "label": 0
                },
                {
                    "sent": "Here I keep moving and moving until I bump into another one.",
                    "label": 0
                },
                {
                    "sent": "I just bumped into function #2 here.",
                    "label": 0
                },
                {
                    "sent": "This arc here describes the intersection of function one and function 2.",
                    "label": 0
                },
                {
                    "sent": "So then I move along that arc until I bump into a third one.",
                    "label": 0
                },
                {
                    "sent": "Right there, that's the intersection of three and that becomes a vertex in this graph that I'm trying to construct.",
                    "label": 0
                },
                {
                    "sent": "I construct the collection of.",
                    "label": 0
                },
                {
                    "sent": "Functions that I'm going to keep in the end that are maximal someplace by creating this graph structure and what I have to do now is explore all the arcs that come out of here.",
                    "label": 0
                },
                {
                    "sent": "If I drop one of these constraints, I dropped three, I get the Ark 1, two and I explore along this this constraint until I meet another function that was number 4 here.",
                    "label": 0
                },
                {
                    "sent": "And if I drop two, I move along Arc 1 three and I get to 135.",
                    "label": 0
                },
                {
                    "sent": "And similarly I can explore all the arcs coming out of here until they terminate in other vertices.",
                    "label": 0
                },
                {
                    "sent": "I do the same.",
                    "label": 0
                },
                {
                    "sent": "This is recursive procedure, so I do the same for all the others here when I drop the drop constraint one I go in the direction 2, four.",
                    "label": 0
                },
                {
                    "sent": "Maybe that just takes me out to Infinity.",
                    "label": 0
                },
                {
                    "sent": "I never meet another constraint in that direction.",
                    "label": 0
                },
                {
                    "sent": "Oh, here I find another vertex.",
                    "label": 0
                },
                {
                    "sent": "I explore one of these vertex that one of these lines coming out of it.",
                    "label": 0
                },
                {
                    "sent": "I come back to something I've already seen before so you just keep exploring all the edges that come out of a vertex until you either go off into Infinity or come back to something that you've already explored before.",
                    "label": 0
                },
                {
                    "sent": "And that's the basic algorithm there that is that.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Rhythm.",
                    "label": 0
                },
                {
                    "sent": "So you're sort of a picture of how the dynamic programming evolves.",
                    "label": 0
                },
                {
                    "sent": "This is my I call this my my DP search tree.",
                    "label": 0
                },
                {
                    "sent": "It's sort of.",
                    "label": 0
                },
                {
                    "sent": "It's like a Christmas tree.",
                    "label": 0
                },
                {
                    "sent": "I did it in red and green down there at the bottom.",
                    "label": 0
                },
                {
                    "sent": "Here.",
                    "label": 0
                },
                {
                    "sent": "What what one essentially has to do is follow all paths through the trellis.",
                    "label": 0
                },
                {
                    "sent": "So I started the trellis here.",
                    "label": 0
                },
                {
                    "sent": "This is got five possible states.",
                    "label": 0
                },
                {
                    "sent": "Well, I just drew three of am here, so I've got three possible progeny, and each of these states has got three more progeny and three more in three more.",
                    "label": 0
                },
                {
                    "sent": "And you have this exponential explosion, or at least you would if it weren't for this thinning property, as we saw some of the possible partial paths can't contribute to the optimal solution, so I'm just.",
                    "label": 0
                },
                {
                    "sent": "Throw in these ones out.",
                    "label": 0
                },
                {
                    "sent": "I don't need to consider them, I just continue to explore the paths that have some chance of figuring into the optimal solution, and the hope is that one can actually carry this out.",
                    "label": 0
                },
                {
                    "sent": "I'll probably there will be still a little bit more pruning that's necessary to make this work, but one hopes one can carry this through all the way through the trellis.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At which point you'll get a picture like the following.",
                    "label": 0
                },
                {
                    "sent": "So here.",
                    "label": 0
                },
                {
                    "sent": "So again, now I'm thinking of data is being 2 dimensional.",
                    "label": 0
                },
                {
                    "sent": "So I've got this collection of regions in my parameter space in my Theta space and remember each one of these regions corresponds to a particular path that led to that region.",
                    "label": 0
                },
                {
                    "sent": "Most of 'em got thrown away.",
                    "label": 0
                },
                {
                    "sent": "Most paths never survived.",
                    "label": 0
                },
                {
                    "sent": "And what I could do if I have actually have labeled data that tells me what the true answer is for every one of those paths I could count up the number of errors that it made.",
                    "label": 0
                },
                {
                    "sent": "Here I made 105 errors here.",
                    "label": 0
                },
                {
                    "sent": "I made 726 errors and as I move over here, I found a particular region where the path that led me there had a lower number of errors.",
                    "label": 0
                },
                {
                    "sent": "So I've I've looked for all values of my parameter.",
                    "label": 0
                },
                {
                    "sent": "I've done the dynamic programming simultaneously.",
                    "label": 0
                },
                {
                    "sent": "This is the idea and this seems to be the preferred region, so maybe I'd take my parameter Theta right in the middle of that.",
                    "label": 0
                },
                {
                    "sent": "So this is this is a new paradigm for training.",
                    "label": 0
                },
                {
                    "sent": "A recognition system that's based on dynamic programming.",
                    "label": 0
                },
                {
                    "sent": "In some sense we completely forget about the probabilistic roots that lead to this.",
                    "label": 0
                },
                {
                    "sent": "There's no hidden Markov model or anything like that.",
                    "label": 0
                },
                {
                    "sent": "I have a recognition problem that I'm trying to phrase as dynamic programming, and I'm trying to optimize the scores.",
                    "label": 0
                },
                {
                    "sent": "I'm trying to tweak the scores of the arcs so that they lead me to the solution that I desire.",
                    "label": 0
                },
                {
                    "sent": "The probabilistic stuff is just completely absent from the heart of this machine array.",
                    "label": 0
                },
                {
                    "sent": "This is the idea that I want to present.",
                    "label": 0
                },
                {
                    "sent": "So, well, that's actually yet for my talk.",
                    "label": 0
                },
                {
                    "sent": "I just had one.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Closing slide.",
                    "label": 0
                },
                {
                    "sent": "I hope this isn't bad form for me to.",
                    "label": 0
                },
                {
                    "sent": "Say this, we're hiring now, so I can't think of a better way for me to advertise so many terrific people in this room.",
                    "label": 0
                },
                {
                    "sent": "We're having an open rank search.",
                    "label": 0
                },
                {
                    "sent": "Come look at us.",
                    "label": 0
                },
                {
                    "sent": "OK, thank you.",
                    "label": 0
                },
                {
                    "sent": "Just fine.",
                    "label": 0
                },
                {
                    "sent": "Wait, I'm not quite quite sure I understand the question, so you're talking about training how?",
                    "label": 0
                },
                {
                    "sent": "As I understood, the motivation was if you do the regulation.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "About marginal.",
                    "label": 0
                },
                {
                    "sent": "Find Victoria pass.",
                    "label": 0
                },
                {
                    "sent": "Oh yeah.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "Yeah, I've tried this before.",
                    "label": 0
                },
                {
                    "sent": "I guess I've always sort of viewed this as a poor man's Baum Welch algorithm.",
                    "label": 0
                },
                {
                    "sent": "I mean, in my experience it this works well when the posterior mask is just clustered very densely on a small number of of states in the graph.",
                    "label": 0
                },
                {
                    "sent": "I've tried this in other problems I haven't had particularly good luck with it.",
                    "label": 0
                },
                {
                    "sent": "Although you know I'm confessing that.",
                    "label": 0
                },
                {
                    "sent": "I don't always have great luck with Baum Welch either.",
                    "label": 0
                },
                {
                    "sent": "I I'm familiar with problems where it's just absolutely terrific and times when it just falls flat and it usually depends on how how much information correct information I've built into the model in the 1st place.",
                    "label": 0
                },
                {
                    "sent": "No, I haven't tried that.",
                    "label": 0
                },
                {
                    "sent": "I mean, I actually haven't successfully yet implemented the thing that I really most believe in, But that's a great idea.",
                    "label": 0
                },
                {
                    "sent": "Could be anyway.",
                    "label": 0
                },
                {
                    "sent": "This procedure was related to that particular procedure.",
                    "label": 0
                },
                {
                    "sent": "Well, I guess I I don't think so.",
                    "label": 0
                },
                {
                    "sent": "I think what you're describing is it's sort of like a very local type of search.",
                    "label": 0
                },
                {
                    "sent": "You begin with the choice of your parameter, Theta.",
                    "label": 0
                },
                {
                    "sent": "You look at the path that that generates.",
                    "label": 0
                },
                {
                    "sent": "You iterate and you get a new Theta as a function of that, and presumably that converges someplace.",
                    "label": 0
                },
                {
                    "sent": "Here I'm searching globally over Theta, so in theory, well, you know if this could actually be done.",
                    "label": 0
                },
                {
                    "sent": "I'd be searching globally over Theta so you know me.",
                    "label": 0
                },
                {
                    "sent": "I'm really big believer in global search.",
                    "label": 0
                },
                {
                    "sent": "I know you've never bought this Thailand, but.",
                    "label": 0
                },
                {
                    "sent": "I do, I just think search spaces like this are just so fraught with local detail of Maxima and minima.",
                    "label": 0
                },
                {
                    "sent": "One needs to take a broader view of the search technique, but we can take that offline.",
                    "label": 0
                },
                {
                    "sent": "Tell us how you find this.",
                    "label": 0
                },
                {
                    "sent": "Program.",
                    "label": 0
                },
                {
                    "sent": "What OK what I have and what I have not succeeded in proving is that what I'm proposing is computationally feasible.",
                    "label": 0
                },
                {
                    "sent": "I've described an algorithm which if you can actually can compute it, it does show you.",
                    "label": 0
                },
                {
                    "sent": "What?",
                    "label": 0
                },
                {
                    "sent": "It shows you the collection of paths that are optimal for some parameter.",
                    "label": 0
                },
                {
                    "sent": "Most won't be optimal for any parameter.",
                    "label": 0
                },
                {
                    "sent": "The hope is there will be a small collection that are optimal for some parameter and you would choose among those according to which does best on a labeled sample so.",
                    "label": 0
                },
                {
                    "sent": "I suppose that's my notion of optimality.",
                    "label": 0
                },
                {
                    "sent": "I'm looking for the configuration of parameters that gives me the best score on this training sample that I have, so it is optimal.",
                    "label": 0
                },
                {
                    "sent": "In that sense, you might not believe in that sense of optimality.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "Yes, yes of course.",
                    "label": 0
                },
                {
                    "sent": "Space is simple enough.",
                    "label": 0
                },
                {
                    "sent": "Makes sense.",
                    "label": 0
                },
                {
                    "sent": "I'm not, I'm not quite sure I understand what you mean by simple enough.",
                    "label": 0
                },
                {
                    "sent": "OK, well I guess OK, so the hope is if the.",
                    "label": 0
                },
                {
                    "sent": "I'm only imagining this to be computationally feasible in cases where the dimension of Theta is not so large.",
                    "label": 0
                },
                {
                    "sent": "Maybe we'll be able to do it in would be very lucky to do this for a 10 dimensional parameter, probably can do it for a 5 dimensional one, so I'm thinking that the parameter is low enough dimensional so there isn't really a big problem with overfitting and this should generalize reasonably well.",
                    "label": 0
                },
                {
                    "sent": "I understand from a learning theory perspective that's that's.",
                    "label": 0
                },
                {
                    "sent": "A rather naive thing to say, but this is the viewpoint that I have.",
                    "label": 0
                }
            ]
        }
    }
}