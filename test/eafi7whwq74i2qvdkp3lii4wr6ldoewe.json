{
    "id": "eafi7whwq74i2qvdkp3lii4wr6ldoewe",
    "title": "Practical Statistical Relational Learning",
    "info": {
        "author": [
            "Pedro Domingos, University of Washington"
        ],
        "published": "June 21, 2007",
        "recorded": "June 2007",
        "category": [
            "Top->Computer Science->Machine Learning->Statistical Learning"
        ]
    },
    "url": "http://videolectures.net/icml07_domingos_psr/",
    "segmentation": [
        [
            "I'm Peter Domingos from the University of Washington and this is a tutorial on practical statistical relational learning."
        ],
        [
            "I will start with.",
            "Trying to make this pointer be visible, which might be impossible.",
            "Can you see this?",
            "No.",
            "Well, I guess I'll have to do it without a pointer then.",
            "I'm.",
            "If anybody has a nice, you know, thick, brightly visible pointer that I can lend, I'll be grateful.",
            "In the meantime, I'll just work with what I have, so I will begin with some motivation and then the tutorial has three main parts.",
            "The first part is what you can think of is the four foundational areas of statistical relational learning, namely probabilistic inference, statistical learning, logical inference, and inductive logic programming.",
            "I will then let's see how this one works.",
            "Yeah, this is better now, yeah?",
            "I will then talk about how we put this all together to build statistical, relational learners.",
            "That's the second part, you know.",
            "This actually parts is probably going to be longer than this because once we know the pieces, putting them together is actually surprisingly, maybe not that hard.",
            "And finally we will spend a good chunk of time talking about various applications, things that you can do with statistical original learning."
        ],
        [
            "Today so let me begin with the motivation.",
            "Most machine learning algorithms assume that the data is IID, meaning that your objects are all independent of each other and you know they're all of the same type.",
            "They all have the same kind of distribution.",
            "And of course this is very unrealistic right in the real world, objects have all kinds of relationships between them.",
            "The properties of 1 object affect the properties of another object, and we would like to be able to model that.",
            "We will.",
            "We want to be able to model domains with multiple types of objects.",
            "We want to be able to model relations between objects.",
            "The dependencies of object attributes on the relations between them, the dependencies of relations on each other and on."
        ],
        [
            "Attributes and so forth.",
            "And I think it's pretty much in almost, I think, every domain where where we have always been assuming IID data.",
            "I think it's the case that if you look closer, data is not IID.",
            "Here's here's a random sampling of domains.",
            "Web search is a famous example.",
            "If you use links between pages, you can get better page rankings than if you don't.",
            "Information extraction is another one.",
            "If you do joint inference between the various things that you want to extract the various tasks, you do better.",
            "Natural language Processing is another example of the same kind.",
            "More generally, perception in vision in speech, etc.",
            "You have dependencies between the various objects that you're seeing.",
            "A medical diagnosis is another interesting example right?",
            "The UCI datasets a large number of them is medical diagnosis problems, and of course the first thing you assume is that all your patients are independent.",
            "Well, in reality they're not because you know epidemics happen, and if somebody has the flu, you know the next person is more likely to have the flu, and so forth.",
            "Another interesting example is computational biology.",
            "It's one thing to model, you know, individual problems, like you know, is this a promoter region or not?",
            "What we really want to do it in today's believe is build models of how the entire cell works and that involves a lot of dependencies among proteins, genes, etc.",
            "Social networks are another obvious example.",
            "Your preferences, your habits, the things you do are influenced by your friends, your coworkers, etc will be good as computing is another important example since their networks are a very hot topic these days, the readings that you get at one sensor.",
            "Are you know, not independent of the readings that you get at nearby sensors, for example ANM."
        ],
        [
            "Anymore examples you know I could spend the rest of the afternoon just going over the domains where modeling dependencies between objects is important.",
            "So what are the statistical rational learning is really trying to do this?",
            "Trying to model domains where the objects are not independent identically distribute the benefits of doing that?",
            "Well, one potential benefit is that we get better predictive accuracy.",
            "Because if there are dependencies between objects and we ignore them, we were throwing out some of the information that we could use for prediction.",
            "So that's one important potential benefit.",
            "Another one is better understanding of the domains.",
            "If we, if we ignoring a lot of the dependencies, alot of the phenomena that are going on their domain, we probably won't understand it very well, as if we do.",
            "And also more generally, I think SRL offers a growth path for machine learning from small isolated problems to really solving the large big massive problems that real intelligent systems have to deal with, and I think we can grow progressively more ambitious in this way.",
            "You know to offset the benefits.",
            "Unfortunately there are also some costs.",
            "1 cost is that learning is now much, much harder.",
            "If you allow dependencies between objects, you know the the number of parameters of the model that you have to learn.",
            "Potentially go up exponentially and this is going up exponentially for something that was already exponentially large, so you know building known ID models can be a really, really hard problem.",
            "Another another issue is that you know when you're just doing something like building a classifier.",
            "You can ignore the problem of inference because you know the inference is just computing a function.",
            "Now you really can't take no difference anymore.",
            "Inference is really crucial.",
            "Because, you know now now different classes, for example of different topics influence each other.",
            "You need to figure out how to how to compute that, and indeed you know a good chunk of this tutorial is going to be talking about the inference methods that are relevant for statistical relational learning.",
            "Here's what is perhaps the biggest problem.",
            "The biggest problem is that it's much more complex for the user to model non IID domains.",
            "This is probably the biggest thing that's holding us back and why people have always tended to assume IID data is.",
            "That is just so much easier.",
            "The number of options that you have to contend with, the number of things that you have to model, the number of decisions that you have to make, you know all of this goes up when you have non IID data, so those are the downsides.",
            "What I hope to persuade you today is that.",
            "Thanks to recent progress, the benefits now the costs and an SRL is something that you can do effectively in practice today without a lot of investment on your."
        ],
        [
            "Part as the researcher or the user.",
            "So our goal stated in one sentence is to enable learning from non IID data as easily as from IID data.",
            "We would like learning from an activity to be as easy as something like applying C 4.5 to a standard classification problem.",
            "Now, maybe we can never completely reach this goal because after all the problems are more complex.",
            "But I think that you know we are fairly close to that.",
            "There's been a lot of research on this problem.",
            "Saint years we've made a lot of progress and I think we are at the point where we're close enough to the goal that you can just give statistical additional learners to various people and they will be useful things with the money that's been our experience, and so the goal of this tutorial is too, you know, share this.",
            "The this knowledge that we have these techniques that we've developed in the field with all of you, and we're also at the point.",
            "I think this is always a sign of maturity in the field where there is easy to use open source software to do these things.",
            "As long as to do SRL we need to go and roll your own system and spend months doing that.",
            "It's really not going to happen, but that's not the case anymore.",
            "There's a bunch of systems out there there are, you know, a fairly usable and so, and they incorporate the algorithms that you need, and then you can build on them and do extensions and variations, but at least the starting point is pretty good and you know we will use one of these systems today as an example in our applications.",
            "Needless to say, there's lots of research questions in this field.",
            "There's both all the old questions.",
            "All the old questions in logical learning and statistical learning and inference are still here.",
            "So research on those is still relevant.",
            "But in addition, there are lots of interesting new research questions, both about the new problems that we can solve and about the new opportunities of things that we can do.",
            "And hopefully you also get a flavor of some of those as well."
        ],
        [
            "Go through the tutorial.",
            "So here's the plan.",
            "We have the basic elements for what we want to do.",
            "The basic elements are probability for handling uncertainty and logic for representing, you know, types, relations, complex dependencies between them, which is what we really want to do in SRL, and we have learning an inference algorithms for each.",
            "We have statistical learning algorithms, we have IOP.",
            "The problem is figuring out how to put them together.",
            "And then, once we've done that, we're going to have tremendous leverage on a wide range of applications, and so each of these is basically going to be one part of the tutorial.",
            "The basics, combining them and applying them."
        ],
        [
            "So let me just preface the tutorial with some disclaimers.",
            "What I'm going to do here is by no means a complete survey of statistical learning.",
            "There was no way to do that in the time that I have, and to some extent the choices that I'm going to have here just represent what I'm most familiar with.",
            "You know, there's there is a random component to this.",
            "I'm also obviously not going to do a complete survey of the foundational areas.",
            "In fact, I'm going to just touch on the very few essential things for what we're going to be needing further.",
            "And you know, if some of you are familiar with one or more of these areas, bear with me.",
            "You know, you're probably not going to see anything you there.",
            "The satisfying thing, though, is that even though we're going to be, we're going to go through all these areas in sort of like a very whirlwind fashion.",
            "Even just what we're going to see is enough to do a lot, and I think you know, that's that's kind of nice.",
            "So I do.",
            "I am going to assume that you will have a basic background in logic, probability and statistics and so forth.",
            "Please ask questions anytime you have them.",
            "You know if there's anything you don't understand or any thoughts that come to your mind, do let me know and I will do my best to answer.",
            "This tutorial written version of the tutorial examples.",
            "The examples that I'm going to do here.",
            "Datasets, the models, etc.",
            "They are all available at this website.",
            "Alchemy.cs.washington.edu and I will put this URL again at the end."
        ],
        [
            "OK, so let's start by surveying the four foundational areas starting with probabilistic inference."
        ],
        [
            "And what I'm going to do is focus mainly on Markov networks.",
            "I assume that most of you have already at least a passing familiarity with vision networks.",
            "One main thing that we're going to be using here is Markov networks that you may not be so familiar with, so let me briefly give you an introduction to Markov networks.",
            "A Markov Markov network, like a vision network, is a graphical model for the joint distribution of a set of variables.",
            "Here are four variables.",
            "I'm assuming there Boolean smoking, cancer, asthma, and cough.",
            "The difference is that Markov networks are undirected models, meaning the edges between the graphs don't have a direction.",
            "And the semantics is actually very simple.",
            "Is that the an edge connects two nodes that are directly dependent on each other?",
            "And two nodes are independent of each other given some others.",
            "If once I remove those nodes they disconnected.",
            "So for example, coffee and smoking are independent of each other.",
            "Given cancer and asthma.",
            "Notice that this is actually easier to verify then then in vision networks and the neighbors of a network of nodes say cancer and asthma for cough, also known as their Markov blanket are the ones that.",
            "If you know those nodes, you don't need to know anybody else in the network.",
            "So that's the graph.",
            "The graph tells you what the conditional independence ease in the domain are.",
            "In addition, we need parameters parameters.",
            "In the case of Markov networks come in the form of what are called potential functions, and there's going to be a potential function for each clique in the graph, and the click is a completely connected sub graph.",
            "So here we have two.",
            "There's the click between smoking and cancer and the click between cancer, asthma and cough and a potential function is just any non negative function it takes on a value for each state of the click.",
            "So for example, for the smoking cancer click, here's a possible potential function.",
            "If they both false, the value is 4.5.",
            "Etc.",
            "What this particular potential function here is capturing?",
            "If you notice, it's just that the state where you smoke and don't get cancer is less likely than the others, and the reason of this for this, of course, is that smoking causes cancer.",
            "Now notice that these numbers can be larger than one, and the probability of a whole state is just obtained by multiplying the values of the potential functions for all the clicks in that state.",
            "So the probability is well defined, but the probabilities of all states don't necessarily add up to one.",
            "So in order to do that we need to divide by the sum of this product of potentials for all possible States and this is called Z, also known as the partition function from its using physics.",
            "So this is the full expression for the probability.",
            "Now there's a.",
            "There's a.",
            "There's a problem with Markov networks, which is the follow if your clicks, which is also a problem with vision networks.",
            "Actually, if your clicks are all small then everything is fine, but if a click is large then the complexity of this model blows up, right?",
            "You need the value of the potential function for every state of a click.",
            "If you have a click with 10 binary variables, you have to to the 10 possible States and that's not going to work.",
            "It's going to be too complex.",
            "For instance.",
            "It's also going to be very difficult to learn, Fortunately.",
            "There's something else that we can do, which is to use what's called."
        ],
        [
            "A log linear model.",
            "In the log linear model, instead of representing the probability of a state as a product of potential functions, we represented as an exponentiated sum of terms, which after all you can always convert from one to the other.",
            "So we still have the normalization constant.",
            "Now we have the exponential, it's some of.",
            "Is a sum of a set of features times their weights.",
            "Now in at 1 extreme I can just have one feature for each state of each click and so I can implement any potential function model in this way.",
            "The nice thing though, is that I could have many fewer features than there are states of the potential functions.",
            "If I have a very large click with a huge number of states, but I know that there's only 10 important features, then I can just represent those in their weights and so my model can stay compact even.",
            "If the potential function would be very large and we're going to take full advantage of this, for example, the potential function that we saw before could be represented simply by 1 feature of the smoking cancer pair, which is 1 if you don't smoke or have cancer, and 0 otherwise.",
            "And if you give 1.5 weight to that feature, you get the exact potential function that we saw before."
        ],
        [
            "Type.",
            "So there's a famous theorem in Markov networks called the Hammersley Clifford theorem, which says the following.",
            "Suppose that you have a distribution that is always non negative.",
            "Sorry there is always strictly positive.",
            "And the graph encodes the conditional independencies in your in your domain.",
            "Then the distribution is a product of potentials over the clicks of the graph.",
            "OK, so notice that I told you two things here, and I in no way proves that they were equivalent.",
            "It turns out that they are equivalent.",
            "The conditional independencies, and then the potential form function as long as every state has non zero probability and the inverse of this is also true.",
            "It's actually also a lot easier to prove.",
            "And you can think of this theorem is in a short form as a Markov network is the same as it gives distribution.",
            "It gives distribution.",
            "Is this thing that I just?"
        ],
        [
            "So here.",
            "Again, statisticians call it a log.",
            "In your model, physicists call it.",
            "It gives distribution and what the Hammersley Clifford."
        ],
        [
            "Eminence even say, is that a Markov network, meaning the graph with the conditional independence ease as I described, and it gives distribution are in our in effect the same thing.",
            "OK, so we know we can we can use one or the other as appropriate, and that's what we're taking advantage here.",
            "So how do more?"
        ],
        [
            "Of networks compared to vision networks.",
            "Well.",
            "They both have the same form.",
            "They both in the form of products of potential.",
            "So at that level is very similar.",
            "The big difference is that in Markov networks the potentials are arbitrary functions, whereas in the Bayes Nets the potentials are forced to be only conditional probabilities of some variables given others right.",
            "So in this way Markov networks are better than business because they're more flexible.",
            "Also, in Bayes Nets we allow cycles.",
            "Where is the market in business?",
            "We can't allow cycles.",
            "A cycle in a directed graph does not correspond to any real distribution, and this flexibility is going to come in very handy when we try to model relational domains.",
            "To offset these two advantages of Markov networks, the disadvantage that they have is that the partition function Z, the normalizing constant, can be very hard to compute, whereas in Bayes networks it's completely trivial to compute.",
            "It's just one.",
            "In fact, if you say I'm going to have a log linear model where the partition function is 1, what you wind up with necessarily is going to be.",
            "A vision network.",
            "OK, so those are the pros and the cons.",
            "Here are some more interesting differences.",
            "How do you check independence in Markov networks?",
            "Is just graph separation.",
            "In Bayes Nets, it's the separation, so it's a much more complicated criteria.",
            "You know in Markov networks, the graph.",
            "Basically, you know says what it seems to be saying, whereas in Bayesian networks the graph is actually somewhat misleading to naive user.",
            "Markov, Mets and business are incomparable in the sense that each one of them can represent the graph can represent some independence properties that the other one can't.",
            "So some things are compact Markov network, but not a compact vision network and vice versa.",
            "However, the most important thing to remember is that the mathematical form of a log linear model will be compact in either case.",
            "So if you can represent us along with things you know, anything that's a compact version network is a compact logging your model and anything that's a compact Markov network is a compact plug in your model.",
            "And now Lastly, how do you do inference?",
            "Well, we're going to look more at that shortly.",
            "For mark up Nets, there's things like Markov chain Monte Carlo, belief propagation and others for Bayes Nets.",
            "What you usually do in different, you know whether it's exact or approximate inference.",
            "Typically, first you convert the Bayes Nets to a Markov network and then you do inference over that.",
            "So in some sense, a Markov network is a more fundamental notion than evasion net."
        ],
        [
            "So how do you do inference in Markov networks?",
            "Well, our goal is to compute marginal and conditional probabilities over any variables in the network given any other variables.",
            "And so here's the expression.",
            "Unfortunately, doing exact inference of these is a sharply complete problem, so we're not going to be able to do it exactly.",
            "One thing that is easy though is to condition on the Markov blanket of a variable.",
            "So computing the probability of a variable given its neighbors is actually very simple.",
            "It's just this you know the normalization constant cancels between the numerator and denominator, and it's just the exponentiated some of the weights of the features that are true when the variable has saved the state one versus the some of that for the state zero in the state.",
            "One OK, and if the variable has more values, you just have more terms here, but the main point is that this is very quick and very simple to do, and So what we can do is exploit this.",
            "And you know famous organ that exploits this."
        ],
        [
            "Called Gibbs sampling and it's and it's a very simple algorithm.",
            "Here's what it does.",
            "We just start with a random assignment of values to the variables.",
            "I'm going to assume that the Boolean, so the truth assignments, and then I do the following for some number of steps or until some convergence criterion is met.",
            "I repeatedly sample each variable according to its neighbors, so I get a new state and then all I do is I count.",
            "What fraction of the time?",
            "Whatever variable I'm interested in was true, and that's going to be my estimate of the probability and you can show that you know under certain benign conditions, this actually converges to the true probabilities if you take enough samples.",
            "So very simple algorithm, but very general.",
            "So very, very widely used.",
            "There's many others in particular, there's lots and lots of variations of Markov chain Monte Carlo.",
            "Gibbs sampling is just the simplest version of that, there's also."
        ],
        [
            "A family of algorithms that go by the name of belief propagation.",
            "In particular, this is what's called the sum product.",
            "Formally propagation, because what it's really doing is computing a sum of products.",
            "There's also variation approximation and various exact methods which are historically the earliest, but they tend not to scale to the kinds of domains that we're going to be interested in here, so we won't focus on the."
        ],
        [
            "Much so the other type of inference that we often want to do is what's called any P or NP inference, which is the following problem.",
            "Given some evidence X, these are variables whose values I know compute the most likely state of the world, meaning the other variables Y which we can call the query variables.",
            "If you're familiar with hidden Markov models, this is for example, what the Viterbi algorithm does, and this is all like the general version of that problem, notice that.",
            "The most likely joint state of the variables is not necessarily the most likely state of each one of them individually, because the most likely state for A&B is not necessarily the most likely state of A and then most likely state would be so.",
            "These are different problems at that level off, and this is the question that we want to answer.",
            "For example, to do collective classification, classify whole bunch of webpages taking their links into account.",
            "What we want to do is compute most maximum a posteriori of our most probable explanation.",
            "Uh."
        ],
        [
            "Of the data that we've seen, and So what algorithms can we use for this purpose?",
            "Well, the oldest and simplest one is something called iterated conditional modes, which has a little bit of the favor of Gibbs sampling.",
            "You just do the following.",
            "I repeatedly go to each variable and I set it to its most likely value given its neighbors.",
            "I I said it too, it's conditional mode, and then I iterate.",
            "The disadvantage of this, of course, is that it could get it could get stuck in local Optima, and so to avoid that we can do simulated annealing, which historically is, you know, the standard method for doing inference in Markov networks.",
            "It can be pretty slow.",
            "Another alternative more recent, that can be quite fast is to use graph cut algorithms.",
            "What I do is I I represent the problem as a graph and I try to find you know the minimum set the least cost set of edges that I can cut, such that say one side is labeled positive and the other side is labeled negative and we can also use belief propagation.",
            "In this case a Max product version, because what we're trying to do is find the maximum of a product.",
            "OK, so let's talk a little bit about learning now.",
            "So how do we?",
            "How do we learn these models?",
            "Well, there's two parts."
        ],
        [
            "There's learning the parameters I either weights and learning the structure.",
            "I either features the parameters could be learned generatively or discriminatively and we will look at both.",
            "In this tutorial, I'm going to assume that we have complete data.",
            "If we don't have complete data, we need to use EM versions of these algorithms and these are available in some of the software that I will be talking about later.",
            "But in this tutorial for simplicity I'm just going to assume that."
        ],
        [
            "The data is always complete.",
            "So how do we do generative wake learning?",
            "Well, you just do the standard you can do, for example maximum likelihood learning or maximum posterior probability learning or full vision learning.",
            "Just as you could for simpler models.",
            "The one thing that's not so fortunate about these models is that you cannot find the weights in closed form.",
            "Unlike same Envision networks, however, it is.",
            "It's a convex problem, so there's a single global optimum, and you can find it efficiently without fear of falling into local Optima using something like gradient descent.",
            "In the simplest case, or using a second order technique like Quasi Newton or conjugate gradient methods, all of which are pretty well understood.",
            "And here's the form of the derivative of the of the log likelihood with respect to await.",
            "The gradient is just the vector of these.",
            "It's actually very intuitive and it's the following the derivative of the log likelihood with respect to a weight is the number of times that the corresponding feature is true in the data.",
            "Minus the expected number of times according to the model.",
            "So what happens is that if the model predicts that this feature is true less often than it really is, then its weight needs to go up.",
            "If it predicts that the feature is true more often than it should be, it's weight needs to go down, and once all of these lineup for all the features we've reached our optimum and we're done OK.",
            "So fairly simple.",
            "There's one big problem though.",
            "The big problem is that in order to compute these expected feature counts, I need to do inference.",
            "An inference, of course, is itself expensive.",
            "So now I'm looking at doing expensive inference at every step of a gradient descent procedure or or related one which could easily take hundreds of iterations.",
            "So a lot of the time this is going."
        ],
        [
            "Be too slow and you know people.",
            "Notice this pretty much right away when they started doing Markov networks in the 70s and the first thing that they came up with was a very clever trick called pseudo likelihood.",
            "And the idea of this trick is that if your objective function is too hard to optimize, let's optimize a different 11.",
            "That's easier to optimize, and hope that that doesn't hurt us too much, so pseudo likelihood is just the product.",
            "For all variables of the probability of each variable given its neighbors in the data.",
            "So I'm just conditioning on the Markov blanket through the data, so no inference needs to happen.",
            "This is something that I can compute immediately given the data and so and if I combine this with something like a fast 2nd order inference method, you actually get quite efficient weight learning, and this is widely used in areas like vision, spatial statistics, natural language processing and so forth.",
            "The disadvantage of this, of course, is that optimizing, so the likelihood is not the same as optimizing likelihood.",
            "The problem is that if you if at inference time you're going to have long chains of inference, these parameters could give poor results because all that.",
            "So the likelihood is optimizing is the short range interactions between variables.",
            "It assumes that the values of your neighbors are correct, and so will tend to overweight them.",
            "OK, so so so the likelihood can be very fast.",
            "For some problems it's just fine for."
        ],
        [
            "Problems that can actually pretty bad, so when it's bad, what can you do?",
            "Well, you can use discriminative learning, and in fact these days in machine learning people pretty much everywhere tend to use discriminative learning over generative just because it tends to give better results.",
            "And it's also easy to see why it would give better results.",
            "So the idea in discriminative learning is that if you know at learning time which variables are going to be query variables and let's call those Y and which variables are going to be evidence, let's call those X.",
            "Then what you can do is instead of optimizing the joint likelihood of X&Y, you can just optimize the conditional likelihood of Y given X.",
            "And the reason for this is if I'm going to know exit query time, there's no point in trying to model P of X.",
            "It's just going to be a waste of time at best and at worst it's actually going to produce the worst model because I'm I'm, you know, mixing what I'm trying to optimize with something else that doesn't really matter.",
            "OK, so discriminative learning often works quite well in our case, what we're going to have is, you know, a we're going to be optimizing something that has pretty much the same form.",
            "Except now I have X&Y instead of Y&X, and I can ignore all the clicks that only involve.",
            "Evidence variables.",
            "And another thing that I can do now though is I have another way of dealing with this hard inference problem here.",
            "And the way the thing that we can do now is we can approximate the expected counts by the counts in the most likely state of Y given X.",
            "And this is because often these distributions have modes all over the place.",
            "But once I've conditioned on enough information, my probability mass often winds up being concentrated around just one solution.",
            "Right, it's the most likely region of why, given the evidence that I have, and so instead of trying to do that big exponential sum, I just find the most likely state of Y and then do feature counts on those off.",
            "And I will get pretty much the same result.",
            "And of course, just finding the most like the state of why is a lot faster than trying to do a sum over all possible states, OK?"
        ],
        [
            "So this is the basic idea in discriminative learning."
        ],
        [
            "Map estimation is as hard in the worst case.",
            "In practice, what happens is that you can get a good approximation with map estimation when trying to do you know the full.",
            "Martial competition will take you too long.",
            "2nd.",
            "Well ICM ICM will not work well because it's it's too.",
            "It's being agreed procedure.",
            "It's very fast but will tend to sub optimize but you think for example is something like simulated annealing right?",
            "Or you know to give a more concrete example and an algorithm of this type is is the voted Perceptron?",
            "What 40% on does is it's for hidden Markov models and it uses the Viterbi algorithm to find the most likely state.",
            "And then use the counting that most like the state and you know it's a polynomial time algorithm.",
            "But we don't we we do not compute the marginals, right?",
            "We just use determined to find the most likely state.",
            "Sure.",
            "Yeah, I mean this will show up again later, so yeah.",
            "So we can approximate the expected counts using them."
        ],
        [
            "AP State This is one way that you can do discriminative learning.",
            "There are other weight learning approaches that I think are worth knowing about.",
            "The oldest one is a generative approach and it's called iterative scaling.",
            "This was traditionally the approach that was used to learn Markov networks these days.",
            "It's pretty much fall into disuse because it's so much less efficient than the other alternatives, but you know who knows it might somebody might improve it tomorrow.",
            "You might make a comeback, another approach which is discriminative and this is the most recent of these.",
            "Is to do Max margin training.",
            "You can actually do discriminate.",
            "In a sense, it's an even more discriminative approach in the sense that it doesn't even care what the probability of Y given X is.",
            "It just wants to get the right way by some margin.",
            "So this is just a generalization of support vector machines."
        ],
        [
            "The non ID problem where I have a bunch of labels that depend on each other and this is a very exciting type of approach.",
            "Again I'm not."
        ],
        [
            "Go into it in detail, but there's been a lot of recent research on it, and it's worth knowing about."
        ],
        [
            "What about structure learning?",
            "Well, so the problem is structured.",
            "Learning is we start out with no Markov network and we want to discover what the relevant features are.",
            "OK, so how might we do that?",
            "Well, we can use the standard greedy search that you would use for lots of other things.",
            "We can start with atomic features, meaning the individual variables are the features and then what I can do is I can join features to the current feature.",
            "I have my current set of features.",
            "I try conjoining every variable negative and not migrated to each feature and I greatly pick the best one.",
            "And I use some kind of, you know, likelihood score or posterior score or Carol Divergance and I keep going until I don't get any better results and I stop.",
            "OK, so this is a fairly straightforward idea.",
            "There is a big problem which is.",
            "When I try and you candidate structure, I just modified some feature.",
            "I now need to relearn the weights in order to be able to compute the likelihood right?",
            "'cause like the structure is just one part of the model and if I need to compute the weights for every single feature that I try this is, you know that could easily be trying, you know millions.",
            "My algorithm is never going to finish running, so typically what people do to sidestep this problem is they do an approximation that's actually quite reasonable.",
            "Which is to say when I modify a certain feature, when I create a new candidate feature.",
            "I'm going to assume that the weights of all the other features stay constant, and I'm only on got to optimize the weight of this one feature and this in some cases can even be done in closed form, so it's much, much faster.",
            "What it's compromising, of course.",
            "Is that in general some of the other features might have to change, and I'm not allowing that to happen, but I can always at the end of each learning step you know, go and relearn all all the weights or or do this at the end so it's not too bad.",
            "OK, and this makes a big difference to the running time of the structure learning algorithms.",
            "OK, so let's switch gears and let's talk about things on the logical side first."
        ],
        [
            "Talk a little bit about logical inference, and then we'll talk a little bit about inductive logic programming."
        ],
        [
            "So first let me get some terminology down formulas in first order logic are built out of logical connectives like conjunction, disjunction, quantifiers etc.",
            "And four types of symbols, constants that represent objects in the domain like sayana variables X, that range over the objects functions like mother of X that take a couple of objects and return an object and predicates like say friends XY that represent relations between objects or properties of them.",
            "So for example friends XY would represent whether X&Y are friends or not.",
            "And I'm going to call a literal a predicate or its negation.",
            "I'm going to call a clause it disjunction of literals.",
            "And every knowledge base and 1st logic can always be converted into clausal form.",
            "I'm going to call a grounding of a predicate or formula what you get by replacing all the variables by constants.",
            "So for example, if one of my predicates is friends XY and two of my constant Saarinen Bob, one possible grounding of friends is friends Anna Bob and Friends, and Bob is just a Boolean variable that is true if an above our friends, and false otherwise.",
            "And I'm going to call a world also known as model or interpretation and assignment of truth values to all the ground predicates.",
            "So if I take all the predicates and replace all the constants into them in all possible ways, I get a very large number of Boolean variables and in essence, what we're going to be interested in is truth assignments to these variables, and later we're going to be interested in probability distributions over these assignments."
        ],
        [
            "So how do we do inference in first order logic?",
            "Well, traditionally inference has been done by theorem proving using things like resolution.",
            "This is for example what Prolog uses.",
            "However, more recently people have found that if you proposition lies the model, IE you ground out everything in the way I just described, and then you do model checking, this can actually be a lot faster than doing resolution.",
            "This came as a surprise because you would think that this would be inefficient because it's not lifted.",
            "It actually turns out then in many domains this is actually very fast.",
            "And then how do you do model checking while you use the satisfiability solvers, of which there are two main families, backtracking is 1 approach, of which the typical paradigmatic example is the PLL and stochastic local search of which the Praying medic example is walk set and I'm going to go over each of these."
        ],
        [
            "Briefly.",
            "So first of all, let's define the satisfiability problem more precisely.",
            "My input is a set of clauses.",
            "I assume that the knowledge base is converted to have been converted to conjunctive normal form ahead of time.",
            "Like I said, this can always be done and my output is either the truth assignment that satisfies all the clauses or the answer no, or false if none exists.",
            "So if the knowledge base is not satisfiable, I want to return failure.",
            "If it is satisfiable, I want to return an assignment that satisfies all the clauses.",
            "And this of course, is the paradigmatic NP complete problem.",
            "So we know there is no efficient solution for it unless P = 2 NP.",
            "So we have to do search.",
            "Now the key point to realize about satisfiability testing is that even though in the worst case the problem is exponentially hard, most instances of the problem are actually easy.",
            "Many satisfiability problems.",
            "You just take a random solution and it actually satisfies all the clauses already.",
            "There's actually only a small region of parameter space where the problem is hard.",
            "What are the relevant parameters?",
            "The relevant parameters are the number of clauses and the number of variables.",
            "And the idea is this is that more variables give you more freedom.",
            "More clauses give you more constraints.",
            "If I have very few clauses per variable, then the problem is easy to satisfy, and probably there's many solutions because it's under constraint.",
            "If I have a larger number of clauses per variable, then the problem is hard, it's over constrained, and the chances that I can very quickly discover that the problem is insoluble.",
            "The hard region is when these have a particular ratio where you really can't tell if you're going to be able to solve the problem or not.",
            "And then you have to keep putting more and more work into it.",
            "And you know exactly what this ratio is, depends on the number of problems.",
            "But for random three set problems it's it's around 4 point something and people are, you know, trying to pin down exactly what that number is.",
            "So, but the important thing for our purposes is that most satisfiability problems are easy.",
            "And that's actually going to be a great."
        ],
        [
            "Boon for us.",
            "OK, so how do we solve satisfiability problems?",
            "Let's look at the backtracking approaches first.",
            "The basic idea in the backtracking approaches is very simple is we're just going to assign truth values by depth first search.",
            "So I start out with no truth values assigned, and then I assign.",
            "You know one value to one variable and then to another and then to another until I have to backtrack and then you know I keep on doing this, exploring the whole tree until I find the solution.",
            "Notice that when I assign a value a truthful to a variable, this has one of two effects.",
            "The false literals are either the Littles that become false by virtue of assigning that variable I either that variable or it's.",
            "Negation, depending on what level I'm assigning.",
            "Those essentially disappear.",
            "Or think of a clause in which the variable appears right if I have made the literal true.",
            "Now the clause is true.",
            "Hi yeah, if I've made a little false the little disappears.",
            "If I've made a little through the cloud disappears.",
            "So every time that I send a value to the variable I wind up with a similar problem.",
            "And so as I progress in my search the problem becomes simpler and simpler until one of two things happens.",
            "Either wind up with an empty set of clauses, which means that I've deleted all of them, so I've succeeded.",
            "Or I wind up with an empty clause, meaning that I've made all the literals in some clause false.",
            "Therefore the clause is false and I failed.",
            "And So what happens when I fail is that I backtrack.",
            "I undo some assignment that I just made, and I try again and I keep on doing this until I succeed, or until I've exhausted the tree and I returned failure.",
            "So this is the basic idea.",
            "There's a couple of additional improvements that we can do that actually make a big difference.",
            "One of those is what's called unit propagation.",
            "And the idea of propagation is that if you have a unit clause meaning a class that's just one literal, you know what value that has to have, right.",
            "If I have the clause, not a, I know that it has to be false.",
            "Otherwise immediately the problem is not satisfiable.",
            "OK, so one thing that I can do before I search is I can look for unit clauses and replace them by the obvious value.",
            "OK, now you might think, well, Gee, how many unique clauses are there going to be in my problem?",
            "Maybe not many, maybe not many, but the key thing is that as you replace.",
            "Variables clauses that were Link 3 become length two and then they become length one.",
            "So unit clauses crop up as a search progresses, so this winds up, you know, giving me enormous time savings.",
            "The other thing that we can use is what's called pure literals, which is Littles that had just had the same truth value everywhere.",
            "If a always appears non negative, then I know that you know I lose nothing by signing into value.",
            "True, and certainly I don't want to send the value false.",
            "So again, pure literals will appear as the search progress is in the in the CNF get simplified and."
        ],
        [
            "It will buy me a lot of time savings, so here's the famous DPL algorithm.",
            "DPL is short for the names of the people who developed it.",
            "Davis, Putman, Lodgment in Loveland.",
            "And the way it works is just this follows.",
            "It's a recursive procedure.",
            "If your CNF is empty, that means we've deleted all the clauses.",
            "I return true.",
            "Else if the CNF contains an empty clause, then I failed.",
            "I return false else if it contains a pure literal I, I called the PLL again with the literal replaced by the necessary value, else if it contains a unit clause, I again just called the PLL with the unit clauses you know value with literal replaced by the by the necessary value, otherwise.",
            "I choose some variable.",
            "There appears in the CN F and you know choosing which variable is a heuristic process, but one that is quite important and then and then.",
            "Here's what I do.",
            "Is I called EPL recursively with that variable, replace the true, and if that succeeds then I'm done.",
            "Otherwise I call it with the value of the variable set to false.",
            "So this is where things branch up, and this is the DPL algorithm.",
            "It can solve a lot of satisfied with problems very fast."
        ],
        [
            "Not nearly as fast as stochastic local search for a lot of problems, so there's many problems.",
            "Like for example, you know something as simple as in Queens, or the PLL is quite slow and stochastic.",
            "Local search is just blindingly fast.",
            "So how does stochastic local search work?",
            "It's the more recent of these types of methods, but it's the one that's close to the largest problems in stochastic local search.",
            "What I have at each point in the search is a complete assignment of values to the variables, so backtracking works with partial assignments.",
            "Stochastic local search works with complete assignments and then what do I do?",
            "Is we just start with a random state and then we repeatedly flip a variable in some unsatisfied clause, right?",
            "There's no point in flipping variables in satisfied clauses, at least heuristically, so we randomly can unsatisfied clause and flip a variable in it that will cause that class to be satisfied.",
            "And now this can be done in two modes.",
            "One is Hill climbing.",
            "So I try flipping each of the variables in the clause and I choose the one that maximizes the total number of satisfied clauses.",
            "OK, so this is just standard greedy search to try and solve as many classes as possible or in order to avoid getting trapped in local minima.",
            "I can I can do a random flip, meaning that I just pick one of the variables at random, and I flip that OK, and then I just do this for some fixed number of steps.",
            "I actually don't stop when I reach a local.",
            "Often this is very important.",
            "I keep going.",
            "You know, I could cross spend a long time just crossing a plateau.",
            "And then things might start improving again and I restart the whole procedure some number of times."
        ],
        [
            "Very simple, the standard algorithm that does this is called walks at.",
            "So here's walk said I do this for one to Max tries start with a random solution and then do this for Max flips.",
            "If all the clouds are satisfied.",
            "I returned the solution.",
            "Otherwise I pick a random clause with probability Pi, flip a random variable.",
            "Otherwise I flip available that maximizes the number of satisfied clauses.",
            "And obviously this P is going to control how greedy versus how random my searches.",
            "And if at the end of this I haven't found a solution.",
            "I returned failure and in fact this is the main limitation of stochastic local search algorithms.",
            "Is that if they return the solution then you know that that's a solution.",
            "If they returned failure, you never know for sure whether there was a solution, but it just wasn't found.",
            "OK, so the main advantage of the PLL is that it can tell you for sure whether it's success or failure."
        ],
        [
            "OK, so let's talk a little bit about learning logical models now."
        ],
        [
            "And this of course, is the field of inductive logic programming.",
            "The best way to introduce is probably to start with propositional rule induction, so inducing rules on just standard ID examples that are vectors of attributes, and I'm going to assume that they're all boolean for simplicity, so standard classification setting.",
            "I have a set of positive and negative examples of some concept.",
            "Each example is a vector of Boolean attributes X one to XN, and the class Y, and the goal is to induce rules that cover all the positive examples and none of the negative ones.",
            "So the rule is it is something like a conjunction of literals implies the class.",
            "This is the same as a horn clause where this is the body and the class is the head.",
            "And I will say that it will covers an example if and only if the example satisfies the body of the rule, IE it meets all the conditions on the Aetna students that I put here, and I'm going to assume that I have some kind of evaluation function like accuracy, information gain, coverage, support or combinations of them to guide my search."
        ],
        [
            "And then the way rule induction works is that I learn one ruler or one basic algorithm is I learned a single rule in the following way.",
            "I started out with the class being the head and an empty body.",
            "And then what I do is I try conjoining each little to the body.",
            "I evaluate the rule with the new body and then I pick the best literal i.e conjoined to the body.",
            "The little that most increases my evaluation function and I keep on doing this until no literal improves my evaluation function and I returned that rule.",
            "OK, so this returns one rule to me that hopefully covers a lot of positive examples and known."
        ],
        [
            "Negative ones, this goes inside a loop where I learn a set of rules.",
            "So what I do in that loop is I start out with an empty rule set and the set S. That's all my examples.",
            "Then I repeat the following.",
            "I learned a single rule in the way that I just described.",
            "I add it to my set of rules and I removed from the training set S all the positive examples that were covered by the rule, so they covered.",
            "I can now ignore them.",
            "They taken care of and now induced another rule to cover as many of the remaining examples as possible, and we keep going until I have no examples uncovered.",
            "OK, and then I return the set of rules that I've found so in that."
        ],
        [
            "If logic programming, or at least the most basic type of inductive logic programming algorithm is really just this idea, it's the same structure.",
            "But then at the level of 1st order.",
            "So what happens when we go to 1st order is that instead of.",
            "Just attributes just pulling attributes.",
            "What I now have are predicates with arguments.",
            "And same with the class.",
            "So now for example, my class could be something like ancestor XY, meaning X is an ancestor of Y, and you know a predicate could be something like parent XY, meaning X is a parent of Y. OK, so I'm still going to build rules as before, except I'm going to do it in a richer language now.",
            "Specifically, I'm going to do in the language of 1st order logic.",
            "So I'm going to what I'm going to do is.",
            "I'm going to add literals to a rule one at a time to try and build a better rule, and then I'm going to try to build.",
            "You know, many rules that cover all my positive instances of, for example, this predicate.",
            "We are going to have one restriction, which I think makes a lot of sense, which is when when I add a literal it now has variables.",
            "Right, this is something we didn't have the propositional case and I'm going to require that than you literal contain at least one variable that already appears in the rule.",
            "And the reason is that if it doesn't, then it's not going to really say anything about.",
            "You know what I'm interested in, so it's going to be pointless.",
            "OK, so I'm going to make that requirement, and then what I'm going to do is essentially the same as before.",
            "I'm going to try conjoining all possible levels to the rule subject to this restriction and I'm going to evaluate them according to some evaluation function and I'm going to pick the best one and I'm going to keep going until I get no further benefits.",
            "Now there's another important change that happens when we go to 1st order, which is that adding a literal changes the number of groundings of the rule.",
            "In the propositional case, the universe of examples that I'm talking about is always the same.",
            "Here, for example, when suppose that I started out with insects or XY, right?",
            "So my universe of examples.",
            "Here's the sets of all pairs of people, right?",
            "If there's Anna, Bob and Charles, then you know there's Anna Anna, Anna, Bobana, Charles, etc.",
            "But if I now add an antecedent like Consister, XZ, notice it satisfies the restriction I just imposed, right?",
            "I have?",
            "Or?",
            "Let's do parents see why?",
            "Which is more meaningful, right?",
            "It shares why, but it doesn't share Z.",
            "So now this rule has three variables, XY and Z.",
            "So now my universe.",
            "Is actually the set of all triples of examples.",
            "And if we're not careful about this, we could fool ourselves into into thinking that we're doing really well, because we're just creating positive examples all over the place.",
            "But the rule isn't really very good, so I need to in some way compensate for that effect.",
            "One heuristic way in which we can do that is to multiply my evaluation function by the number of positive groundings of the original rule that are still covered.",
            "After I've added the new little, because are the ones those are the ones that I care about, so this is just a heuristic, but it can work pretty well.",
            "And there's, you know many other things that you."
        ],
        [
            "Can do.",
            "And of course a huge spectrum of other LP algorithms.",
            "This will just give.",
            "That concludes our brief survey of the foundational areas of statistical initial learning.",
            "Even with just this, little much that we've learned of all the pieces we can put together, pretty effective as statistical relational learning algorithms."
        ],
        [
            "So as I said, this is a very active research area and there's a very large number of approaches that have been proposed in recent years.",
            "Here are some of them, in chronological order, knowledge based model construction is the earliest one.",
            "There's also stochastic logic programs, probabilistic relational models, relational Markov networks, vision logic, Markov logic, and many, many others.",
            "So this is really only a small sample of some of the approaches that people have proposed.",
            "What I'm going to do next is I'm going to very briefly take these as concrete examples and just give you a basic idea of how they do this thing of combining logic and probability, yeah?",
            "Super.",
            "Yes, you can do and supervise the LP in the following sense you can discover Association rules in LP, right?",
            "So what I would just describe was IRP for classification.",
            "In some sense you have this one predicate that you're trying to predict their RP algorithms, like for example codeine that just discover any clauses that hold.",
            "So you could think of this as unsupervised learning in a sense that you know you just model.",
            "It's the equivalent of modeling the joint distribution of a set of variables without having a designated class variable.",
            "And you know more generally, if you take any machine learning task that you can imagine there is an IOP version of that.",
            "That is, IOP.",
            "You know, reinforcement learning.",
            "There's IO P regression, there's LP whatever.",
            "You're still solving the same problem, except that now you're taking relations between objects into account and therefore you have predicates and so forth.",
            "So again, what I gave you was just really, you know, a very basic flavor of the field.",
            "OK, so let me give you a brief survey of some of these."
        ],
        [
            "Roaches, there are some of the better known approaches, so I think it will give you a fair picture of the field.",
            "Before I go into each one of them in detail, though, here's here's the key thing is, there's dozens of these, maybe hundreds, and every year there are more, however, so if you try to keep track of all of them, you know it's a losing game.",
            "The important thing to realize, though, is that there's a number of key dimensions.",
            "Along which these approaches fall, and really what's important to understand is those dimensions, because then when a new approach comes along, you immediately know how it fits into you.",
            "Know the big picture.",
            "And then you know how to you know you know the right way to look at it.",
            "Instead of an exponential number of approaches, we just have a linear number of dimensions to look at which which is an exponential gain.",
            "So what are the key dimensions one of them is the logical language that the approach uses, so we could, for example, use first order logic.",
            "In some sense, it's the most powerful option.",
            "Or you could use something more restricted like horn clauses, very popular approach or something like frame systems.",
            "So this is one dimension and the other another dimension is the probabilistic language that you use.",
            "So you could do something like vision networks, Markov networks like we just saw, you could use something like for example probabilistic context free grammars, or you know some more limited languages like say, you know Naive Bayes, which is a special case of Bayes Nets and so forth.",
            "Another dimension is the type of learning that you can do in this approach.",
            "So there's generative versus discriminative like we've just seen you constructor parameters.",
            "You could have knowledge rich or knowledge for learning.",
            "In principle you could do any of these types of learning with any approach.",
            "In practice, they're not always available.",
            "Sometimes there's no particular reason for that.",
            "Sometimes there is a good reason, and then there's also the type of inference that you do, so you can do me P versus marginal inference as we just saw another important dimension along, which is approach is very is.",
            "How do you handle grounding?",
            "You could ground out.",
            "Everything fully you could ground out things partially.",
            "That's actually the key idea.",
            "Knowledge base model construction.",
            "Or you could even do lifted inference, so again."
        ],
        [
            "This is another important dimension to think about, so let's start with the earliest example, which is knowledge based model construction and actually encompasses quite a variety of approaches.",
            "Here the logical languages, horn clauses and the probabilistic languages Bayes Nets.",
            "And the basic idea on how to combine logic and probability.",
            "Here is the following.",
            "Every ground atoms, so I have a first order world so I have relations.",
            "I have predicates, I have objects etc and I can construct ground atoms in the way that we just saw every possible ground Atom is going to be a positive potential node in my vision network.",
            "So I have a vision network over Boolean variables, each one of which is around that time, like say friends Anna, Bob OK and then what's going to happen is that I'm going to construct a vision network from my first order knowledge base.",
            "That's what this is called knowledge based model construction.",
            "Knowledge based is the horn knowledge base, and the model is the vision network and the way I'm going to construct the vision network is the following.",
            "The head of the clause is going to be the child.",
            "Note the body of the clause is going to be the parent notes OK, and now if I have and now if I have more than one clause with the same head.",
            "I need some kind of combination function.",
            "To combine the predictions from the various clauses.",
            "OK, so all the atoms in all the clauses that have this as their head are going to be parents of the node, right?",
            "Each clause is a is a deterministic conjunction.",
            "And now what I need is some kind of way to combine what the different causes said and this combination function can be something like logistic regression or noisy or noisy.",
            "Or is the most commonly used one.",
            "It basically says that the child is true.",
            "If one of the rules says it's true.",
            "But but there's a failure probability for each one of them, and there's also often some probability that it might be true even if all of the parent clauses fail.",
            "And So what happens is that when I have a query.",
            "What I do is I do partial grounding, meaning I construct just the network that I need to answer the question, which is basically going to be composed of the prologue, proof trees of the query node or nodes and all the evidence nodes.",
            "You can prove that a network containing those has all the information that you need to assign the right probability, IE you will give you the same answer as if you had formed the whole network with all the possible nodes.",
            "And of course a lot of the time it's going to be much, much smaller.",
            "OK, so we do grounding basically by doing all Prolog proofs and then we can do something like belief propagation over these networks.",
            "Or it could be another probabilistic inference method.",
            "But at this point I just have a vision network so I can use anything, belief propagation, MCMC etc.",
            "So to Linda structure of these networks we can use I LP right you can you could learn a model like this just by running any LP system and taking its output and saying it's the model.",
            "Now of course you also need to learn the parameters.",
            "Tylenda parameters often use something like EM, and the reason you something like him is that typically you will not have observed a lot of the intermediate predicates in your inference.",
            "If you've heard everything you can do it in closed form.",
            "Otherwise you need to do something like EM.",
            "Typically what people do in knowledge base also searches that they first learn the clauses using pure IO P and then they learn just the parameters using M, which is actually not quite the right thing to do if you think about it, you would actually like to learn at each point be learning the clauses using.",
            "Your ultimate likelihood objective function, so that's not."
        ],
        [
            "Base model construction.",
            "All distant, probably most varied family of these approaches.",
            "Here's another one stochastic logic programs here.",
            "The logical languages, again, horn clauses.",
            "The probabilistic languages, now probabilistic context free grammars in fact.",
            "Stochastic logic programs can just be seen as lifting PCF's to the 1st order level by turning production rules into horn clauses.",
            "So here's what we do is, we take a prolog program and we just attach a probability to each clause, with the restriction that the sum of the probabilities of the clauses with the same head has to be one.",
            "And the semantics of this is that that head is produced as one of its bodies.",
            "We just don't know which.",
            "But we have a probability distribution over them.",
            "OK, So what an SLP really gives you is a probability distribution of a prologue.",
            "Proof trees.",
            "So if then you want to do inference, then what you have to do is you have to look at the proof tag of whatever query item you have.",
            "You essentially have to do all proofs, but Prolog can do this for you.",
            "What has to happen now is that you need to keep track of the probabilities, meaning as you go down a tree you need to multiply the probabilities.",
            "And then you need to add the probabilities of all of all the trees and this will give you the probability of your query Atom again to do learning we can use IO P to the structure.",
            "Learning to do learn parameters, we can learn them with with with a small wrinkle, which is the M needs to be what's called failure adjusted.",
            "What I mean by fully adjusted?",
            "Not all proofs succeed.",
            "Right, but some of the proofs that don't succeed by this scheme also have some probability.",
            "So what I need to do is that I need to renormalize the partition function in SLPS is not one unlike Envision Networks, so I need to adjust my email with them to take that into account.",
            "I need to normalize to subtract out the probability mass of the proofs that fail."
        ],
        [
            "Here's another one probabilistic relational models.",
            "Alot of work was done in this over the last several years.",
            "Here the logical languages frame systems, IE you have classes of objects, and for each class of object you have a Canonical description of the object, meaning the attributes of the objects of that class and the relations of the objects of that class to other classes.",
            "The probabilistic language is once again vision networks, and the idea here is that we're going to have a frame system where for each class.",
            "We have a vision network that describes the joint distribution of the attributes of that of the objects of that class and now this is a relational model because the attributes of an object, in addition to depending in an attribute of an object in addition to being able to depend on other attributes of the same object, as in as in ordinary statistical learning, it can also depend on attributes of related objects of either the same class or other classes.",
            "Now the restriction that is implicit in frame systems is that, as in the logical case, we only have binary relations.",
            "So in PRMS you don't have relations of arbitrary Arity, and another restriction that is at least currently the case in PRMS is that you can't actually represent dependencies of relations on relations.",
            "You can represent dependencies of relations on attributes of jobs that they relate, but not things like, for example friends of friends or friends.",
            "So one nice thing about PRMS is that you can learn parameters in closed form.",
            "So a PRM is at some level just the vision network, so learning if there is this complete just decomposes into a separate problem for each variable, and so I can compute the parameters in the usual way in closed form if there is missing data, which is often the case, then I need to use EM.",
            "How do we?",
            "How do we learn structure the way structure is learning PRMS is analogous to the weights learning vision networks where you try adding, removing and reversing links, with the difference being that it's done in a tiered way.",
            "So what we do is in order to not get lost in a very large search space of things that you know any attribute could depend on is first we look for dependencies of an attribute on other attributes of the same object.",
            "And then for attributes of objects that that objects related to and then and so on.",
            "OK, so if you think of the length of the chain of relations between an object and another first, I looked at lengths of chain zero and lenses chain one change chain links, chains of length two, etc.",
            "And for inference PRMS fully ground out the network and then they do belief propagation, but it would be straightforward to only do partial grounding.",
            "I think in the same way that K. BMC does.",
            "And to use MCMC or something else for the info."
        ],
        [
            "So here's a more recent approach.",
            "Relational Markov networks in relational Markov networks.",
            "The logical languages, SQL queries, and in particular the simplest kind of SQL queries which are just conjunctive queries.",
            "Or, you know, if you're familiar with Datalog, you could think of this as being Datalog queries and the probabilistic language is Markov networks.",
            "And the way it works is that your SQL queries define the clicks.",
            "So I have a database.",
            "I apply my SQL query to the database and the two poles that this query returns are going to be the nodes in a click.",
            "So each answer you know.",
            "So each query is going to have a relation which is a set of tuples.",
            "Those are going to be my clicks and then I have a potential function for each query.",
            "Meaning that, for instance, each instance of the query I'm going to have another instance of that potential function.",
            "Notice that in this case I'm not so at least to date no uncertainty of relations is allowed, so I used the relations in my SQL query.",
            "When I'm defining the clicks.",
            "But then those clicks are only over ordinary attributes of the objects.",
            "Like for example, I could use the links between web pages to create the click that involves a page and a page that points to.",
            "But then the model is only over, say, the class.",
            "The classes of those pages and maybe the words that appear in them.",
            "So how do we do learning here?",
            "Learning is done discriminatively.",
            "In the way similar to what I described earlier again today, there are no structure learning algorithms for this approach, and then inference is done by full grounding and belief propagation.",
            "Although again, you can imagine doing partial grounding and and using other probabilistic inference methods."
        ],
        [
            "Vision logic we're getting towards.",
            "The more the very recent approaches now in Basel logic, the language is it has its own syntax.",
            "It's A kind of an imperative programming language that tells you how to, how to build a relational world, but the semantics is at the level of 1st order logic.",
            "The probabilistic language is once again vision networks, so at the end of the day, what vision logic does is it builds based networks, so the programming oranges called blog, which is sort revision logic.",
            "And it's it's it's.",
            "It's the idea of a generative model taken to the relational level.",
            "So it it tells you a sequence of steps by which you build additional work.",
            "First generate this set of objects or the number of objects using some distribution and then generate the properties of each of that using this distribution.",
            "If something if something else is another distribution, and so on until we've built potentially a very complicated world.",
            "The blog language itself does not say how the parameters should be set.",
            "It assumes that you've defined them separately in a Java function or some other external source.",
            "Possibly some library that somebody has created.",
            "Now the important feature of vision Logic is that unlike all the all the representations that we've seen so far, where you assume that all the audit senior domain are known in advance.",
            "And if you think about it, often this is not the case.",
            "I don't know what all the objects are or I have some noisy observations that might or might not be some objects or be the same object as each other version.",
            "Logic is a language that was basically designed from the ground up to allow unknown objects.",
            "So I can predict objects that I haven't seen.",
            "I can predict that two different things, for example two blips on a radar, our observations of the same objects.",
            "In this case an airplane.",
            "One big problem in Vision Logic, which was already a problem in things like probably conditional models, but it's bigger here because the language is more powerful is that you could write a block program that creates a vision network with directed cycles.",
            "And of course, that's not a meaningful probability distribution.",
            "And what happens if you run blog inference algorithms on such a network is that it will.",
            "It may not finish running, it could just go on forever.",
            "And unfortunately, checking whether a block program allows you know will have an instance that's a vision network with cycles is an intractable problem.",
            "So currently in the current implementation, this is just not checked, so you have to hope that you're lucky and you haven't created a model that's going to have cycles.",
            "So in terms of learning to date, no learning algorithms have been proposed for vision logic for inference.",
            "There's been a series of algorithms proposed of which the most advanced one is a form of Markov chain Monte Carlo that requires the user to supply a proposal distribution for the domain that they're using.",
            "And you know, even then, it's still not very fast.",
            "This has a very big disadvantage, which is that of course most users don't know how the heck to specify proposal distribution, even you know those of us with PHD's machine learning, often don't know how to do that.",
            "It it also another advantage of inference in invasion logic is that it does partial grounding in a clever way such that you could actually have an infinite model as long as once you've conditioned on the evidence that you have, the model is finite, everything actually still works through, so they call that contingent vision networks because the vision network has to be finite contingent on the evidence that you've seen.",
            "Finally, Markov logic is."
        ],
        [
            "The language where the logical language is first order logic and the probabilistic languages Markov networks.",
            "The syntax is very simple, it's just first order formulas with weights.",
            "So you take take for starter logic, attach away to each formula, and that's a Markov logic network.",
            "The semantics is the following.",
            "A formula in first order formula with the weight is treated as a template for constructing features of a Markov network.",
            "So each grounding of the formula is going to become a feature in the Markov network and the weight of that feature is going to be the weight of the formula that gave rise to it.",
            "So learning algorithms for Markov logic parameters can be learned.",
            "Generatively are discriminatively structure is learned by using LP with with arbitrary clauses.",
            "So not just one clauses and you know with Nmap score to guide the learning.",
            "MVP inference is done by weighted satisfiability testing.",
            "Marginal inference is then by Markov chain Monte Carlo with the moves proposed by by set solver and you know some some clever way that make sure you know the.",
            "You have a meaningful distribution at the end, and there's two ways in which things are made more efficient.",
            "One is partial grounding as before, another one is this idea of raising inference, where there's many very.",
            "You know, you assume that atoms are false unless you explicitly say that they true, and you assume that clauses are satisfied unless you explicitly said that there and satisfied.",
            "So this is only half a dozen as I said."
        ],
        [
            "There are many more.",
            "So what we're going to do here is we're going to focus on Markov logic for the rest of the tutorial for a couple of reasons.",
            "One is that to date it's the most developed approach in terms of the number, and you know, scalability and so forth and variety of the learning and inference algorithms that are developed for it.",
            "Another nice thing is that 'cause it has a very general logical language, namely 1st order logic and a very general probabilistic one, namely logging in models, many of the other approaches can be.",
            "Can be seen as special cases of Markov logic and we will see later how that can be done, so you can you can.",
            "Clearly get the structure of the field by seeing how each of those approaches Maps into this representation also.",
            "For Markov logic, there is a complete set of these algorithms available for people to use, which again I think is not the case, at least to some extent for any of the other approaches.",
            "So that's the main thing."
        ],
        [
            "We're going to be drawing on for the rest of this tutorial, so let me now go a little bit into a little bit more detail on Markov logic.",
            "I will start by talking about the representation and then we will look at some of the inference and learning algorithms, and then after that we will go into doing some applications.",
            "So the basic intuition Markov logic is very simple.",
            "It's the falling.",
            "You can think of a logical knowledge base is a set of hard constraints on the possible states of the world.",
            "If a world violates even one formula, it's impossible, and this is what makes for starter logic so brittle.",
            "Well, how about we make them soft constraints when world violates a formula, it becomes less probable, but not impossible.",
            "Suppose you have the formula smoking causes cancer in first order logic.",
            "As soon as this one smoker in your world that doesn't get cancer, the world is impossible.",
            "First, the logic makes no difference between there being one smoker without cancer and all of the smokers having no cancer.",
            "When of course the last one is vastly less likely than the first one.",
            "In Markov logic, we actually get what you intuitively hope to get, which is the more smokers that don't have cancer, the less likely the world becomes.",
            "And then each formula is going to have a weight that represents how strong of a constraint the formula is.",
            "So the formula is almost always true.",
            "Then it's a strong constraint and it should have a high weight.",
            "And if a world violates that, formulate plays a big penalty and now the probability of a world is just going to be a log linear model where what you have is the sum of the weights of the formulas that the world satisfies.",
            "So the more formulas of world satisfies, the more probability is and also the higher the weight of those formulas that it satisfies, the more probable the world is.",
            "So world where more smokers get cancer will have a higher value of this exponent here.",
            "And be more likely.",
            "So."
        ],
        [
            "Here's a more precise definition.",
            "So we're going to call a Markov logic network or MLN.",
            "A set of peers.",
            "If W where F is a formula in first order logic with the standard syntax and W is any real number, positive or negative.",
            "That's the syntax.",
            "The semantics is that, together with a set of constants representing objects in the domain and then Mail and defines a Markov network as follows, it's going to have one note for each grounding of each predicate in the MLN, and it's going to have one feature for each grounding of each formula in the MLN with the corresponding weight.",
            "So here."
        ],
        [
            "Is an example that will hopefully make things more concrete.",
            "So suppose I have these two statements in English smoking causes cancer and friends have similar smoking habits.",
            "These are both true.",
            "As you know, doctors and sociologists will tell you now anybody who's."
        ],
        [
            "Can AI 101 knows how to turn this into logic?",
            "You write something like for every X smokes of X implies cancer of X for every XY friends of XY implies smokes of X is equivalent to smokes of YK.",
            "Now there's only one problem with this is that both of these statements are not false.",
            "The statements in natural language were true, but these are false because not everybody who smokes gets cancer and certainly not all pairs of friends have.",
            "This makes same smoking habits.",
            "However, if I turn these."
        ],
        [
            "Formulas into Markov logic by giving them weights.",
            "Now I once again have something that's true and potentially useful, so I give a weight of 1.5 to this formula and a weight of 1.1 to this formula.",
            "This weight is higher.",
            "This reflects the fact that this is a stronger regularity than this.",
            "And a good rule of thumb to understand what it means is that other things being equal, the weight of a formula is the log odds that the formula is true.",
            "OK, so the more probable formula, the higher the weight.",
            "If the formula is equally likely to be true or false, the weight is 0.",
            "If the former is more likely to be false, will actually have a negative weight, so a negative weight is actually perfectly perfectly meaningful thing to have, so this is an MLN.",
            "Now let's look what happens in a concrete."
        ],
        [
            "I mean, let's say I have just two constants, Ann and Bob, because that's what will fit on a slide.",
            "So what's the ground Markov network that we're going to create?",
            "Well, it's going to have one variable for every grounding of every Atom with every combination of constants."
        ],
        [
            "So to start with, we're going to have for this smoke Sanon cancer Anna and smokes volvon cans."
        ],
        [
            "Bob and I'm going to have all groundings of the friends predicate, which is friends AB.",
            "Friends be a notice that they are not necessarily the same.",
            "Bob could be a much better friend of Anna.",
            "The nanny is of Bob and I'm also going to have these.",
            "You know, degenerate cases friends Anna Anna and friends Bob Bob which maybe have to do with their degree of self esteem or something.",
            "So So what I have now is a ground Markov network.",
            "This is is this is just I'm just going to build a probabilistic model over these variables and this is just a bunch of Boolean variables.",
            "So at this point we are in a standard.",
            "Probabilistic modeling situation.",
            "We know what to do right?",
            "So?",
            "So what is the Markov network going to be here?",
            "Well, I'm going to have a feature for every grounding of every formula.",
            "So for example, I'm going to have a feature that is smokes.",
            "Anna implies cancer N. And every time I have a feature feature involving two predicates, there will be an arc between the corresponding node."
        ],
        [
            "In the network, so I'm going to have an arc between cancer in and smokes Anna.",
            "That's the result of this formula smokes X implies cancer.",
            "X applied to Anna, and the same thing for Bob.",
            "OK, so this formula involves two predicates, so it gives me a binary click this formula here.",
            "Involves three predicates, so it's going to give me a ternary clique."
        ],
        [
            "And here all of its possible instances, so there's one here.",
            "Between smokes Anna friends and above.",
            "And smokes Bob the same thing here with friends Bob, Anna and they're going to have these two degenerate ones.",
            "So now I have a complete Markov network that I have built from the."
        ],
        [
            "MLN for this domain.",
            "Using this particular objects.",
            "I notice the following important fact that is true for Melanzane is actually generally true of all statistical additional models.",
            "Is that an email and is actually not a probability distribution and MLN is a family of probability distributions, a different one for every different world that you could apply it to, where all of those distributions are going to have in common is that they repetitions of the same templates.",
            "In Markov logic, the templates are farmers in first order, logic in relational Markov networks their SQL queries.",
            "In statistic in knowledge base model model construction there horn clauses, but there's always this idea of the template being repeated the number of times and now the probability of a world that I get out of this is here's my log linear model.",
            "It's the sum, it's the normalized expenditure, did some overall formulas of the weight of the Formula Times the number of true groundings of that formula in the world?",
            "OK, so if there are more smokers who get cancer in my world and for the corresponding?",
            "Formula is going to go up.",
            "It's going to be multiplied by its weight and the probability of that world is going to be higher, which is what I want to have OK. Now, something that you've probably that has probably crossed the minds of some of you is that this is all very nice, but it doesn't seem very practical.",
            "Doesn't seem very practical because what's going to happen when I run the network is that I'm going to get a huge blow up right?",
            "And in any but the smallest worlds, this isn't really going to.",
            "We're not able to do much with this, and you need some of the most significant progress that's been made in the last several years has been in dealing with this problem and the very first thing that you can do, which is very simple but already buys you a tremendous amount, is just to have typed variables and constants.",
            "If you have a predicate like works for XY, you only need to replace X by people and why by organisations it doesn't make sense to do anything else.",
            "So if you only replace variables by constants of the corresponding type immediately, the number of ground items that you have goes down a lot and there's going to be other things that we're going to do as we will see later now in Markov logic, you can actually do the full range of 1st order logic, including function, existential quantifiers, etc.",
            "I'm not going to talk about that here.",
            "For the sake of time, but you can certainly look at the papers, you can also do infinite and continuous domains in Markov logic.",
            "Again, I'm not going to talk about that here if there's time towards the end, I will show you an application to robot mapping where we do continuous domains and show you what happens there.",
            "But no, not at all.",
            "That's the key, right?",
            "Is that?",
            "Sorry, so the question is, do we assume that the groundings are different?",
            "Formulas are independent, right?",
            "Notice what happens is that a grounding of a formula is the dependence between the atoms that are involved in it, right?",
            "Right, so now if you think about it, the format that the atoms depend on each other view the formulas, which means that the formulas, if you think of them as Boolean variables, right?",
            "They also depend on the atoms and so formulas depend on each other via the atoms that they share.",
            "In the same way that an Atom can depend, you know if it appears in multiple clauses, that Atom is going to depend the Markov blanket of an Atom is going to be all the items that appear with it in any formula.",
            "OK, so you connect so you can have arbitrary dependencies in this language.",
            "This expression.",
            "No key point.",
            "This is this expression is not assuming independence, and that's because of what these features are over.",
            "What happens when you have IID data is that the features are only over properties of the same object.",
            "This is the key difference.",
            "When you have non IID data, your features can be over properties of more than one object.",
            "So for example, in this example that we have here.",
            "If if the MLN was just this, it would be an ideal model.",
            "Because we're only talking about properties of the same object, you can think of this as a simple classifier that predicts cancer given smokes and maybe given other features as well.",
            "OK where the non IID comes in is in a formula like this, because now what happens is that whether one person smokes depends on whether another person smokes.",
            "So now there are no longer independent.",
            "OK and this is what we get from first order logic is we get a very nice, well understood compact language for specifying dependencies among objects.",
            "Does that answer your question?",
            "We can, we can talk more about it, and I mean they'll be more examples of this later.",
            "In principle, yes.",
            "In practice, what happens is that if you add that rule and just retrain, starting with the current weights, that probably converges very quickly.",
            "Big enough.",
            "This is a really interesting question, and here's what happens.",
            "This is actually something that we wanted a lot about in the beginning is that.",
            "I mean, one of the good things about these models is that they generalize across domain sizes, right?",
            "That's great where they potentially generalized.",
            "But the question is, are they going to generalize well?",
            "If I learn weights on a small social network, will generalize to a large one, and there is indeed cost to worry that it won't.",
            "However, what actually seems to happen in practice that, at least in our experience, inexpensive other people.",
            "You generalize fairly well across a domain sizes.",
            "And one reason for that is that even though the number of possible groundings goes up a lot, the number of actual true groundings and those are the only ones that matter.",
            "But if you look at the solutions distichs, those don't go up by as much.",
            "Often they go up in proportion to the number of objects.",
            "Another way to look at this is you know, think of a simple model like you know an HMM or hidden Markov random for image processing, right?",
            "You can learn something on straight sequences and applied to large sequences.",
            "You can learn something on small images and apply them to large images and the general."
        ],
        [
            "This will work now.",
            "Underlying this is the fact that there is a learning bias here.",
            "The learning bias here is that the relevant sufficient statistiques are the class counts.",
            "If that's not the case, then you will generalize poorly.",
            "But empirically, this seems to be a pretty good base.",
            "Will talk more about this.",
            "I want to talk about learning and it's 3:30, so let's take a break and reconvene at 4."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm Peter Domingos from the University of Washington and this is a tutorial on practical statistical relational learning.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I will start with.",
                    "label": 0
                },
                {
                    "sent": "Trying to make this pointer be visible, which might be impossible.",
                    "label": 0
                },
                {
                    "sent": "Can you see this?",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "Well, I guess I'll have to do it without a pointer then.",
                    "label": 0
                },
                {
                    "sent": "I'm.",
                    "label": 0
                },
                {
                    "sent": "If anybody has a nice, you know, thick, brightly visible pointer that I can lend, I'll be grateful.",
                    "label": 0
                },
                {
                    "sent": "In the meantime, I'll just work with what I have, so I will begin with some motivation and then the tutorial has three main parts.",
                    "label": 0
                },
                {
                    "sent": "The first part is what you can think of is the four foundational areas of statistical relational learning, namely probabilistic inference, statistical learning, logical inference, and inductive logic programming.",
                    "label": 1
                },
                {
                    "sent": "I will then let's see how this one works.",
                    "label": 0
                },
                {
                    "sent": "Yeah, this is better now, yeah?",
                    "label": 0
                },
                {
                    "sent": "I will then talk about how we put this all together to build statistical, relational learners.",
                    "label": 0
                },
                {
                    "sent": "That's the second part, you know.",
                    "label": 0
                },
                {
                    "sent": "This actually parts is probably going to be longer than this because once we know the pieces, putting them together is actually surprisingly, maybe not that hard.",
                    "label": 0
                },
                {
                    "sent": "And finally we will spend a good chunk of time talking about various applications, things that you can do with statistical original learning.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Today so let me begin with the motivation.",
                    "label": 0
                },
                {
                    "sent": "Most machine learning algorithms assume that the data is IID, meaning that your objects are all independent of each other and you know they're all of the same type.",
                    "label": 0
                },
                {
                    "sent": "They all have the same kind of distribution.",
                    "label": 0
                },
                {
                    "sent": "And of course this is very unrealistic right in the real world, objects have all kinds of relationships between them.",
                    "label": 0
                },
                {
                    "sent": "The properties of 1 object affect the properties of another object, and we would like to be able to model that.",
                    "label": 0
                },
                {
                    "sent": "We will.",
                    "label": 0
                },
                {
                    "sent": "We want to be able to model domains with multiple types of objects.",
                    "label": 1
                },
                {
                    "sent": "We want to be able to model relations between objects.",
                    "label": 1
                },
                {
                    "sent": "The dependencies of object attributes on the relations between them, the dependencies of relations on each other and on.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Attributes and so forth.",
                    "label": 0
                },
                {
                    "sent": "And I think it's pretty much in almost, I think, every domain where where we have always been assuming IID data.",
                    "label": 0
                },
                {
                    "sent": "I think it's the case that if you look closer, data is not IID.",
                    "label": 0
                },
                {
                    "sent": "Here's here's a random sampling of domains.",
                    "label": 0
                },
                {
                    "sent": "Web search is a famous example.",
                    "label": 0
                },
                {
                    "sent": "If you use links between pages, you can get better page rankings than if you don't.",
                    "label": 0
                },
                {
                    "sent": "Information extraction is another one.",
                    "label": 0
                },
                {
                    "sent": "If you do joint inference between the various things that you want to extract the various tasks, you do better.",
                    "label": 0
                },
                {
                    "sent": "Natural language Processing is another example of the same kind.",
                    "label": 1
                },
                {
                    "sent": "More generally, perception in vision in speech, etc.",
                    "label": 0
                },
                {
                    "sent": "You have dependencies between the various objects that you're seeing.",
                    "label": 0
                },
                {
                    "sent": "A medical diagnosis is another interesting example right?",
                    "label": 0
                },
                {
                    "sent": "The UCI datasets a large number of them is medical diagnosis problems, and of course the first thing you assume is that all your patients are independent.",
                    "label": 0
                },
                {
                    "sent": "Well, in reality they're not because you know epidemics happen, and if somebody has the flu, you know the next person is more likely to have the flu, and so forth.",
                    "label": 0
                },
                {
                    "sent": "Another interesting example is computational biology.",
                    "label": 0
                },
                {
                    "sent": "It's one thing to model, you know, individual problems, like you know, is this a promoter region or not?",
                    "label": 0
                },
                {
                    "sent": "What we really want to do it in today's believe is build models of how the entire cell works and that involves a lot of dependencies among proteins, genes, etc.",
                    "label": 0
                },
                {
                    "sent": "Social networks are another obvious example.",
                    "label": 0
                },
                {
                    "sent": "Your preferences, your habits, the things you do are influenced by your friends, your coworkers, etc will be good as computing is another important example since their networks are a very hot topic these days, the readings that you get at one sensor.",
                    "label": 0
                },
                {
                    "sent": "Are you know, not independent of the readings that you get at nearby sensors, for example ANM.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Anymore examples you know I could spend the rest of the afternoon just going over the domains where modeling dependencies between objects is important.",
                    "label": 0
                },
                {
                    "sent": "So what are the statistical rational learning is really trying to do this?",
                    "label": 0
                },
                {
                    "sent": "Trying to model domains where the objects are not independent identically distribute the benefits of doing that?",
                    "label": 0
                },
                {
                    "sent": "Well, one potential benefit is that we get better predictive accuracy.",
                    "label": 1
                },
                {
                    "sent": "Because if there are dependencies between objects and we ignore them, we were throwing out some of the information that we could use for prediction.",
                    "label": 0
                },
                {
                    "sent": "So that's one important potential benefit.",
                    "label": 0
                },
                {
                    "sent": "Another one is better understanding of the domains.",
                    "label": 1
                },
                {
                    "sent": "If we, if we ignoring a lot of the dependencies, alot of the phenomena that are going on their domain, we probably won't understand it very well, as if we do.",
                    "label": 0
                },
                {
                    "sent": "And also more generally, I think SRL offers a growth path for machine learning from small isolated problems to really solving the large big massive problems that real intelligent systems have to deal with, and I think we can grow progressively more ambitious in this way.",
                    "label": 0
                },
                {
                    "sent": "You know to offset the benefits.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately there are also some costs.",
                    "label": 1
                },
                {
                    "sent": "1 cost is that learning is now much, much harder.",
                    "label": 0
                },
                {
                    "sent": "If you allow dependencies between objects, you know the the number of parameters of the model that you have to learn.",
                    "label": 0
                },
                {
                    "sent": "Potentially go up exponentially and this is going up exponentially for something that was already exponentially large, so you know building known ID models can be a really, really hard problem.",
                    "label": 0
                },
                {
                    "sent": "Another another issue is that you know when you're just doing something like building a classifier.",
                    "label": 0
                },
                {
                    "sent": "You can ignore the problem of inference because you know the inference is just computing a function.",
                    "label": 0
                },
                {
                    "sent": "Now you really can't take no difference anymore.",
                    "label": 0
                },
                {
                    "sent": "Inference is really crucial.",
                    "label": 0
                },
                {
                    "sent": "Because, you know now now different classes, for example of different topics influence each other.",
                    "label": 0
                },
                {
                    "sent": "You need to figure out how to how to compute that, and indeed you know a good chunk of this tutorial is going to be talking about the inference methods that are relevant for statistical relational learning.",
                    "label": 0
                },
                {
                    "sent": "Here's what is perhaps the biggest problem.",
                    "label": 0
                },
                {
                    "sent": "The biggest problem is that it's much more complex for the user to model non IID domains.",
                    "label": 0
                },
                {
                    "sent": "This is probably the biggest thing that's holding us back and why people have always tended to assume IID data is.",
                    "label": 0
                },
                {
                    "sent": "That is just so much easier.",
                    "label": 0
                },
                {
                    "sent": "The number of options that you have to contend with, the number of things that you have to model, the number of decisions that you have to make, you know all of this goes up when you have non IID data, so those are the downsides.",
                    "label": 0
                },
                {
                    "sent": "What I hope to persuade you today is that.",
                    "label": 0
                },
                {
                    "sent": "Thanks to recent progress, the benefits now the costs and an SRL is something that you can do effectively in practice today without a lot of investment on your.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Part as the researcher or the user.",
                    "label": 0
                },
                {
                    "sent": "So our goal stated in one sentence is to enable learning from non IID data as easily as from IID data.",
                    "label": 1
                },
                {
                    "sent": "We would like learning from an activity to be as easy as something like applying C 4.5 to a standard classification problem.",
                    "label": 0
                },
                {
                    "sent": "Now, maybe we can never completely reach this goal because after all the problems are more complex.",
                    "label": 0
                },
                {
                    "sent": "But I think that you know we are fairly close to that.",
                    "label": 0
                },
                {
                    "sent": "There's been a lot of research on this problem.",
                    "label": 0
                },
                {
                    "sent": "Saint years we've made a lot of progress and I think we are at the point where we're close enough to the goal that you can just give statistical additional learners to various people and they will be useful things with the money that's been our experience, and so the goal of this tutorial is too, you know, share this.",
                    "label": 0
                },
                {
                    "sent": "The this knowledge that we have these techniques that we've developed in the field with all of you, and we're also at the point.",
                    "label": 0
                },
                {
                    "sent": "I think this is always a sign of maturity in the field where there is easy to use open source software to do these things.",
                    "label": 0
                },
                {
                    "sent": "As long as to do SRL we need to go and roll your own system and spend months doing that.",
                    "label": 0
                },
                {
                    "sent": "It's really not going to happen, but that's not the case anymore.",
                    "label": 0
                },
                {
                    "sent": "There's a bunch of systems out there there are, you know, a fairly usable and so, and they incorporate the algorithms that you need, and then you can build on them and do extensions and variations, but at least the starting point is pretty good and you know we will use one of these systems today as an example in our applications.",
                    "label": 0
                },
                {
                    "sent": "Needless to say, there's lots of research questions in this field.",
                    "label": 0
                },
                {
                    "sent": "There's both all the old questions.",
                    "label": 0
                },
                {
                    "sent": "All the old questions in logical learning and statistical learning and inference are still here.",
                    "label": 0
                },
                {
                    "sent": "So research on those is still relevant.",
                    "label": 0
                },
                {
                    "sent": "But in addition, there are lots of interesting new research questions, both about the new problems that we can solve and about the new opportunities of things that we can do.",
                    "label": 0
                },
                {
                    "sent": "And hopefully you also get a flavor of some of those as well.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Go through the tutorial.",
                    "label": 0
                },
                {
                    "sent": "So here's the plan.",
                    "label": 0
                },
                {
                    "sent": "We have the basic elements for what we want to do.",
                    "label": 0
                },
                {
                    "sent": "The basic elements are probability for handling uncertainty and logic for representing, you know, types, relations, complex dependencies between them, which is what we really want to do in SRL, and we have learning an inference algorithms for each.",
                    "label": 1
                },
                {
                    "sent": "We have statistical learning algorithms, we have IOP.",
                    "label": 1
                },
                {
                    "sent": "The problem is figuring out how to put them together.",
                    "label": 0
                },
                {
                    "sent": "And then, once we've done that, we're going to have tremendous leverage on a wide range of applications, and so each of these is basically going to be one part of the tutorial.",
                    "label": 0
                },
                {
                    "sent": "The basics, combining them and applying them.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let me just preface the tutorial with some disclaimers.",
                    "label": 0
                },
                {
                    "sent": "What I'm going to do here is by no means a complete survey of statistical learning.",
                    "label": 0
                },
                {
                    "sent": "There was no way to do that in the time that I have, and to some extent the choices that I'm going to have here just represent what I'm most familiar with.",
                    "label": 0
                },
                {
                    "sent": "You know, there's there is a random component to this.",
                    "label": 0
                },
                {
                    "sent": "I'm also obviously not going to do a complete survey of the foundational areas.",
                    "label": 1
                },
                {
                    "sent": "In fact, I'm going to just touch on the very few essential things for what we're going to be needing further.",
                    "label": 0
                },
                {
                    "sent": "And you know, if some of you are familiar with one or more of these areas, bear with me.",
                    "label": 0
                },
                {
                    "sent": "You know, you're probably not going to see anything you there.",
                    "label": 0
                },
                {
                    "sent": "The satisfying thing, though, is that even though we're going to be, we're going to go through all these areas in sort of like a very whirlwind fashion.",
                    "label": 0
                },
                {
                    "sent": "Even just what we're going to see is enough to do a lot, and I think you know, that's that's kind of nice.",
                    "label": 0
                },
                {
                    "sent": "So I do.",
                    "label": 1
                },
                {
                    "sent": "I am going to assume that you will have a basic background in logic, probability and statistics and so forth.",
                    "label": 1
                },
                {
                    "sent": "Please ask questions anytime you have them.",
                    "label": 0
                },
                {
                    "sent": "You know if there's anything you don't understand or any thoughts that come to your mind, do let me know and I will do my best to answer.",
                    "label": 0
                },
                {
                    "sent": "This tutorial written version of the tutorial examples.",
                    "label": 0
                },
                {
                    "sent": "The examples that I'm going to do here.",
                    "label": 0
                },
                {
                    "sent": "Datasets, the models, etc.",
                    "label": 0
                },
                {
                    "sent": "They are all available at this website.",
                    "label": 0
                },
                {
                    "sent": "Alchemy.cs.washington.edu and I will put this URL again at the end.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so let's start by surveying the four foundational areas starting with probabilistic inference.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And what I'm going to do is focus mainly on Markov networks.",
                    "label": 0
                },
                {
                    "sent": "I assume that most of you have already at least a passing familiarity with vision networks.",
                    "label": 0
                },
                {
                    "sent": "One main thing that we're going to be using here is Markov networks that you may not be so familiar with, so let me briefly give you an introduction to Markov networks.",
                    "label": 0
                },
                {
                    "sent": "A Markov Markov network, like a vision network, is a graphical model for the joint distribution of a set of variables.",
                    "label": 0
                },
                {
                    "sent": "Here are four variables.",
                    "label": 0
                },
                {
                    "sent": "I'm assuming there Boolean smoking, cancer, asthma, and cough.",
                    "label": 0
                },
                {
                    "sent": "The difference is that Markov networks are undirected models, meaning the edges between the graphs don't have a direction.",
                    "label": 0
                },
                {
                    "sent": "And the semantics is actually very simple.",
                    "label": 0
                },
                {
                    "sent": "Is that the an edge connects two nodes that are directly dependent on each other?",
                    "label": 0
                },
                {
                    "sent": "And two nodes are independent of each other given some others.",
                    "label": 0
                },
                {
                    "sent": "If once I remove those nodes they disconnected.",
                    "label": 0
                },
                {
                    "sent": "So for example, coffee and smoking are independent of each other.",
                    "label": 0
                },
                {
                    "sent": "Given cancer and asthma.",
                    "label": 0
                },
                {
                    "sent": "Notice that this is actually easier to verify then then in vision networks and the neighbors of a network of nodes say cancer and asthma for cough, also known as their Markov blanket are the ones that.",
                    "label": 0
                },
                {
                    "sent": "If you know those nodes, you don't need to know anybody else in the network.",
                    "label": 0
                },
                {
                    "sent": "So that's the graph.",
                    "label": 0
                },
                {
                    "sent": "The graph tells you what the conditional independence ease in the domain are.",
                    "label": 0
                },
                {
                    "sent": "In addition, we need parameters parameters.",
                    "label": 0
                },
                {
                    "sent": "In the case of Markov networks come in the form of what are called potential functions, and there's going to be a potential function for each clique in the graph, and the click is a completely connected sub graph.",
                    "label": 0
                },
                {
                    "sent": "So here we have two.",
                    "label": 0
                },
                {
                    "sent": "There's the click between smoking and cancer and the click between cancer, asthma and cough and a potential function is just any non negative function it takes on a value for each state of the click.",
                    "label": 0
                },
                {
                    "sent": "So for example, for the smoking cancer click, here's a possible potential function.",
                    "label": 0
                },
                {
                    "sent": "If they both false, the value is 4.5.",
                    "label": 0
                },
                {
                    "sent": "Etc.",
                    "label": 0
                },
                {
                    "sent": "What this particular potential function here is capturing?",
                    "label": 0
                },
                {
                    "sent": "If you notice, it's just that the state where you smoke and don't get cancer is less likely than the others, and the reason of this for this, of course, is that smoking causes cancer.",
                    "label": 0
                },
                {
                    "sent": "Now notice that these numbers can be larger than one, and the probability of a whole state is just obtained by multiplying the values of the potential functions for all the clicks in that state.",
                    "label": 0
                },
                {
                    "sent": "So the probability is well defined, but the probabilities of all states don't necessarily add up to one.",
                    "label": 0
                },
                {
                    "sent": "So in order to do that we need to divide by the sum of this product of potentials for all possible States and this is called Z, also known as the partition function from its using physics.",
                    "label": 0
                },
                {
                    "sent": "So this is the full expression for the probability.",
                    "label": 0
                },
                {
                    "sent": "Now there's a.",
                    "label": 0
                },
                {
                    "sent": "There's a.",
                    "label": 0
                },
                {
                    "sent": "There's a problem with Markov networks, which is the follow if your clicks, which is also a problem with vision networks.",
                    "label": 0
                },
                {
                    "sent": "Actually, if your clicks are all small then everything is fine, but if a click is large then the complexity of this model blows up, right?",
                    "label": 0
                },
                {
                    "sent": "You need the value of the potential function for every state of a click.",
                    "label": 0
                },
                {
                    "sent": "If you have a click with 10 binary variables, you have to to the 10 possible States and that's not going to work.",
                    "label": 0
                },
                {
                    "sent": "It's going to be too complex.",
                    "label": 0
                },
                {
                    "sent": "For instance.",
                    "label": 0
                },
                {
                    "sent": "It's also going to be very difficult to learn, Fortunately.",
                    "label": 0
                },
                {
                    "sent": "There's something else that we can do, which is to use what's called.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A log linear model.",
                    "label": 0
                },
                {
                    "sent": "In the log linear model, instead of representing the probability of a state as a product of potential functions, we represented as an exponentiated sum of terms, which after all you can always convert from one to the other.",
                    "label": 0
                },
                {
                    "sent": "So we still have the normalization constant.",
                    "label": 0
                },
                {
                    "sent": "Now we have the exponential, it's some of.",
                    "label": 0
                },
                {
                    "sent": "Is a sum of a set of features times their weights.",
                    "label": 0
                },
                {
                    "sent": "Now in at 1 extreme I can just have one feature for each state of each click and so I can implement any potential function model in this way.",
                    "label": 0
                },
                {
                    "sent": "The nice thing though, is that I could have many fewer features than there are states of the potential functions.",
                    "label": 0
                },
                {
                    "sent": "If I have a very large click with a huge number of states, but I know that there's only 10 important features, then I can just represent those in their weights and so my model can stay compact even.",
                    "label": 0
                },
                {
                    "sent": "If the potential function would be very large and we're going to take full advantage of this, for example, the potential function that we saw before could be represented simply by 1 feature of the smoking cancer pair, which is 1 if you don't smoke or have cancer, and 0 otherwise.",
                    "label": 0
                },
                {
                    "sent": "And if you give 1.5 weight to that feature, you get the exact potential function that we saw before.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Type.",
                    "label": 0
                },
                {
                    "sent": "So there's a famous theorem in Markov networks called the Hammersley Clifford theorem, which says the following.",
                    "label": 0
                },
                {
                    "sent": "Suppose that you have a distribution that is always non negative.",
                    "label": 0
                },
                {
                    "sent": "Sorry there is always strictly positive.",
                    "label": 1
                },
                {
                    "sent": "And the graph encodes the conditional independencies in your in your domain.",
                    "label": 0
                },
                {
                    "sent": "Then the distribution is a product of potentials over the clicks of the graph.",
                    "label": 1
                },
                {
                    "sent": "OK, so notice that I told you two things here, and I in no way proves that they were equivalent.",
                    "label": 0
                },
                {
                    "sent": "It turns out that they are equivalent.",
                    "label": 0
                },
                {
                    "sent": "The conditional independencies, and then the potential form function as long as every state has non zero probability and the inverse of this is also true.",
                    "label": 0
                },
                {
                    "sent": "It's actually also a lot easier to prove.",
                    "label": 0
                },
                {
                    "sent": "And you can think of this theorem is in a short form as a Markov network is the same as it gives distribution.",
                    "label": 0
                },
                {
                    "sent": "It gives distribution.",
                    "label": 0
                },
                {
                    "sent": "Is this thing that I just?",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here.",
                    "label": 0
                },
                {
                    "sent": "Again, statisticians call it a log.",
                    "label": 0
                },
                {
                    "sent": "In your model, physicists call it.",
                    "label": 0
                },
                {
                    "sent": "It gives distribution and what the Hammersley Clifford.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Eminence even say, is that a Markov network, meaning the graph with the conditional independence ease as I described, and it gives distribution are in our in effect the same thing.",
                    "label": 0
                },
                {
                    "sent": "OK, so we know we can we can use one or the other as appropriate, and that's what we're taking advantage here.",
                    "label": 0
                },
                {
                    "sent": "So how do more?",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of networks compared to vision networks.",
                    "label": 0
                },
                {
                    "sent": "Well.",
                    "label": 0
                },
                {
                    "sent": "They both have the same form.",
                    "label": 0
                },
                {
                    "sent": "They both in the form of products of potential.",
                    "label": 0
                },
                {
                    "sent": "So at that level is very similar.",
                    "label": 0
                },
                {
                    "sent": "The big difference is that in Markov networks the potentials are arbitrary functions, whereas in the Bayes Nets the potentials are forced to be only conditional probabilities of some variables given others right.",
                    "label": 0
                },
                {
                    "sent": "So in this way Markov networks are better than business because they're more flexible.",
                    "label": 0
                },
                {
                    "sent": "Also, in Bayes Nets we allow cycles.",
                    "label": 0
                },
                {
                    "sent": "Where is the market in business?",
                    "label": 0
                },
                {
                    "sent": "We can't allow cycles.",
                    "label": 0
                },
                {
                    "sent": "A cycle in a directed graph does not correspond to any real distribution, and this flexibility is going to come in very handy when we try to model relational domains.",
                    "label": 0
                },
                {
                    "sent": "To offset these two advantages of Markov networks, the disadvantage that they have is that the partition function Z, the normalizing constant, can be very hard to compute, whereas in Bayes networks it's completely trivial to compute.",
                    "label": 0
                },
                {
                    "sent": "It's just one.",
                    "label": 0
                },
                {
                    "sent": "In fact, if you say I'm going to have a log linear model where the partition function is 1, what you wind up with necessarily is going to be.",
                    "label": 0
                },
                {
                    "sent": "A vision network.",
                    "label": 0
                },
                {
                    "sent": "OK, so those are the pros and the cons.",
                    "label": 0
                },
                {
                    "sent": "Here are some more interesting differences.",
                    "label": 0
                },
                {
                    "sent": "How do you check independence in Markov networks?",
                    "label": 0
                },
                {
                    "sent": "Is just graph separation.",
                    "label": 0
                },
                {
                    "sent": "In Bayes Nets, it's the separation, so it's a much more complicated criteria.",
                    "label": 0
                },
                {
                    "sent": "You know in Markov networks, the graph.",
                    "label": 0
                },
                {
                    "sent": "Basically, you know says what it seems to be saying, whereas in Bayesian networks the graph is actually somewhat misleading to naive user.",
                    "label": 0
                },
                {
                    "sent": "Markov, Mets and business are incomparable in the sense that each one of them can represent the graph can represent some independence properties that the other one can't.",
                    "label": 0
                },
                {
                    "sent": "So some things are compact Markov network, but not a compact vision network and vice versa.",
                    "label": 0
                },
                {
                    "sent": "However, the most important thing to remember is that the mathematical form of a log linear model will be compact in either case.",
                    "label": 0
                },
                {
                    "sent": "So if you can represent us along with things you know, anything that's a compact version network is a compact logging your model and anything that's a compact Markov network is a compact plug in your model.",
                    "label": 0
                },
                {
                    "sent": "And now Lastly, how do you do inference?",
                    "label": 0
                },
                {
                    "sent": "Well, we're going to look more at that shortly.",
                    "label": 0
                },
                {
                    "sent": "For mark up Nets, there's things like Markov chain Monte Carlo, belief propagation and others for Bayes Nets.",
                    "label": 0
                },
                {
                    "sent": "What you usually do in different, you know whether it's exact or approximate inference.",
                    "label": 0
                },
                {
                    "sent": "Typically, first you convert the Bayes Nets to a Markov network and then you do inference over that.",
                    "label": 0
                },
                {
                    "sent": "So in some sense, a Markov network is a more fundamental notion than evasion net.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how do you do inference in Markov networks?",
                    "label": 1
                },
                {
                    "sent": "Well, our goal is to compute marginal and conditional probabilities over any variables in the network given any other variables.",
                    "label": 0
                },
                {
                    "sent": "And so here's the expression.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately, doing exact inference of these is a sharply complete problem, so we're not going to be able to do it exactly.",
                    "label": 0
                },
                {
                    "sent": "One thing that is easy though is to condition on the Markov blanket of a variable.",
                    "label": 0
                },
                {
                    "sent": "So computing the probability of a variable given its neighbors is actually very simple.",
                    "label": 0
                },
                {
                    "sent": "It's just this you know the normalization constant cancels between the numerator and denominator, and it's just the exponentiated some of the weights of the features that are true when the variable has saved the state one versus the some of that for the state zero in the state.",
                    "label": 0
                },
                {
                    "sent": "One OK, and if the variable has more values, you just have more terms here, but the main point is that this is very quick and very simple to do, and So what we can do is exploit this.",
                    "label": 0
                },
                {
                    "sent": "And you know famous organ that exploits this.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Called Gibbs sampling and it's and it's a very simple algorithm.",
                    "label": 1
                },
                {
                    "sent": "Here's what it does.",
                    "label": 0
                },
                {
                    "sent": "We just start with a random assignment of values to the variables.",
                    "label": 0
                },
                {
                    "sent": "I'm going to assume that the Boolean, so the truth assignments, and then I do the following for some number of steps or until some convergence criterion is met.",
                    "label": 0
                },
                {
                    "sent": "I repeatedly sample each variable according to its neighbors, so I get a new state and then all I do is I count.",
                    "label": 1
                },
                {
                    "sent": "What fraction of the time?",
                    "label": 0
                },
                {
                    "sent": "Whatever variable I'm interested in was true, and that's going to be my estimate of the probability and you can show that you know under certain benign conditions, this actually converges to the true probabilities if you take enough samples.",
                    "label": 0
                },
                {
                    "sent": "So very simple algorithm, but very general.",
                    "label": 0
                },
                {
                    "sent": "So very, very widely used.",
                    "label": 0
                },
                {
                    "sent": "There's many others in particular, there's lots and lots of variations of Markov chain Monte Carlo.",
                    "label": 0
                },
                {
                    "sent": "Gibbs sampling is just the simplest version of that, there's also.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A family of algorithms that go by the name of belief propagation.",
                    "label": 1
                },
                {
                    "sent": "In particular, this is what's called the sum product.",
                    "label": 0
                },
                {
                    "sent": "Formally propagation, because what it's really doing is computing a sum of products.",
                    "label": 0
                },
                {
                    "sent": "There's also variation approximation and various exact methods which are historically the earliest, but they tend not to scale to the kinds of domains that we're going to be interested in here, so we won't focus on the.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Much so the other type of inference that we often want to do is what's called any P or NP inference, which is the following problem.",
                    "label": 0
                },
                {
                    "sent": "Given some evidence X, these are variables whose values I know compute the most likely state of the world, meaning the other variables Y which we can call the query variables.",
                    "label": 1
                },
                {
                    "sent": "If you're familiar with hidden Markov models, this is for example, what the Viterbi algorithm does, and this is all like the general version of that problem, notice that.",
                    "label": 0
                },
                {
                    "sent": "The most likely joint state of the variables is not necessarily the most likely state of each one of them individually, because the most likely state for A&B is not necessarily the most likely state of A and then most likely state would be so.",
                    "label": 0
                },
                {
                    "sent": "These are different problems at that level off, and this is the question that we want to answer.",
                    "label": 0
                },
                {
                    "sent": "For example, to do collective classification, classify whole bunch of webpages taking their links into account.",
                    "label": 0
                },
                {
                    "sent": "What we want to do is compute most maximum a posteriori of our most probable explanation.",
                    "label": 0
                },
                {
                    "sent": "Uh.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Of the data that we've seen, and So what algorithms can we use for this purpose?",
                    "label": 0
                },
                {
                    "sent": "Well, the oldest and simplest one is something called iterated conditional modes, which has a little bit of the favor of Gibbs sampling.",
                    "label": 1
                },
                {
                    "sent": "You just do the following.",
                    "label": 0
                },
                {
                    "sent": "I repeatedly go to each variable and I set it to its most likely value given its neighbors.",
                    "label": 0
                },
                {
                    "sent": "I I said it too, it's conditional mode, and then I iterate.",
                    "label": 0
                },
                {
                    "sent": "The disadvantage of this, of course, is that it could get it could get stuck in local Optima, and so to avoid that we can do simulated annealing, which historically is, you know, the standard method for doing inference in Markov networks.",
                    "label": 0
                },
                {
                    "sent": "It can be pretty slow.",
                    "label": 0
                },
                {
                    "sent": "Another alternative more recent, that can be quite fast is to use graph cut algorithms.",
                    "label": 0
                },
                {
                    "sent": "What I do is I I represent the problem as a graph and I try to find you know the minimum set the least cost set of edges that I can cut, such that say one side is labeled positive and the other side is labeled negative and we can also use belief propagation.",
                    "label": 0
                },
                {
                    "sent": "In this case a Max product version, because what we're trying to do is find the maximum of a product.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's talk a little bit about learning now.",
                    "label": 0
                },
                {
                    "sent": "So how do we?",
                    "label": 0
                },
                {
                    "sent": "How do we learn these models?",
                    "label": 0
                },
                {
                    "sent": "Well, there's two parts.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There's learning the parameters I either weights and learning the structure.",
                    "label": 0
                },
                {
                    "sent": "I either features the parameters could be learned generatively or discriminatively and we will look at both.",
                    "label": 0
                },
                {
                    "sent": "In this tutorial, I'm going to assume that we have complete data.",
                    "label": 1
                },
                {
                    "sent": "If we don't have complete data, we need to use EM versions of these algorithms and these are available in some of the software that I will be talking about later.",
                    "label": 0
                },
                {
                    "sent": "But in this tutorial for simplicity I'm just going to assume that.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The data is always complete.",
                    "label": 0
                },
                {
                    "sent": "So how do we do generative wake learning?",
                    "label": 0
                },
                {
                    "sent": "Well, you just do the standard you can do, for example maximum likelihood learning or maximum posterior probability learning or full vision learning.",
                    "label": 1
                },
                {
                    "sent": "Just as you could for simpler models.",
                    "label": 0
                },
                {
                    "sent": "The one thing that's not so fortunate about these models is that you cannot find the weights in closed form.",
                    "label": 0
                },
                {
                    "sent": "Unlike same Envision networks, however, it is.",
                    "label": 0
                },
                {
                    "sent": "It's a convex problem, so there's a single global optimum, and you can find it efficiently without fear of falling into local Optima using something like gradient descent.",
                    "label": 0
                },
                {
                    "sent": "In the simplest case, or using a second order technique like Quasi Newton or conjugate gradient methods, all of which are pretty well understood.",
                    "label": 0
                },
                {
                    "sent": "And here's the form of the derivative of the of the log likelihood with respect to await.",
                    "label": 0
                },
                {
                    "sent": "The gradient is just the vector of these.",
                    "label": 0
                },
                {
                    "sent": "It's actually very intuitive and it's the following the derivative of the log likelihood with respect to a weight is the number of times that the corresponding feature is true in the data.",
                    "label": 1
                },
                {
                    "sent": "Minus the expected number of times according to the model.",
                    "label": 0
                },
                {
                    "sent": "So what happens is that if the model predicts that this feature is true less often than it really is, then its weight needs to go up.",
                    "label": 0
                },
                {
                    "sent": "If it predicts that the feature is true more often than it should be, it's weight needs to go down, and once all of these lineup for all the features we've reached our optimum and we're done OK.",
                    "label": 0
                },
                {
                    "sent": "So fairly simple.",
                    "label": 0
                },
                {
                    "sent": "There's one big problem though.",
                    "label": 0
                },
                {
                    "sent": "The big problem is that in order to compute these expected feature counts, I need to do inference.",
                    "label": 0
                },
                {
                    "sent": "An inference, of course, is itself expensive.",
                    "label": 0
                },
                {
                    "sent": "So now I'm looking at doing expensive inference at every step of a gradient descent procedure or or related one which could easily take hundreds of iterations.",
                    "label": 0
                },
                {
                    "sent": "So a lot of the time this is going.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Be too slow and you know people.",
                    "label": 0
                },
                {
                    "sent": "Notice this pretty much right away when they started doing Markov networks in the 70s and the first thing that they came up with was a very clever trick called pseudo likelihood.",
                    "label": 0
                },
                {
                    "sent": "And the idea of this trick is that if your objective function is too hard to optimize, let's optimize a different 11.",
                    "label": 0
                },
                {
                    "sent": "That's easier to optimize, and hope that that doesn't hurt us too much, so pseudo likelihood is just the product.",
                    "label": 0
                },
                {
                    "sent": "For all variables of the probability of each variable given its neighbors in the data.",
                    "label": 1
                },
                {
                    "sent": "So I'm just conditioning on the Markov blanket through the data, so no inference needs to happen.",
                    "label": 0
                },
                {
                    "sent": "This is something that I can compute immediately given the data and so and if I combine this with something like a fast 2nd order inference method, you actually get quite efficient weight learning, and this is widely used in areas like vision, spatial statistics, natural language processing and so forth.",
                    "label": 0
                },
                {
                    "sent": "The disadvantage of this, of course, is that optimizing, so the likelihood is not the same as optimizing likelihood.",
                    "label": 0
                },
                {
                    "sent": "The problem is that if you if at inference time you're going to have long chains of inference, these parameters could give poor results because all that.",
                    "label": 0
                },
                {
                    "sent": "So the likelihood is optimizing is the short range interactions between variables.",
                    "label": 0
                },
                {
                    "sent": "It assumes that the values of your neighbors are correct, and so will tend to overweight them.",
                    "label": 0
                },
                {
                    "sent": "OK, so so so the likelihood can be very fast.",
                    "label": 0
                },
                {
                    "sent": "For some problems it's just fine for.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Problems that can actually pretty bad, so when it's bad, what can you do?",
                    "label": 0
                },
                {
                    "sent": "Well, you can use discriminative learning, and in fact these days in machine learning people pretty much everywhere tend to use discriminative learning over generative just because it tends to give better results.",
                    "label": 0
                },
                {
                    "sent": "And it's also easy to see why it would give better results.",
                    "label": 0
                },
                {
                    "sent": "So the idea in discriminative learning is that if you know at learning time which variables are going to be query variables and let's call those Y and which variables are going to be evidence, let's call those X.",
                    "label": 0
                },
                {
                    "sent": "Then what you can do is instead of optimizing the joint likelihood of X&Y, you can just optimize the conditional likelihood of Y given X.",
                    "label": 0
                },
                {
                    "sent": "And the reason for this is if I'm going to know exit query time, there's no point in trying to model P of X.",
                    "label": 0
                },
                {
                    "sent": "It's just going to be a waste of time at best and at worst it's actually going to produce the worst model because I'm I'm, you know, mixing what I'm trying to optimize with something else that doesn't really matter.",
                    "label": 0
                },
                {
                    "sent": "OK, so discriminative learning often works quite well in our case, what we're going to have is, you know, a we're going to be optimizing something that has pretty much the same form.",
                    "label": 0
                },
                {
                    "sent": "Except now I have X&Y instead of Y&X, and I can ignore all the clicks that only involve.",
                    "label": 0
                },
                {
                    "sent": "Evidence variables.",
                    "label": 0
                },
                {
                    "sent": "And another thing that I can do now though is I have another way of dealing with this hard inference problem here.",
                    "label": 0
                },
                {
                    "sent": "And the way the thing that we can do now is we can approximate the expected counts by the counts in the most likely state of Y given X.",
                    "label": 1
                },
                {
                    "sent": "And this is because often these distributions have modes all over the place.",
                    "label": 0
                },
                {
                    "sent": "But once I've conditioned on enough information, my probability mass often winds up being concentrated around just one solution.",
                    "label": 0
                },
                {
                    "sent": "Right, it's the most likely region of why, given the evidence that I have, and so instead of trying to do that big exponential sum, I just find the most likely state of Y and then do feature counts on those off.",
                    "label": 0
                },
                {
                    "sent": "And I will get pretty much the same result.",
                    "label": 0
                },
                {
                    "sent": "And of course, just finding the most like the state of why is a lot faster than trying to do a sum over all possible states, OK?",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is the basic idea in discriminative learning.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Map estimation is as hard in the worst case.",
                    "label": 0
                },
                {
                    "sent": "In practice, what happens is that you can get a good approximation with map estimation when trying to do you know the full.",
                    "label": 0
                },
                {
                    "sent": "Martial competition will take you too long.",
                    "label": 0
                },
                {
                    "sent": "2nd.",
                    "label": 0
                },
                {
                    "sent": "Well ICM ICM will not work well because it's it's too.",
                    "label": 0
                },
                {
                    "sent": "It's being agreed procedure.",
                    "label": 0
                },
                {
                    "sent": "It's very fast but will tend to sub optimize but you think for example is something like simulated annealing right?",
                    "label": 0
                },
                {
                    "sent": "Or you know to give a more concrete example and an algorithm of this type is is the voted Perceptron?",
                    "label": 0
                },
                {
                    "sent": "What 40% on does is it's for hidden Markov models and it uses the Viterbi algorithm to find the most likely state.",
                    "label": 0
                },
                {
                    "sent": "And then use the counting that most like the state and you know it's a polynomial time algorithm.",
                    "label": 0
                },
                {
                    "sent": "But we don't we we do not compute the marginals, right?",
                    "label": 0
                },
                {
                    "sent": "We just use determined to find the most likely state.",
                    "label": 0
                },
                {
                    "sent": "Sure.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I mean this will show up again later, so yeah.",
                    "label": 0
                },
                {
                    "sent": "So we can approximate the expected counts using them.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "AP State This is one way that you can do discriminative learning.",
                    "label": 0
                },
                {
                    "sent": "There are other weight learning approaches that I think are worth knowing about.",
                    "label": 1
                },
                {
                    "sent": "The oldest one is a generative approach and it's called iterative scaling.",
                    "label": 0
                },
                {
                    "sent": "This was traditionally the approach that was used to learn Markov networks these days.",
                    "label": 0
                },
                {
                    "sent": "It's pretty much fall into disuse because it's so much less efficient than the other alternatives, but you know who knows it might somebody might improve it tomorrow.",
                    "label": 0
                },
                {
                    "sent": "You might make a comeback, another approach which is discriminative and this is the most recent of these.",
                    "label": 1
                },
                {
                    "sent": "Is to do Max margin training.",
                    "label": 0
                },
                {
                    "sent": "You can actually do discriminate.",
                    "label": 0
                },
                {
                    "sent": "In a sense, it's an even more discriminative approach in the sense that it doesn't even care what the probability of Y given X is.",
                    "label": 0
                },
                {
                    "sent": "It just wants to get the right way by some margin.",
                    "label": 0
                },
                {
                    "sent": "So this is just a generalization of support vector machines.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The non ID problem where I have a bunch of labels that depend on each other and this is a very exciting type of approach.",
                    "label": 0
                },
                {
                    "sent": "Again I'm not.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Go into it in detail, but there's been a lot of recent research on it, and it's worth knowing about.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What about structure learning?",
                    "label": 0
                },
                {
                    "sent": "Well, so the problem is structured.",
                    "label": 0
                },
                {
                    "sent": "Learning is we start out with no Markov network and we want to discover what the relevant features are.",
                    "label": 0
                },
                {
                    "sent": "OK, so how might we do that?",
                    "label": 0
                },
                {
                    "sent": "Well, we can use the standard greedy search that you would use for lots of other things.",
                    "label": 0
                },
                {
                    "sent": "We can start with atomic features, meaning the individual variables are the features and then what I can do is I can join features to the current feature.",
                    "label": 1
                },
                {
                    "sent": "I have my current set of features.",
                    "label": 0
                },
                {
                    "sent": "I try conjoining every variable negative and not migrated to each feature and I greatly pick the best one.",
                    "label": 0
                },
                {
                    "sent": "And I use some kind of, you know, likelihood score or posterior score or Carol Divergance and I keep going until I don't get any better results and I stop.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is a fairly straightforward idea.",
                    "label": 0
                },
                {
                    "sent": "There is a big problem which is.",
                    "label": 0
                },
                {
                    "sent": "When I try and you candidate structure, I just modified some feature.",
                    "label": 0
                },
                {
                    "sent": "I now need to relearn the weights in order to be able to compute the likelihood right?",
                    "label": 0
                },
                {
                    "sent": "'cause like the structure is just one part of the model and if I need to compute the weights for every single feature that I try this is, you know that could easily be trying, you know millions.",
                    "label": 0
                },
                {
                    "sent": "My algorithm is never going to finish running, so typically what people do to sidestep this problem is they do an approximation that's actually quite reasonable.",
                    "label": 0
                },
                {
                    "sent": "Which is to say when I modify a certain feature, when I create a new candidate feature.",
                    "label": 0
                },
                {
                    "sent": "I'm going to assume that the weights of all the other features stay constant, and I'm only on got to optimize the weight of this one feature and this in some cases can even be done in closed form, so it's much, much faster.",
                    "label": 0
                },
                {
                    "sent": "What it's compromising, of course.",
                    "label": 0
                },
                {
                    "sent": "Is that in general some of the other features might have to change, and I'm not allowing that to happen, but I can always at the end of each learning step you know, go and relearn all all the weights or or do this at the end so it's not too bad.",
                    "label": 0
                },
                {
                    "sent": "OK, and this makes a big difference to the running time of the structure learning algorithms.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's switch gears and let's talk about things on the logical side first.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Talk a little bit about logical inference, and then we'll talk a little bit about inductive logic programming.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So first let me get some terminology down formulas in first order logic are built out of logical connectives like conjunction, disjunction, quantifiers etc.",
                    "label": 0
                },
                {
                    "sent": "And four types of symbols, constants that represent objects in the domain like sayana variables X, that range over the objects functions like mother of X that take a couple of objects and return an object and predicates like say friends XY that represent relations between objects or properties of them.",
                    "label": 0
                },
                {
                    "sent": "So for example friends XY would represent whether X&Y are friends or not.",
                    "label": 0
                },
                {
                    "sent": "And I'm going to call a literal a predicate or its negation.",
                    "label": 1
                },
                {
                    "sent": "I'm going to call a clause it disjunction of literals.",
                    "label": 0
                },
                {
                    "sent": "And every knowledge base and 1st logic can always be converted into clausal form.",
                    "label": 0
                },
                {
                    "sent": "I'm going to call a grounding of a predicate or formula what you get by replacing all the variables by constants.",
                    "label": 0
                },
                {
                    "sent": "So for example, if one of my predicates is friends XY and two of my constant Saarinen Bob, one possible grounding of friends is friends Anna Bob and Friends, and Bob is just a Boolean variable that is true if an above our friends, and false otherwise.",
                    "label": 0
                },
                {
                    "sent": "And I'm going to call a world also known as model or interpretation and assignment of truth values to all the ground predicates.",
                    "label": 1
                },
                {
                    "sent": "So if I take all the predicates and replace all the constants into them in all possible ways, I get a very large number of Boolean variables and in essence, what we're going to be interested in is truth assignments to these variables, and later we're going to be interested in probability distributions over these assignments.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how do we do inference in first order logic?",
                    "label": 1
                },
                {
                    "sent": "Well, traditionally inference has been done by theorem proving using things like resolution.",
                    "label": 1
                },
                {
                    "sent": "This is for example what Prolog uses.",
                    "label": 0
                },
                {
                    "sent": "However, more recently people have found that if you proposition lies the model, IE you ground out everything in the way I just described, and then you do model checking, this can actually be a lot faster than doing resolution.",
                    "label": 1
                },
                {
                    "sent": "This came as a surprise because you would think that this would be inefficient because it's not lifted.",
                    "label": 0
                },
                {
                    "sent": "It actually turns out then in many domains this is actually very fast.",
                    "label": 1
                },
                {
                    "sent": "And then how do you do model checking while you use the satisfiability solvers, of which there are two main families, backtracking is 1 approach, of which the typical paradigmatic example is the PLL and stochastic local search of which the Praying medic example is walk set and I'm going to go over each of these.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Briefly.",
                    "label": 0
                },
                {
                    "sent": "So first of all, let's define the satisfiability problem more precisely.",
                    "label": 0
                },
                {
                    "sent": "My input is a set of clauses.",
                    "label": 1
                },
                {
                    "sent": "I assume that the knowledge base is converted to have been converted to conjunctive normal form ahead of time.",
                    "label": 0
                },
                {
                    "sent": "Like I said, this can always be done and my output is either the truth assignment that satisfies all the clauses or the answer no, or false if none exists.",
                    "label": 1
                },
                {
                    "sent": "So if the knowledge base is not satisfiable, I want to return failure.",
                    "label": 0
                },
                {
                    "sent": "If it is satisfiable, I want to return an assignment that satisfies all the clauses.",
                    "label": 0
                },
                {
                    "sent": "And this of course, is the paradigmatic NP complete problem.",
                    "label": 0
                },
                {
                    "sent": "So we know there is no efficient solution for it unless P = 2 NP.",
                    "label": 0
                },
                {
                    "sent": "So we have to do search.",
                    "label": 0
                },
                {
                    "sent": "Now the key point to realize about satisfiability testing is that even though in the worst case the problem is exponentially hard, most instances of the problem are actually easy.",
                    "label": 0
                },
                {
                    "sent": "Many satisfiability problems.",
                    "label": 0
                },
                {
                    "sent": "You just take a random solution and it actually satisfies all the clauses already.",
                    "label": 0
                },
                {
                    "sent": "There's actually only a small region of parameter space where the problem is hard.",
                    "label": 0
                },
                {
                    "sent": "What are the relevant parameters?",
                    "label": 0
                },
                {
                    "sent": "The relevant parameters are the number of clauses and the number of variables.",
                    "label": 0
                },
                {
                    "sent": "And the idea is this is that more variables give you more freedom.",
                    "label": 0
                },
                {
                    "sent": "More clauses give you more constraints.",
                    "label": 0
                },
                {
                    "sent": "If I have very few clauses per variable, then the problem is easy to satisfy, and probably there's many solutions because it's under constraint.",
                    "label": 0
                },
                {
                    "sent": "If I have a larger number of clauses per variable, then the problem is hard, it's over constrained, and the chances that I can very quickly discover that the problem is insoluble.",
                    "label": 0
                },
                {
                    "sent": "The hard region is when these have a particular ratio where you really can't tell if you're going to be able to solve the problem or not.",
                    "label": 0
                },
                {
                    "sent": "And then you have to keep putting more and more work into it.",
                    "label": 0
                },
                {
                    "sent": "And you know exactly what this ratio is, depends on the number of problems.",
                    "label": 0
                },
                {
                    "sent": "But for random three set problems it's it's around 4 point something and people are, you know, trying to pin down exactly what that number is.",
                    "label": 0
                },
                {
                    "sent": "So, but the important thing for our purposes is that most satisfiability problems are easy.",
                    "label": 0
                },
                {
                    "sent": "And that's actually going to be a great.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Boon for us.",
                    "label": 0
                },
                {
                    "sent": "OK, so how do we solve satisfiability problems?",
                    "label": 0
                },
                {
                    "sent": "Let's look at the backtracking approaches first.",
                    "label": 0
                },
                {
                    "sent": "The basic idea in the backtracking approaches is very simple is we're just going to assign truth values by depth first search.",
                    "label": 1
                },
                {
                    "sent": "So I start out with no truth values assigned, and then I assign.",
                    "label": 0
                },
                {
                    "sent": "You know one value to one variable and then to another and then to another until I have to backtrack and then you know I keep on doing this, exploring the whole tree until I find the solution.",
                    "label": 0
                },
                {
                    "sent": "Notice that when I assign a value a truthful to a variable, this has one of two effects.",
                    "label": 0
                },
                {
                    "sent": "The false literals are either the Littles that become false by virtue of assigning that variable I either that variable or it's.",
                    "label": 0
                },
                {
                    "sent": "Negation, depending on what level I'm assigning.",
                    "label": 0
                },
                {
                    "sent": "Those essentially disappear.",
                    "label": 0
                },
                {
                    "sent": "Or think of a clause in which the variable appears right if I have made the literal true.",
                    "label": 0
                },
                {
                    "sent": "Now the clause is true.",
                    "label": 0
                },
                {
                    "sent": "Hi yeah, if I've made a little false the little disappears.",
                    "label": 0
                },
                {
                    "sent": "If I've made a little through the cloud disappears.",
                    "label": 0
                },
                {
                    "sent": "So every time that I send a value to the variable I wind up with a similar problem.",
                    "label": 0
                },
                {
                    "sent": "And so as I progress in my search the problem becomes simpler and simpler until one of two things happens.",
                    "label": 0
                },
                {
                    "sent": "Either wind up with an empty set of clauses, which means that I've deleted all of them, so I've succeeded.",
                    "label": 1
                },
                {
                    "sent": "Or I wind up with an empty clause, meaning that I've made all the literals in some clause false.",
                    "label": 0
                },
                {
                    "sent": "Therefore the clause is false and I failed.",
                    "label": 0
                },
                {
                    "sent": "And So what happens when I fail is that I backtrack.",
                    "label": 0
                },
                {
                    "sent": "I undo some assignment that I just made, and I try again and I keep on doing this until I succeed, or until I've exhausted the tree and I returned failure.",
                    "label": 0
                },
                {
                    "sent": "So this is the basic idea.",
                    "label": 1
                },
                {
                    "sent": "There's a couple of additional improvements that we can do that actually make a big difference.",
                    "label": 0
                },
                {
                    "sent": "One of those is what's called unit propagation.",
                    "label": 0
                },
                {
                    "sent": "And the idea of propagation is that if you have a unit clause meaning a class that's just one literal, you know what value that has to have, right.",
                    "label": 0
                },
                {
                    "sent": "If I have the clause, not a, I know that it has to be false.",
                    "label": 0
                },
                {
                    "sent": "Otherwise immediately the problem is not satisfiable.",
                    "label": 0
                },
                {
                    "sent": "OK, so one thing that I can do before I search is I can look for unit clauses and replace them by the obvious value.",
                    "label": 0
                },
                {
                    "sent": "OK, now you might think, well, Gee, how many unique clauses are there going to be in my problem?",
                    "label": 0
                },
                {
                    "sent": "Maybe not many, maybe not many, but the key thing is that as you replace.",
                    "label": 0
                },
                {
                    "sent": "Variables clauses that were Link 3 become length two and then they become length one.",
                    "label": 0
                },
                {
                    "sent": "So unit clauses crop up as a search progresses, so this winds up, you know, giving me enormous time savings.",
                    "label": 0
                },
                {
                    "sent": "The other thing that we can use is what's called pure literals, which is Littles that had just had the same truth value everywhere.",
                    "label": 1
                },
                {
                    "sent": "If a always appears non negative, then I know that you know I lose nothing by signing into value.",
                    "label": 0
                },
                {
                    "sent": "True, and certainly I don't want to send the value false.",
                    "label": 0
                },
                {
                    "sent": "So again, pure literals will appear as the search progress is in the in the CNF get simplified and.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It will buy me a lot of time savings, so here's the famous DPL algorithm.",
                    "label": 0
                },
                {
                    "sent": "DPL is short for the names of the people who developed it.",
                    "label": 0
                },
                {
                    "sent": "Davis, Putman, Lodgment in Loveland.",
                    "label": 0
                },
                {
                    "sent": "And the way it works is just this follows.",
                    "label": 0
                },
                {
                    "sent": "It's a recursive procedure.",
                    "label": 0
                },
                {
                    "sent": "If your CNF is empty, that means we've deleted all the clauses.",
                    "label": 0
                },
                {
                    "sent": "I return true.",
                    "label": 0
                },
                {
                    "sent": "Else if the CNF contains an empty clause, then I failed.",
                    "label": 1
                },
                {
                    "sent": "I return false else if it contains a pure literal I, I called the PLL again with the literal replaced by the necessary value, else if it contains a unit clause, I again just called the PLL with the unit clauses you know value with literal replaced by the by the necessary value, otherwise.",
                    "label": 1
                },
                {
                    "sent": "I choose some variable.",
                    "label": 0
                },
                {
                    "sent": "There appears in the CN F and you know choosing which variable is a heuristic process, but one that is quite important and then and then.",
                    "label": 0
                },
                {
                    "sent": "Here's what I do.",
                    "label": 0
                },
                {
                    "sent": "Is I called EPL recursively with that variable, replace the true, and if that succeeds then I'm done.",
                    "label": 0
                },
                {
                    "sent": "Otherwise I call it with the value of the variable set to false.",
                    "label": 0
                },
                {
                    "sent": "So this is where things branch up, and this is the DPL algorithm.",
                    "label": 0
                },
                {
                    "sent": "It can solve a lot of satisfied with problems very fast.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Not nearly as fast as stochastic local search for a lot of problems, so there's many problems.",
                    "label": 0
                },
                {
                    "sent": "Like for example, you know something as simple as in Queens, or the PLL is quite slow and stochastic.",
                    "label": 0
                },
                {
                    "sent": "Local search is just blindingly fast.",
                    "label": 0
                },
                {
                    "sent": "So how does stochastic local search work?",
                    "label": 0
                },
                {
                    "sent": "It's the more recent of these types of methods, but it's the one that's close to the largest problems in stochastic local search.",
                    "label": 0
                },
                {
                    "sent": "What I have at each point in the search is a complete assignment of values to the variables, so backtracking works with partial assignments.",
                    "label": 0
                },
                {
                    "sent": "Stochastic local search works with complete assignments and then what do I do?",
                    "label": 1
                },
                {
                    "sent": "Is we just start with a random state and then we repeatedly flip a variable in some unsatisfied clause, right?",
                    "label": 0
                },
                {
                    "sent": "There's no point in flipping variables in satisfied clauses, at least heuristically, so we randomly can unsatisfied clause and flip a variable in it that will cause that class to be satisfied.",
                    "label": 0
                },
                {
                    "sent": "And now this can be done in two modes.",
                    "label": 0
                },
                {
                    "sent": "One is Hill climbing.",
                    "label": 0
                },
                {
                    "sent": "So I try flipping each of the variables in the clause and I choose the one that maximizes the total number of satisfied clauses.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is just standard greedy search to try and solve as many classes as possible or in order to avoid getting trapped in local minima.",
                    "label": 0
                },
                {
                    "sent": "I can I can do a random flip, meaning that I just pick one of the variables at random, and I flip that OK, and then I just do this for some fixed number of steps.",
                    "label": 0
                },
                {
                    "sent": "I actually don't stop when I reach a local.",
                    "label": 0
                },
                {
                    "sent": "Often this is very important.",
                    "label": 0
                },
                {
                    "sent": "I keep going.",
                    "label": 0
                },
                {
                    "sent": "You know, I could cross spend a long time just crossing a plateau.",
                    "label": 0
                },
                {
                    "sent": "And then things might start improving again and I restart the whole procedure some number of times.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Very simple, the standard algorithm that does this is called walks at.",
                    "label": 0
                },
                {
                    "sent": "So here's walk said I do this for one to Max tries start with a random solution and then do this for Max flips.",
                    "label": 0
                },
                {
                    "sent": "If all the clouds are satisfied.",
                    "label": 1
                },
                {
                    "sent": "I returned the solution.",
                    "label": 0
                },
                {
                    "sent": "Otherwise I pick a random clause with probability Pi, flip a random variable.",
                    "label": 1
                },
                {
                    "sent": "Otherwise I flip available that maximizes the number of satisfied clauses.",
                    "label": 0
                },
                {
                    "sent": "And obviously this P is going to control how greedy versus how random my searches.",
                    "label": 0
                },
                {
                    "sent": "And if at the end of this I haven't found a solution.",
                    "label": 0
                },
                {
                    "sent": "I returned failure and in fact this is the main limitation of stochastic local search algorithms.",
                    "label": 0
                },
                {
                    "sent": "Is that if they return the solution then you know that that's a solution.",
                    "label": 0
                },
                {
                    "sent": "If they returned failure, you never know for sure whether there was a solution, but it just wasn't found.",
                    "label": 0
                },
                {
                    "sent": "OK, so the main advantage of the PLL is that it can tell you for sure whether it's success or failure.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so let's talk a little bit about learning logical models now.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And this of course, is the field of inductive logic programming.",
                    "label": 0
                },
                {
                    "sent": "The best way to introduce is probably to start with propositional rule induction, so inducing rules on just standard ID examples that are vectors of attributes, and I'm going to assume that they're all boolean for simplicity, so standard classification setting.",
                    "label": 0
                },
                {
                    "sent": "I have a set of positive and negative examples of some concept.",
                    "label": 1
                },
                {
                    "sent": "Each example is a vector of Boolean attributes X one to XN, and the class Y, and the goal is to induce rules that cover all the positive examples and none of the negative ones.",
                    "label": 0
                },
                {
                    "sent": "So the rule is it is something like a conjunction of literals implies the class.",
                    "label": 0
                },
                {
                    "sent": "This is the same as a horn clause where this is the body and the class is the head.",
                    "label": 0
                },
                {
                    "sent": "And I will say that it will covers an example if and only if the example satisfies the body of the rule, IE it meets all the conditions on the Aetna students that I put here, and I'm going to assume that I have some kind of evaluation function like accuracy, information gain, coverage, support or combinations of them to guide my search.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then the way rule induction works is that I learn one ruler or one basic algorithm is I learned a single rule in the following way.",
                    "label": 1
                },
                {
                    "sent": "I started out with the class being the head and an empty body.",
                    "label": 0
                },
                {
                    "sent": "And then what I do is I try conjoining each little to the body.",
                    "label": 0
                },
                {
                    "sent": "I evaluate the rule with the new body and then I pick the best literal i.e conjoined to the body.",
                    "label": 1
                },
                {
                    "sent": "The little that most increases my evaluation function and I keep on doing this until no literal improves my evaluation function and I returned that rule.",
                    "label": 0
                },
                {
                    "sent": "OK, so this returns one rule to me that hopefully covers a lot of positive examples and known.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Negative ones, this goes inside a loop where I learn a set of rules.",
                    "label": 1
                },
                {
                    "sent": "So what I do in that loop is I start out with an empty rule set and the set S. That's all my examples.",
                    "label": 0
                },
                {
                    "sent": "Then I repeat the following.",
                    "label": 1
                },
                {
                    "sent": "I learned a single rule in the way that I just described.",
                    "label": 0
                },
                {
                    "sent": "I add it to my set of rules and I removed from the training set S all the positive examples that were covered by the rule, so they covered.",
                    "label": 0
                },
                {
                    "sent": "I can now ignore them.",
                    "label": 0
                },
                {
                    "sent": "They taken care of and now induced another rule to cover as many of the remaining examples as possible, and we keep going until I have no examples uncovered.",
                    "label": 0
                },
                {
                    "sent": "OK, and then I return the set of rules that I've found so in that.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If logic programming, or at least the most basic type of inductive logic programming algorithm is really just this idea, it's the same structure.",
                    "label": 0
                },
                {
                    "sent": "But then at the level of 1st order.",
                    "label": 0
                },
                {
                    "sent": "So what happens when we go to 1st order is that instead of.",
                    "label": 0
                },
                {
                    "sent": "Just attributes just pulling attributes.",
                    "label": 0
                },
                {
                    "sent": "What I now have are predicates with arguments.",
                    "label": 1
                },
                {
                    "sent": "And same with the class.",
                    "label": 0
                },
                {
                    "sent": "So now for example, my class could be something like ancestor XY, meaning X is an ancestor of Y, and you know a predicate could be something like parent XY, meaning X is a parent of Y. OK, so I'm still going to build rules as before, except I'm going to do it in a richer language now.",
                    "label": 0
                },
                {
                    "sent": "Specifically, I'm going to do in the language of 1st order logic.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to what I'm going to do is.",
                    "label": 0
                },
                {
                    "sent": "I'm going to add literals to a rule one at a time to try and build a better rule, and then I'm going to try to build.",
                    "label": 0
                },
                {
                    "sent": "You know, many rules that cover all my positive instances of, for example, this predicate.",
                    "label": 0
                },
                {
                    "sent": "We are going to have one restriction, which I think makes a lot of sense, which is when when I add a literal it now has variables.",
                    "label": 1
                },
                {
                    "sent": "Right, this is something we didn't have the propositional case and I'm going to require that than you literal contain at least one variable that already appears in the rule.",
                    "label": 0
                },
                {
                    "sent": "And the reason is that if it doesn't, then it's not going to really say anything about.",
                    "label": 0
                },
                {
                    "sent": "You know what I'm interested in, so it's going to be pointless.",
                    "label": 0
                },
                {
                    "sent": "OK, so I'm going to make that requirement, and then what I'm going to do is essentially the same as before.",
                    "label": 0
                },
                {
                    "sent": "I'm going to try conjoining all possible levels to the rule subject to this restriction and I'm going to evaluate them according to some evaluation function and I'm going to pick the best one and I'm going to keep going until I get no further benefits.",
                    "label": 0
                },
                {
                    "sent": "Now there's another important change that happens when we go to 1st order, which is that adding a literal changes the number of groundings of the rule.",
                    "label": 1
                },
                {
                    "sent": "In the propositional case, the universe of examples that I'm talking about is always the same.",
                    "label": 0
                },
                {
                    "sent": "Here, for example, when suppose that I started out with insects or XY, right?",
                    "label": 0
                },
                {
                    "sent": "So my universe of examples.",
                    "label": 0
                },
                {
                    "sent": "Here's the sets of all pairs of people, right?",
                    "label": 0
                },
                {
                    "sent": "If there's Anna, Bob and Charles, then you know there's Anna Anna, Anna, Bobana, Charles, etc.",
                    "label": 0
                },
                {
                    "sent": "But if I now add an antecedent like Consister, XZ, notice it satisfies the restriction I just imposed, right?",
                    "label": 0
                },
                {
                    "sent": "I have?",
                    "label": 0
                },
                {
                    "sent": "Or?",
                    "label": 0
                },
                {
                    "sent": "Let's do parents see why?",
                    "label": 0
                },
                {
                    "sent": "Which is more meaningful, right?",
                    "label": 0
                },
                {
                    "sent": "It shares why, but it doesn't share Z.",
                    "label": 0
                },
                {
                    "sent": "So now this rule has three variables, XY and Z.",
                    "label": 0
                },
                {
                    "sent": "So now my universe.",
                    "label": 0
                },
                {
                    "sent": "Is actually the set of all triples of examples.",
                    "label": 0
                },
                {
                    "sent": "And if we're not careful about this, we could fool ourselves into into thinking that we're doing really well, because we're just creating positive examples all over the place.",
                    "label": 1
                },
                {
                    "sent": "But the rule isn't really very good, so I need to in some way compensate for that effect.",
                    "label": 0
                },
                {
                    "sent": "One heuristic way in which we can do that is to multiply my evaluation function by the number of positive groundings of the original rule that are still covered.",
                    "label": 0
                },
                {
                    "sent": "After I've added the new little, because are the ones those are the ones that I care about, so this is just a heuristic, but it can work pretty well.",
                    "label": 0
                },
                {
                    "sent": "And there's, you know many other things that you.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Can do.",
                    "label": 0
                },
                {
                    "sent": "And of course a huge spectrum of other LP algorithms.",
                    "label": 0
                },
                {
                    "sent": "This will just give.",
                    "label": 0
                },
                {
                    "sent": "That concludes our brief survey of the foundational areas of statistical initial learning.",
                    "label": 1
                },
                {
                    "sent": "Even with just this, little much that we've learned of all the pieces we can put together, pretty effective as statistical relational learning algorithms.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So as I said, this is a very active research area and there's a very large number of approaches that have been proposed in recent years.",
                    "label": 0
                },
                {
                    "sent": "Here are some of them, in chronological order, knowledge based model construction is the earliest one.",
                    "label": 0
                },
                {
                    "sent": "There's also stochastic logic programs, probabilistic relational models, relational Markov networks, vision logic, Markov logic, and many, many others.",
                    "label": 1
                },
                {
                    "sent": "So this is really only a small sample of some of the approaches that people have proposed.",
                    "label": 0
                },
                {
                    "sent": "What I'm going to do next is I'm going to very briefly take these as concrete examples and just give you a basic idea of how they do this thing of combining logic and probability, yeah?",
                    "label": 0
                },
                {
                    "sent": "Super.",
                    "label": 0
                },
                {
                    "sent": "Yes, you can do and supervise the LP in the following sense you can discover Association rules in LP, right?",
                    "label": 0
                },
                {
                    "sent": "So what I would just describe was IRP for classification.",
                    "label": 0
                },
                {
                    "sent": "In some sense you have this one predicate that you're trying to predict their RP algorithms, like for example codeine that just discover any clauses that hold.",
                    "label": 0
                },
                {
                    "sent": "So you could think of this as unsupervised learning in a sense that you know you just model.",
                    "label": 0
                },
                {
                    "sent": "It's the equivalent of modeling the joint distribution of a set of variables without having a designated class variable.",
                    "label": 0
                },
                {
                    "sent": "And you know more generally, if you take any machine learning task that you can imagine there is an IOP version of that.",
                    "label": 0
                },
                {
                    "sent": "That is, IOP.",
                    "label": 0
                },
                {
                    "sent": "You know, reinforcement learning.",
                    "label": 0
                },
                {
                    "sent": "There's IO P regression, there's LP whatever.",
                    "label": 0
                },
                {
                    "sent": "You're still solving the same problem, except that now you're taking relations between objects into account and therefore you have predicates and so forth.",
                    "label": 0
                },
                {
                    "sent": "So again, what I gave you was just really, you know, a very basic flavor of the field.",
                    "label": 0
                },
                {
                    "sent": "OK, so let me give you a brief survey of some of these.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Roaches, there are some of the better known approaches, so I think it will give you a fair picture of the field.",
                    "label": 0
                },
                {
                    "sent": "Before I go into each one of them in detail, though, here's here's the key thing is, there's dozens of these, maybe hundreds, and every year there are more, however, so if you try to keep track of all of them, you know it's a losing game.",
                    "label": 0
                },
                {
                    "sent": "The important thing to realize, though, is that there's a number of key dimensions.",
                    "label": 0
                },
                {
                    "sent": "Along which these approaches fall, and really what's important to understand is those dimensions, because then when a new approach comes along, you immediately know how it fits into you.",
                    "label": 0
                },
                {
                    "sent": "Know the big picture.",
                    "label": 0
                },
                {
                    "sent": "And then you know how to you know you know the right way to look at it.",
                    "label": 0
                },
                {
                    "sent": "Instead of an exponential number of approaches, we just have a linear number of dimensions to look at which which is an exponential gain.",
                    "label": 0
                },
                {
                    "sent": "So what are the key dimensions one of them is the logical language that the approach uses, so we could, for example, use first order logic.",
                    "label": 1
                },
                {
                    "sent": "In some sense, it's the most powerful option.",
                    "label": 0
                },
                {
                    "sent": "Or you could use something more restricted like horn clauses, very popular approach or something like frame systems.",
                    "label": 1
                },
                {
                    "sent": "So this is one dimension and the other another dimension is the probabilistic language that you use.",
                    "label": 0
                },
                {
                    "sent": "So you could do something like vision networks, Markov networks like we just saw, you could use something like for example probabilistic context free grammars, or you know some more limited languages like say, you know Naive Bayes, which is a special case of Bayes Nets and so forth.",
                    "label": 0
                },
                {
                    "sent": "Another dimension is the type of learning that you can do in this approach.",
                    "label": 1
                },
                {
                    "sent": "So there's generative versus discriminative like we've just seen you constructor parameters.",
                    "label": 0
                },
                {
                    "sent": "You could have knowledge rich or knowledge for learning.",
                    "label": 0
                },
                {
                    "sent": "In principle you could do any of these types of learning with any approach.",
                    "label": 0
                },
                {
                    "sent": "In practice, they're not always available.",
                    "label": 0
                },
                {
                    "sent": "Sometimes there's no particular reason for that.",
                    "label": 0
                },
                {
                    "sent": "Sometimes there is a good reason, and then there's also the type of inference that you do, so you can do me P versus marginal inference as we just saw another important dimension along, which is approach is very is.",
                    "label": 0
                },
                {
                    "sent": "How do you handle grounding?",
                    "label": 0
                },
                {
                    "sent": "You could ground out.",
                    "label": 0
                },
                {
                    "sent": "Everything fully you could ground out things partially.",
                    "label": 0
                },
                {
                    "sent": "That's actually the key idea.",
                    "label": 0
                },
                {
                    "sent": "Knowledge base model construction.",
                    "label": 0
                },
                {
                    "sent": "Or you could even do lifted inference, so again.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is another important dimension to think about, so let's start with the earliest example, which is knowledge based model construction and actually encompasses quite a variety of approaches.",
                    "label": 0
                },
                {
                    "sent": "Here the logical languages, horn clauses and the probabilistic languages Bayes Nets.",
                    "label": 1
                },
                {
                    "sent": "And the basic idea on how to combine logic and probability.",
                    "label": 0
                },
                {
                    "sent": "Here is the following.",
                    "label": 0
                },
                {
                    "sent": "Every ground atoms, so I have a first order world so I have relations.",
                    "label": 0
                },
                {
                    "sent": "I have predicates, I have objects etc and I can construct ground atoms in the way that we just saw every possible ground Atom is going to be a positive potential node in my vision network.",
                    "label": 0
                },
                {
                    "sent": "So I have a vision network over Boolean variables, each one of which is around that time, like say friends Anna, Bob OK and then what's going to happen is that I'm going to construct a vision network from my first order knowledge base.",
                    "label": 0
                },
                {
                    "sent": "That's what this is called knowledge based model construction.",
                    "label": 0
                },
                {
                    "sent": "Knowledge based is the horn knowledge base, and the model is the vision network and the way I'm going to construct the vision network is the following.",
                    "label": 0
                },
                {
                    "sent": "The head of the clause is going to be the child.",
                    "label": 0
                },
                {
                    "sent": "Note the body of the clause is going to be the parent notes OK, and now if I have and now if I have more than one clause with the same head.",
                    "label": 0
                },
                {
                    "sent": "I need some kind of combination function.",
                    "label": 0
                },
                {
                    "sent": "To combine the predictions from the various clauses.",
                    "label": 0
                },
                {
                    "sent": "OK, so all the atoms in all the clauses that have this as their head are going to be parents of the node, right?",
                    "label": 0
                },
                {
                    "sent": "Each clause is a is a deterministic conjunction.",
                    "label": 0
                },
                {
                    "sent": "And now what I need is some kind of way to combine what the different causes said and this combination function can be something like logistic regression or noisy or noisy.",
                    "label": 0
                },
                {
                    "sent": "Or is the most commonly used one.",
                    "label": 0
                },
                {
                    "sent": "It basically says that the child is true.",
                    "label": 0
                },
                {
                    "sent": "If one of the rules says it's true.",
                    "label": 0
                },
                {
                    "sent": "But but there's a failure probability for each one of them, and there's also often some probability that it might be true even if all of the parent clauses fail.",
                    "label": 0
                },
                {
                    "sent": "And So what happens is that when I have a query.",
                    "label": 0
                },
                {
                    "sent": "What I do is I do partial grounding, meaning I construct just the network that I need to answer the question, which is basically going to be composed of the prologue, proof trees of the query node or nodes and all the evidence nodes.",
                    "label": 0
                },
                {
                    "sent": "You can prove that a network containing those has all the information that you need to assign the right probability, IE you will give you the same answer as if you had formed the whole network with all the possible nodes.",
                    "label": 0
                },
                {
                    "sent": "And of course a lot of the time it's going to be much, much smaller.",
                    "label": 0
                },
                {
                    "sent": "OK, so we do grounding basically by doing all Prolog proofs and then we can do something like belief propagation over these networks.",
                    "label": 0
                },
                {
                    "sent": "Or it could be another probabilistic inference method.",
                    "label": 0
                },
                {
                    "sent": "But at this point I just have a vision network so I can use anything, belief propagation, MCMC etc.",
                    "label": 0
                },
                {
                    "sent": "So to Linda structure of these networks we can use I LP right you can you could learn a model like this just by running any LP system and taking its output and saying it's the model.",
                    "label": 0
                },
                {
                    "sent": "Now of course you also need to learn the parameters.",
                    "label": 0
                },
                {
                    "sent": "Tylenda parameters often use something like EM, and the reason you something like him is that typically you will not have observed a lot of the intermediate predicates in your inference.",
                    "label": 0
                },
                {
                    "sent": "If you've heard everything you can do it in closed form.",
                    "label": 0
                },
                {
                    "sent": "Otherwise you need to do something like EM.",
                    "label": 0
                },
                {
                    "sent": "Typically what people do in knowledge base also searches that they first learn the clauses using pure IO P and then they learn just the parameters using M, which is actually not quite the right thing to do if you think about it, you would actually like to learn at each point be learning the clauses using.",
                    "label": 0
                },
                {
                    "sent": "Your ultimate likelihood objective function, so that's not.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Base model construction.",
                    "label": 0
                },
                {
                    "sent": "All distant, probably most varied family of these approaches.",
                    "label": 0
                },
                {
                    "sent": "Here's another one stochastic logic programs here.",
                    "label": 1
                },
                {
                    "sent": "The logical languages, again, horn clauses.",
                    "label": 0
                },
                {
                    "sent": "The probabilistic languages, now probabilistic context free grammars in fact.",
                    "label": 0
                },
                {
                    "sent": "Stochastic logic programs can just be seen as lifting PCF's to the 1st order level by turning production rules into horn clauses.",
                    "label": 1
                },
                {
                    "sent": "So here's what we do is, we take a prolog program and we just attach a probability to each clause, with the restriction that the sum of the probabilities of the clauses with the same head has to be one.",
                    "label": 0
                },
                {
                    "sent": "And the semantics of this is that that head is produced as one of its bodies.",
                    "label": 0
                },
                {
                    "sent": "We just don't know which.",
                    "label": 0
                },
                {
                    "sent": "But we have a probability distribution over them.",
                    "label": 0
                },
                {
                    "sent": "OK, So what an SLP really gives you is a probability distribution of a prologue.",
                    "label": 0
                },
                {
                    "sent": "Proof trees.",
                    "label": 0
                },
                {
                    "sent": "So if then you want to do inference, then what you have to do is you have to look at the proof tag of whatever query item you have.",
                    "label": 1
                },
                {
                    "sent": "You essentially have to do all proofs, but Prolog can do this for you.",
                    "label": 0
                },
                {
                    "sent": "What has to happen now is that you need to keep track of the probabilities, meaning as you go down a tree you need to multiply the probabilities.",
                    "label": 0
                },
                {
                    "sent": "And then you need to add the probabilities of all of all the trees and this will give you the probability of your query Atom again to do learning we can use IO P to the structure.",
                    "label": 0
                },
                {
                    "sent": "Learning to do learn parameters, we can learn them with with with a small wrinkle, which is the M needs to be what's called failure adjusted.",
                    "label": 0
                },
                {
                    "sent": "What I mean by fully adjusted?",
                    "label": 0
                },
                {
                    "sent": "Not all proofs succeed.",
                    "label": 0
                },
                {
                    "sent": "Right, but some of the proofs that don't succeed by this scheme also have some probability.",
                    "label": 0
                },
                {
                    "sent": "So what I need to do is that I need to renormalize the partition function in SLPS is not one unlike Envision Networks, so I need to adjust my email with them to take that into account.",
                    "label": 0
                },
                {
                    "sent": "I need to normalize to subtract out the probability mass of the proofs that fail.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here's another one probabilistic relational models.",
                    "label": 1
                },
                {
                    "sent": "Alot of work was done in this over the last several years.",
                    "label": 0
                },
                {
                    "sent": "Here the logical languages frame systems, IE you have classes of objects, and for each class of object you have a Canonical description of the object, meaning the attributes of the objects of that class and the relations of the objects of that class to other classes.",
                    "label": 1
                },
                {
                    "sent": "The probabilistic language is once again vision networks, and the idea here is that we're going to have a frame system where for each class.",
                    "label": 0
                },
                {
                    "sent": "We have a vision network that describes the joint distribution of the attributes of that of the objects of that class and now this is a relational model because the attributes of an object, in addition to depending in an attribute of an object in addition to being able to depend on other attributes of the same object, as in as in ordinary statistical learning, it can also depend on attributes of related objects of either the same class or other classes.",
                    "label": 0
                },
                {
                    "sent": "Now the restriction that is implicit in frame systems is that, as in the logical case, we only have binary relations.",
                    "label": 1
                },
                {
                    "sent": "So in PRMS you don't have relations of arbitrary Arity, and another restriction that is at least currently the case in PRMS is that you can't actually represent dependencies of relations on relations.",
                    "label": 0
                },
                {
                    "sent": "You can represent dependencies of relations on attributes of jobs that they relate, but not things like, for example friends of friends or friends.",
                    "label": 0
                },
                {
                    "sent": "So one nice thing about PRMS is that you can learn parameters in closed form.",
                    "label": 0
                },
                {
                    "sent": "So a PRM is at some level just the vision network, so learning if there is this complete just decomposes into a separate problem for each variable, and so I can compute the parameters in the usual way in closed form if there is missing data, which is often the case, then I need to use EM.",
                    "label": 0
                },
                {
                    "sent": "How do we?",
                    "label": 0
                },
                {
                    "sent": "How do we learn structure the way structure is learning PRMS is analogous to the weights learning vision networks where you try adding, removing and reversing links, with the difference being that it's done in a tiered way.",
                    "label": 0
                },
                {
                    "sent": "So what we do is in order to not get lost in a very large search space of things that you know any attribute could depend on is first we look for dependencies of an attribute on other attributes of the same object.",
                    "label": 0
                },
                {
                    "sent": "And then for attributes of objects that that objects related to and then and so on.",
                    "label": 0
                },
                {
                    "sent": "OK, so if you think of the length of the chain of relations between an object and another first, I looked at lengths of chain zero and lenses chain one change chain links, chains of length two, etc.",
                    "label": 0
                },
                {
                    "sent": "And for inference PRMS fully ground out the network and then they do belief propagation, but it would be straightforward to only do partial grounding.",
                    "label": 0
                },
                {
                    "sent": "I think in the same way that K. BMC does.",
                    "label": 0
                },
                {
                    "sent": "And to use MCMC or something else for the info.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's a more recent approach.",
                    "label": 0
                },
                {
                    "sent": "Relational Markov networks in relational Markov networks.",
                    "label": 1
                },
                {
                    "sent": "The logical languages, SQL queries, and in particular the simplest kind of SQL queries which are just conjunctive queries.",
                    "label": 0
                },
                {
                    "sent": "Or, you know, if you're familiar with Datalog, you could think of this as being Datalog queries and the probabilistic language is Markov networks.",
                    "label": 0
                },
                {
                    "sent": "And the way it works is that your SQL queries define the clicks.",
                    "label": 0
                },
                {
                    "sent": "So I have a database.",
                    "label": 0
                },
                {
                    "sent": "I apply my SQL query to the database and the two poles that this query returns are going to be the nodes in a click.",
                    "label": 0
                },
                {
                    "sent": "So each answer you know.",
                    "label": 0
                },
                {
                    "sent": "So each query is going to have a relation which is a set of tuples.",
                    "label": 0
                },
                {
                    "sent": "Those are going to be my clicks and then I have a potential function for each query.",
                    "label": 1
                },
                {
                    "sent": "Meaning that, for instance, each instance of the query I'm going to have another instance of that potential function.",
                    "label": 0
                },
                {
                    "sent": "Notice that in this case I'm not so at least to date no uncertainty of relations is allowed, so I used the relations in my SQL query.",
                    "label": 0
                },
                {
                    "sent": "When I'm defining the clicks.",
                    "label": 0
                },
                {
                    "sent": "But then those clicks are only over ordinary attributes of the objects.",
                    "label": 0
                },
                {
                    "sent": "Like for example, I could use the links between web pages to create the click that involves a page and a page that points to.",
                    "label": 0
                },
                {
                    "sent": "But then the model is only over, say, the class.",
                    "label": 0
                },
                {
                    "sent": "The classes of those pages and maybe the words that appear in them.",
                    "label": 0
                },
                {
                    "sent": "So how do we do learning here?",
                    "label": 0
                },
                {
                    "sent": "Learning is done discriminatively.",
                    "label": 0
                },
                {
                    "sent": "In the way similar to what I described earlier again today, there are no structure learning algorithms for this approach, and then inference is done by full grounding and belief propagation.",
                    "label": 0
                },
                {
                    "sent": "Although again, you can imagine doing partial grounding and and using other probabilistic inference methods.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Vision logic we're getting towards.",
                    "label": 0
                },
                {
                    "sent": "The more the very recent approaches now in Basel logic, the language is it has its own syntax.",
                    "label": 0
                },
                {
                    "sent": "It's A kind of an imperative programming language that tells you how to, how to build a relational world, but the semantics is at the level of 1st order logic.",
                    "label": 1
                },
                {
                    "sent": "The probabilistic language is once again vision networks, so at the end of the day, what vision logic does is it builds based networks, so the programming oranges called blog, which is sort revision logic.",
                    "label": 0
                },
                {
                    "sent": "And it's it's it's.",
                    "label": 0
                },
                {
                    "sent": "It's the idea of a generative model taken to the relational level.",
                    "label": 0
                },
                {
                    "sent": "So it it tells you a sequence of steps by which you build additional work.",
                    "label": 0
                },
                {
                    "sent": "First generate this set of objects or the number of objects using some distribution and then generate the properties of each of that using this distribution.",
                    "label": 0
                },
                {
                    "sent": "If something if something else is another distribution, and so on until we've built potentially a very complicated world.",
                    "label": 0
                },
                {
                    "sent": "The blog language itself does not say how the parameters should be set.",
                    "label": 1
                },
                {
                    "sent": "It assumes that you've defined them separately in a Java function or some other external source.",
                    "label": 0
                },
                {
                    "sent": "Possibly some library that somebody has created.",
                    "label": 0
                },
                {
                    "sent": "Now the important feature of vision Logic is that unlike all the all the representations that we've seen so far, where you assume that all the audit senior domain are known in advance.",
                    "label": 0
                },
                {
                    "sent": "And if you think about it, often this is not the case.",
                    "label": 1
                },
                {
                    "sent": "I don't know what all the objects are or I have some noisy observations that might or might not be some objects or be the same object as each other version.",
                    "label": 0
                },
                {
                    "sent": "Logic is a language that was basically designed from the ground up to allow unknown objects.",
                    "label": 0
                },
                {
                    "sent": "So I can predict objects that I haven't seen.",
                    "label": 0
                },
                {
                    "sent": "I can predict that two different things, for example two blips on a radar, our observations of the same objects.",
                    "label": 0
                },
                {
                    "sent": "In this case an airplane.",
                    "label": 1
                },
                {
                    "sent": "One big problem in Vision Logic, which was already a problem in things like probably conditional models, but it's bigger here because the language is more powerful is that you could write a block program that creates a vision network with directed cycles.",
                    "label": 0
                },
                {
                    "sent": "And of course, that's not a meaningful probability distribution.",
                    "label": 0
                },
                {
                    "sent": "And what happens if you run blog inference algorithms on such a network is that it will.",
                    "label": 1
                },
                {
                    "sent": "It may not finish running, it could just go on forever.",
                    "label": 0
                },
                {
                    "sent": "And unfortunately, checking whether a block program allows you know will have an instance that's a vision network with cycles is an intractable problem.",
                    "label": 0
                },
                {
                    "sent": "So currently in the current implementation, this is just not checked, so you have to hope that you're lucky and you haven't created a model that's going to have cycles.",
                    "label": 0
                },
                {
                    "sent": "So in terms of learning to date, no learning algorithms have been proposed for vision logic for inference.",
                    "label": 0
                },
                {
                    "sent": "There's been a series of algorithms proposed of which the most advanced one is a form of Markov chain Monte Carlo that requires the user to supply a proposal distribution for the domain that they're using.",
                    "label": 0
                },
                {
                    "sent": "And you know, even then, it's still not very fast.",
                    "label": 0
                },
                {
                    "sent": "This has a very big disadvantage, which is that of course most users don't know how the heck to specify proposal distribution, even you know those of us with PHD's machine learning, often don't know how to do that.",
                    "label": 0
                },
                {
                    "sent": "It it also another advantage of inference in invasion logic is that it does partial grounding in a clever way such that you could actually have an infinite model as long as once you've conditioned on the evidence that you have, the model is finite, everything actually still works through, so they call that contingent vision networks because the vision network has to be finite contingent on the evidence that you've seen.",
                    "label": 0
                },
                {
                    "sent": "Finally, Markov logic is.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The language where the logical language is first order logic and the probabilistic languages Markov networks.",
                    "label": 0
                },
                {
                    "sent": "The syntax is very simple, it's just first order formulas with weights.",
                    "label": 0
                },
                {
                    "sent": "So you take take for starter logic, attach away to each formula, and that's a Markov logic network.",
                    "label": 0
                },
                {
                    "sent": "The semantics is the following.",
                    "label": 0
                },
                {
                    "sent": "A formula in first order formula with the weight is treated as a template for constructing features of a Markov network.",
                    "label": 0
                },
                {
                    "sent": "So each grounding of the formula is going to become a feature in the Markov network and the weight of that feature is going to be the weight of the formula that gave rise to it.",
                    "label": 0
                },
                {
                    "sent": "So learning algorithms for Markov logic parameters can be learned.",
                    "label": 1
                },
                {
                    "sent": "Generatively are discriminatively structure is learned by using LP with with arbitrary clauses.",
                    "label": 0
                },
                {
                    "sent": "So not just one clauses and you know with Nmap score to guide the learning.",
                    "label": 0
                },
                {
                    "sent": "MVP inference is done by weighted satisfiability testing.",
                    "label": 0
                },
                {
                    "sent": "Marginal inference is then by Markov chain Monte Carlo with the moves proposed by by set solver and you know some some clever way that make sure you know the.",
                    "label": 0
                },
                {
                    "sent": "You have a meaningful distribution at the end, and there's two ways in which things are made more efficient.",
                    "label": 0
                },
                {
                    "sent": "One is partial grounding as before, another one is this idea of raising inference, where there's many very.",
                    "label": 0
                },
                {
                    "sent": "You know, you assume that atoms are false unless you explicitly say that they true, and you assume that clauses are satisfied unless you explicitly said that there and satisfied.",
                    "label": 0
                },
                {
                    "sent": "So this is only half a dozen as I said.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There are many more.",
                    "label": 0
                },
                {
                    "sent": "So what we're going to do here is we're going to focus on Markov logic for the rest of the tutorial for a couple of reasons.",
                    "label": 0
                },
                {
                    "sent": "One is that to date it's the most developed approach in terms of the number, and you know, scalability and so forth and variety of the learning and inference algorithms that are developed for it.",
                    "label": 0
                },
                {
                    "sent": "Another nice thing is that 'cause it has a very general logical language, namely 1st order logic and a very general probabilistic one, namely logging in models, many of the other approaches can be.",
                    "label": 0
                },
                {
                    "sent": "Can be seen as special cases of Markov logic and we will see later how that can be done, so you can you can.",
                    "label": 1
                },
                {
                    "sent": "Clearly get the structure of the field by seeing how each of those approaches Maps into this representation also.",
                    "label": 0
                },
                {
                    "sent": "For Markov logic, there is a complete set of these algorithms available for people to use, which again I think is not the case, at least to some extent for any of the other approaches.",
                    "label": 0
                },
                {
                    "sent": "So that's the main thing.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We're going to be drawing on for the rest of this tutorial, so let me now go a little bit into a little bit more detail on Markov logic.",
                    "label": 0
                },
                {
                    "sent": "I will start by talking about the representation and then we will look at some of the inference and learning algorithms, and then after that we will go into doing some applications.",
                    "label": 0
                },
                {
                    "sent": "So the basic intuition Markov logic is very simple.",
                    "label": 0
                },
                {
                    "sent": "It's the falling.",
                    "label": 0
                },
                {
                    "sent": "You can think of a logical knowledge base is a set of hard constraints on the possible states of the world.",
                    "label": 1
                },
                {
                    "sent": "If a world violates even one formula, it's impossible, and this is what makes for starter logic so brittle.",
                    "label": 0
                },
                {
                    "sent": "Well, how about we make them soft constraints when world violates a formula, it becomes less probable, but not impossible.",
                    "label": 1
                },
                {
                    "sent": "Suppose you have the formula smoking causes cancer in first order logic.",
                    "label": 0
                },
                {
                    "sent": "As soon as this one smoker in your world that doesn't get cancer, the world is impossible.",
                    "label": 0
                },
                {
                    "sent": "First, the logic makes no difference between there being one smoker without cancer and all of the smokers having no cancer.",
                    "label": 0
                },
                {
                    "sent": "When of course the last one is vastly less likely than the first one.",
                    "label": 0
                },
                {
                    "sent": "In Markov logic, we actually get what you intuitively hope to get, which is the more smokers that don't have cancer, the less likely the world becomes.",
                    "label": 0
                },
                {
                    "sent": "And then each formula is going to have a weight that represents how strong of a constraint the formula is.",
                    "label": 0
                },
                {
                    "sent": "So the formula is almost always true.",
                    "label": 0
                },
                {
                    "sent": "Then it's a strong constraint and it should have a high weight.",
                    "label": 0
                },
                {
                    "sent": "And if a world violates that, formulate plays a big penalty and now the probability of a world is just going to be a log linear model where what you have is the sum of the weights of the formulas that the world satisfies.",
                    "label": 0
                },
                {
                    "sent": "So the more formulas of world satisfies, the more probability is and also the higher the weight of those formulas that it satisfies, the more probable the world is.",
                    "label": 0
                },
                {
                    "sent": "So world where more smokers get cancer will have a higher value of this exponent here.",
                    "label": 0
                },
                {
                    "sent": "And be more likely.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here's a more precise definition.",
                    "label": 0
                },
                {
                    "sent": "So we're going to call a Markov logic network or MLN.",
                    "label": 0
                },
                {
                    "sent": "A set of peers.",
                    "label": 0
                },
                {
                    "sent": "If W where F is a formula in first order logic with the standard syntax and W is any real number, positive or negative.",
                    "label": 0
                },
                {
                    "sent": "That's the syntax.",
                    "label": 0
                },
                {
                    "sent": "The semantics is that, together with a set of constants representing objects in the domain and then Mail and defines a Markov network as follows, it's going to have one note for each grounding of each predicate in the MLN, and it's going to have one feature for each grounding of each formula in the MLN with the corresponding weight.",
                    "label": 1
                },
                {
                    "sent": "So here.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is an example that will hopefully make things more concrete.",
                    "label": 0
                },
                {
                    "sent": "So suppose I have these two statements in English smoking causes cancer and friends have similar smoking habits.",
                    "label": 0
                },
                {
                    "sent": "These are both true.",
                    "label": 0
                },
                {
                    "sent": "As you know, doctors and sociologists will tell you now anybody who's.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Can AI 101 knows how to turn this into logic?",
                    "label": 0
                },
                {
                    "sent": "You write something like for every X smokes of X implies cancer of X for every XY friends of XY implies smokes of X is equivalent to smokes of YK.",
                    "label": 0
                },
                {
                    "sent": "Now there's only one problem with this is that both of these statements are not false.",
                    "label": 0
                },
                {
                    "sent": "The statements in natural language were true, but these are false because not everybody who smokes gets cancer and certainly not all pairs of friends have.",
                    "label": 0
                },
                {
                    "sent": "This makes same smoking habits.",
                    "label": 0
                },
                {
                    "sent": "However, if I turn these.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Formulas into Markov logic by giving them weights.",
                    "label": 0
                },
                {
                    "sent": "Now I once again have something that's true and potentially useful, so I give a weight of 1.5 to this formula and a weight of 1.1 to this formula.",
                    "label": 0
                },
                {
                    "sent": "This weight is higher.",
                    "label": 0
                },
                {
                    "sent": "This reflects the fact that this is a stronger regularity than this.",
                    "label": 0
                },
                {
                    "sent": "And a good rule of thumb to understand what it means is that other things being equal, the weight of a formula is the log odds that the formula is true.",
                    "label": 0
                },
                {
                    "sent": "OK, so the more probable formula, the higher the weight.",
                    "label": 0
                },
                {
                    "sent": "If the formula is equally likely to be true or false, the weight is 0.",
                    "label": 0
                },
                {
                    "sent": "If the former is more likely to be false, will actually have a negative weight, so a negative weight is actually perfectly perfectly meaningful thing to have, so this is an MLN.",
                    "label": 0
                },
                {
                    "sent": "Now let's look what happens in a concrete.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I mean, let's say I have just two constants, Ann and Bob, because that's what will fit on a slide.",
                    "label": 1
                },
                {
                    "sent": "So what's the ground Markov network that we're going to create?",
                    "label": 0
                },
                {
                    "sent": "Well, it's going to have one variable for every grounding of every Atom with every combination of constants.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So to start with, we're going to have for this smoke Sanon cancer Anna and smokes volvon cans.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Bob and I'm going to have all groundings of the friends predicate, which is friends AB.",
                    "label": 0
                },
                {
                    "sent": "Friends be a notice that they are not necessarily the same.",
                    "label": 0
                },
                {
                    "sent": "Bob could be a much better friend of Anna.",
                    "label": 0
                },
                {
                    "sent": "The nanny is of Bob and I'm also going to have these.",
                    "label": 0
                },
                {
                    "sent": "You know, degenerate cases friends Anna Anna and friends Bob Bob which maybe have to do with their degree of self esteem or something.",
                    "label": 0
                },
                {
                    "sent": "So So what I have now is a ground Markov network.",
                    "label": 0
                },
                {
                    "sent": "This is is this is just I'm just going to build a probabilistic model over these variables and this is just a bunch of Boolean variables.",
                    "label": 0
                },
                {
                    "sent": "So at this point we are in a standard.",
                    "label": 0
                },
                {
                    "sent": "Probabilistic modeling situation.",
                    "label": 0
                },
                {
                    "sent": "We know what to do right?",
                    "label": 0
                },
                {
                    "sent": "So?",
                    "label": 0
                },
                {
                    "sent": "So what is the Markov network going to be here?",
                    "label": 0
                },
                {
                    "sent": "Well, I'm going to have a feature for every grounding of every formula.",
                    "label": 0
                },
                {
                    "sent": "So for example, I'm going to have a feature that is smokes.",
                    "label": 0
                },
                {
                    "sent": "Anna implies cancer N. And every time I have a feature feature involving two predicates, there will be an arc between the corresponding node.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the network, so I'm going to have an arc between cancer in and smokes Anna.",
                    "label": 0
                },
                {
                    "sent": "That's the result of this formula smokes X implies cancer.",
                    "label": 0
                },
                {
                    "sent": "X applied to Anna, and the same thing for Bob.",
                    "label": 0
                },
                {
                    "sent": "OK, so this formula involves two predicates, so it gives me a binary click this formula here.",
                    "label": 0
                },
                {
                    "sent": "Involves three predicates, so it's going to give me a ternary clique.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here all of its possible instances, so there's one here.",
                    "label": 0
                },
                {
                    "sent": "Between smokes Anna friends and above.",
                    "label": 0
                },
                {
                    "sent": "And smokes Bob the same thing here with friends Bob, Anna and they're going to have these two degenerate ones.",
                    "label": 0
                },
                {
                    "sent": "So now I have a complete Markov network that I have built from the.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "MLN for this domain.",
                    "label": 0
                },
                {
                    "sent": "Using this particular objects.",
                    "label": 0
                },
                {
                    "sent": "I notice the following important fact that is true for Melanzane is actually generally true of all statistical additional models.",
                    "label": 0
                },
                {
                    "sent": "Is that an email and is actually not a probability distribution and MLN is a family of probability distributions, a different one for every different world that you could apply it to, where all of those distributions are going to have in common is that they repetitions of the same templates.",
                    "label": 0
                },
                {
                    "sent": "In Markov logic, the templates are farmers in first order, logic in relational Markov networks their SQL queries.",
                    "label": 0
                },
                {
                    "sent": "In statistic in knowledge base model model construction there horn clauses, but there's always this idea of the template being repeated the number of times and now the probability of a world that I get out of this is here's my log linear model.",
                    "label": 1
                },
                {
                    "sent": "It's the sum, it's the normalized expenditure, did some overall formulas of the weight of the Formula Times the number of true groundings of that formula in the world?",
                    "label": 1
                },
                {
                    "sent": "OK, so if there are more smokers who get cancer in my world and for the corresponding?",
                    "label": 0
                },
                {
                    "sent": "Formula is going to go up.",
                    "label": 0
                },
                {
                    "sent": "It's going to be multiplied by its weight and the probability of that world is going to be higher, which is what I want to have OK. Now, something that you've probably that has probably crossed the minds of some of you is that this is all very nice, but it doesn't seem very practical.",
                    "label": 0
                },
                {
                    "sent": "Doesn't seem very practical because what's going to happen when I run the network is that I'm going to get a huge blow up right?",
                    "label": 0
                },
                {
                    "sent": "And in any but the smallest worlds, this isn't really going to.",
                    "label": 0
                },
                {
                    "sent": "We're not able to do much with this, and you need some of the most significant progress that's been made in the last several years has been in dealing with this problem and the very first thing that you can do, which is very simple but already buys you a tremendous amount, is just to have typed variables and constants.",
                    "label": 0
                },
                {
                    "sent": "If you have a predicate like works for XY, you only need to replace X by people and why by organisations it doesn't make sense to do anything else.",
                    "label": 0
                },
                {
                    "sent": "So if you only replace variables by constants of the corresponding type immediately, the number of ground items that you have goes down a lot and there's going to be other things that we're going to do as we will see later now in Markov logic, you can actually do the full range of 1st order logic, including function, existential quantifiers, etc.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to talk about that here.",
                    "label": 0
                },
                {
                    "sent": "For the sake of time, but you can certainly look at the papers, you can also do infinite and continuous domains in Markov logic.",
                    "label": 1
                },
                {
                    "sent": "Again, I'm not going to talk about that here if there's time towards the end, I will show you an application to robot mapping where we do continuous domains and show you what happens there.",
                    "label": 0
                },
                {
                    "sent": "But no, not at all.",
                    "label": 0
                },
                {
                    "sent": "That's the key, right?",
                    "label": 0
                },
                {
                    "sent": "Is that?",
                    "label": 0
                },
                {
                    "sent": "Sorry, so the question is, do we assume that the groundings are different?",
                    "label": 0
                },
                {
                    "sent": "Formulas are independent, right?",
                    "label": 0
                },
                {
                    "sent": "Notice what happens is that a grounding of a formula is the dependence between the atoms that are involved in it, right?",
                    "label": 0
                },
                {
                    "sent": "Right, so now if you think about it, the format that the atoms depend on each other view the formulas, which means that the formulas, if you think of them as Boolean variables, right?",
                    "label": 0
                },
                {
                    "sent": "They also depend on the atoms and so formulas depend on each other via the atoms that they share.",
                    "label": 0
                },
                {
                    "sent": "In the same way that an Atom can depend, you know if it appears in multiple clauses, that Atom is going to depend the Markov blanket of an Atom is going to be all the items that appear with it in any formula.",
                    "label": 0
                },
                {
                    "sent": "OK, so you connect so you can have arbitrary dependencies in this language.",
                    "label": 0
                },
                {
                    "sent": "This expression.",
                    "label": 0
                },
                {
                    "sent": "No key point.",
                    "label": 0
                },
                {
                    "sent": "This is this expression is not assuming independence, and that's because of what these features are over.",
                    "label": 0
                },
                {
                    "sent": "What happens when you have IID data is that the features are only over properties of the same object.",
                    "label": 0
                },
                {
                    "sent": "This is the key difference.",
                    "label": 0
                },
                {
                    "sent": "When you have non IID data, your features can be over properties of more than one object.",
                    "label": 0
                },
                {
                    "sent": "So for example, in this example that we have here.",
                    "label": 0
                },
                {
                    "sent": "If if the MLN was just this, it would be an ideal model.",
                    "label": 0
                },
                {
                    "sent": "Because we're only talking about properties of the same object, you can think of this as a simple classifier that predicts cancer given smokes and maybe given other features as well.",
                    "label": 0
                },
                {
                    "sent": "OK where the non IID comes in is in a formula like this, because now what happens is that whether one person smokes depends on whether another person smokes.",
                    "label": 0
                },
                {
                    "sent": "So now there are no longer independent.",
                    "label": 0
                },
                {
                    "sent": "OK and this is what we get from first order logic is we get a very nice, well understood compact language for specifying dependencies among objects.",
                    "label": 0
                },
                {
                    "sent": "Does that answer your question?",
                    "label": 0
                },
                {
                    "sent": "We can, we can talk more about it, and I mean they'll be more examples of this later.",
                    "label": 0
                },
                {
                    "sent": "In principle, yes.",
                    "label": 0
                },
                {
                    "sent": "In practice, what happens is that if you add that rule and just retrain, starting with the current weights, that probably converges very quickly.",
                    "label": 0
                },
                {
                    "sent": "Big enough.",
                    "label": 0
                },
                {
                    "sent": "This is a really interesting question, and here's what happens.",
                    "label": 0
                },
                {
                    "sent": "This is actually something that we wanted a lot about in the beginning is that.",
                    "label": 0
                },
                {
                    "sent": "I mean, one of the good things about these models is that they generalize across domain sizes, right?",
                    "label": 0
                },
                {
                    "sent": "That's great where they potentially generalized.",
                    "label": 0
                },
                {
                    "sent": "But the question is, are they going to generalize well?",
                    "label": 0
                },
                {
                    "sent": "If I learn weights on a small social network, will generalize to a large one, and there is indeed cost to worry that it won't.",
                    "label": 0
                },
                {
                    "sent": "However, what actually seems to happen in practice that, at least in our experience, inexpensive other people.",
                    "label": 0
                },
                {
                    "sent": "You generalize fairly well across a domain sizes.",
                    "label": 0
                },
                {
                    "sent": "And one reason for that is that even though the number of possible groundings goes up a lot, the number of actual true groundings and those are the only ones that matter.",
                    "label": 0
                },
                {
                    "sent": "But if you look at the solutions distichs, those don't go up by as much.",
                    "label": 0
                },
                {
                    "sent": "Often they go up in proportion to the number of objects.",
                    "label": 0
                },
                {
                    "sent": "Another way to look at this is you know, think of a simple model like you know an HMM or hidden Markov random for image processing, right?",
                    "label": 0
                },
                {
                    "sent": "You can learn something on straight sequences and applied to large sequences.",
                    "label": 0
                },
                {
                    "sent": "You can learn something on small images and apply them to large images and the general.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This will work now.",
                    "label": 0
                },
                {
                    "sent": "Underlying this is the fact that there is a learning bias here.",
                    "label": 0
                },
                {
                    "sent": "The learning bias here is that the relevant sufficient statistiques are the class counts.",
                    "label": 0
                },
                {
                    "sent": "If that's not the case, then you will generalize poorly.",
                    "label": 0
                },
                {
                    "sent": "But empirically, this seems to be a pretty good base.",
                    "label": 1
                },
                {
                    "sent": "Will talk more about this.",
                    "label": 0
                },
                {
                    "sent": "I want to talk about learning and it's 3:30, so let's take a break and reconvene at 4.",
                    "label": 0
                }
            ]
        }
    }
}