{
    "id": "ldwoiawe252oqnamnoatvliqmxj4ul7l",
    "title": "Inferring Networks of Diffusion and Influence",
    "info": {
        "author": [
            "Manuel Gomez Rodriguez, Department of Electrical Engineering, Stanford University"
        ],
        "published": "Oct. 1, 2010",
        "recorded": "July 2010",
        "category": [
            "Top->Computer Science->Data Mining"
        ]
    },
    "url": "http://videolectures.net/kdd2010_gomez_ind/",
    "segmentation": [
        [
            "Now talk about inferring networks of diffusion and influence.",
            "So what is the?"
        ],
        [
            "Problem that we are dealing with and there are a lot of networks that can be social networks or information networks that we cannot observe.",
            "That can be because mainly two reasons.",
            "The first reason, if it is hard reach population for instance, imagine drug users that are sharing needles and we cannot know who are the users that are sharing needles or the case would be implicit connections.",
            "An example of this would be an information propagation network in which online media are talking about the same things.",
            "But we don't know who is copying from whom, but then.",
            "What we can observe indigenous networks is the processes that are happening on them.",
            "For instance, for the case of needle sharing, we can see when a person gets ill and goes to the doctor.",
            "For the case of information networks we can see when site or web lock is mentioning a piece of information.",
            "So with the problem that we want to solve is, can we infer this hidden networks from the activity that is happening in them?"
        ],
        [
            "So if we see a little bit graphically, what is the problem?",
            "There is a directed social network and information network over which diffusions take place.",
            "But the problem is that we don't share the edges of this network.",
            "The only thing that we can observe is the activity on them.",
            "If we see a cascade C one that we call Cascade to a change of infections.",
            "If we go to the first one, we can see that the note a gets infected in time one.",
            "After that, they don't see get infected.",
            "The node B, or they know.",
            "But we don't know who was infected home in the same manner we can see how Cascade C2 would be.",
            "C gets infected, the first one and after a B or did.",
            "And besides the incubation time between infections is known.",
            "Is unknown, but we can see exactly the timing.",
            "Which effects can happen.",
            "So again, the problem from this activity, can we infer the underlying network?"
        ],
        [
            "Besides these examples, we can see another example shop applications.",
            "For instance, in Beatles propagation we can see how The Beatles propagate through the network and we can see again how people get sick.",
            "But again we cannot see who infected whom.",
            "For instance, in viral marketing or worth of mouth, we can see how their recommendations that are.",
            "A propagating influence, but we cannot observe.",
            "We can observe who buy the products, but we cannot observe A who influence at home.",
            "So again, our problem is, can we infer the underlying network so the rest of the talk is going to be about solving this problem."
        ],
        [
            "Our plan is first to define a model of diffusion that works in continuous time.",
            "After that we are going to define a likelihood of the observed cascades given the network, and we're going to see how to efficiently compute the likelihood of the Cascades and how to efficiently find a graph key that maximize the likelihood that booty to estimate the network, and we have to take into account that the networks we have a super exponential time of super exponential number of them, and our method is going to achieve to find a sub optimal graph on network.",
            "In any square."
        ],
        [
            "So let's go for them.",
            "Continuous time diffusion model.",
            "Imagine that Cascade arrives to annoy you at at time TU, and then we have to see how it spreads to the neighbors.",
            "So with relative data, we're going to propagate along an edge to a neighbor.",
            "And besides, we're going to determine also the time difference between the infections that in case for simplicity we chose an exponential power law distribution on the time difference between infections.",
            "So if we see a little example, we can see how there is an infection.",
            "In all, due at time TU and then with better probability we see OK, we're infecting the notepad and now we draw from the distribution of time difference, a time difference and we have that B was infected in TV.",
            "This process we can continue with the next neighbors of U.",
            "And we can see how, for instance T doesn't get infected or C gets infected.",
            "So the assumption that we are making is that every node has only one parent."
        ],
        [
            "So given a cascade, see that we know that the two nodes are belonging to that cascade.",
            "UMB.",
            "We can define the probability that the infection went from you to be as a function that in our case depends on the time difference.",
            "We have to take into account that we could also use a function that depends on other parameters.",
            "For instance, in the kind of illnesses some proper property of the illness in the node, or in the case of information, some textual information.",
            "Besides.",
            "Until now we have seen only examples in which all the notes that are in the network are they once producing infections on each other.",
            "But it can happen that there is an external influence and so we model this external influence and every note can be infected.",
            "But the Cisternal influence with really small probability.",
            "So now if we see the probability of a cascade C. In a pattern tea in a pattern in a tree pattern T we can see that it's only the product of the priorities of every edge we can see visually on the right, down.",
            "For instance, for a cascade that is containing the nodes are in term one and B in time 2 scene time four and in time eight we can see how that would be a possibility.",
            "That would be that a is infected B&C&B is infected E. The problem."
        ],
        [
            "Is that we have to take into account all the possible trees that can explain a cascade.",
            "Again, if we define a cascade C that is happening, the nodes 8 CRE in chronological order, we can see how these trees are visible in the sense that there are edges in the network that we could use them to explain those infections.",
            "So if we consider all the possible provides on trees supported by the graph D or the network that is showing the connectivity, we can see how simply.",
            "Is on.",
            "An average over all the possible trees, and we consider that every three is equally probable.",
            "So when we have a set of cascades, is simply the joint probability of the Cascades given a graph and we are confident that every cascade is independent.",
            "So our problem is to find in a graph G that better explain this set of cascades and we limit the number of edges of key to a number K. So what are the good news and the bad news about this?",
            "The good news is that although we have a really big number of propagation trees.",
            "We can compute this quantity in Ncube when the number of super exponential and the bad news is that we actually want to share it over the graphs.",
            "We don't want only to compute how good is a graph to infra cascade offset of cascades.",
            "But to generate this graph and the number of rush is super exponential.",
            "So what is the alternative formulation?"
        ],
        [
            "Is that in case of considering all the possible trees?",
            "We are considering only the most likely tree.",
            "If you see in the equation before we have a product that in this case because we apply logarithms to have the log likelihood instead of the assume we have a Max, so we are a substitute in every zoom via Max and the rest of the formulation is equal taking into account that because we are reducing lock look like it likelihood instead of probabilities.",
            "Then we can compare the product systems.",
            "So anyway, even with this formulation, the problem is that our problem is still intractable in the sense that is NP hard.",
            "But now we're going to present an algorithm that finds near optimal networks in a square.",
            "So far."
        ],
        [
            "All we have to see how we compute the maximum likelihood tree forgiving cascade and we can see that at the end of the day it reduced to compute the maximum directed spanning tree.",
            "And besides because the every edge is pointing forward in time in the sense that a node cannot buy get infected by another node but was infected in the future, we have a maximum directed spanning tree over attack.",
            "So that means that for every note we can.",
            "Basically, choose the edge that has the maximum weight and in that sense we can choose the pattern of every note independently.",
            "So we have a local procedure that gives a globally optimal tree."
        ],
        [
            "So, but this is not the end of the story, because we are interested not only computing the maximum likelihood, the maximum, the most likely tree, but we are interested in generating the graph and we can see how they look.",
            "Likelihood that we just define this monotonic and is submodular in the edges of the graph.",
            "That means that if we have a graph and we are the testing, how come at an edge increase our objective function is going to increase more?",
            "A graph that is smaller?",
            "The graph that is bigger, so in the mathematical notations we can see a is smaller than B, so the difference in a is bigger than the difference in B and to prove this we are using exactly the idea that I just presented that we can have a greedy parents election.",
            "That means that local procedure that gives an optimal solution and basically using also the submodularity definition and even more this log likelihood works for a single cascade.",
            "But because the log likelihood for a set of cascades, it simply does soon we know that the sum of two modular functions.",
            "It's also mother, So what that?"
        ],
        [
            "It mean that we can use a greedy algorithm that is basically that in every step of the algorithm we started with an empty graph.",
            "We evaluate how every edge is increasing our rain and based on that we choose on edge.",
            "So we do this procedure sequentially.",
            "For instance, if we started with a graph that is completely empty graph, we evaluate the marginal gain for all the possible latest.",
            "So we choose the biggest one and we re estimate the increments in the other ideas and we continue further.",
            "And it's a sequential.",
            "And then is very efficient, so the benefits of doing this is that we can we have an approximation guarantee in the sense that we know theoretically that we are 63% of the optimal.",
            "We have tight online bonds and we can have speedups.",
            "One of them is based on the submodularity that is lazy evaluation, and another one is based on the structure of the problem.",
            "That is this idea that a local solution gives a global optimal that we call it in our paper localized update."
        ],
        [
            "So for validating our method, we carry on experiments in synthetic data and in real data in synthetic data is straightforward in the sense that we can generate scraps with K edges, generate case over them, and record the note infections times and to try to reconstruct the graph D. For real data we will see that we use them in tracker data set, so questions that are interesting to evaluate the quality is precision and recall.",
            "That basically is the number of edges that we can recover at the number of edges that we can recover in a wrong manner.",
            "How many cascades do we need for inferring the network?",
            "How well do optimize?",
            "Because we have a bound, or how fast are we?",
            "So if we."
        ],
        [
            "Go to a small example we can see on the left that is the true network and we can see on the right is our method and on the middle is a baseline that we're basically picking the strongest edges.",
            "The edges that appear in the greatest number of cascades so we can see how our method only means two edges while the baseline is missing a great amount of them.",
            "So if we see in."
        ],
        [
            "Bigger scale for chronic graphs of forest fire graph both.",
            "Both of them of 1024 nodes or 1000 nodes and with an exponential transmission model and power law model.",
            "How our method is outperforming the baseline and even more important, the methods since invariant against the structure of the network and against the transmission time distribution we get break even points of 90%.",
            "That is when the precision and recall are equal.",
            "So."
        ],
        [
            "So how good is our graph if we compute an online bond that is in green and we compute our solution that is in red, we can see how our method is doing 90% of the best possible network."
        ],
        [
            "If we see the number of cascades that do we need, in general we need twice as many infections at edges and as you can see with the better parameter, we control the size of the size of the Cascades and when we have a smaller cascades, our problem is easier.",
            "So we have a break even points that are bigger."
        ],
        [
            "If we see to the running time so we can see how the spirits that they were talking about a let us improve the speed by two orders of magnitude in blue are not speed up San in green and red, they are speedups.",
            "And then in this manner we can infer a network of 10,000 nodes in several hours."
        ],
        [
            "So for real data we have the following problem, that is that we don't have a ground truth and we want to use the mentions of quotes that are happening in the network to infer who is copying from whom or who is repeating after whom.",
            "So what we did is we have also the hyperlinks that are happening between the sites in this ground in this network and we use it as a ground truth.",
            "So from the data set we can have cascades of hyperlinks would be to take the time when our site creates links and we have cascades of textual phrases.",
            "That means when a site mentions information and."
        ],
        [
            "Compare both of them.",
            "We trying to infer this network based on the hyperlinks based on the cascades of hyperlinks and cascades of textual phrases, and we can see how our method again is outperforming the baseline in this case for a smaller quantity that is due to the fact that the model is pretty simple to explain real data and anyway even for the case of memory tracker cascades, we can see how clusters are up."
        ],
        [
            "Getting in the sense that in this case, if you focus on the left, we can see how there are general news media sites that are mainly regarding politics.",
            "If we go to the top, we can see how celebrity news are happening on the bottom to the right.",
            "How technological sites are happening?",
            "Besides, there are some sites that they have social capital as salon.com because they are connecting this class."
        ],
        [
            "So what is the conclusion?",
            "Is our work?",
            "We managed to infer hidden networks based only on the diffusion data that is activity happening in this data or formulation is based on a maximum likelihood framework and we are able to approximate an NP hard problem with a solution that runs in any square, is invariant to the structure of the underlying network and give a suboptimal network that we can bound tightly.",
            "So the feature work would be not only to learn the network, but also to learn the fashion model.",
            "And besides that, there are other applications to other domains that can be interesting to explore, like biology on the other side."
        ],
        [
            "And that's it, thanks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now talk about inferring networks of diffusion and influence.",
                    "label": 0
                },
                {
                    "sent": "So what is the?",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Problem that we are dealing with and there are a lot of networks that can be social networks or information networks that we cannot observe.",
                    "label": 0
                },
                {
                    "sent": "That can be because mainly two reasons.",
                    "label": 0
                },
                {
                    "sent": "The first reason, if it is hard reach population for instance, imagine drug users that are sharing needles and we cannot know who are the users that are sharing needles or the case would be implicit connections.",
                    "label": 0
                },
                {
                    "sent": "An example of this would be an information propagation network in which online media are talking about the same things.",
                    "label": 0
                },
                {
                    "sent": "But we don't know who is copying from whom, but then.",
                    "label": 1
                },
                {
                    "sent": "What we can observe indigenous networks is the processes that are happening on them.",
                    "label": 1
                },
                {
                    "sent": "For instance, for the case of needle sharing, we can see when a person gets ill and goes to the doctor.",
                    "label": 1
                },
                {
                    "sent": "For the case of information networks we can see when site or web lock is mentioning a piece of information.",
                    "label": 1
                },
                {
                    "sent": "So with the problem that we want to solve is, can we infer this hidden networks from the activity that is happening in them?",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So if we see a little bit graphically, what is the problem?",
                    "label": 0
                },
                {
                    "sent": "There is a directed social network and information network over which diffusions take place.",
                    "label": 1
                },
                {
                    "sent": "But the problem is that we don't share the edges of this network.",
                    "label": 0
                },
                {
                    "sent": "The only thing that we can observe is the activity on them.",
                    "label": 0
                },
                {
                    "sent": "If we see a cascade C one that we call Cascade to a change of infections.",
                    "label": 0
                },
                {
                    "sent": "If we go to the first one, we can see that the note a gets infected in time one.",
                    "label": 0
                },
                {
                    "sent": "After that, they don't see get infected.",
                    "label": 0
                },
                {
                    "sent": "The node B, or they know.",
                    "label": 0
                },
                {
                    "sent": "But we don't know who was infected home in the same manner we can see how Cascade C2 would be.",
                    "label": 0
                },
                {
                    "sent": "C gets infected, the first one and after a B or did.",
                    "label": 0
                },
                {
                    "sent": "And besides the incubation time between infections is known.",
                    "label": 0
                },
                {
                    "sent": "Is unknown, but we can see exactly the timing.",
                    "label": 0
                },
                {
                    "sent": "Which effects can happen.",
                    "label": 0
                },
                {
                    "sent": "So again, the problem from this activity, can we infer the underlying network?",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Besides these examples, we can see another example shop applications.",
                    "label": 0
                },
                {
                    "sent": "For instance, in Beatles propagation we can see how The Beatles propagate through the network and we can see again how people get sick.",
                    "label": 1
                },
                {
                    "sent": "But again we cannot see who infected whom.",
                    "label": 0
                },
                {
                    "sent": "For instance, in viral marketing or worth of mouth, we can see how their recommendations that are.",
                    "label": 0
                },
                {
                    "sent": "A propagating influence, but we cannot observe.",
                    "label": 0
                },
                {
                    "sent": "We can observe who buy the products, but we cannot observe A who influence at home.",
                    "label": 1
                },
                {
                    "sent": "So again, our problem is, can we infer the underlying network so the rest of the talk is going to be about solving this problem.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Our plan is first to define a model of diffusion that works in continuous time.",
                    "label": 1
                },
                {
                    "sent": "After that we are going to define a likelihood of the observed cascades given the network, and we're going to see how to efficiently compute the likelihood of the Cascades and how to efficiently find a graph key that maximize the likelihood that booty to estimate the network, and we have to take into account that the networks we have a super exponential time of super exponential number of them, and our method is going to achieve to find a sub optimal graph on network.",
                    "label": 1
                },
                {
                    "sent": "In any square.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's go for them.",
                    "label": 0
                },
                {
                    "sent": "Continuous time diffusion model.",
                    "label": 0
                },
                {
                    "sent": "Imagine that Cascade arrives to annoy you at at time TU, and then we have to see how it spreads to the neighbors.",
                    "label": 1
                },
                {
                    "sent": "So with relative data, we're going to propagate along an edge to a neighbor.",
                    "label": 0
                },
                {
                    "sent": "And besides, we're going to determine also the time difference between the infections that in case for simplicity we chose an exponential power law distribution on the time difference between infections.",
                    "label": 0
                },
                {
                    "sent": "So if we see a little example, we can see how there is an infection.",
                    "label": 0
                },
                {
                    "sent": "In all, due at time TU and then with better probability we see OK, we're infecting the notepad and now we draw from the distribution of time difference, a time difference and we have that B was infected in TV.",
                    "label": 0
                },
                {
                    "sent": "This process we can continue with the next neighbors of U.",
                    "label": 0
                },
                {
                    "sent": "And we can see how, for instance T doesn't get infected or C gets infected.",
                    "label": 0
                },
                {
                    "sent": "So the assumption that we are making is that every node has only one parent.",
                    "label": 1
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So given a cascade, see that we know that the two nodes are belonging to that cascade.",
                    "label": 0
                },
                {
                    "sent": "UMB.",
                    "label": 0
                },
                {
                    "sent": "We can define the probability that the infection went from you to be as a function that in our case depends on the time difference.",
                    "label": 0
                },
                {
                    "sent": "We have to take into account that we could also use a function that depends on other parameters.",
                    "label": 0
                },
                {
                    "sent": "For instance, in the kind of illnesses some proper property of the illness in the node, or in the case of information, some textual information.",
                    "label": 0
                },
                {
                    "sent": "Besides.",
                    "label": 0
                },
                {
                    "sent": "Until now we have seen only examples in which all the notes that are in the network are they once producing infections on each other.",
                    "label": 0
                },
                {
                    "sent": "But it can happen that there is an external influence and so we model this external influence and every note can be infected.",
                    "label": 0
                },
                {
                    "sent": "But the Cisternal influence with really small probability.",
                    "label": 0
                },
                {
                    "sent": "So now if we see the probability of a cascade C. In a pattern tea in a pattern in a tree pattern T we can see that it's only the product of the priorities of every edge we can see visually on the right, down.",
                    "label": 1
                },
                {
                    "sent": "For instance, for a cascade that is containing the nodes are in term one and B in time 2 scene time four and in time eight we can see how that would be a possibility.",
                    "label": 0
                },
                {
                    "sent": "That would be that a is infected B&C&B is infected E. The problem.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is that we have to take into account all the possible trees that can explain a cascade.",
                    "label": 0
                },
                {
                    "sent": "Again, if we define a cascade C that is happening, the nodes 8 CRE in chronological order, we can see how these trees are visible in the sense that there are edges in the network that we could use them to explain those infections.",
                    "label": 0
                },
                {
                    "sent": "So if we consider all the possible provides on trees supported by the graph D or the network that is showing the connectivity, we can see how simply.",
                    "label": 1
                },
                {
                    "sent": "Is on.",
                    "label": 0
                },
                {
                    "sent": "An average over all the possible trees, and we consider that every three is equally probable.",
                    "label": 0
                },
                {
                    "sent": "So when we have a set of cascades, is simply the joint probability of the Cascades given a graph and we are confident that every cascade is independent.",
                    "label": 0
                },
                {
                    "sent": "So our problem is to find in a graph G that better explain this set of cascades and we limit the number of edges of key to a number K. So what are the good news and the bad news about this?",
                    "label": 1
                },
                {
                    "sent": "The good news is that although we have a really big number of propagation trees.",
                    "label": 0
                },
                {
                    "sent": "We can compute this quantity in Ncube when the number of super exponential and the bad news is that we actually want to share it over the graphs.",
                    "label": 1
                },
                {
                    "sent": "We don't want only to compute how good is a graph to infra cascade offset of cascades.",
                    "label": 0
                },
                {
                    "sent": "But to generate this graph and the number of rush is super exponential.",
                    "label": 0
                },
                {
                    "sent": "So what is the alternative formulation?",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is that in case of considering all the possible trees?",
                    "label": 0
                },
                {
                    "sent": "We are considering only the most likely tree.",
                    "label": 1
                },
                {
                    "sent": "If you see in the equation before we have a product that in this case because we apply logarithms to have the log likelihood instead of the assume we have a Max, so we are a substitute in every zoom via Max and the rest of the formulation is equal taking into account that because we are reducing lock look like it likelihood instead of probabilities.",
                    "label": 0
                },
                {
                    "sent": "Then we can compare the product systems.",
                    "label": 1
                },
                {
                    "sent": "So anyway, even with this formulation, the problem is that our problem is still intractable in the sense that is NP hard.",
                    "label": 0
                },
                {
                    "sent": "But now we're going to present an algorithm that finds near optimal networks in a square.",
                    "label": 1
                },
                {
                    "sent": "So far.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "All we have to see how we compute the maximum likelihood tree forgiving cascade and we can see that at the end of the day it reduced to compute the maximum directed spanning tree.",
                    "label": 0
                },
                {
                    "sent": "And besides because the every edge is pointing forward in time in the sense that a node cannot buy get infected by another node but was infected in the future, we have a maximum directed spanning tree over attack.",
                    "label": 1
                },
                {
                    "sent": "So that means that for every note we can.",
                    "label": 0
                },
                {
                    "sent": "Basically, choose the edge that has the maximum weight and in that sense we can choose the pattern of every note independently.",
                    "label": 1
                },
                {
                    "sent": "So we have a local procedure that gives a globally optimal tree.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, but this is not the end of the story, because we are interested not only computing the maximum likelihood, the maximum, the most likely tree, but we are interested in generating the graph and we can see how they look.",
                    "label": 0
                },
                {
                    "sent": "Likelihood that we just define this monotonic and is submodular in the edges of the graph.",
                    "label": 1
                },
                {
                    "sent": "That means that if we have a graph and we are the testing, how come at an edge increase our objective function is going to increase more?",
                    "label": 0
                },
                {
                    "sent": "A graph that is smaller?",
                    "label": 0
                },
                {
                    "sent": "The graph that is bigger, so in the mathematical notations we can see a is smaller than B, so the difference in a is bigger than the difference in B and to prove this we are using exactly the idea that I just presented that we can have a greedy parents election.",
                    "label": 0
                },
                {
                    "sent": "That means that local procedure that gives an optimal solution and basically using also the submodularity definition and even more this log likelihood works for a single cascade.",
                    "label": 0
                },
                {
                    "sent": "But because the log likelihood for a set of cascades, it simply does soon we know that the sum of two modular functions.",
                    "label": 0
                },
                {
                    "sent": "It's also mother, So what that?",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It mean that we can use a greedy algorithm that is basically that in every step of the algorithm we started with an empty graph.",
                    "label": 0
                },
                {
                    "sent": "We evaluate how every edge is increasing our rain and based on that we choose on edge.",
                    "label": 0
                },
                {
                    "sent": "So we do this procedure sequentially.",
                    "label": 0
                },
                {
                    "sent": "For instance, if we started with a graph that is completely empty graph, we evaluate the marginal gain for all the possible latest.",
                    "label": 0
                },
                {
                    "sent": "So we choose the biggest one and we re estimate the increments in the other ideas and we continue further.",
                    "label": 0
                },
                {
                    "sent": "And it's a sequential.",
                    "label": 0
                },
                {
                    "sent": "And then is very efficient, so the benefits of doing this is that we can we have an approximation guarantee in the sense that we know theoretically that we are 63% of the optimal.",
                    "label": 0
                },
                {
                    "sent": "We have tight online bonds and we can have speedups.",
                    "label": 1
                },
                {
                    "sent": "One of them is based on the submodularity that is lazy evaluation, and another one is based on the structure of the problem.",
                    "label": 1
                },
                {
                    "sent": "That is this idea that a local solution gives a global optimal that we call it in our paper localized update.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for validating our method, we carry on experiments in synthetic data and in real data in synthetic data is straightforward in the sense that we can generate scraps with K edges, generate case over them, and record the note infections times and to try to reconstruct the graph D. For real data we will see that we use them in tracker data set, so questions that are interesting to evaluate the quality is precision and recall.",
                    "label": 0
                },
                {
                    "sent": "That basically is the number of edges that we can recover at the number of edges that we can recover in a wrong manner.",
                    "label": 0
                },
                {
                    "sent": "How many cascades do we need for inferring the network?",
                    "label": 1
                },
                {
                    "sent": "How well do optimize?",
                    "label": 0
                },
                {
                    "sent": "Because we have a bound, or how fast are we?",
                    "label": 0
                },
                {
                    "sent": "So if we.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Go to a small example we can see on the left that is the true network and we can see on the right is our method and on the middle is a baseline that we're basically picking the strongest edges.",
                    "label": 1
                },
                {
                    "sent": "The edges that appear in the greatest number of cascades so we can see how our method only means two edges while the baseline is missing a great amount of them.",
                    "label": 0
                },
                {
                    "sent": "So if we see in.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Bigger scale for chronic graphs of forest fire graph both.",
                    "label": 1
                },
                {
                    "sent": "Both of them of 1024 nodes or 1000 nodes and with an exponential transmission model and power law model.",
                    "label": 1
                },
                {
                    "sent": "How our method is outperforming the baseline and even more important, the methods since invariant against the structure of the network and against the transmission time distribution we get break even points of 90%.",
                    "label": 1
                },
                {
                    "sent": "That is when the precision and recall are equal.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how good is our graph if we compute an online bond that is in green and we compute our solution that is in red, we can see how our method is doing 90% of the best possible network.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If we see the number of cascades that do we need, in general we need twice as many infections at edges and as you can see with the better parameter, we control the size of the size of the Cascades and when we have a smaller cascades, our problem is easier.",
                    "label": 0
                },
                {
                    "sent": "So we have a break even points that are bigger.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If we see to the running time so we can see how the spirits that they were talking about a let us improve the speed by two orders of magnitude in blue are not speed up San in green and red, they are speedups.",
                    "label": 0
                },
                {
                    "sent": "And then in this manner we can infer a network of 10,000 nodes in several hours.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for real data we have the following problem, that is that we don't have a ground truth and we want to use the mentions of quotes that are happening in the network to infer who is copying from whom or who is repeating after whom.",
                    "label": 1
                },
                {
                    "sent": "So what we did is we have also the hyperlinks that are happening between the sites in this ground in this network and we use it as a ground truth.",
                    "label": 1
                },
                {
                    "sent": "So from the data set we can have cascades of hyperlinks would be to take the time when our site creates links and we have cascades of textual phrases.",
                    "label": 1
                },
                {
                    "sent": "That means when a site mentions information and.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Compare both of them.",
                    "label": 0
                },
                {
                    "sent": "We trying to infer this network based on the hyperlinks based on the cascades of hyperlinks and cascades of textual phrases, and we can see how our method again is outperforming the baseline in this case for a smaller quantity that is due to the fact that the model is pretty simple to explain real data and anyway even for the case of memory tracker cascades, we can see how clusters are up.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Getting in the sense that in this case, if you focus on the left, we can see how there are general news media sites that are mainly regarding politics.",
                    "label": 0
                },
                {
                    "sent": "If we go to the top, we can see how celebrity news are happening on the bottom to the right.",
                    "label": 0
                },
                {
                    "sent": "How technological sites are happening?",
                    "label": 0
                },
                {
                    "sent": "Besides, there are some sites that they have social capital as salon.com because they are connecting this class.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what is the conclusion?",
                    "label": 0
                },
                {
                    "sent": "Is our work?",
                    "label": 0
                },
                {
                    "sent": "We managed to infer hidden networks based only on the diffusion data that is activity happening in this data or formulation is based on a maximum likelihood framework and we are able to approximate an NP hard problem with a solution that runs in any square, is invariant to the structure of the underlying network and give a suboptimal network that we can bound tightly.",
                    "label": 1
                },
                {
                    "sent": "So the feature work would be not only to learn the network, but also to learn the fashion model.",
                    "label": 0
                },
                {
                    "sent": "And besides that, there are other applications to other domains that can be interesting to explore, like biology on the other side.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And that's it, thanks.",
                    "label": 0
                }
            ]
        }
    }
}