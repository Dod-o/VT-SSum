{
    "id": "whdwohkegbgecodwqjp7wuovzq37eji7",
    "title": "Gait Representation Using Flow Fields",
    "info": {
        "author": [
            "Khalid Bashir, Queen Mary, University of London"
        ],
        "published": "Dec. 1, 2009",
        "recorded": "September 2009",
        "category": [
            "Top->Computer Science->Computer Vision",
            "Top->Computer Science->Image Analysis"
        ]
    },
    "url": "http://videolectures.net/bmvc09_bashir_gruff/",
    "segmentation": [
        [
            "Hi there, my name is Holly here and I've been working with the talk young in Chenggong in Queen Mary, University of London."
        ],
        [
            "So let's go down straight down to the problem.",
            "The problem is to improve the performance of Kate recognition under different covariate conditions.",
            "So what age, guys recognition by the way gait recognition is recognizing people by the way they walk, so it is recognizing people by their gate.",
            "And why is this important?",
            "It's important cause gait recognition is non intrusive as compared to other physiological biometrics such as face, fingerprint, iris.",
            "They all require close proximity subjects and.",
            "Kim cooperation as well, and that's the other thing.",
            "Gate operates at a distance without subject Corporation.",
            "This is what makes it very useful.",
            "And that's why people have been studying it and up till now.",
            "It thinks that everything about gate is great so but there is another side to it."
        ],
        [
            "And that is covered.",
            "Conditions gate of ahem, person changing under different conditions.",
            "And these conditions are lifted over there and they can.",
            "They get off two types, one stalk effect.",
            "The features extracted from gate captures the carrying condition.",
            "The glowing condition in the view.",
            "And there are other sexual catches, shoe time, injury and speed and that affect how that affect gated shelf.",
            "And there is 1 missing over there.",
            "The mood of the person also changes the way you walk.",
            "And let's have this cover."
        ],
        [
            "Condition connection in these are from the top rope here that there is normal working condition.",
            "Then there is a person working with the bag and then the person with the code on.",
            "Then there is that condition with different shoes, bare feet and then slow and fast working and here we hear that OK during the gate cycle there are there is one global motion in a single direction.",
            "Then there are different relative independent motions in different direction.",
            "For example the legs are moving the arm you're moving so there is so much info."
        ],
        [
            "And in that we want to capture.",
            "So how does the existing work cope with that?",
            "The existing work?",
            "The state of the art, is the gate energy image and it will embalming hero 6 and it is basically a motion intensity representation of gate over a complete cycle and similar is the motion killer image.",
            "The Humala representation both of these representations are very good representation and compact.",
            "But the problem with them is that if the appearance changes, for example in the carrying condition or the clothing condition and then they suffer a lot.",
            "So how do they actually be the shape variation based free patterns try to address that problem by subtracting the shape.",
            "Of the representation.",
            "So what they do is they have keyframe.",
            "Can they subtract the keyframes from the gate representation and they have representation which is which behaves very well and their under shape changes.",
            "For example the back loading condition and the carrying condition.",
            "But the problem with that is under normal condition it does not perform that well.",
            "So then there is this representation based on motion.",
            "He had control templates and static still hurt templates, so this representation is actually representing gate using two descriptors.",
            "One is trying to represent the dynamic content of gate, the MCT and the SSD is trying to represent the static content of gate.",
            "But the problem with MSIT is that the same problem if the person is carrying a bag then these controls would be different.",
            "And we have actually not been able to do what we wanted to do, that they get rid of that bag somehow.",
            "And history is not descriptive enough so.",
            "The existing representations are based on motion intensity, which is not a bad thing, which is alright.",
            "As we said earlier, the gate is.",
            "There are too many independent motions in different directions, but none of these representation actually tried to capture that motion direction information.",
            "And some of these actually show are not descriptive enough.",
            "So how do we solve this problem?",
            "Our solution is."
        ],
        [
            "A novel representation of gate and how we construct that.",
            "We construct that from the optical flow field.",
            "Optical flow field computations and in our representation.",
            "We use the same idea if we can get you can shape descriptor, answer motion descriptors and why do we have some motion descriptors?",
            "Because we.",
            "And include the notion of direction in there.",
            "So we have motion in different directions and this is the overall approach that we use.",
            "We have a great video."
        ],
        [
            "Sequence background subtraction mixture model.",
            "We extract the foreground.",
            "The person in there.",
            "Then we do a killer extraction normalization procedure to get that black and White Hill hurt.",
            "Then we use it as a mask to extract that textured killer because we will be computing optical flow so.",
            "Then the gate.",
            "Is estimated.",
            "There have a bit of derivative off, yet on the optical flow it should be on that arrow.",
            "Here, optical flow is computed, and from this optical flow field we get this representation of gate which is the top one is the motion intensity image.",
            "The Mii which is actually representing the shape of gate over a complete cycle and then we have the MX slash legal motion, direction, direction descriptors.",
            "Let's see how we get them."
        ],
        [
            "We got them from discrete allegation of optical flow.",
            "The optical flow field, thresholded, and the.",
            "If the magnitude of flow is less than a certain threshold Theta, then the flow direction is not reliable and also we need to generate a shape descriptor so in that case what we do is we have actually.",
            "Initialized five wins at each image location and what we do is we put, we increment the image location corresponding, increment the bin corresponding to the shape descriptor, which is M and if the flow magnitude is created in theater or equal to Theta, then what we do is we look at the flow direction and in that case we increment the corresponding bin and that is done for complete gate.",
            "And then what we do is we normalize to get.",
            "The motion intensity image, which looks like this.",
            "And we normalize to get the motion direction images, normalize over complete gate.",
            "That means so that is the motion, motion, direction, images and here we see that the downward direction that there is not much information in there and this is what we expected, because engaged there is not much downward motion.",
            "There is no pronounced downward motion during a gate sequence.",
            "And the."
        ],
        [
            "Let's have a look at them under different conditions.",
            "For example, the top row shows the target representation without the downward direction descriptor under normal conditions, and the middle one is the carrying condition and the bottom is the clothing condition.",
            "So what we see here is that the motion the shape descriptor, the Mii is changing a lot because there is shape change in these three scenarios, but are.",
            "Motion direction descriptors are showing less change because there is not much change in the in the dynamics of gate, so that is what the image what was our aim.",
            "The aim was to represent gate using a set of descriptors that are sensitive to different covariate conditions and a Fusion of them give you a representation that is insensitive to most covariate conditions."
        ],
        [
            "So how do we do recognition then?",
            "We have this motion intensity image.",
            "These motion direction descriptors and each of them go on their separate independent path and we use component and discriminant analysis.",
            "That is simple technique based on PCA and MDA to get the dissimilarity scores.",
            "And from there we fuse the coach together using the simple equation written over there and where Lambda is the weight of how much the Mii and how much of the motion direction images we need in there.",
            "And then there is a decision here."
        ],
        [
            "Look at the results that we got.",
            "The results for the here Sia that I said which is of 124 individual can capture scale from normal carrying condition and clothing condition and what we see is that OK the TM means the template matching records published by the state of the Art Gate Energy Magical state of the art and the results we get over there.",
            "M as our motion intensity image and then MX plus M X -- Y plus our motion direction descriptors and then.",
            "Even if the result of Fusion of MM X + M X&Y, using our equation on the previous page.",
            "So what we hear that when they're under under normal conditions, the motion intensity image is giving us very good results, similar to get an edge image 99.4 version and the Fusion is a little bit worse than that's 97.5%.",
            "When the person Russia bag that is under the carrying condition, we hear that the results are very good for Fusion and that 83.6% and none of the other is greater than 60%.",
            "So that is very good.",
            "That is what we are aiming for.",
            "We are aiming for.",
            "Get representation that can perform well under different covered conditions.",
            "The last one is wearing the code and here we see that.",
            "The motion intensity image.",
            "So much degradation, 14.8%.",
            "That is because there is much shape change over there, but the motion direction images MX plus shows very good results 59%.",
            "And overall you also not bad 48.8% and when we hit overall results for this data set we see that OK, we've got 76.6% and that is better than what we had before and there is a significant improvement over there.",
            "That is what we see."
        ],
        [
            "The others we tested it on another data set and the health Hampton large data set A&E.",
            "The difference between A&E is that a structured windows and each captured outdoors.",
            "And we see that the result.",
            "On the on the top table, the result is for our technique and the Fusion gives 99.1% and then there is some published results for the heat on large data set and we see that we are right up there and then for the short on large data set E we see that.",
            "The result is also 97.4 by confusion, but an interesting thing to notice that the motion intensity image gives us very good results over there 100%, and the recognition that and the motion direction images don't give us that.",
            "Under the direct direct 93.1% similar result, the reconnect at optical flow is noisy and an outdoor condition.",
            "We expect some noise and because we are for small directions for small value optical flow, we're just ignoring that direction, and we're just implementing the emotion intensity.",
            "Been so that is mostly robust to noise and we get good results over the."
        ],
        [
            "And then we have the short and small that I had.",
            "This data set has conditions that affect both gated shelves and the feature is affected from gate that it has the carrying condition.",
            "The clothing conditioned issues which affect gated shelf and the speed of gate slow or fast working.",
            "And here we see that I our method is doing great and.",
            "But particularly, we look at the short and small cat SH.",
            "The 3rd row from the bottom and the short and small set as the 2nd row from the bottom.",
            "These are conditions where gate change itself, and here we see that M the motion intensity image gives us very good result and there is some degradation in the motion direction.",
            "Image is actually expected and the Fusion actually correct it."
        ],
        [
            "And actually this is that is all for it.",
            "And in summary, we are proposing a great representation based on optical flow computation and the information is captured in a set of motion descriptors and each descriptor have different sensitivity to different conditions and their Fusion gives us representation that is not only discriminative but also but also less sensitive to covert condition changes and.",
            "That is all."
        ],
        [
            "No, we didn't try any other way of combining.",
            "The only the only Fusion team that we used was the addition of.",
            "To disrupt the motion intensity distributor in the motion direction disrupted."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi there, my name is Holly here and I've been working with the talk young in Chenggong in Queen Mary, University of London.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's go down straight down to the problem.",
                    "label": 0
                },
                {
                    "sent": "The problem is to improve the performance of Kate recognition under different covariate conditions.",
                    "label": 1
                },
                {
                    "sent": "So what age, guys recognition by the way gait recognition is recognizing people by the way they walk, so it is recognizing people by their gate.",
                    "label": 1
                },
                {
                    "sent": "And why is this important?",
                    "label": 0
                },
                {
                    "sent": "It's important cause gait recognition is non intrusive as compared to other physiological biometrics such as face, fingerprint, iris.",
                    "label": 0
                },
                {
                    "sent": "They all require close proximity subjects and.",
                    "label": 0
                },
                {
                    "sent": "Kim cooperation as well, and that's the other thing.",
                    "label": 1
                },
                {
                    "sent": "Gate operates at a distance without subject Corporation.",
                    "label": 0
                },
                {
                    "sent": "This is what makes it very useful.",
                    "label": 0
                },
                {
                    "sent": "And that's why people have been studying it and up till now.",
                    "label": 0
                },
                {
                    "sent": "It thinks that everything about gate is great so but there is another side to it.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And that is covered.",
                    "label": 0
                },
                {
                    "sent": "Conditions gate of ahem, person changing under different conditions.",
                    "label": 0
                },
                {
                    "sent": "And these conditions are lifted over there and they can.",
                    "label": 0
                },
                {
                    "sent": "They get off two types, one stalk effect.",
                    "label": 0
                },
                {
                    "sent": "The features extracted from gate captures the carrying condition.",
                    "label": 1
                },
                {
                    "sent": "The glowing condition in the view.",
                    "label": 1
                },
                {
                    "sent": "And there are other sexual catches, shoe time, injury and speed and that affect how that affect gated shelf.",
                    "label": 0
                },
                {
                    "sent": "And there is 1 missing over there.",
                    "label": 0
                },
                {
                    "sent": "The mood of the person also changes the way you walk.",
                    "label": 0
                },
                {
                    "sent": "And let's have this cover.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Condition connection in these are from the top rope here that there is normal working condition.",
                    "label": 0
                },
                {
                    "sent": "Then there is a person working with the bag and then the person with the code on.",
                    "label": 0
                },
                {
                    "sent": "Then there is that condition with different shoes, bare feet and then slow and fast working and here we hear that OK during the gate cycle there are there is one global motion in a single direction.",
                    "label": 0
                },
                {
                    "sent": "Then there are different relative independent motions in different direction.",
                    "label": 0
                },
                {
                    "sent": "For example the legs are moving the arm you're moving so there is so much info.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And in that we want to capture.",
                    "label": 0
                },
                {
                    "sent": "So how does the existing work cope with that?",
                    "label": 1
                },
                {
                    "sent": "The existing work?",
                    "label": 0
                },
                {
                    "sent": "The state of the art, is the gate energy image and it will embalming hero 6 and it is basically a motion intensity representation of gate over a complete cycle and similar is the motion killer image.",
                    "label": 0
                },
                {
                    "sent": "The Humala representation both of these representations are very good representation and compact.",
                    "label": 0
                },
                {
                    "sent": "But the problem with them is that if the appearance changes, for example in the carrying condition or the clothing condition and then they suffer a lot.",
                    "label": 0
                },
                {
                    "sent": "So how do they actually be the shape variation based free patterns try to address that problem by subtracting the shape.",
                    "label": 0
                },
                {
                    "sent": "Of the representation.",
                    "label": 0
                },
                {
                    "sent": "So what they do is they have keyframe.",
                    "label": 0
                },
                {
                    "sent": "Can they subtract the keyframes from the gate representation and they have representation which is which behaves very well and their under shape changes.",
                    "label": 0
                },
                {
                    "sent": "For example the back loading condition and the carrying condition.",
                    "label": 0
                },
                {
                    "sent": "But the problem with that is under normal condition it does not perform that well.",
                    "label": 0
                },
                {
                    "sent": "So then there is this representation based on motion.",
                    "label": 1
                },
                {
                    "sent": "He had control templates and static still hurt templates, so this representation is actually representing gate using two descriptors.",
                    "label": 0
                },
                {
                    "sent": "One is trying to represent the dynamic content of gate, the MCT and the SSD is trying to represent the static content of gate.",
                    "label": 0
                },
                {
                    "sent": "But the problem with MSIT is that the same problem if the person is carrying a bag then these controls would be different.",
                    "label": 0
                },
                {
                    "sent": "And we have actually not been able to do what we wanted to do, that they get rid of that bag somehow.",
                    "label": 0
                },
                {
                    "sent": "And history is not descriptive enough so.",
                    "label": 0
                },
                {
                    "sent": "The existing representations are based on motion intensity, which is not a bad thing, which is alright.",
                    "label": 1
                },
                {
                    "sent": "As we said earlier, the gate is.",
                    "label": 0
                },
                {
                    "sent": "There are too many independent motions in different directions, but none of these representation actually tried to capture that motion direction information.",
                    "label": 0
                },
                {
                    "sent": "And some of these actually show are not descriptive enough.",
                    "label": 0
                },
                {
                    "sent": "So how do we solve this problem?",
                    "label": 0
                },
                {
                    "sent": "Our solution is.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A novel representation of gate and how we construct that.",
                    "label": 1
                },
                {
                    "sent": "We construct that from the optical flow field.",
                    "label": 0
                },
                {
                    "sent": "Optical flow field computations and in our representation.",
                    "label": 0
                },
                {
                    "sent": "We use the same idea if we can get you can shape descriptor, answer motion descriptors and why do we have some motion descriptors?",
                    "label": 0
                },
                {
                    "sent": "Because we.",
                    "label": 0
                },
                {
                    "sent": "And include the notion of direction in there.",
                    "label": 0
                },
                {
                    "sent": "So we have motion in different directions and this is the overall approach that we use.",
                    "label": 0
                },
                {
                    "sent": "We have a great video.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sequence background subtraction mixture model.",
                    "label": 1
                },
                {
                    "sent": "We extract the foreground.",
                    "label": 0
                },
                {
                    "sent": "The person in there.",
                    "label": 0
                },
                {
                    "sent": "Then we do a killer extraction normalization procedure to get that black and White Hill hurt.",
                    "label": 0
                },
                {
                    "sent": "Then we use it as a mask to extract that textured killer because we will be computing optical flow so.",
                    "label": 0
                },
                {
                    "sent": "Then the gate.",
                    "label": 0
                },
                {
                    "sent": "Is estimated.",
                    "label": 0
                },
                {
                    "sent": "There have a bit of derivative off, yet on the optical flow it should be on that arrow.",
                    "label": 1
                },
                {
                    "sent": "Here, optical flow is computed, and from this optical flow field we get this representation of gate which is the top one is the motion intensity image.",
                    "label": 0
                },
                {
                    "sent": "The Mii which is actually representing the shape of gate over a complete cycle and then we have the MX slash legal motion, direction, direction descriptors.",
                    "label": 0
                },
                {
                    "sent": "Let's see how we get them.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We got them from discrete allegation of optical flow.",
                    "label": 0
                },
                {
                    "sent": "The optical flow field, thresholded, and the.",
                    "label": 1
                },
                {
                    "sent": "If the magnitude of flow is less than a certain threshold Theta, then the flow direction is not reliable and also we need to generate a shape descriptor so in that case what we do is we have actually.",
                    "label": 0
                },
                {
                    "sent": "Initialized five wins at each image location and what we do is we put, we increment the image location corresponding, increment the bin corresponding to the shape descriptor, which is M and if the flow magnitude is created in theater or equal to Theta, then what we do is we look at the flow direction and in that case we increment the corresponding bin and that is done for complete gate.",
                    "label": 0
                },
                {
                    "sent": "And then what we do is we normalize to get.",
                    "label": 0
                },
                {
                    "sent": "The motion intensity image, which looks like this.",
                    "label": 1
                },
                {
                    "sent": "And we normalize to get the motion direction images, normalize over complete gate.",
                    "label": 0
                },
                {
                    "sent": "That means so that is the motion, motion, direction, images and here we see that the downward direction that there is not much information in there and this is what we expected, because engaged there is not much downward motion.",
                    "label": 0
                },
                {
                    "sent": "There is no pronounced downward motion during a gate sequence.",
                    "label": 0
                },
                {
                    "sent": "And the.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let's have a look at them under different conditions.",
                    "label": 1
                },
                {
                    "sent": "For example, the top row shows the target representation without the downward direction descriptor under normal conditions, and the middle one is the carrying condition and the bottom is the clothing condition.",
                    "label": 0
                },
                {
                    "sent": "So what we see here is that the motion the shape descriptor, the Mii is changing a lot because there is shape change in these three scenarios, but are.",
                    "label": 0
                },
                {
                    "sent": "Motion direction descriptors are showing less change because there is not much change in the in the dynamics of gate, so that is what the image what was our aim.",
                    "label": 0
                },
                {
                    "sent": "The aim was to represent gate using a set of descriptors that are sensitive to different covariate conditions and a Fusion of them give you a representation that is insensitive to most covariate conditions.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how do we do recognition then?",
                    "label": 0
                },
                {
                    "sent": "We have this motion intensity image.",
                    "label": 0
                },
                {
                    "sent": "These motion direction descriptors and each of them go on their separate independent path and we use component and discriminant analysis.",
                    "label": 0
                },
                {
                    "sent": "That is simple technique based on PCA and MDA to get the dissimilarity scores.",
                    "label": 0
                },
                {
                    "sent": "And from there we fuse the coach together using the simple equation written over there and where Lambda is the weight of how much the Mii and how much of the motion direction images we need in there.",
                    "label": 0
                },
                {
                    "sent": "And then there is a decision here.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Look at the results that we got.",
                    "label": 0
                },
                {
                    "sent": "The results for the here Sia that I said which is of 124 individual can capture scale from normal carrying condition and clothing condition and what we see is that OK the TM means the template matching records published by the state of the Art Gate Energy Magical state of the art and the results we get over there.",
                    "label": 1
                },
                {
                    "sent": "M as our motion intensity image and then MX plus M X -- Y plus our motion direction descriptors and then.",
                    "label": 0
                },
                {
                    "sent": "Even if the result of Fusion of MM X + M X&Y, using our equation on the previous page.",
                    "label": 0
                },
                {
                    "sent": "So what we hear that when they're under under normal conditions, the motion intensity image is giving us very good results, similar to get an edge image 99.4 version and the Fusion is a little bit worse than that's 97.5%.",
                    "label": 0
                },
                {
                    "sent": "When the person Russia bag that is under the carrying condition, we hear that the results are very good for Fusion and that 83.6% and none of the other is greater than 60%.",
                    "label": 0
                },
                {
                    "sent": "So that is very good.",
                    "label": 0
                },
                {
                    "sent": "That is what we are aiming for.",
                    "label": 0
                },
                {
                    "sent": "We are aiming for.",
                    "label": 0
                },
                {
                    "sent": "Get representation that can perform well under different covered conditions.",
                    "label": 0
                },
                {
                    "sent": "The last one is wearing the code and here we see that.",
                    "label": 0
                },
                {
                    "sent": "The motion intensity image.",
                    "label": 0
                },
                {
                    "sent": "So much degradation, 14.8%.",
                    "label": 0
                },
                {
                    "sent": "That is because there is much shape change over there, but the motion direction images MX plus shows very good results 59%.",
                    "label": 0
                },
                {
                    "sent": "And overall you also not bad 48.8% and when we hit overall results for this data set we see that OK, we've got 76.6% and that is better than what we had before and there is a significant improvement over there.",
                    "label": 0
                },
                {
                    "sent": "That is what we see.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The others we tested it on another data set and the health Hampton large data set A&E.",
                    "label": 0
                },
                {
                    "sent": "The difference between A&E is that a structured windows and each captured outdoors.",
                    "label": 0
                },
                {
                    "sent": "And we see that the result.",
                    "label": 0
                },
                {
                    "sent": "On the on the top table, the result is for our technique and the Fusion gives 99.1% and then there is some published results for the heat on large data set and we see that we are right up there and then for the short on large data set E we see that.",
                    "label": 0
                },
                {
                    "sent": "The result is also 97.4 by confusion, but an interesting thing to notice that the motion intensity image gives us very good results over there 100%, and the recognition that and the motion direction images don't give us that.",
                    "label": 0
                },
                {
                    "sent": "Under the direct direct 93.1% similar result, the reconnect at optical flow is noisy and an outdoor condition.",
                    "label": 0
                },
                {
                    "sent": "We expect some noise and because we are for small directions for small value optical flow, we're just ignoring that direction, and we're just implementing the emotion intensity.",
                    "label": 0
                },
                {
                    "sent": "Been so that is mostly robust to noise and we get good results over the.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we have the short and small that I had.",
                    "label": 0
                },
                {
                    "sent": "This data set has conditions that affect both gated shelves and the feature is affected from gate that it has the carrying condition.",
                    "label": 0
                },
                {
                    "sent": "The clothing conditioned issues which affect gated shelf and the speed of gate slow or fast working.",
                    "label": 0
                },
                {
                    "sent": "And here we see that I our method is doing great and.",
                    "label": 0
                },
                {
                    "sent": "But particularly, we look at the short and small cat SH.",
                    "label": 0
                },
                {
                    "sent": "The 3rd row from the bottom and the short and small set as the 2nd row from the bottom.",
                    "label": 0
                },
                {
                    "sent": "These are conditions where gate change itself, and here we see that M the motion intensity image gives us very good result and there is some degradation in the motion direction.",
                    "label": 0
                },
                {
                    "sent": "Image is actually expected and the Fusion actually correct it.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And actually this is that is all for it.",
                    "label": 0
                },
                {
                    "sent": "And in summary, we are proposing a great representation based on optical flow computation and the information is captured in a set of motion descriptors and each descriptor have different sensitivity to different conditions and their Fusion gives us representation that is not only discriminative but also but also less sensitive to covert condition changes and.",
                    "label": 1
                },
                {
                    "sent": "That is all.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "No, we didn't try any other way of combining.",
                    "label": 0
                },
                {
                    "sent": "The only the only Fusion team that we used was the addition of.",
                    "label": 0
                },
                {
                    "sent": "To disrupt the motion intensity distributor in the motion direction disrupted.",
                    "label": 0
                }
            ]
        }
    }
}