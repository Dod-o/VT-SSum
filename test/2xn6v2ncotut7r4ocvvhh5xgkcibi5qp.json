{
    "id": "2xn6v2ncotut7r4ocvvhh5xgkcibi5qp",
    "title": "Gaussian Processes and Gene Regulation",
    "info": {
        "author": [
            "Neil D. Lawrence, Department of Computer Science, University of Sheffield"
        ],
        "published": "Oct. 14, 2010",
        "recorded": "September 2010",
        "category": [
            "Top->Computer Science->Machine Learning->Gaussian Processes"
        ]
    },
    "url": "http://videolectures.net/prib2010_lawrence_gpg/",
    "segmentation": [
        [
            "So thanks very much for the invite to be here.",
            "I I should have in some sense I had an urge to give a longer tutorial than than time allows for, and I tried to stem that urge.",
            "So I've tried to sort of show a bit about.",
            "I don't know how many people have seen Gaussian processes before in the audience.",
            "OK, so a few OK everyone so I can come to know.",
            "So I tried to give sort of a soft overview of Gaussian process is and then also a bit of an overview of our philosophy of what we're trying to do.",
            "In combining these methods with the mechanistic models and how we're trying to apply that to transcriptional regulation, but I think it has other applications and wider implications for sort of machine learning in general or pattern RECOGN."
        ],
        [
            "And in general.",
            "OK, so quick outline of the talk.",
            "I'll give a bit of motivation and then this probabilistic model for this function is going to be Gaussian process and then I'll give an example on these cascaded differential equation models for transcription.",
            "Anne."
        ],
        [
            "That'll mainly be it.",
            "I should mention people that so this is really it's a tutorial, but it's almost a guide to our recent work to feel slightly guilty about.",
            "Rather 'cause tutorials should really be about everyone's work.",
            "But Gaussian processes are widely used and have lots of applications.",
            "Beyond that, our work as well so I feel less guilty for that reason, so I have to acknowledge the people that have contributed to the sort of things I'm going to show today.",
            "So I work very closely with Magnus Rattray, who's also moved from Manchester to Sheffield.",
            "Pai Gow was postdoc who worked on early variants of this model, anti hunkeler from Aalto University, formerly Helsinki University of Technology, visited us a lot and spent a lot of time working on these models.",
            "A lot of the results have come from his coding.",
            "Guido Sanquenetti was an earlier post Doc Underground work with us on some of the earlier stuff on this and Jennifer with us was a PhD student with."
        ],
        [
            "Agnes."
        ],
        [
            "So I read this paper actually and I was quite struck by this idea.",
            "Can a biologist fix a radio lays make?",
            "I don't necessarily agree with everything in it, but it's about the case for systems biology, which perhaps I don't need to sell to this audience.",
            "But the idea is that you should move well kind of biologist, fix a radio can by using the techniques people are using in biology.",
            "You go in and work out how radio is going to work.",
            "So if you just go and destroy a circuit in a radio.",
            "Does that help you learn how the radio is working?",
            "And obviously it doesn't.",
            "I mean, in some sense, the analogy I think maybe it was, it's a good analogy in a broad sense, but it's also bad analogy, because biological systems are much more robust than radios are, but he does have this phrase in the paper, which is an old saying from some country or another that it's difficult to find a black cat in a dark room, especially if there's no cat.",
            "I don't quite know what that mean."
        ],
        [
            "Means but one thing you could take it to mean is that biological systems are sort of very, very calm."
        ],
        [
            "Allocated and end in this paper lays makes I arguing the need for models that are."
        ],
        [
            "Quantitative and these models should be predictive of biological behave."
        ],
        [
            "Asia and.",
            "These need to be combined with biological data.",
            "So what I what this is?"
        ],
        [
            "Leading to is what I think of systems biologists are combining this with my only.",
            "My background in machine learning I think of systems biology is traditionally it.",
            "Let's build mechanistic models based on biochemical knowledge of the system."
        ],
        [
            "And then what we try and do is identify modules and submodules and parameterized these modules.",
            "So in the biologist fixing radio analogy, the modules in the submodules are.",
            "I don't know the tuning system and the various components of the radio, and then try and walk out the parameters of these models are undescribed biological."
        ],
        [
            "System that way.",
            "So I think to an extent what a lot of us may have been involved in is maybe more computational biology.",
            "So the case for computational biology, and I give an example which would be the Co regulation of gene expression.",
            "So if we've got gene expression data from a biological system, what we typically may be interested in is actually transcriptional regulation.",
            "So I'm particularly will think of time series.",
            "If I think of gene expression data.",
            "So we might have a time series of developmental system where we've observed the gene expression at.",
            "I don't know early time points for perhaps seven time points and what we're interested in is from this time service.",
            "What can we say about the regulatory structures that?",
            "Are involved in development, so I think of this is a data exploration problem.",
            "We've got some data and we want to find something out about it.",
            "You can use the gene expression data to speculate on which a Co regulated genes and traditionally sort of very early on people started using clustering for this sort of thing.",
            "So you sort of try and find gene expressions that cluster together and then you hypothesize that they might be Co regulated.",
            "You give them back to the biologist and he gets very excited because one of the clusters make sense and then he starts doing some literature and he might do some knockouts.",
            "But you can contrast that sort of clustering approach with this sort of computational systems biology approach, which would be to create a detailed mechanistic model of the system, and then fit the parameters of this model to the data.",
            "So you create a mechanistic model that is described in these biochemical relationships and then you fit these kinetic parameters to the data.",
            "That's going to be quite problematic for very large datasets because you have to have a mechanistic all that describes everything that's going on to the cell, which in some sense is the end goal of all of this work, and it's going to be very difficult and you don't have enough data to actually fit all the parameters of that model.",
            "Another thing is that you need to deal with, say, an observed by a chemical species, because in an ideal world.",
            "We would observe every profile available in the system.",
            "All the gene expression.",
            "But then a transcriptional network.",
            "This protein expression as well.",
            "But of course in practice the protein expression is quite difficult to measure, so there are these things going on in the system that you're not even observing."
        ],
        [
            "OK, so general approach so broadly speaking I would like to summarize there's two approaches to modeling data or to modeling, not modeling data I should say, But modeling this situation that I."
        ],
        [
            "Sort of briefly talked about in data modeling, which is the sort of computational biology clustering approach we let the data."
        ],
        [
            "Speak.",
            "Whereas in mechanistic modeling, this systems biology approach, we might impose mechanistic rules on our data, force it to conform, yes.",
            "So.",
            "As soon as we have labels or is also available data, you may not even have data.",
            "So you actually have a mechanistic modeling in the way.",
            "It's sometimes practice.",
            "You know, you know, you just build a mechanism of the data and then and often you see talks where they might write down the mechanism of the data, and then they might show some simulations from the model, and then they might plot actually what you see in the data, and so broadly speaking, the same, so you never actually do a data fit.",
            "You say look, it oscillates the period somewhat similar, so you may not.",
            "In this case you may not even be looking at data.",
            "Typically you would, I mean.",
            "What I would sort of argue is that, well, that's perhaps a longer talk.",
            "In some sense, well, let me finish this slide and I'll come back to that other little."
        ],
        [
            "So in this data modeling we might have computational models, by which I mean sort of things like PCA, data driven models, support vector machines, classification things, things which are just sort of allowing the data."
        ],
        [
            "Fit the model and these are systems MoD."
        ],
        [
            "It's based on here.",
            "Would you be?"
        ],
        [
            "Adaptive things and here we have differential equations, so here you got very flexible adaptive activity and here you've got differential equations, so we're actually very constraining once you observe one profile, say at the top of the differential equation, everyone else everything."
        ],
        [
            "This is determined.",
            "So examples here would be principal component."
        ],
        [
            "Analysis, clustering and examples.",
            "He Ristic ostick differential equation, ordinary differential equation models OK. One of these two bumps here.",
            "So, relating back to this point, so these two bumps are supposed to be my schematic of the amount of activity in these two areas.",
            "So what I'm saying is, there's actually a spectrum, So what your point about data and where do you get?",
            "How do you combine the messaging and mechanistic models with the data?",
            "So at one end you're completely ignoring data, almost just based on prior knowledge or your knowledge of the physics and at the other end you're sort of ignoring mechanistic and justice working with data.",
            "OK, the truth is somewhere in between, because people use a little bit of data to fit some of the parameters.",
            "They might do an experiment.",
            "A separate experiment just to fit a parameter.",
            "And people suggest that in systems biology, let's find the decay rate of this thing in vitro and then use that here.",
            "Actually, the assumptions underlying these things and these assumptions can be equated to physical models of some type extreme versions.",
            "But my main argument is that there's a gap here that there's a problem.",
            "If I tell you I'm working with differential equations, you're all very good at posterior inference, and you know about this likelihood here, so you immediately assume I'm doing mechanistic modeling.",
            "And if I tell you I'm I'm analyzing large amounts of data, you do the same thing, and you assume I'm going to be doing PCA or clustering.",
            "And my main argument is actually we should be in here that that's what these methods which relates to the question earlier.",
            "That's what these methods.",
            "Should be applied to an if you go all the way back to the first person to write down, well, let's say the most famous person to write down a mechanistic model of the universe, which was Newton sort of 200 and something years ago, right.",
            "He wrote down a mechanistic model not really inspired by data.",
            "But then Gauss came along and fitted this mechanistic model to the orbit of series as it goes around, then predicted where it was going to be.",
            "I don't have pronounced series or cherries.",
            "Whatever the dwarf planet and Gauss became famous because of that, and he was combining domestic.",
            "Mechanistic model with the data model.",
            "Of course he had a lot of work to do.",
            "His data fit and we have computers to do that today.",
            "What he had, which was very nice, was a very accurate, mechanistic model that really reflected the system he was studying.",
            "Where is today?",
            "We perhaps have more complex systems, an idea of the mechanistic model will be perhaps less good, so the quality of our mechanistic model as a representation of our system will be less accurate.",
            "An I think that means even more that we have to be in this region that this split is artificial."
        ],
        [
            "And I'll argue that a little little bit further.",
            "So what I would say is that we should be looking at approach between systems and computational biology.",
            "Hum and issues aspects of systems biology to the computational approach 'cause I really come more from this background.",
            "The computational approach.",
            "So I think of bringing this into that, but you Conversely could be a systems person who wanted to introduce computational ideas more.",
            "Computation ideas systems approach, so there's computational penalty.",
            "These models tend to be slower.",
            "They can deal with less data.",
            "That's what I mean by slower, but it may be worth paying.",
            "Ideally, there should be a sort of smooth transition from pure computational.",
            "These sort of methods to complete systems nonlinear stochastic differential equations.",
            "And this sort of stuff that I'll be talking about, which is going to include these Gaussian process, is one part of that transition.",
            "So."
        ],
        [
            "Let me give the background to the example which actually inspired all this work, which is by a guy called Martino Barranco and Mike Eubank and a few others at UCL Institute of Child Health, which was a P53 radiation damage.",
            "So radiation damage in cells so radiation can damage molecules including DNA, and in this case could be ultraviolet radiation or any type of radiation, and this is normally quickly prepared.",
            "So if it's a single strand break in your DNA, but double strand breaks into the more serious you can get these complete disconnects, and in particular.",
            "If the cell is not dividing, then you have a problem because you don't have a copy of the original DNA and you need to decide."
        ],
        [
            "But to do So what you actually do is you activate P 53.",
            "Which is responsible for, well, it's responsible for repairing DNA damage and activates DNA repair proteins.",
            "It also pauses the cell cycle to stop the cell dividing while this is going on and it starts trying to kill the cell.",
            "So it does this by sort of overtime.",
            "The more P 53 is in the cell, the more likely the cell is to undergo cell death.",
            "If you like spending a lot of time, a time in the sun on your skin is quite fair.",
            "Your skin will age prematurely and what's going on is that P. 53 is causing apoptosis of your skin because it's being damaged by ultraviolet radiation."
        ],
        [
            "And so I just like these pictures.",
            "These David S good self molecule of the month.",
            "So I think it looks a bit like the Flying Spaghetti Monster which any of you know is a sort of pseudo religious figure.",
            "But I think that there's I'm not.",
            "It's not completely clear what's going on here, but this is the structure of P53 and this is it binding to the DNA in order to."
        ],
        [
            "Recruit.",
            "Sort of just.",
            "Check transcription and here it is another one.",
            "It looks a bit like the Flying Spaghetti Monster here and it's recruiting.",
            "Transcriptase to produce."
        ],
        [
            "M RNA.",
            "So here's some known P53 targets.",
            "So this is an example of sort of modeling we might be interested in.",
            "We've got some knowledge that this is an actual target of P53 DNA damage.",
            "Specific DNA binding protein.",
            "Associated with repair, this is.",
            "I think this is a regulator of cell cycle progression, so it's pausing the cell cycle.",
            "This is pausing the cell cycle.",
            "This is killing the cell and this is killing the cells, so these are all targets of P53.",
            "They will become activated when P. 53.",
            "Actually P 53 is phosphorylated and becomes active and starts."
        ],
        [
            "Transcribing causing these to be transcribed.",
            "So we got this is a model by Barranco.",
            "This is also the barrancos work, the P53 targeting these sort of five things and the idea is you got this little network motif.",
            "So this is a known transcriptional network structurally known."
        ],
        [
            "And what we want to do is in the standard approach, we might assume that Co regulated genes are going to cluster in the same group.",
            "So what we'll do is we'll do a gene expression will do, will initiate.",
            "P53 will do a time series of gene expression will have all these gene expression levels for the bunch of these targets, and we will assume that any Co regulated dreams are going to be in the same cluster, so will perform the clustering.",
            "Then we'll look for clusters containing these jeans, and then we'll assume that those clusters are being regulated.",
            "For P53 those are candidates, and we look for confirmation literature.",
            "That's the comp."
        ],
        [
            "Initational approach.",
            "This is what Barranco sort of suggested doing, which is I like it because it's clearly an inaccurate differential equation model, but it's still going to get you somewhere beyond the computational approach.",
            "So Barranco says, well, let's look at the rate of transcription.",
            "As being given by a base transcription rate, so there's a constant transcription in the absence of anything else plus the sensitivity that green.",
            "You might not be able to see it there, so that's a sensitivity to the transcription factor concentration.",
            "So this is all activity, let's say.",
            "So the transcription factor activity is here F of T and if it's higher than the rate of transcription of P53 will be high.",
            "And then there's a decay on the target gene.",
            "the M RNA of the target gene which is given by this term here.",
            "So the idea is that we've got observations of XJ of T this thing here from Genik."
        ],
        [
            "Oppression and what Barranco sort of said, is, well, let's reorganize this equation and then here we've sort of gotten.",
            "This is known.",
            "This the transcription factor concentration activity is unknown 'cause you can't measure the protein.",
            "So you've got this also could be estimated by doing in sort of interpolation on this and estimating these gradients.",
            "You've got sort of knowns pseudo nones on this side, and you've got an unknown here.",
            "An unknown here and we should be dividing this side by do to get that unknown on there.",
            "So we've got unknowns there and knowns there."
        ],
        [
            "So he estimated then this gradient through fitting polynomials to the underlying gene expression."
        ],
        [
            "Temporal profiles and then he jointly estimated F of T, so he estimated at the time points of the observations.",
            "So he estimated discrete time intervals of F of T along with these."
        ],
        [
            "The parameters.",
            "And then he fits that by maximum likelihood.",
            "So or Martin."
        ],
        [
            "Chain Monte Carlo.",
            "So what's interesting about this is you can see that clustering in this model is equivalent to assuming Debian SJR very large because."
        ],
        [
            "If we do that, then this term here basically disappears and we can rearrange to say.",
            "We can rearrange to say that the M RNA level is equal to a an offset plus some sensitivity to the transcription factor.",
            "So what this is basically saying is what you see is the M RNA is a scaled and offset version of the transcription factor activity.",
            "So if you saw that for all your targets, then your targets would cluster because they're all going to look the same as the underlying transcription factor activity."
        ],
        [
            "So this suggests that jeans are all scaled and offset versions of that."
        ],
        [
            "Scription factor and by normalizing the data and clustering, we hope to find the transcription factors activity, and I think that's effectively what's going on.",
            "If you go and say to a biologist, well, let's do PCA.",
            "Let's do clustering.",
            "You're making this assumption.",
            "You're making the assumption that the K. Basel rate sensitivities are very high.",
            "So basically this gradient term disappears."
        ],
        [
            "So this is his paper."
        ],
        [
            "And I, I mean he wasn't talking about he wasn't making this point.",
            "That's sort of my point."
        ],
        [
            "But his paper."
        ],
        [
            "Is here and what he was able to do was estimate these parameters so these are the parameters for each of those jeans with some error bars and then he was fitting his differential equation model and getting these estimates of the activity profile for P53 so that through fitting the differential equation model and these are error bars for that.",
            "So these are results."
        ],
        [
            "From his his work and then this is a doing Western blot to actually determine the level of protein active protein and you get a sort of similar profile."
        ],
        [
            "File from the Western blot.",
            "OK, so I haven't said anything about Gaussian process so far, which may be a record for me in a talk to go whatever 20 minutes without mentioning Gaussian process is.",
            "So what I want to do is sort of.",
            "I've tried to motivate what's going to come next, but now I'm going to sort of talk just about Gaussian processes, so.",
            "What was?"
        ],
        [
            "Going on here is this thing is a missing variable and what Martine."
        ],
        [
            "Loaded in this slide is he sort of.",
            "He moved the knowns to one side and then the unknowns and."
        ],
        [
            "Other side what we're going to do is we're going to treat this missing variable.",
            "Probabilistically.",
            "It's a missing function, actually, so an obvious choice is."
        ],
        [
            "Something called the Gaussian process.",
            "So a probabilistic model for the function."
        ],
        [
            "F of T. So what's the Gaussian process?",
            "Well, let's think of Gaussian distributions.",
            "First, it makes life a lot easier multivariate Gaussian distributions.",
            "So a multivariate Gaussian distribution has this form.",
            "It's got this sort of quadratic form up here with the mean and then the covariance in this case is K, and there's the normalization.",
            "What we're going to do worry about is considering the special case where the.",
            "The mean is 0.",
            "Now this is completely sensible.",
            "To do this.",
            "I mean you can always put them back in, but it makes everything much easier if you do this actually as well, you can also put Gaussian priors over the mean, and if there's zero mean Gaussian priors over the mean, you would just end up with a form that looks like this anyway.",
            "So it's quite a general special case as it were where you've got a zero mean Gaussian process, the Gaussian distribution.",
            "So the only thing controlling this distribution is K, which will think of."
        ],
        [
            "As a covariance matrix.",
            "So what we're going to do is, we're going to think of a Gaussian distribution with a particular structure of covariance matrix, so it's a full covariance.",
            "It's not independent across it's going to be 25 dimensional Gaussian.",
            "It's not independent across these 25 dimensions.",
            "There's correlations expressed between all these 25 dimensions and what we're going to do is we're going to generate 1 sample from that Gaussian distribution.",
            "So I'm going to show you is 1 sample from the Gaussian distribution and pull up the points of that sample against their index.",
            "So that example is going to be a vector F. F1 to F-25 are going to be elements and will plot F1 to F-25 against."
        ],
        [
            "It's index.",
            "And this is what we see.",
            "So this on the right is the covariance matrix.",
            "Now it turns out to be a normalized covariance matrix.",
            "So the diagonal is 1, so it's also a correlation matrix.",
            "So what you see on the left is the one Gaussian sample from this covariance matrix.",
            "Now what's interesting is if you look at their plotted against their index.",
            "So this is index one and index two.",
            "And if you look at index one and index to the correlation is very high, nearly one.",
            "Yeah, so you see these two points, a sample very close together as you move away.",
            "So if we go from 1 to 15, so the correlation is 0.",
            "So actually that's up there.",
            "In fact this does look like it might be correlated with one, but it's just completely random.",
            "It's happened to go up.",
            "Back down again, so this well by the time you get out to what about seven data points?",
            "A7 indexes away.",
            "Sorry, not data points 7 steps away.",
            "There's sort of no correlation between there and there, But the interesting thing is that you know humans naturally look at this.",
            "This is just a discrete set of points, but you will naturally be thinking that looks like a smooth curve.",
            "I hope it does look like a smooth curve as we go along it.",
            "You can see that there's sort of nice smooth interpolation."
        ],
        [
            "OK, so the covariance matrix is showing the correlation, or in this case it's showing correlation as well between these two points.",
            "FI&FJ if I is new."
        ],
        [
            "TJ the strong correlation?",
            "There's less correlation if."
        ],
        [
            "Ryan J distant so the ordering of the points that we chose meant that this function appears smooth by plotting them along this index."
        ],
        [
            "This way.",
            "But what I want to do is get a bit more insight into that by focusing on the joint distribution of two points from the 25."
        ],
        [
            "So we're going to look at two points from those 25 points, and we're going to look at F1 and F2 an what I've shown here is actually the numerical values from that covariance matrix.",
            "So this is the upper left block that the correlation is very strong between F1 and F2.",
            "It's .966 that gets that would get a statistician very excited.",
            "If you saw that sort of correlation.",
            "F1F2 plotted here and here and then.",
            "This is 1 contour from the joint Gaussian density, so just sort of."
        ],
        [
            "Reminder for some of you about Gaussians, this is a correlation over 25 indices.",
            "If I want to marginalized 20, three of those and look at the correlation over the first 2 indicies, all I have to do is sort of put my can't reach it.",
            "But I have to just block out all these rows and columns that are not associated with the 1st and 2nd index and that gives me the marginal distribution.",
            "So it's a special nice property of Gaussians that I can get the marginal very easy.",
            "The marginals just associated with the covariance up here.",
            "So the covariance is very important and that sort of."
        ],
        [
            "Property is kind of unusual in distributions, so this is the marginal distribution of F1 and F2.",
            "Now the interesting thing is, what happens if we?"
        ],
        [
            "The conditional distribution.",
            "So let's say I observe F1 being here and then I condition on that object."
        ],
        [
            "Ovation of F1 that gives me this conditional distribution for F2.",
            "So what I get is F2 is negative as well, so the way you get that conditional is basically by projecting this Gaussian onto this line here.",
            "So what we see is if we have observed that F1 is well about in the minus .5 or something then we also get F2 is mean close to minus .5 but with some variance."
        ],
        [
            "If we were to look at more distant points F1 and F5."
        ],
        [
            "We can do."
        ],
        [
            "The same thing, but we get a much more diffuse situation, so there's some slight bias towards negative values for F2, but it's very very broad.",
            "So by looking at the conditioning you can see why you're getting so.",
            "Once I know for example."
        ],
        [
            "That F1 is here.",
            "That's telling me the broad range of distributions of F2 and then F5.",
            "So we see actually F5 manages to get all the way up there in that area.",
            "An F2 is there.",
            "So if you look at those conditional."
        ],
        [
            "Distributions you see under those conditional distributions, F2 is around here, which is very likely.",
            "You know that's quite within one standard deviation or something of the corresponding."
        ],
        [
            "Additional distribution."
        ],
        [
            "Five same thing is all the way up there actually, but it still wants that in deviation of the conditional distribution.",
            "So we can see how that's coming out and it's being determined by this weaker correlation here.",
            "That's coming from that covariance structure.",
            "So the basic message is all the information is."
        ],
        [
            "In that covariance structure?",
            "So where is this coming from?",
            "Well, this is this is a function that's called a lot of things, so some people call it a Gaussian, but some people don't like that 'cause it's not got a normalization.",
            "Some people call it squared exponential, and some people don't like that because it's not a squared exponential.",
            "Some people call it a radial basis function, and some people don't like that.",
            "'cause it reminds them of neural networks.",
            "So I decided I'd call it an exponentiated quadratic covariance function.",
            "Which is strictly speaking, accurate.",
            "So what you've got is is this form here.",
            "So we're building this structure.",
            "So let's think of T initially is the index and L is some scale.",
            "Some measure on this Euclidean distance.",
            "So is the Euclidean distance between these indexes increases?",
            "We basically get a smaller, larger distance away.",
            "This exponent is negative and large, and this thing tends towards 0 if the distance is 0, then this thing is zero.",
            "And the answer here is 1, so that's how well it.",
            "Alpha actually, but if we set Alpha to one, then that's how we're forming this matrix.",
            "So the covariance matrix is built using the inputs to the function T, so I've now started saying things like function because what I want you to think of is in first case it was a discrete Gaussian over 25 variables.",
            "What we're going to do is just replace that discrete index by a continuous index T. So that's a bit of a freaky operation if you've never seen it before, but.",
            "All you're saying is instead of having discrete inputs to form my covariance, I'm going to have continuous inputs so they're both 1 dimensional, so it's not freaky.",
            "From that perspective, it's just freaky 'cause this is a continuous number.",
            "So now we can ask about conditioning on this Gaussian distribution for between any two time points instead of any two indexes like we were looking at before, and we can sample.",
            "We can write down, we can ask to sample from a Gaussian distribution for a bunch of different.",
            "Time points which have now become."
        ],
        [
            "Rindex and if we do that sort of thing.",
            "So here I've made the time go from minus one to one.",
            "Obviously this looks like a continuous function, but I'm doing it in Matlab, so the way I'm doing this is by sampling like 400 points.",
            "So this is a 400 dimensional Gaussian."
        ],
        [
            "With time being input to create this code."
        ],
        [
            "Variance function and this being my output and I can sample all this.",
            "Each line is a different sample and they all look like curves, so I've set particular parameters.",
            "Here.",
            "I've set the length scale is .3 and this Alpha which controls the scale in the Y axis."
        ],
        [
            "To one, but I could change that length scale and make the length scale longer and you get slower varying functions."
        ],
        [
            "Who I can make that shorter again, an increase the vertical length scale or the vertical variants and then get functions that have?",
            "Go over a wider range."
        ],
        [
            "So actually if you look at these, you see these four within pretty much standard deviation of this thing.",
            "Here is 1 so they all fall approximately within 2 standard deviations of the mean, which is 0 because the mean function."
        ],
        [
            "Zero and the same here."
        ],
        [
            "Yeah."
        ],
        [
            "And here by making A4.",
            "The standard deviation is 2, so you get them falling between 4:00 and minus four, broadly speaking, so there's actual sensible.",
            "Physical interpretations of what these parameters are doing.",
            "There's this L has a sort of interpretation for number of crossings of the zero point that you expect in a particular interval."
        ],
        [
            "Here's another one, so this is a linear covariance function, so it's a covariance function, so one way of doing linear models is just to write down a linear model.",
            "Another is to do it by Gaussian process, and then you can sample from the Gaussian process and you see.",
            "Very oddly things coming out a linear functions, but everything is encoded in a covariance function.",
            "It's not immediately apparent that that's going to happen when you write down the."
        ],
        [
            "Variance function, but that is what happens.",
            "This is another one I like which doesn't have this tendency to stay around zero.",
            "It's sort of a covariance function that was derived by Chris Williams based on sort of neural network models.",
            "It has these parameters which have interpretations of.",
            "If you know about neural networks, sort of MLP neural networks.",
            "This is the prior variance on the weights of the neural network and this is the prior variance on the biases of the neural network.",
            "So the interesting thing is if you reduce that enforce the biases to all be at 0 so.",
            "All the signal."
        ],
        [
            "It's in your neural network are at zero.",
            "You can get funky functions like this, so this is an infinite number of sigmoidal functions sitting on top of each other at the origin, so you get because we put this parameter down to zero, so there's lots of different covariance function."
        ],
        [
            "You can build this is just adding a bias term so that you can have a non zero function but you don't cooperate priority.",
            "What your biases so it can sort of move up and down like that."
        ],
        [
            "And the point is, you can add these things together.",
            "So what here I'm showing is a combination of that exponentiated quadratic plus the bias.",
            "So it's allowed to move up and down plus some noise.",
            "So I put noise on top to give these sort of little disturb."
        ],
        [
            "Lines.",
            "Another really interesting one which brings a big overlap in with physics is the Ornstein Uhlenbeck.",
            "There's also a Brownian motion covariance function, but this is like a stationary.",
            "This is the uniquely defined stationary Gauss Markov process, so this is a Markov process that is also a Gaussian process that is also stationary and its covariance function has the form of instead of a exponentiated quadratic.",
            "It's an exponentiated absolute.",
            "To."
        ],
        [
            "OK, So what can you do with that?",
            "Well, once you've defined your covariance function, actually all you need is your data.",
            "So these models are called nonparametric because.",
            "You just combine as you add data to them.",
            "That's what defines what the final posterior.",
            "Mean function is.",
            "So the way we get.",
            "Results out of these things is that operation I did earlier where you take the covariance function and you combine it with an observation.",
            "You can also combine it with two observations and then you can ask what the prediction is, what the predictive mean is for all other time points.",
            "So here we're taking a exponentiated quadratic covariance function in two data points and what we're doing is we're not having any noise on this system, so this is a noiseless system.",
            "We combine it with the covariance function with the party."
        ],
        [
            "The length scale and this is what we get as a prediction, so the original prediction would have been flat with error bars at 2 standard deviations, but once we've seen these two data points, we know that the function must go through those two data points.",
            "The length scale of the function tells us how expect how rapidly we expect it to move away from those data points, and therefore gives us these error bars.",
            "With this sort of mean and error bars at 2 standard deviations."
        ],
        [
            "Now as we."
        ],
        [
            "More data then we become more confident about the function."
        ],
        [
            "So you should see the data is typically falling within the error bars."
        ],
        [
            "And actually in this case it collapses down almost to absolute certainty.",
            "It isn't quite absolute certainty, but it looks like it certainly to the human eye across the range of where the data is.",
            "The reason why you're getting absolute certainty is sort of related a bit to Nyquist sampling theorems in signal processing.",
            "So because the length scale is equivalent to the window of frequencies you expect, there's in fact an interpretation for Gaussian processes in frequency space.",
            "So as you start observing your data points at certain close together intervals.",
            "Then this function has getting a certain rigidity.",
            "You can think of if you are splines, type person, which means that it's not possible for it to move away any further from like where the data points are.",
            "So you get you become very confident about what the error bars are.",
            "That's also side effect of property of this covariance function, which is infinitely smooth.",
            "So when one downside to this covariance function is, you can perhaps become two."
        ],
        [
            "Confident without warrant.",
            "So you can actually there was a noiseless system, and the sort of thing you can do is you can add noise to your Gaussian process, so that's what this is supposed to indicate here.",
            "So the relationship between time and some unobserved function.",
            "Is a Gaussian process with some parameters Theta, but then you may add Gaussian noise so Gaussian noise can be added independently.",
            "That's what this plate notation is supposed to be indicating for every data point you."
        ],
        [
            "Observe.",
            "So you end up with this relationship between F, the unobserved function and what you observe X, which is just Gaussian and independent.",
            "Now it turns out that's equivalent to another covariance function.",
            "I've already shown you samples from it.",
            "That covariance function is simply.",
            "I mean, this is the Kronecker Delta, so it's a diagonal times Sigma squared, which makes sense, it's just the product across data points, so it's an independent Gaussian, so it's just a diagonal Gaussian with constant variance.",
            "Now the really nice thing about Gaussians?",
            "If I add two Gaussian random variables together, the result of doing that is also Gaussian.",
            "The covariance of the result is the sum of the covariances of the two variables I was interested in.",
            "So if I know the covariance of my underlying function, the smooth thing that's one term and then I have this covariance of the noise, I just have to add this noise covariance to my underlying smooth covariance.",
            "I just have to sum these covariances together and I get some defect, so I think they call these.",
            "Additive models in statistics, but they're just there like super trivial for Gaussian processes, and you can Add all these props."
        ],
        [
            "Tease him.",
            "And if you do that with another similar data example."
        ],
        [
            "Hi, you get this sort of effect.",
            "So now the date of the infant."
        ],
        [
            "Doesn't pass directly."
        ],
        [
            "Through the points, it can pass either side."
        ],
        [
            "In the error bars."
        ],
        [
            "Are reflecting."
        ],
        [
            "Estimate of the noise."
        ],
        [
            "Now some of you with Colonel backgrounds may have been thinking that this.",
            "Covariance function is very similar to a kernel.",
            "An indeed it is, and the reason is as follows.",
            "Because the kernel, as in a Mercer kernel, people using support vector machines is required to be positive definite so that this infinite dimensional funky feature space exists.",
            "Now in a Gaussian process a covariance function is coming from producing a covariance matrix, which is also required to be positive definite.",
            "So the requirements for covariance function are the same as the requirements from Mercer Kernel and these methods.",
            "Very closely related, so if you don't know about.",
            "Gaussian processes, then one of the ways you can think of them is there like kernel methods, but only a lot better.",
            "And the reason they're a lot better is the following.",
            "You have a likelihood associated with this, so you make these observations of your data X.",
            "And you can compute the likelihood, which is just the likelihood of a 0 mean Gaussian.",
            "What you can then do though, is you can ask the question what happens to this likelihood?",
            "As I change the parameters in this case, I'm going to change the length scale.",
            "So here we're on a very short length scale and this is the resulting interpolation, so it may not appeal to you very much now, but these two terms in here one is an entropy term and one is like a data fit term, so this is matching K to X and this is just the entropy of K, so this is like the capacity of this system and what we're going to do is we'll play."
        ],
        [
            "As we change the length scales."
        ],
        [
            "These different terms, so let me get this right.",
            "So takes awhile to."
        ],
        [
            "What we sought out with is what's going to be dropping.",
            "Is the data fit term because as we reduce the length scale?"
        ],
        [
            "We fit this data."
        ],
        [
            "Well, you'll see that yeah, so we're not fitting this data that well, so here at the top we've got the data fit term, which is dropping."
        ],
        [
            "And what we're going to be improving is the."
        ],
        [
            "Entropy term."
        ],
        [
            "So the."
        ],
        [
            "Combination of."
        ],
        [
            "Is 2 though leads to this.",
            "So this is the entropy term.",
            "This is the data fit term, but when you add those two together so normally naive non Bayesians basically spend their time working with this and that says get over to the left hand side.",
            "Make the length scale as short as possible.",
            "This is the capacity term arises naturally from the Gaussian distribution and the sum of these two leads to this.",
            "The log likelihood and what you see is the log likelihood has a maximum of one, and since I generated this data well, it probably will have a maximum just off 1.",
            "Actually, 'cause I'm just showing discrete time points in terms of the discrete point, discrete length scale points to the discrete points, the length scale maximum is 1 an.",
            "Actually I generated that data from a function with the length scale of 1, so it recovers the parameter of the kernel matrix, which is something it's very difficult to do with kernel matrices.",
            "With kernel methods trivial to do with Gaussian process, as long as you accept you're going to have to do a nonlinear optimization.",
            "The optimization of this you would do by gradient based methods.",
            "You would use scale, conjugate gradient, or quasi Newton, whatever your favorite gradient based optimization azatian is, it's not necessarily convex.",
            "It may have nasty properties as long as you're prepared to accept that fitting your kernel parameters is trivial, that becomes very important for what we're going to return to.",
            "Just transcriptional regulation.",
            "The example I talked about for the 1st of 20 minutes.",
            "So.",
            "Any question about Gaussian processes, I should say.",
            "Covering the ground there something like we can do that just 10 fold cross validation for yeah, so let me give you 30 parameters an let me see how you manage to do your 10 fold cross validation plan.",
            "OK so leave one out.",
            "Cross Validation is another approach to doing it so.",
            "I think Olivier Chappelle has shown very nicely that you can write down.",
            "Leave one out cross validation measures that can be measured optimized with respect to those 30 parameters.",
            "Interestingly, very few people seem to do it.",
            "I don't know why, and if you ask Olivier Chappelle, I think he would say just use a Gaussian process so there I don't know all the details.",
            "But there are also other interesting reasons about when cross validations good and when Bayesian optimization is good.",
            "But basically yeah, I mean, I leave one out.",
            "I would accept that, but no one is doing it now.",
            "I've never seen anyone optimize 30 parameters, so we're doing that.",
            "We're about to do that with no problem without buying an eyelid.",
            "But yeah, leave one out is a potential thing you could do.",
            "We have just.",
            "Yeah, so that's why that's why we as a Gaussian process community suffered in the face of support vector machines.",
            "When you start doing things like digit classification, because fundamentally there's just one parameter to fit everyone sort of fits it multiple times and then shows the best of their results on the test data.",
            "And there's not much you can do to demonstrate the way what you get out of the Gaussian process, apart from like these error bars.",
            "I think now, so I spent a portion of my research career trying to demonstrate Gaussian processes were as good as support vector machines.",
            "I think it's sort of pointless for the reasons that you just pointed out what you can do with Gaussian processes that you can't do with kernel methods.",
            "Is this very low data scenario that we're going to talk about next?",
            "So number of data points we're going to use is going to be very few, and the number of parameters will fit with."
        ],
        [
            "At large.",
            "So the 1st order differential equation.",
            "So any other questions so.",
            "OK, so back to this first."
        ],
        [
            "Sort of differential equations so it turns out that if you assume F of T is a Gaussian process, this equation here implies the X of T is also a Gaussian process, so the result of solving this differential equation leads to a linear operator and a linear operator on a Gaussian process is a Gaussian process.",
            "I'll review the."
        ],
        [
            "In a second, but then you Gaussian process is over F of T and all the targets.",
            "So you get this expanded Gaussian process that is not just over one function, it's over multiple functions, so it's over the latent function, the one you haven't observed, and the observed ones.",
            "This means you can transfer information from the observed."
        ],
        [
            "Gene expression to the latent function.",
            "And the new covariance matrix which we have to compare."
        ],
        [
            "Who gives correlations between all these functions?",
            "Now this gives us a probabilistic model for transcriptional regulation."
        ],
        [
            "What I think is an extremely elegant way, and this is the way it works out.",
            "So let's look at the top first.",
            "So this is the solution of that differential equation, ignoring the transient terms now.",
            "This is F of you.",
            "This was our Gaussian process and this is just a standard exponential and another exponential that arise from the solution to the differential equation.",
            "So if you're not used to looking at these convolutions, it's a Laplacian one.",
            "It goes from nought to T. It might appear a little bit intimidating, but there's another way of looking at it.",
            "So you see, that's constant.",
            "Plus this thing times an integral of."
        ],
        [
            "Two functions multiplied together, but if I were to write it like this constant X is equal to a constant plus an inner product of something I've just called either some over a bunch of eyes of these Tees times F, so where's F is drawn from a multivariate Gaussian?",
            "If I were to write it like that, then I hope that you wouldn't be too upset.",
            "If I told you all the result of this.",
            "If I if I say this is a Gaussian and I add something to a Gaussian that gives me a mean on the Gaussian.",
            "And the covariance as a result of an inner product applied to Gaussian distributed random variable is just going to be the sum of the double inner products of E with that Sigma.",
            "So that's the case for a discrete Gaussian distribution.",
            "Now the case for."
        ],
        [
            "The continuous case is just the same, only involves a bunch of integrals over the covariance functions.",
            "So instead of summing over these eyes, you're integrating over the tease analytic.",
            "OK, so that's the headache.",
            "So what you do with this first one is you spend ages working it out yourself.",
            "What you do with the later one is you get a guy from Finland to visit you, and you have him work it all out because it's much harder than the first one.",
            "Very very involved, but the principles there.",
            "And you can do it.",
            "And it turns out to be an analytic, and this is the result.",
            "So this is the form of the covariance function, where we now get to put in.",
            "Here is the original thing we started with.",
            "Just act exponentiated quadratic up the top.",
            "But now we can compute cross covariances between it and target genes and this is what they look like there.",
            "In this case we've had one of these is strongly high decay, high sensitivity ones, medium decay, medium sensitivity ones, low decay, low sensitivity.",
            "So this high decay high sensitivity frame work is the one we talked about before I said.",
            "Well, if all these things are very high, basically it doesn't matter.",
            "It's a differential equation, and indeed you see very strong correlations between X1 and F1.",
            "Basically, this will sample something very similar to F. As you reduce the decay and sensitivity, those correlations become weaker and you get something that's much more diffuse in its correlation between this potential target and that F. Are there any questions about what this is trying to show?",
            "I'm not sure I explained that very clearly.",
            "So basically now you end up with a situation where you would not just having a covariance function overtime points, you've got a covariance function over M RNA expression as well, and it's correlating the M RNA expression to the latent function.",
            "Extreme itself is lower than.",
            "Yeah, interesting, I think that's a result of.",
            "I think that's it's not going to be a result of.",
            "Potentially just this sensitivity being low because it's pre multiplying that portion.",
            "Yeah that I think that will be it that you basically one of the terms in this covariance is a multiplication of.",
            "The sensitivity.",
            "On these terms and the sensitivity squared on the diagonal.",
            "So if the sensitivity squared is .5 then this thing ends up being lower."
        ],
        [
            "OK, So what I can do is before we were showing samples from an exponentiated quadratic on its own, an underlying here is the same thing.",
            "So this F of T is one of those samples like the one I showed you at the beginning.",
            "The black thing, yeah?",
            "But here we jointly sampled.",
            "The black thing with some of these targets.",
            "So three of these targets the red, the green, and the blue.",
            "We actually constrained them all to start at zero as well.",
            "So what's interesting about that is you see that the red, which is the high decay high sensitivity.",
            "The target basically tracks black.",
            "As we suggested early on when we said if you were doing clustering, you're looking for targets like that.",
            "Green is the lower decay, lower sensitivity and blue is the lowest decay.",
            "Lower sensitivity.",
            "So coming back to it is lower variance than the other functions.",
            "I suppose that's inevitable, because if it's going only up when those guys go up and it's tracking behind them, it will end up being lower variance which.",
            "Comes out in the covariance."
        ],
        [
            "Function as was pointed out before, here's another example.",
            "So in this case Black is sort of oscillating a bit more wildly and red is following it again.",
            "High decay, high sensitivity, blue and green are following it, lesser the point of this type of modeling is you might not cluster cluster blue and red, so you might not understand.",
            "Blue and red are both targets of black.",
            "Unless you've got the differential equation model, you wouldn't pick it out from this clustering."
        ],
        [
            "Another example, I just like doing this."
        ],
        [
            "Samples and another example.",
            "So you just see the same pattern with each sample.",
            "So these are joint samples from the system.",
            "What's rather funky about it is just sort of jointly sampling at the same time the.",
            "Solution to the differential equation or that you're inverting the convolution somehow at the same time as you're doing this sampling 'cause you did all this analytical work beforehand, which is quite unusual."
        ],
        [
            "So the framework is so before we saw these plots where I was showing direct observations of a function and showing how the error bars changed.",
            "But the framework here is slightly different.",
            "We're going to see observations of the M RNA's, which are the gene expression measurements and will look to see how the.",
            "Estimate of the transcription factor activity changes.",
            "So in this case it's an artificial system with two bumps, two transcription transcription factor is 2 bumps and the parameters are realistic parameters.",
            "While they're all high sensitivity but once high decay ones, medium decay ones loader case.",
            "So this one just integrates the two bumps in effect, whereas this one follows them fairly closely.",
            "I'm not showing you the fitting of the parameters which we talked about earlier in this system.",
            "There are, I think, 11 parameters.",
            "They were all fitted from the data I'm showing.",
            "Once they've been fitted what the inference is?",
            "I know what those parameters are, but I did parameter fits using the data that you'll see here and now."
        ],
        [
            "I want to sort of show how the inference process."
        ],
        [
            "So now you make observations."
        ],
        [
            "In the gene expression area, but it."
        ],
        [
            "Takes influence."
        ],
        [
            "On"
        ],
        [
            "What happens for your estimate of the?"
        ],
        [
            "Transcription factor."
        ],
        [
            "Activities now I've made realistic noises."
        ],
        [
            "Options say you can."
        ],
        [
            "See."
        ],
        [
            "The noise has an effect on what the estimate is so."
        ],
        [
            "Quite high Arabic."
        ],
        [
            "But the point is as."
        ],
        [
            "You observe more."
        ],
        [
            "Jeans."
        ],
        [
            "Obviously the."
        ],
        [
            "Noise is sort of in."
        ],
        [
            "Pendant across Jean."
        ],
        [
            "But the underlying."
        ],
        [
            "Transcription factor."
        ],
        [
            "File."
        ],
        [
            "Is concern."
        ],
        [
            "Say."
        ],
        [
            "You end up with a better."
        ],
        [
            "Even better estimate."
        ],
        [
            "At."
        ],
        [
            "Of what the true trance?"
        ],
        [
            "Which in fact are active."
        ],
        [
            "She is and if your estimate isn't good, you have these large error bars to show you that something wrong.",
            "That's the beauty of Gaussian process.",
            "So that's having observed three jeans with what, 123456789, ten, 11, twelve, 1314 fifteen 1617 time points.",
            "In practice, we may be looking at.",
            "We've done things as low as five jeans, six time points, that sort of order, so quite small systems.",
            "So this covariant.",
            "The size of this covariance matrix that we need to compute.",
            "I won't go all the way back is only going to be in these small cases.",
            "This is going to be about 60."
        ],
        [
            "60 So quite small.",
            "So we published this idea in ECB in 2008.",
            "With Pai Gow with this sort of lead postdoc on it and Auntie we published the early result on the Cascade system I'm going to."
        ],
        [
            "About next I. OK, so this is a sort of result on real data.",
            "Now the first thing you might say this is the data from Barangka.",
            "The first thing you might say is all up, but all those profiles are the same.",
            "Well, that's not surprising because known targets of transcription factors tend to have very similar profiles because people have been using clustering to identify them.",
            "Um, so we can infer that."
        ],
        [
            "Of protein activity."
        ],
        [
            "But here's an example where the profiles can be very different, so here's.",
            "123456 known targets of so 1345 known targets in an elk one system.",
            "And this is our inference of the transcription factor activity.",
            "But notice here that it the Dick."
        ],
        [
            "A rate is obviously lower and then we can do things like rank potential targets, so this is a target of the gene that is predicted as a true target and this is a."
        ],
        [
            "Rated nontarget."
        ],
        [
            "Team so just quickly I want to mention we had a paper in PNS.",
            "Part was published this year that used an extended idea that Auntie and Magnus came up with sits on top."
        ],
        [
            "This model, so the extended idea is basically to include the fact that the transcription factor protein has a governing M RNA, so each transcription factor has its own M RNA and add a model of translation.",
            "Now in the P53 system, translation isn't really occur in phosphorylation is what activates the system.",
            "But in a developmental system this is quite a potentially interesting model for the system."
        ],
        [
            "So in collaboration with the Furlong lab in the NBL, we looked at mesoderm development in Drosophila.",
            "So what we did is we there the wild type.",
            "My career experiments are publicly available in this embryonic developmental stage.",
            "And it's across the formation of the heart and other muscle systems.",
            "So what we're interested in is, can we use this cascaded model idea to predict viable targets of a known transcr?"
        ],
        [
            "In fact.",
            "So in this case the model is.",
            "Slightly modified.",
            "So now we have the same protein being produced by an M RNA that we can also observe.",
            "So this is unknown.",
            "But this is known.",
            "And this is our simple model of translation.",
            "Again, a first order differential equation and it solved in a similar way to our previous one."
        ],
        [
            "Now we can look at a joint Gaussian process over Y FX-1 and X2.",
            "We also realized another way of doing it rich for being a lot quicker would have been supporting at RBF covariance function over F. And differentiate to get the covariance function for Y.",
            "So in some sense that means we can immediately do a three layer network by looking at differentiation to get the guy above Y, but we haven't done that yet.",
            "So in this cascade system you've basically got Y in at the top that drives the output of F, which drives the output of X.",
            "Now the nice thing about this."
        ],
        [
            "Yes.",
            "OK, we can again do these samples, so here this is the M RNA of the transcription factor, then black is the transcription factor concentration and then these are."
        ],
        [
            "Three targets of."
        ],
        [
            "So we can do this."
        ],
        [
            "Same sort of sample systems again.",
            "What we like about this is this ability.",
            "Up to now, use M RNA of twist as the thing we're using to perform the search.",
            "So if we know the M RNA of twist, then we can basically build a model for every single gene in the genome.",
            "So we look at the possibility for M RNA of twist.",
            "Did it regulate each gene and we can fit those models independently and we can rank all those models to find out what is the most likely gene to have been regulated by twist, and we're doing that simply from wild type data.",
            "So no extra data."
        ],
        [
            "And this is what we're doing here.",
            "So this is a fit.",
            "This is the driving input of twist.",
            "This is a potential target that was very highly ranked and what it says is for this to be a target.",
            "That fits there to twist, which is just an RBF it to twist.",
            "That should be the protein and then that should be the target M RNA, so it manages to fit that quite well.",
            "So this becomes very highly ranked.",
            "Notice that that would never cluster with that, so you're not going to get this."
        ],
        [
            "Clustering.",
            "Here's an example that would cluster here's the same system, very high decay at very high sensitivity.",
            "It does to fit this.",
            "Basically that looks identical to that, so you would get this out of clustering.",
            "An extremely different protein profile, so there's something fishy going on here because we fitted these two independently and the protein profiles are very varied."
        ],
        [
            "Different.",
            "Here again, we go back to the first protein profile, lower decay, lower sensitivity."
        ],
        [
            "This system and again."
        ],
        [
            "Lower Kayla sensitivity."
        ],
        [
            "And again, all these protein profiles are independently fitted, but they are consistent, which is sort of encouraging.",
            "But there is the it's nice to work on flies 'cause you."
        ],
        [
            "Say there's a fly in the ointment and that's this protein profile here, which is high decay high sensitivity.",
            "Something odd."
        ],
        [
            "Going on well, we email that collaborator about that because what is does seem to be orders that this activity seems to occur."
        ],
        [
            "Early.",
            "And then there's that."
        ],
        [
            "Liberty later, and it looks like we're missing something in the model.",
            "We're missing a phosphorylation step or something like that, so I don't know what it is, but she said that they biologically notice that twist has two affects.",
            "It either affects early or it affects late, and we're just picking in both of these up because we are fitting independently, so it turns out that that is something in the system, and it's something slightly incorrect in our model, which doesn't bother me because the model is incorrect in many ways, But you can still find interesting things out."
        ],
        [
            "By fitting an incorrect model."
        ],
        [
            "So we did a sort of evaluation of this system where they had they had chip on chip validation for sort of these particular transcription factors across the genome.",
            "So what we can do is see how our ranking predictions, how well enriched they are for things that were also in the chip, and now the chip was very conservative so they didn't make a chip call and less.",
            "They were very confident.",
            "So it's not a gold standard, but it's a useful measure so I didn't talk about the multi target GP, but that's a model that assumes that multiple genes are controlled together.",
            "I did talk about the single one.",
            "That's the results I was showing you there, which is this blue line.",
            "Now it's interesting for the twist results.",
            "Do extremely well.",
            "We do much better than knockouts knockouts perform as well as random.",
            "In this case, these focus results are looking at things that were in the in situ only, so I'll just look at the global results.",
            "Actually, and we see that knockouts only do randomly well here, so there's very poor way of finding out what's regulated.",
            "Correlation, which is just looking at the correlation between these targets and the M RNA of the transcription factor we're interested in.",
            "Also does pretty poorly.",
            "These two models, which are based on the differential equations, do quite well.",
            "Math to the story is a little bit more complicated, so in math two correlation turns out to be very good."
        ],
        [
            "Maybe we haven't shown you F2, but Mathews activity only comes up there right at the very end, so you don't get to see the downstream effects of meth 2.",
            "So that would mean that the advantages of our model is somewhat lost against correlation.",
            "In some sense, it's only going to be able to pick up things that are."
        ],
        [
            "It like correlation, so that may explain why correlation does so well here.",
            "Indeed, on the focus chip it's doing slightly better on the global chip.",
            "It is doing.",
            "Probably better overall, but our method is always up there always performing well and it's predicting."
        ],
        [
            "These targets are using.",
            "Only a wild type gene expression data, so it's very very cheap versus say the knockouts.",
            "So so the summary of the sort of work that I've shown.",
            "I hope I've been able to give you.",
            "The aim was to give you an impression of what a Gaussian process is, how it works, and how it can be used by then sort of showing you.",
            "Sort of research.",
            "We've been looking at using Gaussian processes in transcriptional regulation, the Cascade models.",
            "These allow genome wide analysis of potential targets given only wild type expression data and you can identify a set of candidate targets and then model these impacts and more complicated manner.",
            "Now we didn't have any ground truth, but we seem to be forming as well."
        ],
        [
            "Is a knockout.",
            "So."
        ],
        [
            "The discussion is that what I've been trying to motivate in the tutorial is the idea of combining probabilistic inference and mechanistic modeling as the right thing to do that either one on its own is ignoring something important.",
            "And then we talked about applications in modeling gene expression and the key component to this combination was the Gaussian process and we also introduced the model of translation with the Cascade model, and these are the sort of things we're doing at the moment, so this we've got methods for doing very large systems, genome wide systems and we're just fine.",
            "Finishing a paper on nonlinear diff nonlinear response, and we can do not learn differential equations.",
            "We haven't explored it yet.",
            "Stochastic differential equations.",
            "We have also ways of expanding it first."
        ],
        [
            "Plastic differential equations too.",
            "So, and I should.",
            "Acknowledge Samartino Barranco Mike Eubank at the Institute of Child Health and UCL, who were always very amiable and good to talk to you and provided this great data set, which is a really nice clean data set on the P 53 pathway.",
            "Charles O DAU and Eileen Furlong provide the same role with the Drosophila example I showed at the end and the researchers I mentioned at the beginning and the work I've shown was funded by.",
            "Along time ago it was funded by BBC Award that funded Guido Andani PSC awards that funded pay.",
            "Gaussian process for systems identification in in systems biology.",
            "That's it, time for questions.",
            "I think I hope."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So thanks very much for the invite to be here.",
                    "label": 0
                },
                {
                    "sent": "I I should have in some sense I had an urge to give a longer tutorial than than time allows for, and I tried to stem that urge.",
                    "label": 0
                },
                {
                    "sent": "So I've tried to sort of show a bit about.",
                    "label": 0
                },
                {
                    "sent": "I don't know how many people have seen Gaussian processes before in the audience.",
                    "label": 0
                },
                {
                    "sent": "OK, so a few OK everyone so I can come to know.",
                    "label": 0
                },
                {
                    "sent": "So I tried to give sort of a soft overview of Gaussian process is and then also a bit of an overview of our philosophy of what we're trying to do.",
                    "label": 0
                },
                {
                    "sent": "In combining these methods with the mechanistic models and how we're trying to apply that to transcriptional regulation, but I think it has other applications and wider implications for sort of machine learning in general or pattern RECOGN.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in general.",
                    "label": 0
                },
                {
                    "sent": "OK, so quick outline of the talk.",
                    "label": 0
                },
                {
                    "sent": "I'll give a bit of motivation and then this probabilistic model for this function is going to be Gaussian process and then I'll give an example on these cascaded differential equation models for transcription.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That'll mainly be it.",
                    "label": 0
                },
                {
                    "sent": "I should mention people that so this is really it's a tutorial, but it's almost a guide to our recent work to feel slightly guilty about.",
                    "label": 0
                },
                {
                    "sent": "Rather 'cause tutorials should really be about everyone's work.",
                    "label": 0
                },
                {
                    "sent": "But Gaussian processes are widely used and have lots of applications.",
                    "label": 0
                },
                {
                    "sent": "Beyond that, our work as well so I feel less guilty for that reason, so I have to acknowledge the people that have contributed to the sort of things I'm going to show today.",
                    "label": 0
                },
                {
                    "sent": "So I work very closely with Magnus Rattray, who's also moved from Manchester to Sheffield.",
                    "label": 1
                },
                {
                    "sent": "Pai Gow was postdoc who worked on early variants of this model, anti hunkeler from Aalto University, formerly Helsinki University of Technology, visited us a lot and spent a lot of time working on these models.",
                    "label": 0
                },
                {
                    "sent": "A lot of the results have come from his coding.",
                    "label": 0
                },
                {
                    "sent": "Guido Sanquenetti was an earlier post Doc Underground work with us on some of the earlier stuff on this and Jennifer with us was a PhD student with.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Agnes.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I read this paper actually and I was quite struck by this idea.",
                    "label": 0
                },
                {
                    "sent": "Can a biologist fix a radio lays make?",
                    "label": 1
                },
                {
                    "sent": "I don't necessarily agree with everything in it, but it's about the case for systems biology, which perhaps I don't need to sell to this audience.",
                    "label": 0
                },
                {
                    "sent": "But the idea is that you should move well kind of biologist, fix a radio can by using the techniques people are using in biology.",
                    "label": 0
                },
                {
                    "sent": "You go in and work out how radio is going to work.",
                    "label": 0
                },
                {
                    "sent": "So if you just go and destroy a circuit in a radio.",
                    "label": 0
                },
                {
                    "sent": "Does that help you learn how the radio is working?",
                    "label": 0
                },
                {
                    "sent": "And obviously it doesn't.",
                    "label": 0
                },
                {
                    "sent": "I mean, in some sense, the analogy I think maybe it was, it's a good analogy in a broad sense, but it's also bad analogy, because biological systems are much more robust than radios are, but he does have this phrase in the paper, which is an old saying from some country or another that it's difficult to find a black cat in a dark room, especially if there's no cat.",
                    "label": 1
                },
                {
                    "sent": "I don't quite know what that mean.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Means but one thing you could take it to mean is that biological systems are sort of very, very calm.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Allocated and end in this paper lays makes I arguing the need for models that are.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Quantitative and these models should be predictive of biological behave.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Asia and.",
                    "label": 0
                },
                {
                    "sent": "These need to be combined with biological data.",
                    "label": 1
                },
                {
                    "sent": "So what I what this is?",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Leading to is what I think of systems biologists are combining this with my only.",
                    "label": 0
                },
                {
                    "sent": "My background in machine learning I think of systems biology is traditionally it.",
                    "label": 0
                },
                {
                    "sent": "Let's build mechanistic models based on biochemical knowledge of the system.",
                    "label": 1
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then what we try and do is identify modules and submodules and parameterized these modules.",
                    "label": 0
                },
                {
                    "sent": "So in the biologist fixing radio analogy, the modules in the submodules are.",
                    "label": 0
                },
                {
                    "sent": "I don't know the tuning system and the various components of the radio, and then try and walk out the parameters of these models are undescribed biological.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "System that way.",
                    "label": 0
                },
                {
                    "sent": "So I think to an extent what a lot of us may have been involved in is maybe more computational biology.",
                    "label": 0
                },
                {
                    "sent": "So the case for computational biology, and I give an example which would be the Co regulation of gene expression.",
                    "label": 1
                },
                {
                    "sent": "So if we've got gene expression data from a biological system, what we typically may be interested in is actually transcriptional regulation.",
                    "label": 0
                },
                {
                    "sent": "So I'm particularly will think of time series.",
                    "label": 0
                },
                {
                    "sent": "If I think of gene expression data.",
                    "label": 0
                },
                {
                    "sent": "So we might have a time series of developmental system where we've observed the gene expression at.",
                    "label": 0
                },
                {
                    "sent": "I don't know early time points for perhaps seven time points and what we're interested in is from this time service.",
                    "label": 0
                },
                {
                    "sent": "What can we say about the regulatory structures that?",
                    "label": 0
                },
                {
                    "sent": "Are involved in development, so I think of this is a data exploration problem.",
                    "label": 1
                },
                {
                    "sent": "We've got some data and we want to find something out about it.",
                    "label": 0
                },
                {
                    "sent": "You can use the gene expression data to speculate on which a Co regulated genes and traditionally sort of very early on people started using clustering for this sort of thing.",
                    "label": 0
                },
                {
                    "sent": "So you sort of try and find gene expressions that cluster together and then you hypothesize that they might be Co regulated.",
                    "label": 0
                },
                {
                    "sent": "You give them back to the biologist and he gets very excited because one of the clusters make sense and then he starts doing some literature and he might do some knockouts.",
                    "label": 0
                },
                {
                    "sent": "But you can contrast that sort of clustering approach with this sort of computational systems biology approach, which would be to create a detailed mechanistic model of the system, and then fit the parameters of this model to the data.",
                    "label": 1
                },
                {
                    "sent": "So you create a mechanistic model that is described in these biochemical relationships and then you fit these kinetic parameters to the data.",
                    "label": 0
                },
                {
                    "sent": "That's going to be quite problematic for very large datasets because you have to have a mechanistic all that describes everything that's going on to the cell, which in some sense is the end goal of all of this work, and it's going to be very difficult and you don't have enough data to actually fit all the parameters of that model.",
                    "label": 0
                },
                {
                    "sent": "Another thing is that you need to deal with, say, an observed by a chemical species, because in an ideal world.",
                    "label": 0
                },
                {
                    "sent": "We would observe every profile available in the system.",
                    "label": 0
                },
                {
                    "sent": "All the gene expression.",
                    "label": 0
                },
                {
                    "sent": "But then a transcriptional network.",
                    "label": 0
                },
                {
                    "sent": "This protein expression as well.",
                    "label": 0
                },
                {
                    "sent": "But of course in practice the protein expression is quite difficult to measure, so there are these things going on in the system that you're not even observing.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so general approach so broadly speaking I would like to summarize there's two approaches to modeling data or to modeling, not modeling data I should say, But modeling this situation that I.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sort of briefly talked about in data modeling, which is the sort of computational biology clustering approach we let the data.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Speak.",
                    "label": 0
                },
                {
                    "sent": "Whereas in mechanistic modeling, this systems biology approach, we might impose mechanistic rules on our data, force it to conform, yes.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "As soon as we have labels or is also available data, you may not even have data.",
                    "label": 0
                },
                {
                    "sent": "So you actually have a mechanistic modeling in the way.",
                    "label": 1
                },
                {
                    "sent": "It's sometimes practice.",
                    "label": 0
                },
                {
                    "sent": "You know, you know, you just build a mechanism of the data and then and often you see talks where they might write down the mechanism of the data, and then they might show some simulations from the model, and then they might plot actually what you see in the data, and so broadly speaking, the same, so you never actually do a data fit.",
                    "label": 0
                },
                {
                    "sent": "You say look, it oscillates the period somewhat similar, so you may not.",
                    "label": 0
                },
                {
                    "sent": "In this case you may not even be looking at data.",
                    "label": 0
                },
                {
                    "sent": "Typically you would, I mean.",
                    "label": 0
                },
                {
                    "sent": "What I would sort of argue is that, well, that's perhaps a longer talk.",
                    "label": 0
                },
                {
                    "sent": "In some sense, well, let me finish this slide and I'll come back to that other little.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in this data modeling we might have computational models, by which I mean sort of things like PCA, data driven models, support vector machines, classification things, things which are just sort of allowing the data.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Fit the model and these are systems MoD.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's based on here.",
                    "label": 0
                },
                {
                    "sent": "Would you be?",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Adaptive things and here we have differential equations, so here you got very flexible adaptive activity and here you've got differential equations, so we're actually very constraining once you observe one profile, say at the top of the differential equation, everyone else everything.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is determined.",
                    "label": 0
                },
                {
                    "sent": "So examples here would be principal component.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Analysis, clustering and examples.",
                    "label": 0
                },
                {
                    "sent": "He Ristic ostick differential equation, ordinary differential equation models OK. One of these two bumps here.",
                    "label": 0
                },
                {
                    "sent": "So, relating back to this point, so these two bumps are supposed to be my schematic of the amount of activity in these two areas.",
                    "label": 0
                },
                {
                    "sent": "So what I'm saying is, there's actually a spectrum, So what your point about data and where do you get?",
                    "label": 0
                },
                {
                    "sent": "How do you combine the messaging and mechanistic models with the data?",
                    "label": 0
                },
                {
                    "sent": "So at one end you're completely ignoring data, almost just based on prior knowledge or your knowledge of the physics and at the other end you're sort of ignoring mechanistic and justice working with data.",
                    "label": 0
                },
                {
                    "sent": "OK, the truth is somewhere in between, because people use a little bit of data to fit some of the parameters.",
                    "label": 0
                },
                {
                    "sent": "They might do an experiment.",
                    "label": 0
                },
                {
                    "sent": "A separate experiment just to fit a parameter.",
                    "label": 0
                },
                {
                    "sent": "And people suggest that in systems biology, let's find the decay rate of this thing in vitro and then use that here.",
                    "label": 0
                },
                {
                    "sent": "Actually, the assumptions underlying these things and these assumptions can be equated to physical models of some type extreme versions.",
                    "label": 0
                },
                {
                    "sent": "But my main argument is that there's a gap here that there's a problem.",
                    "label": 0
                },
                {
                    "sent": "If I tell you I'm working with differential equations, you're all very good at posterior inference, and you know about this likelihood here, so you immediately assume I'm doing mechanistic modeling.",
                    "label": 1
                },
                {
                    "sent": "And if I tell you I'm I'm analyzing large amounts of data, you do the same thing, and you assume I'm going to be doing PCA or clustering.",
                    "label": 0
                },
                {
                    "sent": "And my main argument is actually we should be in here that that's what these methods which relates to the question earlier.",
                    "label": 0
                },
                {
                    "sent": "That's what these methods.",
                    "label": 0
                },
                {
                    "sent": "Should be applied to an if you go all the way back to the first person to write down, well, let's say the most famous person to write down a mechanistic model of the universe, which was Newton sort of 200 and something years ago, right.",
                    "label": 0
                },
                {
                    "sent": "He wrote down a mechanistic model not really inspired by data.",
                    "label": 0
                },
                {
                    "sent": "But then Gauss came along and fitted this mechanistic model to the orbit of series as it goes around, then predicted where it was going to be.",
                    "label": 0
                },
                {
                    "sent": "I don't have pronounced series or cherries.",
                    "label": 0
                },
                {
                    "sent": "Whatever the dwarf planet and Gauss became famous because of that, and he was combining domestic.",
                    "label": 1
                },
                {
                    "sent": "Mechanistic model with the data model.",
                    "label": 0
                },
                {
                    "sent": "Of course he had a lot of work to do.",
                    "label": 0
                },
                {
                    "sent": "His data fit and we have computers to do that today.",
                    "label": 0
                },
                {
                    "sent": "What he had, which was very nice, was a very accurate, mechanistic model that really reflected the system he was studying.",
                    "label": 0
                },
                {
                    "sent": "Where is today?",
                    "label": 0
                },
                {
                    "sent": "We perhaps have more complex systems, an idea of the mechanistic model will be perhaps less good, so the quality of our mechanistic model as a representation of our system will be less accurate.",
                    "label": 0
                },
                {
                    "sent": "An I think that means even more that we have to be in this region that this split is artificial.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And I'll argue that a little little bit further.",
                    "label": 0
                },
                {
                    "sent": "So what I would say is that we should be looking at approach between systems and computational biology.",
                    "label": 0
                },
                {
                    "sent": "Hum and issues aspects of systems biology to the computational approach 'cause I really come more from this background.",
                    "label": 0
                },
                {
                    "sent": "The computational approach.",
                    "label": 0
                },
                {
                    "sent": "So I think of bringing this into that, but you Conversely could be a systems person who wanted to introduce computational ideas more.",
                    "label": 0
                },
                {
                    "sent": "Computation ideas systems approach, so there's computational penalty.",
                    "label": 0
                },
                {
                    "sent": "These models tend to be slower.",
                    "label": 0
                },
                {
                    "sent": "They can deal with less data.",
                    "label": 0
                },
                {
                    "sent": "That's what I mean by slower, but it may be worth paying.",
                    "label": 0
                },
                {
                    "sent": "Ideally, there should be a sort of smooth transition from pure computational.",
                    "label": 0
                },
                {
                    "sent": "These sort of methods to complete systems nonlinear stochastic differential equations.",
                    "label": 0
                },
                {
                    "sent": "And this sort of stuff that I'll be talking about, which is going to include these Gaussian process, is one part of that transition.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let me give the background to the example which actually inspired all this work, which is by a guy called Martino Barranco and Mike Eubank and a few others at UCL Institute of Child Health, which was a P53 radiation damage.",
                    "label": 0
                },
                {
                    "sent": "So radiation damage in cells so radiation can damage molecules including DNA, and in this case could be ultraviolet radiation or any type of radiation, and this is normally quickly prepared.",
                    "label": 0
                },
                {
                    "sent": "So if it's a single strand break in your DNA, but double strand breaks into the more serious you can get these complete disconnects, and in particular.",
                    "label": 0
                },
                {
                    "sent": "If the cell is not dividing, then you have a problem because you don't have a copy of the original DNA and you need to decide.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But to do So what you actually do is you activate P 53.",
                    "label": 0
                },
                {
                    "sent": "Which is responsible for, well, it's responsible for repairing DNA damage and activates DNA repair proteins.",
                    "label": 1
                },
                {
                    "sent": "It also pauses the cell cycle to stop the cell dividing while this is going on and it starts trying to kill the cell.",
                    "label": 0
                },
                {
                    "sent": "So it does this by sort of overtime.",
                    "label": 0
                },
                {
                    "sent": "The more P 53 is in the cell, the more likely the cell is to undergo cell death.",
                    "label": 1
                },
                {
                    "sent": "If you like spending a lot of time, a time in the sun on your skin is quite fair.",
                    "label": 0
                },
                {
                    "sent": "Your skin will age prematurely and what's going on is that P. 53 is causing apoptosis of your skin because it's being damaged by ultraviolet radiation.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so I just like these pictures.",
                    "label": 0
                },
                {
                    "sent": "These David S good self molecule of the month.",
                    "label": 0
                },
                {
                    "sent": "So I think it looks a bit like the Flying Spaghetti Monster which any of you know is a sort of pseudo religious figure.",
                    "label": 0
                },
                {
                    "sent": "But I think that there's I'm not.",
                    "label": 0
                },
                {
                    "sent": "It's not completely clear what's going on here, but this is the structure of P53 and this is it binding to the DNA in order to.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Recruit.",
                    "label": 0
                },
                {
                    "sent": "Sort of just.",
                    "label": 0
                },
                {
                    "sent": "Check transcription and here it is another one.",
                    "label": 0
                },
                {
                    "sent": "It looks a bit like the Flying Spaghetti Monster here and it's recruiting.",
                    "label": 0
                },
                {
                    "sent": "Transcriptase to produce.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "M RNA.",
                    "label": 0
                },
                {
                    "sent": "So here's some known P53 targets.",
                    "label": 0
                },
                {
                    "sent": "So this is an example of sort of modeling we might be interested in.",
                    "label": 0
                },
                {
                    "sent": "We've got some knowledge that this is an actual target of P53 DNA damage.",
                    "label": 1
                },
                {
                    "sent": "Specific DNA binding protein.",
                    "label": 0
                },
                {
                    "sent": "Associated with repair, this is.",
                    "label": 0
                },
                {
                    "sent": "I think this is a regulator of cell cycle progression, so it's pausing the cell cycle.",
                    "label": 0
                },
                {
                    "sent": "This is pausing the cell cycle.",
                    "label": 0
                },
                {
                    "sent": "This is killing the cell and this is killing the cells, so these are all targets of P53.",
                    "label": 0
                },
                {
                    "sent": "They will become activated when P. 53.",
                    "label": 0
                },
                {
                    "sent": "Actually P 53 is phosphorylated and becomes active and starts.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Transcribing causing these to be transcribed.",
                    "label": 0
                },
                {
                    "sent": "So we got this is a model by Barranco.",
                    "label": 0
                },
                {
                    "sent": "This is also the barrancos work, the P53 targeting these sort of five things and the idea is you got this little network motif.",
                    "label": 0
                },
                {
                    "sent": "So this is a known transcriptional network structurally known.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And what we want to do is in the standard approach, we might assume that Co regulated genes are going to cluster in the same group.",
                    "label": 0
                },
                {
                    "sent": "So what we'll do is we'll do a gene expression will do, will initiate.",
                    "label": 0
                },
                {
                    "sent": "P53 will do a time series of gene expression will have all these gene expression levels for the bunch of these targets, and we will assume that any Co regulated dreams are going to be in the same cluster, so will perform the clustering.",
                    "label": 0
                },
                {
                    "sent": "Then we'll look for clusters containing these jeans, and then we'll assume that those clusters are being regulated.",
                    "label": 0
                },
                {
                    "sent": "For P53 those are candidates, and we look for confirmation literature.",
                    "label": 0
                },
                {
                    "sent": "That's the comp.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Initational approach.",
                    "label": 0
                },
                {
                    "sent": "This is what Barranco sort of suggested doing, which is I like it because it's clearly an inaccurate differential equation model, but it's still going to get you somewhere beyond the computational approach.",
                    "label": 0
                },
                {
                    "sent": "So Barranco says, well, let's look at the rate of transcription.",
                    "label": 0
                },
                {
                    "sent": "As being given by a base transcription rate, so there's a constant transcription in the absence of anything else plus the sensitivity that green.",
                    "label": 0
                },
                {
                    "sent": "You might not be able to see it there, so that's a sensitivity to the transcription factor concentration.",
                    "label": 0
                },
                {
                    "sent": "So this is all activity, let's say.",
                    "label": 0
                },
                {
                    "sent": "So the transcription factor activity is here F of T and if it's higher than the rate of transcription of P53 will be high.",
                    "label": 0
                },
                {
                    "sent": "And then there's a decay on the target gene.",
                    "label": 0
                },
                {
                    "sent": "the M RNA of the target gene which is given by this term here.",
                    "label": 0
                },
                {
                    "sent": "So the idea is that we've got observations of XJ of T this thing here from Genik.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Oppression and what Barranco sort of said, is, well, let's reorganize this equation and then here we've sort of gotten.",
                    "label": 0
                },
                {
                    "sent": "This is known.",
                    "label": 0
                },
                {
                    "sent": "This the transcription factor concentration activity is unknown 'cause you can't measure the protein.",
                    "label": 0
                },
                {
                    "sent": "So you've got this also could be estimated by doing in sort of interpolation on this and estimating these gradients.",
                    "label": 0
                },
                {
                    "sent": "You've got sort of knowns pseudo nones on this side, and you've got an unknown here.",
                    "label": 0
                },
                {
                    "sent": "An unknown here and we should be dividing this side by do to get that unknown on there.",
                    "label": 0
                },
                {
                    "sent": "So we've got unknowns there and knowns there.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So he estimated then this gradient through fitting polynomials to the underlying gene expression.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Temporal profiles and then he jointly estimated F of T, so he estimated at the time points of the observations.",
                    "label": 0
                },
                {
                    "sent": "So he estimated discrete time intervals of F of T along with these.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The parameters.",
                    "label": 0
                },
                {
                    "sent": "And then he fits that by maximum likelihood.",
                    "label": 0
                },
                {
                    "sent": "So or Martin.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Chain Monte Carlo.",
                    "label": 0
                },
                {
                    "sent": "So what's interesting about this is you can see that clustering in this model is equivalent to assuming Debian SJR very large because.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If we do that, then this term here basically disappears and we can rearrange to say.",
                    "label": 0
                },
                {
                    "sent": "We can rearrange to say that the M RNA level is equal to a an offset plus some sensitivity to the transcription factor.",
                    "label": 0
                },
                {
                    "sent": "So what this is basically saying is what you see is the M RNA is a scaled and offset version of the transcription factor activity.",
                    "label": 1
                },
                {
                    "sent": "So if you saw that for all your targets, then your targets would cluster because they're all going to look the same as the underlying transcription factor activity.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this suggests that jeans are all scaled and offset versions of that.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Scription factor and by normalizing the data and clustering, we hope to find the transcription factors activity, and I think that's effectively what's going on.",
                    "label": 0
                },
                {
                    "sent": "If you go and say to a biologist, well, let's do PCA.",
                    "label": 0
                },
                {
                    "sent": "Let's do clustering.",
                    "label": 0
                },
                {
                    "sent": "You're making this assumption.",
                    "label": 0
                },
                {
                    "sent": "You're making the assumption that the K. Basel rate sensitivities are very high.",
                    "label": 0
                },
                {
                    "sent": "So basically this gradient term disappears.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is his paper.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And I, I mean he wasn't talking about he wasn't making this point.",
                    "label": 0
                },
                {
                    "sent": "That's sort of my point.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But his paper.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is here and what he was able to do was estimate these parameters so these are the parameters for each of those jeans with some error bars and then he was fitting his differential equation model and getting these estimates of the activity profile for P53 so that through fitting the differential equation model and these are error bars for that.",
                    "label": 0
                },
                {
                    "sent": "So these are results.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "From his his work and then this is a doing Western blot to actually determine the level of protein active protein and you get a sort of similar profile.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "File from the Western blot.",
                    "label": 1
                },
                {
                    "sent": "OK, so I haven't said anything about Gaussian process so far, which may be a record for me in a talk to go whatever 20 minutes without mentioning Gaussian process is.",
                    "label": 0
                },
                {
                    "sent": "So what I want to do is sort of.",
                    "label": 0
                },
                {
                    "sent": "I've tried to motivate what's going to come next, but now I'm going to sort of talk just about Gaussian processes, so.",
                    "label": 0
                },
                {
                    "sent": "What was?",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Going on here is this thing is a missing variable and what Martine.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Loaded in this slide is he sort of.",
                    "label": 0
                },
                {
                    "sent": "He moved the knowns to one side and then the unknowns and.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Other side what we're going to do is we're going to treat this missing variable.",
                    "label": 0
                },
                {
                    "sent": "Probabilistically.",
                    "label": 0
                },
                {
                    "sent": "It's a missing function, actually, so an obvious choice is.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Something called the Gaussian process.",
                    "label": 0
                },
                {
                    "sent": "So a probabilistic model for the function.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "F of T. So what's the Gaussian process?",
                    "label": 0
                },
                {
                    "sent": "Well, let's think of Gaussian distributions.",
                    "label": 0
                },
                {
                    "sent": "First, it makes life a lot easier multivariate Gaussian distributions.",
                    "label": 0
                },
                {
                    "sent": "So a multivariate Gaussian distribution has this form.",
                    "label": 0
                },
                {
                    "sent": "It's got this sort of quadratic form up here with the mean and then the covariance in this case is K, and there's the normalization.",
                    "label": 0
                },
                {
                    "sent": "What we're going to do worry about is considering the special case where the.",
                    "label": 0
                },
                {
                    "sent": "The mean is 0.",
                    "label": 0
                },
                {
                    "sent": "Now this is completely sensible.",
                    "label": 0
                },
                {
                    "sent": "To do this.",
                    "label": 0
                },
                {
                    "sent": "I mean you can always put them back in, but it makes everything much easier if you do this actually as well, you can also put Gaussian priors over the mean, and if there's zero mean Gaussian priors over the mean, you would just end up with a form that looks like this anyway.",
                    "label": 0
                },
                {
                    "sent": "So it's quite a general special case as it were where you've got a zero mean Gaussian process, the Gaussian distribution.",
                    "label": 0
                },
                {
                    "sent": "So the only thing controlling this distribution is K, which will think of.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As a covariance matrix.",
                    "label": 0
                },
                {
                    "sent": "So what we're going to do is, we're going to think of a Gaussian distribution with a particular structure of covariance matrix, so it's a full covariance.",
                    "label": 0
                },
                {
                    "sent": "It's not independent across it's going to be 25 dimensional Gaussian.",
                    "label": 0
                },
                {
                    "sent": "It's not independent across these 25 dimensions.",
                    "label": 0
                },
                {
                    "sent": "There's correlations expressed between all these 25 dimensions and what we're going to do is we're going to generate 1 sample from that Gaussian distribution.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to show you is 1 sample from the Gaussian distribution and pull up the points of that sample against their index.",
                    "label": 0
                },
                {
                    "sent": "So that example is going to be a vector F. F1 to F-25 are going to be elements and will plot F1 to F-25 against.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It's index.",
                    "label": 0
                },
                {
                    "sent": "And this is what we see.",
                    "label": 0
                },
                {
                    "sent": "So this on the right is the covariance matrix.",
                    "label": 0
                },
                {
                    "sent": "Now it turns out to be a normalized covariance matrix.",
                    "label": 0
                },
                {
                    "sent": "So the diagonal is 1, so it's also a correlation matrix.",
                    "label": 0
                },
                {
                    "sent": "So what you see on the left is the one Gaussian sample from this covariance matrix.",
                    "label": 1
                },
                {
                    "sent": "Now what's interesting is if you look at their plotted against their index.",
                    "label": 0
                },
                {
                    "sent": "So this is index one and index two.",
                    "label": 0
                },
                {
                    "sent": "And if you look at index one and index to the correlation is very high, nearly one.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so you see these two points, a sample very close together as you move away.",
                    "label": 0
                },
                {
                    "sent": "So if we go from 1 to 15, so the correlation is 0.",
                    "label": 0
                },
                {
                    "sent": "So actually that's up there.",
                    "label": 0
                },
                {
                    "sent": "In fact this does look like it might be correlated with one, but it's just completely random.",
                    "label": 0
                },
                {
                    "sent": "It's happened to go up.",
                    "label": 0
                },
                {
                    "sent": "Back down again, so this well by the time you get out to what about seven data points?",
                    "label": 0
                },
                {
                    "sent": "A7 indexes away.",
                    "label": 0
                },
                {
                    "sent": "Sorry, not data points 7 steps away.",
                    "label": 0
                },
                {
                    "sent": "There's sort of no correlation between there and there, But the interesting thing is that you know humans naturally look at this.",
                    "label": 0
                },
                {
                    "sent": "This is just a discrete set of points, but you will naturally be thinking that looks like a smooth curve.",
                    "label": 0
                },
                {
                    "sent": "I hope it does look like a smooth curve as we go along it.",
                    "label": 0
                },
                {
                    "sent": "You can see that there's sort of nice smooth interpolation.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so the covariance matrix is showing the correlation, or in this case it's showing correlation as well between these two points.",
                    "label": 0
                },
                {
                    "sent": "FI&FJ if I is new.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "TJ the strong correlation?",
                    "label": 0
                },
                {
                    "sent": "There's less correlation if.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Ryan J distant so the ordering of the points that we chose meant that this function appears smooth by plotting them along this index.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This way.",
                    "label": 0
                },
                {
                    "sent": "But what I want to do is get a bit more insight into that by focusing on the joint distribution of two points from the 25.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we're going to look at two points from those 25 points, and we're going to look at F1 and F2 an what I've shown here is actually the numerical values from that covariance matrix.",
                    "label": 1
                },
                {
                    "sent": "So this is the upper left block that the correlation is very strong between F1 and F2.",
                    "label": 0
                },
                {
                    "sent": "It's .966 that gets that would get a statistician very excited.",
                    "label": 0
                },
                {
                    "sent": "If you saw that sort of correlation.",
                    "label": 0
                },
                {
                    "sent": "F1F2 plotted here and here and then.",
                    "label": 1
                },
                {
                    "sent": "This is 1 contour from the joint Gaussian density, so just sort of.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Reminder for some of you about Gaussians, this is a correlation over 25 indices.",
                    "label": 0
                },
                {
                    "sent": "If I want to marginalized 20, three of those and look at the correlation over the first 2 indicies, all I have to do is sort of put my can't reach it.",
                    "label": 0
                },
                {
                    "sent": "But I have to just block out all these rows and columns that are not associated with the 1st and 2nd index and that gives me the marginal distribution.",
                    "label": 0
                },
                {
                    "sent": "So it's a special nice property of Gaussians that I can get the marginal very easy.",
                    "label": 0
                },
                {
                    "sent": "The marginals just associated with the covariance up here.",
                    "label": 0
                },
                {
                    "sent": "So the covariance is very important and that sort of.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Property is kind of unusual in distributions, so this is the marginal distribution of F1 and F2.",
                    "label": 0
                },
                {
                    "sent": "Now the interesting thing is, what happens if we?",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The conditional distribution.",
                    "label": 0
                },
                {
                    "sent": "So let's say I observe F1 being here and then I condition on that object.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Ovation of F1 that gives me this conditional distribution for F2.",
                    "label": 0
                },
                {
                    "sent": "So what I get is F2 is negative as well, so the way you get that conditional is basically by projecting this Gaussian onto this line here.",
                    "label": 0
                },
                {
                    "sent": "So what we see is if we have observed that F1 is well about in the minus .5 or something then we also get F2 is mean close to minus .5 but with some variance.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If we were to look at more distant points F1 and F5.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We can do.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The same thing, but we get a much more diffuse situation, so there's some slight bias towards negative values for F2, but it's very very broad.",
                    "label": 0
                },
                {
                    "sent": "So by looking at the conditioning you can see why you're getting so.",
                    "label": 0
                },
                {
                    "sent": "Once I know for example.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That F1 is here.",
                    "label": 0
                },
                {
                    "sent": "That's telling me the broad range of distributions of F2 and then F5.",
                    "label": 0
                },
                {
                    "sent": "So we see actually F5 manages to get all the way up there in that area.",
                    "label": 0
                },
                {
                    "sent": "An F2 is there.",
                    "label": 0
                },
                {
                    "sent": "So if you look at those conditional.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Distributions you see under those conditional distributions, F2 is around here, which is very likely.",
                    "label": 0
                },
                {
                    "sent": "You know that's quite within one standard deviation or something of the corresponding.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Additional distribution.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Five same thing is all the way up there actually, but it still wants that in deviation of the conditional distribution.",
                    "label": 0
                },
                {
                    "sent": "So we can see how that's coming out and it's being determined by this weaker correlation here.",
                    "label": 0
                },
                {
                    "sent": "That's coming from that covariance structure.",
                    "label": 0
                },
                {
                    "sent": "So the basic message is all the information is.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In that covariance structure?",
                    "label": 0
                },
                {
                    "sent": "So where is this coming from?",
                    "label": 0
                },
                {
                    "sent": "Well, this is this is a function that's called a lot of things, so some people call it a Gaussian, but some people don't like that 'cause it's not got a normalization.",
                    "label": 0
                },
                {
                    "sent": "Some people call it squared exponential, and some people don't like that because it's not a squared exponential.",
                    "label": 0
                },
                {
                    "sent": "Some people call it a radial basis function, and some people don't like that.",
                    "label": 0
                },
                {
                    "sent": "'cause it reminds them of neural networks.",
                    "label": 0
                },
                {
                    "sent": "So I decided I'd call it an exponentiated quadratic covariance function.",
                    "label": 0
                },
                {
                    "sent": "Which is strictly speaking, accurate.",
                    "label": 0
                },
                {
                    "sent": "So what you've got is is this form here.",
                    "label": 0
                },
                {
                    "sent": "So we're building this structure.",
                    "label": 0
                },
                {
                    "sent": "So let's think of T initially is the index and L is some scale.",
                    "label": 0
                },
                {
                    "sent": "Some measure on this Euclidean distance.",
                    "label": 0
                },
                {
                    "sent": "So is the Euclidean distance between these indexes increases?",
                    "label": 0
                },
                {
                    "sent": "We basically get a smaller, larger distance away.",
                    "label": 0
                },
                {
                    "sent": "This exponent is negative and large, and this thing tends towards 0 if the distance is 0, then this thing is zero.",
                    "label": 0
                },
                {
                    "sent": "And the answer here is 1, so that's how well it.",
                    "label": 0
                },
                {
                    "sent": "Alpha actually, but if we set Alpha to one, then that's how we're forming this matrix.",
                    "label": 0
                },
                {
                    "sent": "So the covariance matrix is built using the inputs to the function T, so I've now started saying things like function because what I want you to think of is in first case it was a discrete Gaussian over 25 variables.",
                    "label": 0
                },
                {
                    "sent": "What we're going to do is just replace that discrete index by a continuous index T. So that's a bit of a freaky operation if you've never seen it before, but.",
                    "label": 0
                },
                {
                    "sent": "All you're saying is instead of having discrete inputs to form my covariance, I'm going to have continuous inputs so they're both 1 dimensional, so it's not freaky.",
                    "label": 0
                },
                {
                    "sent": "From that perspective, it's just freaky 'cause this is a continuous number.",
                    "label": 0
                },
                {
                    "sent": "So now we can ask about conditioning on this Gaussian distribution for between any two time points instead of any two indexes like we were looking at before, and we can sample.",
                    "label": 0
                },
                {
                    "sent": "We can write down, we can ask to sample from a Gaussian distribution for a bunch of different.",
                    "label": 0
                },
                {
                    "sent": "Time points which have now become.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Rindex and if we do that sort of thing.",
                    "label": 0
                },
                {
                    "sent": "So here I've made the time go from minus one to one.",
                    "label": 0
                },
                {
                    "sent": "Obviously this looks like a continuous function, but I'm doing it in Matlab, so the way I'm doing this is by sampling like 400 points.",
                    "label": 0
                },
                {
                    "sent": "So this is a 400 dimensional Gaussian.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With time being input to create this code.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Variance function and this being my output and I can sample all this.",
                    "label": 0
                },
                {
                    "sent": "Each line is a different sample and they all look like curves, so I've set particular parameters.",
                    "label": 0
                },
                {
                    "sent": "Here.",
                    "label": 0
                },
                {
                    "sent": "I've set the length scale is .3 and this Alpha which controls the scale in the Y axis.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To one, but I could change that length scale and make the length scale longer and you get slower varying functions.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Who I can make that shorter again, an increase the vertical length scale or the vertical variants and then get functions that have?",
                    "label": 0
                },
                {
                    "sent": "Go over a wider range.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So actually if you look at these, you see these four within pretty much standard deviation of this thing.",
                    "label": 0
                },
                {
                    "sent": "Here is 1 so they all fall approximately within 2 standard deviations of the mean, which is 0 because the mean function.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Zero and the same here.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here by making A4.",
                    "label": 0
                },
                {
                    "sent": "The standard deviation is 2, so you get them falling between 4:00 and minus four, broadly speaking, so there's actual sensible.",
                    "label": 0
                },
                {
                    "sent": "Physical interpretations of what these parameters are doing.",
                    "label": 0
                },
                {
                    "sent": "There's this L has a sort of interpretation for number of crossings of the zero point that you expect in a particular interval.",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here's another one, so this is a linear covariance function, so it's a covariance function, so one way of doing linear models is just to write down a linear model.",
                    "label": 0
                },
                {
                    "sent": "Another is to do it by Gaussian process, and then you can sample from the Gaussian process and you see.",
                    "label": 0
                },
                {
                    "sent": "Very oddly things coming out a linear functions, but everything is encoded in a covariance function.",
                    "label": 0
                },
                {
                    "sent": "It's not immediately apparent that that's going to happen when you write down the.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Variance function, but that is what happens.",
                    "label": 0
                },
                {
                    "sent": "This is another one I like which doesn't have this tendency to stay around zero.",
                    "label": 0
                },
                {
                    "sent": "It's sort of a covariance function that was derived by Chris Williams based on sort of neural network models.",
                    "label": 0
                },
                {
                    "sent": "It has these parameters which have interpretations of.",
                    "label": 0
                },
                {
                    "sent": "If you know about neural networks, sort of MLP neural networks.",
                    "label": 0
                },
                {
                    "sent": "This is the prior variance on the weights of the neural network and this is the prior variance on the biases of the neural network.",
                    "label": 0
                },
                {
                    "sent": "So the interesting thing is if you reduce that enforce the biases to all be at 0 so.",
                    "label": 0
                },
                {
                    "sent": "All the signal.",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's in your neural network are at zero.",
                    "label": 0
                },
                {
                    "sent": "You can get funky functions like this, so this is an infinite number of sigmoidal functions sitting on top of each other at the origin, so you get because we put this parameter down to zero, so there's lots of different covariance function.",
                    "label": 0
                }
            ]
        },
        "clip_80": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can build this is just adding a bias term so that you can have a non zero function but you don't cooperate priority.",
                    "label": 0
                },
                {
                    "sent": "What your biases so it can sort of move up and down like that.",
                    "label": 0
                }
            ]
        },
        "clip_81": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the point is, you can add these things together.",
                    "label": 0
                },
                {
                    "sent": "So what here I'm showing is a combination of that exponentiated quadratic plus the bias.",
                    "label": 0
                },
                {
                    "sent": "So it's allowed to move up and down plus some noise.",
                    "label": 0
                },
                {
                    "sent": "So I put noise on top to give these sort of little disturb.",
                    "label": 0
                }
            ]
        },
        "clip_82": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Lines.",
                    "label": 0
                },
                {
                    "sent": "Another really interesting one which brings a big overlap in with physics is the Ornstein Uhlenbeck.",
                    "label": 0
                },
                {
                    "sent": "There's also a Brownian motion covariance function, but this is like a stationary.",
                    "label": 0
                },
                {
                    "sent": "This is the uniquely defined stationary Gauss Markov process, so this is a Markov process that is also a Gaussian process that is also stationary and its covariance function has the form of instead of a exponentiated quadratic.",
                    "label": 0
                },
                {
                    "sent": "It's an exponentiated absolute.",
                    "label": 0
                },
                {
                    "sent": "To.",
                    "label": 0
                }
            ]
        },
        "clip_83": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, So what can you do with that?",
                    "label": 0
                },
                {
                    "sent": "Well, once you've defined your covariance function, actually all you need is your data.",
                    "label": 0
                },
                {
                    "sent": "So these models are called nonparametric because.",
                    "label": 0
                },
                {
                    "sent": "You just combine as you add data to them.",
                    "label": 0
                },
                {
                    "sent": "That's what defines what the final posterior.",
                    "label": 0
                },
                {
                    "sent": "Mean function is.",
                    "label": 0
                },
                {
                    "sent": "So the way we get.",
                    "label": 0
                },
                {
                    "sent": "Results out of these things is that operation I did earlier where you take the covariance function and you combine it with an observation.",
                    "label": 0
                },
                {
                    "sent": "You can also combine it with two observations and then you can ask what the prediction is, what the predictive mean is for all other time points.",
                    "label": 0
                },
                {
                    "sent": "So here we're taking a exponentiated quadratic covariance function in two data points and what we're doing is we're not having any noise on this system, so this is a noiseless system.",
                    "label": 0
                },
                {
                    "sent": "We combine it with the covariance function with the party.",
                    "label": 0
                }
            ]
        },
        "clip_84": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The length scale and this is what we get as a prediction, so the original prediction would have been flat with error bars at 2 standard deviations, but once we've seen these two data points, we know that the function must go through those two data points.",
                    "label": 0
                },
                {
                    "sent": "The length scale of the function tells us how expect how rapidly we expect it to move away from those data points, and therefore gives us these error bars.",
                    "label": 0
                },
                {
                    "sent": "With this sort of mean and error bars at 2 standard deviations.",
                    "label": 0
                }
            ]
        },
        "clip_85": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now as we.",
                    "label": 0
                }
            ]
        },
        "clip_86": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "More data then we become more confident about the function.",
                    "label": 0
                }
            ]
        },
        "clip_87": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So you should see the data is typically falling within the error bars.",
                    "label": 0
                }
            ]
        },
        "clip_88": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_89": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And actually in this case it collapses down almost to absolute certainty.",
                    "label": 0
                },
                {
                    "sent": "It isn't quite absolute certainty, but it looks like it certainly to the human eye across the range of where the data is.",
                    "label": 0
                },
                {
                    "sent": "The reason why you're getting absolute certainty is sort of related a bit to Nyquist sampling theorems in signal processing.",
                    "label": 0
                },
                {
                    "sent": "So because the length scale is equivalent to the window of frequencies you expect, there's in fact an interpretation for Gaussian processes in frequency space.",
                    "label": 0
                },
                {
                    "sent": "So as you start observing your data points at certain close together intervals.",
                    "label": 0
                },
                {
                    "sent": "Then this function has getting a certain rigidity.",
                    "label": 0
                },
                {
                    "sent": "You can think of if you are splines, type person, which means that it's not possible for it to move away any further from like where the data points are.",
                    "label": 0
                },
                {
                    "sent": "So you get you become very confident about what the error bars are.",
                    "label": 0
                },
                {
                    "sent": "That's also side effect of property of this covariance function, which is infinitely smooth.",
                    "label": 0
                },
                {
                    "sent": "So when one downside to this covariance function is, you can perhaps become two.",
                    "label": 0
                }
            ]
        },
        "clip_90": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Confident without warrant.",
                    "label": 0
                },
                {
                    "sent": "So you can actually there was a noiseless system, and the sort of thing you can do is you can add noise to your Gaussian process, so that's what this is supposed to indicate here.",
                    "label": 0
                },
                {
                    "sent": "So the relationship between time and some unobserved function.",
                    "label": 0
                },
                {
                    "sent": "Is a Gaussian process with some parameters Theta, but then you may add Gaussian noise so Gaussian noise can be added independently.",
                    "label": 0
                },
                {
                    "sent": "That's what this plate notation is supposed to be indicating for every data point you.",
                    "label": 0
                }
            ]
        },
        "clip_91": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Observe.",
                    "label": 0
                },
                {
                    "sent": "So you end up with this relationship between F, the unobserved function and what you observe X, which is just Gaussian and independent.",
                    "label": 0
                },
                {
                    "sent": "Now it turns out that's equivalent to another covariance function.",
                    "label": 0
                },
                {
                    "sent": "I've already shown you samples from it.",
                    "label": 0
                },
                {
                    "sent": "That covariance function is simply.",
                    "label": 0
                },
                {
                    "sent": "I mean, this is the Kronecker Delta, so it's a diagonal times Sigma squared, which makes sense, it's just the product across data points, so it's an independent Gaussian, so it's just a diagonal Gaussian with constant variance.",
                    "label": 0
                },
                {
                    "sent": "Now the really nice thing about Gaussians?",
                    "label": 0
                },
                {
                    "sent": "If I add two Gaussian random variables together, the result of doing that is also Gaussian.",
                    "label": 0
                },
                {
                    "sent": "The covariance of the result is the sum of the covariances of the two variables I was interested in.",
                    "label": 0
                },
                {
                    "sent": "So if I know the covariance of my underlying function, the smooth thing that's one term and then I have this covariance of the noise, I just have to add this noise covariance to my underlying smooth covariance.",
                    "label": 0
                },
                {
                    "sent": "I just have to sum these covariances together and I get some defect, so I think they call these.",
                    "label": 0
                },
                {
                    "sent": "Additive models in statistics, but they're just there like super trivial for Gaussian processes, and you can Add all these props.",
                    "label": 0
                }
            ]
        },
        "clip_92": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Tease him.",
                    "label": 0
                },
                {
                    "sent": "And if you do that with another similar data example.",
                    "label": 0
                }
            ]
        },
        "clip_93": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi, you get this sort of effect.",
                    "label": 0
                },
                {
                    "sent": "So now the date of the infant.",
                    "label": 0
                }
            ]
        },
        "clip_94": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Doesn't pass directly.",
                    "label": 0
                }
            ]
        },
        "clip_95": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Through the points, it can pass either side.",
                    "label": 0
                }
            ]
        },
        "clip_96": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the error bars.",
                    "label": 0
                }
            ]
        },
        "clip_97": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Are reflecting.",
                    "label": 0
                }
            ]
        },
        "clip_98": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Estimate of the noise.",
                    "label": 0
                }
            ]
        },
        "clip_99": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now some of you with Colonel backgrounds may have been thinking that this.",
                    "label": 0
                },
                {
                    "sent": "Covariance function is very similar to a kernel.",
                    "label": 0
                },
                {
                    "sent": "An indeed it is, and the reason is as follows.",
                    "label": 0
                },
                {
                    "sent": "Because the kernel, as in a Mercer kernel, people using support vector machines is required to be positive definite so that this infinite dimensional funky feature space exists.",
                    "label": 0
                },
                {
                    "sent": "Now in a Gaussian process a covariance function is coming from producing a covariance matrix, which is also required to be positive definite.",
                    "label": 0
                },
                {
                    "sent": "So the requirements for covariance function are the same as the requirements from Mercer Kernel and these methods.",
                    "label": 0
                },
                {
                    "sent": "Very closely related, so if you don't know about.",
                    "label": 0
                },
                {
                    "sent": "Gaussian processes, then one of the ways you can think of them is there like kernel methods, but only a lot better.",
                    "label": 0
                },
                {
                    "sent": "And the reason they're a lot better is the following.",
                    "label": 0
                },
                {
                    "sent": "You have a likelihood associated with this, so you make these observations of your data X.",
                    "label": 0
                },
                {
                    "sent": "And you can compute the likelihood, which is just the likelihood of a 0 mean Gaussian.",
                    "label": 0
                },
                {
                    "sent": "What you can then do though, is you can ask the question what happens to this likelihood?",
                    "label": 0
                },
                {
                    "sent": "As I change the parameters in this case, I'm going to change the length scale.",
                    "label": 0
                },
                {
                    "sent": "So here we're on a very short length scale and this is the resulting interpolation, so it may not appeal to you very much now, but these two terms in here one is an entropy term and one is like a data fit term, so this is matching K to X and this is just the entropy of K, so this is like the capacity of this system and what we're going to do is we'll play.",
                    "label": 0
                }
            ]
        },
        "clip_100": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As we change the length scales.",
                    "label": 0
                }
            ]
        },
        "clip_101": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_102": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "These different terms, so let me get this right.",
                    "label": 0
                },
                {
                    "sent": "So takes awhile to.",
                    "label": 0
                }
            ]
        },
        "clip_103": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What we sought out with is what's going to be dropping.",
                    "label": 0
                },
                {
                    "sent": "Is the data fit term because as we reduce the length scale?",
                    "label": 0
                }
            ]
        },
        "clip_104": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We fit this data.",
                    "label": 0
                }
            ]
        },
        "clip_105": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, you'll see that yeah, so we're not fitting this data that well, so here at the top we've got the data fit term, which is dropping.",
                    "label": 0
                }
            ]
        },
        "clip_106": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_107": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And what we're going to be improving is the.",
                    "label": 0
                }
            ]
        },
        "clip_108": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Entropy term.",
                    "label": 0
                }
            ]
        },
        "clip_109": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the.",
                    "label": 0
                }
            ]
        },
        "clip_110": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Combination of.",
                    "label": 0
                }
            ]
        },
        "clip_111": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is 2 though leads to this.",
                    "label": 0
                },
                {
                    "sent": "So this is the entropy term.",
                    "label": 0
                },
                {
                    "sent": "This is the data fit term, but when you add those two together so normally naive non Bayesians basically spend their time working with this and that says get over to the left hand side.",
                    "label": 1
                },
                {
                    "sent": "Make the length scale as short as possible.",
                    "label": 1
                },
                {
                    "sent": "This is the capacity term arises naturally from the Gaussian distribution and the sum of these two leads to this.",
                    "label": 0
                },
                {
                    "sent": "The log likelihood and what you see is the log likelihood has a maximum of one, and since I generated this data well, it probably will have a maximum just off 1.",
                    "label": 0
                },
                {
                    "sent": "Actually, 'cause I'm just showing discrete time points in terms of the discrete point, discrete length scale points to the discrete points, the length scale maximum is 1 an.",
                    "label": 0
                },
                {
                    "sent": "Actually I generated that data from a function with the length scale of 1, so it recovers the parameter of the kernel matrix, which is something it's very difficult to do with kernel matrices.",
                    "label": 0
                },
                {
                    "sent": "With kernel methods trivial to do with Gaussian process, as long as you accept you're going to have to do a nonlinear optimization.",
                    "label": 0
                },
                {
                    "sent": "The optimization of this you would do by gradient based methods.",
                    "label": 1
                },
                {
                    "sent": "You would use scale, conjugate gradient, or quasi Newton, whatever your favorite gradient based optimization azatian is, it's not necessarily convex.",
                    "label": 0
                },
                {
                    "sent": "It may have nasty properties as long as you're prepared to accept that fitting your kernel parameters is trivial, that becomes very important for what we're going to return to.",
                    "label": 0
                },
                {
                    "sent": "Just transcriptional regulation.",
                    "label": 0
                },
                {
                    "sent": "The example I talked about for the 1st of 20 minutes.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Any question about Gaussian processes, I should say.",
                    "label": 0
                },
                {
                    "sent": "Covering the ground there something like we can do that just 10 fold cross validation for yeah, so let me give you 30 parameters an let me see how you manage to do your 10 fold cross validation plan.",
                    "label": 0
                },
                {
                    "sent": "OK so leave one out.",
                    "label": 0
                },
                {
                    "sent": "Cross Validation is another approach to doing it so.",
                    "label": 0
                },
                {
                    "sent": "I think Olivier Chappelle has shown very nicely that you can write down.",
                    "label": 0
                },
                {
                    "sent": "Leave one out cross validation measures that can be measured optimized with respect to those 30 parameters.",
                    "label": 0
                },
                {
                    "sent": "Interestingly, very few people seem to do it.",
                    "label": 0
                },
                {
                    "sent": "I don't know why, and if you ask Olivier Chappelle, I think he would say just use a Gaussian process so there I don't know all the details.",
                    "label": 0
                },
                {
                    "sent": "But there are also other interesting reasons about when cross validations good and when Bayesian optimization is good.",
                    "label": 0
                },
                {
                    "sent": "But basically yeah, I mean, I leave one out.",
                    "label": 0
                },
                {
                    "sent": "I would accept that, but no one is doing it now.",
                    "label": 0
                },
                {
                    "sent": "I've never seen anyone optimize 30 parameters, so we're doing that.",
                    "label": 0
                },
                {
                    "sent": "We're about to do that with no problem without buying an eyelid.",
                    "label": 0
                },
                {
                    "sent": "But yeah, leave one out is a potential thing you could do.",
                    "label": 0
                },
                {
                    "sent": "We have just.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so that's why that's why we as a Gaussian process community suffered in the face of support vector machines.",
                    "label": 0
                },
                {
                    "sent": "When you start doing things like digit classification, because fundamentally there's just one parameter to fit everyone sort of fits it multiple times and then shows the best of their results on the test data.",
                    "label": 0
                },
                {
                    "sent": "And there's not much you can do to demonstrate the way what you get out of the Gaussian process, apart from like these error bars.",
                    "label": 0
                },
                {
                    "sent": "I think now, so I spent a portion of my research career trying to demonstrate Gaussian processes were as good as support vector machines.",
                    "label": 0
                },
                {
                    "sent": "I think it's sort of pointless for the reasons that you just pointed out what you can do with Gaussian processes that you can't do with kernel methods.",
                    "label": 0
                },
                {
                    "sent": "Is this very low data scenario that we're going to talk about next?",
                    "label": 0
                },
                {
                    "sent": "So number of data points we're going to use is going to be very few, and the number of parameters will fit with.",
                    "label": 0
                }
            ]
        },
        "clip_112": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At large.",
                    "label": 0
                },
                {
                    "sent": "So the 1st order differential equation.",
                    "label": 0
                },
                {
                    "sent": "So any other questions so.",
                    "label": 0
                },
                {
                    "sent": "OK, so back to this first.",
                    "label": 0
                }
            ]
        },
        "clip_113": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sort of differential equations so it turns out that if you assume F of T is a Gaussian process, this equation here implies the X of T is also a Gaussian process, so the result of solving this differential equation leads to a linear operator and a linear operator on a Gaussian process is a Gaussian process.",
                    "label": 0
                },
                {
                    "sent": "I'll review the.",
                    "label": 0
                }
            ]
        },
        "clip_114": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In a second, but then you Gaussian process is over F of T and all the targets.",
                    "label": 0
                },
                {
                    "sent": "So you get this expanded Gaussian process that is not just over one function, it's over multiple functions, so it's over the latent function, the one you haven't observed, and the observed ones.",
                    "label": 0
                },
                {
                    "sent": "This means you can transfer information from the observed.",
                    "label": 0
                }
            ]
        },
        "clip_115": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Gene expression to the latent function.",
                    "label": 0
                },
                {
                    "sent": "And the new covariance matrix which we have to compare.",
                    "label": 0
                }
            ]
        },
        "clip_116": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Who gives correlations between all these functions?",
                    "label": 0
                },
                {
                    "sent": "Now this gives us a probabilistic model for transcriptional regulation.",
                    "label": 0
                }
            ]
        },
        "clip_117": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What I think is an extremely elegant way, and this is the way it works out.",
                    "label": 0
                },
                {
                    "sent": "So let's look at the top first.",
                    "label": 0
                },
                {
                    "sent": "So this is the solution of that differential equation, ignoring the transient terms now.",
                    "label": 0
                },
                {
                    "sent": "This is F of you.",
                    "label": 0
                },
                {
                    "sent": "This was our Gaussian process and this is just a standard exponential and another exponential that arise from the solution to the differential equation.",
                    "label": 0
                },
                {
                    "sent": "So if you're not used to looking at these convolutions, it's a Laplacian one.",
                    "label": 0
                },
                {
                    "sent": "It goes from nought to T. It might appear a little bit intimidating, but there's another way of looking at it.",
                    "label": 0
                },
                {
                    "sent": "So you see, that's constant.",
                    "label": 0
                },
                {
                    "sent": "Plus this thing times an integral of.",
                    "label": 0
                }
            ]
        },
        "clip_118": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Two functions multiplied together, but if I were to write it like this constant X is equal to a constant plus an inner product of something I've just called either some over a bunch of eyes of these Tees times F, so where's F is drawn from a multivariate Gaussian?",
                    "label": 0
                },
                {
                    "sent": "If I were to write it like that, then I hope that you wouldn't be too upset.",
                    "label": 0
                },
                {
                    "sent": "If I told you all the result of this.",
                    "label": 0
                },
                {
                    "sent": "If I if I say this is a Gaussian and I add something to a Gaussian that gives me a mean on the Gaussian.",
                    "label": 0
                },
                {
                    "sent": "And the covariance as a result of an inner product applied to Gaussian distributed random variable is just going to be the sum of the double inner products of E with that Sigma.",
                    "label": 0
                },
                {
                    "sent": "So that's the case for a discrete Gaussian distribution.",
                    "label": 0
                },
                {
                    "sent": "Now the case for.",
                    "label": 0
                }
            ]
        },
        "clip_119": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The continuous case is just the same, only involves a bunch of integrals over the covariance functions.",
                    "label": 0
                },
                {
                    "sent": "So instead of summing over these eyes, you're integrating over the tease analytic.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's the headache.",
                    "label": 0
                },
                {
                    "sent": "So what you do with this first one is you spend ages working it out yourself.",
                    "label": 0
                },
                {
                    "sent": "What you do with the later one is you get a guy from Finland to visit you, and you have him work it all out because it's much harder than the first one.",
                    "label": 0
                },
                {
                    "sent": "Very very involved, but the principles there.",
                    "label": 0
                },
                {
                    "sent": "And you can do it.",
                    "label": 0
                },
                {
                    "sent": "And it turns out to be an analytic, and this is the result.",
                    "label": 0
                },
                {
                    "sent": "So this is the form of the covariance function, where we now get to put in.",
                    "label": 0
                },
                {
                    "sent": "Here is the original thing we started with.",
                    "label": 0
                },
                {
                    "sent": "Just act exponentiated quadratic up the top.",
                    "label": 0
                },
                {
                    "sent": "But now we can compute cross covariances between it and target genes and this is what they look like there.",
                    "label": 0
                },
                {
                    "sent": "In this case we've had one of these is strongly high decay, high sensitivity ones, medium decay, medium sensitivity ones, low decay, low sensitivity.",
                    "label": 0
                },
                {
                    "sent": "So this high decay high sensitivity frame work is the one we talked about before I said.",
                    "label": 0
                },
                {
                    "sent": "Well, if all these things are very high, basically it doesn't matter.",
                    "label": 0
                },
                {
                    "sent": "It's a differential equation, and indeed you see very strong correlations between X1 and F1.",
                    "label": 0
                },
                {
                    "sent": "Basically, this will sample something very similar to F. As you reduce the decay and sensitivity, those correlations become weaker and you get something that's much more diffuse in its correlation between this potential target and that F. Are there any questions about what this is trying to show?",
                    "label": 0
                },
                {
                    "sent": "I'm not sure I explained that very clearly.",
                    "label": 0
                },
                {
                    "sent": "So basically now you end up with a situation where you would not just having a covariance function overtime points, you've got a covariance function over M RNA expression as well, and it's correlating the M RNA expression to the latent function.",
                    "label": 0
                },
                {
                    "sent": "Extreme itself is lower than.",
                    "label": 0
                },
                {
                    "sent": "Yeah, interesting, I think that's a result of.",
                    "label": 0
                },
                {
                    "sent": "I think that's it's not going to be a result of.",
                    "label": 0
                },
                {
                    "sent": "Potentially just this sensitivity being low because it's pre multiplying that portion.",
                    "label": 0
                },
                {
                    "sent": "Yeah that I think that will be it that you basically one of the terms in this covariance is a multiplication of.",
                    "label": 0
                },
                {
                    "sent": "The sensitivity.",
                    "label": 0
                },
                {
                    "sent": "On these terms and the sensitivity squared on the diagonal.",
                    "label": 0
                },
                {
                    "sent": "So if the sensitivity squared is .5 then this thing ends up being lower.",
                    "label": 0
                }
            ]
        },
        "clip_120": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, So what I can do is before we were showing samples from an exponentiated quadratic on its own, an underlying here is the same thing.",
                    "label": 0
                },
                {
                    "sent": "So this F of T is one of those samples like the one I showed you at the beginning.",
                    "label": 0
                },
                {
                    "sent": "The black thing, yeah?",
                    "label": 0
                },
                {
                    "sent": "But here we jointly sampled.",
                    "label": 0
                },
                {
                    "sent": "The black thing with some of these targets.",
                    "label": 0
                },
                {
                    "sent": "So three of these targets the red, the green, and the blue.",
                    "label": 0
                },
                {
                    "sent": "We actually constrained them all to start at zero as well.",
                    "label": 0
                },
                {
                    "sent": "So what's interesting about that is you see that the red, which is the high decay high sensitivity.",
                    "label": 0
                },
                {
                    "sent": "The target basically tracks black.",
                    "label": 0
                },
                {
                    "sent": "As we suggested early on when we said if you were doing clustering, you're looking for targets like that.",
                    "label": 0
                },
                {
                    "sent": "Green is the lower decay, lower sensitivity and blue is the lowest decay.",
                    "label": 0
                },
                {
                    "sent": "Lower sensitivity.",
                    "label": 0
                },
                {
                    "sent": "So coming back to it is lower variance than the other functions.",
                    "label": 0
                },
                {
                    "sent": "I suppose that's inevitable, because if it's going only up when those guys go up and it's tracking behind them, it will end up being lower variance which.",
                    "label": 0
                },
                {
                    "sent": "Comes out in the covariance.",
                    "label": 0
                }
            ]
        },
        "clip_121": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Function as was pointed out before, here's another example.",
                    "label": 0
                },
                {
                    "sent": "So in this case Black is sort of oscillating a bit more wildly and red is following it again.",
                    "label": 0
                },
                {
                    "sent": "High decay, high sensitivity, blue and green are following it, lesser the point of this type of modeling is you might not cluster cluster blue and red, so you might not understand.",
                    "label": 0
                },
                {
                    "sent": "Blue and red are both targets of black.",
                    "label": 0
                },
                {
                    "sent": "Unless you've got the differential equation model, you wouldn't pick it out from this clustering.",
                    "label": 0
                }
            ]
        },
        "clip_122": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another example, I just like doing this.",
                    "label": 0
                }
            ]
        },
        "clip_123": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Samples and another example.",
                    "label": 0
                },
                {
                    "sent": "So you just see the same pattern with each sample.",
                    "label": 0
                },
                {
                    "sent": "So these are joint samples from the system.",
                    "label": 0
                },
                {
                    "sent": "What's rather funky about it is just sort of jointly sampling at the same time the.",
                    "label": 0
                },
                {
                    "sent": "Solution to the differential equation or that you're inverting the convolution somehow at the same time as you're doing this sampling 'cause you did all this analytical work beforehand, which is quite unusual.",
                    "label": 0
                }
            ]
        },
        "clip_124": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the framework is so before we saw these plots where I was showing direct observations of a function and showing how the error bars changed.",
                    "label": 0
                },
                {
                    "sent": "But the framework here is slightly different.",
                    "label": 0
                },
                {
                    "sent": "We're going to see observations of the M RNA's, which are the gene expression measurements and will look to see how the.",
                    "label": 0
                },
                {
                    "sent": "Estimate of the transcription factor activity changes.",
                    "label": 0
                },
                {
                    "sent": "So in this case it's an artificial system with two bumps, two transcription transcription factor is 2 bumps and the parameters are realistic parameters.",
                    "label": 0
                },
                {
                    "sent": "While they're all high sensitivity but once high decay ones, medium decay ones loader case.",
                    "label": 0
                },
                {
                    "sent": "So this one just integrates the two bumps in effect, whereas this one follows them fairly closely.",
                    "label": 0
                },
                {
                    "sent": "I'm not showing you the fitting of the parameters which we talked about earlier in this system.",
                    "label": 0
                },
                {
                    "sent": "There are, I think, 11 parameters.",
                    "label": 0
                },
                {
                    "sent": "They were all fitted from the data I'm showing.",
                    "label": 0
                },
                {
                    "sent": "Once they've been fitted what the inference is?",
                    "label": 0
                },
                {
                    "sent": "I know what those parameters are, but I did parameter fits using the data that you'll see here and now.",
                    "label": 0
                }
            ]
        },
        "clip_125": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I want to sort of show how the inference process.",
                    "label": 0
                }
            ]
        },
        "clip_126": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now you make observations.",
                    "label": 0
                }
            ]
        },
        "clip_127": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the gene expression area, but it.",
                    "label": 0
                }
            ]
        },
        "clip_128": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Takes influence.",
                    "label": 0
                }
            ]
        },
        "clip_129": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On",
                    "label": 0
                }
            ]
        },
        "clip_130": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What happens for your estimate of the?",
                    "label": 0
                }
            ]
        },
        "clip_131": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Transcription factor.",
                    "label": 0
                }
            ]
        },
        "clip_132": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Activities now I've made realistic noises.",
                    "label": 0
                }
            ]
        },
        "clip_133": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Options say you can.",
                    "label": 0
                }
            ]
        },
        "clip_134": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "See.",
                    "label": 0
                }
            ]
        },
        "clip_135": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The noise has an effect on what the estimate is so.",
                    "label": 0
                }
            ]
        },
        "clip_136": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Quite high Arabic.",
                    "label": 0
                }
            ]
        },
        "clip_137": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_138": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But the point is as.",
                    "label": 0
                }
            ]
        },
        "clip_139": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You observe more.",
                    "label": 0
                }
            ]
        },
        "clip_140": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Jeans.",
                    "label": 0
                }
            ]
        },
        "clip_141": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_142": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_143": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Obviously the.",
                    "label": 0
                }
            ]
        },
        "clip_144": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Noise is sort of in.",
                    "label": 0
                }
            ]
        },
        "clip_145": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Pendant across Jean.",
                    "label": 0
                }
            ]
        },
        "clip_146": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But the underlying.",
                    "label": 0
                }
            ]
        },
        "clip_147": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Transcription factor.",
                    "label": 0
                }
            ]
        },
        "clip_148": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "File.",
                    "label": 0
                }
            ]
        },
        "clip_149": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is concern.",
                    "label": 0
                }
            ]
        },
        "clip_150": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Say.",
                    "label": 0
                }
            ]
        },
        "clip_151": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You end up with a better.",
                    "label": 0
                }
            ]
        },
        "clip_152": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Even better estimate.",
                    "label": 0
                }
            ]
        },
        "clip_153": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At.",
                    "label": 0
                }
            ]
        },
        "clip_154": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of what the true trance?",
                    "label": 0
                }
            ]
        },
        "clip_155": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which in fact are active.",
                    "label": 0
                }
            ]
        },
        "clip_156": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "She is and if your estimate isn't good, you have these large error bars to show you that something wrong.",
                    "label": 0
                },
                {
                    "sent": "That's the beauty of Gaussian process.",
                    "label": 0
                },
                {
                    "sent": "So that's having observed three jeans with what, 123456789, ten, 11, twelve, 1314 fifteen 1617 time points.",
                    "label": 0
                },
                {
                    "sent": "In practice, we may be looking at.",
                    "label": 0
                },
                {
                    "sent": "We've done things as low as five jeans, six time points, that sort of order, so quite small systems.",
                    "label": 0
                },
                {
                    "sent": "So this covariant.",
                    "label": 0
                },
                {
                    "sent": "The size of this covariance matrix that we need to compute.",
                    "label": 0
                },
                {
                    "sent": "I won't go all the way back is only going to be in these small cases.",
                    "label": 0
                },
                {
                    "sent": "This is going to be about 60.",
                    "label": 0
                }
            ]
        },
        "clip_157": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "60 So quite small.",
                    "label": 0
                },
                {
                    "sent": "So we published this idea in ECB in 2008.",
                    "label": 0
                },
                {
                    "sent": "With Pai Gow with this sort of lead postdoc on it and Auntie we published the early result on the Cascade system I'm going to.",
                    "label": 0
                }
            ]
        },
        "clip_158": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "About next I. OK, so this is a sort of result on real data.",
                    "label": 0
                },
                {
                    "sent": "Now the first thing you might say this is the data from Barangka.",
                    "label": 0
                },
                {
                    "sent": "The first thing you might say is all up, but all those profiles are the same.",
                    "label": 0
                },
                {
                    "sent": "Well, that's not surprising because known targets of transcription factors tend to have very similar profiles because people have been using clustering to identify them.",
                    "label": 0
                },
                {
                    "sent": "Um, so we can infer that.",
                    "label": 0
                }
            ]
        },
        "clip_159": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of protein activity.",
                    "label": 0
                }
            ]
        },
        "clip_160": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But here's an example where the profiles can be very different, so here's.",
                    "label": 0
                },
                {
                    "sent": "123456 known targets of so 1345 known targets in an elk one system.",
                    "label": 0
                },
                {
                    "sent": "And this is our inference of the transcription factor activity.",
                    "label": 1
                },
                {
                    "sent": "But notice here that it the Dick.",
                    "label": 0
                }
            ]
        },
        "clip_161": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A rate is obviously lower and then we can do things like rank potential targets, so this is a target of the gene that is predicted as a true target and this is a.",
                    "label": 0
                }
            ]
        },
        "clip_162": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Rated nontarget.",
                    "label": 0
                }
            ]
        },
        "clip_163": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Team so just quickly I want to mention we had a paper in PNS.",
                    "label": 0
                },
                {
                    "sent": "Part was published this year that used an extended idea that Auntie and Magnus came up with sits on top.",
                    "label": 0
                }
            ]
        },
        "clip_164": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This model, so the extended idea is basically to include the fact that the transcription factor protein has a governing M RNA, so each transcription factor has its own M RNA and add a model of translation.",
                    "label": 0
                },
                {
                    "sent": "Now in the P53 system, translation isn't really occur in phosphorylation is what activates the system.",
                    "label": 0
                },
                {
                    "sent": "But in a developmental system this is quite a potentially interesting model for the system.",
                    "label": 0
                }
            ]
        },
        "clip_165": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in collaboration with the Furlong lab in the NBL, we looked at mesoderm development in Drosophila.",
                    "label": 0
                },
                {
                    "sent": "So what we did is we there the wild type.",
                    "label": 0
                },
                {
                    "sent": "My career experiments are publicly available in this embryonic developmental stage.",
                    "label": 0
                },
                {
                    "sent": "And it's across the formation of the heart and other muscle systems.",
                    "label": 0
                },
                {
                    "sent": "So what we're interested in is, can we use this cascaded model idea to predict viable targets of a known transcr?",
                    "label": 0
                }
            ]
        },
        "clip_166": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In fact.",
                    "label": 0
                },
                {
                    "sent": "So in this case the model is.",
                    "label": 0
                },
                {
                    "sent": "Slightly modified.",
                    "label": 0
                },
                {
                    "sent": "So now we have the same protein being produced by an M RNA that we can also observe.",
                    "label": 0
                },
                {
                    "sent": "So this is unknown.",
                    "label": 0
                },
                {
                    "sent": "But this is known.",
                    "label": 0
                },
                {
                    "sent": "And this is our simple model of translation.",
                    "label": 0
                },
                {
                    "sent": "Again, a first order differential equation and it solved in a similar way to our previous one.",
                    "label": 0
                }
            ]
        },
        "clip_167": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now we can look at a joint Gaussian process over Y FX-1 and X2.",
                    "label": 0
                },
                {
                    "sent": "We also realized another way of doing it rich for being a lot quicker would have been supporting at RBF covariance function over F. And differentiate to get the covariance function for Y.",
                    "label": 0
                },
                {
                    "sent": "So in some sense that means we can immediately do a three layer network by looking at differentiation to get the guy above Y, but we haven't done that yet.",
                    "label": 0
                },
                {
                    "sent": "So in this cascade system you've basically got Y in at the top that drives the output of F, which drives the output of X.",
                    "label": 0
                },
                {
                    "sent": "Now the nice thing about this.",
                    "label": 0
                }
            ]
        },
        "clip_168": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "OK, we can again do these samples, so here this is the M RNA of the transcription factor, then black is the transcription factor concentration and then these are.",
                    "label": 0
                }
            ]
        },
        "clip_169": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Three targets of.",
                    "label": 0
                }
            ]
        },
        "clip_170": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we can do this.",
                    "label": 0
                }
            ]
        },
        "clip_171": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Same sort of sample systems again.",
                    "label": 0
                },
                {
                    "sent": "What we like about this is this ability.",
                    "label": 0
                },
                {
                    "sent": "Up to now, use M RNA of twist as the thing we're using to perform the search.",
                    "label": 0
                },
                {
                    "sent": "So if we know the M RNA of twist, then we can basically build a model for every single gene in the genome.",
                    "label": 0
                },
                {
                    "sent": "So we look at the possibility for M RNA of twist.",
                    "label": 0
                },
                {
                    "sent": "Did it regulate each gene and we can fit those models independently and we can rank all those models to find out what is the most likely gene to have been regulated by twist, and we're doing that simply from wild type data.",
                    "label": 0
                },
                {
                    "sent": "So no extra data.",
                    "label": 0
                }
            ]
        },
        "clip_172": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is what we're doing here.",
                    "label": 0
                },
                {
                    "sent": "So this is a fit.",
                    "label": 0
                },
                {
                    "sent": "This is the driving input of twist.",
                    "label": 0
                },
                {
                    "sent": "This is a potential target that was very highly ranked and what it says is for this to be a target.",
                    "label": 0
                },
                {
                    "sent": "That fits there to twist, which is just an RBF it to twist.",
                    "label": 0
                },
                {
                    "sent": "That should be the protein and then that should be the target M RNA, so it manages to fit that quite well.",
                    "label": 0
                },
                {
                    "sent": "So this becomes very highly ranked.",
                    "label": 0
                },
                {
                    "sent": "Notice that that would never cluster with that, so you're not going to get this.",
                    "label": 0
                }
            ]
        },
        "clip_173": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Clustering.",
                    "label": 0
                },
                {
                    "sent": "Here's an example that would cluster here's the same system, very high decay at very high sensitivity.",
                    "label": 0
                },
                {
                    "sent": "It does to fit this.",
                    "label": 0
                },
                {
                    "sent": "Basically that looks identical to that, so you would get this out of clustering.",
                    "label": 0
                },
                {
                    "sent": "An extremely different protein profile, so there's something fishy going on here because we fitted these two independently and the protein profiles are very varied.",
                    "label": 0
                }
            ]
        },
        "clip_174": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Different.",
                    "label": 0
                },
                {
                    "sent": "Here again, we go back to the first protein profile, lower decay, lower sensitivity.",
                    "label": 0
                }
            ]
        },
        "clip_175": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This system and again.",
                    "label": 0
                }
            ]
        },
        "clip_176": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Lower Kayla sensitivity.",
                    "label": 0
                }
            ]
        },
        "clip_177": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And again, all these protein profiles are independently fitted, but they are consistent, which is sort of encouraging.",
                    "label": 0
                },
                {
                    "sent": "But there is the it's nice to work on flies 'cause you.",
                    "label": 0
                }
            ]
        },
        "clip_178": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Say there's a fly in the ointment and that's this protein profile here, which is high decay high sensitivity.",
                    "label": 0
                },
                {
                    "sent": "Something odd.",
                    "label": 0
                }
            ]
        },
        "clip_179": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Going on well, we email that collaborator about that because what is does seem to be orders that this activity seems to occur.",
                    "label": 0
                }
            ]
        },
        "clip_180": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Early.",
                    "label": 0
                },
                {
                    "sent": "And then there's that.",
                    "label": 0
                }
            ]
        },
        "clip_181": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Liberty later, and it looks like we're missing something in the model.",
                    "label": 0
                },
                {
                    "sent": "We're missing a phosphorylation step or something like that, so I don't know what it is, but she said that they biologically notice that twist has two affects.",
                    "label": 0
                },
                {
                    "sent": "It either affects early or it affects late, and we're just picking in both of these up because we are fitting independently, so it turns out that that is something in the system, and it's something slightly incorrect in our model, which doesn't bother me because the model is incorrect in many ways, But you can still find interesting things out.",
                    "label": 0
                }
            ]
        },
        "clip_182": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "By fitting an incorrect model.",
                    "label": 0
                }
            ]
        },
        "clip_183": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we did a sort of evaluation of this system where they had they had chip on chip validation for sort of these particular transcription factors across the genome.",
                    "label": 0
                },
                {
                    "sent": "So what we can do is see how our ranking predictions, how well enriched they are for things that were also in the chip, and now the chip was very conservative so they didn't make a chip call and less.",
                    "label": 0
                },
                {
                    "sent": "They were very confident.",
                    "label": 0
                },
                {
                    "sent": "So it's not a gold standard, but it's a useful measure so I didn't talk about the multi target GP, but that's a model that assumes that multiple genes are controlled together.",
                    "label": 0
                },
                {
                    "sent": "I did talk about the single one.",
                    "label": 0
                },
                {
                    "sent": "That's the results I was showing you there, which is this blue line.",
                    "label": 0
                },
                {
                    "sent": "Now it's interesting for the twist results.",
                    "label": 0
                },
                {
                    "sent": "Do extremely well.",
                    "label": 0
                },
                {
                    "sent": "We do much better than knockouts knockouts perform as well as random.",
                    "label": 0
                },
                {
                    "sent": "In this case, these focus results are looking at things that were in the in situ only, so I'll just look at the global results.",
                    "label": 0
                },
                {
                    "sent": "Actually, and we see that knockouts only do randomly well here, so there's very poor way of finding out what's regulated.",
                    "label": 0
                },
                {
                    "sent": "Correlation, which is just looking at the correlation between these targets and the M RNA of the transcription factor we're interested in.",
                    "label": 0
                },
                {
                    "sent": "Also does pretty poorly.",
                    "label": 0
                },
                {
                    "sent": "These two models, which are based on the differential equations, do quite well.",
                    "label": 0
                },
                {
                    "sent": "Math to the story is a little bit more complicated, so in math two correlation turns out to be very good.",
                    "label": 0
                }
            ]
        },
        "clip_184": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Maybe we haven't shown you F2, but Mathews activity only comes up there right at the very end, so you don't get to see the downstream effects of meth 2.",
                    "label": 0
                },
                {
                    "sent": "So that would mean that the advantages of our model is somewhat lost against correlation.",
                    "label": 0
                },
                {
                    "sent": "In some sense, it's only going to be able to pick up things that are.",
                    "label": 0
                }
            ]
        },
        "clip_185": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It like correlation, so that may explain why correlation does so well here.",
                    "label": 0
                },
                {
                    "sent": "Indeed, on the focus chip it's doing slightly better on the global chip.",
                    "label": 0
                },
                {
                    "sent": "It is doing.",
                    "label": 0
                },
                {
                    "sent": "Probably better overall, but our method is always up there always performing well and it's predicting.",
                    "label": 0
                }
            ]
        },
        "clip_186": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "These targets are using.",
                    "label": 0
                },
                {
                    "sent": "Only a wild type gene expression data, so it's very very cheap versus say the knockouts.",
                    "label": 0
                },
                {
                    "sent": "So so the summary of the sort of work that I've shown.",
                    "label": 0
                },
                {
                    "sent": "I hope I've been able to give you.",
                    "label": 0
                },
                {
                    "sent": "The aim was to give you an impression of what a Gaussian process is, how it works, and how it can be used by then sort of showing you.",
                    "label": 0
                },
                {
                    "sent": "Sort of research.",
                    "label": 0
                },
                {
                    "sent": "We've been looking at using Gaussian processes in transcriptional regulation, the Cascade models.",
                    "label": 0
                },
                {
                    "sent": "These allow genome wide analysis of potential targets given only wild type expression data and you can identify a set of candidate targets and then model these impacts and more complicated manner.",
                    "label": 0
                },
                {
                    "sent": "Now we didn't have any ground truth, but we seem to be forming as well.",
                    "label": 0
                }
            ]
        },
        "clip_187": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is a knockout.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_188": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The discussion is that what I've been trying to motivate in the tutorial is the idea of combining probabilistic inference and mechanistic modeling as the right thing to do that either one on its own is ignoring something important.",
                    "label": 0
                },
                {
                    "sent": "And then we talked about applications in modeling gene expression and the key component to this combination was the Gaussian process and we also introduced the model of translation with the Cascade model, and these are the sort of things we're doing at the moment, so this we've got methods for doing very large systems, genome wide systems and we're just fine.",
                    "label": 0
                },
                {
                    "sent": "Finishing a paper on nonlinear diff nonlinear response, and we can do not learn differential equations.",
                    "label": 0
                },
                {
                    "sent": "We haven't explored it yet.",
                    "label": 0
                },
                {
                    "sent": "Stochastic differential equations.",
                    "label": 0
                },
                {
                    "sent": "We have also ways of expanding it first.",
                    "label": 0
                }
            ]
        },
        "clip_189": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Plastic differential equations too.",
                    "label": 0
                },
                {
                    "sent": "So, and I should.",
                    "label": 0
                },
                {
                    "sent": "Acknowledge Samartino Barranco Mike Eubank at the Institute of Child Health and UCL, who were always very amiable and good to talk to you and provided this great data set, which is a really nice clean data set on the P 53 pathway.",
                    "label": 0
                },
                {
                    "sent": "Charles O DAU and Eileen Furlong provide the same role with the Drosophila example I showed at the end and the researchers I mentioned at the beginning and the work I've shown was funded by.",
                    "label": 0
                },
                {
                    "sent": "Along time ago it was funded by BBC Award that funded Guido Andani PSC awards that funded pay.",
                    "label": 0
                },
                {
                    "sent": "Gaussian process for systems identification in in systems biology.",
                    "label": 0
                },
                {
                    "sent": "That's it, time for questions.",
                    "label": 0
                },
                {
                    "sent": "I think I hope.",
                    "label": 0
                }
            ]
        }
    }
}