{
    "id": "km6tifilgjujfrmeb4ev4ftznds2f7xa",
    "title": "Sufficient covariates and linear propensity analysis",
    "info": {
        "author": [
            "Hui Guo, Faculty of Mathematics, University of Cambridge"
        ],
        "published": "June 3, 2010",
        "recorded": "May 2010",
        "category": [
            "Top->Computer Science->Machine Learning->Bayesian Learning"
        ]
    },
    "url": "http://videolectures.net/aistats2010_guo_scalp/",
    "segmentation": [
        [
            "So I'm quite cool.",
            "I'm supervised by Professor Philip David, so this is joint work with my supervisor, sufficient covariates and linear propensity analysis."
        ],
        [
            "In many cases, our interest lies in identifying causal effects from observation.",
            "ULL studies rather than randomized experiment which requires adjustment for a set of covariates.",
            "For example, age, gender or family income, etc.",
            "If we have many such covaries and then it's necessary for us to conduct dimension reduction for some of the approaches, I'll talk about it later."
        ],
        [
            "First of all, I would like to introduce 3 random variables, binary treatment, T very one stands for treatment Group and 0 control.",
            "We have response Y also P dimensional covariates X."
        ],
        [
            "Oh, analysis is based on decision theoretic framework within which we introduce announced acoustic regime indicator FT.",
            "It's explains the treatment assignment mechanism, it can.",
            "It can take three values if is.",
            "Idle equal to idle, so we say it's observational regime, so in this case we don't do anything, hands off and then just does the treatment arise naturally?",
            "If FT is equal to 1 and then we say it's an interventional regime, which means the assignment to the treatment group is by the external intervention, and if is equal to 1, is another interventional regime.",
            "The assignment to control is by the external force as well."
        ],
        [
            "Because the causality is all about manipulation.",
            "So we define our average causal effect as the difference of the expectation of our response under two interventional regimes.",
            "For convenience, we write down the values for regime indicator as the subscript here.",
            "As in our framework, sufficient covariates plays a key role, so next I would look at the possible proper properties for such."
        ],
        [
            "Sufficient covariates, the first one is that the marginal distribution X is independent of FT, which means the distribution of X in each regime is equivalent.",
            "So we call such.",
            "X is a covariate."
        ],
        [
            "In addition, if the distribution of Y given X&T is the same in each regime, then we call such X is sufficient covariates, so sufficient covariates must must satisfy two properties, both one and two."
        ],
        [
            "Most strongly, if we have given X, we've observed both treatment group, so then we call.",
            "Such X is strongly sufficient covariates, so in this case, as we can say, it's condition becomes stronger and then the name of X become longer.",
            "Well, whatever I think, yeah, that's just in general setting.",
            "Doesn't say anything about it dimension.",
            "At all."
        ],
        [
            "So if we let express property one and two for sufficient covariates graphically and then we can find out in the DAG which is directed acyclic graph.",
            "So here we can say that X is independent FT. And why is independent FT given X&T by moralization?",
            "If you're already familiar with this deck?",
            "Expression."
        ],
        [
            "Before going to details, I would like to introduce another definition which is called specific causal effects.",
            "It is actually very similar to the average causal effects, but here is the difference of the conditional mean of the response given X.",
            "So which means SC.",
            "Here is actually a function of X."
        ],
        [
            "If X is a covariate, let's go back to."
        ],
        [
            "The property one.",
            "If X is covaries and then the distribution of X must be the same in each regime, so that's why it comes to.",
            "Serum"
        ],
        [
            "Two so the average causal effects just expectation of specific specific causal effects for each regime here.",
            "Which is actually a post back door formula if you."
        ],
        [
            "Put that before.",
            "So what happens if X is drawn is sufficient?",
            "If this is the case and then for any intervals at which is a function of YX&T and any versions of conditional expectations almost surely in any regime we have that conditional on X and forgiven specific treatment group the estimated the expectation of Z is the same no matter.",
            "Whether this this treatment is from intervention or from the observation so that is nice because from theorem one we can find out that the specific causal effects which is defined in interventional regimes can be identified from observation, ULL data and by theorem two.",
            "Consequently, the average cause or effect can be identified from the purely observation.",
            "ULL data as well."
        ],
        [
            "As I said before, for some approaches such as matching and subclassification for Jasmine, purpose is much easier to adjust for just just for a single random variable rather than multi dimensional variable.",
            "So our point is how we carry out such dimension Redux."
        ],
        [
            "Chen so conditional on X, that X is strongly sufficient and V is a function of X, then we must be strong sufficient as well.",
            "If this conditional independence properties satisfied, which means that distribution of Y given V&T is the same in each regime.",
            "So I would skip all the proofs here.",
            "So if you are really interested in you can refer to our paper afterwards."
        ],
        [
            "Theorem Three provides us 2 alternative ways to carry out such dimension reduction."
        ],
        [
            "So the first one is called response efficient.",
            "This look at this dad this graph.",
            "So actually V is on the pathway from X to Y to response Y.",
            "So that is why is called response sufficient reduction.",
            "Intuitively we might think OK there is another alternative way for us to carry out such reduction, which probably is from X2T."
        ],
        [
            "Exactly, so that's exactly our second approach.",
            "So from X to T, that is V, so it's called treatment sufficient reduction."
        ],
        [
            "Then how we obtain such reduction?",
            "So if we have a family Q with two components Q, not, Q1 consists of the observation of distributions for X given T being equal to 01 respectively on it can be shown that a treatment sufficient reduction is a sufficient statistic for Q. Consequently, a minimal treatment sufficient reduction.",
            "Is a minimal sufficient statistic for Q which is equivalent to the ratio down?"
        ],
        [
            "Then we call such minimal sufficient treatment sufficient reduction a propensity variable as.",
            "Some of you may come across.",
            "Propensity Score which is defined as the probability of being in a treatment group given observed X that is actually a one to one function of likelihood ratio.",
            "So in this case a propensity variable is just a one to one function of the propensity score."
        ],
        [
            "So will carry out propensity analysis by very simple example.",
            "Is from a normal linear model because propensity analysis is regarded as a very useful tool to reduce bias or even increase precision for our estimators.",
            "So let's see if it's always true.",
            "The joint distribution is given us following, so we actually observe both treatment groups.",
            "Conditional distribution of X given T and observation regime is from normal with mean depend dependent on the treatment and covariance matrix of X given TR for the two for both treatment group is identical and distribution of Y conditional on.",
            "Xton FT is again from normal, with its men being a linear function of T&X.",
            "So here from the second model setting, we can see that the distribution of eggs under the observation regime is actually a normal mixture.",
            "If we take its distribution and Inter."
        ],
        [
            "National regime is the same.",
            "And then we can actually prove that X is strongly sufficient, because in this third's model setting, Huawei doesn't depend on FT at all given X&T.",
            "So the average causal effect can be obtained is just the coefficient of T in response regression model is just Delta.",
            "And it can be shown that is also true for any regression on the linear sufficient reduction of X."
        ],
        [
            "So as I said before, we can carry out the treatment sufficient reduction by looking at the likelihood ratio.",
            "So let's take log.",
            "Then the dog like ratio is in the really simple form.",
            "LD here is fishes, fishes, linear discriminants and also is a propensity variable in our model.",
            "So let's carry out two linear regressions.",
            "One is multivariate linear regression as usual, and the other is to carry out the regression linear discriminants.",
            "Actually, we end up with the same coefficient of T, so here because.",
            "Linear discriminants also a propensity variable is actually a linear sufficient reduction of X, so that's why it's this result holds, but are interested is in the observed data, so that is population based.",
            "So what happens?",
            "What's going to happen in a data, let's say from the formula in the linear discriminants is only first and 2nd one, second moments being involved.",
            "So if we replace.",
            "Muse and covariance matrix by their sample estimates, and then the sample based on linear discriminants is again a linear sufficient.",
            "Reduction of X.",
            "So in this case for sample based."
        ],
        [
            "Analysis is still true.",
            "That's exactly what said for what I said for Curly one, so everything is based on sample and again we end up with the same coefficient of T."
        ],
        [
            "So here this say from our model really simple model setting propensity analysis does not increase precision at all, it just give us the identical result as a multi various linear regression."
        ],
        [
            "Will verify our results by simulations.",
            "For simplicity, we only consider two components in X, X1, and X2 and X1 given tease from standard normal X2.",
            "Given T is normal again with minty and variance 1X an X1 and X2 independent given T. Also, the conditional distribution of Y given X&T is from normal as well with this mean.",
            "Is a linear function of T and X1, so it's really easy saying that X one is true linear predictor of our response."
        ],
        [
            "For some simple algebra we can find out that linear discriminants is propensity variable which is just X2.",
            "So the distribution of Y, conditional X2 and T. Let's say it doesn't depend on X2 at all, because that's not surprising because X2 is not a linear predictor of the response."
        ],
        [
            "Then we carried out for linear regressions.",
            "Am not is the baseline regression, which means we don't know which one is a linear predictor or propensity variable doesn't matter, we just include everything in a linear regression and M1 here, if we know the two linear predictor is X1, then we include this X one in a linear regression in M2.",
            "If we know the true propensity variable which is X2.",
            "And then we included in the regression.",
            "So the last M3 is the case in general, because normally we don't know the true propensity variable.",
            "We need to estimate it from our data.",
            "So first of all we estimated from data and then we do adjustment on this estimated propensity variable.",
            "Actually, this for all for linear regression's give us unbiased estimator for the for the average causal effect.",
            "So let's look at the performance of the variance."
        ],
        [
            "So that's a result of simulations graphically, so let's look at the left hand side.",
            "The top one is from the baseline linear regression model, which means why the linear regression of Y on the whole set of covariates and T. The bottom one is the adjustment for the sample linear discriminants, which means is just the estimated propensity variable.",
            "Indeed, these two graphs gives us exactly same results.",
            "No difference at all.",
            "And let's look at right hand side to graphs.",
            "The top one is the regression linear predictor X1, which resulting.",
            "The most precise estimator.",
            "As we can see.",
            "And in contrast to the bottom one here, which is a linear regression on the true linear prediction true propensity variable.",
            "That is the worst in terms of the variation of our estimator."
        ],
        [
            "So to summarize, I propensity variable is identified as a minimal treatment, sufficient reduction and for simple normal linear model, propensity variable and linear discriminants that just equivalent to each other.",
            "So adjustment for the sample based.",
            "Linear predictor, sorry.",
            "They're proposing variable yields.",
            "The same estimated average causal effects as a multivariate X, so it can neither increase nor decrease precision.",
            "Therefore, our investigations add some weight to the accruing evidence that propensity analysis in some circumstances is of little help to improve the estimation of our cause causal effects."
        ],
        [
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I'm quite cool.",
                    "label": 0
                },
                {
                    "sent": "I'm supervised by Professor Philip David, so this is joint work with my supervisor, sufficient covariates and linear propensity analysis.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In many cases, our interest lies in identifying causal effects from observation.",
                    "label": 0
                },
                {
                    "sent": "ULL studies rather than randomized experiment which requires adjustment for a set of covariates.",
                    "label": 1
                },
                {
                    "sent": "For example, age, gender or family income, etc.",
                    "label": 1
                },
                {
                    "sent": "If we have many such covaries and then it's necessary for us to conduct dimension reduction for some of the approaches, I'll talk about it later.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "First of all, I would like to introduce 3 random variables, binary treatment, T very one stands for treatment Group and 0 control.",
                    "label": 0
                },
                {
                    "sent": "We have response Y also P dimensional covariates X.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Oh, analysis is based on decision theoretic framework within which we introduce announced acoustic regime indicator FT.",
                    "label": 1
                },
                {
                    "sent": "It's explains the treatment assignment mechanism, it can.",
                    "label": 0
                },
                {
                    "sent": "It can take three values if is.",
                    "label": 0
                },
                {
                    "sent": "Idle equal to idle, so we say it's observational regime, so in this case we don't do anything, hands off and then just does the treatment arise naturally?",
                    "label": 0
                },
                {
                    "sent": "If FT is equal to 1 and then we say it's an interventional regime, which means the assignment to the treatment group is by the external intervention, and if is equal to 1, is another interventional regime.",
                    "label": 0
                },
                {
                    "sent": "The assignment to control is by the external force as well.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Because the causality is all about manipulation.",
                    "label": 0
                },
                {
                    "sent": "So we define our average causal effect as the difference of the expectation of our response under two interventional regimes.",
                    "label": 1
                },
                {
                    "sent": "For convenience, we write down the values for regime indicator as the subscript here.",
                    "label": 1
                },
                {
                    "sent": "As in our framework, sufficient covariates plays a key role, so next I would look at the possible proper properties for such.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sufficient covariates, the first one is that the marginal distribution X is independent of FT, which means the distribution of X in each regime is equivalent.",
                    "label": 0
                },
                {
                    "sent": "So we call such.",
                    "label": 0
                },
                {
                    "sent": "X is a covariate.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In addition, if the distribution of Y given X&T is the same in each regime, then we call such X is sufficient covariates, so sufficient covariates must must satisfy two properties, both one and two.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Most strongly, if we have given X, we've observed both treatment group, so then we call.",
                    "label": 0
                },
                {
                    "sent": "Such X is strongly sufficient covariates, so in this case, as we can say, it's condition becomes stronger and then the name of X become longer.",
                    "label": 1
                },
                {
                    "sent": "Well, whatever I think, yeah, that's just in general setting.",
                    "label": 0
                },
                {
                    "sent": "Doesn't say anything about it dimension.",
                    "label": 0
                },
                {
                    "sent": "At all.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So if we let express property one and two for sufficient covariates graphically and then we can find out in the DAG which is directed acyclic graph.",
                    "label": 1
                },
                {
                    "sent": "So here we can say that X is independent FT. And why is independent FT given X&T by moralization?",
                    "label": 0
                },
                {
                    "sent": "If you're already familiar with this deck?",
                    "label": 0
                },
                {
                    "sent": "Expression.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Before going to details, I would like to introduce another definition which is called specific causal effects.",
                    "label": 0
                },
                {
                    "sent": "It is actually very similar to the average causal effects, but here is the difference of the conditional mean of the response given X.",
                    "label": 0
                },
                {
                    "sent": "So which means SC.",
                    "label": 0
                },
                {
                    "sent": "Here is actually a function of X.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If X is a covariate, let's go back to.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The property one.",
                    "label": 0
                },
                {
                    "sent": "If X is covaries and then the distribution of X must be the same in each regime, so that's why it comes to.",
                    "label": 0
                },
                {
                    "sent": "Serum",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Two so the average causal effects just expectation of specific specific causal effects for each regime here.",
                    "label": 0
                },
                {
                    "sent": "Which is actually a post back door formula if you.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Put that before.",
                    "label": 0
                },
                {
                    "sent": "So what happens if X is drawn is sufficient?",
                    "label": 0
                },
                {
                    "sent": "If this is the case and then for any intervals at which is a function of YX&T and any versions of conditional expectations almost surely in any regime we have that conditional on X and forgiven specific treatment group the estimated the expectation of Z is the same no matter.",
                    "label": 1
                },
                {
                    "sent": "Whether this this treatment is from intervention or from the observation so that is nice because from theorem one we can find out that the specific causal effects which is defined in interventional regimes can be identified from observation, ULL data and by theorem two.",
                    "label": 0
                },
                {
                    "sent": "Consequently, the average cause or effect can be identified from the purely observation.",
                    "label": 0
                },
                {
                    "sent": "ULL data as well.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As I said before, for some approaches such as matching and subclassification for Jasmine, purpose is much easier to adjust for just just for a single random variable rather than multi dimensional variable.",
                    "label": 0
                },
                {
                    "sent": "So our point is how we carry out such dimension Redux.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Chen so conditional on X, that X is strongly sufficient and V is a function of X, then we must be strong sufficient as well.",
                    "label": 1
                },
                {
                    "sent": "If this conditional independence properties satisfied, which means that distribution of Y given V&T is the same in each regime.",
                    "label": 0
                },
                {
                    "sent": "So I would skip all the proofs here.",
                    "label": 0
                },
                {
                    "sent": "So if you are really interested in you can refer to our paper afterwards.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Theorem Three provides us 2 alternative ways to carry out such dimension reduction.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the first one is called response efficient.",
                    "label": 0
                },
                {
                    "sent": "This look at this dad this graph.",
                    "label": 0
                },
                {
                    "sent": "So actually V is on the pathway from X to Y to response Y.",
                    "label": 0
                },
                {
                    "sent": "So that is why is called response sufficient reduction.",
                    "label": 0
                },
                {
                    "sent": "Intuitively we might think OK there is another alternative way for us to carry out such reduction, which probably is from X2T.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Exactly, so that's exactly our second approach.",
                    "label": 0
                },
                {
                    "sent": "So from X to T, that is V, so it's called treatment sufficient reduction.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then how we obtain such reduction?",
                    "label": 0
                },
                {
                    "sent": "So if we have a family Q with two components Q, not, Q1 consists of the observation of distributions for X given T being equal to 01 respectively on it can be shown that a treatment sufficient reduction is a sufficient statistic for Q. Consequently, a minimal treatment sufficient reduction.",
                    "label": 1
                },
                {
                    "sent": "Is a minimal sufficient statistic for Q which is equivalent to the ratio down?",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then we call such minimal sufficient treatment sufficient reduction a propensity variable as.",
                    "label": 1
                },
                {
                    "sent": "Some of you may come across.",
                    "label": 0
                },
                {
                    "sent": "Propensity Score which is defined as the probability of being in a treatment group given observed X that is actually a one to one function of likelihood ratio.",
                    "label": 0
                },
                {
                    "sent": "So in this case a propensity variable is just a one to one function of the propensity score.",
                    "label": 1
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So will carry out propensity analysis by very simple example.",
                    "label": 1
                },
                {
                    "sent": "Is from a normal linear model because propensity analysis is regarded as a very useful tool to reduce bias or even increase precision for our estimators.",
                    "label": 1
                },
                {
                    "sent": "So let's see if it's always true.",
                    "label": 0
                },
                {
                    "sent": "The joint distribution is given us following, so we actually observe both treatment groups.",
                    "label": 1
                },
                {
                    "sent": "Conditional distribution of X given T and observation regime is from normal with mean depend dependent on the treatment and covariance matrix of X given TR for the two for both treatment group is identical and distribution of Y conditional on.",
                    "label": 0
                },
                {
                    "sent": "Xton FT is again from normal, with its men being a linear function of T&X.",
                    "label": 0
                },
                {
                    "sent": "So here from the second model setting, we can see that the distribution of eggs under the observation regime is actually a normal mixture.",
                    "label": 0
                },
                {
                    "sent": "If we take its distribution and Inter.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "National regime is the same.",
                    "label": 0
                },
                {
                    "sent": "And then we can actually prove that X is strongly sufficient, because in this third's model setting, Huawei doesn't depend on FT at all given X&T.",
                    "label": 1
                },
                {
                    "sent": "So the average causal effect can be obtained is just the coefficient of T in response regression model is just Delta.",
                    "label": 0
                },
                {
                    "sent": "And it can be shown that is also true for any regression on the linear sufficient reduction of X.",
                    "label": 1
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So as I said before, we can carry out the treatment sufficient reduction by looking at the likelihood ratio.",
                    "label": 0
                },
                {
                    "sent": "So let's take log.",
                    "label": 0
                },
                {
                    "sent": "Then the dog like ratio is in the really simple form.",
                    "label": 1
                },
                {
                    "sent": "LD here is fishes, fishes, linear discriminants and also is a propensity variable in our model.",
                    "label": 1
                },
                {
                    "sent": "So let's carry out two linear regressions.",
                    "label": 1
                },
                {
                    "sent": "One is multivariate linear regression as usual, and the other is to carry out the regression linear discriminants.",
                    "label": 1
                },
                {
                    "sent": "Actually, we end up with the same coefficient of T, so here because.",
                    "label": 0
                },
                {
                    "sent": "Linear discriminants also a propensity variable is actually a linear sufficient reduction of X, so that's why it's this result holds, but are interested is in the observed data, so that is population based.",
                    "label": 0
                },
                {
                    "sent": "So what happens?",
                    "label": 0
                },
                {
                    "sent": "What's going to happen in a data, let's say from the formula in the linear discriminants is only first and 2nd one, second moments being involved.",
                    "label": 0
                },
                {
                    "sent": "So if we replace.",
                    "label": 0
                },
                {
                    "sent": "Muse and covariance matrix by their sample estimates, and then the sample based on linear discriminants is again a linear sufficient.",
                    "label": 0
                },
                {
                    "sent": "Reduction of X.",
                    "label": 0
                },
                {
                    "sent": "So in this case for sample based.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Analysis is still true.",
                    "label": 0
                },
                {
                    "sent": "That's exactly what said for what I said for Curly one, so everything is based on sample and again we end up with the same coefficient of T.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here this say from our model really simple model setting propensity analysis does not increase precision at all, it just give us the identical result as a multi various linear regression.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Will verify our results by simulations.",
                    "label": 0
                },
                {
                    "sent": "For simplicity, we only consider two components in X, X1, and X2 and X1 given tease from standard normal X2.",
                    "label": 0
                },
                {
                    "sent": "Given T is normal again with minty and variance 1X an X1 and X2 independent given T. Also, the conditional distribution of Y given X&T is from normal as well with this mean.",
                    "label": 0
                },
                {
                    "sent": "Is a linear function of T and X1, so it's really easy saying that X one is true linear predictor of our response.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For some simple algebra we can find out that linear discriminants is propensity variable which is just X2.",
                    "label": 0
                },
                {
                    "sent": "So the distribution of Y, conditional X2 and T. Let's say it doesn't depend on X2 at all, because that's not surprising because X2 is not a linear predictor of the response.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then we carried out for linear regressions.",
                    "label": 0
                },
                {
                    "sent": "Am not is the baseline regression, which means we don't know which one is a linear predictor or propensity variable doesn't matter, we just include everything in a linear regression and M1 here, if we know the two linear predictor is X1, then we include this X one in a linear regression in M2.",
                    "label": 0
                },
                {
                    "sent": "If we know the true propensity variable which is X2.",
                    "label": 0
                },
                {
                    "sent": "And then we included in the regression.",
                    "label": 0
                },
                {
                    "sent": "So the last M3 is the case in general, because normally we don't know the true propensity variable.",
                    "label": 0
                },
                {
                    "sent": "We need to estimate it from our data.",
                    "label": 0
                },
                {
                    "sent": "So first of all we estimated from data and then we do adjustment on this estimated propensity variable.",
                    "label": 0
                },
                {
                    "sent": "Actually, this for all for linear regression's give us unbiased estimator for the for the average causal effect.",
                    "label": 0
                },
                {
                    "sent": "So let's look at the performance of the variance.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that's a result of simulations graphically, so let's look at the left hand side.",
                    "label": 0
                },
                {
                    "sent": "The top one is from the baseline linear regression model, which means why the linear regression of Y on the whole set of covariates and T. The bottom one is the adjustment for the sample linear discriminants, which means is just the estimated propensity variable.",
                    "label": 0
                },
                {
                    "sent": "Indeed, these two graphs gives us exactly same results.",
                    "label": 0
                },
                {
                    "sent": "No difference at all.",
                    "label": 0
                },
                {
                    "sent": "And let's look at right hand side to graphs.",
                    "label": 0
                },
                {
                    "sent": "The top one is the regression linear predictor X1, which resulting.",
                    "label": 0
                },
                {
                    "sent": "The most precise estimator.",
                    "label": 0
                },
                {
                    "sent": "As we can see.",
                    "label": 0
                },
                {
                    "sent": "And in contrast to the bottom one here, which is a linear regression on the true linear prediction true propensity variable.",
                    "label": 0
                },
                {
                    "sent": "That is the worst in terms of the variation of our estimator.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to summarize, I propensity variable is identified as a minimal treatment, sufficient reduction and for simple normal linear model, propensity variable and linear discriminants that just equivalent to each other.",
                    "label": 1
                },
                {
                    "sent": "So adjustment for the sample based.",
                    "label": 0
                },
                {
                    "sent": "Linear predictor, sorry.",
                    "label": 0
                },
                {
                    "sent": "They're proposing variable yields.",
                    "label": 0
                },
                {
                    "sent": "The same estimated average causal effects as a multivariate X, so it can neither increase nor decrease precision.",
                    "label": 1
                },
                {
                    "sent": "Therefore, our investigations add some weight to the accruing evidence that propensity analysis in some circumstances is of little help to improve the estimation of our cause causal effects.",
                    "label": 1
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}