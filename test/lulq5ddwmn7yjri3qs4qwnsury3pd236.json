{
    "id": "lulq5ddwmn7yjri3qs4qwnsury3pd236",
    "title": "Using Graph-based Metrics with Empirical Risk Minimization to Speed Up Active Learning on Networked Data",
    "info": {
        "author": [
            "Sofus Attila Macskassy, Facebook"
        ],
        "published": "Sept. 14, 2009",
        "recorded": "June 2009",
        "category": [
            "Top->Computer Science->Data Mining->Multi-Relational Mining"
        ]
    },
    "url": "http://videolectures.net/kdd09_macskassy_ugbmermsualnd/",
    "segmentation": [
        [
            "Crates are, some are little bit of an outlier.",
            "Since I'm not really doing multi relational data mining at this point, although it can be clearly extended to that.",
            "I'll talk about that in a bit.",
            "Also, I know it's late for everybody, so I will keep this very high level and.",
            "Hopefully relatively short with very minimal math so.",
            "Let me first set there."
        ],
        [
            "The context of where what this talk really is about and what I'm trying to achieve here.",
            "So we all know about supervised learning.",
            "Most of us, hopefully all of us know about what semi supervised learning is.",
            "Basically you given a partially labeled data set and you want to label the unlabeled data.",
            "In that particular scenario, in the relational setting up and working well last couple of years on what we call within network learning or transductive learning with relational data.",
            "Active learning, of course, is this idea of that you want to be able to select actively, select the next node to label in order to optimize and get a good model as possible with a few labels given labels as possible."
        ],
        [
            "Right, so the motivation behind this is that there was some reason work a few years back.",
            "They combined relational learning and semi supervised learning graph with active learning and they showed that using empirical risk minimization really worked really well and they showed a really good method for doing that.",
            "The problem with the with ERM is that it is quite slow.",
            "You need basically need to go through every single unlabeled instance to a lot of computation to figure out which one you should label next.",
            "So there's a lot of computational involved there.",
            "The method they used here was a graph based semi supervised learning.",
            "I'm not actually going to be coming Deputy algorithm here since that's somewhat beside the point, but I'm going to be using that same graph based machine learning method here.",
            "It's basically a harmonic harmonic function.",
            "Get the paper or talk to me afterward about that.",
            "So the idea behind this work is to say, well, if we want to use DRM because you work really well, can we somehow figure out what are the SMS candidate number of instances you should look at?",
            "Because that's probably going to be where the best instances and so in there by speeding up active learning by acquired by a lot of factors and so."
        ],
        [
            "Using one of the key observations from that prior work here that let me down this path, namely the work in the prior works.",
            "Notice that on synthetic graph data, ERM, tended to pick for that particular method which I'm using here, ERM, tended to pick notes there was, there were central to the underlying clusters in that data set, and so that seemed to me that we should be able to leverage leverage that particular observation in some way, right?"
        ],
        [
            "So as I said, the idea is to keep your end, but limit computation by looking at the best candidates.",
            "Right, and so the key observation from before seems to suggest that maybe we could do some kind of unsupervised clustering on the graph and then use graph metrics to find the central nodes in that particular cluster.",
            "And that's where we should start off.",
            "So that is 1 particular way.",
            "Maybe there's also been all Noble uncertainty sampling, so maybe that's a better way of doing it as well.",
            "They did that, but I'm putting it down here as well as another potential strategy and you'll see that late why I'm including that here later on.",
            "You can also use a little bit more global graph metrics like just between the centrality or closeness and shadow across the whole graph.",
            "Then maybe that's maybe those.",
            "Those are the ways to go so their various ways we can try to come up with heuristics for seeing which instances."
        ],
        [
            "You should be labeling next.",
            "Right so.",
            "I've noticed a so so I would like a few here.",
            "I'm just going to go through what they actually mean, so I'm actually going to propose three particular metrics.",
            "I'm going to take a little bit closer.",
            "Look at the first one.",
            "Being uncertainty sampling.",
            "We all know about that.",
            "We're basically just going to pick the most there.",
            "Instead, you're most certain about.",
            "Now, if you're going."
        ],
        [
            "Graph based metrics between the centrality so between the centrality is really if you have this this graph so obviously showing a very toy example here to really show what's going on here.",
            "So between the centrality of really the nodes in a graph that has the largest or maximum amount of information flowing through them.",
            "If you look at how various nodes are connected in the graph, and so here is a I'm just putting in the equation here, but I'm not going to go through it.",
            "But basically you're going to look at the shortest path between all possible nodes are going to look at the nodes that that.",
            "That occur in most of these shortest paths, so in this particular instance here, in this particular toy graph, the ones that have the highest between us here is actually the ones that are not learning here, and so all their neighbors in fact, is also going to be relatively high between this as well, so they seem to be pretty good candidates."
        ],
        [
            "That you would want to take a look at.",
            "The third one I'm going to start with.",
            "Closeness, centrality.",
            "Closeness centrality is basically trying to identify the notes in the graph that has the shortest path average path to all other nodes in the graph.",
            "So in this particular case here, closeness is basically going to be closer to the central notes here, so it doesn't seem that closes by itself is really what you want to go by.",
            "In fact, empirically, I found that that was certainly not the case either, so I did validate that although that's not in."
        ],
        [
            "Paper.",
            "However, looking at propagation from from before, the idea would be, well, how about we cluster the graph first?",
            "So if you first cluster the nodes, and in fact if he was any kind of clustering algorithm on this particular graph, you will come up with these nice clusters that have color coded here just a tool to really highlight what's going on.",
            "So if you cluster the graph and then find the most central nodes in each graph in each of these sub clusters, you're going to find these particular notes here, and these were the ones that you would go after, and that seems to be that seems to be a pretty good heuristic at least.",
            "Intuitively and theoretically, looking these kind of toy graphs.",
            "That's probably that seems to be a pretty good way of going.",
            "As I mentioned the paper.",
            "However, this turned out not to be very good.",
            "Still trying to figure out that, but I'm coming back to it a little bit later on."
        ],
        [
            "Right and part of part of the reasons is also that Tigres are really nice, but real graphs are a lot more dirty, right?",
            "And so empirically, chances are that you probably want to be able to do a little bit better than using any of these heuristics, which really assume you have some really nice clean separation right then.",
            "That's in fact what I found.",
            "So the question that I."
        ],
        [
            "And that is well.",
            "Which of these methods actually seems to work pretty well?",
            "In particular, first just for validation and just compare uncertainty between this so the full ERM and also just random sampling just to get a baseline and see what's going on.",
            "And the two things I'm really interested in to make sure I preserve accuracy to ERM, which is pretty much one of the better ones.",
            "Active learning strategies out there.",
            "And I also want to certainly decrease the time, time to finish, and so that's really the key metric.",
            "Keep the accuracy, but make it much faster.",
            "And so the methodology I'm going to be using throughout here is initially I just randomly pick one instance for each class and then it'll just pick the next the next label until I have 100 instances.",
            "That was just an ad hoc limit I said here to understand what's going on and I just repeated 10 times to get an average performance.",
            "For those of you, if you think a little bit about it turns out that between this really has very little randomness here because it's a global measure on the graph, so it's a pretty much incentive to insensitive to the initial labels.",
            "Whereas the others are not."
        ],
        [
            "511 benchmark datasets.",
            "I'm not really going through the tail here.",
            "Some of them are relatively small to webcaps are relatively small and a few hundreds.",
            "The industry classifications about 1000 to about 2000.",
            "That was a typo that supposed to be around.",
            "2000 here and Core is the 4000 datasets, so they're not huge datasets, but at least give some sense of perform."
        ],
        [
            "Games here.",
            "Alright, so the first thing I did was just comparing a certainty the full DRM tools between this uncertainty just to make sure to gauge well what's going on here with these very simple heuristics and you can see here, two of the prototypical runs you see, ERM, is the red line, so that's quite well and you will see the other methods or so the purplish line is the random sampling and the two other lines you'll see is, erm, answer is between us and uncertainty, and you can see that they have some mixed.",
            "They're not consistently.",
            "Which one is better or worse here?",
            "And as I said, the closeness and even the cluster closeness turned out not to work very well, so I didn't really look at it here, but I had an inch."
        ],
        [
            "Sting observation when I looked at these things and also when I looked at the closeness, namely that none of these strategies work very well by themselves, especially if you just looked at their topic.",
            "And so obviously the idea here was also told to actually go back and redo CRM.",
            "So what I actually did notice what that all of these strategies in their top K5 five to 10 PX they very consistently had had the instance that ERM would pick as well.",
            "So that suggested a hybrid approach to me here, and that is basically look at all the other strategies, three of them here.",
            "In this case, uncertainty between this and this cluster closeness.",
            "Look at all three strategies.",
            "Basically just get the top K pics in this particular instance I used the top five picks from each of these three strategies, and so that means I get a certain set of picks back from from each of these strategies.",
            "And I actually use DRM on those to figure out which of them I should label next.",
            "So that's the hype."
        ],
        [
            "Approach and that actually turned out to work really well.",
            "As you can see here in the arm versus the hybrid approach on the on the left you see the accuracy.",
            "You can see we actually do a very consistently close to what DRM is.",
            "So MSO is still the red line degree.",
            "My is my hybrid approach and on the other side on the right side you'll see here there's the running time and we can see we basically get an order of magnitude speedup using this, and this is on a relatively small data set, so we would expect.",
            "And so there's some interesting tradeoffs here between what is, what is the computational computations needed to all the tools or the graph mining versus just running these classifiers over again, and so, but I would in general expect this to go up and have a significant amount speedup even as you get up to larger graphs.",
            "So the second question then."
        ],
        [
            "Had was I wanted to understand a little bit better how each of these metrics actually will use and how often they actually were used by this hybrid approach.",
            "And so here we have the 11 datasets that I have, and so in these cases here I'm looking at each cluster each column you can see how often the topic by ERM was was picked for feature for each metric, and so you see cluster closeness here in the in the.",
            "In a in the top cases on the larger crowds here you can see it was picked roughly about 10% of the time over there, but on average I guess I should have an average at the bottom on.",
            "Certainly something you can see.",
            "It's actually being used quite a bit, and then you can see that between the centrality is actually also being used quite a bit.",
            "And I was also interested to see we have consistently were.",
            "How consistent with these metrics in terms of actually trying to going after the same area of the graph or the same instances.",
            "And you can see here on the last column how often did multiple of these metrics actually select the same instance.",
            "You can see here that on the larger graphs that actually didn't turn out to be very often put on these smaller graphs that actually turned out to be quite a bit, and so that was actually interesting by itself.",
            "I think probably actually gets larger graphs.",
            "You're going to have less of a tie.",
            "Because they really seem to tend to to go after different parts of the graph.",
            "The bottom graphs, obviously with relatively small, so there really wasn't much Marshall play around with there."
        ],
        [
            "So.",
            "Just to summarize, ERM, is a really strong active learning strategy, but it's extremely slow, and so I Shona showed one weather method here to efficiently identify a small Canada set of notes that you should go after to use your M and figure out which one of these so to use.",
            "So in particular here, if you have relational data or graph data, you can use graph metrics such as those I showed here, and I think it has really potentially great speedups.",
            "And as I showed, we have basically comperable performance too.",
            "So using the full RN but we get also an order of magnitude speedup in it."
        ],
        [
            "But still, there's a lot of questions, so this is really an initial foray into this whole area, and I think there's a lot of things that still need to be done here, and so these are just some of the the first questions that really comes to mind, and there is.",
            "I'm not quite sure why, why, for example, that cluster closeness didn't quite work as well as I thought, and so that's that's interesting.",
            "But I think part of it is actually that I'm not really taking into account what has already been labeled very well, and so I think there's a lot that can be done if you actually take a look at at these metrics and try to change them as you start labeling more instances.",
            "So you really start focusing on the areas over the graph or the data that you should, but I think I think this just shows there's a great potential for using graph metrics to help.",
            "Active learning when you have relational data."
        ],
        [
            "And I'll leave it at that.",
            "Thank you.",
            "Very nice service.",
            "I'm going to use this so.",
            "I'll repeat that.",
            "So I was interested in the fact that you said the ERM chosen example was usually near the top of one of the strategies, and I'm just wondering, did you try to just do like a round Robin from the?",
            "From the strategies to try to have a better, possibly a better comparison algorithm to the any individuals, right?",
            "No, that's actually an interesting approach.",
            "No, I did not, but it's certainly worthwhile thinking about.",
            "That's a good idea.",
            "Fast.",
            "How did you do the clustering?",
            "Right, so I basically used one of the standard clustering methods out there from physics Mark Newman's community clustering using modularity.",
            "Yeah, I mean you get partitions right, right?",
            "Well there is, yeah.",
            "Really want overlapping clusters that may improve your process?",
            "That's that's that's that's that's that's that's true.",
            "One of the reasons I used it is it has he had a nice information theoretic color.",
            "He said these are the kind of optimal clusters using modularity and it really nice decomposed into subclusters, which I'm actually using.",
            "It didn't go through it here, so it has some really nice properties I liked and that was one of the reasons I used it.",
            "But your point is well taken.",
            "One of those, yes.",
            "It's not necessarily something we want, but that is something that we can measure right exactly right, right?",
            "Right, but it just has some really nice hierarchical characteristics, and so I like that.",
            "That I wanted for this particular approach.",
            "Thanks Peter for his answers.",
            "Sounds good."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Crates are, some are little bit of an outlier.",
                    "label": 0
                },
                {
                    "sent": "Since I'm not really doing multi relational data mining at this point, although it can be clearly extended to that.",
                    "label": 0
                },
                {
                    "sent": "I'll talk about that in a bit.",
                    "label": 0
                },
                {
                    "sent": "Also, I know it's late for everybody, so I will keep this very high level and.",
                    "label": 0
                },
                {
                    "sent": "Hopefully relatively short with very minimal math so.",
                    "label": 0
                },
                {
                    "sent": "Let me first set there.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The context of where what this talk really is about and what I'm trying to achieve here.",
                    "label": 0
                },
                {
                    "sent": "So we all know about supervised learning.",
                    "label": 0
                },
                {
                    "sent": "Most of us, hopefully all of us know about what semi supervised learning is.",
                    "label": 1
                },
                {
                    "sent": "Basically you given a partially labeled data set and you want to label the unlabeled data.",
                    "label": 1
                },
                {
                    "sent": "In that particular scenario, in the relational setting up and working well last couple of years on what we call within network learning or transductive learning with relational data.",
                    "label": 0
                },
                {
                    "sent": "Active learning, of course, is this idea of that you want to be able to select actively, select the next node to label in order to optimize and get a good model as possible with a few labels given labels as possible.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right, so the motivation behind this is that there was some reason work a few years back.",
                    "label": 0
                },
                {
                    "sent": "They combined relational learning and semi supervised learning graph with active learning and they showed that using empirical risk minimization really worked really well and they showed a really good method for doing that.",
                    "label": 1
                },
                {
                    "sent": "The problem with the with ERM is that it is quite slow.",
                    "label": 0
                },
                {
                    "sent": "You need basically need to go through every single unlabeled instance to a lot of computation to figure out which one you should label next.",
                    "label": 0
                },
                {
                    "sent": "So there's a lot of computational involved there.",
                    "label": 0
                },
                {
                    "sent": "The method they used here was a graph based semi supervised learning.",
                    "label": 0
                },
                {
                    "sent": "I'm not actually going to be coming Deputy algorithm here since that's somewhat beside the point, but I'm going to be using that same graph based machine learning method here.",
                    "label": 0
                },
                {
                    "sent": "It's basically a harmonic harmonic function.",
                    "label": 0
                },
                {
                    "sent": "Get the paper or talk to me afterward about that.",
                    "label": 0
                },
                {
                    "sent": "So the idea behind this work is to say, well, if we want to use DRM because you work really well, can we somehow figure out what are the SMS candidate number of instances you should look at?",
                    "label": 0
                },
                {
                    "sent": "Because that's probably going to be where the best instances and so in there by speeding up active learning by acquired by a lot of factors and so.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Using one of the key observations from that prior work here that let me down this path, namely the work in the prior works.",
                    "label": 0
                },
                {
                    "sent": "Notice that on synthetic graph data, ERM, tended to pick for that particular method which I'm using here, ERM, tended to pick notes there was, there were central to the underlying clusters in that data set, and so that seemed to me that we should be able to leverage leverage that particular observation in some way, right?",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So as I said, the idea is to keep your end, but limit computation by looking at the best candidates.",
                    "label": 1
                },
                {
                    "sent": "Right, and so the key observation from before seems to suggest that maybe we could do some kind of unsupervised clustering on the graph and then use graph metrics to find the central nodes in that particular cluster.",
                    "label": 0
                },
                {
                    "sent": "And that's where we should start off.",
                    "label": 1
                },
                {
                    "sent": "So that is 1 particular way.",
                    "label": 0
                },
                {
                    "sent": "Maybe there's also been all Noble uncertainty sampling, so maybe that's a better way of doing it as well.",
                    "label": 0
                },
                {
                    "sent": "They did that, but I'm putting it down here as well as another potential strategy and you'll see that late why I'm including that here later on.",
                    "label": 0
                },
                {
                    "sent": "You can also use a little bit more global graph metrics like just between the centrality or closeness and shadow across the whole graph.",
                    "label": 0
                },
                {
                    "sent": "Then maybe that's maybe those.",
                    "label": 0
                },
                {
                    "sent": "Those are the ways to go so their various ways we can try to come up with heuristics for seeing which instances.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You should be labeling next.",
                    "label": 0
                },
                {
                    "sent": "Right so.",
                    "label": 0
                },
                {
                    "sent": "I've noticed a so so I would like a few here.",
                    "label": 0
                },
                {
                    "sent": "I'm just going to go through what they actually mean, so I'm actually going to propose three particular metrics.",
                    "label": 0
                },
                {
                    "sent": "I'm going to take a little bit closer.",
                    "label": 0
                },
                {
                    "sent": "Look at the first one.",
                    "label": 0
                },
                {
                    "sent": "Being uncertainty sampling.",
                    "label": 0
                },
                {
                    "sent": "We all know about that.",
                    "label": 0
                },
                {
                    "sent": "We're basically just going to pick the most there.",
                    "label": 0
                },
                {
                    "sent": "Instead, you're most certain about.",
                    "label": 0
                },
                {
                    "sent": "Now, if you're going.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Graph based metrics between the centrality so between the centrality is really if you have this this graph so obviously showing a very toy example here to really show what's going on here.",
                    "label": 0
                },
                {
                    "sent": "So between the centrality of really the nodes in a graph that has the largest or maximum amount of information flowing through them.",
                    "label": 0
                },
                {
                    "sent": "If you look at how various nodes are connected in the graph, and so here is a I'm just putting in the equation here, but I'm not going to go through it.",
                    "label": 0
                },
                {
                    "sent": "But basically you're going to look at the shortest path between all possible nodes are going to look at the nodes that that.",
                    "label": 0
                },
                {
                    "sent": "That occur in most of these shortest paths, so in this particular instance here, in this particular toy graph, the ones that have the highest between us here is actually the ones that are not learning here, and so all their neighbors in fact, is also going to be relatively high between this as well, so they seem to be pretty good candidates.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That you would want to take a look at.",
                    "label": 0
                },
                {
                    "sent": "The third one I'm going to start with.",
                    "label": 0
                },
                {
                    "sent": "Closeness, centrality.",
                    "label": 0
                },
                {
                    "sent": "Closeness centrality is basically trying to identify the notes in the graph that has the shortest path average path to all other nodes in the graph.",
                    "label": 1
                },
                {
                    "sent": "So in this particular case here, closeness is basically going to be closer to the central notes here, so it doesn't seem that closes by itself is really what you want to go by.",
                    "label": 0
                },
                {
                    "sent": "In fact, empirically, I found that that was certainly not the case either, so I did validate that although that's not in.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Paper.",
                    "label": 0
                },
                {
                    "sent": "However, looking at propagation from from before, the idea would be, well, how about we cluster the graph first?",
                    "label": 0
                },
                {
                    "sent": "So if you first cluster the nodes, and in fact if he was any kind of clustering algorithm on this particular graph, you will come up with these nice clusters that have color coded here just a tool to really highlight what's going on.",
                    "label": 0
                },
                {
                    "sent": "So if you cluster the graph and then find the most central nodes in each graph in each of these sub clusters, you're going to find these particular notes here, and these were the ones that you would go after, and that seems to be that seems to be a pretty good heuristic at least.",
                    "label": 1
                },
                {
                    "sent": "Intuitively and theoretically, looking these kind of toy graphs.",
                    "label": 0
                },
                {
                    "sent": "That's probably that seems to be a pretty good way of going.",
                    "label": 0
                },
                {
                    "sent": "As I mentioned the paper.",
                    "label": 0
                },
                {
                    "sent": "However, this turned out not to be very good.",
                    "label": 0
                },
                {
                    "sent": "Still trying to figure out that, but I'm coming back to it a little bit later on.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right and part of part of the reasons is also that Tigres are really nice, but real graphs are a lot more dirty, right?",
                    "label": 0
                },
                {
                    "sent": "And so empirically, chances are that you probably want to be able to do a little bit better than using any of these heuristics, which really assume you have some really nice clean separation right then.",
                    "label": 0
                },
                {
                    "sent": "That's in fact what I found.",
                    "label": 0
                },
                {
                    "sent": "So the question that I.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And that is well.",
                    "label": 0
                },
                {
                    "sent": "Which of these methods actually seems to work pretty well?",
                    "label": 0
                },
                {
                    "sent": "In particular, first just for validation and just compare uncertainty between this so the full ERM and also just random sampling just to get a baseline and see what's going on.",
                    "label": 1
                },
                {
                    "sent": "And the two things I'm really interested in to make sure I preserve accuracy to ERM, which is pretty much one of the better ones.",
                    "label": 0
                },
                {
                    "sent": "Active learning strategies out there.",
                    "label": 0
                },
                {
                    "sent": "And I also want to certainly decrease the time, time to finish, and so that's really the key metric.",
                    "label": 0
                },
                {
                    "sent": "Keep the accuracy, but make it much faster.",
                    "label": 1
                },
                {
                    "sent": "And so the methodology I'm going to be using throughout here is initially I just randomly pick one instance for each class and then it'll just pick the next the next label until I have 100 instances.",
                    "label": 0
                },
                {
                    "sent": "That was just an ad hoc limit I said here to understand what's going on and I just repeated 10 times to get an average performance.",
                    "label": 0
                },
                {
                    "sent": "For those of you, if you think a little bit about it turns out that between this really has very little randomness here because it's a global measure on the graph, so it's a pretty much incentive to insensitive to the initial labels.",
                    "label": 0
                },
                {
                    "sent": "Whereas the others are not.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "511 benchmark datasets.",
                    "label": 0
                },
                {
                    "sent": "I'm not really going through the tail here.",
                    "label": 0
                },
                {
                    "sent": "Some of them are relatively small to webcaps are relatively small and a few hundreds.",
                    "label": 0
                },
                {
                    "sent": "The industry classifications about 1000 to about 2000.",
                    "label": 0
                },
                {
                    "sent": "That was a typo that supposed to be around.",
                    "label": 0
                },
                {
                    "sent": "2000 here and Core is the 4000 datasets, so they're not huge datasets, but at least give some sense of perform.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Games here.",
                    "label": 0
                },
                {
                    "sent": "Alright, so the first thing I did was just comparing a certainty the full DRM tools between this uncertainty just to make sure to gauge well what's going on here with these very simple heuristics and you can see here, two of the prototypical runs you see, ERM, is the red line, so that's quite well and you will see the other methods or so the purplish line is the random sampling and the two other lines you'll see is, erm, answer is between us and uncertainty, and you can see that they have some mixed.",
                    "label": 0
                },
                {
                    "sent": "They're not consistently.",
                    "label": 0
                },
                {
                    "sent": "Which one is better or worse here?",
                    "label": 0
                },
                {
                    "sent": "And as I said, the closeness and even the cluster closeness turned out not to work very well, so I didn't really look at it here, but I had an inch.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sting observation when I looked at these things and also when I looked at the closeness, namely that none of these strategies work very well by themselves, especially if you just looked at their topic.",
                    "label": 1
                },
                {
                    "sent": "And so obviously the idea here was also told to actually go back and redo CRM.",
                    "label": 0
                },
                {
                    "sent": "So what I actually did notice what that all of these strategies in their top K5 five to 10 PX they very consistently had had the instance that ERM would pick as well.",
                    "label": 0
                },
                {
                    "sent": "So that suggested a hybrid approach to me here, and that is basically look at all the other strategies, three of them here.",
                    "label": 1
                },
                {
                    "sent": "In this case, uncertainty between this and this cluster closeness.",
                    "label": 0
                },
                {
                    "sent": "Look at all three strategies.",
                    "label": 1
                },
                {
                    "sent": "Basically just get the top K pics in this particular instance I used the top five picks from each of these three strategies, and so that means I get a certain set of picks back from from each of these strategies.",
                    "label": 0
                },
                {
                    "sent": "And I actually use DRM on those to figure out which of them I should label next.",
                    "label": 0
                },
                {
                    "sent": "So that's the hype.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Approach and that actually turned out to work really well.",
                    "label": 0
                },
                {
                    "sent": "As you can see here in the arm versus the hybrid approach on the on the left you see the accuracy.",
                    "label": 0
                },
                {
                    "sent": "You can see we actually do a very consistently close to what DRM is.",
                    "label": 0
                },
                {
                    "sent": "So MSO is still the red line degree.",
                    "label": 0
                },
                {
                    "sent": "My is my hybrid approach and on the other side on the right side you'll see here there's the running time and we can see we basically get an order of magnitude speedup using this, and this is on a relatively small data set, so we would expect.",
                    "label": 0
                },
                {
                    "sent": "And so there's some interesting tradeoffs here between what is, what is the computational computations needed to all the tools or the graph mining versus just running these classifiers over again, and so, but I would in general expect this to go up and have a significant amount speedup even as you get up to larger graphs.",
                    "label": 0
                },
                {
                    "sent": "So the second question then.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Had was I wanted to understand a little bit better how each of these metrics actually will use and how often they actually were used by this hybrid approach.",
                    "label": 0
                },
                {
                    "sent": "And so here we have the 11 datasets that I have, and so in these cases here I'm looking at each cluster each column you can see how often the topic by ERM was was picked for feature for each metric, and so you see cluster closeness here in the in the.",
                    "label": 0
                },
                {
                    "sent": "In a in the top cases on the larger crowds here you can see it was picked roughly about 10% of the time over there, but on average I guess I should have an average at the bottom on.",
                    "label": 0
                },
                {
                    "sent": "Certainly something you can see.",
                    "label": 0
                },
                {
                    "sent": "It's actually being used quite a bit, and then you can see that between the centrality is actually also being used quite a bit.",
                    "label": 0
                },
                {
                    "sent": "And I was also interested to see we have consistently were.",
                    "label": 0
                },
                {
                    "sent": "How consistent with these metrics in terms of actually trying to going after the same area of the graph or the same instances.",
                    "label": 0
                },
                {
                    "sent": "And you can see here on the last column how often did multiple of these metrics actually select the same instance.",
                    "label": 0
                },
                {
                    "sent": "You can see here that on the larger graphs that actually didn't turn out to be very often put on these smaller graphs that actually turned out to be quite a bit, and so that was actually interesting by itself.",
                    "label": 0
                },
                {
                    "sent": "I think probably actually gets larger graphs.",
                    "label": 0
                },
                {
                    "sent": "You're going to have less of a tie.",
                    "label": 0
                },
                {
                    "sent": "Because they really seem to tend to to go after different parts of the graph.",
                    "label": 0
                },
                {
                    "sent": "The bottom graphs, obviously with relatively small, so there really wasn't much Marshall play around with there.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Just to summarize, ERM, is a really strong active learning strategy, but it's extremely slow, and so I Shona showed one weather method here to efficiently identify a small Canada set of notes that you should go after to use your M and figure out which one of these so to use.",
                    "label": 1
                },
                {
                    "sent": "So in particular here, if you have relational data or graph data, you can use graph metrics such as those I showed here, and I think it has really potentially great speedups.",
                    "label": 0
                },
                {
                    "sent": "And as I showed, we have basically comperable performance too.",
                    "label": 1
                },
                {
                    "sent": "So using the full RN but we get also an order of magnitude speedup in it.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But still, there's a lot of questions, so this is really an initial foray into this whole area, and I think there's a lot of things that still need to be done here, and so these are just some of the the first questions that really comes to mind, and there is.",
                    "label": 0
                },
                {
                    "sent": "I'm not quite sure why, why, for example, that cluster closeness didn't quite work as well as I thought, and so that's that's interesting.",
                    "label": 1
                },
                {
                    "sent": "But I think part of it is actually that I'm not really taking into account what has already been labeled very well, and so I think there's a lot that can be done if you actually take a look at at these metrics and try to change them as you start labeling more instances.",
                    "label": 0
                },
                {
                    "sent": "So you really start focusing on the areas over the graph or the data that you should, but I think I think this just shows there's a great potential for using graph metrics to help.",
                    "label": 1
                },
                {
                    "sent": "Active learning when you have relational data.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And I'll leave it at that.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Very nice service.",
                    "label": 0
                },
                {
                    "sent": "I'm going to use this so.",
                    "label": 0
                },
                {
                    "sent": "I'll repeat that.",
                    "label": 0
                },
                {
                    "sent": "So I was interested in the fact that you said the ERM chosen example was usually near the top of one of the strategies, and I'm just wondering, did you try to just do like a round Robin from the?",
                    "label": 0
                },
                {
                    "sent": "From the strategies to try to have a better, possibly a better comparison algorithm to the any individuals, right?",
                    "label": 0
                },
                {
                    "sent": "No, that's actually an interesting approach.",
                    "label": 0
                },
                {
                    "sent": "No, I did not, but it's certainly worthwhile thinking about.",
                    "label": 0
                },
                {
                    "sent": "That's a good idea.",
                    "label": 0
                },
                {
                    "sent": "Fast.",
                    "label": 0
                },
                {
                    "sent": "How did you do the clustering?",
                    "label": 0
                },
                {
                    "sent": "Right, so I basically used one of the standard clustering methods out there from physics Mark Newman's community clustering using modularity.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I mean you get partitions right, right?",
                    "label": 0
                },
                {
                    "sent": "Well there is, yeah.",
                    "label": 0
                },
                {
                    "sent": "Really want overlapping clusters that may improve your process?",
                    "label": 0
                },
                {
                    "sent": "That's that's that's that's that's that's that's true.",
                    "label": 0
                },
                {
                    "sent": "One of the reasons I used it is it has he had a nice information theoretic color.",
                    "label": 0
                },
                {
                    "sent": "He said these are the kind of optimal clusters using modularity and it really nice decomposed into subclusters, which I'm actually using.",
                    "label": 0
                },
                {
                    "sent": "It didn't go through it here, so it has some really nice properties I liked and that was one of the reasons I used it.",
                    "label": 0
                },
                {
                    "sent": "But your point is well taken.",
                    "label": 0
                },
                {
                    "sent": "One of those, yes.",
                    "label": 0
                },
                {
                    "sent": "It's not necessarily something we want, but that is something that we can measure right exactly right, right?",
                    "label": 0
                },
                {
                    "sent": "Right, but it just has some really nice hierarchical characteristics, and so I like that.",
                    "label": 0
                },
                {
                    "sent": "That I wanted for this particular approach.",
                    "label": 0
                },
                {
                    "sent": "Thanks Peter for his answers.",
                    "label": 0
                },
                {
                    "sent": "Sounds good.",
                    "label": 0
                }
            ]
        }
    }
}