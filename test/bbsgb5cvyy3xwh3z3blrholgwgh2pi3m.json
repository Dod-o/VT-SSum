{
    "id": "bbsgb5cvyy3xwh3z3blrholgwgh2pi3m",
    "title": "Measuring the Quality of Multi-document Cluster Headlines",
    "info": {
        "author": [
            "Frank Van Kesteren, University of Twente"
        ],
        "published": "Feb. 25, 2007",
        "recorded": "July 2006",
        "category": [
            "Top->Computer Science"
        ]
    },
    "url": "http://videolectures.net/iiia06_kesteren_mqmdc/",
    "segmentation": [
        [
            "Come to this session for today so we have two calls, the first of which would be by Frank Run Tester in and will be about measuring the quality of multi document cluster headlines.",
            "Hello.",
            "I did this research as part of my internship at.",
            "You know, together with vessel cry all semester."
        ],
        [
            "What will I tell?",
            "I first will give you some background on this research I've built just mean that I'll explain my internship.",
            "Actually, let me give some motivation for this.",
            "The rest of this experiment.",
            "What does the experimental setup model of my results and conclusions in some future?"
        ],
        [
            "Work.",
            "OK, first backgrounds.",
            "The research was part of a larger research project called Novalis.",
            "Novalis is a multifaceted information browser, which means that it consists of several types of documents.",
            "For example newspaper articles and annotated videos.",
            "All these documents are clustered automatically by topic and some extra metadata is generated for it.",
            "For example, proper names are extracted.",
            "Keywords bigrams, that sort of things.",
            "Better you can search novelist using an office browser and.",
            "Yeah, search for keywords and you were presented with a list of the clusters and the classes are represented by their headline."
        ],
        [
            "And that is why headline is important, because a good headline enables an efficient navigation in case of the browser.",
            "So.",
            "What are the headlines?",
            "Do we use?",
            "Well, we have two options.",
            "The first option we actually used before was a list of keywords and bigrams.",
            "Extracted from the cluster, so this headline gives a lot of information because, yeah, they sort of most important words in the documents.",
            "However, our opinion is that it's not really clear what it is about.",
            "Still, you got this words, but not the relations between them.",
            "For example, after Liverpool yadda yadda Cruyff and Surprising 5 one now you expect it's about football game but.",
            "Is not really sure.",
            "So the alternative is well formed sentences.",
            "So test the thing you can see there.",
            "But this gives the problem of course that you have to generate that."
        ],
        [
            "And there are several options how to do that at?",
            "You know, we experimented with several methods.",
            "Before I explain them.",
            "For before we started running these methods, first we took from all the documents in the clusters all the sentences and ordered the sentences on relevance.",
            "So the first sentence is most salient to the cluster.",
            "OK, the method we tried was first.",
            "Yeah, for completeness we included the old method of just listing the.",
            "Keywords and the bigrams.",
            "And the second option is the noun phrase selection from the list of sentences or sentence.",
            "We took the first 5 sentences or the experiment that.",
            "Extracted all the noun phrases and the best non traders were selected on the basis of the number of keywords that were in there.",
            "Another option, most selecting the best document headline.",
            "All the documents in a cluster or most of the times from newspaper articles and that sort of things.",
            "So they had already and headline a title.",
            "So one option was just to pick one of these titles and.",
            "Use that test headline for the entire cluster.",
            "Fort Methods we tried was compressing the most salient sentence, so pick the first sentence from the list and remove an important part of us.",
            "Just a rule based approach.",
            "In by which we try to make a sentence shorter.",
            "And last options we tried.",
            "I must change the cluster.",
            "What I mean by that is the generation of the clusters went automatically and it happened a lot that there are some documents that did not completely belong to the cluster.",
            "So we try to re cluster a cluster so we kept only the most important documents.",
            "And try to extract the headline from these documents.",
            "This didn't actually work very well because the ordering of the sentence is already solved.",
            "The problem actually of the important documents."
        ],
        [
            "From these methods manual activation detected that the third method was the best.",
            "Actually her selecting a document headline.",
            "From twister.",
            "Note that this means that we have no influence on the length of the headline.",
            "That line is just one of the titles that an author gave to his document, so we cannot implement this."
        ],
        [
            "So in itself is not very interesting, but we also did automatic affirmation.",
            "My use of Rouge one recall.",
            "We use we use Russia because that was standard evaluation, used a lot for measuring the quality of summaries and becausw headline can be seen as an extremely short summary before we could use Rolshoven recall as well for our problem.",
            "Well, how did we do that?",
            "We picked 100 clusters and manually created a headline for them.",
            "The models and.",
            "Breanne average of these clusters 60.",
            "Methods or variants of the one I just mentioned.",
            "And after that we manually evaluated this by giving them a score from one to five and automatically using the Russian recall."
        ],
        [
            "So what did you find?",
            "I stopped the manual evaluation, gave.",
            "#3 the method tree as the best option, so selecting the best document headline, but the recall gave us the non face selection as the best option.",
            "Well, in itself it doesn't say much, but we also.",
            "Calculated the correlation between them and there's a 0.21 and it's very low.",
            "Yeah, well."
        ],
        [
            "We wanted of course, Nope.",
            "How did this happen?",
            "Why?",
            "So I have a hypothesis was that rush one recall does not work well with headlines of different lengths.",
            "Longer headline gets better recall, of course.",
            "So we wanted to try to solutions to test of this hypothesis was correct the first month experiment with Jean Precision instead of recall.",
            "Tradition should negate the length of the sentence, so we thought it might help.",
            "And the second option was implementing a penalty for Russian recall for the length of the headline."
        ],
        [
            "Experimental setup was that we took a subset of the 100 clusters of 10 disk clusters.",
            "And for every ten of these clusters we ask 5 persons to create a headline manual headline.",
            "We use five models here to solve the problem of variability in the headline.",
            "You can think of that one person.",
            "Just use different words.",
            "We also asked 5 these five annotators to manually get headlines of the methods we used and this results in high correlation between these annotators.",
            "So before that, this was a reliable source.",
            "Next, we determine the correlation between these average manual quality scores and delicious course.",
            "In this case, Russia precision and the Russian recall with."
        ],
        [
            "Penalty.",
            "So much was the penalty we apply.",
            "Penalty was modeled after the penalties used in blue mean short blue as the rouges based on blue.",
            "Reply brief penalty when the generators headline was shorter than the shortest models, so one of the five models shorted in that one.",
            "And link penalty similar if the generated line was longer.",
            "Then along this model."
        ],
        [
            "Well, how did you calculate it?",
            "We just copied them from blue actually, so it's not really.",
            "Thought about but important here is that we used the sum of the length of all the generated headlines for one method.",
            "So if one generated headline was very short, this doesn't.",
            "Great absurd penalty for that.",
            "Cluster.",
            "However, we use the same over the length of the shortest model for the brevity penalty, and of course the length of the longest models for the length penalty."
        ],
        [
            "Further, we also, according to the hypothesis, was the sentence length important.",
            "So we also determine the correlation between the sentence length and Russia scores."
        ],
        [
            "Well.",
            "What about our results?",
            "What is presented here is a list of the evaluation methods and the correlation with the manual quality and the sentence length.",
            "And 1st row.",
            "Is the original set up?",
            "And you see the local correlation there at a high correlation with the sentence length we want to lower the sentence length.",
            "Increase the correlation with the quality."
        ],
        [
            "Every take look at the position.",
            "You see that the correlation with the manual quality isn't it increased.",
            "However, the sentence length is, yeah, it's negative, but it's still a high correlation and it's negative cause longer sentence.",
            "Get the lower roof curb."
        ],
        [
            "We're looking at the brevity penalty.",
            "You see that there's actually a little change, and this was the cause.",
            "The brief dependencies only applied when the generated headline is shorter than the shortest model, but we found that it never almost never happened, because the manual headlines were already fairly short.",
            "So not much change there."
        ],
        [
            "Final Michelle this Toriko one plus.",
            "A link penalty what we see here is actually what we want.",
            "Correlation with the manual quality compared with the original.",
            "Recall increased some double and the correlation with the sentence length is almost 0, so I think this is the way to go."
        ],
        [
            "So are the conclusions bridges that position one improves quality correlation between the manual and automatically?",
            "Between manual and automatic activation, however, the correlation with the length is just a sign and which is on recall and a length penalty doubles the correlation and minimize.",
            "The correlation of length."
        ],
        [
            "However, it's a higher score, as you could see, it's still a weak correlation, so further research research should improve use of this penalty score."
        ],
        [
            "That's also for station or any questions.",
            "Plenty of time for questions.",
            "So I actually have a question.",
            "In machine translation there is the same issue of automatic measures or the quality of the translation.",
            "And there is a very strong difference between the correlation coefficients that one gets at the sentence level, which are very low.",
            "Basically in the same range as the one you're showing, and the correlation coefficients that one gets at the system level.",
            "That is, when the score is used to compare different systems on a large number of sentences, and this one can be very high in the high.",
            "90s OK. Did you do I need any?",
            "So we only check the correlation with the manual evaluation, but not with other systems like what you mean.",
            "No, I mean.",
            "The correlation between.",
            "The average score given not on a single headline, but on a whole set of headlines in order to rank different sentences have gains.",
            "Yeah, a single number reference.",
            "Yeah we did that.",
            "I believe it don't have the numbers here.",
            "These were higher but.",
            "Yeah, they thought it didn't say really much because you want to check one headline.",
            "Normally you want to know the quality of 1 headline.",
            "I see, so that's what we wanted to try.",
            "We wanted to see if there was a method to.",
            "Find out that information.",
            "Specific reason to restrict your experiments to lose 1 only?",
            "After do the similar things with.",
            "Yeah, I know there's the time.",
            "We can also explain the issue etc.",
            "Any other questions?",
            "OK, thank you.",
            "So."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Come to this session for today so we have two calls, the first of which would be by Frank Run Tester in and will be about measuring the quality of multi document cluster headlines.",
                    "label": 0
                },
                {
                    "sent": "Hello.",
                    "label": 0
                },
                {
                    "sent": "I did this research as part of my internship at.",
                    "label": 0
                },
                {
                    "sent": "You know, together with vessel cry all semester.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What will I tell?",
                    "label": 0
                },
                {
                    "sent": "I first will give you some background on this research I've built just mean that I'll explain my internship.",
                    "label": 0
                },
                {
                    "sent": "Actually, let me give some motivation for this.",
                    "label": 0
                },
                {
                    "sent": "The rest of this experiment.",
                    "label": 0
                },
                {
                    "sent": "What does the experimental setup model of my results and conclusions in some future?",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Work.",
                    "label": 0
                },
                {
                    "sent": "OK, first backgrounds.",
                    "label": 0
                },
                {
                    "sent": "The research was part of a larger research project called Novalis.",
                    "label": 0
                },
                {
                    "sent": "Novalis is a multifaceted information browser, which means that it consists of several types of documents.",
                    "label": 1
                },
                {
                    "sent": "For example newspaper articles and annotated videos.",
                    "label": 0
                },
                {
                    "sent": "All these documents are clustered automatically by topic and some extra metadata is generated for it.",
                    "label": 0
                },
                {
                    "sent": "For example, proper names are extracted.",
                    "label": 0
                },
                {
                    "sent": "Keywords bigrams, that sort of things.",
                    "label": 0
                },
                {
                    "sent": "Better you can search novelist using an office browser and.",
                    "label": 0
                },
                {
                    "sent": "Yeah, search for keywords and you were presented with a list of the clusters and the classes are represented by their headline.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And that is why headline is important, because a good headline enables an efficient navigation in case of the browser.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "What are the headlines?",
                    "label": 0
                },
                {
                    "sent": "Do we use?",
                    "label": 0
                },
                {
                    "sent": "Well, we have two options.",
                    "label": 1
                },
                {
                    "sent": "The first option we actually used before was a list of keywords and bigrams.",
                    "label": 1
                },
                {
                    "sent": "Extracted from the cluster, so this headline gives a lot of information because, yeah, they sort of most important words in the documents.",
                    "label": 0
                },
                {
                    "sent": "However, our opinion is that it's not really clear what it is about.",
                    "label": 0
                },
                {
                    "sent": "Still, you got this words, but not the relations between them.",
                    "label": 0
                },
                {
                    "sent": "For example, after Liverpool yadda yadda Cruyff and Surprising 5 one now you expect it's about football game but.",
                    "label": 1
                },
                {
                    "sent": "Is not really sure.",
                    "label": 0
                },
                {
                    "sent": "So the alternative is well formed sentences.",
                    "label": 0
                },
                {
                    "sent": "So test the thing you can see there.",
                    "label": 0
                },
                {
                    "sent": "But this gives the problem of course that you have to generate that.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And there are several options how to do that at?",
                    "label": 0
                },
                {
                    "sent": "You know, we experimented with several methods.",
                    "label": 0
                },
                {
                    "sent": "Before I explain them.",
                    "label": 0
                },
                {
                    "sent": "For before we started running these methods, first we took from all the documents in the clusters all the sentences and ordered the sentences on relevance.",
                    "label": 0
                },
                {
                    "sent": "So the first sentence is most salient to the cluster.",
                    "label": 0
                },
                {
                    "sent": "OK, the method we tried was first.",
                    "label": 0
                },
                {
                    "sent": "Yeah, for completeness we included the old method of just listing the.",
                    "label": 0
                },
                {
                    "sent": "Keywords and the bigrams.",
                    "label": 0
                },
                {
                    "sent": "And the second option is the noun phrase selection from the list of sentences or sentence.",
                    "label": 1
                },
                {
                    "sent": "We took the first 5 sentences or the experiment that.",
                    "label": 0
                },
                {
                    "sent": "Extracted all the noun phrases and the best non traders were selected on the basis of the number of keywords that were in there.",
                    "label": 0
                },
                {
                    "sent": "Another option, most selecting the best document headline.",
                    "label": 1
                },
                {
                    "sent": "All the documents in a cluster or most of the times from newspaper articles and that sort of things.",
                    "label": 0
                },
                {
                    "sent": "So they had already and headline a title.",
                    "label": 0
                },
                {
                    "sent": "So one option was just to pick one of these titles and.",
                    "label": 1
                },
                {
                    "sent": "Use that test headline for the entire cluster.",
                    "label": 0
                },
                {
                    "sent": "Fort Methods we tried was compressing the most salient sentence, so pick the first sentence from the list and remove an important part of us.",
                    "label": 0
                },
                {
                    "sent": "Just a rule based approach.",
                    "label": 0
                },
                {
                    "sent": "In by which we try to make a sentence shorter.",
                    "label": 0
                },
                {
                    "sent": "And last options we tried.",
                    "label": 0
                },
                {
                    "sent": "I must change the cluster.",
                    "label": 0
                },
                {
                    "sent": "What I mean by that is the generation of the clusters went automatically and it happened a lot that there are some documents that did not completely belong to the cluster.",
                    "label": 0
                },
                {
                    "sent": "So we try to re cluster a cluster so we kept only the most important documents.",
                    "label": 0
                },
                {
                    "sent": "And try to extract the headline from these documents.",
                    "label": 0
                },
                {
                    "sent": "This didn't actually work very well because the ordering of the sentence is already solved.",
                    "label": 0
                },
                {
                    "sent": "The problem actually of the important documents.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "From these methods manual activation detected that the third method was the best.",
                    "label": 0
                },
                {
                    "sent": "Actually her selecting a document headline.",
                    "label": 0
                },
                {
                    "sent": "From twister.",
                    "label": 0
                },
                {
                    "sent": "Note that this means that we have no influence on the length of the headline.",
                    "label": 0
                },
                {
                    "sent": "That line is just one of the titles that an author gave to his document, so we cannot implement this.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in itself is not very interesting, but we also did automatic affirmation.",
                    "label": 0
                },
                {
                    "sent": "My use of Rouge one recall.",
                    "label": 0
                },
                {
                    "sent": "We use we use Russia because that was standard evaluation, used a lot for measuring the quality of summaries and becausw headline can be seen as an extremely short summary before we could use Rolshoven recall as well for our problem.",
                    "label": 0
                },
                {
                    "sent": "Well, how did we do that?",
                    "label": 0
                },
                {
                    "sent": "We picked 100 clusters and manually created a headline for them.",
                    "label": 0
                },
                {
                    "sent": "The models and.",
                    "label": 0
                },
                {
                    "sent": "Breanne average of these clusters 60.",
                    "label": 1
                },
                {
                    "sent": "Methods or variants of the one I just mentioned.",
                    "label": 0
                },
                {
                    "sent": "And after that we manually evaluated this by giving them a score from one to five and automatically using the Russian recall.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what did you find?",
                    "label": 0
                },
                {
                    "sent": "I stopped the manual evaluation, gave.",
                    "label": 0
                },
                {
                    "sent": "#3 the method tree as the best option, so selecting the best document headline, but the recall gave us the non face selection as the best option.",
                    "label": 0
                },
                {
                    "sent": "Well, in itself it doesn't say much, but we also.",
                    "label": 0
                },
                {
                    "sent": "Calculated the correlation between them and there's a 0.21 and it's very low.",
                    "label": 0
                },
                {
                    "sent": "Yeah, well.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We wanted of course, Nope.",
                    "label": 0
                },
                {
                    "sent": "How did this happen?",
                    "label": 0
                },
                {
                    "sent": "Why?",
                    "label": 0
                },
                {
                    "sent": "So I have a hypothesis was that rush one recall does not work well with headlines of different lengths.",
                    "label": 1
                },
                {
                    "sent": "Longer headline gets better recall, of course.",
                    "label": 0
                },
                {
                    "sent": "So we wanted to try to solutions to test of this hypothesis was correct the first month experiment with Jean Precision instead of recall.",
                    "label": 0
                },
                {
                    "sent": "Tradition should negate the length of the sentence, so we thought it might help.",
                    "label": 1
                },
                {
                    "sent": "And the second option was implementing a penalty for Russian recall for the length of the headline.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Experimental setup was that we took a subset of the 100 clusters of 10 disk clusters.",
                    "label": 1
                },
                {
                    "sent": "And for every ten of these clusters we ask 5 persons to create a headline manual headline.",
                    "label": 0
                },
                {
                    "sent": "We use five models here to solve the problem of variability in the headline.",
                    "label": 0
                },
                {
                    "sent": "You can think of that one person.",
                    "label": 0
                },
                {
                    "sent": "Just use different words.",
                    "label": 1
                },
                {
                    "sent": "We also asked 5 these five annotators to manually get headlines of the methods we used and this results in high correlation between these annotators.",
                    "label": 0
                },
                {
                    "sent": "So before that, this was a reliable source.",
                    "label": 1
                },
                {
                    "sent": "Next, we determine the correlation between these average manual quality scores and delicious course.",
                    "label": 0
                },
                {
                    "sent": "In this case, Russia precision and the Russian recall with.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Penalty.",
                    "label": 0
                },
                {
                    "sent": "So much was the penalty we apply.",
                    "label": 0
                },
                {
                    "sent": "Penalty was modeled after the penalties used in blue mean short blue as the rouges based on blue.",
                    "label": 1
                },
                {
                    "sent": "Reply brief penalty when the generators headline was shorter than the shortest models, so one of the five models shorted in that one.",
                    "label": 1
                },
                {
                    "sent": "And link penalty similar if the generated line was longer.",
                    "label": 0
                },
                {
                    "sent": "Then along this model.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well, how did you calculate it?",
                    "label": 0
                },
                {
                    "sent": "We just copied them from blue actually, so it's not really.",
                    "label": 0
                },
                {
                    "sent": "Thought about but important here is that we used the sum of the length of all the generated headlines for one method.",
                    "label": 1
                },
                {
                    "sent": "So if one generated headline was very short, this doesn't.",
                    "label": 0
                },
                {
                    "sent": "Great absurd penalty for that.",
                    "label": 0
                },
                {
                    "sent": "Cluster.",
                    "label": 1
                },
                {
                    "sent": "However, we use the same over the length of the shortest model for the brevity penalty, and of course the length of the longest models for the length penalty.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Further, we also, according to the hypothesis, was the sentence length important.",
                    "label": 0
                },
                {
                    "sent": "So we also determine the correlation between the sentence length and Russia scores.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well.",
                    "label": 0
                },
                {
                    "sent": "What about our results?",
                    "label": 0
                },
                {
                    "sent": "What is presented here is a list of the evaluation methods and the correlation with the manual quality and the sentence length.",
                    "label": 1
                },
                {
                    "sent": "And 1st row.",
                    "label": 0
                },
                {
                    "sent": "Is the original set up?",
                    "label": 0
                },
                {
                    "sent": "And you see the local correlation there at a high correlation with the sentence length we want to lower the sentence length.",
                    "label": 0
                },
                {
                    "sent": "Increase the correlation with the quality.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Every take look at the position.",
                    "label": 0
                },
                {
                    "sent": "You see that the correlation with the manual quality isn't it increased.",
                    "label": 1
                },
                {
                    "sent": "However, the sentence length is, yeah, it's negative, but it's still a high correlation and it's negative cause longer sentence.",
                    "label": 0
                },
                {
                    "sent": "Get the lower roof curb.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We're looking at the brevity penalty.",
                    "label": 0
                },
                {
                    "sent": "You see that there's actually a little change, and this was the cause.",
                    "label": 0
                },
                {
                    "sent": "The brief dependencies only applied when the generated headline is shorter than the shortest model, but we found that it never almost never happened, because the manual headlines were already fairly short.",
                    "label": 0
                },
                {
                    "sent": "So not much change there.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Final Michelle this Toriko one plus.",
                    "label": 0
                },
                {
                    "sent": "A link penalty what we see here is actually what we want.",
                    "label": 0
                },
                {
                    "sent": "Correlation with the manual quality compared with the original.",
                    "label": 1
                },
                {
                    "sent": "Recall increased some double and the correlation with the sentence length is almost 0, so I think this is the way to go.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So are the conclusions bridges that position one improves quality correlation between the manual and automatically?",
                    "label": 0
                },
                {
                    "sent": "Between manual and automatic activation, however, the correlation with the length is just a sign and which is on recall and a length penalty doubles the correlation and minimize.",
                    "label": 1
                },
                {
                    "sent": "The correlation of length.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "However, it's a higher score, as you could see, it's still a weak correlation, so further research research should improve use of this penalty score.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's also for station or any questions.",
                    "label": 0
                },
                {
                    "sent": "Plenty of time for questions.",
                    "label": 0
                },
                {
                    "sent": "So I actually have a question.",
                    "label": 0
                },
                {
                    "sent": "In machine translation there is the same issue of automatic measures or the quality of the translation.",
                    "label": 0
                },
                {
                    "sent": "And there is a very strong difference between the correlation coefficients that one gets at the sentence level, which are very low.",
                    "label": 0
                },
                {
                    "sent": "Basically in the same range as the one you're showing, and the correlation coefficients that one gets at the system level.",
                    "label": 0
                },
                {
                    "sent": "That is, when the score is used to compare different systems on a large number of sentences, and this one can be very high in the high.",
                    "label": 0
                },
                {
                    "sent": "90s OK. Did you do I need any?",
                    "label": 0
                },
                {
                    "sent": "So we only check the correlation with the manual evaluation, but not with other systems like what you mean.",
                    "label": 0
                },
                {
                    "sent": "No, I mean.",
                    "label": 0
                },
                {
                    "sent": "The correlation between.",
                    "label": 0
                },
                {
                    "sent": "The average score given not on a single headline, but on a whole set of headlines in order to rank different sentences have gains.",
                    "label": 0
                },
                {
                    "sent": "Yeah, a single number reference.",
                    "label": 0
                },
                {
                    "sent": "Yeah we did that.",
                    "label": 0
                },
                {
                    "sent": "I believe it don't have the numbers here.",
                    "label": 0
                },
                {
                    "sent": "These were higher but.",
                    "label": 0
                },
                {
                    "sent": "Yeah, they thought it didn't say really much because you want to check one headline.",
                    "label": 0
                },
                {
                    "sent": "Normally you want to know the quality of 1 headline.",
                    "label": 0
                },
                {
                    "sent": "I see, so that's what we wanted to try.",
                    "label": 0
                },
                {
                    "sent": "We wanted to see if there was a method to.",
                    "label": 0
                },
                {
                    "sent": "Find out that information.",
                    "label": 0
                },
                {
                    "sent": "Specific reason to restrict your experiments to lose 1 only?",
                    "label": 0
                },
                {
                    "sent": "After do the similar things with.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I know there's the time.",
                    "label": 0
                },
                {
                    "sent": "We can also explain the issue etc.",
                    "label": 0
                },
                {
                    "sent": "Any other questions?",
                    "label": 0
                },
                {
                    "sent": "OK, thank you.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        }
    }
}