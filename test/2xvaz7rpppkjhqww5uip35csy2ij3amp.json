{
    "id": "2xvaz7rpppkjhqww5uip35csy2ij3amp",
    "title": "Ihara Coeficients: A Flexible Tool for Higher Order Learning",
    "info": {
        "author": [
            "Edwin Hancock, Department of Computer Science, University of York"
        ],
        "published": "Sept. 13, 2010",
        "recorded": "August 2010",
        "category": [
            "Top->Computer Science->Pattern Recognition"
        ]
    },
    "url": "http://videolectures.net/ssspr2010_hancock_icft/",
    "segmentation": [
        [
            "OK, this is work which is principally being undertaken by Peng Run and Butt and Tatiana Alexi in collaboration with Rich Wilson.",
            "Myself.",
            "Tatiana was a visiting research student from this University in Serbia.",
            "So the book is supported by the Royal Society and the Europe."
        ],
        [
            "Projects in bed.",
            "So just to go back to the talk I gave earlier in the conference, one of the problems that you're confronted with in structural pattern recognition is to characterize variations in graph structure which arise from variations in underlying data source.",
            "For instance, here images."
        ],
        [
            "And one of the things you would like to be able to do is to find an efficient way of characterizing such variations in graph structure without actually having to go the whole hog and evaluate correspondences between every pair of graphs in the data set that you're analyzing.",
            "So the problem is, can we analyze the structure of graphs without solving the graph matching problem, and in my group we've made a certain amount of progress over the last years.",
            "In approaching this problem using.",
            "Models based on random walks, particularly Fusion processes on graphs, so to go."
        ],
        [
            "After some.",
            "I'll try to explain how we might sort of break this problem down if one were trying to characterize graphs, then a number of different approaches that you could take so user characterizations that don't involve searching for correspondence is and so for instance, the simplest thing to do is to take take a topological viewpoint, and here we can use simple measures derived from graphs such as the average degree degree distribution, edge density, so on and so forth as a characterization.",
            "Of the overall structure of a graph.",
            "Never course more sophisticated ways, and there's a lot of mileage and using graph spectral methods and very closely linked to graph spectral methods are algebraic methods, and so, whereas the spectral methods use the eigenvalues of an adjacency matrix or in plastic matrix, algebraic methods use the coefficients of a characteristic polynomial.",
            "And of course there's a one to one link between the coefficients of.",
            "The characteristic polynomial and a set of eigen values.",
            "And that's that the eigenvalues are symmetric polynomials of the sort of coefficients are symmetric polynomials of the icon."
        ],
        [
            "Values.",
            "Now in some prior work, particularly with beige.",
            "So what we were able to do is to show how representation derived from the heat kernel trace provided a way of distinguishing graphs based on on measurements of the of the structure and the I'll go through this in a moment, but the idea was that if we took the heat kernel trace, this turned out to be a function of time that differentiates.",
            "The structure of different graphs and if we tried to characterize the heat kernel trace using a moments representation list, let it lead us to representation of graphs based on Zeta functions.",
            "Another interesting feature that came out of this work is if you took the derivative of the Zeta function at the origin.",
            "This quantity was linked to the number of spanning trees in the graph and this results be known for a long time and it's it's due to Mackay."
        ],
        [
            "So here's a picture to illustrate this.",
            "This earlier work here are a number of different graphs with different overall structure.",
            "We start with the square.",
            "Then we have a Pentagon.",
            "We have a dumbbell and we have a filled in dumbbell here.",
            "What I've done is I've computed the trace of the heat kernel, which is the sum of the policy and eigenvalues expert exponentiated with negative time.",
            "And I've plotted this function that race the heat kernel as a function of time here and what you see is that for these different graphs.",
            "We get different shape curves and so for instance the square and Pentagon have similar curves and the dumbbell and the field dumbbell have similar curves.",
            "And if one then asks if you could distinguish these these curves, that race is the heat kernel using some sort of parameterization that leads you naturally to computing the moments of the heat, kernel, trace and peace."
        ],
        [
            "Analysis, which I won't go into, won't go into much depth, shows that the Zeta function or the sum of the non zero Laplacian eigenvalues exponentiated with a negative argument of the Zeta function.",
            "If you."
        ],
        [
            "Compute that quantity.",
            "Then it's actually very closely linked to the moments of the heat kernel trace.",
            "In fact, it's the moments of the heat kernel trace minus the number of connected components in a graph divided by normalizing gamma function."
        ],
        [
            "So that was where we we got two with beige.",
            "We showed that these Zeta function characterizations I moments of the heat kernel trace, were capable of distinguishing the graph.",
            "In fact, in a final way than the original heat kernel trace.",
            "And this led to successful object."
        ],
        [
            "Ignition.",
            "So really, the aim of this talk is to explore whether we could gain deeper insights into this problem.",
            "So the number of questions that we might want to ask, what more can Zita functions tell us about graph structure?",
            "How can they be used to probe structure and deepen way and how they linked to graph Spectra?"
        ],
        [
            "So what else to functions?",
            "Well, you come across them in number theory, where they're used to.",
            "Characterize the distribution of prime numbers and their extension since the graph domains where we replaced the concept of a prime number with the prime cycle and the Zeta function is defined over the length of those prime cycles and can be used as a graph characterization."
        ],
        [
            "And in particular, there's something called norouzi to function, which is rather different to the one I just showed you in terms of Laplacian Spectra, which captures information about the topological, spectral and algebraic properties of a graph in a very compact way, and what I want to do in this talk is to show how this representation would be applied to graphs, weighted graphs and also to hypergraphs."
        ],
        [
            "So how is the Harris Teeter function computed well?",
            "As I explained earlier, is determined by the distribution of prime cycles on a graph.",
            "I'll talk a little bit more about the mathematical definition later on, but there's actually a very straightforward way of computing the horezu to function which involves the transformation of the original graph, and I've written down the steps.",
            "Here, first of all, we transform the graph into an orientated line graph with edges, nodes and edges in the new.",
            "Sorry about this.",
            "It's gone, it's gone.",
            "Edges in the digraph indicating incidence of a common vertex.",
            "The Zeta function is the reciprocal of the characteristic polynomial for the orientated line graph adjacency matrix, and if we take the coefficients of this characteristic polynomial, these are determined by the eigenvalues of the orientated line graph adjacency matrix and an analysis which I'm trying to go through very quickly shows that the coefficients are linked.",
            "The coefficients of the characteristic polynomial are linked to topological quantities, such as cycle frequencies.",
            "Number of spanning trees so and so forth."
        ],
        [
            "So let's just show what I said in the previous slide in terms of pixels.",
            "So here's an original graph.",
            "Here's the digraph the directed graph you compute from that.",
            "And here is the orientated line graph and it's this this structure, whose adjacency matrix determines the harazi to function via its characteristic polynomial."
        ],
        [
            "So this is how they the horizontal function is defined mathematically rather than in pictures for graph G, with vertex set.",
            "VSE is defined over prime cycles, so if big peers, the prime cycle set P is little pieces.",
            "One of those prime cycles is the product of 1 minus.",
            "You will use the argument of the length of the prime cycle to the minus one.",
            "And we can reorganize this and express the horezu to function in terms of the characteristic polynomial of the orientated line graph.",
            "And this is the expression when it's written in that form.",
            "Here we have a sort of normalizing constant and then we multiply this by the inverse determinant of the characteristic polynomial which is given here in terms of a identity matrix.",
            "The adjacency matrix of the diagraph and this make this matrix D which is Q which is D minus either degree matrix minus the identity matrix times you squared."
        ],
        [
            "OK, so in that form it turns out to be a little a little bit intractable to manipulate the harazi to function, but it turns out there's a much simpler determinant expression for it in terms of the adjacency matrix 2H of the orientated line graph and I've written it here.",
            "That is the result of functions, just a determinant of I which is identity matrix minus two times TH to the minus one.",
            "And then this determinant is in fact just a characteristic polynomial in you, which I've written here, and it turns out that these coefficients the C note through to see M of the characteristic polynomial linked to the eigenvalues of this matrix TH, and in fact they're just a symmetric polynomials of the eigenvalues of TH and natural representation of the harazi to function.",
            "Which we could use for pattern analysis of graphs is simply to take these characteristic coefficients and to construct a vector over them and then to use these vectors for standard standard clustering.",
            "Or discrimination?"
        ],
        [
            "This is.",
            "So.",
            "This determinant, although it's just really a simple characteristic polynomial, there's little bit intimidating, and so in fact it can be rewritten in a slightly more tractable form, and so the one over the determinant of I -- T of S can be re expressed as the exponent of the sum of traces of T to the KT is the transition matrix times estica divided by K, where.",
            "The argument of the harazi to function and also what do these?",
            "What does the tracer TK mean?",
            "Well, trace of T to the K is simply a symmetric polynomial of order K, so expressed in this way.",
            "What it means is that we can.",
            "We can sum the RE Express the determinant, so approximation based on exponentials of sums of symmetric polynomials of the eigenvalues.",
            "Avti"
        ],
        [
            "So what are the points of contact based on that analysis between the harazi to function representation and existing representations of graphs?",
            "Well, first of all, the way in which we construct the harazi to function based on the orientated line graph turns out to be very similar to the construction that is used in order to compute the support matrix of a discrete time random walk and a piece of related work.",
            "David Adams, Richard Wilson, Simone Severini and myself have shown that if you use the the spectrum.",
            "Of the support matrix of discrete time quantum Walk, then that's able to lift problems of Co. Spectrality associated, particularly with strongly regular graphs and trees.",
            "So there's some hope that this representation based on the high Rosita function might possess the same properties.",
            "And then, as I've shown, there's a link between the Rosita function and symmetric polynomials or spectral spectral polynomials.",
            "Of the eigenvalues.",
            "So in a paper which appeared in Pam in 2005, Richard Wilson been lower myself, showed how to use how to cluster graphs using symmetric polynomials over the Laplacian matrix, so this representation seems to capture the desirable properties of both of these pieces of previous work."
        ],
        [
            "Well, if we analyze the determinant, I won't go into the details.",
            "It turns out that by taking derivatives of the harazi to function and projecting out the derivative."
        ],
        [
            "Is that the origin?"
        ],
        [
            "What we can do is compute cycle frequencies in the graph that we're analyzing of various order.",
            "So a number of cycles of length L are determined by these derivatives of the horezu to function at the origin.",
            "So that's an interesting interesting assonance with the the result which we had for the first Zeta function.",
            "I showed the one analyzed by beige, where we showed that the.",
            "Derivative of that see to function at the origin is linked to number of spanning trees in a graph, and so higher order derivatives for the Rosita function give us information about the numbers of prime cycles of particular length in the graph.",
            "So this is a way of projecting out the prime cycles without actually necessarily having to detect them via exhaustive search."
        ],
        [
            "Each.",
            "So just some some results on this.",
            "This representation applied to simple graphs.",
            "What I've done here is I've done a scatter plot of the distance between vectors of the higher coefficients versus edit distance and you'll see that the scatter of Euclidean distance between our coefficients and edit distance has a sort of linear trend, and then I've compared coefficient representations based on on various.",
            "Representations of graphs here.",
            "So this is the Laplacian spectrum for a family of random graphs with random perturbations at into the nodes and edges, the same for symmetric polynomials, and then here for the higher coefficients and what you see is that the higher coefficients.",
            "Offer the best separation under noise of the three different representations that I've studied."
        ],
        [
            "So one of the hot topics now in dealing with relational data, is how to extend ideas from graphs where you can represent pairwise relationships to hypergraphs where you can represent higher order relationships.",
            "And I just like to go through some of the.",
            "How the higher representation extends to hypergraphs and give you a few experimental results.",
            "So I think I said this earlier hypergraphs requiring interest as a means of representing patterns involving higher order relations.",
            "They found a compact means of characterizing hypergraph if we're going to do this, we can require a compact means of characterizing hyper graphs that can be used in pattern recognition.",
            "So how we can do clustering, classification or compute similarity measures?",
            "And really, it's I think it's fair to say that there's no clearly accepted way of do."
        ],
        [
            "This at the moment.",
            "So I've listed here a number of previous attempts in the literature do this.",
            "I'm sort of rich or don't."
        ],
        [
            "Times I won't touch on that, but one of the approaches is to is to try to extend the concept of a Laplacian from the graph domain to the hypergraph domain.",
            "And here there are a number of alternatives, for instance, due in ICML 2005 proposed.",
            "This version we have a somewhat different version which pen Rang and I reported in SPR 2008."
        ],
        [
            "You compute these two different.",
            "Representations for here a graph and hear a hypergraph connecting the same set of three nodes.",
            "It turns out that there's no way in which you can distinguish on the basis of those laplacian's the difference between hyper graph and graph, and so it doesn't probe the relation relational structure of the points in a way which will give.",
            "You will distinguish the."
        ],
        [
            "Different possibilities so.",
            "The past few matrix only records adjacency relationships between pairs of nodes and the GLEX cardinality's of the hyperedges.",
            "This results in information laceration orders of varying degree or present so possible solution to this."
        ],
        [
            "Is to try to see whether we can use the O'Hara representation to overcome the problem."
        ],
        [
            "And so I mean, I won't go through the details of this, but in this paper in the previous paper we report how to extend the higher representation from graphs to hypergraphs."
        ],
        [
            "What I can do is I can show you this in pictures, so we start with with a hypergraph.",
            "We convert that into a bipartite."
        ],
        [
            "Graph."
        ],
        [
            "Then we compute the clique graph."
        ],
        [
            "For the bipartite."
        ],
        [
            "Graph and then we computed."
        ],
        [
            "Right click graph."
        ],
        [
            "And then that finally we compute an orientated line graph for the diklic graph."
        ],
        [
            "And we get the same sort of representation that I had earlier in terms of characteristic polynomials whose coefficients are now related to the symmetric polynomials of a spectrum of the transition matrix for the orientated line graph."
        ],
        [
            "So let's have a little look about what this means in terms of that simple example that I showed you earlier, where the two different versions of the Laplacian were not able to distinguish the situations of having a graph and hypergraph connecting the three different nodes here as other steps of the construction that I showed you on the previous slides applied to this, and so here we have the digraphs and the orientated line graphs for the two different situations.",
            "And what you notice is that for the first, for the first, for the graph, I get this situation in G where the relationships between the two sets of edges are represented.",
            "And then in this case here for the hypergraph I got a completely different representation of the arrangement of of nodes.",
            "So that means that I can I can."
        ],
        [
            "Distinguish between those those two situations.",
            "Of the three, the three different edges being connected by graph or the three different nodes being involved in a hyper graph."
        ],
        [
            "OK, so I mean that one of the issues which arises in this is that you have to be able to efficiently compute the numerical coefficients.",
            "One things we address in this work is how to do that, but I won't."
        ],
        [
            "Into details, so we've applied this to some of the familiar datasets that we've used previously, particularly modellhaus image sequences.",
            "And the whole datasets and what we've done is we have constructed a hyper graph where the hyper edges indicate two sets of relationships.",
            "The first is our proximity relationships.",
            "That is, so points have to be closer than a particular threshold, and Secondly we've encoded intensity.",
            "Information, that is to say, the intensity information around a feature point as difference between two points has to be less than a threshold as well, so I won't go into that.",
            "There are details in the paper we applied this to the three model House and the data set and images from the cloud."
        ],
        [
            "Data set, so there's some examples of the images."
        ],
        [
            "And so for the house."
        ],
        [
            "Dataset what we've done here is that we've compared compared the plus in Spectra.",
            "The passing methods of issue and also paying random myself with the higher coefficients and these distance Maps show the Euclidean distances between the hara coefficients for the hyper graphs, and we're getting here.",
            "Fred is strong distinction.",
            "Differentiation between the three different.",
            "Three different house datasets in the high."
        ],
        [
            "Coefficients, so if we didn't try to cluster that data based on the coefficient vectors, then we have from left right.",
            "The normalized Laplacian hypergraph Laplacian spectrum, the Laplacian spectrum and the higher coefficients.",
            "And you can see that in the case of the higher coefficients were getting better separation in the subspace that I've."
        ],
        [
            "No.",
            "Here's here's the results for."
        ],
        [
            "Oil and.",
            "What I've done here is I've plotted the coefficient data at the top.",
            "So here we have the coefficient data from the zoo, Laplacian, Penguins, normalized Laplacian, and the higher coefficients.",
            "So in the case of shoes Laplacian, the coefficient data is heavily overlapped with slightly less overlapped.",
            "In the case of Penguins normalized Laplacian but the overlap is smallest when we would use the higher coefficients and then here we've done PCA.",
            "On the coefficient vectors him and protect him down to 3 dimensional subspace and you again you see overlap severe overlap in the case of Jews Laplacian they overlap but of a lesser magnitude.",
            "In the case of Penguins at the place in Spectra and really quite clean separation when we use the hara coefficients of vectors of a higher coefficients for hypergraphs and then sort of a more quantitative analysis of the results.",
            "Underneath, in terms of the Rand index, so larger the Rand index here, the better the classification, and so the best results are always given by the higher coefficients in the bottom line."
        ],
        [
            "So just to conclude what I've done is, I've shown that a higher coefficients provide a flexible tool for both characterizing pairwise structures and higher order structures higher, higher coefficients capable of distinguishing structures were saying why pairwise connectivity with different relational orders, and I've shown efficient means of computing them for hypergraphs.",
            "So thank you very much indeed.",
            "Any questions?",
            "I think the question that comes clearly to mind is, without the equivalence classes of the different characterizing polynomial coefficients, right, so?",
            "Efficient with other graphs that give the same coefficients, right?",
            "I mean at the moment we were investigating that I mean the issue is really raised here.",
            "If I go back to some of the points of contact.",
            "In this previous work that we did.",
            "On using the support matrix of a discrete quantum walk on a graph, we showed empirically, we didn't really have.",
            "We didn't have any theoretical results.",
            "Moral intuition that this representation lifts the Co spectrality of families are strongly regular graphs and also reduces the Co spectrality of trees.",
            "The matrix that we use is constructed in the same way and.",
            "But in the in the case of discrete quantum walk, what we do is we take the positive support of the third power of that matrix and.",
            "What that means is that the discrete quantum walk gets a chance to interfere because by taking the third power, we're taking three steps, and so the walk and go out and then return back to the same node again.",
            "And in the case of a quantum walk you have a amplitudes which could interfere on the graph so that that seems to suggest that this representation is somehow sort of detecting.",
            "Symmetries that exist locally in the graph.",
            "The representation used in the higher coefficients is the same, but we don't take the third power.",
            "We don't take the positive support, and So what we're doing at the moment is we're investigating the relationship between these two representations, and although I can't answer your question Now, I might be able to answer it in three months time.",
            "Sorry for that tease.",
            "What happens if I?",
            "If you go to the space in which you have the graph represented in terms of those various properties, what happens if you subject the graph to slide perturbation?",
            "Right?",
            "We we represented in terms of slight deviations in the representation or.",
            "We are not assured of that.",
            "I think I think I've shown it here empirically.",
            "I mean this.",
            "So this is these graphs with sort of added and deleted nodes and edges, and so these.",
            "I mean I think we sort of go typically up to 5% node and edge noise.",
            "What did you do to change the graphs?",
            "We modify the edge structure and we remove nodes.",
            "So fresh.",
            "Yeah.",
            "Yeah, I mean I think the basically what we're doing is we were modifying the graphs up to a certain edit distance, allowing all modifications of graph up to a certain distance both in terms of node and edge modifications.",
            "Replacement property.",
            "The red labels and then the.",
            "I don't think they were replacements in the experiments, so we were dropping or adding nodes of a particular.",
            "Towards the original structure.",
            "So I mean that what this represents is the perturbations you get under those.",
            "Those kind of edit operations.",
            "And the question is, if you have a graph in which.",
            "The noise is added as follows.",
            "I have two classes of graphs that is hardly any noise.",
            "They are pretty solid, compact.",
            "Glasses.",
            "Locally.",
            "It's considered Part 2 classes were sent in one in class.",
            "Today I have brushed with her.",
            "Which are identical in structure.",
            "Let's just to make it simple, but their property, the sliding window, meaning the node properties like right?",
            "Has still the same problem, same set, except now I have added locali subgraph.",
            "The small subgraphs is localized right?",
            "Yeah, but otherwise it's exactly the same.",
            "Properties are following the same distribution or properties.",
            "Only thing is very localized localized.",
            "I mean in terms of the number of nodes and edges affected, right?",
            "Rush.",
            "I don't.",
            "I don't know the answer that question.",
            "I mean, it's just experiment.",
            "I mean basically take a piece of structure and to add it on.",
            "Or maybe swap it between two graphs and to see what happens.",
            "I don't know the answer to question.",
            "Do you believe that?",
            "Must or will it be showing through?",
            "And now I think you could answer the way which would show through.",
            "So for instance, if I take that structure.",
            "And I connect it to the original structure with a just a single bridging edge.",
            "It will have a big impact on the spectral gap and so that will perturb the coefficients in a very systematic way.",
            "Using.",
            "Adoption.",
            "Do some sort of numbers problem.",
            "If you design A graph with a particular.",
            "Polynomial.",
            "That's hard, and I mean somebody who knows quite a lot about it is sitting behind you the.",
            "A problem is this that if you these coefficients are determined by the spectrum.",
            "To compute the original Laplacian or adjacency matrix, what you do is you take the spectrum pre and post multiply it by the eigenvector matrix and the transpose.",
            "Now though these coefficients you could you could use them, you could set generated coefficients.",
            "You could in principle that's going to be quite hard solve the set of symmetric polynomials for the eigenvalues.",
            "That's going to be have lots of ambiguities in it because you're solving a mixed set of equations which go from.",
            "Sum to a product of eigenvalues.",
            "Even if you could actually recover the eigenvalues from a solving the set of symmetric polynomials.",
            "You would then have to worry about how to generate the eigenvectors.",
            "And so there are counting ways of doing it.",
            "And as I say, someone who knows something about that is sitting directly behind you and.",
            "What you suggested is in the form you stated it not really tractable."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, this is work which is principally being undertaken by Peng Run and Butt and Tatiana Alexi in collaboration with Rich Wilson.",
                    "label": 0
                },
                {
                    "sent": "Myself.",
                    "label": 0
                },
                {
                    "sent": "Tatiana was a visiting research student from this University in Serbia.",
                    "label": 0
                },
                {
                    "sent": "So the book is supported by the Royal Society and the Europe.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Projects in bed.",
                    "label": 0
                },
                {
                    "sent": "So just to go back to the talk I gave earlier in the conference, one of the problems that you're confronted with in structural pattern recognition is to characterize variations in graph structure which arise from variations in underlying data source.",
                    "label": 0
                },
                {
                    "sent": "For instance, here images.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And one of the things you would like to be able to do is to find an efficient way of characterizing such variations in graph structure without actually having to go the whole hog and evaluate correspondences between every pair of graphs in the data set that you're analyzing.",
                    "label": 0
                },
                {
                    "sent": "So the problem is, can we analyze the structure of graphs without solving the graph matching problem, and in my group we've made a certain amount of progress over the last years.",
                    "label": 1
                },
                {
                    "sent": "In approaching this problem using.",
                    "label": 0
                },
                {
                    "sent": "Models based on random walks, particularly Fusion processes on graphs, so to go.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "After some.",
                    "label": 0
                },
                {
                    "sent": "I'll try to explain how we might sort of break this problem down if one were trying to characterize graphs, then a number of different approaches that you could take so user characterizations that don't involve searching for correspondence is and so for instance, the simplest thing to do is to take take a topological viewpoint, and here we can use simple measures derived from graphs such as the average degree degree distribution, edge density, so on and so forth as a characterization.",
                    "label": 0
                },
                {
                    "sent": "Of the overall structure of a graph.",
                    "label": 0
                },
                {
                    "sent": "Never course more sophisticated ways, and there's a lot of mileage and using graph spectral methods and very closely linked to graph spectral methods are algebraic methods, and so, whereas the spectral methods use the eigenvalues of an adjacency matrix or in plastic matrix, algebraic methods use the coefficients of a characteristic polynomial.",
                    "label": 1
                },
                {
                    "sent": "And of course there's a one to one link between the coefficients of.",
                    "label": 0
                },
                {
                    "sent": "The characteristic polynomial and a set of eigen values.",
                    "label": 0
                },
                {
                    "sent": "And that's that the eigenvalues are symmetric polynomials of the sort of coefficients are symmetric polynomials of the icon.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Values.",
                    "label": 0
                },
                {
                    "sent": "Now in some prior work, particularly with beige.",
                    "label": 0
                },
                {
                    "sent": "So what we were able to do is to show how representation derived from the heat kernel trace provided a way of distinguishing graphs based on on measurements of the of the structure and the I'll go through this in a moment, but the idea was that if we took the heat kernel trace, this turned out to be a function of time that differentiates.",
                    "label": 0
                },
                {
                    "sent": "The structure of different graphs and if we tried to characterize the heat kernel trace using a moments representation list, let it lead us to representation of graphs based on Zeta functions.",
                    "label": 1
                },
                {
                    "sent": "Another interesting feature that came out of this work is if you took the derivative of the Zeta function at the origin.",
                    "label": 0
                },
                {
                    "sent": "This quantity was linked to the number of spanning trees in the graph and this results be known for a long time and it's it's due to Mackay.",
                    "label": 1
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's a picture to illustrate this.",
                    "label": 0
                },
                {
                    "sent": "This earlier work here are a number of different graphs with different overall structure.",
                    "label": 0
                },
                {
                    "sent": "We start with the square.",
                    "label": 0
                },
                {
                    "sent": "Then we have a Pentagon.",
                    "label": 0
                },
                {
                    "sent": "We have a dumbbell and we have a filled in dumbbell here.",
                    "label": 0
                },
                {
                    "sent": "What I've done is I've computed the trace of the heat kernel, which is the sum of the policy and eigenvalues expert exponentiated with negative time.",
                    "label": 0
                },
                {
                    "sent": "And I've plotted this function that race the heat kernel as a function of time here and what you see is that for these different graphs.",
                    "label": 0
                },
                {
                    "sent": "We get different shape curves and so for instance the square and Pentagon have similar curves and the dumbbell and the field dumbbell have similar curves.",
                    "label": 0
                },
                {
                    "sent": "And if one then asks if you could distinguish these these curves, that race is the heat kernel using some sort of parameterization that leads you naturally to computing the moments of the heat, kernel, trace and peace.",
                    "label": 1
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Analysis, which I won't go into, won't go into much depth, shows that the Zeta function or the sum of the non zero Laplacian eigenvalues exponentiated with a negative argument of the Zeta function.",
                    "label": 0
                },
                {
                    "sent": "If you.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Compute that quantity.",
                    "label": 0
                },
                {
                    "sent": "Then it's actually very closely linked to the moments of the heat kernel trace.",
                    "label": 0
                },
                {
                    "sent": "In fact, it's the moments of the heat kernel trace minus the number of connected components in a graph divided by normalizing gamma function.",
                    "label": 1
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that was where we we got two with beige.",
                    "label": 0
                },
                {
                    "sent": "We showed that these Zeta function characterizations I moments of the heat kernel trace, were capable of distinguishing the graph.",
                    "label": 0
                },
                {
                    "sent": "In fact, in a final way than the original heat kernel trace.",
                    "label": 0
                },
                {
                    "sent": "And this led to successful object.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Ignition.",
                    "label": 0
                },
                {
                    "sent": "So really, the aim of this talk is to explore whether we could gain deeper insights into this problem.",
                    "label": 0
                },
                {
                    "sent": "So the number of questions that we might want to ask, what more can Zita functions tell us about graph structure?",
                    "label": 1
                },
                {
                    "sent": "How can they be used to probe structure and deepen way and how they linked to graph Spectra?",
                    "label": 1
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what else to functions?",
                    "label": 0
                },
                {
                    "sent": "Well, you come across them in number theory, where they're used to.",
                    "label": 1
                },
                {
                    "sent": "Characterize the distribution of prime numbers and their extension since the graph domains where we replaced the concept of a prime number with the prime cycle and the Zeta function is defined over the length of those prime cycles and can be used as a graph characterization.",
                    "label": 1
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in particular, there's something called norouzi to function, which is rather different to the one I just showed you in terms of Laplacian Spectra, which captures information about the topological, spectral and algebraic properties of a graph in a very compact way, and what I want to do in this talk is to show how this representation would be applied to graphs, weighted graphs and also to hypergraphs.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how is the Harris Teeter function computed well?",
                    "label": 0
                },
                {
                    "sent": "As I explained earlier, is determined by the distribution of prime cycles on a graph.",
                    "label": 1
                },
                {
                    "sent": "I'll talk a little bit more about the mathematical definition later on, but there's actually a very straightforward way of computing the horezu to function which involves the transformation of the original graph, and I've written down the steps.",
                    "label": 0
                },
                {
                    "sent": "Here, first of all, we transform the graph into an orientated line graph with edges, nodes and edges in the new.",
                    "label": 0
                },
                {
                    "sent": "Sorry about this.",
                    "label": 0
                },
                {
                    "sent": "It's gone, it's gone.",
                    "label": 0
                },
                {
                    "sent": "Edges in the digraph indicating incidence of a common vertex.",
                    "label": 1
                },
                {
                    "sent": "The Zeta function is the reciprocal of the characteristic polynomial for the orientated line graph adjacency matrix, and if we take the coefficients of this characteristic polynomial, these are determined by the eigenvalues of the orientated line graph adjacency matrix and an analysis which I'm trying to go through very quickly shows that the coefficients are linked.",
                    "label": 0
                },
                {
                    "sent": "The coefficients of the characteristic polynomial are linked to topological quantities, such as cycle frequencies.",
                    "label": 0
                },
                {
                    "sent": "Number of spanning trees so and so forth.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's just show what I said in the previous slide in terms of pixels.",
                    "label": 0
                },
                {
                    "sent": "So here's an original graph.",
                    "label": 0
                },
                {
                    "sent": "Here's the digraph the directed graph you compute from that.",
                    "label": 0
                },
                {
                    "sent": "And here is the orientated line graph and it's this this structure, whose adjacency matrix determines the harazi to function via its characteristic polynomial.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is how they the horizontal function is defined mathematically rather than in pictures for graph G, with vertex set.",
                    "label": 0
                },
                {
                    "sent": "VSE is defined over prime cycles, so if big peers, the prime cycle set P is little pieces.",
                    "label": 1
                },
                {
                    "sent": "One of those prime cycles is the product of 1 minus.",
                    "label": 0
                },
                {
                    "sent": "You will use the argument of the length of the prime cycle to the minus one.",
                    "label": 0
                },
                {
                    "sent": "And we can reorganize this and express the horezu to function in terms of the characteristic polynomial of the orientated line graph.",
                    "label": 1
                },
                {
                    "sent": "And this is the expression when it's written in that form.",
                    "label": 0
                },
                {
                    "sent": "Here we have a sort of normalizing constant and then we multiply this by the inverse determinant of the characteristic polynomial which is given here in terms of a identity matrix.",
                    "label": 1
                },
                {
                    "sent": "The adjacency matrix of the diagraph and this make this matrix D which is Q which is D minus either degree matrix minus the identity matrix times you squared.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so in that form it turns out to be a little a little bit intractable to manipulate the harazi to function, but it turns out there's a much simpler determinant expression for it in terms of the adjacency matrix 2H of the orientated line graph and I've written it here.",
                    "label": 1
                },
                {
                    "sent": "That is the result of functions, just a determinant of I which is identity matrix minus two times TH to the minus one.",
                    "label": 0
                },
                {
                    "sent": "And then this determinant is in fact just a characteristic polynomial in you, which I've written here, and it turns out that these coefficients the C note through to see M of the characteristic polynomial linked to the eigenvalues of this matrix TH, and in fact they're just a symmetric polynomials of the eigenvalues of TH and natural representation of the harazi to function.",
                    "label": 0
                },
                {
                    "sent": "Which we could use for pattern analysis of graphs is simply to take these characteristic coefficients and to construct a vector over them and then to use these vectors for standard standard clustering.",
                    "label": 0
                },
                {
                    "sent": "Or discrimination?",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "This determinant, although it's just really a simple characteristic polynomial, there's little bit intimidating, and so in fact it can be rewritten in a slightly more tractable form, and so the one over the determinant of I -- T of S can be re expressed as the exponent of the sum of traces of T to the KT is the transition matrix times estica divided by K, where.",
                    "label": 0
                },
                {
                    "sent": "The argument of the harazi to function and also what do these?",
                    "label": 0
                },
                {
                    "sent": "What does the tracer TK mean?",
                    "label": 0
                },
                {
                    "sent": "Well, trace of T to the K is simply a symmetric polynomial of order K, so expressed in this way.",
                    "label": 1
                },
                {
                    "sent": "What it means is that we can.",
                    "label": 0
                },
                {
                    "sent": "We can sum the RE Express the determinant, so approximation based on exponentials of sums of symmetric polynomials of the eigenvalues.",
                    "label": 0
                },
                {
                    "sent": "Avti",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what are the points of contact based on that analysis between the harazi to function representation and existing representations of graphs?",
                    "label": 0
                },
                {
                    "sent": "Well, first of all, the way in which we construct the harazi to function based on the orientated line graph turns out to be very similar to the construction that is used in order to compute the support matrix of a discrete time random walk and a piece of related work.",
                    "label": 0
                },
                {
                    "sent": "David Adams, Richard Wilson, Simone Severini and myself have shown that if you use the the spectrum.",
                    "label": 1
                },
                {
                    "sent": "Of the support matrix of discrete time quantum Walk, then that's able to lift problems of Co. Spectrality associated, particularly with strongly regular graphs and trees.",
                    "label": 1
                },
                {
                    "sent": "So there's some hope that this representation based on the high Rosita function might possess the same properties.",
                    "label": 0
                },
                {
                    "sent": "And then, as I've shown, there's a link between the Rosita function and symmetric polynomials or spectral spectral polynomials.",
                    "label": 0
                },
                {
                    "sent": "Of the eigenvalues.",
                    "label": 0
                },
                {
                    "sent": "So in a paper which appeared in Pam in 2005, Richard Wilson been lower myself, showed how to use how to cluster graphs using symmetric polynomials over the Laplacian matrix, so this representation seems to capture the desirable properties of both of these pieces of previous work.",
                    "label": 1
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, if we analyze the determinant, I won't go into the details.",
                    "label": 0
                },
                {
                    "sent": "It turns out that by taking derivatives of the harazi to function and projecting out the derivative.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is that the origin?",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What we can do is compute cycle frequencies in the graph that we're analyzing of various order.",
                    "label": 0
                },
                {
                    "sent": "So a number of cycles of length L are determined by these derivatives of the horezu to function at the origin.",
                    "label": 1
                },
                {
                    "sent": "So that's an interesting interesting assonance with the the result which we had for the first Zeta function.",
                    "label": 0
                },
                {
                    "sent": "I showed the one analyzed by beige, where we showed that the.",
                    "label": 0
                },
                {
                    "sent": "Derivative of that see to function at the origin is linked to number of spanning trees in a graph, and so higher order derivatives for the Rosita function give us information about the numbers of prime cycles of particular length in the graph.",
                    "label": 0
                },
                {
                    "sent": "So this is a way of projecting out the prime cycles without actually necessarily having to detect them via exhaustive search.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Each.",
                    "label": 0
                },
                {
                    "sent": "So just some some results on this.",
                    "label": 0
                },
                {
                    "sent": "This representation applied to simple graphs.",
                    "label": 0
                },
                {
                    "sent": "What I've done here is I've done a scatter plot of the distance between vectors of the higher coefficients versus edit distance and you'll see that the scatter of Euclidean distance between our coefficients and edit distance has a sort of linear trend, and then I've compared coefficient representations based on on various.",
                    "label": 0
                },
                {
                    "sent": "Representations of graphs here.",
                    "label": 0
                },
                {
                    "sent": "So this is the Laplacian spectrum for a family of random graphs with random perturbations at into the nodes and edges, the same for symmetric polynomials, and then here for the higher coefficients and what you see is that the higher coefficients.",
                    "label": 0
                },
                {
                    "sent": "Offer the best separation under noise of the three different representations that I've studied.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So one of the hot topics now in dealing with relational data, is how to extend ideas from graphs where you can represent pairwise relationships to hypergraphs where you can represent higher order relationships.",
                    "label": 0
                },
                {
                    "sent": "And I just like to go through some of the.",
                    "label": 0
                },
                {
                    "sent": "How the higher representation extends to hypergraphs and give you a few experimental results.",
                    "label": 0
                },
                {
                    "sent": "So I think I said this earlier hypergraphs requiring interest as a means of representing patterns involving higher order relations.",
                    "label": 1
                },
                {
                    "sent": "They found a compact means of characterizing hypergraph if we're going to do this, we can require a compact means of characterizing hyper graphs that can be used in pattern recognition.",
                    "label": 1
                },
                {
                    "sent": "So how we can do clustering, classification or compute similarity measures?",
                    "label": 0
                },
                {
                    "sent": "And really, it's I think it's fair to say that there's no clearly accepted way of do.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This at the moment.",
                    "label": 0
                },
                {
                    "sent": "So I've listed here a number of previous attempts in the literature do this.",
                    "label": 0
                },
                {
                    "sent": "I'm sort of rich or don't.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Times I won't touch on that, but one of the approaches is to is to try to extend the concept of a Laplacian from the graph domain to the hypergraph domain.",
                    "label": 1
                },
                {
                    "sent": "And here there are a number of alternatives, for instance, due in ICML 2005 proposed.",
                    "label": 0
                },
                {
                    "sent": "This version we have a somewhat different version which pen Rang and I reported in SPR 2008.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You compute these two different.",
                    "label": 0
                },
                {
                    "sent": "Representations for here a graph and hear a hypergraph connecting the same set of three nodes.",
                    "label": 0
                },
                {
                    "sent": "It turns out that there's no way in which you can distinguish on the basis of those laplacian's the difference between hyper graph and graph, and so it doesn't probe the relation relational structure of the points in a way which will give.",
                    "label": 0
                },
                {
                    "sent": "You will distinguish the.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Different possibilities so.",
                    "label": 0
                },
                {
                    "sent": "The past few matrix only records adjacency relationships between pairs of nodes and the GLEX cardinality's of the hyperedges.",
                    "label": 1
                },
                {
                    "sent": "This results in information laceration orders of varying degree or present so possible solution to this.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is to try to see whether we can use the O'Hara representation to overcome the problem.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so I mean, I won't go through the details of this, but in this paper in the previous paper we report how to extend the higher representation from graphs to hypergraphs.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What I can do is I can show you this in pictures, so we start with with a hypergraph.",
                    "label": 0
                },
                {
                    "sent": "We convert that into a bipartite.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Graph.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then we compute the clique graph.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For the bipartite.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Graph and then we computed.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right click graph.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then that finally we compute an orientated line graph for the diklic graph.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we get the same sort of representation that I had earlier in terms of characteristic polynomials whose coefficients are now related to the symmetric polynomials of a spectrum of the transition matrix for the orientated line graph.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's have a little look about what this means in terms of that simple example that I showed you earlier, where the two different versions of the Laplacian were not able to distinguish the situations of having a graph and hypergraph connecting the three different nodes here as other steps of the construction that I showed you on the previous slides applied to this, and so here we have the digraphs and the orientated line graphs for the two different situations.",
                    "label": 0
                },
                {
                    "sent": "And what you notice is that for the first, for the first, for the graph, I get this situation in G where the relationships between the two sets of edges are represented.",
                    "label": 0
                },
                {
                    "sent": "And then in this case here for the hypergraph I got a completely different representation of the arrangement of of nodes.",
                    "label": 0
                },
                {
                    "sent": "So that means that I can I can.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Distinguish between those those two situations.",
                    "label": 0
                },
                {
                    "sent": "Of the three, the three different edges being connected by graph or the three different nodes being involved in a hyper graph.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so I mean that one of the issues which arises in this is that you have to be able to efficiently compute the numerical coefficients.",
                    "label": 0
                },
                {
                    "sent": "One things we address in this work is how to do that, but I won't.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Into details, so we've applied this to some of the familiar datasets that we've used previously, particularly modellhaus image sequences.",
                    "label": 1
                },
                {
                    "sent": "And the whole datasets and what we've done is we have constructed a hyper graph where the hyper edges indicate two sets of relationships.",
                    "label": 0
                },
                {
                    "sent": "The first is our proximity relationships.",
                    "label": 0
                },
                {
                    "sent": "That is, so points have to be closer than a particular threshold, and Secondly we've encoded intensity.",
                    "label": 0
                },
                {
                    "sent": "Information, that is to say, the intensity information around a feature point as difference between two points has to be less than a threshold as well, so I won't go into that.",
                    "label": 1
                },
                {
                    "sent": "There are details in the paper we applied this to the three model House and the data set and images from the cloud.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Data set, so there's some examples of the images.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so for the house.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Dataset what we've done here is that we've compared compared the plus in Spectra.",
                    "label": 0
                },
                {
                    "sent": "The passing methods of issue and also paying random myself with the higher coefficients and these distance Maps show the Euclidean distances between the hara coefficients for the hyper graphs, and we're getting here.",
                    "label": 0
                },
                {
                    "sent": "Fred is strong distinction.",
                    "label": 0
                },
                {
                    "sent": "Differentiation between the three different.",
                    "label": 0
                },
                {
                    "sent": "Three different house datasets in the high.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Coefficients, so if we didn't try to cluster that data based on the coefficient vectors, then we have from left right.",
                    "label": 0
                },
                {
                    "sent": "The normalized Laplacian hypergraph Laplacian spectrum, the Laplacian spectrum and the higher coefficients.",
                    "label": 0
                },
                {
                    "sent": "And you can see that in the case of the higher coefficients were getting better separation in the subspace that I've.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "Here's here's the results for.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Oil and.",
                    "label": 0
                },
                {
                    "sent": "What I've done here is I've plotted the coefficient data at the top.",
                    "label": 0
                },
                {
                    "sent": "So here we have the coefficient data from the zoo, Laplacian, Penguins, normalized Laplacian, and the higher coefficients.",
                    "label": 0
                },
                {
                    "sent": "So in the case of shoes Laplacian, the coefficient data is heavily overlapped with slightly less overlapped.",
                    "label": 0
                },
                {
                    "sent": "In the case of Penguins normalized Laplacian but the overlap is smallest when we would use the higher coefficients and then here we've done PCA.",
                    "label": 0
                },
                {
                    "sent": "On the coefficient vectors him and protect him down to 3 dimensional subspace and you again you see overlap severe overlap in the case of Jews Laplacian they overlap but of a lesser magnitude.",
                    "label": 0
                },
                {
                    "sent": "In the case of Penguins at the place in Spectra and really quite clean separation when we use the hara coefficients of vectors of a higher coefficients for hypergraphs and then sort of a more quantitative analysis of the results.",
                    "label": 0
                },
                {
                    "sent": "Underneath, in terms of the Rand index, so larger the Rand index here, the better the classification, and so the best results are always given by the higher coefficients in the bottom line.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So just to conclude what I've done is, I've shown that a higher coefficients provide a flexible tool for both characterizing pairwise structures and higher order structures higher, higher coefficients capable of distinguishing structures were saying why pairwise connectivity with different relational orders, and I've shown efficient means of computing them for hypergraphs.",
                    "label": 1
                },
                {
                    "sent": "So thank you very much indeed.",
                    "label": 0
                },
                {
                    "sent": "Any questions?",
                    "label": 0
                },
                {
                    "sent": "I think the question that comes clearly to mind is, without the equivalence classes of the different characterizing polynomial coefficients, right, so?",
                    "label": 0
                },
                {
                    "sent": "Efficient with other graphs that give the same coefficients, right?",
                    "label": 0
                },
                {
                    "sent": "I mean at the moment we were investigating that I mean the issue is really raised here.",
                    "label": 0
                },
                {
                    "sent": "If I go back to some of the points of contact.",
                    "label": 0
                },
                {
                    "sent": "In this previous work that we did.",
                    "label": 0
                },
                {
                    "sent": "On using the support matrix of a discrete quantum walk on a graph, we showed empirically, we didn't really have.",
                    "label": 0
                },
                {
                    "sent": "We didn't have any theoretical results.",
                    "label": 0
                },
                {
                    "sent": "Moral intuition that this representation lifts the Co spectrality of families are strongly regular graphs and also reduces the Co spectrality of trees.",
                    "label": 0
                },
                {
                    "sent": "The matrix that we use is constructed in the same way and.",
                    "label": 0
                },
                {
                    "sent": "But in the in the case of discrete quantum walk, what we do is we take the positive support of the third power of that matrix and.",
                    "label": 0
                },
                {
                    "sent": "What that means is that the discrete quantum walk gets a chance to interfere because by taking the third power, we're taking three steps, and so the walk and go out and then return back to the same node again.",
                    "label": 0
                },
                {
                    "sent": "And in the case of a quantum walk you have a amplitudes which could interfere on the graph so that that seems to suggest that this representation is somehow sort of detecting.",
                    "label": 0
                },
                {
                    "sent": "Symmetries that exist locally in the graph.",
                    "label": 0
                },
                {
                    "sent": "The representation used in the higher coefficients is the same, but we don't take the third power.",
                    "label": 0
                },
                {
                    "sent": "We don't take the positive support, and So what we're doing at the moment is we're investigating the relationship between these two representations, and although I can't answer your question Now, I might be able to answer it in three months time.",
                    "label": 0
                },
                {
                    "sent": "Sorry for that tease.",
                    "label": 0
                },
                {
                    "sent": "What happens if I?",
                    "label": 0
                },
                {
                    "sent": "If you go to the space in which you have the graph represented in terms of those various properties, what happens if you subject the graph to slide perturbation?",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "We we represented in terms of slight deviations in the representation or.",
                    "label": 0
                },
                {
                    "sent": "We are not assured of that.",
                    "label": 0
                },
                {
                    "sent": "I think I think I've shown it here empirically.",
                    "label": 0
                },
                {
                    "sent": "I mean this.",
                    "label": 0
                },
                {
                    "sent": "So this is these graphs with sort of added and deleted nodes and edges, and so these.",
                    "label": 0
                },
                {
                    "sent": "I mean I think we sort of go typically up to 5% node and edge noise.",
                    "label": 0
                },
                {
                    "sent": "What did you do to change the graphs?",
                    "label": 0
                },
                {
                    "sent": "We modify the edge structure and we remove nodes.",
                    "label": 0
                },
                {
                    "sent": "So fresh.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I mean I think the basically what we're doing is we were modifying the graphs up to a certain edit distance, allowing all modifications of graph up to a certain distance both in terms of node and edge modifications.",
                    "label": 0
                },
                {
                    "sent": "Replacement property.",
                    "label": 0
                },
                {
                    "sent": "The red labels and then the.",
                    "label": 0
                },
                {
                    "sent": "I don't think they were replacements in the experiments, so we were dropping or adding nodes of a particular.",
                    "label": 0
                },
                {
                    "sent": "Towards the original structure.",
                    "label": 0
                },
                {
                    "sent": "So I mean that what this represents is the perturbations you get under those.",
                    "label": 0
                },
                {
                    "sent": "Those kind of edit operations.",
                    "label": 0
                },
                {
                    "sent": "And the question is, if you have a graph in which.",
                    "label": 0
                },
                {
                    "sent": "The noise is added as follows.",
                    "label": 0
                },
                {
                    "sent": "I have two classes of graphs that is hardly any noise.",
                    "label": 0
                },
                {
                    "sent": "They are pretty solid, compact.",
                    "label": 0
                },
                {
                    "sent": "Glasses.",
                    "label": 0
                },
                {
                    "sent": "Locally.",
                    "label": 0
                },
                {
                    "sent": "It's considered Part 2 classes were sent in one in class.",
                    "label": 0
                },
                {
                    "sent": "Today I have brushed with her.",
                    "label": 0
                },
                {
                    "sent": "Which are identical in structure.",
                    "label": 0
                },
                {
                    "sent": "Let's just to make it simple, but their property, the sliding window, meaning the node properties like right?",
                    "label": 0
                },
                {
                    "sent": "Has still the same problem, same set, except now I have added locali subgraph.",
                    "label": 0
                },
                {
                    "sent": "The small subgraphs is localized right?",
                    "label": 0
                },
                {
                    "sent": "Yeah, but otherwise it's exactly the same.",
                    "label": 0
                },
                {
                    "sent": "Properties are following the same distribution or properties.",
                    "label": 0
                },
                {
                    "sent": "Only thing is very localized localized.",
                    "label": 0
                },
                {
                    "sent": "I mean in terms of the number of nodes and edges affected, right?",
                    "label": 0
                },
                {
                    "sent": "Rush.",
                    "label": 0
                },
                {
                    "sent": "I don't.",
                    "label": 0
                },
                {
                    "sent": "I don't know the answer that question.",
                    "label": 0
                },
                {
                    "sent": "I mean, it's just experiment.",
                    "label": 0
                },
                {
                    "sent": "I mean basically take a piece of structure and to add it on.",
                    "label": 0
                },
                {
                    "sent": "Or maybe swap it between two graphs and to see what happens.",
                    "label": 0
                },
                {
                    "sent": "I don't know the answer to question.",
                    "label": 0
                },
                {
                    "sent": "Do you believe that?",
                    "label": 0
                },
                {
                    "sent": "Must or will it be showing through?",
                    "label": 0
                },
                {
                    "sent": "And now I think you could answer the way which would show through.",
                    "label": 0
                },
                {
                    "sent": "So for instance, if I take that structure.",
                    "label": 0
                },
                {
                    "sent": "And I connect it to the original structure with a just a single bridging edge.",
                    "label": 0
                },
                {
                    "sent": "It will have a big impact on the spectral gap and so that will perturb the coefficients in a very systematic way.",
                    "label": 0
                },
                {
                    "sent": "Using.",
                    "label": 0
                },
                {
                    "sent": "Adoption.",
                    "label": 0
                },
                {
                    "sent": "Do some sort of numbers problem.",
                    "label": 0
                },
                {
                    "sent": "If you design A graph with a particular.",
                    "label": 0
                },
                {
                    "sent": "Polynomial.",
                    "label": 0
                },
                {
                    "sent": "That's hard, and I mean somebody who knows quite a lot about it is sitting behind you the.",
                    "label": 0
                },
                {
                    "sent": "A problem is this that if you these coefficients are determined by the spectrum.",
                    "label": 0
                },
                {
                    "sent": "To compute the original Laplacian or adjacency matrix, what you do is you take the spectrum pre and post multiply it by the eigenvector matrix and the transpose.",
                    "label": 0
                },
                {
                    "sent": "Now though these coefficients you could you could use them, you could set generated coefficients.",
                    "label": 0
                },
                {
                    "sent": "You could in principle that's going to be quite hard solve the set of symmetric polynomials for the eigenvalues.",
                    "label": 0
                },
                {
                    "sent": "That's going to be have lots of ambiguities in it because you're solving a mixed set of equations which go from.",
                    "label": 0
                },
                {
                    "sent": "Sum to a product of eigenvalues.",
                    "label": 0
                },
                {
                    "sent": "Even if you could actually recover the eigenvalues from a solving the set of symmetric polynomials.",
                    "label": 0
                },
                {
                    "sent": "You would then have to worry about how to generate the eigenvectors.",
                    "label": 0
                },
                {
                    "sent": "And so there are counting ways of doing it.",
                    "label": 0
                },
                {
                    "sent": "And as I say, someone who knows something about that is sitting directly behind you and.",
                    "label": 0
                },
                {
                    "sent": "What you suggested is in the form you stated it not really tractable.",
                    "label": 0
                }
            ]
        }
    }
}