{
    "id": "xsadp6xqk74a2h6yv7nud3h2shgcudd7",
    "title": "Populating the Semantic Web by Macro-Reading Internet Text",
    "info": {
        "author": [
            "Tom Mitchell, Machine Learning Department, School of Computer Science, Carnegie Mellon University"
        ],
        "published": "Nov. 24, 2009",
        "recorded": "October 2009",
        "category": [
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/iswc09_mitchell_ptsw/",
    "segmentation": [
        [
            "Carnegie Mellon University and it has numerous other achievements which can all be found in the book rather than kind of reading them down.",
            "And we're counting in two years and not being quite the astute.",
            "Introductions I will rather try to recount a episodes from last year, so some of you may know.",
            "At last year I was actually visiting Tom on my sabbatical, and I recall one specific evening that was very, very insightful for me in the following way.",
            "We were both stealing time out of our busy schedules and Tom schedule being much busier because I'm three and a half 1000 miles away from my apartment.",
            "To look at some data we had done some data collection of some Max cancer brain scans and we stole it sometime and we sat down at like 8:00 o'clock in the evening and we just waited through these data as you have to think 4 gigabytes worth of brain waves.",
            "Kind of going at us.",
            "And after a few hours.",
            "I wouldn't say we're running out with the Eureka feeling, but I was reminded of 1 very important insights that computer science, even though we see us as a science that mostly builds abstractions and models.",
            "Actually, at the end of the day, is an empirical science as well.",
            "We have a lot of data and we should study that data.",
            "It's out there and we should sometimes take that inside from biologists and others.",
            "I think told myself that eventually somebody who's done this very well over.",
            "Uber is very interesting.",
            "Datasets being brain waves around us, but today he will talk about one specific datasets that you look set which is called the World Wide Web on.",
            "Thanks Harvey and everybody for getting up early.",
            "For the talk.",
            "Let's see I guess I should start with a slight disclaimer.",
            "I'm probably.",
            "Lucky if I'm above the 10th percentile in this room in terms of sophistication about the current state of the semantic web, so my apologies an I'm fessing up to that right up front so that you can interpret my words as those of somewhat.",
            "Under informed person about some of the latest advances in the semantic web, but I'm very, very glad to be here, and I learned a lot yesterday.",
            "About um some of the datasets you all are working with and it really has changed my.",
            "Own impression about what our own research should be focusing on.",
            "So I think going forward, one effect of this meeting on me is that we're going to be relying a lot more on some of the large coupled databases that you're building DB, PDN and so forth.",
            "But as the title here on my slide says, what I want to talk about is a question that I think is kind of central to this community.",
            "How will we really populate the semantic web on a very large?",
            "Scale and."
        ],
        [
            "Again, as an outsider, which sometimes is a virtue 'cause you can just kind of see from 50,000 feet, it seems to me there are only three potential answers to this.",
            "You may have others, but one of them is that will get humans to enter this structured information, and indeed, Wikipedia and the structure and information boxes to go along with that.",
            "Is one kind of evidence that supports the assertion that humans may indeed enter this kind of information.",
            "A second answer could be, well, there's a lot of structured information around in the world.",
            "For example, the US Census Department in Census Department's in many countries, have structured data, and some of those are willing to publish that data.",
            "Here's another route.",
            "Excuse me, it doesn't involve typing in additional information, it involves releasing to the world existing databases.",
            "A third possibility, and in fact the one that I'm most interested in and what we're going to spend the next 40 minutes on is that computers might at some point be able to read unstructured web data.",
            "In some sense of read and help us populate that structured data themselves.",
            "So for the next 40 minutes what I want to do is tell you about a project that we started a while ago, a year and a half ago or two years ago.",
            "To explore this and it builds on research for many other groups.",
            "For example, I heard yesterday a very interesting talk from the IBM folks.",
            "On a similar kind of effort that they're working on, so there are a number of efforts of this type.",
            "But so the question, I want you all to help me think about for the next 40 minutes is.",
            "What's the feasibility and what is what are the prospects of getting computers to read unstructured web data?"
        ],
        [
            "I said that I wanted to tell you about a project we're doing.",
            "We immodestly, I guess.",
            "Call this project to read the web, and we have a problem specification that you can see here.",
            "We haven't solved this problem yet, but I will tell you the partial solution that we have.",
            "But our goal is to build a system where we input in ontology, not a populated database, but an ontology that defines the categories, the relations, and some of their meta properties.",
            "That we're interested in extracting.",
            "And we're willing to give a handful of examples of training examples of each item in that ontology.",
            "So, for example, if we're interested in an ontology that involves people in conferences and technical fields, then will give some examples of conferences and people in technical fields.",
            "And if we're interested in relations like which person attends which conference, will give some examples of that, will also give it the web, because that's a lot of.",
            "Data to read and perhaps occasional access to human trainer, but we're interested in kind of exploring the question of.",
            "To what degree can a computer system?",
            "Work on its own to extract this, and we're not so rigid as to say humans will never be able to help out, but we're interested in just exploring the end of the spectrum.",
            "That's more on the automated end.",
            "So then our goal, and we're not quite there, is to have a system that runs 24 hours a day, seven days a week in each day.",
            "It only has to do these two things.",
            "It has to extract more facts from the web to populate that.",
            "Initial ontology find more people in conferences and which ones are attending which.",
            "And it has to also each day learn to read better than it could the day before.",
            "And one way of checking that is if it goes back to the same web pages that it read yesterday, it should be able to extract more facts more accurately than it did yesterday, so we wanted each day to do these two things.",
            "Wanted to extract more fancy, but we also wanted to get to read better.",
            "We figure if we could do that 24 hours a day forever, then we'd have a very interesting system in a year or so.",
            "So there's the problem specification and I should can see it's a rather kind of ambitious.",
            "And not yet achieved.",
            "And of course one of the problem."
        ],
        [
            "Is that?",
            "Without problem specification, it seems is that natural language understanding is already an impossible problem.",
            "In yesterday's paper, for example, you could pick up an article where the first sentence.",
            "It is really hard for a computer to interpret launch of NASA Ames is 1X rocket on a plan 445 million dollar test flight was delayed 24 hours Tuesday because of bad weather and an errant freighter that briefly strayed into the offshore danger area.",
            "So there's an example of a sentence that's I would say it's kind of out there in terms beyond the state of the art in terms of what current natural language understanding programs can do.",
            "But despite the fact that natural language understanding is far from being solved.",
            "It seems to me and this is one of the things I want to convince you in this talk.",
            "It seems to me that the prospects for having computers doing some form of reading.",
            "Very soon to help populate the semantic web.",
            "The prospects for that I think are very good and the reason is that I think there are ways of making miss."
        ],
        [
            "Been reading much more plausable.",
            "So one way is to leverage redundancy on the web if we want to know where NASA launches rockets from.",
            "We don't necessarily have to interpret that sentence that I just read to you.",
            "I'm sure that if you search over the web, there will be thousands, maybe hundreds of thousands of individual in dependently written assertions that tell you where NASA launches rockets from.",
            "There might even be 1.",
            "One of those will maybe be as simple as saying NASA launches rockets from where is it, Cape Canaveral?",
            "In Florida um?",
            "So by the redundancy of fat statements we can cherrypick we don't have to understand every sentence on the web.",
            "We just have to find.",
            "That there exists a sentence which is simple enough to understand that contains the fact we're interested in.",
            "Another thing is that we can target are reading too populated given ontology really one of the reasons that natural language understanding is so darn hard is that people can say pretty much anything in language.",
            "But if we have a predefined ontology, that means that probably most of the stuff in most sentences is not particularly relevant to that ontology, and we can restrict our focus of attention and as we'll see.",
            "Very importantly, it also turns out that having an ontology in advance makes the machine learning problem of learning to read significantly easier, and we'll see that in a second.",
            "Another thing we'll see is that we're going to use some new.",
            "Semi supervised learning algorithms that coupled the training of many.",
            "Extraction functions and.",
            "As I saw very dramatically yesterday in the IBM talk, we could also make the problem easier by leveraging the many, many facts, even though they're not 100% correct.",
            "They're pretty much correct that many, many fats in the growing semantic web.",
            "So these are the reasons that I have optimism, despite the fact that I'm a realist and understand it.",
            "It's going to be many years before we have computer programs that can understand arbitrary sentence is it seems to me that because of these things, we're going to be able to sooner have programs that can at least understand enough of the web to be useful to help us populate the semantic web.",
            "OK, so I mentioned that we."
        ],
        [
            "I have not achieved this goal, but what I do want to talk about today is a system that.",
            "As this slide says begins, we do give it an initial ontology.",
            "We do give it 10 to 20 seed examples of every predicate.",
            "Category relation in an ontology.",
            "And we give it a couple 100 million web pages which we process on a cluster generously provided by Yahoo.",
            "The M45 cluster.",
            "And the result is that it extracts a knowledge base with.",
            "10 to 100,000 triples with reasonable accuracy, where reasonable means 85 to 95% accuracy.",
            "So let me before I get into that."
        ],
        [
            "Details of that let me show you what I mean, so I'll show you the initial ontology that we give to the system."
        ],
        [
            "This looks like a very dangerous step.",
            "OK, so here when I say we provide an initial ontology, I mean that we define a set of relations like these.",
            "We define some of those we want to populate, and so we provide seed instances.",
            "So you see here the seed instances for CEO of.",
            "Here are some examples of CEOs and their corresponding companies were team coaches and which companies acquired which in which athlete is coached by which coach and which athlete plays in which stadium, and so forth.",
            "So here are the kinds of things that are in the initial input to the system.",
            "And the system is very generic.",
            "It doesn't care.",
            "It doesn't, it's not tuned around any particular ontology.",
            "You give it the ontology of your choice.",
            "But of course you must provide examples like this of both relations and the categories.",
            "So for example, if we wanted to learn about awards trophies in tournaments, we have to give some examples of those were board games or conferences.",
            "Or economic sectors or emotions and so forth.",
            "OK, so that's the input to the system.",
            "And.",
            "After it has run for a number of days on this M45 cluster."
        ],
        [
            "It produces the knowledge base that we can also browse."
        ],
        [
            "By the way, all of this is open source stuff, so we're putting this all on the web.",
            "These are all in XML format.",
            "We're working on converting to RDF.",
            "And what we're looking at here is literally the XML data with a stylesheet through a stylesheet.",
            "But now, for example, if we.",
            "Look at the.",
            "Knowledge base produced by the system it's based on that same ontology, but now it has many more instances populated.",
            "So for example for academic field.",
            "The seed examples where these first ones up to theater arts and now it has added on its own.",
            "By reading those 200 million web pages, a number of other things which it believes are also academic fields, and I'll just Scroll down here you can.",
            "See that it's not perfect, but it's pretty good actually.",
            "So you get the idea, and here are some of the awards and trophies since then.",
            "So it it it learns these things here some of the board games.",
            "OK, so you get the idea.",
            "And for each one of these things it has created a entity with its own collection of triples, lunoe, for example, it believes is the board game.",
            "It doesn't have any other triple associated with, you know.",
            "But if we look for some.",
            "Some of the ones that I know.",
            "That I know do.",
            "For example, for sports teams that tends to.",
            "No affair amount.",
            "So for example, the Indians are a.",
            "Sports team, which it believes plays baseball.",
            "You can see that it has other candidate values that it was considering, but it's not using those it believes they play baseball.",
            "It has source information for each of these candidate triples that it is.",
            "Considering you can see here some of the patterns.",
            "About that that it has used to extract some of these things and if we just kind of Scroll down here, most of this stuff that we're looking at now is the justification for that belief that we saw.",
            "But let me Scroll down to where there's something else.",
            "So for example, here are team members.",
            "It believes play on the loops.",
            "It believes play on the Indians so.",
            "We can look at some of those, like Josh Barr is an athlete who police plays for the Padres.",
            "Although the Indians were also a candidate, Cleveland was the candidate.",
            "And it believes he plays baseball, by the way, the reason it believes he plays baseball is from this horn clause rule, which it data mined out of the database itself.",
            "So that gives you a little glimpse of the kind of.",
            "Knowledge base that comes out of a very small amount of starting in."
        ],
        [
            "Nation, so in essentially an ontology that defines categories in relations, a dozen or so examples of each, and then a lot of processing on a lot of web data with some machine learning algorithms.",
            "So what I want to do is is take you through that algorithm, and in particular the design choices that we had to make to improve over its original lousy accuracy to get to the level that we have.",
            "Today so the very first."
        ],
        [
            "Thing is, on the very first design choice is.",
            "That we ended up using a new kind of semi supervised learning algorithm that couples the training of many, many different extractors for many many different categories in relations.",
            "So when I talk about semi supervised."
        ],
        [
            "Learning many of you are familiar with a kind of bootstrapping process that's pretty common.",
            "For example, many people use an algorithm like this.",
            "Suppose I want to learn to extract cities, and I start with a handful of cities like Paris and Seattle, and so forth.",
            "Then I can search for occurrences of those cities in my text, find the linguistic context in which they occur.",
            "Perhaps mayor of X or live in X occurs a lot with these things.",
            "And then having found those I can go back now and search my text data again for additional occurrences of mayor of and live in.",
            "And this will allow me to extract some more noun phrases that become candidate cities.",
            "So San Francisco Austin.",
            "I know some people who live in denial.",
            "And we get other noun phrases.",
            "Then we can again iterate this loop and we might find additional patterns, some of which.",
            "Are influenced by this one erroneous example and the problem is this a very nice idea.",
            "This kind of iterative bootstrapping, but in truth it doesn't work very well if you do it like this.",
            "It works great for the first iteration or two and then it kind of runs off the rails.",
            "Because words like denial creep into your cities and then it doesn't take very long after that for other excludes other extraction patterns that you don't want to show up.",
            "And then it diverges and you get very inaccurate categories eventually.",
            "So we like this idea, but it's fundamentally an under constrained machine learning problem.",
            "We have very little only in this case for training examples, and there's just not enough to specify really the category we're interested in."
        ],
        [
            "So our way around that and this was actually I think the single most important design choice we made.",
            "In terms of learning algorithm.",
            "Is at some point we realized the problem.",
            "We just looked at in the previous slide is a very hard learning problem.",
            "Hard in the sense that it's under constrained.",
            "If you're trying to learn a single classifier for a noun, phrases like whether it's a city or whether it's a coach.",
            "You don't have much of a constraint.",
            "On the other hand, if you.",
            "One an easier learning problem you should make and apparently more complex.",
            "Task and instead of asking the system to learn this one classifier of noun phrases according to whether a city or not, you should force it to simultaneously learn in a coupled way.",
            "Classifiers for many many different ontology categories and relations, and that's actually."
        ],
        [
            "Need the key because now.",
            "Every.",
            "Unlabeled example, and that's mostly what we have in those 200 million web pages.",
            "Is unlabeled noun phrases.",
            "Every unlabeled example becomes a constraint.",
            "Even though we don't know its label.",
            "Becomes a constraint on the joint choice of parameters for all these different classifiers that we're trying to learn.",
            "And just to illustrate, if I give this sentence.",
            "As an unlabeled example, and the system might not know whether this noun phrase represents a city or a coach or a team or a person or an athlete, or any of those things, and it might not know the same about Blue Devils, but it does know.",
            "Through our ontology that.",
            "A sport is mutually exclusive with the team and Furthermore, if team plays this, if we're going to assert through one classifier, the team plays the sport.",
            "Our team classifier has to agree it's a team and our sport classifier has to agree that it's a sport."
        ],
        [
            "So there are all these nested Inter coupling constraints and each unlabeled example therefore.",
            "Can be viewed as a constraint because there only some joint assignments to all these predicates that make sense, and some joint assignments don't make sense.",
            "You can't say.",
            "Krysinski coaches for.",
            "The Devils, but the but Krasinski is not a coach or the Devils is not a team.",
            "You have to get a consistent labeling.",
            "So.",
            "Armed with that intuition, we started getting a little more serious about what are the types of coupling functions that we can figure that we can see, and so one type is with some people called Co training.",
            "The idea here is if we're trying to learn some function, let's say to classify a noun phrase according to whether it's the city or not.",
            "In Co training what we can do is we could say well if our examples are these noun phrases embedded in sentences.",
            "One kind of coupling to make multiple functions that we can couple the training of is to.",
            "Instead of learning just one classifier will learn two will learn one classifier that uses just.",
            "The noun phrase will lose, will learn one that learns.",
            "To classify just the.",
            "Weather Pittsburgh is a city according to weather.",
            "Those green words to what those green words are.",
            "So if you see Luke as mayor of and you don't know what the noun phrases, it's probably a city.",
            "And by setting it up as learning these two.",
            "Somewhat different functions.",
            "They have different inputs.",
            "Now we can.",
            "Now we have again with the condition we want.",
            "We have a situation where we have in this case two functions.",
            "We're trying to learn.",
            "If somebody gives us an unlabeled example like the sentence here, the system doesn't know whether Pittsburgh is a city or not, but it knows that the green classifier has to give the same answer as the red classifier.",
            "So if if on this unlabeled example, the red classifier says yes, it's a city in the Greenland says no, then the learner knows it's gotta change something so.",
            "And that's really the name of the game in coupling the training of these classifiers."
        ],
        [
            "So once you see that then it's easy to kind of explode that idea.",
            "Well.",
            "I just showed you an ontology.",
            "They had a lot of different categories and in our ontology, their relations among the categories that are known.",
            "For example, a city is a kind of location.",
            "So if the city classifier says yes, the location classifier obviously has to say yes.",
            "It also knows that politicians are mutually exclusive from locations.",
            "You can't have a noun phrase that simultaneously referring to both.",
            "And so a second kind of coupling is to take functions with different outputs and constraints among those, and that's where the ontology comes in.",
            "Our ontology I didn't show you this part, but if we were to go back and browse the knowledge base again, you'd see that in our definition of politician it says the domain that it says that the.",
            "Category politician is mutually exclusive with location and a number of other categories in the ontology.",
            "So that information in the initial ontology provides just the kind of constraint that we need to couple the training of these classifiers so that we can squeeze more information out of the unlabeled data.",
            "And then the third."
        ],
        [
            "Type of coupling involves coupling the training of category extractors with relation extractors.",
            "So, for example, is shown here.",
            "If we have a relation like mayor of and now we have to learn a classifier where the input is not a single noun phrase but a pair of noun phrases in sum.",
            "Sentence like Luke in Petsburgh there.",
            "But that classifier for mayor of can only say yes.",
            "Noun phrase one is a mayor of noun phrase two if the city classifier and the politician classifier give compatible.",
            "Outputs.",
            "And again, the ontology provides the information we need in terms of domain and range of that relation in the data types of those.",
            "And that's information we assert in our initial ontology."
        ],
        [
            "So, given those kinds of coupling, you can think of a lot of algorithms.",
            "Here's one of the early algorithms that we developed, and it works pretty well.",
            "Since then we were working on number of more probabilistic Lee grounded algorithms, but here's an algorithm that works well in that produce knowledge basis that you can browse on line like the one that I showed you.",
            "And so the input is an ontology in a text corpus, and the very first step of the algorithm is to share the instances.",
            "So when I said we provided a dozen training examples for each of those categories.",
            "Well, we provided a dozen politicians and it doesn't cities.",
            "But since the system knows that cities and politicians are mutually exclusive, it can now take all of our city examples and assert those as negative examples of politicians.",
            "And similarly for the other constraints.",
            "So the first thing it does is use that ontology information to assign positive and negative examples to all the categories and.",
            "Then it does that kind of bootstrapping thing that we saw that we illustrated with just the city category at 1st and complained about.",
            "But it does that kind of bootstrapping where now it takes those seed examples, finds patterns in the text in those 200 million web pages.",
            "That fit those examples.",
            "It does this simultaneously for every predicate in the ontology.",
            "In the ontology I showed you there probably on the order of 100 or 150 predicates now.",
            "Then it filters these by looking at the evidence.",
            "It doesn't take every.",
            "Context in which every noun phrase occurs in those 200 million pages.",
            "It looks at some statistics.",
            "For example, it will only approve.",
            "Appear like CBC in Toronto, being an instance of headquartered in if that matches.",
            "Multiple.",
            "Text patterns, if it matches just one of the tips patterns associated with headquartered in that's not strong enough evidence, so it's fairly conservative and filtering out things that are.",
            "Don't have overwhelming evidence.",
            "Then it trains a classifier of the noun phrases using these extraction patterns that it has found.",
            "Well, we'll see some of those patterns in this setting.",
            "Then it selects the most.",
            "Confident new.",
            "Previously unlabeled noun phrases to promote them as things that will also believe.",
            "Our cities in politicians and instances of the relation, mayor of and so forth.",
            "And then it takes those promoted instances and shares those using the mutually exclusive and subset superset relation in the ontology so that a new city that it just promoted also gets propagated to become a new positive example for location.",
            "And a new negative example for politician.",
            "And so forth.",
            "So now you see the coupling coming in and you also see that there's an interesting scaling property of virtuous scaling property the more.",
            "The larger we make the ontology and the more coupling constraints we make.",
            "The more propagation of positive and negative examples there are among these different categories, we're trying to learn and therefore the better the tray."
        ],
        [
            "King will be.",
            "So when this process is done.",
            "The system has a collection of learned extraction patterns and candidate noun phrases.",
            "For all of the categories that we asked it to learn about.",
            "So for example here the top learned extraction patterns that found for company.",
            "And you can see you know they're pretty reasonable.",
            "And now just to sort of be clear.",
            "Given a new noun phrase like.",
            "Marriott if it wants to know whether Marriott is a company or not the way it decides is, it looks through the 200 million web pages for every occurrence of Marriott.",
            "That matches any of these patterns.",
            "It gathers the statistics.",
            "How often does Marriott Co occur with each one of those patterns and then that gives it a feature vector.",
            "The number of times this noun phrase Co occurs with each one of those patterns, and then it applies a naive Bayes classifier which it trained during that bootstrapping procedure to that vector of Co occurrence statistics with these patterns.",
            "So it's in a sense is not reading individual documents.",
            "Instead it's macro reading the 200 million web pages, so it doesn't make decision about whether Mary it's a company or not by looking at an individual sentence.",
            "Instead, it makes a decision about whether Mary it's a company by looking at the statistical properties of the token Marriott across these two 100 million web pages, where the features is looking for our.",
            "This set of learned extraction patterns and so that gives it a.",
            "Much more broad and safe set of information to base its decision on about whether Mary it's a company than if it had to read individual sentences.",
            "And that's important, so it kind of comes back for first.",
            "Theme about, well, natural language understanding is way too hard.",
            "How can we use?",
            "Some form of machine reading to help us populate the semantic web.",
            "I think the answer in the short term is we want to do this kind of macro reading of many documents simultaneously instead of trying to micro read individual sentences.",
            "It's going to be a decade or so before that problem gets off.",
            "But then."
        ],
        [
            "And then for example, here are the patterns for play sport and again you see that kind of makes sense.",
            "My favorite one, by the way, is this one here.",
            "Someday I want to be referred to as the Tiger Woods of something.",
            "It all."
        ],
        [
            "So automatically extracts a number of other things that here's just to give you an example."
        ],
        [
            "We saw this when we're browsing the knowledge base, but there was a lot of jumbled justification information in that knowledge base that we were browsing, so it's kind of hard to see.",
            "But here, for example, is what it extracted about IBM, which was not one of its seed examples.",
            "So in black you see the things that re ified that that it puts into the knowledge bases.",
            "Triples, it's going to believe, so it believes IBM is a company headquartered in Armonk.",
            "Produces PC acquired these things.",
            "It was acquired by Lenovo Group.",
            "It's not perfect.",
            "Competes with these things, etc.",
            "But you also see in blue the stuff is just below the tip of the iceberg, so these are the candidate noun phrases that had some but not overwhelming evidence, and so they weren't promoted.",
            "But you can see that looking at these, you know IBM might have been a product, might have been a company might have been a conference that decided it was a company.",
            "They produce a PC.",
            "It might have produced the ThinkPad Line, but there wasn't enough evidence for that and so forth.",
            "But if you look at these candidates, one thing that becomes clear is you know some of them are correct.",
            "Some of them are not correct, but they would be great lists to give to people who wanted to spend some time helping out building knowledge bases.",
            "So even the less confident extractions might be useful to us in some man machine.",
            "HCI kind of loop."
        ],
        [
            "OK, so there that's really the main idea and now I want to take a couple of minutes to talk about how to amplify that idea.",
            "So again, the idea is.",
            "We can actually do a remarkably good job of semi supervised training of many classifiers simultaneously, even though it's really hard to train just one classifier.",
            "With little labeled data.",
            "And it's because of the coupling constraints that we get when we try to do many of them together.",
            "So armed with that idea.",
            "You can say, well, how can we increase the coupling even further?",
            "How could we add even more functions to learn that will synergise and give us even stronger accuracy?",
            "And one way to do that is to train classifiers that instead of looking at the sentence kind of text, look at HTML structure.",
            "Well, it turns out there is a PhD student at Carnegie Mellon.",
            "Richard Wang working with."
        ],
        [
            "William Cohen, who is just finishing up a thesis doing exactly that.",
            "So we tapped into Richard's work.",
            "He's built a system.",
            "His thesis system is very nice.",
            "You give it some noun phrases and it goes and finds essentially webpages where multiple of those noun phrases appear.",
            "And then it learns a wrapper for those noun phrases.",
            "And then based on that wrapper looks on that same page for additional noun phrases that are surrounded by similar HTML structure.",
            "A good.",
            "Case of a web page where this works well.",
            "For example as if there is a web page somewhere that has a list of different kinds of cars.",
            "And if you find Toyota, Nissan and Ford in a list, probably the other things in the list are also cars.",
            "So it does that and it also learns many other kinds of HTML layout structure.",
            "But so for example here."
        ],
        [
            "There's one that says, you know on this particular URL.",
            "If you find this string, then the thing that's in here is a car.",
            "And here are the things that were in fact extracted that way.",
            "Here's another in another.",
            "So The thing is Ceil Richards program.",
            "Does something try to do something like?",
            "Our couple Bootstrap learner was doing except he's using orthogonal set of features.",
            "He's using HTML structure whereas we were using sentence type text.",
            "So why don't we just put the two systems together?"
        ],
        [
            "In on every loop of our iterative bootstrapping procedure, instead of just running that coupled bootstrap learning process that we talked about a moment ago, let's also on the each loop run this seal program.",
            "And what examples will it work off of?",
            "Well, the same ones that are in the knowledge base that got promoted on the previous.",
            "Iteration through our loop.",
            "And then we'll just add an evidance integration module that looks at the proposals each iteration.",
            "What are the proposals from these two different programs about new instances of cars and cities and politicians and mayor of relations and so forth?",
            "And it will integrate that evidence to make a decision about how to update the ontology, how to further populate the knowledge base.",
            "So we did that and in fact."
        ],
        [
            "It works, it helps a lot to add this additional redundant kind of learner that's making errors independent of the errors that are being made by our learner, which is looking at text.",
            "And there are a lot of numbers on this page.",
            "Please don't look at them all but.",
            "The The Red column is the coupled system that's using both seal and the Cpl couple learning system, and if you just look at these different in this case categories that it was learning, in most cases you see that the couple learning.",
            "In the seal learning, once their combined we get much higher accuracies.",
            "You also see quite interesting Lee for a number of these categories we appear to get 100% accuracy.",
            "So for example they found 181 new academic fields.",
            "When we sampled 40 of those and gave them to Mechanical Turk to label all 40 of those were judged to be academic fields.",
            "So you can see here also something about the distribution of of accuracies in different categories.",
            "Many of them are really strong.",
            "Summer really bad product type for example, and sports equipment was also a real loser.",
            "So it's not perfect and it still can run off the tracks the way that bootstrapping procedure can, but.",
            "For example, one reason that sports equipment tends to run off the tracks is that.",
            "In a way, there are no categories in the ontology that are close to sports equipment.",
            "And so it's easy for it to kind of move out into other categories.",
            "So if you look at the final list of proposed sports equipment includes weird stuff like chairs and things like that that you wouldn't think of sports equipment.",
            "But I bet, and we found this actually by running the system many times on different ontologies that if you want to improve the performance of the system, what you should do is add some additional categories to the ontology that are.",
            "Kind of nearby.",
            "So for example, if you want to.",
            "Conferences you should add other kinds of meetings like sports games and.",
            "Dances and things like that to so that there will be semantic space taken up elsewhere in the ontology that will kind of keep this thing from expanding out to fill the void.",
            "Here's another glimpse of."
        ],
        [
            "What the system is doing.",
            "Hopefully you can't see any of the numbers on this slide, but what it shows is for each of those categories that it was learning how many new proposed noun phrases it promoted on each iteration.",
            "So this gives you some idea of the.",
            "The is the iterative bootstrapping process continues?",
            "What happens?",
            "You know, and you'll see here.",
            "Green means a large number in red means zero and intermediate colors mean intermediate numbers.",
            "I.",
            "And so you see, there are some categories like.",
            "Conferences is a good one where it started out.",
            "Here's conferences here were started out yellow, adding many categories up to about iteration 10.",
            "Then it added another four on iteration 13.",
            "Then it kind of zeroed out and never added anymore.",
            "So it kind of saturated what it could extract about conferences and then just didn't get anymore.",
            "In other cases you see really interesting, often on behavior like stadiums, sports stadiums, well stadiums in general start out with a lot then it died out, then it picked up again.",
            "Died out, picked up again, died out, picked up again.",
            "You see this kind of oscillatory behavior and we see that a fair amount.",
            "And if you actually dig into what's going on, it appears to be that it's this couple learning is having is creating this kind of oscillatory effect 'cause if it learns some new stadiums it might be able to use that to learn some other things like which team plays in which stadium and better rules, better extraction patterns for.",
            "Teams playing in stadiums.",
            "But then if it can extract more relations about teams playing in stadiums, you get some new candidate stadiums so you get this kind of 1 predicate being learned.",
            "Helping another predicate have better data to learn more.",
            "So anyway, this diagram shows a little bit of that ebb and flow."
        ],
        [
            "So the final thing.",
            "I want to tell you about is more recently we've.",
            "I notice that.",
            "Again, in the spirit of having our long-term goal of having a never ending learning process that each day gets better.",
            "You want to build it kind of system.",
            "Then you don't want it to just learn one type of knowledge.",
            "Like these extraction patterns.",
            "By six months from now it should have.",
            "If we were to be running.",
            "Continuously, which it isn't, and I'll just tell you it only runs for about a week and then we have systems issues right now.",
            "Some combination of running out of memory and Java crashing and also the system sometimes saturating.",
            "So like on conferences there just aren't anymore conferences it can find.",
            "So it's a combination of factors that currently keep it from running forever, but in the spirit of moving in that direction.",
            "We wanted to learn a variety of types of knowledge.",
            "And so one obvious thing to have it try to learn is."
        ],
        [
            "Our rules from that Huawei doesn't data mine, it's extracted knowledge base.",
            "So we wrote a rule learner.",
            "That goes through the knowledge base and for each relation in the ontology like team play Sport.",
            "It tries to learn 1st order probabilistic horn clauses.",
            "That are essentially rules that will predict the value of.",
            "The Play Sport relation for any given team.",
            "So the idea is once you have, you know 40,000 extracted relations.",
            "You have an interesting database, is not perfectly is not perfect, but still statistically there might be regularity's exhibited there that could be valuable to learn.",
            "So if you want to do that, if you want to build a program that will learn to predict the value of this relation from other properties of the team.",
            "Course you need positive and negative examples.",
            "The positive examples?",
            "Well, it's obvious where they come from.",
            "We have a knowledge base now that has read from the web certain assertions about which teams play which sports.",
            "The real question is where you get negative examples.",
            "The knowledge base doesn't store things of the form.",
            "You know.",
            "I'm not Lithuanian.",
            "We don't bother this.",
            "There are a lot of false things, so we don't bother to store them all.",
            "Also, it's not tuned to actually read them.",
            "So question where you get negative examples in this kind of extracting knowledge base is critical if you want to learn rules because you can't learn rules from just positive examples very well.",
            "And again, the ontology turns out to be a very important clue here.",
            "So one of the meta properties of relations that's in our ontology is how many values can this relation take on a team play sport can take only one value.",
            "Teams play only one sport.",
            "On the other hand, competes with can take on any number of values.",
            "Microsoft can compete with Yahoo and simultaneously compete with Google.",
            "So the importance of this is that if you think about it.",
            "The relations for which this is true.",
            "We can get negative examples once we know that the Yankees play baseball.",
            "We now know for all other sports that we've got in our knowledge base.",
            "the Yankees do not play that sport.",
            "And so that's one place we can get negative examples.",
            "And in fact, in this version of the rule learner, that's the only place we get negative examples, and so we only learn rules for relations for which number of values equals one.",
            "Let me show you some of the learn Drew."
        ],
        [
            "Rules here, here are some out of 49.",
            "Here are some of the good ones.",
            "So the way you read this is these are horn clauses with conditional probabilities.",
            "So this horn clause says this is true if the things over here are true and the conditional probability of the conclusion is .83.",
            "So this says athlete X plays in League Y.",
            "If athlete X plays for Team Z and teams plays in League, why?",
            "So that's reasonable, and this rule was learned from.",
            "In general, these numbers are the number of positive examples that the rule covers.",
            "The number of negative examples that the rule covers, and the number of other examples.",
            "To which the rule will apply if we allow it in an for which it will make a new prediction.",
            "So if you scan down here, you know it's kind of interesting.",
            "And these you know, if team plays against the Yankees, they're baseball team.",
            "If they won the Stanley Cup their hockey team.",
            "So these are the kinds of regularity's that are automatically discovered from that knowledge base once it starts getting extracted.",
            "Here's some of."
        ],
        [
            "Looser rules just to in the spirit of Full disclosure.",
            "And so it also learned that a team plays in the NBA if it plays basketball.",
            "Well, that's not true.",
            "College teams play basketball and they don't play in the NBA.",
            "It didn't know that.",
            "In fact, if you look over here, it is evidence.",
            "Interestingly, the extraction patterns and its macro reading strategy.",
            "Hit found many sports teams, including many college sports teams, and they're all there in the knowledge base, but for some reason the patterns that learn for learning for reading.",
            "Our team plays in League only.",
            "Worked well for professional sports teams.",
            "And so it just didn't succeed in extracting any assertions.",
            "Any triples about those college teams in what leagues they played in the NC AA or the Atlantic Coast Conference, or whatever?",
            "It didn't extract those by reading, and so its knowledge base was missed.",
            "With skewed in terms of the kinds of fats that I had and empirically, it is true that in that knowledge base.",
            "Things for which it had read that they play basketball.",
            "It had also read that they often that they play in the NBA, but you and I know the rule is wrong.",
            "So there are number of things like this.",
            "You know most of the States and provinces that read about are in the United States, so it assumed all States and provinces are in the United States of problem that some humans have.",
            "So anyway, if you look at all these rules, if you and I think this is a place where we do want human intervention because the damage that a bad rule can do is widespread, and the good that a good rule can do is great, and so if you manually filter these out you end up throwing away 15 of the 49 learned rules, then when you apply then you get over 1000 new Triples added to the knowledge base."
        ],
        [
            "So."
        ],
        [
            "There's the story.",
            "And.",
            "To conclude, I want to just kind of suggest a couple of directions that we would like to go and then wrap up.",
            "One is really would like to push on this rule learning and incorporated in the inner loop of the bootstrapping procedure.",
            "So what I just showed you was just the result of taking system they had run in their case, 35 iterations running the rule learning system.",
            "Once manually examining the rules, crossing out the bad ones and then letting them apply.",
            "And it added 1000 new assertions to the knowledge base.",
            "Almost all of which were correct.",
            "But in fact, why don't we put that rule learning in the middle loop of this bootstrapping process, so that on every iteration the rule learner can look for more regularity's and suggest new examples which then might actually allow reading of those assertions.",
            "We also are working on a couple new modules, for example one additional.",
            "We talked about using free text and also HTML structure is very different feature sets for deciding if something is the city.",
            "Another kind of features that you can use is the actual morphology of the noun phrase.",
            "The actual substructure in the noun phrase.",
            "So if you see a noun phrase with multiple words.",
            "That are capitalized.",
            "It's much more likely.",
            "It's much less likely to be.",
            "Food.",
            "It's more, it's more likely now to be a city or some kind of proper noun.",
            "Or if you see a noun phrase that ends with the three letters, SKI.",
            "It's probably a person name.",
            "So we have a student working on adding such modules.",
            "So One Direction I see is adding more and more.",
            "Helpful and.",
            "Components to the inner loop of this bootstrapping procedure and hopefully modules that make errors independent of the modules that are already there.",
            "'cause independent errors is going to lead to a virtuous cycle of better learning and better reading.",
            "And the other obvious."
        ],
        [
            "Thing today because I attended some talks yesterday and 'cause I'm here at this meeting is really my eyes were opened up yesterday and I went to bed last night.",
            "I think of you and I had talked about this at supper last night.",
            "I thought, why on Earth are we starting with just a dozen examples of these categories?",
            "We really should be tapping into the databases that are being created by this community and providing exporting back to them.",
            "Hun.",
            "Information that might be helpful.",
            "So let me end there so we have some a little bit of time for questions and."
        ],
        [
            "Just want to.",
            "Just wanted to come back to the question that was the title of the talk of how can we populate the Semantic Web and I think what I tried to convey here is that there first of all there really are multiple ways that the semantic web is going to get populated, but I think that.",
            "It seems to me realistic to to believe that in a short period of time, not a decade, but more on the order of a year, we should start to have systems and the IBM talk yesterday is another example of such a system.",
            "Some of the work at University of Washington and Text Runner is another example of the system, and there are other examples too, but within the next year I think we're going to see more and more of these systems that do this kind of macro reading of many documents simultaneously.",
            "And because of that can extract fear somewhat accurately.",
            "Information on a large scale that can be very helpful for populating databases is not the same as annotating a single web page.",
            "To annotate a single webpage, I think you still have to micro read.",
            "But the fan."
        ],
        [
            "Is there a lot of things that are true that aren't specific to a webpage but are mentioned many times, and for those kind of things, I think these techniques will play an important role.",
            "Thank you.",
            "Thank you, I think we have time for a couple of questions in there.",
            "Some mikes floating around.",
            "Yes, they were waiting.",
            "Very interesting work.",
            "What you doing?",
            "This type of setting, supervised and strap has to correct previous mistakes made even for Mr Lee by conference.",
            "Seems like there's some asymmetry there between overgeneralizing and overspecializing, perhaps in that regard.",
            "I mean, is it a matter of crunching more with different professionals fired kind of information?",
            "Yeah yeah, I got it.",
            "It's great question and we can see evidence of this already.",
            "So the current system that I described.",
            "Unfortunately, marches forward monotonically, never retracting anything that it once believed was true.",
            "But if you look inside the evidence that something is becoming untrue in many cases increases overtime.",
            "And so I think one of the reasons that I mentioned we're working now in a more probabilistically grounded way of integrating the evidence, is that I think that will allow us to retract will allow the system to.",
            "Recognize this overwhelming evidence that the thing you believed on iteration.",
            "23 now that we're at iteration 74?",
            "Really, that wasn't true, because now we know more about.",
            "You know the Yankees, and they're not.",
            "They're not really likely to be over.",
            "Headquartered in San Francisco or something.",
            "The evidence will increase.",
            "So that's an important.",
            "Future topic.",
            "Come precharged.",
            "One question though is.",
            "How do you deal with ambiguity so Cleveland is a baseball team and the city, and that's how we put off the grid.",
            "Yeah yeah good.",
            "One of the biggest problems with the current system is it is a knowledge base of noun phrases.",
            "It's not a knowledge base of entities out there in the world.",
            "And so it has a description of sorry.",
            "What was your example?",
            "Your noun phrase?",
            "Cleveland Cleveland is so if there are many places in the knowledge base where you can look and you will see that, for example Cleveland, it might believe that Cleveland is a city.",
            "It might believe that it's a football team.",
            "And.",
            "Some other things, and Furthermore it knows because the ontology knows that football teams are mutually exclusive with cities.",
            "You can't be both a football team in a city.",
            "Those are two different entities, so.",
            "There are many such.",
            "Easily spotted inconsistencies in the current knowledge base.",
            "In fact.",
            "One of my students, Jayant, just wrote a program to scan the knowledge base to just report out those very kinds of inconsistencies that particular triangle, believing that X is a Y&X is Z&XZ&Y are mutually exclusive.",
            "Just reporting out those inconsistencies, and there are many.",
            "The overwhelming majority of those, probably 90%, maybe, are simply due to word sense ambiguity, and so I think one of the big changes that we need to make to this.",
            "In its on our agenda for the coming year is to build a knowledge based, much more like what I've seen in the some of the work that the psych people have done where they have an entity for Cleveland.",
            "The word they have another entity for Cleveland, the city, and a third one for Cleveland, the football team.",
            "And then you can have relations among those entities like Cleveland.",
            "The word can refer to Cleveland.",
            "The city can refer to Cleveland, the football team, and by making a better model.",
            "For the representation, I think will.",
            "Will be, that'll be the way to handle it, but the important but one reason I flipped up this slide as I had this little self reflection phrase up here.",
            "One of the things they see the this evidence integrator.",
            "Expanding is that it should take on more of this kind of self reflection capability looking for inconsistencies, figuring out what to do about them."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Carnegie Mellon University and it has numerous other achievements which can all be found in the book rather than kind of reading them down.",
                    "label": 0
                },
                {
                    "sent": "And we're counting in two years and not being quite the astute.",
                    "label": 0
                },
                {
                    "sent": "Introductions I will rather try to recount a episodes from last year, so some of you may know.",
                    "label": 0
                },
                {
                    "sent": "At last year I was actually visiting Tom on my sabbatical, and I recall one specific evening that was very, very insightful for me in the following way.",
                    "label": 0
                },
                {
                    "sent": "We were both stealing time out of our busy schedules and Tom schedule being much busier because I'm three and a half 1000 miles away from my apartment.",
                    "label": 0
                },
                {
                    "sent": "To look at some data we had done some data collection of some Max cancer brain scans and we stole it sometime and we sat down at like 8:00 o'clock in the evening and we just waited through these data as you have to think 4 gigabytes worth of brain waves.",
                    "label": 0
                },
                {
                    "sent": "Kind of going at us.",
                    "label": 0
                },
                {
                    "sent": "And after a few hours.",
                    "label": 0
                },
                {
                    "sent": "I wouldn't say we're running out with the Eureka feeling, but I was reminded of 1 very important insights that computer science, even though we see us as a science that mostly builds abstractions and models.",
                    "label": 0
                },
                {
                    "sent": "Actually, at the end of the day, is an empirical science as well.",
                    "label": 0
                },
                {
                    "sent": "We have a lot of data and we should study that data.",
                    "label": 0
                },
                {
                    "sent": "It's out there and we should sometimes take that inside from biologists and others.",
                    "label": 0
                },
                {
                    "sent": "I think told myself that eventually somebody who's done this very well over.",
                    "label": 0
                },
                {
                    "sent": "Uber is very interesting.",
                    "label": 0
                },
                {
                    "sent": "Datasets being brain waves around us, but today he will talk about one specific datasets that you look set which is called the World Wide Web on.",
                    "label": 0
                },
                {
                    "sent": "Thanks Harvey and everybody for getting up early.",
                    "label": 0
                },
                {
                    "sent": "For the talk.",
                    "label": 0
                },
                {
                    "sent": "Let's see I guess I should start with a slight disclaimer.",
                    "label": 0
                },
                {
                    "sent": "I'm probably.",
                    "label": 0
                },
                {
                    "sent": "Lucky if I'm above the 10th percentile in this room in terms of sophistication about the current state of the semantic web, so my apologies an I'm fessing up to that right up front so that you can interpret my words as those of somewhat.",
                    "label": 0
                },
                {
                    "sent": "Under informed person about some of the latest advances in the semantic web, but I'm very, very glad to be here, and I learned a lot yesterday.",
                    "label": 0
                },
                {
                    "sent": "About um some of the datasets you all are working with and it really has changed my.",
                    "label": 0
                },
                {
                    "sent": "Own impression about what our own research should be focusing on.",
                    "label": 0
                },
                {
                    "sent": "So I think going forward, one effect of this meeting on me is that we're going to be relying a lot more on some of the large coupled databases that you're building DB, PDN and so forth.",
                    "label": 0
                },
                {
                    "sent": "But as the title here on my slide says, what I want to talk about is a question that I think is kind of central to this community.",
                    "label": 0
                },
                {
                    "sent": "How will we really populate the semantic web on a very large?",
                    "label": 1
                },
                {
                    "sent": "Scale and.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Again, as an outsider, which sometimes is a virtue 'cause you can just kind of see from 50,000 feet, it seems to me there are only three potential answers to this.",
                    "label": 0
                },
                {
                    "sent": "You may have others, but one of them is that will get humans to enter this structured information, and indeed, Wikipedia and the structure and information boxes to go along with that.",
                    "label": 0
                },
                {
                    "sent": "Is one kind of evidence that supports the assertion that humans may indeed enter this kind of information.",
                    "label": 0
                },
                {
                    "sent": "A second answer could be, well, there's a lot of structured information around in the world.",
                    "label": 0
                },
                {
                    "sent": "For example, the US Census Department in Census Department's in many countries, have structured data, and some of those are willing to publish that data.",
                    "label": 0
                },
                {
                    "sent": "Here's another route.",
                    "label": 0
                },
                {
                    "sent": "Excuse me, it doesn't involve typing in additional information, it involves releasing to the world existing databases.",
                    "label": 0
                },
                {
                    "sent": "A third possibility, and in fact the one that I'm most interested in and what we're going to spend the next 40 minutes on is that computers might at some point be able to read unstructured web data.",
                    "label": 0
                },
                {
                    "sent": "In some sense of read and help us populate that structured data themselves.",
                    "label": 0
                },
                {
                    "sent": "So for the next 40 minutes what I want to do is tell you about a project that we started a while ago, a year and a half ago or two years ago.",
                    "label": 0
                },
                {
                    "sent": "To explore this and it builds on research for many other groups.",
                    "label": 0
                },
                {
                    "sent": "For example, I heard yesterday a very interesting talk from the IBM folks.",
                    "label": 0
                },
                {
                    "sent": "On a similar kind of effort that they're working on, so there are a number of efforts of this type.",
                    "label": 0
                },
                {
                    "sent": "But so the question, I want you all to help me think about for the next 40 minutes is.",
                    "label": 0
                },
                {
                    "sent": "What's the feasibility and what is what are the prospects of getting computers to read unstructured web data?",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I said that I wanted to tell you about a project we're doing.",
                    "label": 0
                },
                {
                    "sent": "We immodestly, I guess.",
                    "label": 0
                },
                {
                    "sent": "Call this project to read the web, and we have a problem specification that you can see here.",
                    "label": 1
                },
                {
                    "sent": "We haven't solved this problem yet, but I will tell you the partial solution that we have.",
                    "label": 0
                },
                {
                    "sent": "But our goal is to build a system where we input in ontology, not a populated database, but an ontology that defines the categories, the relations, and some of their meta properties.",
                    "label": 0
                },
                {
                    "sent": "That we're interested in extracting.",
                    "label": 0
                },
                {
                    "sent": "And we're willing to give a handful of examples of training examples of each item in that ontology.",
                    "label": 1
                },
                {
                    "sent": "So, for example, if we're interested in an ontology that involves people in conferences and technical fields, then will give some examples of conferences and people in technical fields.",
                    "label": 0
                },
                {
                    "sent": "And if we're interested in relations like which person attends which conference, will give some examples of that, will also give it the web, because that's a lot of.",
                    "label": 0
                },
                {
                    "sent": "Data to read and perhaps occasional access to human trainer, but we're interested in kind of exploring the question of.",
                    "label": 1
                },
                {
                    "sent": "To what degree can a computer system?",
                    "label": 0
                },
                {
                    "sent": "Work on its own to extract this, and we're not so rigid as to say humans will never be able to help out, but we're interested in just exploring the end of the spectrum.",
                    "label": 0
                },
                {
                    "sent": "That's more on the automated end.",
                    "label": 0
                },
                {
                    "sent": "So then our goal, and we're not quite there, is to have a system that runs 24 hours a day, seven days a week in each day.",
                    "label": 0
                },
                {
                    "sent": "It only has to do these two things.",
                    "label": 1
                },
                {
                    "sent": "It has to extract more facts from the web to populate that.",
                    "label": 1
                },
                {
                    "sent": "Initial ontology find more people in conferences and which ones are attending which.",
                    "label": 0
                },
                {
                    "sent": "And it has to also each day learn to read better than it could the day before.",
                    "label": 0
                },
                {
                    "sent": "And one way of checking that is if it goes back to the same web pages that it read yesterday, it should be able to extract more facts more accurately than it did yesterday, so we wanted each day to do these two things.",
                    "label": 0
                },
                {
                    "sent": "Wanted to extract more fancy, but we also wanted to get to read better.",
                    "label": 0
                },
                {
                    "sent": "We figure if we could do that 24 hours a day forever, then we'd have a very interesting system in a year or so.",
                    "label": 0
                },
                {
                    "sent": "So there's the problem specification and I should can see it's a rather kind of ambitious.",
                    "label": 0
                },
                {
                    "sent": "And not yet achieved.",
                    "label": 0
                },
                {
                    "sent": "And of course one of the problem.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is that?",
                    "label": 0
                },
                {
                    "sent": "Without problem specification, it seems is that natural language understanding is already an impossible problem.",
                    "label": 0
                },
                {
                    "sent": "In yesterday's paper, for example, you could pick up an article where the first sentence.",
                    "label": 0
                },
                {
                    "sent": "It is really hard for a computer to interpret launch of NASA Ames is 1X rocket on a plan 445 million dollar test flight was delayed 24 hours Tuesday because of bad weather and an errant freighter that briefly strayed into the offshore danger area.",
                    "label": 0
                },
                {
                    "sent": "So there's an example of a sentence that's I would say it's kind of out there in terms beyond the state of the art in terms of what current natural language understanding programs can do.",
                    "label": 0
                },
                {
                    "sent": "But despite the fact that natural language understanding is far from being solved.",
                    "label": 1
                },
                {
                    "sent": "It seems to me and this is one of the things I want to convince you in this talk.",
                    "label": 0
                },
                {
                    "sent": "It seems to me that the prospects for having computers doing some form of reading.",
                    "label": 0
                },
                {
                    "sent": "Very soon to help populate the semantic web.",
                    "label": 0
                },
                {
                    "sent": "The prospects for that I think are very good and the reason is that I think there are ways of making miss.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Been reading much more plausable.",
                    "label": 0
                },
                {
                    "sent": "So one way is to leverage redundancy on the web if we want to know where NASA launches rockets from.",
                    "label": 1
                },
                {
                    "sent": "We don't necessarily have to interpret that sentence that I just read to you.",
                    "label": 0
                },
                {
                    "sent": "I'm sure that if you search over the web, there will be thousands, maybe hundreds of thousands of individual in dependently written assertions that tell you where NASA launches rockets from.",
                    "label": 0
                },
                {
                    "sent": "There might even be 1.",
                    "label": 0
                },
                {
                    "sent": "One of those will maybe be as simple as saying NASA launches rockets from where is it, Cape Canaveral?",
                    "label": 0
                },
                {
                    "sent": "In Florida um?",
                    "label": 0
                },
                {
                    "sent": "So by the redundancy of fat statements we can cherrypick we don't have to understand every sentence on the web.",
                    "label": 0
                },
                {
                    "sent": "We just have to find.",
                    "label": 0
                },
                {
                    "sent": "That there exists a sentence which is simple enough to understand that contains the fact we're interested in.",
                    "label": 0
                },
                {
                    "sent": "Another thing is that we can target are reading too populated given ontology really one of the reasons that natural language understanding is so darn hard is that people can say pretty much anything in language.",
                    "label": 0
                },
                {
                    "sent": "But if we have a predefined ontology, that means that probably most of the stuff in most sentences is not particularly relevant to that ontology, and we can restrict our focus of attention and as we'll see.",
                    "label": 0
                },
                {
                    "sent": "Very importantly, it also turns out that having an ontology in advance makes the machine learning problem of learning to read significantly easier, and we'll see that in a second.",
                    "label": 0
                },
                {
                    "sent": "Another thing we'll see is that we're going to use some new.",
                    "label": 1
                },
                {
                    "sent": "Semi supervised learning algorithms that coupled the training of many.",
                    "label": 0
                },
                {
                    "sent": "Extraction functions and.",
                    "label": 0
                },
                {
                    "sent": "As I saw very dramatically yesterday in the IBM talk, we could also make the problem easier by leveraging the many, many facts, even though they're not 100% correct.",
                    "label": 0
                },
                {
                    "sent": "They're pretty much correct that many, many fats in the growing semantic web.",
                    "label": 0
                },
                {
                    "sent": "So these are the reasons that I have optimism, despite the fact that I'm a realist and understand it.",
                    "label": 0
                },
                {
                    "sent": "It's going to be many years before we have computer programs that can understand arbitrary sentence is it seems to me that because of these things, we're going to be able to sooner have programs that can at least understand enough of the web to be useful to help us populate the semantic web.",
                    "label": 0
                },
                {
                    "sent": "OK, so I mentioned that we.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I have not achieved this goal, but what I do want to talk about today is a system that.",
                    "label": 0
                },
                {
                    "sent": "As this slide says begins, we do give it an initial ontology.",
                    "label": 1
                },
                {
                    "sent": "We do give it 10 to 20 seed examples of every predicate.",
                    "label": 1
                },
                {
                    "sent": "Category relation in an ontology.",
                    "label": 0
                },
                {
                    "sent": "And we give it a couple 100 million web pages which we process on a cluster generously provided by Yahoo.",
                    "label": 0
                },
                {
                    "sent": "The M45 cluster.",
                    "label": 0
                },
                {
                    "sent": "And the result is that it extracts a knowledge base with.",
                    "label": 0
                },
                {
                    "sent": "10 to 100,000 triples with reasonable accuracy, where reasonable means 85 to 95% accuracy.",
                    "label": 0
                },
                {
                    "sent": "So let me before I get into that.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Details of that let me show you what I mean, so I'll show you the initial ontology that we give to the system.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This looks like a very dangerous step.",
                    "label": 0
                },
                {
                    "sent": "OK, so here when I say we provide an initial ontology, I mean that we define a set of relations like these.",
                    "label": 0
                },
                {
                    "sent": "We define some of those we want to populate, and so we provide seed instances.",
                    "label": 0
                },
                {
                    "sent": "So you see here the seed instances for CEO of.",
                    "label": 0
                },
                {
                    "sent": "Here are some examples of CEOs and their corresponding companies were team coaches and which companies acquired which in which athlete is coached by which coach and which athlete plays in which stadium, and so forth.",
                    "label": 0
                },
                {
                    "sent": "So here are the kinds of things that are in the initial input to the system.",
                    "label": 0
                },
                {
                    "sent": "And the system is very generic.",
                    "label": 0
                },
                {
                    "sent": "It doesn't care.",
                    "label": 0
                },
                {
                    "sent": "It doesn't, it's not tuned around any particular ontology.",
                    "label": 0
                },
                {
                    "sent": "You give it the ontology of your choice.",
                    "label": 0
                },
                {
                    "sent": "But of course you must provide examples like this of both relations and the categories.",
                    "label": 0
                },
                {
                    "sent": "So for example, if we wanted to learn about awards trophies in tournaments, we have to give some examples of those were board games or conferences.",
                    "label": 0
                },
                {
                    "sent": "Or economic sectors or emotions and so forth.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's the input to the system.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "After it has run for a number of days on this M45 cluster.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It produces the knowledge base that we can also browse.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "By the way, all of this is open source stuff, so we're putting this all on the web.",
                    "label": 0
                },
                {
                    "sent": "These are all in XML format.",
                    "label": 0
                },
                {
                    "sent": "We're working on converting to RDF.",
                    "label": 0
                },
                {
                    "sent": "And what we're looking at here is literally the XML data with a stylesheet through a stylesheet.",
                    "label": 0
                },
                {
                    "sent": "But now, for example, if we.",
                    "label": 0
                },
                {
                    "sent": "Look at the.",
                    "label": 0
                },
                {
                    "sent": "Knowledge base produced by the system it's based on that same ontology, but now it has many more instances populated.",
                    "label": 0
                },
                {
                    "sent": "So for example for academic field.",
                    "label": 0
                },
                {
                    "sent": "The seed examples where these first ones up to theater arts and now it has added on its own.",
                    "label": 1
                },
                {
                    "sent": "By reading those 200 million web pages, a number of other things which it believes are also academic fields, and I'll just Scroll down here you can.",
                    "label": 0
                },
                {
                    "sent": "See that it's not perfect, but it's pretty good actually.",
                    "label": 0
                },
                {
                    "sent": "So you get the idea, and here are some of the awards and trophies since then.",
                    "label": 0
                },
                {
                    "sent": "So it it it learns these things here some of the board games.",
                    "label": 0
                },
                {
                    "sent": "OK, so you get the idea.",
                    "label": 0
                },
                {
                    "sent": "And for each one of these things it has created a entity with its own collection of triples, lunoe, for example, it believes is the board game.",
                    "label": 0
                },
                {
                    "sent": "It doesn't have any other triple associated with, you know.",
                    "label": 0
                },
                {
                    "sent": "But if we look for some.",
                    "label": 0
                },
                {
                    "sent": "Some of the ones that I know.",
                    "label": 0
                },
                {
                    "sent": "That I know do.",
                    "label": 0
                },
                {
                    "sent": "For example, for sports teams that tends to.",
                    "label": 0
                },
                {
                    "sent": "No affair amount.",
                    "label": 0
                },
                {
                    "sent": "So for example, the Indians are a.",
                    "label": 0
                },
                {
                    "sent": "Sports team, which it believes plays baseball.",
                    "label": 0
                },
                {
                    "sent": "You can see that it has other candidate values that it was considering, but it's not using those it believes they play baseball.",
                    "label": 0
                },
                {
                    "sent": "It has source information for each of these candidate triples that it is.",
                    "label": 0
                },
                {
                    "sent": "Considering you can see here some of the patterns.",
                    "label": 0
                },
                {
                    "sent": "About that that it has used to extract some of these things and if we just kind of Scroll down here, most of this stuff that we're looking at now is the justification for that belief that we saw.",
                    "label": 0
                },
                {
                    "sent": "But let me Scroll down to where there's something else.",
                    "label": 0
                },
                {
                    "sent": "So for example, here are team members.",
                    "label": 0
                },
                {
                    "sent": "It believes play on the loops.",
                    "label": 0
                },
                {
                    "sent": "It believes play on the Indians so.",
                    "label": 0
                },
                {
                    "sent": "We can look at some of those, like Josh Barr is an athlete who police plays for the Padres.",
                    "label": 0
                },
                {
                    "sent": "Although the Indians were also a candidate, Cleveland was the candidate.",
                    "label": 0
                },
                {
                    "sent": "And it believes he plays baseball, by the way, the reason it believes he plays baseball is from this horn clause rule, which it data mined out of the database itself.",
                    "label": 0
                },
                {
                    "sent": "So that gives you a little glimpse of the kind of.",
                    "label": 0
                },
                {
                    "sent": "Knowledge base that comes out of a very small amount of starting in.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Nation, so in essentially an ontology that defines categories in relations, a dozen or so examples of each, and then a lot of processing on a lot of web data with some machine learning algorithms.",
                    "label": 0
                },
                {
                    "sent": "So what I want to do is is take you through that algorithm, and in particular the design choices that we had to make to improve over its original lousy accuracy to get to the level that we have.",
                    "label": 0
                },
                {
                    "sent": "Today so the very first.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thing is, on the very first design choice is.",
                    "label": 0
                },
                {
                    "sent": "That we ended up using a new kind of semi supervised learning algorithm that couples the training of many, many different extractors for many many different categories in relations.",
                    "label": 0
                },
                {
                    "sent": "So when I talk about semi supervised.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Learning many of you are familiar with a kind of bootstrapping process that's pretty common.",
                    "label": 0
                },
                {
                    "sent": "For example, many people use an algorithm like this.",
                    "label": 0
                },
                {
                    "sent": "Suppose I want to learn to extract cities, and I start with a handful of cities like Paris and Seattle, and so forth.",
                    "label": 0
                },
                {
                    "sent": "Then I can search for occurrences of those cities in my text, find the linguistic context in which they occur.",
                    "label": 0
                },
                {
                    "sent": "Perhaps mayor of X or live in X occurs a lot with these things.",
                    "label": 1
                },
                {
                    "sent": "And then having found those I can go back now and search my text data again for additional occurrences of mayor of and live in.",
                    "label": 0
                },
                {
                    "sent": "And this will allow me to extract some more noun phrases that become candidate cities.",
                    "label": 0
                },
                {
                    "sent": "So San Francisco Austin.",
                    "label": 0
                },
                {
                    "sent": "I know some people who live in denial.",
                    "label": 0
                },
                {
                    "sent": "And we get other noun phrases.",
                    "label": 0
                },
                {
                    "sent": "Then we can again iterate this loop and we might find additional patterns, some of which.",
                    "label": 0
                },
                {
                    "sent": "Are influenced by this one erroneous example and the problem is this a very nice idea.",
                    "label": 0
                },
                {
                    "sent": "This kind of iterative bootstrapping, but in truth it doesn't work very well if you do it like this.",
                    "label": 0
                },
                {
                    "sent": "It works great for the first iteration or two and then it kind of runs off the rails.",
                    "label": 0
                },
                {
                    "sent": "Because words like denial creep into your cities and then it doesn't take very long after that for other excludes other extraction patterns that you don't want to show up.",
                    "label": 0
                },
                {
                    "sent": "And then it diverges and you get very inaccurate categories eventually.",
                    "label": 0
                },
                {
                    "sent": "So we like this idea, but it's fundamentally an under constrained machine learning problem.",
                    "label": 0
                },
                {
                    "sent": "We have very little only in this case for training examples, and there's just not enough to specify really the category we're interested in.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So our way around that and this was actually I think the single most important design choice we made.",
                    "label": 0
                },
                {
                    "sent": "In terms of learning algorithm.",
                    "label": 0
                },
                {
                    "sent": "Is at some point we realized the problem.",
                    "label": 0
                },
                {
                    "sent": "We just looked at in the previous slide is a very hard learning problem.",
                    "label": 1
                },
                {
                    "sent": "Hard in the sense that it's under constrained.",
                    "label": 0
                },
                {
                    "sent": "If you're trying to learn a single classifier for a noun, phrases like whether it's a city or whether it's a coach.",
                    "label": 0
                },
                {
                    "sent": "You don't have much of a constraint.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, if you.",
                    "label": 0
                },
                {
                    "sent": "One an easier learning problem you should make and apparently more complex.",
                    "label": 1
                },
                {
                    "sent": "Task and instead of asking the system to learn this one classifier of noun phrases according to whether a city or not, you should force it to simultaneously learn in a coupled way.",
                    "label": 0
                },
                {
                    "sent": "Classifiers for many many different ontology categories and relations, and that's actually.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Need the key because now.",
                    "label": 0
                },
                {
                    "sent": "Every.",
                    "label": 0
                },
                {
                    "sent": "Unlabeled example, and that's mostly what we have in those 200 million web pages.",
                    "label": 0
                },
                {
                    "sent": "Is unlabeled noun phrases.",
                    "label": 0
                },
                {
                    "sent": "Every unlabeled example becomes a constraint.",
                    "label": 0
                },
                {
                    "sent": "Even though we don't know its label.",
                    "label": 0
                },
                {
                    "sent": "Becomes a constraint on the joint choice of parameters for all these different classifiers that we're trying to learn.",
                    "label": 0
                },
                {
                    "sent": "And just to illustrate, if I give this sentence.",
                    "label": 0
                },
                {
                    "sent": "As an unlabeled example, and the system might not know whether this noun phrase represents a city or a coach or a team or a person or an athlete, or any of those things, and it might not know the same about Blue Devils, but it does know.",
                    "label": 0
                },
                {
                    "sent": "Through our ontology that.",
                    "label": 0
                },
                {
                    "sent": "A sport is mutually exclusive with the team and Furthermore, if team plays this, if we're going to assert through one classifier, the team plays the sport.",
                    "label": 0
                },
                {
                    "sent": "Our team classifier has to agree it's a team and our sport classifier has to agree that it's a sport.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So there are all these nested Inter coupling constraints and each unlabeled example therefore.",
                    "label": 0
                },
                {
                    "sent": "Can be viewed as a constraint because there only some joint assignments to all these predicates that make sense, and some joint assignments don't make sense.",
                    "label": 0
                },
                {
                    "sent": "You can't say.",
                    "label": 0
                },
                {
                    "sent": "Krysinski coaches for.",
                    "label": 0
                },
                {
                    "sent": "The Devils, but the but Krasinski is not a coach or the Devils is not a team.",
                    "label": 0
                },
                {
                    "sent": "You have to get a consistent labeling.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Armed with that intuition, we started getting a little more serious about what are the types of coupling functions that we can figure that we can see, and so one type is with some people called Co training.",
                    "label": 0
                },
                {
                    "sent": "The idea here is if we're trying to learn some function, let's say to classify a noun phrase according to whether it's the city or not.",
                    "label": 0
                },
                {
                    "sent": "In Co training what we can do is we could say well if our examples are these noun phrases embedded in sentences.",
                    "label": 0
                },
                {
                    "sent": "One kind of coupling to make multiple functions that we can couple the training of is to.",
                    "label": 0
                },
                {
                    "sent": "Instead of learning just one classifier will learn two will learn one classifier that uses just.",
                    "label": 0
                },
                {
                    "sent": "The noun phrase will lose, will learn one that learns.",
                    "label": 0
                },
                {
                    "sent": "To classify just the.",
                    "label": 0
                },
                {
                    "sent": "Weather Pittsburgh is a city according to weather.",
                    "label": 0
                },
                {
                    "sent": "Those green words to what those green words are.",
                    "label": 0
                },
                {
                    "sent": "So if you see Luke as mayor of and you don't know what the noun phrases, it's probably a city.",
                    "label": 0
                },
                {
                    "sent": "And by setting it up as learning these two.",
                    "label": 0
                },
                {
                    "sent": "Somewhat different functions.",
                    "label": 0
                },
                {
                    "sent": "They have different inputs.",
                    "label": 0
                },
                {
                    "sent": "Now we can.",
                    "label": 0
                },
                {
                    "sent": "Now we have again with the condition we want.",
                    "label": 0
                },
                {
                    "sent": "We have a situation where we have in this case two functions.",
                    "label": 0
                },
                {
                    "sent": "We're trying to learn.",
                    "label": 0
                },
                {
                    "sent": "If somebody gives us an unlabeled example like the sentence here, the system doesn't know whether Pittsburgh is a city or not, but it knows that the green classifier has to give the same answer as the red classifier.",
                    "label": 0
                },
                {
                    "sent": "So if if on this unlabeled example, the red classifier says yes, it's a city in the Greenland says no, then the learner knows it's gotta change something so.",
                    "label": 0
                },
                {
                    "sent": "And that's really the name of the game in coupling the training of these classifiers.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So once you see that then it's easy to kind of explode that idea.",
                    "label": 0
                },
                {
                    "sent": "Well.",
                    "label": 0
                },
                {
                    "sent": "I just showed you an ontology.",
                    "label": 0
                },
                {
                    "sent": "They had a lot of different categories and in our ontology, their relations among the categories that are known.",
                    "label": 0
                },
                {
                    "sent": "For example, a city is a kind of location.",
                    "label": 0
                },
                {
                    "sent": "So if the city classifier says yes, the location classifier obviously has to say yes.",
                    "label": 0
                },
                {
                    "sent": "It also knows that politicians are mutually exclusive from locations.",
                    "label": 0
                },
                {
                    "sent": "You can't have a noun phrase that simultaneously referring to both.",
                    "label": 0
                },
                {
                    "sent": "And so a second kind of coupling is to take functions with different outputs and constraints among those, and that's where the ontology comes in.",
                    "label": 0
                },
                {
                    "sent": "Our ontology I didn't show you this part, but if we were to go back and browse the knowledge base again, you'd see that in our definition of politician it says the domain that it says that the.",
                    "label": 0
                },
                {
                    "sent": "Category politician is mutually exclusive with location and a number of other categories in the ontology.",
                    "label": 0
                },
                {
                    "sent": "So that information in the initial ontology provides just the kind of constraint that we need to couple the training of these classifiers so that we can squeeze more information out of the unlabeled data.",
                    "label": 0
                },
                {
                    "sent": "And then the third.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Type of coupling involves coupling the training of category extractors with relation extractors.",
                    "label": 0
                },
                {
                    "sent": "So, for example, is shown here.",
                    "label": 0
                },
                {
                    "sent": "If we have a relation like mayor of and now we have to learn a classifier where the input is not a single noun phrase but a pair of noun phrases in sum.",
                    "label": 0
                },
                {
                    "sent": "Sentence like Luke in Petsburgh there.",
                    "label": 0
                },
                {
                    "sent": "But that classifier for mayor of can only say yes.",
                    "label": 0
                },
                {
                    "sent": "Noun phrase one is a mayor of noun phrase two if the city classifier and the politician classifier give compatible.",
                    "label": 0
                },
                {
                    "sent": "Outputs.",
                    "label": 0
                },
                {
                    "sent": "And again, the ontology provides the information we need in terms of domain and range of that relation in the data types of those.",
                    "label": 0
                },
                {
                    "sent": "And that's information we assert in our initial ontology.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, given those kinds of coupling, you can think of a lot of algorithms.",
                    "label": 0
                },
                {
                    "sent": "Here's one of the early algorithms that we developed, and it works pretty well.",
                    "label": 0
                },
                {
                    "sent": "Since then we were working on number of more probabilistic Lee grounded algorithms, but here's an algorithm that works well in that produce knowledge basis that you can browse on line like the one that I showed you.",
                    "label": 0
                },
                {
                    "sent": "And so the input is an ontology in a text corpus, and the very first step of the algorithm is to share the instances.",
                    "label": 0
                },
                {
                    "sent": "So when I said we provided a dozen training examples for each of those categories.",
                    "label": 0
                },
                {
                    "sent": "Well, we provided a dozen politicians and it doesn't cities.",
                    "label": 0
                },
                {
                    "sent": "But since the system knows that cities and politicians are mutually exclusive, it can now take all of our city examples and assert those as negative examples of politicians.",
                    "label": 0
                },
                {
                    "sent": "And similarly for the other constraints.",
                    "label": 0
                },
                {
                    "sent": "So the first thing it does is use that ontology information to assign positive and negative examples to all the categories and.",
                    "label": 0
                },
                {
                    "sent": "Then it does that kind of bootstrapping thing that we saw that we illustrated with just the city category at 1st and complained about.",
                    "label": 0
                },
                {
                    "sent": "But it does that kind of bootstrapping where now it takes those seed examples, finds patterns in the text in those 200 million web pages.",
                    "label": 0
                },
                {
                    "sent": "That fit those examples.",
                    "label": 0
                },
                {
                    "sent": "It does this simultaneously for every predicate in the ontology.",
                    "label": 0
                },
                {
                    "sent": "In the ontology I showed you there probably on the order of 100 or 150 predicates now.",
                    "label": 0
                },
                {
                    "sent": "Then it filters these by looking at the evidence.",
                    "label": 0
                },
                {
                    "sent": "It doesn't take every.",
                    "label": 0
                },
                {
                    "sent": "Context in which every noun phrase occurs in those 200 million pages.",
                    "label": 0
                },
                {
                    "sent": "It looks at some statistics.",
                    "label": 0
                },
                {
                    "sent": "For example, it will only approve.",
                    "label": 0
                },
                {
                    "sent": "Appear like CBC in Toronto, being an instance of headquartered in if that matches.",
                    "label": 0
                },
                {
                    "sent": "Multiple.",
                    "label": 0
                },
                {
                    "sent": "Text patterns, if it matches just one of the tips patterns associated with headquartered in that's not strong enough evidence, so it's fairly conservative and filtering out things that are.",
                    "label": 1
                },
                {
                    "sent": "Don't have overwhelming evidence.",
                    "label": 0
                },
                {
                    "sent": "Then it trains a classifier of the noun phrases using these extraction patterns that it has found.",
                    "label": 0
                },
                {
                    "sent": "Well, we'll see some of those patterns in this setting.",
                    "label": 0
                },
                {
                    "sent": "Then it selects the most.",
                    "label": 0
                },
                {
                    "sent": "Confident new.",
                    "label": 0
                },
                {
                    "sent": "Previously unlabeled noun phrases to promote them as things that will also believe.",
                    "label": 0
                },
                {
                    "sent": "Our cities in politicians and instances of the relation, mayor of and so forth.",
                    "label": 0
                },
                {
                    "sent": "And then it takes those promoted instances and shares those using the mutually exclusive and subset superset relation in the ontology so that a new city that it just promoted also gets propagated to become a new positive example for location.",
                    "label": 1
                },
                {
                    "sent": "And a new negative example for politician.",
                    "label": 0
                },
                {
                    "sent": "And so forth.",
                    "label": 0
                },
                {
                    "sent": "So now you see the coupling coming in and you also see that there's an interesting scaling property of virtuous scaling property the more.",
                    "label": 0
                },
                {
                    "sent": "The larger we make the ontology and the more coupling constraints we make.",
                    "label": 0
                },
                {
                    "sent": "The more propagation of positive and negative examples there are among these different categories, we're trying to learn and therefore the better the tray.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "King will be.",
                    "label": 0
                },
                {
                    "sent": "So when this process is done.",
                    "label": 0
                },
                {
                    "sent": "The system has a collection of learned extraction patterns and candidate noun phrases.",
                    "label": 0
                },
                {
                    "sent": "For all of the categories that we asked it to learn about.",
                    "label": 0
                },
                {
                    "sent": "So for example here the top learned extraction patterns that found for company.",
                    "label": 0
                },
                {
                    "sent": "And you can see you know they're pretty reasonable.",
                    "label": 0
                },
                {
                    "sent": "And now just to sort of be clear.",
                    "label": 0
                },
                {
                    "sent": "Given a new noun phrase like.",
                    "label": 0
                },
                {
                    "sent": "Marriott if it wants to know whether Marriott is a company or not the way it decides is, it looks through the 200 million web pages for every occurrence of Marriott.",
                    "label": 0
                },
                {
                    "sent": "That matches any of these patterns.",
                    "label": 0
                },
                {
                    "sent": "It gathers the statistics.",
                    "label": 0
                },
                {
                    "sent": "How often does Marriott Co occur with each one of those patterns and then that gives it a feature vector.",
                    "label": 0
                },
                {
                    "sent": "The number of times this noun phrase Co occurs with each one of those patterns, and then it applies a naive Bayes classifier which it trained during that bootstrapping procedure to that vector of Co occurrence statistics with these patterns.",
                    "label": 0
                },
                {
                    "sent": "So it's in a sense is not reading individual documents.",
                    "label": 0
                },
                {
                    "sent": "Instead it's macro reading the 200 million web pages, so it doesn't make decision about whether Mary it's a company or not by looking at an individual sentence.",
                    "label": 0
                },
                {
                    "sent": "Instead, it makes a decision about whether Mary it's a company by looking at the statistical properties of the token Marriott across these two 100 million web pages, where the features is looking for our.",
                    "label": 0
                },
                {
                    "sent": "This set of learned extraction patterns and so that gives it a.",
                    "label": 0
                },
                {
                    "sent": "Much more broad and safe set of information to base its decision on about whether Mary it's a company than if it had to read individual sentences.",
                    "label": 0
                },
                {
                    "sent": "And that's important, so it kind of comes back for first.",
                    "label": 0
                },
                {
                    "sent": "Theme about, well, natural language understanding is way too hard.",
                    "label": 0
                },
                {
                    "sent": "How can we use?",
                    "label": 0
                },
                {
                    "sent": "Some form of machine reading to help us populate the semantic web.",
                    "label": 0
                },
                {
                    "sent": "I think the answer in the short term is we want to do this kind of macro reading of many documents simultaneously instead of trying to micro read individual sentences.",
                    "label": 0
                },
                {
                    "sent": "It's going to be a decade or so before that problem gets off.",
                    "label": 0
                },
                {
                    "sent": "But then.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then for example, here are the patterns for play sport and again you see that kind of makes sense.",
                    "label": 0
                },
                {
                    "sent": "My favorite one, by the way, is this one here.",
                    "label": 0
                },
                {
                    "sent": "Someday I want to be referred to as the Tiger Woods of something.",
                    "label": 0
                },
                {
                    "sent": "It all.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So automatically extracts a number of other things that here's just to give you an example.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We saw this when we're browsing the knowledge base, but there was a lot of jumbled justification information in that knowledge base that we were browsing, so it's kind of hard to see.",
                    "label": 0
                },
                {
                    "sent": "But here, for example, is what it extracted about IBM, which was not one of its seed examples.",
                    "label": 0
                },
                {
                    "sent": "So in black you see the things that re ified that that it puts into the knowledge bases.",
                    "label": 0
                },
                {
                    "sent": "Triples, it's going to believe, so it believes IBM is a company headquartered in Armonk.",
                    "label": 0
                },
                {
                    "sent": "Produces PC acquired these things.",
                    "label": 0
                },
                {
                    "sent": "It was acquired by Lenovo Group.",
                    "label": 0
                },
                {
                    "sent": "It's not perfect.",
                    "label": 0
                },
                {
                    "sent": "Competes with these things, etc.",
                    "label": 0
                },
                {
                    "sent": "But you also see in blue the stuff is just below the tip of the iceberg, so these are the candidate noun phrases that had some but not overwhelming evidence, and so they weren't promoted.",
                    "label": 0
                },
                {
                    "sent": "But you can see that looking at these, you know IBM might have been a product, might have been a company might have been a conference that decided it was a company.",
                    "label": 0
                },
                {
                    "sent": "They produce a PC.",
                    "label": 0
                },
                {
                    "sent": "It might have produced the ThinkPad Line, but there wasn't enough evidence for that and so forth.",
                    "label": 0
                },
                {
                    "sent": "But if you look at these candidates, one thing that becomes clear is you know some of them are correct.",
                    "label": 0
                },
                {
                    "sent": "Some of them are not correct, but they would be great lists to give to people who wanted to spend some time helping out building knowledge bases.",
                    "label": 0
                },
                {
                    "sent": "So even the less confident extractions might be useful to us in some man machine.",
                    "label": 0
                },
                {
                    "sent": "HCI kind of loop.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so there that's really the main idea and now I want to take a couple of minutes to talk about how to amplify that idea.",
                    "label": 0
                },
                {
                    "sent": "So again, the idea is.",
                    "label": 0
                },
                {
                    "sent": "We can actually do a remarkably good job of semi supervised training of many classifiers simultaneously, even though it's really hard to train just one classifier.",
                    "label": 1
                },
                {
                    "sent": "With little labeled data.",
                    "label": 0
                },
                {
                    "sent": "And it's because of the coupling constraints that we get when we try to do many of them together.",
                    "label": 0
                },
                {
                    "sent": "So armed with that idea.",
                    "label": 1
                },
                {
                    "sent": "You can say, well, how can we increase the coupling even further?",
                    "label": 1
                },
                {
                    "sent": "How could we add even more functions to learn that will synergise and give us even stronger accuracy?",
                    "label": 0
                },
                {
                    "sent": "And one way to do that is to train classifiers that instead of looking at the sentence kind of text, look at HTML structure.",
                    "label": 0
                },
                {
                    "sent": "Well, it turns out there is a PhD student at Carnegie Mellon.",
                    "label": 0
                },
                {
                    "sent": "Richard Wang working with.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "William Cohen, who is just finishing up a thesis doing exactly that.",
                    "label": 0
                },
                {
                    "sent": "So we tapped into Richard's work.",
                    "label": 0
                },
                {
                    "sent": "He's built a system.",
                    "label": 0
                },
                {
                    "sent": "His thesis system is very nice.",
                    "label": 0
                },
                {
                    "sent": "You give it some noun phrases and it goes and finds essentially webpages where multiple of those noun phrases appear.",
                    "label": 0
                },
                {
                    "sent": "And then it learns a wrapper for those noun phrases.",
                    "label": 0
                },
                {
                    "sent": "And then based on that wrapper looks on that same page for additional noun phrases that are surrounded by similar HTML structure.",
                    "label": 0
                },
                {
                    "sent": "A good.",
                    "label": 0
                },
                {
                    "sent": "Case of a web page where this works well.",
                    "label": 0
                },
                {
                    "sent": "For example as if there is a web page somewhere that has a list of different kinds of cars.",
                    "label": 0
                },
                {
                    "sent": "And if you find Toyota, Nissan and Ford in a list, probably the other things in the list are also cars.",
                    "label": 0
                },
                {
                    "sent": "So it does that and it also learns many other kinds of HTML layout structure.",
                    "label": 0
                },
                {
                    "sent": "But so for example here.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There's one that says, you know on this particular URL.",
                    "label": 0
                },
                {
                    "sent": "If you find this string, then the thing that's in here is a car.",
                    "label": 0
                },
                {
                    "sent": "And here are the things that were in fact extracted that way.",
                    "label": 0
                },
                {
                    "sent": "Here's another in another.",
                    "label": 0
                },
                {
                    "sent": "So The thing is Ceil Richards program.",
                    "label": 0
                },
                {
                    "sent": "Does something try to do something like?",
                    "label": 0
                },
                {
                    "sent": "Our couple Bootstrap learner was doing except he's using orthogonal set of features.",
                    "label": 0
                },
                {
                    "sent": "He's using HTML structure whereas we were using sentence type text.",
                    "label": 0
                },
                {
                    "sent": "So why don't we just put the two systems together?",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In on every loop of our iterative bootstrapping procedure, instead of just running that coupled bootstrap learning process that we talked about a moment ago, let's also on the each loop run this seal program.",
                    "label": 0
                },
                {
                    "sent": "And what examples will it work off of?",
                    "label": 0
                },
                {
                    "sent": "Well, the same ones that are in the knowledge base that got promoted on the previous.",
                    "label": 0
                },
                {
                    "sent": "Iteration through our loop.",
                    "label": 0
                },
                {
                    "sent": "And then we'll just add an evidance integration module that looks at the proposals each iteration.",
                    "label": 0
                },
                {
                    "sent": "What are the proposals from these two different programs about new instances of cars and cities and politicians and mayor of relations and so forth?",
                    "label": 0
                },
                {
                    "sent": "And it will integrate that evidence to make a decision about how to update the ontology, how to further populate the knowledge base.",
                    "label": 0
                },
                {
                    "sent": "So we did that and in fact.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It works, it helps a lot to add this additional redundant kind of learner that's making errors independent of the errors that are being made by our learner, which is looking at text.",
                    "label": 0
                },
                {
                    "sent": "And there are a lot of numbers on this page.",
                    "label": 0
                },
                {
                    "sent": "Please don't look at them all but.",
                    "label": 0
                },
                {
                    "sent": "The The Red column is the coupled system that's using both seal and the Cpl couple learning system, and if you just look at these different in this case categories that it was learning, in most cases you see that the couple learning.",
                    "label": 0
                },
                {
                    "sent": "In the seal learning, once their combined we get much higher accuracies.",
                    "label": 0
                },
                {
                    "sent": "You also see quite interesting Lee for a number of these categories we appear to get 100% accuracy.",
                    "label": 0
                },
                {
                    "sent": "So for example they found 181 new academic fields.",
                    "label": 0
                },
                {
                    "sent": "When we sampled 40 of those and gave them to Mechanical Turk to label all 40 of those were judged to be academic fields.",
                    "label": 0
                },
                {
                    "sent": "So you can see here also something about the distribution of of accuracies in different categories.",
                    "label": 0
                },
                {
                    "sent": "Many of them are really strong.",
                    "label": 0
                },
                {
                    "sent": "Summer really bad product type for example, and sports equipment was also a real loser.",
                    "label": 0
                },
                {
                    "sent": "So it's not perfect and it still can run off the tracks the way that bootstrapping procedure can, but.",
                    "label": 0
                },
                {
                    "sent": "For example, one reason that sports equipment tends to run off the tracks is that.",
                    "label": 0
                },
                {
                    "sent": "In a way, there are no categories in the ontology that are close to sports equipment.",
                    "label": 0
                },
                {
                    "sent": "And so it's easy for it to kind of move out into other categories.",
                    "label": 0
                },
                {
                    "sent": "So if you look at the final list of proposed sports equipment includes weird stuff like chairs and things like that that you wouldn't think of sports equipment.",
                    "label": 0
                },
                {
                    "sent": "But I bet, and we found this actually by running the system many times on different ontologies that if you want to improve the performance of the system, what you should do is add some additional categories to the ontology that are.",
                    "label": 0
                },
                {
                    "sent": "Kind of nearby.",
                    "label": 0
                },
                {
                    "sent": "So for example, if you want to.",
                    "label": 0
                },
                {
                    "sent": "Conferences you should add other kinds of meetings like sports games and.",
                    "label": 0
                },
                {
                    "sent": "Dances and things like that to so that there will be semantic space taken up elsewhere in the ontology that will kind of keep this thing from expanding out to fill the void.",
                    "label": 0
                },
                {
                    "sent": "Here's another glimpse of.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What the system is doing.",
                    "label": 0
                },
                {
                    "sent": "Hopefully you can't see any of the numbers on this slide, but what it shows is for each of those categories that it was learning how many new proposed noun phrases it promoted on each iteration.",
                    "label": 0
                },
                {
                    "sent": "So this gives you some idea of the.",
                    "label": 0
                },
                {
                    "sent": "The is the iterative bootstrapping process continues?",
                    "label": 0
                },
                {
                    "sent": "What happens?",
                    "label": 0
                },
                {
                    "sent": "You know, and you'll see here.",
                    "label": 0
                },
                {
                    "sent": "Green means a large number in red means zero and intermediate colors mean intermediate numbers.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                },
                {
                    "sent": "And so you see, there are some categories like.",
                    "label": 0
                },
                {
                    "sent": "Conferences is a good one where it started out.",
                    "label": 0
                },
                {
                    "sent": "Here's conferences here were started out yellow, adding many categories up to about iteration 10.",
                    "label": 0
                },
                {
                    "sent": "Then it added another four on iteration 13.",
                    "label": 0
                },
                {
                    "sent": "Then it kind of zeroed out and never added anymore.",
                    "label": 0
                },
                {
                    "sent": "So it kind of saturated what it could extract about conferences and then just didn't get anymore.",
                    "label": 0
                },
                {
                    "sent": "In other cases you see really interesting, often on behavior like stadiums, sports stadiums, well stadiums in general start out with a lot then it died out, then it picked up again.",
                    "label": 0
                },
                {
                    "sent": "Died out, picked up again, died out, picked up again.",
                    "label": 0
                },
                {
                    "sent": "You see this kind of oscillatory behavior and we see that a fair amount.",
                    "label": 0
                },
                {
                    "sent": "And if you actually dig into what's going on, it appears to be that it's this couple learning is having is creating this kind of oscillatory effect 'cause if it learns some new stadiums it might be able to use that to learn some other things like which team plays in which stadium and better rules, better extraction patterns for.",
                    "label": 0
                },
                {
                    "sent": "Teams playing in stadiums.",
                    "label": 0
                },
                {
                    "sent": "But then if it can extract more relations about teams playing in stadiums, you get some new candidate stadiums so you get this kind of 1 predicate being learned.",
                    "label": 0
                },
                {
                    "sent": "Helping another predicate have better data to learn more.",
                    "label": 0
                },
                {
                    "sent": "So anyway, this diagram shows a little bit of that ebb and flow.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the final thing.",
                    "label": 0
                },
                {
                    "sent": "I want to tell you about is more recently we've.",
                    "label": 0
                },
                {
                    "sent": "I notice that.",
                    "label": 0
                },
                {
                    "sent": "Again, in the spirit of having our long-term goal of having a never ending learning process that each day gets better.",
                    "label": 0
                },
                {
                    "sent": "You want to build it kind of system.",
                    "label": 0
                },
                {
                    "sent": "Then you don't want it to just learn one type of knowledge.",
                    "label": 0
                },
                {
                    "sent": "Like these extraction patterns.",
                    "label": 0
                },
                {
                    "sent": "By six months from now it should have.",
                    "label": 0
                },
                {
                    "sent": "If we were to be running.",
                    "label": 0
                },
                {
                    "sent": "Continuously, which it isn't, and I'll just tell you it only runs for about a week and then we have systems issues right now.",
                    "label": 0
                },
                {
                    "sent": "Some combination of running out of memory and Java crashing and also the system sometimes saturating.",
                    "label": 0
                },
                {
                    "sent": "So like on conferences there just aren't anymore conferences it can find.",
                    "label": 0
                },
                {
                    "sent": "So it's a combination of factors that currently keep it from running forever, but in the spirit of moving in that direction.",
                    "label": 0
                },
                {
                    "sent": "We wanted to learn a variety of types of knowledge.",
                    "label": 0
                },
                {
                    "sent": "And so one obvious thing to have it try to learn is.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Our rules from that Huawei doesn't data mine, it's extracted knowledge base.",
                    "label": 0
                },
                {
                    "sent": "So we wrote a rule learner.",
                    "label": 0
                },
                {
                    "sent": "That goes through the knowledge base and for each relation in the ontology like team play Sport.",
                    "label": 1
                },
                {
                    "sent": "It tries to learn 1st order probabilistic horn clauses.",
                    "label": 0
                },
                {
                    "sent": "That are essentially rules that will predict the value of.",
                    "label": 0
                },
                {
                    "sent": "The Play Sport relation for any given team.",
                    "label": 0
                },
                {
                    "sent": "So the idea is once you have, you know 40,000 extracted relations.",
                    "label": 0
                },
                {
                    "sent": "You have an interesting database, is not perfectly is not perfect, but still statistically there might be regularity's exhibited there that could be valuable to learn.",
                    "label": 0
                },
                {
                    "sent": "So if you want to do that, if you want to build a program that will learn to predict the value of this relation from other properties of the team.",
                    "label": 1
                },
                {
                    "sent": "Course you need positive and negative examples.",
                    "label": 0
                },
                {
                    "sent": "The positive examples?",
                    "label": 0
                },
                {
                    "sent": "Well, it's obvious where they come from.",
                    "label": 1
                },
                {
                    "sent": "We have a knowledge base now that has read from the web certain assertions about which teams play which sports.",
                    "label": 0
                },
                {
                    "sent": "The real question is where you get negative examples.",
                    "label": 0
                },
                {
                    "sent": "The knowledge base doesn't store things of the form.",
                    "label": 0
                },
                {
                    "sent": "You know.",
                    "label": 0
                },
                {
                    "sent": "I'm not Lithuanian.",
                    "label": 0
                },
                {
                    "sent": "We don't bother this.",
                    "label": 0
                },
                {
                    "sent": "There are a lot of false things, so we don't bother to store them all.",
                    "label": 0
                },
                {
                    "sent": "Also, it's not tuned to actually read them.",
                    "label": 0
                },
                {
                    "sent": "So question where you get negative examples in this kind of extracting knowledge base is critical if you want to learn rules because you can't learn rules from just positive examples very well.",
                    "label": 0
                },
                {
                    "sent": "And again, the ontology turns out to be a very important clue here.",
                    "label": 0
                },
                {
                    "sent": "So one of the meta properties of relations that's in our ontology is how many values can this relation take on a team play sport can take only one value.",
                    "label": 0
                },
                {
                    "sent": "Teams play only one sport.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, competes with can take on any number of values.",
                    "label": 0
                },
                {
                    "sent": "Microsoft can compete with Yahoo and simultaneously compete with Google.",
                    "label": 0
                },
                {
                    "sent": "So the importance of this is that if you think about it.",
                    "label": 0
                },
                {
                    "sent": "The relations for which this is true.",
                    "label": 0
                },
                {
                    "sent": "We can get negative examples once we know that the Yankees play baseball.",
                    "label": 0
                },
                {
                    "sent": "We now know for all other sports that we've got in our knowledge base.",
                    "label": 0
                },
                {
                    "sent": "the Yankees do not play that sport.",
                    "label": 0
                },
                {
                    "sent": "And so that's one place we can get negative examples.",
                    "label": 0
                },
                {
                    "sent": "And in fact, in this version of the rule learner, that's the only place we get negative examples, and so we only learn rules for relations for which number of values equals one.",
                    "label": 0
                },
                {
                    "sent": "Let me show you some of the learn Drew.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Rules here, here are some out of 49.",
                    "label": 0
                },
                {
                    "sent": "Here are some of the good ones.",
                    "label": 0
                },
                {
                    "sent": "So the way you read this is these are horn clauses with conditional probabilities.",
                    "label": 0
                },
                {
                    "sent": "So this horn clause says this is true if the things over here are true and the conditional probability of the conclusion is .83.",
                    "label": 0
                },
                {
                    "sent": "So this says athlete X plays in League Y.",
                    "label": 0
                },
                {
                    "sent": "If athlete X plays for Team Z and teams plays in League, why?",
                    "label": 0
                },
                {
                    "sent": "So that's reasonable, and this rule was learned from.",
                    "label": 0
                },
                {
                    "sent": "In general, these numbers are the number of positive examples that the rule covers.",
                    "label": 0
                },
                {
                    "sent": "The number of negative examples that the rule covers, and the number of other examples.",
                    "label": 0
                },
                {
                    "sent": "To which the rule will apply if we allow it in an for which it will make a new prediction.",
                    "label": 0
                },
                {
                    "sent": "So if you scan down here, you know it's kind of interesting.",
                    "label": 0
                },
                {
                    "sent": "And these you know, if team plays against the Yankees, they're baseball team.",
                    "label": 0
                },
                {
                    "sent": "If they won the Stanley Cup their hockey team.",
                    "label": 0
                },
                {
                    "sent": "So these are the kinds of regularity's that are automatically discovered from that knowledge base once it starts getting extracted.",
                    "label": 0
                },
                {
                    "sent": "Here's some of.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Looser rules just to in the spirit of Full disclosure.",
                    "label": 0
                },
                {
                    "sent": "And so it also learned that a team plays in the NBA if it plays basketball.",
                    "label": 0
                },
                {
                    "sent": "Well, that's not true.",
                    "label": 0
                },
                {
                    "sent": "College teams play basketball and they don't play in the NBA.",
                    "label": 0
                },
                {
                    "sent": "It didn't know that.",
                    "label": 0
                },
                {
                    "sent": "In fact, if you look over here, it is evidence.",
                    "label": 0
                },
                {
                    "sent": "Interestingly, the extraction patterns and its macro reading strategy.",
                    "label": 0
                },
                {
                    "sent": "Hit found many sports teams, including many college sports teams, and they're all there in the knowledge base, but for some reason the patterns that learn for learning for reading.",
                    "label": 0
                },
                {
                    "sent": "Our team plays in League only.",
                    "label": 0
                },
                {
                    "sent": "Worked well for professional sports teams.",
                    "label": 0
                },
                {
                    "sent": "And so it just didn't succeed in extracting any assertions.",
                    "label": 0
                },
                {
                    "sent": "Any triples about those college teams in what leagues they played in the NC AA or the Atlantic Coast Conference, or whatever?",
                    "label": 0
                },
                {
                    "sent": "It didn't extract those by reading, and so its knowledge base was missed.",
                    "label": 0
                },
                {
                    "sent": "With skewed in terms of the kinds of fats that I had and empirically, it is true that in that knowledge base.",
                    "label": 0
                },
                {
                    "sent": "Things for which it had read that they play basketball.",
                    "label": 0
                },
                {
                    "sent": "It had also read that they often that they play in the NBA, but you and I know the rule is wrong.",
                    "label": 0
                },
                {
                    "sent": "So there are number of things like this.",
                    "label": 0
                },
                {
                    "sent": "You know most of the States and provinces that read about are in the United States, so it assumed all States and provinces are in the United States of problem that some humans have.",
                    "label": 0
                },
                {
                    "sent": "So anyway, if you look at all these rules, if you and I think this is a place where we do want human intervention because the damage that a bad rule can do is widespread, and the good that a good rule can do is great, and so if you manually filter these out you end up throwing away 15 of the 49 learned rules, then when you apply then you get over 1000 new Triples added to the knowledge base.",
                    "label": 1
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There's the story.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "To conclude, I want to just kind of suggest a couple of directions that we would like to go and then wrap up.",
                    "label": 0
                },
                {
                    "sent": "One is really would like to push on this rule learning and incorporated in the inner loop of the bootstrapping procedure.",
                    "label": 0
                },
                {
                    "sent": "So what I just showed you was just the result of taking system they had run in their case, 35 iterations running the rule learning system.",
                    "label": 0
                },
                {
                    "sent": "Once manually examining the rules, crossing out the bad ones and then letting them apply.",
                    "label": 0
                },
                {
                    "sent": "And it added 1000 new assertions to the knowledge base.",
                    "label": 0
                },
                {
                    "sent": "Almost all of which were correct.",
                    "label": 0
                },
                {
                    "sent": "But in fact, why don't we put that rule learning in the middle loop of this bootstrapping process, so that on every iteration the rule learner can look for more regularity's and suggest new examples which then might actually allow reading of those assertions.",
                    "label": 0
                },
                {
                    "sent": "We also are working on a couple new modules, for example one additional.",
                    "label": 0
                },
                {
                    "sent": "We talked about using free text and also HTML structure is very different feature sets for deciding if something is the city.",
                    "label": 0
                },
                {
                    "sent": "Another kind of features that you can use is the actual morphology of the noun phrase.",
                    "label": 0
                },
                {
                    "sent": "The actual substructure in the noun phrase.",
                    "label": 0
                },
                {
                    "sent": "So if you see a noun phrase with multiple words.",
                    "label": 0
                },
                {
                    "sent": "That are capitalized.",
                    "label": 0
                },
                {
                    "sent": "It's much more likely.",
                    "label": 0
                },
                {
                    "sent": "It's much less likely to be.",
                    "label": 0
                },
                {
                    "sent": "Food.",
                    "label": 0
                },
                {
                    "sent": "It's more, it's more likely now to be a city or some kind of proper noun.",
                    "label": 0
                },
                {
                    "sent": "Or if you see a noun phrase that ends with the three letters, SKI.",
                    "label": 0
                },
                {
                    "sent": "It's probably a person name.",
                    "label": 0
                },
                {
                    "sent": "So we have a student working on adding such modules.",
                    "label": 0
                },
                {
                    "sent": "So One Direction I see is adding more and more.",
                    "label": 0
                },
                {
                    "sent": "Helpful and.",
                    "label": 0
                },
                {
                    "sent": "Components to the inner loop of this bootstrapping procedure and hopefully modules that make errors independent of the modules that are already there.",
                    "label": 0
                },
                {
                    "sent": "'cause independent errors is going to lead to a virtuous cycle of better learning and better reading.",
                    "label": 0
                },
                {
                    "sent": "And the other obvious.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thing today because I attended some talks yesterday and 'cause I'm here at this meeting is really my eyes were opened up yesterday and I went to bed last night.",
                    "label": 0
                },
                {
                    "sent": "I think of you and I had talked about this at supper last night.",
                    "label": 0
                },
                {
                    "sent": "I thought, why on Earth are we starting with just a dozen examples of these categories?",
                    "label": 0
                },
                {
                    "sent": "We really should be tapping into the databases that are being created by this community and providing exporting back to them.",
                    "label": 0
                },
                {
                    "sent": "Hun.",
                    "label": 0
                },
                {
                    "sent": "Information that might be helpful.",
                    "label": 0
                },
                {
                    "sent": "So let me end there so we have some a little bit of time for questions and.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just want to.",
                    "label": 0
                },
                {
                    "sent": "Just wanted to come back to the question that was the title of the talk of how can we populate the Semantic Web and I think what I tried to convey here is that there first of all there really are multiple ways that the semantic web is going to get populated, but I think that.",
                    "label": 0
                },
                {
                    "sent": "It seems to me realistic to to believe that in a short period of time, not a decade, but more on the order of a year, we should start to have systems and the IBM talk yesterday is another example of such a system.",
                    "label": 0
                },
                {
                    "sent": "Some of the work at University of Washington and Text Runner is another example of the system, and there are other examples too, but within the next year I think we're going to see more and more of these systems that do this kind of macro reading of many documents simultaneously.",
                    "label": 0
                },
                {
                    "sent": "And because of that can extract fear somewhat accurately.",
                    "label": 0
                },
                {
                    "sent": "Information on a large scale that can be very helpful for populating databases is not the same as annotating a single web page.",
                    "label": 0
                },
                {
                    "sent": "To annotate a single webpage, I think you still have to micro read.",
                    "label": 0
                },
                {
                    "sent": "But the fan.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is there a lot of things that are true that aren't specific to a webpage but are mentioned many times, and for those kind of things, I think these techniques will play an important role.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Thank you, I think we have time for a couple of questions in there.",
                    "label": 0
                },
                {
                    "sent": "Some mikes floating around.",
                    "label": 0
                },
                {
                    "sent": "Yes, they were waiting.",
                    "label": 0
                },
                {
                    "sent": "Very interesting work.",
                    "label": 0
                },
                {
                    "sent": "What you doing?",
                    "label": 0
                },
                {
                    "sent": "This type of setting, supervised and strap has to correct previous mistakes made even for Mr Lee by conference.",
                    "label": 0
                },
                {
                    "sent": "Seems like there's some asymmetry there between overgeneralizing and overspecializing, perhaps in that regard.",
                    "label": 0
                },
                {
                    "sent": "I mean, is it a matter of crunching more with different professionals fired kind of information?",
                    "label": 0
                },
                {
                    "sent": "Yeah yeah, I got it.",
                    "label": 0
                },
                {
                    "sent": "It's great question and we can see evidence of this already.",
                    "label": 0
                },
                {
                    "sent": "So the current system that I described.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately, marches forward monotonically, never retracting anything that it once believed was true.",
                    "label": 0
                },
                {
                    "sent": "But if you look inside the evidence that something is becoming untrue in many cases increases overtime.",
                    "label": 0
                },
                {
                    "sent": "And so I think one of the reasons that I mentioned we're working now in a more probabilistically grounded way of integrating the evidence, is that I think that will allow us to retract will allow the system to.",
                    "label": 0
                },
                {
                    "sent": "Recognize this overwhelming evidence that the thing you believed on iteration.",
                    "label": 0
                },
                {
                    "sent": "23 now that we're at iteration 74?",
                    "label": 0
                },
                {
                    "sent": "Really, that wasn't true, because now we know more about.",
                    "label": 0
                },
                {
                    "sent": "You know the Yankees, and they're not.",
                    "label": 0
                },
                {
                    "sent": "They're not really likely to be over.",
                    "label": 0
                },
                {
                    "sent": "Headquartered in San Francisco or something.",
                    "label": 0
                },
                {
                    "sent": "The evidence will increase.",
                    "label": 0
                },
                {
                    "sent": "So that's an important.",
                    "label": 0
                },
                {
                    "sent": "Future topic.",
                    "label": 0
                },
                {
                    "sent": "Come precharged.",
                    "label": 0
                },
                {
                    "sent": "One question though is.",
                    "label": 0
                },
                {
                    "sent": "How do you deal with ambiguity so Cleveland is a baseball team and the city, and that's how we put off the grid.",
                    "label": 0
                },
                {
                    "sent": "Yeah yeah good.",
                    "label": 0
                },
                {
                    "sent": "One of the biggest problems with the current system is it is a knowledge base of noun phrases.",
                    "label": 0
                },
                {
                    "sent": "It's not a knowledge base of entities out there in the world.",
                    "label": 0
                },
                {
                    "sent": "And so it has a description of sorry.",
                    "label": 0
                },
                {
                    "sent": "What was your example?",
                    "label": 0
                },
                {
                    "sent": "Your noun phrase?",
                    "label": 0
                },
                {
                    "sent": "Cleveland Cleveland is so if there are many places in the knowledge base where you can look and you will see that, for example Cleveland, it might believe that Cleveland is a city.",
                    "label": 0
                },
                {
                    "sent": "It might believe that it's a football team.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Some other things, and Furthermore it knows because the ontology knows that football teams are mutually exclusive with cities.",
                    "label": 0
                },
                {
                    "sent": "You can't be both a football team in a city.",
                    "label": 0
                },
                {
                    "sent": "Those are two different entities, so.",
                    "label": 0
                },
                {
                    "sent": "There are many such.",
                    "label": 0
                },
                {
                    "sent": "Easily spotted inconsistencies in the current knowledge base.",
                    "label": 0
                },
                {
                    "sent": "In fact.",
                    "label": 0
                },
                {
                    "sent": "One of my students, Jayant, just wrote a program to scan the knowledge base to just report out those very kinds of inconsistencies that particular triangle, believing that X is a Y&X is Z&XZ&Y are mutually exclusive.",
                    "label": 0
                },
                {
                    "sent": "Just reporting out those inconsistencies, and there are many.",
                    "label": 0
                },
                {
                    "sent": "The overwhelming majority of those, probably 90%, maybe, are simply due to word sense ambiguity, and so I think one of the big changes that we need to make to this.",
                    "label": 0
                },
                {
                    "sent": "In its on our agenda for the coming year is to build a knowledge based, much more like what I've seen in the some of the work that the psych people have done where they have an entity for Cleveland.",
                    "label": 0
                },
                {
                    "sent": "The word they have another entity for Cleveland, the city, and a third one for Cleveland, the football team.",
                    "label": 0
                },
                {
                    "sent": "And then you can have relations among those entities like Cleveland.",
                    "label": 0
                },
                {
                    "sent": "The word can refer to Cleveland.",
                    "label": 0
                },
                {
                    "sent": "The city can refer to Cleveland, the football team, and by making a better model.",
                    "label": 0
                },
                {
                    "sent": "For the representation, I think will.",
                    "label": 0
                },
                {
                    "sent": "Will be, that'll be the way to handle it, but the important but one reason I flipped up this slide as I had this little self reflection phrase up here.",
                    "label": 0
                },
                {
                    "sent": "One of the things they see the this evidence integrator.",
                    "label": 0
                },
                {
                    "sent": "Expanding is that it should take on more of this kind of self reflection capability looking for inconsistencies, figuring out what to do about them.",
                    "label": 0
                }
            ]
        }
    }
}