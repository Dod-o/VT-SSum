{
    "id": "363lcbh3ngxi5p5wammumtsr3lrrgnez",
    "title": "Smooth, Finite, and Convex Optimization Deep Learning Summer School",
    "info": {
        "author": [
            "Mark Schmidt, Department of Computer Science, University of British Columbia"
        ],
        "published": "Sept. 13, 2015",
        "recorded": "August 2015",
        "category": [
            "Top->Computer Science->Machine Learning->Deep Learning",
            "Top->Computer Science->Machine Learning->Reinforcement Learning",
            "Top->Computer Science->Machine Learning->Unsupervised Learning"
        ]
    },
    "url": "http://videolectures.net/deeplearning2015_schmidt_smooth_finite/",
    "segmentation": [
        [
            "OK, so First off, thanks to the organizers for inviting me.",
            "It's always fun to come out to Montreal and like Escape the Vancouver rain.",
            "And.",
            "I always like coming here 'cause you learn like so many different things in the deep learning.",
            "People are always doing amazing applications and like the last few days, it's just like tremendous what's happening in this area.",
            "But as you mentioned, I kind of I'm only working on this sort of stuff recently.",
            "We've got a few projects in our lab, but we mostly just do optimization proofs.",
            "So I'm going to start with the first lecture talking about very easy problems in the sense that they are smooth, finite and convex.",
            "So these are problems that we can solve in polynomial time, and more recently we can solve very very large instances in polynomial time.",
            "And the reason I want to talk about this is because there I think there's a few very exciting developments in the last three years which potentially have applications in applications that you're interested in.",
            "Tomorrow we're going to basically take the negation of this.",
            "We're going to talk about non smooth, non finite and non convex and see what changes what extra challenges arise there weather what are things that you need to think about."
        ],
        [
            "OK, so I think I can more or less skip the motivation."
        ],
        [
            "You can we.",
            "We've heard all week about how you can use these big datasets.",
            "You can fit these big models.",
            "An optimization seems to be a crew."
        ],
        [
            "So part of this, so a common framework we think about is empirical risk minimization.",
            "Usually we have some data fitting term, so I'm going to use X as in R to the DD as your dimension.",
            "X is your parameters.",
            "You might have some inputs, AI and outputs BI, or possibly just inputs loss, L, and then you often have a regularizer too, so the regularizer has not been talked about as much in the lectures, but it's often there so we have N observations and we're just going to talk about finding the optimal parameters X star, and we're really talking about this in the mathematical sense.",
            "Of we want to really find the globally optimal parameters.",
            "We want to minimize this."
        ],
        [
            "Function.",
            "So you can talk, put almost anything in this framework.",
            "Everything from L2 regularizer, least squares, conditional random fields and a lot of the deep neural network models will also fit in this framework."
        ],
        [
            "So the practical challenges are designing or learning good features or efficiently solving the problem.",
            "When energy are very large."
        ],
        [
            "So why think about large scale optimization?",
            "Well, optimization is the core of a lot of machine learning models.",
            "Most of the models we've seen talked about during during the summer school have been based on optimization algorithms.",
            "And you can't really solve huge problems with traditional methods, so we've seen."
        ],
        [
            "A lot of stochastic gradient in particular to solve large problems.",
            "OK, so why do I want to focus on convex optimization to start with?"
        ],
        [
            "Well, these are among the only efficiently solvable continuous problems, and I'll say what I mean by that in a moment.",
            "But these are problems we can solve in polynomial time."
        ],
        [
            "You can also do a lot with convex models, so there's a lot of models in machine learning that are convex and a lot of the empirically effective non convex methods are based on methods with good properties.",
            "For convex functions.",
            "You can also talk about the converse of that where if you really want to get to a local minimum then near local minimum your function will look like a convex function.",
            "So if you design A method that doesn't have good properties for convex functions you wouldn't expect it to have nice properties for non convex functions either."
        ],
        [
            "And the thing that I'll talk about in Part 2 is a lot of the tools from convex analysis are being extended to non convex functions.",
            "So there's a few tools that have been developed in this very special, smooth, finite convex case that it's now we've now realized we can apply to nonsmooth, nonconvex and or non finite prob."
        ],
        [
            "OK, so.",
            "Testing the audience.",
            "How hard is this problem?",
            "I have some function F of XI.",
            "Haven't told you anything about it.",
            "You have parameters X real space R to the D. You can use whatever you want, except you can't use an Oracle that tells you the answer.",
            "How long does it take you to solve this problem?",
            "I heard a few.",
            "Yeah, you don't.",
            "You don't have to get the solution.",
            "You just have to be within within epsilon of the best F of X.",
            "Lot of people talking once.",
            "OK so I heard some I heard some exponential.",
            "I heard some forever.",
            "The correct answer is actually forever."
        ],
        [
            "So you can't actually solve this problem.",
            "I can design A function that's basically flat everywhere, and then it's infinitely small at some arbitrary real value decimal expansion and then you can just never find it.",
            "Whatever algorithm you give me, I just add one extra decimal place to make sure your algorithm never actually finds it.",
            "So to even talk about solving optimization problems, you need to start making some sort of assumptions.",
            "Usually these come in in the form of Lipschitz continuous assumptions, so either assume that your function or radiant, or your Hessian or something doesn't change too quickly.",
            "So if you do it on your function, we say that the absolute value of the function can't change by more than L as you change the parameters."
        ],
        [
            "So as a picture, I've got my function here.",
            "And if I evaluate some point."
        ],
        [
            "Then this L gives me the slope of two lines.",
            "And what this inequality tells me?"
        ],
        [
            "Is that if I just know my function at this point, the other function values have to lie in this sort of mauve area on this projector?",
            "So when you start to make assumptions like this, now you can narrow down things.",
            "Now it's not an impossible problem anymore because I can't make something arbitrarily low.",
            "It can't be lower than this line."
        ],
        [
            "And then if I can maybe get another point, I can narrow down the space even more.",
            "And as you go along, you can start to narrow down."
        ],
        [
            "The solution would be.",
            "So if you make that assumption.",
            "There's a worst case bound that you can.",
            "Well, there's there's an upper and a matching lower bound, so if you have that assumption you can now apply a sort of a grid search where you actually like.",
            "Explicitly explore the entire space in high dimensions and you can eventually find that epsilon optimal solution.",
            "There's also a matching lower bound, which is this rate, so let's take 1 / T to the 1 / D. So this is a very bad rate if you're in high dimensions.",
            "So 1 / T is already not very nice, but raising that to the power of the dimension it makes means that this is going to take an extremely long time.",
            "This is a crazy exponential runtime.",
            "Um, another thing is OK, so there's a lot of.",
            "Results for non convex elements.",
            "We have convergence rates that are actually even slower than this and I want to point out how absurd that is because if you actually just search for random points and then take the best one, you also get this convergence rate in expectation.",
            "So you should you see convergence rates lower than this, you should be very uh."
        ],
        [
            "Happy with it.",
            "OK, so the point I want to make with this slide is optimization can actually be very hard in the general case.",
            "But as soon as you start making assumptions, it makes a big difference.",
            "So we went from an absolutely impossible problem to a problem that we can solve very slowly by just making one simple assumption.",
            "And this is sort of where convexity is going to come in."
        ],
        [
            "Other generalizations of that.",
            "So a convex function is a function satisfying this inequality."
        ],
        [
            "It is easier to show it by pictures, so if you."
        ],
        [
            "Somefunction we have two points."
        ],
        [
            "A convex function is always below the line between the two points, so I evaluate F of X&F of Y and if I evaluate the function at any point between X of what X&Y, the function is going to be below this line.",
            "It's a very simple definition, but the nice implication of that is that if you have a local minima, it's a global minima."
        ],
        [
            "So."
        ],
        [
            "The point between."
        ],
        [
            "So this would be a non convex function where you."
        ],
        [
            "If you have two points, the function is actually above, so that's non convex and that means you can have non global local minima."
        ],
        [
            "A second characterization of convexity is by this sort of tangent."
        ],
        [
            "Asian.",
            "And what it means is that convex functions are."
        ],
        [
            "Are basically above their tangent everywhere.",
            "So if I take an F of X."
        ],
        [
            "And I draw a line which is this F of X plus this linear term.",
            "Then the function is always above it, so you can always sort of find a lower bound to your function everywhere.",
            "Once you have a point and a derivative."
        ],
        [
            "And from that you can easily see that if the gradient is zero that you are global minimum 'cause if I'm here and the tangent to zero, that means the function is above that line everywhere."
        ],
        [
            "There's a third characterization of convexity for twice differentiable functions, and that's the Hessian always has non negative eigenvalues and this is maybe less nice from a geometric perspective.",
            "It just means that the function is curved upwards in every direction at every point, but this is usually the easiest way to show that a function is convex.",
            "If you're not sure that a function is convex and you want to try and prove it often, you can just take the second derivatives and show that those are never negative.",
            "Are we happy with convex functions?"
        ],
        [
            "That makes sense.",
            "OK, so there's a whole bunch of simple convex functions.",
            "You can basically just memorize the list.",
            "These are the ones that occur most often and we've got linear functions, quadratic functions, sort of exponential Max functions, norms and norm squared."
        ],
        [
            "There's some more exotic things like the log, some exponential log determinants, and these linear quadratic race."
        ],
        [
            "Shows there's a bunch of operations that preserve convexity, so you can take a non negative weighted sum.",
            "You can take a linear or convex function of a linear function will still be convex, or you can take the maximum of convex functions that's also."
        ],
        [
            "Sex.",
            "So if you want to show that some more complicated functions are convex, usually just compose them with these simple operators."
        ],
        [
            "So, so that function.",
            "We know that this is a norm, and so it follows from this second rule."
        ],
        [
            "Or if you want to show it."
        ],
        [
            "SVM's are convex.",
            "Well, this term is the norm squared.",
            "These two are linear functions.",
            "You take the Max and you take a non negative weighted sum.",
            "So with these rules you can show the lot of things or convex."
        ],
        [
            "OK, so I don't want to go too much more into the details of convex functions 'cause I actually want to get into methods which are which are more of interest, but I just want to go over that to sort of introduce notation and to set the stage for what we're talking about."
        ],
        [
            "OK, so there's these things called interior Point methods which can solve convex problems in polynomial time.",
            "I'm not going to talk about these too much, but this is nice in computer science.",
            "We want problems that we can solve in polynomial time."
        ],
        [
            "But usually those have a D squared or worse cost per iteration.",
            "So if you have if you have a billion variables, these are very expensive.",
            "Even just to do one iteration.",
            "Um?",
            "Yeah, so usually there will be an end in there may not be N squared, so usually you can pick either D squared or N ^2.",
            "We"
        ],
        [
            "Whichever is smaller.",
            "So that's sort of cause renewed interest in gradient methods, so grading methods have been used in the deep learning literature like forever.",
            "But it's only recently that in convex optimization people realized that we really consider gradient methods there too.",
            "Just 'cause they have a better scaling with the dimension.",
            "So the methods are very simple.",
            "We have XT stepsize, Alpha T, Anna gradient FXT and we use that to generate a new iteration XD plus one, so I'm assuming you've seen this many times over the past two weeks, but I just wanted to show it to sort of."
        ],
        [
            "Read the notation I'm."
        ],
        [
            "So the nice thing is we have the cheap iteration cost, but there's a tradeoff, because now you're going to need more iterations and the question is, do we lose this polynomial time guarantee when we go to gradient method instead?"
        ],
        [
            "Of Interior point style methods.",
            "So let's consider one of the sort of test problems in the convex world of machine learning, which is L2 regularizer, logistic regression.",
            "This is a simple binary classification model.",
            "The objective is convex.",
            "That first term is Lipschitz continuous.",
            "The second term is not Lipschitz continuous."
        ],
        [
            "But the assumptions you have which you often have are that the eigenvalues of the Hessian are bounded above by a positive constant, so that's a very reasonable assumption.",
            "That's almost always true.",
            "I believe that's even true for almost all deep.",
            "Well, I don't know about recurrent networks, but the standard feedforward networks that's definitely true.",
            "And then this is so much stronger assumption.",
            "This is called strong convexity.",
            "So for the."
        ],
        [
            "Aggression that satisfies this, but you often have those.",
            "Where muse greater than zero?",
            "Yeah, so you often have it for some you, but we are worried about them.",
            "You greater than zero case here.",
            "So we're saying that the gradient is Lipschitz continuous is equivalent to that, and this mu greater than zero, which bounds the eigenvalues.",
            "That's called a strongly convex function.",
            "That's right, so so this is a notation meaning that the eigenvalues of this are less than or equal to L. All the animals are lessening with L, which is often written like this in sort of the convex books."
        ],
        [
            "OK, So what are those assumptions give us?",
            "The Lipschitz continuous gradient, so this is going to be.",
            "This is going to be true on this slide for any Lipschitz continuous function, which includes feedforward networks.",
            "I've never proved that, but I'm almost sure that it's true.",
            "OK, so from Taylor's theorem we have this inequality.",
            "This is the 2nd order Taylor's theorem.",
            "I've written new innovative.",
            "OK, yeah, so definitely.",
            "If you stay on a compact set then your if your weights don't get too big then it's definitely true.",
            "OK, so normally will talk about having a third order term or something that, but there's also a version related to like the mean value theorem, which is that for some value of the Hessian between X&Y, this is going to hold with equality."
        ],
        [
            "And now you're going to use that Lipschitz assumption to bound this second term.",
            "So if you have the email, then you're bounded by Li.",
            "Then I can think of the worst direction, y -- X, and that that can be at most L times the difference between y -- X.",
            "So what this says is when you have the Lipschitz continuous gradient, you can use Taylor expansion to get this global upper bound on the function value."
        ],
        [
            "And you can think of just setting your next iteration to the minimizer of that upper bound.",
            "This is like em.",
            "You make an upper bound, you go to the minimum of it.",
            "So if you plug that value back into this equation, you see that these two terms start to cancel out and you get something that looks like this and what it means is.",
            "If you use gradient descent with a step size of 1 / L, you actually guaranteed to decrease the objective function, so there's no line search or anything.",
            "This is just because the Hessian or the gradient can't change too quickly if you use the step size, you're guaranteed that the objective function goes down, and strictly so if you're not at the minimizer."
        ],
        [
            "So as a picture you at some point X and you have."
        ],
        [
            "Function F of X.",
            "This was our first order term.",
            "The first 2 terms in our Taylor expansion, which we said are always below the function.",
            "But then because you have, you know the gradient doesn't change too quickly."
        ],
        [
            "You can make this blue thing, which is an upper bound on the function."
        ],
        [
            "And then you can think of moving to the minimizer of that function to get your new your new editor."
        ],
        [
            "Or as a 2D picture, we always see the gradient descent is always moving inside the level curves of a function and making steady progress towards the optimum."
        ],
        [
            "OK, so that will be true even for non convex problems.",
            "That's just the property of the Lipschitz continuous gradient, so strong convexity lets us go in the other direction."
        ],
        [
            "We're now going to say the eigenvalues.",
            "Will they have to be at least knew times I and that lets us turn the inequality around and get an upper bound or lower bound that depends on you."
        ],
        [
            "So is a pig."
        ],
        [
            "Sure, it's kind of the same."
        ],
        [
            "This before, but now we've got this red function that's always below our function, so we know that we can't really go too far below where we are now."
        ],
        [
            "If you minimize both sides of this inequality, you get an inequality that looks like this, so it's roughly saying that the solution can't be too far down from where we are now.",
            "Depending on the current function value in the current gradient."
        ],
        [
            "And once you have those two assumptions, it actually lets you show that you get what's called a linear convergence rate."
        ],
        [
            "So you put those."
        ],
        [
            "Inequality is to get."
        ],
        [
            "Here you have this guaranteed progress coming from the Lipschitz continuous prop."
        ],
        [
            "And you have that you can only go so far because of strong convexity."
        ],
        [
            "That's what's going to let."
        ],
        [
            "You got a convergence rate, so if you put those two together, you subtract F of X star from both sides.",
            "You get something that looks like this, so my suboptimally an iteration T plus one is the suboptimality an iteration T times this property 1 minus me over L&L overview is often called the condition number of the problem.",
            "This tells you how hard the problem is to solve or or how much the."
        ],
        [
            "Problem changes in some sense.",
            "And if we apply that inequality over and over and over again, going back to X zero, we get this quantity raised to the power T. So each time you run an iteration of gradient descent, you're multiplying your error by some fixed amount.",
            "Now one thing I want to point out is this is dimension independent.",
            "There's no, there's no D here, so D indirectly affects me in L. But in principle, if you and L is constant, you can solve billion dimensional problems for the same number of iterations as you can solve 2 dimensional problems.",
            "So people really like that.",
            "If you were always close to one, this can be very fast.",
            "If it's close to 0, this can be very slow, and this is in some sense a polynomial time runtime, because if you want an extra.",
            "Digit of accuracy.",
            "You make you multiply the number of iterations G by some constant amount."
        ],
        [
            "OK, what if we don't have their regularizer?",
            "What if we're not strongly convex, but we're just convex.",
            "This is supposed to be easy, right?"
        ],
        [
            "Well, it changes things, so we're still convex, so we still have the.",
            "The eigen values are greater than zero greater than or equal to 0.",
            "But we don't have that lower bound anymore.",
            "Now we have a linear."
        ],
        [
            "Lower bound so."
        ],
        [
            "Instead of that nice red line that curved back up and made sure minimum was finite.",
            "Now we just know that the function is above this green line and that leads us to some kind of weird."
        ],
        [
            "Cases."
        ],
        [
            "So if you just have that assumption, you get what's called a sublinear convergence rate, so your suboptimality iteration T is going to be some constant Times 1 / T Now.",
            "This is way faster than a general nonconvex problem, right?",
            "We don't have this negative 1 / D. We just have 1 / T so we don't have the dimension dimension dependence, but this is in some sense not really a polynomial runtime.",
            "If you want to get one more digit of accuracy, you might have to do 10 times as many iterations as you did before.",
            "If you want two more digits of accuracy, you might have to do 103 more digits 1000 and so on.",
            "So this is this is less appealing and so I just want to emphasize that the linear convergence rate is.",
            "Is."
        ],
        [
            "A bit nicer than the sublinear convergence rate.",
            "And in machine learning.",
            "That's right, so that's my next point here is that if you have a convex function, you can always add a regularizer.",
            "So if you add the two norm squared, it actually strictly increases that new value by Lambda.",
            "So if you have a convex function and this actually should be Lambda over 2, then you is at least Lambda an you might have extra strong convexity from your function, but you can always do that.",
            "There's a second reason that machine learning.",
            "We probably don't care about this result, and I'll get to that when I start talking about non convex functions, because actually for almost every convex function you'll ever encounter in machine learning, you can prove the faster rate from the last slide, and so I'll get to that part."
        ],
        [
            "Tomorrow OK, so that's some theoretical issues, but in practice you never use this 1 / L. What do you actually use?",
            "So there's these things called line searches which actually work much better and they don't require that you know that value."
        ],
        [
            "L. So the basic one is in Armillo backtracking line search.",
            "You just start with some big step size and you start dividing it until some inequality that looks like what you want is satisfied.",
            "You just want to make sure you decrease the function by a little bit more than what the grey."
        ],
        [
            "It tells you you can.",
            "Then there's more fancy things like the Wolf conditions, which make sure the step sizes don't get too small, and if you implement these properly, usually really only need about one evaluation per iteration, so there's some people think that line searches take many.",
            "Evaluation of the function preparation.",
            "But if you do it properly, you can really avoid that."
        ],
        [
            "Another thing to mention in practice.",
            "The intuition is you can do a clever initialization, Anna clever selection of the points you evaluate along the line.",
            "So for example, let's say you tried some step size and it failed.",
            "Well, you actually value the function.",
            "At that point you had the function of the old point and the gradient at that point.",
            "Now you can fit a quadratic function through all those pieces of information and move to the minimum of that.",
            "If you also like the gradient at the new point, now you can fit a cubic function and move to the middle of that an.",
            "If, once you do these tricks, you can actually avoid a lot of the line search iterations.",
            "It's called Hermite interpolation or something."
        ],
        [
            "No yeah Hermite tribulation OK, but usually the number one reason this fails is because your rating code is wrong and I don't mean you as in like a general sense, I'm saying you're not good at coding gradients.",
            "I'm including myself and more.",
            "You know all inclusive sense.",
            "Usually your derivative code is wrong the first time you try it, you should actually check your derivative code.",
            "Finite difference is one way to do it.",
            "If you have a really big complicated model that's very high dimensional and you're worried something weird is happening.",
            "In high dimensions, there's this nice trick from Nicola Leroux, which just says just take some random direction and you can evaluate the directional derivative along that random direction, not on some sense.",
            "Check all your coordinates at once with just two function evaluations instead of.",
            "Checking all N function evaluations.",
            "Yes, yes, that's right.",
            "So if you go in both directions and then you can go like 4 function evaluations and things like that too.",
            "But going to two usually gives you much more precision than one."
        ],
        [
            "OK, so it's gradient method in optimal 1st order method.",
            "The answer is no.",
            "So Nesterov's method has been mentioned a few."
        ],
        [
            "Times here.",
            "So the gradient method has this 1 / T rate for convex functions, and Nesterov's method gets you to 1 / T ^2.",
            "For strongly convex it improves you from 1 minus mover L to 1 minus square root of me over L. Mu overalls are number less than one, so taking the square root makes it bigger.",
            "And so that means that this is a faster rate."
        ],
        [
            "So Nesterov's accelerated gradient method looks like this.",
            "It looks almost exactly like momentum or what's called the heavy ball method, an conjugate gradient.",
            "I think you change around the few of the X is unwise, but the form is roughly the same and the ideas are roughly the same.",
            "And the nice thing about Nestor's method is it's nearly optimal if you want a dimension independent algorithm.",
            "So if you want an algorithm that doesn't depend on how many variables you have in the convergence rate.",
            "These are almost the best that you can do.",
            "There's not much hope for a better algorithm unless you make more assumptions about the function, so that's a very nice."
        ],
        [
            "Property.",
            "But for logistic regression, a lot of a lot of other losses you can actually get linear convergence without the strong convexity.",
            "So in optimization they really care about this 1 / T versus 1 / T squared rate.",
            "But actually it's this difference.",
            "That's the more important one.",
            "In machine learning we almost never have a general convex function where the 1 / T style rates would apply."
        ],
        [
            "And now I'll just mention Newtons method which has been mentioned a few times in the summer school too.",
            "So here we're taking the 2nd order step where we solve this Newton system.",
            "We find a direction DT and take a step in that direction."
        ],
        [
            "That's equivalent to minimizing some sort of quadratic approximation, so it's the same as before, except for it's not really an inequality here, it's an approximation, and we're using a norm that's based on our Hessian instead of just the Euclidean norm.",
            "And I'll talk next time about things where you actually try and put the 3rd order term here, and that those are actually a little bit more elegant an I wish they would have been invented before Newton's method, 'cause the sort of the classical development of Newton's method is very ugly and lead to things like line search and trust regions and stuff.",
            "And in 2006 there was a much more elegant method invented that should have been invented 1st and makes life so."
        ],
        [
            "Much simpler.",
            "Also very nice if you want to talk about saddle points.",
            "OK, so we can generalize the army oh condition to Newtons method with something like that and Newtons method has a sort of a natural step length of 1, so usually you just try a step length of 1 and you hope that that works.",
            "That's always going to work when you're close to a minimizer."
        ],
        [
            "So what is newtons?"
        ],
        [
            "Would look like."
        ],
        [
            "So our gradient method looks like that or we have some point or minimum is here.",
            "We're going into the board.",
            "You're moving sort of perpendicular to the level curves your function, which is not a great."
        ],
        [
            "Direction of progress here and Noone's method you can think of as making some sort of quadratic approximation."
        ],
        [
            "You're going to move to the minimum of the quadratic approximation.",
            "This blue function, which you're hoping approximates your original red function, and here it makes much more prob."
        ],
        [
            "Russ so in terms of convergence rate, if you assume you're strongly convex and you assume that the Hessian is Lipschitz continuous, then Newtons method has what's called a super linear rate when you're near the solution.",
            "So you get something that looks like this, but instead of having a fixed value here you have some sequence of values, row T that converges to 0.",
            "So the longer you run it, the faster it gets, which is a very nice property, so.",
            "If you can afford to use that style of method, you probably should."
        ],
        [
            "You often can't, though, because you have to solve this sort of system.",
            "There is a variant called Cubic Regularization which I'll talk about next time, which will let you get global convergence rates and also certain solve certain nonconvex problems."
        ],
        [
            "Now there are practical versions of Newton like methods, so one thing you can do is you can only use the diagonal of the Hessian, which is equivalent to just having a step size for each dimension.",
            "There's bars libro in which is a very cute algorithm which just uses this as the step size, and it's kind of magical.",
            "So I made people do this in my class where they were applying a method where gradient descent took thousands and thousands of iterations and they just changed the step size to this and then it takes 75 and just solves the problem to some.",
            "Crazy accuracy, so just you know you can try that out this afternoon."
        ],
        [
            "Quasi Newton that's right, I'm so stochastic gradient is my next section, which I'll get to shortly.",
            "But yes, we we did have a version of this.",
            "First the casted gradient, but it requires the noise to sort of be bounded.",
            "That's right, yeah.",
            "So for large mini batches, try this step size.",
            "It'll work for awhile until you get until your noise starts to dominate.",
            "The forgetting of the initial conditions.",
            "That that that that will work for a while.",
            "You can keep changing the mini batch.",
            "You can do a true stochastic method up until some point and at some point you'll stop making progress as you will with any sort of fixed step size.",
            "Yeah you that your noise gets too big, so if you increase the mini batch size overtime then you can keep doing this and that will work OK. OK, so there's also more fancy things quasi Newton Hessian, free Newton methods, so these either keep an approximation of the Hessian or they use Hessian vector products to approximately solve the Newton system, and another relative methods nonlinear conjugate gradient.",
            "I'm not going to go over go over these in details 'cause I really want to get to stochastic optimization methods, but I just want to mention that they exist and if you have a problem where you can go through data set many times these are very appealing methods."
        ],
        [
            "And this is just something I have on my web page comparing a bunch of these things.",
            "So I have this code min funk and this is sort of a standard optimization test problem.",
            "You start at zero, you want to get to 1.",
            "The problem is very ill conditioned.",
            "If you use gradient descent with a very fancy line search, it doesn't do much was if you if you some of the more fancy things limited memory, FGS testing for Newton all these fancy conjugate gradients you can do much better."
        ],
        [
            "That's right.",
            "Yeah, well, so so actually a very nice property is if you just want the derivative in One Direction, whether it's your function, your gradient, your Hessian, whatever you can in some sense always do that efficiently.",
            "If you want to automatically compute the gradient with respect to every direction with respect to all your coordinates, that's expensive, But if you just give me One Direction, I can always compute that the cost of.",
            "At most, like three times the cost of computing the value itself.",
            "So gradients and directions are very cheap.",
            "And for neural networks they have a very nice structure.",
            "As for they do from any other problems.",
            "That's true, another thing you can do is you evaluate your gradient in the complex domain with a small perturbation in the complex domain and then the real part will give you the gradient and the complex part will give you the exact Hessian vector product.",
            "Yeah.",
            "It's very cool.",
            "It's in our ICML 2006 paper for CRF's, but the exact same thing is true of most neural network models.",
            "As long as you're saying that you're not doing something like a Max, it has to be like a smooth function.",
            "It's implement as a sequence of operations.",
            "So for a lot of functions, yeah, you can just use complex arithmetic to take the Hessian vector product and that's in Min Funk."
        ],
        [
            "Two so I just want to show you sort of a sample that these things really can make a difference from not making much progress to making just basically solving the problem."
        ],
        [
            "OK.",
            "But we don't usually talk about gradient methods were often talk about stochastic gradient methods.",
            "Hussain."
        ],
        [
            "What do you mean by approximations?",
            "For LBF Jess, it's a complicated question.",
            "So if you read the books and stuff they say it's OK.",
            "In practice, something weird can happen.",
            "So if you really want to Newton like method to converge.",
            "You basically need your sequence of Hessian approximations, their eigenvalues to be bounded between two fixed positive constants.",
            "Now LDF Jess.",
            "If you read about in the textbooks and you look at the implementations, what they usually do is they make sure that it's not ever zero.",
            "The eigenvalues of your approximation, but they're not checking that it's too big, or two or two close to 0 so.",
            "What can actually happen is that that can go wrong and the algorithm stops working.",
            "There's an easy fix, you just restart the algorithm.",
            "Oh, I usually say the LB FGS or the precondition testing free Newton methods so.",
            "Precondition hassian fruit and uses LB FS to precondition the Hessian free method and that's a very nice, simple, elegant method that works quite well.",
            "If you keep the fixed batch size.",
            "That's a very complicated question.",
            "So that'll work if your Hessian converges to a constant.",
            "I'm not sure if that works if you're heading approximation of the eigenvalues stay bounded between interval.",
            "I don't know, but the nice thing about the polyak Ruppert result is in some sense it says you don't need to approximate the Hessian in that setting.",
            "I'll get to the polyak Ruppert result momentarily.",
            "Are there other questions on deterministic methods before we move on to stochastic methods?",
            "I feel like there's one more random comment waiting to get out.",
            "Not random, insightful.",
            "Sorry, I meant this thing in my head.",
            "Got replaced with.",
            "I'm just joking.",
            "Oh, 'cause this is a 2D function.",
            "This is 2D, very hard function.",
            "Often you're dealing with much easier and much higher dimensional functions, and the story kind of switches when you go to those problems.",
            "But yeah, that's a really good question.",
            "OK."
        ],
        [
            "So oh."
        ],
        [
            "So if I put in I hear and I hear.",
            "I don't need to do this anymore.",
            "The imaginary part is just going to give me the Hessian vector product.",
            "Times Delta so you have to multiply it by Delta but will give it give it to you to like 150 decimal places accuracy so not like the usual like 6.",
            "It just completely computes it's.",
            "It's actually a special case of automatic differentiation, but you don't do anything fancy, you just change your code to work with complex numbers."
        ],
        [
            "OK, so back to our problem formulation."
        ],
        [
            "Grading methods they kind of let us solve the scaling with D, But what about the case where N is very large?",
            "So if we talked about image net, I guess it's even bigger now, but at the time of the slide it was 14,000,000 images which you don't want to go through like 100 times.",
            "You want to go through it like at most 10 to 15 times.",
            "That's sort of the sweet spot.",
            "It seems like you need more than one, but probably you don't need more than 50, you don't."
        ],
        [
            "Too much progress after that.",
            "So let's just consider the very abstract problem minimizing a sum of smooth."
        ],
        [
            "Functions so deterministic grading methods.",
            "Very old method when you have that some structure, you just take the average of the gradients in the sum.",
            "That's your gradient direction.",
            "The problem is the iteration cost is linear in N 'cause you need to complete your grading on every single training example.",
            "But you get the nice convergence with constants with constant stepsize or you have."
        ],
        [
            "Your linesearch stochastic gradient methods sort of a different tradeoff.",
            "Instead of valuing every function, you just sample one random function.",
            "You take your gradient step with respect to that one random function."
        ],
        [
            "It's nice it gives an unbiased estimate of the true gradient.",
            "So if you take the expectation of this value over all eyes and sometimes I replaced my gradient with F prime.",
            "Then you just get the average of the gradients, which is the true gradient.",
            "So this is very beautiful.",
            "The iteration cost is independent of N. If you have 15 million training examples, this is 15 million times faster, which is the speedup you should care about."
        ],
        [
            "But the convergence means your step size has to go to 0, and that's sort of what's going to ruin all the fun."
        ],
        [
            "So this is the deterministic rating with this casting method you start taking big step sizes, but you slowly make them smaller.",
            "So if you do that properly you'll converge."
        ],
        [
            "So stochastic iterations there end times faster, but we really care about how many."
        ],
        [
            "Actions are required, and if you just do the table, it's actually not so hard to find these results, but they are out there in the literature.",
            "The stochastic method for convex function is 1 / sqrt T and for strongly convex functions it's 1 / T. So as I mentioned, we're really going to focus on the strongly convex case and the problem here is that the convergence rate is actually very slow.",
            "This 1 / T rate means that the longer you run stochastic gradient, the less progress that's going to make the difference between 1 / 1,000,000 and one over million one is almost nothing.",
            "So if you're running it for a million iterations, you're not doing very much.",
            "And if you're only relying on unbiased grading approximations, you can't actually improve on the 1 / T. That's true, that's Part 2.",
            "That's tomorrow.",
            "So today I'm I'm assuming the world is very nice to me and then tomorrow I'm going to step outside my comfort zone and talk about issues like that.",
            "But yes, I will get to that."
        ],
        [
            "OK, here's another weird thing which I added yesterday, 'cause I realized that I really need to mention this.",
            "OK, so momentum slash acceleration does not improve the rate, so you're still in this rate regime.",
            "So in terms of convergence rate, momentum doesn't make you faster.",
            "Here's another weird thing though is that there's only one convergence rate.",
            "Proof of momentum in this casting aware of, and actually requires the momentum to go to 0.",
            "So this usual thing of setting that data to .9, there's actually no theory to justify that as far as I'm aware.",
            "Just throwing that out there since that seems to be a very common thing.",
            "I it's.",
            "In the stochastic case, momentum does not help in terms of the dependence on T. I'll get to in a few slides.",
            "You can actually improve the constants that are hidden in there, but you cannot improve the dependence on T. And you need the momentum to go to 02, which is another weird thing."
        ],
        [
            "OK, so this is kind of the story in the smooth, strongly convex case where we've got the deterministic methods, which kind of do nothing for a long time.",
            "Take a big step, do nothing, take a big step and so on, but make steady progress with this casting methods which make a whole lot of progress right away.",
            "But the longer you run them, the less progress they're going to make.",
            "So if you're really in the low time or you don't care much about accuracy, then stochastic methods are definitely superior, whereas if you have a lot of time or you need a very high accuracy than the deterministic methods are a bit better than.",
            "Unfortunately it's a little bit tricky 'cause you're not allowed to see the green curve when you run stochastic methods.",
            "You can't really decide which method to use, so I just want to point out that trade."
        ],
        [
            "Off"
        ],
        [
            "Well, yes, so you have to make this the casting method lot slower.",
            "'cause now you have to compute the function values itself to figure out where the crossing point is.",
            "Right, so if you're using a validation set, then I think.",
            "It goes away a bit.",
            "Depending on the cost of evaluating the validation set for.",
            "Yeah, so yeah, in that case you could actually look for the crossing point definitely.",
            "Oh, so I'm pointing versus time so it has to actually go through all 15 million data points.",
            "And at that point in time it's not changing the parameters, so it's effectively doing nothing on those iterations.",
            "Other questions about this plot.",
            "So this is actually set up point, which I'll get to very shortly.",
            "Is that for a lot of the stochastic gradient methods that at least the theory used in some of the ones that use in practice, they actually exponentially go up before they start going down.",
            "And this is this is this is approvable phenomenon.",
            "The answer to that is used constant step size and I'll get.",
            "Or something that looks like constant step size and I'll get to that momentarily.",
            "Yes, definitely.",
            "That's right, so that's a very common strategy.",
            "Classically, the.",
            "Yeah, so often the recommended right places after one pass through the data, so right there.",
            "And that's usually a pretty good approximation of where you should do it."
        ],
        [
            "OK, before we get to that trip, I just want to mention that the story is not the same for nonsmooth problems.",
            "So if we think about things like SVM's, the story between."
        ],
        [
            "Realistic and stochastic is actually much simpler.",
            "So here's the rates of what's called a subgradient method.",
            "It's generalization of grading for nonsmooth problems, for non, for convex problems.",
            "So if we go through the full data set on each iteration, we get 1 / sqrt, T one over T, so it's not.",
            "It's not great, it's much slower than if this function is smooth.",
            "But the stochastic rain actually has the same rate.",
            "Which is kind of cool.",
            "It's like a free lunch if your function is really.",
            "If you're really optimizing a nonsmooth convex function used the castec subgradient.",
            "Don't use cutting plane, don't use.",
            "I think that's still in the non smooth setting.",
            "You still have you still have.",
            "Discontinuity's if you can show that the minimizer, the point you're converging to, that the function is smooth, then you're really in the easier case.",
            "But if you're non smooth out the minimizer then you're in the hard case.",
            "So there's a bunch of optimization people have been saying that we can just apply quasi Newton Smith problems and not even worry about it, but they don't work on problems like L1 regularization where you're actually not smooth at the minimizer.",
            "OK, so they're convex.",
            "What I mean by non smooth is that you can't take the derivative everywhere, there's there's some points where there's no gradient.",
            "It's not, it does not exist.",
            "Now this function so you can't talk about the gradient being Lipschitz continuous anymore.",
            "So what you do is you.",
            "So, so Lipschitz is kind of an upper bound on the rate of change, and strong convexity is a is a lower bound on the rate of change.",
            "This happens to be a strongly convex function, so we still have the lower bound, but the upper bound we have to change now 'cause we don't have a gradient, but you assume that the sub what's called the sub gradient, which I'll get to in the next slide is bounded.",
            "The subgradient can't change too quickly either and then you get analogous things.",
            "In the gradient descent stuff, you only care about the gradient function doesn't have to be Lipschitz continuous, and at least squares, it's not.",
            "Right?",
            "It's true, so.",
            "So actually for convex functions, any nonsmooth convex function has to be differentiable almost everywhere.",
            "The problem is not that you're on the non differentiable points.",
            "The problem is that the gradient you sort of lose this that the gradient can change slowly when you have non differentiable points you get to you go from here to here in the gradient sort of jumps in magnitude, and that's going to prevent you from.",
            "Sort of approaching it slowly and smoothly.",
            "That's right.",
            "I will talk about smoothing approaches next time 'cause 'cause you can beat these bounds with approaches like that.",
            "I am one of the points I really make next time.",
            "Is these bounds actually really pessimistic and you can.",
            "You can just destroy them in practice, which is kind of like a theme of my research is showing that you can often beat these bounds under very small changes to your assumptions, but that's a very good point.",
            "OK, so so.",
            "So if any of you are still using like SVM, whatever structure per for light or whatever, just you stochastic gradient instead.",
            "It'll work much better."
        ],
        [
            "OK.",
            "So for announcement problems, determining determining methods are not faster than stochastic methods.",
            "So if you truly have a black box dance with problem, you stochastic subgradient durations will be 10 times faster.",
            "Convergence rates the same.",
            "It really is a free lunch until we get to tomorrow."
        ],
        [
            "OK, So what is?",
            "What is the subgrade in the subdifferential?",
            "So that was our that was our sort of 1st order DEF."
        ],
        [
            "Notion of convexity and we're just going to say a subgradient is any direction.",
            "D where I can plug it into that inequality and the inequality is still satisfied."
        ],
        [
            "If you had a differential point, there's only one sub gradient which is the gradient and at non differentiable X you're going to have a whole set of sub gradients, called the subdifferential, which is confusingly used with this notation.",
            "A nice property of the subdifferential is if zero is in your subdifferential, then you're at the global minimum of a convex function, so that generalizes the condition that the gradient is 0 for the."
        ],
        [
            "The minimum of a smooth function."
        ],
        [
            "As a picture."
        ],
        [
            "If you're at a smooth point, you've got one subgradient.",
            "It's the gradient."
        ],
        [
            "If you're at a non smooth point then."
        ],
        [
            "You have you know that."
        ],
        [
            "Subgradient, that's it."
        ],
        [
            "Gradient that's a subgroup."
        ],
        [
            "Print and basically any any way you sort of tilt this line.",
            "You'll get a subgradient and it turns out it doesn't.",
            "Well, I'll talk about."
        ],
        [
            "Whether it matters which."
        ],
        [
            "When you pick but essentially for stochastic subgradient it doesn't matter which one you pick.",
            "So if you're doing this generalization of this for nonsmooth functions called the Clark Subdifferential, which is a very fancy way of saying that's what you guys are doing when you do Relu.",
            "So if you want to make your papers sound more fancy, you should say you're taking the Clark subgradient, which is basically like a local subgradient, and that would be.",
            "What would you do for revenue when you take either one or the other line?",
            "If you're actually at the nonsmooth."
        ],
        [
            "Which you may not be.",
            "So sub differential absolute value function is is plus one if you're bigger than 0 -- 1.",
            "If you're less than zero, and then anything in between when you're equal to 0."
        ],
        [
            "As a picture."
        ],
        [
            "Sure, if you're there, it's the line with slope minus one."
        ],
        [
            "If you're at."
        ],
        [
            "Zero then you."
        ],
        [
            "Minus one plus."
        ],
        [
            "10 So this is the global minimum of the absolute value."
        ],
        [
            "And then a whole bunch of us."
        ],
        [
            "Thing, so any of those will work as subgradients, they're all fine."
        ],
        [
            "Subdifferential of Max."
        ],
        [
            "Function as in the Relu is you just take whichever one is the arc Max and take its gradient, assuming they're both smooth.",
            "So if F1 is bigger, you take that one.",
            "If F2 is bigger, you take that one.",
            "If they are tide then you can take any convex combination.",
            "You can take any anything that mixes between the two."
        ],
        [
            "OK so the basic subgradient method I'm going to use this notation where DT is now some element of the sub diferente."
        ],
        [
            "I'll if you want to talk about the best subgradient that's called the steepest descent rule, and it's given by this weird relationship where you actually take the smallest subgradient that's in some sense the direction that will give you the most improvement.",
            "That's often not easy to compute if you're doing something like L1 regularization.",
            "It is easy and very common, but in Gen."
        ],
        [
            "Well, it's not easy to compute.",
            "If you don't pick that direction, you can actually increase the objective even for small alphas.",
            "So if you there's no guarantee that you'll decrease the objective function by following a subgradient.",
            "But if your step size is small enough, you can guarantee that you decrease the distance to the solution.",
            "So even though you might increase the function, you still actually get closer to the solution.",
            "But you still require the step size to go to 0, and that's what's going to lead to those bad convergence."
        ],
        [
            "So I showed before.",
            "The basic stochastic subgradient method is exactly what you think it would be.",
            "Instead of taking the true subgradient, you just take the subgradient for one of your functions, randomly chosen, so no surprises there.",
            "I'm pretty sure most people in the room have actually used this hour."
        ],
        [
            "OK, so let's talk a little bit about what is known of the theory versus the practice for convex functions.",
            "So if I just take this Alpha T is one over mu times T this is this is very common for SVM.",
            "Is this actually works for every other problem?",
            "This doesn't really work, they don't ever write that in the papers.",
            "I don't know why.",
            "OK, so 1 / T for smoothing functions one over log T / T for nonsmooth functions you use a log factor compared."
        ],
        [
            "Optimal, but it's not a big deal, but except for if you're doing binary streams, you should actually never use that version of stochastic gradient descent, so the initial steps are huge, so usually mu is something like 1 / N or 1 / sqrt N. So your initial step size is something like N. The number of data points like 15 million.",
            "You can, you can easily imagine why this is a ridiculous thing to do, and you can actually prove that until some point.",
            "This step size is going to be exponentially fast away from the solution, it's going to increase the objective function, so this was a comment before that often stochastic rain.",
            "You don't see this sharp increase.",
            "You see a big increase, and then it goes down.",
            "That's usually from using some crazy stepsize like this.",
            "The later steps actually get very small, so 1 / T goes to zero very quickly.",
            "The convergence rate is also not robust to misspecification of mu, so there's one paper where they said well, what if he is off by a little bit and then they show that the convergence rate is incredibly slow.",
            "Yeah.",
            "Yeah.",
            "Don't use this, I don't, I don't.",
            "I'm not going you are using this.",
            "People do this, but not not people who work on hard problems.",
            "People who work on hard problems know what step sizes they should use, and we'll get to that shortly.",
            ".1, yes, exactly.",
            "I'll show you a theorem for .1 in two slides.",
            "OK, and this is really for the worst case problem.",
            "This is think about the worst possible strongly convex function you can think of, but often you're not optimizing the worst strongly convex function.",
            "There's no adaptivity of the problem in the step size at all here, so this is sort of a very pessimistic."
        ],
        [
            "Algorithm.",
            "So tricks that work both in theory and in practice 2 very simple tricks are well, use smaller initial step sizes that go to zero more slowly, and this sort of has been much more appreciated in the last few years, especially Francis Bach.",
            "Published a series of papers showing that this is a good idea so you don't want to use this 15 million size initial step and you don't want it to go to 0 so quickly either.",
            "Another thing is taking a weighted average of either the gradients or the iteration so you can show those have some very nice properties and I'll get to the polyak Ruppert result momentarily.",
            "They're just some weights, so.",
            "Non negative yeah.",
            "So one common one is you.",
            "You average like the second half year iterations or something like that."
        ],
        [
            "OK, so there's a few works that support using large steps and averaging, so if you do what I just mentioned, you're just average the second half of the iteration.",
            "That's going to achieve the 1 / T rate without the log factor.",
            "It works a little bit better, or you can just average by the iteration number is another weird thing.",
            "So instead of averaging 1 / N, you sort of take the iteration number T, and you normalize your step to average by that, so you focus more on the later iterations than the earlier iterations.",
            "Um?",
            "I'd have to think about the first iteration would have weight proportional to one and the last one would ever weight proportional to T. And then you normalize them.",
            "So I think you get a T squared in there somewhere in the weights.",
            "Um?",
            "Yeah, you you have the TT plus one over the old Gauss some story.",
            "OK, so there's this thing called dual averaging which where you take gradient averaging and that's been shown to improve the constants and if you have a sparse regularizer that will actually identify the sparsity pattern, which is not true of stochastic gradient methods or subgrade methods.",
            "So Bakken Muline showed that if you sort of a smaller steps."
        ],
        [
            "Guys, it's more robust to miss specifying you, and here's the result that if you're going to take one thing away from the first 2/3 of this lecture, study this line.",
            "So this result is very much hidden in this paper of netishyn bertsekas, but I wrote like a three page report last year giving like a simplified like half page proof of this result in the more general setting.",
            "OK, so if I use a constant stepsize, if I use .1.",
            "This is the result that you get, so are my expected function value.",
            "It's going to be something that forgets my initial conditions with a linear convergence rate, so I go away from my initial conditions very quickly.",
            "But I don't converge.",
            "I have this extra term that doesn't depend on T. It's proportional to the stepsize.",
            "So basically you you go very quickly to some region, but then after that you can't make any progress anymore.",
            "There's sort of this this level set this level below which you go very quickly and then after that you're stuck.",
            "You don't know what's going to happen.",
            "If you make the step size smaller, that region goes down and down and down.",
            "So if you're using this strategy, which my understanding is, it's very common use some step size some concepts for a long time.",
            "Take something smaller, use that for a long time, take something smaller, do that for a long time.",
            "That's a very reasonable thing to do.",
            "In fact, for classic stochastic gradient methods, I often recommend that 'cause that's very easy to tune compared to these, this decreasing sequence and it is completely justified theoretically, as long as you're willing to give up convergence and you say, well, I'm not going to get these back solution, but I'll get to someplace quite good.",
            "Yes, then you're back to 1 / T. Ha."
        ],
        [
            "So so gradient averaging Yagi actually averaging the directions.",
            "So you you know you're taking one stochastic gradients, another another another, and you take the average of all those directions you've looked at.",
            "Just an magnitudes, yes.",
            "And then the other one is.",
            "You actually average the iterations themselves, so if you're bouncing all around the place, you actually go to the middle of where you're bouncing around.",
            "Usually this is an offline thing.",
            "We actually run your algorithm and then you just return the average as opposed to.",
            "And then there's something called bathers method, which is not well known but has the same polyak Ruppert result, which I'll get to momentarily, which does which does online averaging and averaging in the gradients, and has very beautiful properties, but it's not well known 'cause there's no PDF of it online.",
            "Who's that?",
            "Maybe that's."
        ],
        [
            "Hypothesis, or is there another question?",
            "See are you saying at some point, stop and evaluate the function or approximate the function and then decide to choose the step size?",
            "I think you're still going to be stuck in the 1 / T regime.",
            "I think if you really want to converge, you're stuck with 1 / T. There's not really something that can solve that in the general case, unless you're talking about finite sums, which I'll get to shortly.",
            "With this rate, yeah yeah.",
            "So that will still work, but but this is a very nice rate 'cause you really do get this exponential convergence to some nice region.",
            "Sure, yeah.",
            "If it's converging then it can't be faster than one over there.",
            "That's a theorem.",
            "If it's constant and it's within some bound between two bounded intervals, then it, then it's in this an your Alpha is probably the Max of the interval, but if you do something more refined you might be able show it's a bit better than that as you go through the interval.",
            "Are there more questions I I think this result is not well known, and perhaps is underappreciated 'cause it wasn't.",
            "It's hidden in a longer paper that discusses a whole bunch of other things.",
            "That's all we're talking about today.",
            "If you.",
            "OK, so I'll make two comments on that.",
            "So First off, you actually don't need smoothness for this result.",
            "If you state in terms of the distance to the solution.",
            "So smoothness is not not important, but strong convexity is important to this result.",
            "The second point is we don't really have any theory on what happens in that case.",
            "So to say that this theory doesn't apply is true, but the same thing with everything else that anyone has said except for that very first that it can't go faster than grid search.",
            "If you're talking about solving a general problem so.",
            "Yes, you can make that criticism, but we have to try to find out what's understanding and we're starting with this easy case to try and understand what's happening.",
            "It's true, but I'll show you function tomorrow that does not look like that at all.",
            "Where this theorem still applies.",
            "It's not even convex, it's not.",
            "It has flat rate.",
            "You know it's much more nasty."
        ],
        [
            "But today I just want to make my life simple, not talk with things.",
            "OK, so the Poly actor engine.",
            "It's key result is a very very important result and.",
            "It's still not really well written.",
            "It's very complicated with there's no results, which I'll talk about tomorrow, which are very interesting.",
            "OK, so if you're talking about this smooth and strongly convex case, iterate averaging is asymptotically optimal in the sense that if you have the optimal estimator in terms of statistics.",
            "Asymptotically, once you forget about the initial phase averaging the iterations, that's the optimal thing you can do.",
            "You can also do optimal with the stochastic Newton's method, but why would you do this to castec Newtons method if you can just do iterate averaging and the 1st order gradient method.",
            "So in some sense this is almost a negative result saying that maybe stochastic methods aren't the right thing to do, they certainly aren't the right thing to do asymptotically.",
            "So, so I think that result is sort of underappreciated an whenever you're thinking of developing is to Gaston method, you should always.",
            "Try and think about like the Polyak in Judith's key case 'cause."
        ],
        [
            "I think sometimes our intuition with the determinant deterministic case can mislead us in the stochastic case.",
            "OK, so should we use accelerated or Newton like methods?",
            "We know that they don't improve the convergence rate.",
            "Those methods still have 1 / T."
        ],
        [
            "But there are a bunch of positive results, so acceleration or momentum or heavy ball can actually improve your dependence on other constants, so they don't improve your dependence on the number iterations T. But if you if they improve your depends on the condition number, they may still be appealing to use, and I think This is why they actually work in practice is because T may not be the bottleneck in some cases.",
            "In some cases the optimization problem might just be really hard.",
            "We wanted to improve our dependency on the optimization problem as opposed to the number of iterations we ran.",
            "So that will improve the performance either at the start or if your noise is very small.",
            "There's also this ADA grad and a sequence of works following it, whether using a step size for each coordinate.",
            "Again, that's not going to get you around 1 / T. But Ducey, Al Al did show that can improve regret bounds.",
            "So so if you add up your suboptimality across all iterations, you can do a little bit better using this.",
            "Back in New Orleans gave sort of a Newton like method, which actually I think I mean this has seen vector products which gives the 1 / T rate without strong convexity.",
            "When unfortunately I got to Frances.",
            "After he submitted the version of the paper so we didn't have this nice complex number trick in the paper, but he should have, so that's kind of nice that actually we don't need the strong convexity in a lot of cases to get the 1 / T rate.",
            "OK, I think that's all I have to disable stochastic methods, so maybe I'll pause there to see if there's some more questions.",
            "The short answer is no.",
            "The funnier answer is someone asked this to number of ski at a workshop at NIPS one year, and he got mad at them.",
            "He's like how can you possibly define a distribution over possible problems you could solve?",
            "If you apply conjugate gradient tool in your system that comes from random data points.",
            "It actually converges way faster.",
            "You can prove out much faster rate, so there may be results like that that exists.",
            "But there in like Nesterov's notebook in his file cabinet drawer somewhere and I that none of them are actually out in the world as far as I'm aware, except for for linear programming there's this proof with like the smooth analysis of simplex method showing that simplex is actually polynomial time in practice.",
            "Oh no, I'm just saying you can.",
            "You can actually pick any subgradient the theory applies.",
            "Yeah.",
            "You have to.",
            "You have to think of like a function like this where the level.",
            "So I've been showing all these like round level sets these circles but if you have something like a triangle then you can have something that actually doesn't go inside the triangle but actually moves you closer to the solution.",
            "So you have to really consider like a non smooth point in your level curve and then you can get that property.",
            "But seekers had some very nice illustrations in his book.",
            "Right, I mean all of it's in most of his books.",
            "So what I'm saying here is this is kind of a mystery.",
            "I would I would say like try and find a good constant stepsize and maybe like divide that by two or 10 or something if you find that it's not working after all.",
            "I mean, my understanding is that this is what people already doing and I just wanted to say that that's actually like a reasonable thing to do from a theoretical perspective.",
            "Um?",
            "So I mean this land guy, he wants to design out and that works for every single problem, so I'll get to his results next time where he actually addresses nonconvex problems and he gets an algorithm like works well.",
            "If you're convex or non smooth or stochastic or whatever.",
            "So there are people working on that.",
            "The algorithms that work in every single case though tend not to be the fastest hours in specific cases and in practice we care about the algorithm works best for my problem, not for every problem.",
            "So there's definitely research in both directions.",
            "I think there's another question somewhere.",
            "Well, not free lunch program is not for optimization.",
            "For optimization, there's definitely free lunches.",
            "It's great.",
            "It's much nicer as a theorist."
        ],
        [
            "OK, so I mean if I was talking about any function as opposed to this specific class of functions, then there would be like a no free lunch thing where you can't beat dropping down random points in general.",
            "But because I'm making such strong assumptions I can actually get free lunches.",
            "Well, no, he still has assumptions, but he's trying to just think of all the ones you can possibly have."
        ],
        [
            "OK, so I want to get to this last thing which is which is finite sum problems.",
            "So that was the problem that we."
        ],
        [
            "Motivating we sense to Cassie and this 1 / T rate, but they need one gradient preparation and those rates can't be improved for general stochastic."
        ],
        [
            "Actives whereas the Terministic methods had this linear rate but they required ingredients preparation and the reason that you can get a faster rate, you can get it around the lower bound is because the number of data points you have is finite."
        ],
        [
            "So the question is for if you are minimizing finite sum, can we actually design A better method?",
            "Do we have to look at these two?"
        ],
        [
            "Dreams so back to this picture."
        ],
        [
            "We want to design something like this.",
            "And there's many ways you can think of doing that, like switching or growing the batch or whatever.",
            "We're actually going to get a method that actually has a better slope than the deterministic method by taking this."
        ],
        [
            "Perspective OK, so approach one is."
        ],
        [
            "Control the sample size.",
            "For grading method uses all in gradients stochastic gradient methods."
        ],
        [
            "What uses 1 using mini batch?",
            "You're kind of getting somewhere in between.",
            "For example in that constant step size rule that all of Alpha term is kind of also proportional to the batch size.",
            "So instead of decreasing your step size, you could also increase your batch size and get back to the exponentially converging.",
            "Or you can do that bars like bro in step or quasi Newton stuff, as long as you're increasing the batch size, sort of the deterministic methods work.",
            "It's kind of cheating."
        ],
        [
            "So."
        ],
        [
            "Perfect sample size."
        ],
        [
            "Rated sub linear but."
        ],
        [
            "Can increase the batch size and that's."
        ],
        [
            "Pretty common strategy, and you can actually choose to do that properly to get convergence rates if you want to sort of you start with something looks like a stochastic gradient method, but at the end it looks like a quasi Newton method."
        ],
        [
            "But that eventually requires full passes through the data, so it's really just sort of like hiding the fact, or maybe cleaning up the first iterations of the quasi Newton method.",
            "Can we really get a rate that has linear with just one gradient parameter?"
        ],
        [
            "And and this is work."
        ],
        [
            "Did with Nikola LaRue.",
            "Who's a former student of Joshua's as well as Francis Bach and it's called the stochastic average gradient so.",
            "This is your standard gradient step.",
            "On each iteration of SAG, we're going to take one random datapoint."
        ],
        [
            "It it's gradient and instead of."
        ],
        [
            "In those gradients there I'm going to put here the last gradient that I computed for function I.",
            "So we have this sort of weird memory where in each iteration I remember the gradient of every single training example, which seems crazy, but I'll say why it's not completely crazy in a moment, and then we compute a new one and replace the old one with the new one, and we're just going to assume that that's our true gradient."
        ],
        [
            "So, so that's a stochastic version of."
        ],
        [
            "They came before where they went through cyclically.",
            "It's really sort of, assuming that your gradients are not changing too quickly, but as you converge to the solution, they happen to not change very quickly because your ex is we're getting closer together, so your Lipschitz continuous gradient means that your gradients are getting closer together, so this becomes a good approximation as you go."
        ],
        [
            "So maybe the most technical slide today, which possibly should not be at the very end.",
            "But basically it gets a linear convergence rate with a constant that's actually very good."
        ],
        [
            "Hi, a lot better than you would expect, so we have a linear convergence rate.",
            "We just have to look at one function on each iteration so same cost as stochastic gradient method, but much faster convergence rate.",
            "If you're in this setting, the well conditioned setting it means you multiply your air by .8825 after each pass through the data, which doesn't seem great, but you go .825 to the 20.",
            "It gets fairly small, whereas the 1 / T can start getting slow in that regime.",
            "If you're in this case, if you have a hard optimization problem, the rate is actually almost as fast as if you were doing the gradient descent where you going through the full data set on each iteration, which I think is the kind of the fascinating part.",
            "This album really works for hard optimization problems."
        ],
        [
            "So just."
        ],
        [
            "Some numbers there."
        ],
        [
            "So gradient descent, the fastest known rate, looks like this for accelerated gradient.",
            "The Nesterov style method you get to this and optimization people really care about that rate, but but sag we cheat a little bit where we have a slower rate, but we can do N iterations for the cost of one of those methods, so we can actually raise the power N and get a much faster rate.",
            "And if I force you to go through the full data set in every iteration, this is."
        ],
        [
            "The fastest rate you can get, so it's faster than any black box method that goes through the full data set each time.",
            "So it's not only faster than stochastic gradient because it beats 1 / T, But for most deterministic gradient methods."
        ],
        [
            "Also faster."
        ],
        [
            "Another way to look at that as number of valuations to reach epsilon.",
            "So in stochastic case you've kind of got condition number divided."
        ],
        [
            "Epsilon gradient you've got condition number times log which is better, but then you multiply by N and then."
        ],
        [
            "Acceleration you put a square root and Max.",
            "You take the are inside.",
            "You take the Max of these two big numbers so the Max is going to be much smaller than the product.",
            "No.",
            "You're just assuming that there's a finite number of data points, and that you solve this Lipschitz continuous and the strong convexity assumption, but they can be from some weird distribution.",
            "There's no idea assumption here.",
            "That's right.",
            "Actually, yeah, so that's a good point.",
            "So here.",
            "And that's why it's a little bit hard to compare these.",
            "So in this rate L is actually the L for individual data points.",
            "So if you have one data point, that's really crazy.",
            "It's going to kind of screw things up for everything else, but if you have two distributions with the same L value, then the theory says it works the same.",
            "So you can have weird things happen.",
            "Almost no result applies in that setting, so bruticus and medics have some old results that apply in that setting, but they are not good, so we have very little analysis for that setting.",
            "I'll briefly mention something about that case shortly."
        ],
        [
            "OK, so we did.",
            "We did a lot of testing.",
            "We actually compared to some pretty serious methods like LB, FGS, Nesterov.",
            "We tune some stochastic grading methods like crazy and if you look at the appendix of our paper you'll see we actually compared to 14 different stochastic gradient methods including like Ada, Grad and all that stuff.",
            "But we're just showing the best ones, and when you add the new."
        ],
        [
            "Method on the plot.",
            "It works really well.",
            "This method works way better than I thought.",
            "I thought I was just going to theory paper, but it kind of made me rethink how we should actually solve problems in practice too.",
            "I was really surprised that it beat LBF Jess.",
            "I wasn't going to do that comparison but Nicola made."
        ],
        [
            "Do it.",
            "'cause I I didn't even imagine it would work better.",
            "OK, so there's been a whole bunch of subsequent the cascarones with linear rates.",
            "There's this stochastic dual, core descent, SVR G saga, miso."
        ],
        [
            "Is on there.",
            "Talk about SVG momentarily.",
            "The next thing would SVG in, while focus on is it doesn't have the memory requirement that the other methods have.",
            "And then I guess next time I'll talk about Nonsmooth problems.",
            "That's right, yeah, yeah, for sure.",
            "Yes, not every up to every training point.",
            "Yeah."
        ],
        [
            "OK, so that's what."
        ],
        [
            "Alan looks like and I just want to emphasize a few practical issues so you can add regularization if your data is sparse, it doesn't look like this is a sparse sequence of operations, but you can implement it in a sparse way.",
            "There's an automatic stepsize selection and a termination criterion, so there's no.",
            "There's no tuning.",
            "You can just tell the code off my web page an run it, and it just goes.",
            "There's no, you don't have to step size or anything.",
            "It figures out on its own there a little bit heuristic key, but there definitely less heuristically than the stuff you have to do when you have truly stochastic objective.",
            "There's also."
        ],
        [
            "Celerated versions, but two points on emphasize.",
            "One is the nonuniform sampling."
        ],
        [
            "So we had this question briefly about this reshuffling trick where you are and permanent pass through the data anaran permanent password."
        ],
        [
            "Data OK does that work better?",
            "For classic stochastic gradient methods, the answer is maybe.",
            "There's a whole lot of empirical evidence.",
            "In particular.",
            "Nice report by Lambeau 2 showing that it does seem to work better and there was a paper in 2012 showing if we can show a certain inequality is true, then it's actually true that that's faster than random.",
            "But this is a very complicated paper, so if you really like math and want a high impact result in, you're confident in your skills, try and prove that.",
            "Yeah.",
            "I.",
            "We actually saw a version is a little bit weird.",
            "I don't want to get into it, but you have to basically use agaza subroutine to solve another problem and then use a sequence of those to solve it.",
            "I don't know.",
            "No, people have not quite figured out how to do that.",
            "It's similar, but not the same.",
            "Yes, so doing you're doing going through all your data points in a random permutation and then switching it and doing another one.",
            "Yes.",
            "Yeah, so so the so the company that's actually the companies I've talked to.",
            "Two companies that are actually.",
            "What they do in practice, they don't want the random accesses, they do 2 random permutations and alternate between the two.",
            "And that seems to work OK."
        ],
        [
            "OK for stag it doesn't seem to actually help.",
            "It gets performance intermediate between cyclic and stochastic, which means it's not as good as stochastic.",
            "Some of the other algorithms that have come afterwards do seem to work with this and we have no idea why we actually know very little about this trick."
        ],
        [
            "One thing we do know a lot more about lately is nonuniform sampling, so we have a nice."
        ],
        [
            "The distribution.",
            "But you actually try and pick which data points you're going to sample more often.",
            "So for classic SG you can improve the constants.",
            "You can improve the dependence on Ellen Mu, but not the 1 / T rate."
        ],
        [
            "On for say, you can actually improve the rate, and the idea is the same.",
            "You're going to have Lipschitz constant for each function, so you're going to see each functions.",
            "Gradient has an ally and you sample proportional to those allies, so the gradients that change quickly.",
            "You want to sample them very often.",
            "The ones that change slowly.",
            "You don't want to marry often, and I'll answer that momentarily, but I just want to say for a lot of problems the big allies point class correspond to points you've classified well, and or at least when you start talking to local ally where's the small lies or points you haven't classified well.",
            "So what this is saying is.",
            "You don't want to sample the points.",
            "You've already classified very well very often because you've in some sense already got them, whereas the points you don't have.",
            "Well, you want to put more attention on them and that kind of just comes out of the math, which is nice.",
            "OK, go.",
            "Yeah, so yes, definitely there was an IP server last year, but it improves the dependence on Ellen Mu, but not on like the epsilon and the Sigma squared.",
            "So the dominant term doesn't get improved, but the sort of the optimization hardness term can get improved by this trick.",
            "The nice thing with sag is those two terms kind of mixed together so you can improve on everything and so so when you do this sample, you actually depend on the average of these Lipschitz constant instead of the worst function."
        ],
        [
            "Yeah.",
            "Yeah, so for logistic regression.",
            "Think of the Lipschitz constant is something that's way out there on the list logistic curve.",
            "If you're really well classified, then your slope is almost zero and your gradient doesn't change very quickly as you move, so the so the method actually just learns to start ignoring these data points or it samples them very, very rarely.",
            "I think this is something that could potentially be used in deep networks, is maybe trying to figure out which data points you should sample more often than others, and Yoshi has talked about this and various points in time.",
            "I've been coming to see far for many years.",
            "OK, so we're here stick to actually estimate those allies.",
            "You go so that you can try and figure out what you're doing as you go along.",
            "So we really want."
        ],
        [
            "Box type of things and these were two datasets from our experiments where we found that sag didn't work well in the sense that it achieved state of the art but didn't destroy state of the art."
        ],
        [
            "And the non uniform makes that so.",
            "But the the adaptive was really important though if you just sample portion of the global Lipschitz constant, it was like a minor improvement.",
            "But when you really trying to estimate these local ones you try and find out which points are well class."
        ],
        [
            "Spired then then it really helps.",
            "OK so I just want to."
        ],
        [
            "Um, we we have an estimate for each one, we just initialize it to one when we get to that data point, we take a step in the gradient direction for that point, and we know that the function value should change by a certain amount.",
            "If our Lipschitz constant is big enough.",
            "If it's not big enough, we just double it until it's big enough.",
            "The nice thing is, for linear models you can actually do this for free.",
            "There's there's no cost for linear models, would you?",
            "Yeah, well you you start reading you know your first pass through the data you're revisiting, like 60 or 40% of the data or something already so.",
            "I think it yeah it does take a while to kick in.",
            "That's a good point, but I haven't thought about how long that takes to kick in.",
            "That's a good point that I should really update my plots.",
            "'cause in the Journal version we actually do have the like the min and Max and the regions are actually non overlapping like the best run of these algorithms is better than the worst run of this algorithm.",
            "So, so in the general version we have those error regions, but this this here is just one run.",
            "Slower.",
            "So do you.",
            "I wouldn't say a lot more.",
            "It's definitely a small constant factor.",
            "I mean, there's just a few other extra arithmetic operations.",
            "I mean, assuming like some nice model of computation, where different implementations aren't using different tricks, then then it's almost the same.",
            "Yeah, I mean, so the stochastic grading methods would definitely be a little bit faster.",
            "This would be a little bit slower.",
            "Some of the other methods like would also be slower too, and I think LBF's would be quite a bit faster 'cause that would use vectorized computation more effectively, 'cause it's embarrassingly parallel, but the I have I don't have this one, but on the subsequent paper we do have runtime plots and it didn't change any conclusions.",
            "Yeah, I think I've got 2."
        ],
        [
            "I'd left, I just want to mention mini batching.",
            "What am I at?",
            "One minute?",
            "OK, I think I have two slides reasons to use mini batch with sag."
        ],
        [
            "You can parallelize the gradient calculation.",
            "You can decrease the memory.",
            "You can also increase the convergence rate."
        ],
        [
            "So the convergence rate depends on the Lipschitz constants of the batches.",
            "If you can make the Lipschitz constant, the batch is much smaller than the worst Lipschitz constant.",
            "The algorithm converges faster, so you can imagine finding these these bad training examples and putting them in batches with good training examples you can prove that actually makes you go faster.",
            "How do that?",
            "Optimally, I don't quite know other than that heuristic."
        ],
        [
            "Big and small trick.",
            "To deal with them."
        ],
        [
            "Only there's a few ways you can use me."
        ],
        [
            "Batches linear models CRF's it works fine."
        ],
        [
            "If those."
        ],
        [
            "Don't work, you should you."
        ],
        [
            "Just PRG."
        ],
        [
            "And I'll just put this up here.",
            "So one thing I'll say is the practical issues are very similar to say you can talk about acceleration, automatic step size, determination, sparsity regularization, nonuniform sampling, mini batches and so on.",
            "The key difference between Saginaw CRG is that SVG does not require the gradient of every example.",
            "It just requires storing 1 old parameter vector and doing.",
            "Two gradient evaluations on each iteration, so you need to evaluate the old parameter vector and the new parameter vector.",
            "It's a little bit slower, but it gets rid of the memory, so now you can apply it to any problem you want.",
            "I'll talk a little bit more about this next time, but again, it's a very simple algorithm.",
            "You can implement this out.",
            "This is this afternoon.",
            "Try it on whatever problem you want.",
            "Constant stepsize.",
            "You know, fairly easy to tune."
        ],
        [
            "OK, so just to summarize part one."
        ],
        [
            "You need to know L or you need to have an approximation of L and so we do that same trick where we start with one and we increase it.",
            "If the inequality is we want to be satisfied or not satisfied."
        ],
        [
            "OK, so convex functions have special properties that let us efficiently minimize them.",
            "Grading methods are good for high dimensions.",
            "Stochastic rating methods are good for large training examples, but you have a slower rate.",
            "And then for finite datasets, sag sort of fixes the convergence rate, but introduces the memory.",
            "An SVG fixes that."
        ],
        [
            "Mary Ann so tomorrow will talk about non smooth test error and non convex problems."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so First off, thanks to the organizers for inviting me.",
                    "label": 0
                },
                {
                    "sent": "It's always fun to come out to Montreal and like Escape the Vancouver rain.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "I always like coming here 'cause you learn like so many different things in the deep learning.",
                    "label": 0
                },
                {
                    "sent": "People are always doing amazing applications and like the last few days, it's just like tremendous what's happening in this area.",
                    "label": 0
                },
                {
                    "sent": "But as you mentioned, I kind of I'm only working on this sort of stuff recently.",
                    "label": 0
                },
                {
                    "sent": "We've got a few projects in our lab, but we mostly just do optimization proofs.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to start with the first lecture talking about very easy problems in the sense that they are smooth, finite and convex.",
                    "label": 1
                },
                {
                    "sent": "So these are problems that we can solve in polynomial time, and more recently we can solve very very large instances in polynomial time.",
                    "label": 0
                },
                {
                    "sent": "And the reason I want to talk about this is because there I think there's a few very exciting developments in the last three years which potentially have applications in applications that you're interested in.",
                    "label": 0
                },
                {
                    "sent": "Tomorrow we're going to basically take the negation of this.",
                    "label": 0
                },
                {
                    "sent": "We're going to talk about non smooth, non finite and non convex and see what changes what extra challenges arise there weather what are things that you need to think about.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so I think I can more or less skip the motivation.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You can we.",
                    "label": 0
                },
                {
                    "sent": "We've heard all week about how you can use these big datasets.",
                    "label": 1
                },
                {
                    "sent": "You can fit these big models.",
                    "label": 1
                },
                {
                    "sent": "An optimization seems to be a crew.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So part of this, so a common framework we think about is empirical risk minimization.",
                    "label": 1
                },
                {
                    "sent": "Usually we have some data fitting term, so I'm going to use X as in R to the DD as your dimension.",
                    "label": 0
                },
                {
                    "sent": "X is your parameters.",
                    "label": 0
                },
                {
                    "sent": "You might have some inputs, AI and outputs BI, or possibly just inputs loss, L, and then you often have a regularizer too, so the regularizer has not been talked about as much in the lectures, but it's often there so we have N observations and we're just going to talk about finding the optimal parameters X star, and we're really talking about this in the mathematical sense.",
                    "label": 1
                },
                {
                    "sent": "Of we want to really find the globally optimal parameters.",
                    "label": 0
                },
                {
                    "sent": "We want to minimize this.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Function.",
                    "label": 0
                },
                {
                    "sent": "So you can talk, put almost anything in this framework.",
                    "label": 0
                },
                {
                    "sent": "Everything from L2 regularizer, least squares, conditional random fields and a lot of the deep neural network models will also fit in this framework.",
                    "label": 1
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the practical challenges are designing or learning good features or efficiently solving the problem.",
                    "label": 0
                },
                {
                    "sent": "When energy are very large.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So why think about large scale optimization?",
                    "label": 0
                },
                {
                    "sent": "Well, optimization is the core of a lot of machine learning models.",
                    "label": 1
                },
                {
                    "sent": "Most of the models we've seen talked about during during the summer school have been based on optimization algorithms.",
                    "label": 0
                },
                {
                    "sent": "And you can't really solve huge problems with traditional methods, so we've seen.",
                    "label": 1
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A lot of stochastic gradient in particular to solve large problems.",
                    "label": 0
                },
                {
                    "sent": "OK, so why do I want to focus on convex optimization to start with?",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, these are among the only efficiently solvable continuous problems, and I'll say what I mean by that in a moment.",
                    "label": 0
                },
                {
                    "sent": "But these are problems we can solve in polynomial time.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You can also do a lot with convex models, so there's a lot of models in machine learning that are convex and a lot of the empirically effective non convex methods are based on methods with good properties.",
                    "label": 1
                },
                {
                    "sent": "For convex functions.",
                    "label": 0
                },
                {
                    "sent": "You can also talk about the converse of that where if you really want to get to a local minimum then near local minimum your function will look like a convex function.",
                    "label": 0
                },
                {
                    "sent": "So if you design A method that doesn't have good properties for convex functions you wouldn't expect it to have nice properties for non convex functions either.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the thing that I'll talk about in Part 2 is a lot of the tools from convex analysis are being extended to non convex functions.",
                    "label": 0
                },
                {
                    "sent": "So there's a few tools that have been developed in this very special, smooth, finite convex case that it's now we've now realized we can apply to nonsmooth, nonconvex and or non finite prob.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Testing the audience.",
                    "label": 0
                },
                {
                    "sent": "How hard is this problem?",
                    "label": 1
                },
                {
                    "sent": "I have some function F of XI.",
                    "label": 0
                },
                {
                    "sent": "Haven't told you anything about it.",
                    "label": 0
                },
                {
                    "sent": "You have parameters X real space R to the D. You can use whatever you want, except you can't use an Oracle that tells you the answer.",
                    "label": 0
                },
                {
                    "sent": "How long does it take you to solve this problem?",
                    "label": 0
                },
                {
                    "sent": "I heard a few.",
                    "label": 0
                },
                {
                    "sent": "Yeah, you don't.",
                    "label": 0
                },
                {
                    "sent": "You don't have to get the solution.",
                    "label": 0
                },
                {
                    "sent": "You just have to be within within epsilon of the best F of X.",
                    "label": 0
                },
                {
                    "sent": "Lot of people talking once.",
                    "label": 0
                },
                {
                    "sent": "OK so I heard some I heard some exponential.",
                    "label": 0
                },
                {
                    "sent": "I heard some forever.",
                    "label": 0
                },
                {
                    "sent": "The correct answer is actually forever.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So you can't actually solve this problem.",
                    "label": 0
                },
                {
                    "sent": "I can design A function that's basically flat everywhere, and then it's infinitely small at some arbitrary real value decimal expansion and then you can just never find it.",
                    "label": 0
                },
                {
                    "sent": "Whatever algorithm you give me, I just add one extra decimal place to make sure your algorithm never actually finds it.",
                    "label": 1
                },
                {
                    "sent": "So to even talk about solving optimization problems, you need to start making some sort of assumptions.",
                    "label": 1
                },
                {
                    "sent": "Usually these come in in the form of Lipschitz continuous assumptions, so either assume that your function or radiant, or your Hessian or something doesn't change too quickly.",
                    "label": 1
                },
                {
                    "sent": "So if you do it on your function, we say that the absolute value of the function can't change by more than L as you change the parameters.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So as a picture, I've got my function here.",
                    "label": 0
                },
                {
                    "sent": "And if I evaluate some point.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then this L gives me the slope of two lines.",
                    "label": 0
                },
                {
                    "sent": "And what this inequality tells me?",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is that if I just know my function at this point, the other function values have to lie in this sort of mauve area on this projector?",
                    "label": 0
                },
                {
                    "sent": "So when you start to make assumptions like this, now you can narrow down things.",
                    "label": 0
                },
                {
                    "sent": "Now it's not an impossible problem anymore because I can't make something arbitrarily low.",
                    "label": 0
                },
                {
                    "sent": "It can't be lower than this line.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then if I can maybe get another point, I can narrow down the space even more.",
                    "label": 0
                },
                {
                    "sent": "And as you go along, you can start to narrow down.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The solution would be.",
                    "label": 0
                },
                {
                    "sent": "So if you make that assumption.",
                    "label": 0
                },
                {
                    "sent": "There's a worst case bound that you can.",
                    "label": 0
                },
                {
                    "sent": "Well, there's there's an upper and a matching lower bound, so if you have that assumption you can now apply a sort of a grid search where you actually like.",
                    "label": 0
                },
                {
                    "sent": "Explicitly explore the entire space in high dimensions and you can eventually find that epsilon optimal solution.",
                    "label": 0
                },
                {
                    "sent": "There's also a matching lower bound, which is this rate, so let's take 1 / T to the 1 / D. So this is a very bad rate if you're in high dimensions.",
                    "label": 0
                },
                {
                    "sent": "So 1 / T is already not very nice, but raising that to the power of the dimension it makes means that this is going to take an extremely long time.",
                    "label": 0
                },
                {
                    "sent": "This is a crazy exponential runtime.",
                    "label": 0
                },
                {
                    "sent": "Um, another thing is OK, so there's a lot of.",
                    "label": 0
                },
                {
                    "sent": "Results for non convex elements.",
                    "label": 0
                },
                {
                    "sent": "We have convergence rates that are actually even slower than this and I want to point out how absurd that is because if you actually just search for random points and then take the best one, you also get this convergence rate in expectation.",
                    "label": 0
                },
                {
                    "sent": "So you should you see convergence rates lower than this, you should be very uh.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Happy with it.",
                    "label": 0
                },
                {
                    "sent": "OK, so the point I want to make with this slide is optimization can actually be very hard in the general case.",
                    "label": 0
                },
                {
                    "sent": "But as soon as you start making assumptions, it makes a big difference.",
                    "label": 0
                },
                {
                    "sent": "So we went from an absolutely impossible problem to a problem that we can solve very slowly by just making one simple assumption.",
                    "label": 0
                },
                {
                    "sent": "And this is sort of where convexity is going to come in.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Other generalizations of that.",
                    "label": 0
                },
                {
                    "sent": "So a convex function is a function satisfying this inequality.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It is easier to show it by pictures, so if you.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Somefunction we have two points.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A convex function is always below the line between the two points, so I evaluate F of X&F of Y and if I evaluate the function at any point between X of what X&Y, the function is going to be below this line.",
                    "label": 0
                },
                {
                    "sent": "It's a very simple definition, but the nice implication of that is that if you have a local minima, it's a global minima.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The point between.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this would be a non convex function where you.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you have two points, the function is actually above, so that's non convex and that means you can have non global local minima.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A second characterization of convexity is by this sort of tangent.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Asian.",
                    "label": 0
                },
                {
                    "sent": "And what it means is that convex functions are.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Are basically above their tangent everywhere.",
                    "label": 0
                },
                {
                    "sent": "So if I take an F of X.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And I draw a line which is this F of X plus this linear term.",
                    "label": 0
                },
                {
                    "sent": "Then the function is always above it, so you can always sort of find a lower bound to your function everywhere.",
                    "label": 0
                },
                {
                    "sent": "Once you have a point and a derivative.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And from that you can easily see that if the gradient is zero that you are global minimum 'cause if I'm here and the tangent to zero, that means the function is above that line everywhere.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There's a third characterization of convexity for twice differentiable functions, and that's the Hessian always has non negative eigenvalues and this is maybe less nice from a geometric perspective.",
                    "label": 0
                },
                {
                    "sent": "It just means that the function is curved upwards in every direction at every point, but this is usually the easiest way to show that a function is convex.",
                    "label": 1
                },
                {
                    "sent": "If you're not sure that a function is convex and you want to try and prove it often, you can just take the second derivatives and show that those are never negative.",
                    "label": 0
                },
                {
                    "sent": "Are we happy with convex functions?",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That makes sense.",
                    "label": 0
                },
                {
                    "sent": "OK, so there's a whole bunch of simple convex functions.",
                    "label": 0
                },
                {
                    "sent": "You can basically just memorize the list.",
                    "label": 0
                },
                {
                    "sent": "These are the ones that occur most often and we've got linear functions, quadratic functions, sort of exponential Max functions, norms and norm squared.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There's some more exotic things like the log, some exponential log determinants, and these linear quadratic race.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Shows there's a bunch of operations that preserve convexity, so you can take a non negative weighted sum.",
                    "label": 0
                },
                {
                    "sent": "You can take a linear or convex function of a linear function will still be convex, or you can take the maximum of convex functions that's also.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sex.",
                    "label": 0
                },
                {
                    "sent": "So if you want to show that some more complicated functions are convex, usually just compose them with these simple operators.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So, so that function.",
                    "label": 0
                },
                {
                    "sent": "We know that this is a norm, and so it follows from this second rule.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or if you want to show it.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "SVM's are convex.",
                    "label": 0
                },
                {
                    "sent": "Well, this term is the norm squared.",
                    "label": 0
                },
                {
                    "sent": "These two are linear functions.",
                    "label": 0
                },
                {
                    "sent": "You take the Max and you take a non negative weighted sum.",
                    "label": 0
                },
                {
                    "sent": "So with these rules you can show the lot of things or convex.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so I don't want to go too much more into the details of convex functions 'cause I actually want to get into methods which are which are more of interest, but I just want to go over that to sort of introduce notation and to set the stage for what we're talking about.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so there's these things called interior Point methods which can solve convex problems in polynomial time.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to talk about these too much, but this is nice in computer science.",
                    "label": 0
                },
                {
                    "sent": "We want problems that we can solve in polynomial time.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But usually those have a D squared or worse cost per iteration.",
                    "label": 0
                },
                {
                    "sent": "So if you have if you have a billion variables, these are very expensive.",
                    "label": 0
                },
                {
                    "sent": "Even just to do one iteration.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Yeah, so usually there will be an end in there may not be N squared, so usually you can pick either D squared or N ^2.",
                    "label": 0
                },
                {
                    "sent": "We",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Whichever is smaller.",
                    "label": 0
                },
                {
                    "sent": "So that's sort of cause renewed interest in gradient methods, so grading methods have been used in the deep learning literature like forever.",
                    "label": 1
                },
                {
                    "sent": "But it's only recently that in convex optimization people realized that we really consider gradient methods there too.",
                    "label": 1
                },
                {
                    "sent": "Just 'cause they have a better scaling with the dimension.",
                    "label": 0
                },
                {
                    "sent": "So the methods are very simple.",
                    "label": 0
                },
                {
                    "sent": "We have XT stepsize, Alpha T, Anna gradient FXT and we use that to generate a new iteration XD plus one, so I'm assuming you've seen this many times over the past two weeks, but I just wanted to show it to sort of.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Read the notation I'm.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the nice thing is we have the cheap iteration cost, but there's a tradeoff, because now you're going to need more iterations and the question is, do we lose this polynomial time guarantee when we go to gradient method instead?",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of Interior point style methods.",
                    "label": 0
                },
                {
                    "sent": "So let's consider one of the sort of test problems in the convex world of machine learning, which is L2 regularizer, logistic regression.",
                    "label": 0
                },
                {
                    "sent": "This is a simple binary classification model.",
                    "label": 0
                },
                {
                    "sent": "The objective is convex.",
                    "label": 0
                },
                {
                    "sent": "That first term is Lipschitz continuous.",
                    "label": 0
                },
                {
                    "sent": "The second term is not Lipschitz continuous.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But the assumptions you have which you often have are that the eigenvalues of the Hessian are bounded above by a positive constant, so that's a very reasonable assumption.",
                    "label": 0
                },
                {
                    "sent": "That's almost always true.",
                    "label": 0
                },
                {
                    "sent": "I believe that's even true for almost all deep.",
                    "label": 0
                },
                {
                    "sent": "Well, I don't know about recurrent networks, but the standard feedforward networks that's definitely true.",
                    "label": 0
                },
                {
                    "sent": "And then this is so much stronger assumption.",
                    "label": 0
                },
                {
                    "sent": "This is called strong convexity.",
                    "label": 0
                },
                {
                    "sent": "So for the.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Aggression that satisfies this, but you often have those.",
                    "label": 0
                },
                {
                    "sent": "Where muse greater than zero?",
                    "label": 0
                },
                {
                    "sent": "Yeah, so you often have it for some you, but we are worried about them.",
                    "label": 1
                },
                {
                    "sent": "You greater than zero case here.",
                    "label": 1
                },
                {
                    "sent": "So we're saying that the gradient is Lipschitz continuous is equivalent to that, and this mu greater than zero, which bounds the eigenvalues.",
                    "label": 0
                },
                {
                    "sent": "That's called a strongly convex function.",
                    "label": 0
                },
                {
                    "sent": "That's right, so so this is a notation meaning that the eigenvalues of this are less than or equal to L. All the animals are lessening with L, which is often written like this in sort of the convex books.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, So what are those assumptions give us?",
                    "label": 0
                },
                {
                    "sent": "The Lipschitz continuous gradient, so this is going to be.",
                    "label": 0
                },
                {
                    "sent": "This is going to be true on this slide for any Lipschitz continuous function, which includes feedforward networks.",
                    "label": 0
                },
                {
                    "sent": "I've never proved that, but I'm almost sure that it's true.",
                    "label": 0
                },
                {
                    "sent": "OK, so from Taylor's theorem we have this inequality.",
                    "label": 0
                },
                {
                    "sent": "This is the 2nd order Taylor's theorem.",
                    "label": 0
                },
                {
                    "sent": "I've written new innovative.",
                    "label": 0
                },
                {
                    "sent": "OK, yeah, so definitely.",
                    "label": 0
                },
                {
                    "sent": "If you stay on a compact set then your if your weights don't get too big then it's definitely true.",
                    "label": 0
                },
                {
                    "sent": "OK, so normally will talk about having a third order term or something that, but there's also a version related to like the mean value theorem, which is that for some value of the Hessian between X&Y, this is going to hold with equality.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And now you're going to use that Lipschitz assumption to bound this second term.",
                    "label": 0
                },
                {
                    "sent": "So if you have the email, then you're bounded by Li.",
                    "label": 0
                },
                {
                    "sent": "Then I can think of the worst direction, y -- X, and that that can be at most L times the difference between y -- X.",
                    "label": 0
                },
                {
                    "sent": "So what this says is when you have the Lipschitz continuous gradient, you can use Taylor expansion to get this global upper bound on the function value.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And you can think of just setting your next iteration to the minimizer of that upper bound.",
                    "label": 0
                },
                {
                    "sent": "This is like em.",
                    "label": 0
                },
                {
                    "sent": "You make an upper bound, you go to the minimum of it.",
                    "label": 0
                },
                {
                    "sent": "So if you plug that value back into this equation, you see that these two terms start to cancel out and you get something that looks like this and what it means is.",
                    "label": 0
                },
                {
                    "sent": "If you use gradient descent with a step size of 1 / L, you actually guaranteed to decrease the objective function, so there's no line search or anything.",
                    "label": 0
                },
                {
                    "sent": "This is just because the Hessian or the gradient can't change too quickly if you use the step size, you're guaranteed that the objective function goes down, and strictly so if you're not at the minimizer.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So as a picture you at some point X and you have.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Function F of X.",
                    "label": 0
                },
                {
                    "sent": "This was our first order term.",
                    "label": 0
                },
                {
                    "sent": "The first 2 terms in our Taylor expansion, which we said are always below the function.",
                    "label": 0
                },
                {
                    "sent": "But then because you have, you know the gradient doesn't change too quickly.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can make this blue thing, which is an upper bound on the function.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then you can think of moving to the minimizer of that function to get your new your new editor.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or as a 2D picture, we always see the gradient descent is always moving inside the level curves of a function and making steady progress towards the optimum.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so that will be true even for non convex problems.",
                    "label": 0
                },
                {
                    "sent": "That's just the property of the Lipschitz continuous gradient, so strong convexity lets us go in the other direction.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We're now going to say the eigenvalues.",
                    "label": 0
                },
                {
                    "sent": "Will they have to be at least knew times I and that lets us turn the inequality around and get an upper bound or lower bound that depends on you.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So is a pig.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sure, it's kind of the same.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This before, but now we've got this red function that's always below our function, so we know that we can't really go too far below where we are now.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you minimize both sides of this inequality, you get an inequality that looks like this, so it's roughly saying that the solution can't be too far down from where we are now.",
                    "label": 0
                },
                {
                    "sent": "Depending on the current function value in the current gradient.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And once you have those two assumptions, it actually lets you show that you get what's called a linear convergence rate.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So you put those.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Inequality is to get.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here you have this guaranteed progress coming from the Lipschitz continuous prop.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And you have that you can only go so far because of strong convexity.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's what's going to let.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You got a convergence rate, so if you put those two together, you subtract F of X star from both sides.",
                    "label": 0
                },
                {
                    "sent": "You get something that looks like this, so my suboptimally an iteration T plus one is the suboptimality an iteration T times this property 1 minus me over L&L overview is often called the condition number of the problem.",
                    "label": 0
                },
                {
                    "sent": "This tells you how hard the problem is to solve or or how much the.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Problem changes in some sense.",
                    "label": 0
                },
                {
                    "sent": "And if we apply that inequality over and over and over again, going back to X zero, we get this quantity raised to the power T. So each time you run an iteration of gradient descent, you're multiplying your error by some fixed amount.",
                    "label": 0
                },
                {
                    "sent": "Now one thing I want to point out is this is dimension independent.",
                    "label": 0
                },
                {
                    "sent": "There's no, there's no D here, so D indirectly affects me in L. But in principle, if you and L is constant, you can solve billion dimensional problems for the same number of iterations as you can solve 2 dimensional problems.",
                    "label": 0
                },
                {
                    "sent": "So people really like that.",
                    "label": 0
                },
                {
                    "sent": "If you were always close to one, this can be very fast.",
                    "label": 0
                },
                {
                    "sent": "If it's close to 0, this can be very slow, and this is in some sense a polynomial time runtime, because if you want an extra.",
                    "label": 0
                },
                {
                    "sent": "Digit of accuracy.",
                    "label": 0
                },
                {
                    "sent": "You make you multiply the number of iterations G by some constant amount.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, what if we don't have their regularizer?",
                    "label": 0
                },
                {
                    "sent": "What if we're not strongly convex, but we're just convex.",
                    "label": 0
                },
                {
                    "sent": "This is supposed to be easy, right?",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, it changes things, so we're still convex, so we still have the.",
                    "label": 0
                },
                {
                    "sent": "The eigen values are greater than zero greater than or equal to 0.",
                    "label": 0
                },
                {
                    "sent": "But we don't have that lower bound anymore.",
                    "label": 0
                },
                {
                    "sent": "Now we have a linear.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Lower bound so.",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Instead of that nice red line that curved back up and made sure minimum was finite.",
                    "label": 0
                },
                {
                    "sent": "Now we just know that the function is above this green line and that leads us to some kind of weird.",
                    "label": 0
                }
            ]
        },
        "clip_80": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Cases.",
                    "label": 0
                }
            ]
        },
        "clip_81": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if you just have that assumption, you get what's called a sublinear convergence rate, so your suboptimality iteration T is going to be some constant Times 1 / T Now.",
                    "label": 0
                },
                {
                    "sent": "This is way faster than a general nonconvex problem, right?",
                    "label": 0
                },
                {
                    "sent": "We don't have this negative 1 / D. We just have 1 / T so we don't have the dimension dimension dependence, but this is in some sense not really a polynomial runtime.",
                    "label": 0
                },
                {
                    "sent": "If you want to get one more digit of accuracy, you might have to do 10 times as many iterations as you did before.",
                    "label": 0
                },
                {
                    "sent": "If you want two more digits of accuracy, you might have to do 103 more digits 1000 and so on.",
                    "label": 0
                },
                {
                    "sent": "So this is this is less appealing and so I just want to emphasize that the linear convergence rate is.",
                    "label": 0
                },
                {
                    "sent": "Is.",
                    "label": 0
                }
            ]
        },
        "clip_82": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A bit nicer than the sublinear convergence rate.",
                    "label": 1
                },
                {
                    "sent": "And in machine learning.",
                    "label": 0
                },
                {
                    "sent": "That's right, so that's my next point here is that if you have a convex function, you can always add a regularizer.",
                    "label": 0
                },
                {
                    "sent": "So if you add the two norm squared, it actually strictly increases that new value by Lambda.",
                    "label": 0
                },
                {
                    "sent": "So if you have a convex function and this actually should be Lambda over 2, then you is at least Lambda an you might have extra strong convexity from your function, but you can always do that.",
                    "label": 0
                },
                {
                    "sent": "There's a second reason that machine learning.",
                    "label": 0
                },
                {
                    "sent": "We probably don't care about this result, and I'll get to that when I start talking about non convex functions, because actually for almost every convex function you'll ever encounter in machine learning, you can prove the faster rate from the last slide, and so I'll get to that part.",
                    "label": 0
                }
            ]
        },
        "clip_83": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Tomorrow OK, so that's some theoretical issues, but in practice you never use this 1 / L. What do you actually use?",
                    "label": 0
                },
                {
                    "sent": "So there's these things called line searches which actually work much better and they don't require that you know that value.",
                    "label": 0
                }
            ]
        },
        "clip_84": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "L. So the basic one is in Armillo backtracking line search.",
                    "label": 0
                },
                {
                    "sent": "You just start with some big step size and you start dividing it until some inequality that looks like what you want is satisfied.",
                    "label": 0
                },
                {
                    "sent": "You just want to make sure you decrease the function by a little bit more than what the grey.",
                    "label": 0
                }
            ]
        },
        "clip_85": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It tells you you can.",
                    "label": 0
                },
                {
                    "sent": "Then there's more fancy things like the Wolf conditions, which make sure the step sizes don't get too small, and if you implement these properly, usually really only need about one evaluation per iteration, so there's some people think that line searches take many.",
                    "label": 0
                },
                {
                    "sent": "Evaluation of the function preparation.",
                    "label": 0
                },
                {
                    "sent": "But if you do it properly, you can really avoid that.",
                    "label": 0
                }
            ]
        },
        "clip_86": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another thing to mention in practice.",
                    "label": 0
                },
                {
                    "sent": "The intuition is you can do a clever initialization, Anna clever selection of the points you evaluate along the line.",
                    "label": 0
                },
                {
                    "sent": "So for example, let's say you tried some step size and it failed.",
                    "label": 0
                },
                {
                    "sent": "Well, you actually value the function.",
                    "label": 0
                },
                {
                    "sent": "At that point you had the function of the old point and the gradient at that point.",
                    "label": 0
                },
                {
                    "sent": "Now you can fit a quadratic function through all those pieces of information and move to the minimum of that.",
                    "label": 0
                },
                {
                    "sent": "If you also like the gradient at the new point, now you can fit a cubic function and move to the middle of that an.",
                    "label": 0
                },
                {
                    "sent": "If, once you do these tricks, you can actually avoid a lot of the line search iterations.",
                    "label": 0
                },
                {
                    "sent": "It's called Hermite interpolation or something.",
                    "label": 0
                }
            ]
        },
        "clip_87": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "No yeah Hermite tribulation OK, but usually the number one reason this fails is because your rating code is wrong and I don't mean you as in like a general sense, I'm saying you're not good at coding gradients.",
                    "label": 0
                },
                {
                    "sent": "I'm including myself and more.",
                    "label": 0
                },
                {
                    "sent": "You know all inclusive sense.",
                    "label": 0
                },
                {
                    "sent": "Usually your derivative code is wrong the first time you try it, you should actually check your derivative code.",
                    "label": 1
                },
                {
                    "sent": "Finite difference is one way to do it.",
                    "label": 0
                },
                {
                    "sent": "If you have a really big complicated model that's very high dimensional and you're worried something weird is happening.",
                    "label": 1
                },
                {
                    "sent": "In high dimensions, there's this nice trick from Nicola Leroux, which just says just take some random direction and you can evaluate the directional derivative along that random direction, not on some sense.",
                    "label": 0
                },
                {
                    "sent": "Check all your coordinates at once with just two function evaluations instead of.",
                    "label": 0
                },
                {
                    "sent": "Checking all N function evaluations.",
                    "label": 0
                },
                {
                    "sent": "Yes, yes, that's right.",
                    "label": 0
                },
                {
                    "sent": "So if you go in both directions and then you can go like 4 function evaluations and things like that too.",
                    "label": 0
                },
                {
                    "sent": "But going to two usually gives you much more precision than one.",
                    "label": 0
                }
            ]
        },
        "clip_88": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so it's gradient method in optimal 1st order method.",
                    "label": 1
                },
                {
                    "sent": "The answer is no.",
                    "label": 0
                },
                {
                    "sent": "So Nesterov's method has been mentioned a few.",
                    "label": 0
                }
            ]
        },
        "clip_89": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Times here.",
                    "label": 0
                },
                {
                    "sent": "So the gradient method has this 1 / T rate for convex functions, and Nesterov's method gets you to 1 / T ^2.",
                    "label": 1
                },
                {
                    "sent": "For strongly convex it improves you from 1 minus mover L to 1 minus square root of me over L. Mu overalls are number less than one, so taking the square root makes it bigger.",
                    "label": 0
                },
                {
                    "sent": "And so that means that this is a faster rate.",
                    "label": 0
                }
            ]
        },
        "clip_90": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So Nesterov's accelerated gradient method looks like this.",
                    "label": 1
                },
                {
                    "sent": "It looks almost exactly like momentum or what's called the heavy ball method, an conjugate gradient.",
                    "label": 1
                },
                {
                    "sent": "I think you change around the few of the X is unwise, but the form is roughly the same and the ideas are roughly the same.",
                    "label": 0
                },
                {
                    "sent": "And the nice thing about Nestor's method is it's nearly optimal if you want a dimension independent algorithm.",
                    "label": 0
                },
                {
                    "sent": "So if you want an algorithm that doesn't depend on how many variables you have in the convergence rate.",
                    "label": 0
                },
                {
                    "sent": "These are almost the best that you can do.",
                    "label": 0
                },
                {
                    "sent": "There's not much hope for a better algorithm unless you make more assumptions about the function, so that's a very nice.",
                    "label": 0
                }
            ]
        },
        "clip_91": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Property.",
                    "label": 0
                },
                {
                    "sent": "But for logistic regression, a lot of a lot of other losses you can actually get linear convergence without the strong convexity.",
                    "label": 0
                },
                {
                    "sent": "So in optimization they really care about this 1 / T versus 1 / T squared rate.",
                    "label": 0
                },
                {
                    "sent": "But actually it's this difference.",
                    "label": 0
                },
                {
                    "sent": "That's the more important one.",
                    "label": 0
                },
                {
                    "sent": "In machine learning we almost never have a general convex function where the 1 / T style rates would apply.",
                    "label": 0
                }
            ]
        },
        "clip_92": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And now I'll just mention Newtons method which has been mentioned a few times in the summer school too.",
                    "label": 0
                },
                {
                    "sent": "So here we're taking the 2nd order step where we solve this Newton system.",
                    "label": 0
                },
                {
                    "sent": "We find a direction DT and take a step in that direction.",
                    "label": 0
                }
            ]
        },
        "clip_93": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That's equivalent to minimizing some sort of quadratic approximation, so it's the same as before, except for it's not really an inequality here, it's an approximation, and we're using a norm that's based on our Hessian instead of just the Euclidean norm.",
                    "label": 0
                },
                {
                    "sent": "And I'll talk next time about things where you actually try and put the 3rd order term here, and that those are actually a little bit more elegant an I wish they would have been invented before Newton's method, 'cause the sort of the classical development of Newton's method is very ugly and lead to things like line search and trust regions and stuff.",
                    "label": 1
                },
                {
                    "sent": "And in 2006 there was a much more elegant method invented that should have been invented 1st and makes life so.",
                    "label": 0
                }
            ]
        },
        "clip_94": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Much simpler.",
                    "label": 0
                },
                {
                    "sent": "Also very nice if you want to talk about saddle points.",
                    "label": 0
                },
                {
                    "sent": "OK, so we can generalize the army oh condition to Newtons method with something like that and Newtons method has a sort of a natural step length of 1, so usually you just try a step length of 1 and you hope that that works.",
                    "label": 0
                },
                {
                    "sent": "That's always going to work when you're close to a minimizer.",
                    "label": 0
                }
            ]
        },
        "clip_95": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what is newtons?",
                    "label": 0
                }
            ]
        },
        "clip_96": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Would look like.",
                    "label": 0
                }
            ]
        },
        "clip_97": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So our gradient method looks like that or we have some point or minimum is here.",
                    "label": 1
                },
                {
                    "sent": "We're going into the board.",
                    "label": 0
                },
                {
                    "sent": "You're moving sort of perpendicular to the level curves your function, which is not a great.",
                    "label": 0
                }
            ]
        },
        "clip_98": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Direction of progress here and Noone's method you can think of as making some sort of quadratic approximation.",
                    "label": 0
                }
            ]
        },
        "clip_99": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You're going to move to the minimum of the quadratic approximation.",
                    "label": 0
                },
                {
                    "sent": "This blue function, which you're hoping approximates your original red function, and here it makes much more prob.",
                    "label": 0
                }
            ]
        },
        "clip_100": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Russ so in terms of convergence rate, if you assume you're strongly convex and you assume that the Hessian is Lipschitz continuous, then Newtons method has what's called a super linear rate when you're near the solution.",
                    "label": 0
                },
                {
                    "sent": "So you get something that looks like this, but instead of having a fixed value here you have some sequence of values, row T that converges to 0.",
                    "label": 0
                },
                {
                    "sent": "So the longer you run it, the faster it gets, which is a very nice property, so.",
                    "label": 0
                },
                {
                    "sent": "If you can afford to use that style of method, you probably should.",
                    "label": 0
                }
            ]
        },
        "clip_101": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You often can't, though, because you have to solve this sort of system.",
                    "label": 0
                },
                {
                    "sent": "There is a variant called Cubic Regularization which I'll talk about next time, which will let you get global convergence rates and also certain solve certain nonconvex problems.",
                    "label": 0
                }
            ]
        },
        "clip_102": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now there are practical versions of Newton like methods, so one thing you can do is you can only use the diagonal of the Hessian, which is equivalent to just having a step size for each dimension.",
                    "label": 0
                },
                {
                    "sent": "There's bars libro in which is a very cute algorithm which just uses this as the step size, and it's kind of magical.",
                    "label": 0
                },
                {
                    "sent": "So I made people do this in my class where they were applying a method where gradient descent took thousands and thousands of iterations and they just changed the step size to this and then it takes 75 and just solves the problem to some.",
                    "label": 0
                },
                {
                    "sent": "Crazy accuracy, so just you know you can try that out this afternoon.",
                    "label": 0
                }
            ]
        },
        "clip_103": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Quasi Newton that's right, I'm so stochastic gradient is my next section, which I'll get to shortly.",
                    "label": 0
                },
                {
                    "sent": "But yes, we we did have a version of this.",
                    "label": 0
                },
                {
                    "sent": "First the casted gradient, but it requires the noise to sort of be bounded.",
                    "label": 0
                },
                {
                    "sent": "That's right, yeah.",
                    "label": 0
                },
                {
                    "sent": "So for large mini batches, try this step size.",
                    "label": 0
                },
                {
                    "sent": "It'll work for awhile until you get until your noise starts to dominate.",
                    "label": 0
                },
                {
                    "sent": "The forgetting of the initial conditions.",
                    "label": 0
                },
                {
                    "sent": "That that that that will work for a while.",
                    "label": 0
                },
                {
                    "sent": "You can keep changing the mini batch.",
                    "label": 0
                },
                {
                    "sent": "You can do a true stochastic method up until some point and at some point you'll stop making progress as you will with any sort of fixed step size.",
                    "label": 0
                },
                {
                    "sent": "Yeah you that your noise gets too big, so if you increase the mini batch size overtime then you can keep doing this and that will work OK. OK, so there's also more fancy things quasi Newton Hessian, free Newton methods, so these either keep an approximation of the Hessian or they use Hessian vector products to approximately solve the Newton system, and another relative methods nonlinear conjugate gradient.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to go over go over these in details 'cause I really want to get to stochastic optimization methods, but I just want to mention that they exist and if you have a problem where you can go through data set many times these are very appealing methods.",
                    "label": 0
                }
            ]
        },
        "clip_104": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is just something I have on my web page comparing a bunch of these things.",
                    "label": 0
                },
                {
                    "sent": "So I have this code min funk and this is sort of a standard optimization test problem.",
                    "label": 0
                },
                {
                    "sent": "You start at zero, you want to get to 1.",
                    "label": 0
                },
                {
                    "sent": "The problem is very ill conditioned.",
                    "label": 0
                },
                {
                    "sent": "If you use gradient descent with a very fancy line search, it doesn't do much was if you if you some of the more fancy things limited memory, FGS testing for Newton all these fancy conjugate gradients you can do much better.",
                    "label": 0
                }
            ]
        },
        "clip_105": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's right.",
                    "label": 0
                },
                {
                    "sent": "Yeah, well, so so actually a very nice property is if you just want the derivative in One Direction, whether it's your function, your gradient, your Hessian, whatever you can in some sense always do that efficiently.",
                    "label": 0
                },
                {
                    "sent": "If you want to automatically compute the gradient with respect to every direction with respect to all your coordinates, that's expensive, But if you just give me One Direction, I can always compute that the cost of.",
                    "label": 0
                },
                {
                    "sent": "At most, like three times the cost of computing the value itself.",
                    "label": 0
                },
                {
                    "sent": "So gradients and directions are very cheap.",
                    "label": 0
                },
                {
                    "sent": "And for neural networks they have a very nice structure.",
                    "label": 0
                },
                {
                    "sent": "As for they do from any other problems.",
                    "label": 0
                },
                {
                    "sent": "That's true, another thing you can do is you evaluate your gradient in the complex domain with a small perturbation in the complex domain and then the real part will give you the gradient and the complex part will give you the exact Hessian vector product.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "It's very cool.",
                    "label": 0
                },
                {
                    "sent": "It's in our ICML 2006 paper for CRF's, but the exact same thing is true of most neural network models.",
                    "label": 0
                },
                {
                    "sent": "As long as you're saying that you're not doing something like a Max, it has to be like a smooth function.",
                    "label": 0
                },
                {
                    "sent": "It's implement as a sequence of operations.",
                    "label": 0
                },
                {
                    "sent": "So for a lot of functions, yeah, you can just use complex arithmetic to take the Hessian vector product and that's in Min Funk.",
                    "label": 0
                }
            ]
        },
        "clip_106": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Two so I just want to show you sort of a sample that these things really can make a difference from not making much progress to making just basically solving the problem.",
                    "label": 0
                }
            ]
        },
        "clip_107": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "But we don't usually talk about gradient methods were often talk about stochastic gradient methods.",
                    "label": 0
                },
                {
                    "sent": "Hussain.",
                    "label": 0
                }
            ]
        },
        "clip_108": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What do you mean by approximations?",
                    "label": 0
                },
                {
                    "sent": "For LBF Jess, it's a complicated question.",
                    "label": 0
                },
                {
                    "sent": "So if you read the books and stuff they say it's OK.",
                    "label": 0
                },
                {
                    "sent": "In practice, something weird can happen.",
                    "label": 0
                },
                {
                    "sent": "So if you really want to Newton like method to converge.",
                    "label": 0
                },
                {
                    "sent": "You basically need your sequence of Hessian approximations, their eigenvalues to be bounded between two fixed positive constants.",
                    "label": 0
                },
                {
                    "sent": "Now LDF Jess.",
                    "label": 0
                },
                {
                    "sent": "If you read about in the textbooks and you look at the implementations, what they usually do is they make sure that it's not ever zero.",
                    "label": 0
                },
                {
                    "sent": "The eigenvalues of your approximation, but they're not checking that it's too big, or two or two close to 0 so.",
                    "label": 0
                },
                {
                    "sent": "What can actually happen is that that can go wrong and the algorithm stops working.",
                    "label": 0
                },
                {
                    "sent": "There's an easy fix, you just restart the algorithm.",
                    "label": 0
                },
                {
                    "sent": "Oh, I usually say the LB FGS or the precondition testing free Newton methods so.",
                    "label": 0
                },
                {
                    "sent": "Precondition hassian fruit and uses LB FS to precondition the Hessian free method and that's a very nice, simple, elegant method that works quite well.",
                    "label": 0
                },
                {
                    "sent": "If you keep the fixed batch size.",
                    "label": 0
                },
                {
                    "sent": "That's a very complicated question.",
                    "label": 0
                },
                {
                    "sent": "So that'll work if your Hessian converges to a constant.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure if that works if you're heading approximation of the eigenvalues stay bounded between interval.",
                    "label": 0
                },
                {
                    "sent": "I don't know, but the nice thing about the polyak Ruppert result is in some sense it says you don't need to approximate the Hessian in that setting.",
                    "label": 0
                },
                {
                    "sent": "I'll get to the polyak Ruppert result momentarily.",
                    "label": 0
                },
                {
                    "sent": "Are there other questions on deterministic methods before we move on to stochastic methods?",
                    "label": 0
                },
                {
                    "sent": "I feel like there's one more random comment waiting to get out.",
                    "label": 0
                },
                {
                    "sent": "Not random, insightful.",
                    "label": 0
                },
                {
                    "sent": "Sorry, I meant this thing in my head.",
                    "label": 0
                },
                {
                    "sent": "Got replaced with.",
                    "label": 0
                },
                {
                    "sent": "I'm just joking.",
                    "label": 0
                },
                {
                    "sent": "Oh, 'cause this is a 2D function.",
                    "label": 0
                },
                {
                    "sent": "This is 2D, very hard function.",
                    "label": 0
                },
                {
                    "sent": "Often you're dealing with much easier and much higher dimensional functions, and the story kind of switches when you go to those problems.",
                    "label": 0
                },
                {
                    "sent": "But yeah, that's a really good question.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_109": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So oh.",
                    "label": 0
                }
            ]
        },
        "clip_110": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_111": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if I put in I hear and I hear.",
                    "label": 0
                },
                {
                    "sent": "I don't need to do this anymore.",
                    "label": 0
                },
                {
                    "sent": "The imaginary part is just going to give me the Hessian vector product.",
                    "label": 0
                },
                {
                    "sent": "Times Delta so you have to multiply it by Delta but will give it give it to you to like 150 decimal places accuracy so not like the usual like 6.",
                    "label": 0
                },
                {
                    "sent": "It just completely computes it's.",
                    "label": 0
                },
                {
                    "sent": "It's actually a special case of automatic differentiation, but you don't do anything fancy, you just change your code to work with complex numbers.",
                    "label": 0
                }
            ]
        },
        "clip_112": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_113": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_114": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so back to our problem formulation.",
                    "label": 0
                }
            ]
        },
        "clip_115": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Grading methods they kind of let us solve the scaling with D, But what about the case where N is very large?",
                    "label": 0
                },
                {
                    "sent": "So if we talked about image net, I guess it's even bigger now, but at the time of the slide it was 14,000,000 images which you don't want to go through like 100 times.",
                    "label": 0
                },
                {
                    "sent": "You want to go through it like at most 10 to 15 times.",
                    "label": 0
                },
                {
                    "sent": "That's sort of the sweet spot.",
                    "label": 0
                },
                {
                    "sent": "It seems like you need more than one, but probably you don't need more than 50, you don't.",
                    "label": 0
                }
            ]
        },
        "clip_116": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Too much progress after that.",
                    "label": 0
                },
                {
                    "sent": "So let's just consider the very abstract problem minimizing a sum of smooth.",
                    "label": 0
                }
            ]
        },
        "clip_117": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Functions so deterministic grading methods.",
                    "label": 0
                },
                {
                    "sent": "Very old method when you have that some structure, you just take the average of the gradients in the sum.",
                    "label": 0
                },
                {
                    "sent": "That's your gradient direction.",
                    "label": 0
                },
                {
                    "sent": "The problem is the iteration cost is linear in N 'cause you need to complete your grading on every single training example.",
                    "label": 0
                },
                {
                    "sent": "But you get the nice convergence with constants with constant stepsize or you have.",
                    "label": 0
                }
            ]
        },
        "clip_118": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Your linesearch stochastic gradient methods sort of a different tradeoff.",
                    "label": 0
                },
                {
                    "sent": "Instead of valuing every function, you just sample one random function.",
                    "label": 0
                },
                {
                    "sent": "You take your gradient step with respect to that one random function.",
                    "label": 0
                }
            ]
        },
        "clip_119": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's nice it gives an unbiased estimate of the true gradient.",
                    "label": 0
                },
                {
                    "sent": "So if you take the expectation of this value over all eyes and sometimes I replaced my gradient with F prime.",
                    "label": 0
                },
                {
                    "sent": "Then you just get the average of the gradients, which is the true gradient.",
                    "label": 0
                },
                {
                    "sent": "So this is very beautiful.",
                    "label": 0
                },
                {
                    "sent": "The iteration cost is independent of N. If you have 15 million training examples, this is 15 million times faster, which is the speedup you should care about.",
                    "label": 0
                }
            ]
        },
        "clip_120": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But the convergence means your step size has to go to 0, and that's sort of what's going to ruin all the fun.",
                    "label": 0
                }
            ]
        },
        "clip_121": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is the deterministic rating with this casting method you start taking big step sizes, but you slowly make them smaller.",
                    "label": 0
                },
                {
                    "sent": "So if you do that properly you'll converge.",
                    "label": 0
                }
            ]
        },
        "clip_122": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So stochastic iterations there end times faster, but we really care about how many.",
                    "label": 0
                }
            ]
        },
        "clip_123": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Actions are required, and if you just do the table, it's actually not so hard to find these results, but they are out there in the literature.",
                    "label": 0
                },
                {
                    "sent": "The stochastic method for convex function is 1 / sqrt T and for strongly convex functions it's 1 / T. So as I mentioned, we're really going to focus on the strongly convex case and the problem here is that the convergence rate is actually very slow.",
                    "label": 0
                },
                {
                    "sent": "This 1 / T rate means that the longer you run stochastic gradient, the less progress that's going to make the difference between 1 / 1,000,000 and one over million one is almost nothing.",
                    "label": 0
                },
                {
                    "sent": "So if you're running it for a million iterations, you're not doing very much.",
                    "label": 0
                },
                {
                    "sent": "And if you're only relying on unbiased grading approximations, you can't actually improve on the 1 / T. That's true, that's Part 2.",
                    "label": 0
                },
                {
                    "sent": "That's tomorrow.",
                    "label": 0
                },
                {
                    "sent": "So today I'm I'm assuming the world is very nice to me and then tomorrow I'm going to step outside my comfort zone and talk about issues like that.",
                    "label": 0
                },
                {
                    "sent": "But yes, I will get to that.",
                    "label": 0
                }
            ]
        },
        "clip_124": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, here's another weird thing which I added yesterday, 'cause I realized that I really need to mention this.",
                    "label": 0
                },
                {
                    "sent": "OK, so momentum slash acceleration does not improve the rate, so you're still in this rate regime.",
                    "label": 0
                },
                {
                    "sent": "So in terms of convergence rate, momentum doesn't make you faster.",
                    "label": 0
                },
                {
                    "sent": "Here's another weird thing though is that there's only one convergence rate.",
                    "label": 0
                },
                {
                    "sent": "Proof of momentum in this casting aware of, and actually requires the momentum to go to 0.",
                    "label": 0
                },
                {
                    "sent": "So this usual thing of setting that data to .9, there's actually no theory to justify that as far as I'm aware.",
                    "label": 0
                },
                {
                    "sent": "Just throwing that out there since that seems to be a very common thing.",
                    "label": 0
                },
                {
                    "sent": "I it's.",
                    "label": 0
                },
                {
                    "sent": "In the stochastic case, momentum does not help in terms of the dependence on T. I'll get to in a few slides.",
                    "label": 0
                },
                {
                    "sent": "You can actually improve the constants that are hidden in there, but you cannot improve the dependence on T. And you need the momentum to go to 02, which is another weird thing.",
                    "label": 0
                }
            ]
        },
        "clip_125": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so this is kind of the story in the smooth, strongly convex case where we've got the deterministic methods, which kind of do nothing for a long time.",
                    "label": 0
                },
                {
                    "sent": "Take a big step, do nothing, take a big step and so on, but make steady progress with this casting methods which make a whole lot of progress right away.",
                    "label": 0
                },
                {
                    "sent": "But the longer you run them, the less progress they're going to make.",
                    "label": 0
                },
                {
                    "sent": "So if you're really in the low time or you don't care much about accuracy, then stochastic methods are definitely superior, whereas if you have a lot of time or you need a very high accuracy than the deterministic methods are a bit better than.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately it's a little bit tricky 'cause you're not allowed to see the green curve when you run stochastic methods.",
                    "label": 0
                },
                {
                    "sent": "You can't really decide which method to use, so I just want to point out that trade.",
                    "label": 0
                }
            ]
        },
        "clip_126": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Off",
                    "label": 0
                }
            ]
        },
        "clip_127": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, yes, so you have to make this the casting method lot slower.",
                    "label": 0
                },
                {
                    "sent": "'cause now you have to compute the function values itself to figure out where the crossing point is.",
                    "label": 0
                },
                {
                    "sent": "Right, so if you're using a validation set, then I think.",
                    "label": 0
                },
                {
                    "sent": "It goes away a bit.",
                    "label": 0
                },
                {
                    "sent": "Depending on the cost of evaluating the validation set for.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so yeah, in that case you could actually look for the crossing point definitely.",
                    "label": 0
                },
                {
                    "sent": "Oh, so I'm pointing versus time so it has to actually go through all 15 million data points.",
                    "label": 0
                },
                {
                    "sent": "And at that point in time it's not changing the parameters, so it's effectively doing nothing on those iterations.",
                    "label": 0
                },
                {
                    "sent": "Other questions about this plot.",
                    "label": 0
                },
                {
                    "sent": "So this is actually set up point, which I'll get to very shortly.",
                    "label": 0
                },
                {
                    "sent": "Is that for a lot of the stochastic gradient methods that at least the theory used in some of the ones that use in practice, they actually exponentially go up before they start going down.",
                    "label": 0
                },
                {
                    "sent": "And this is this is this is approvable phenomenon.",
                    "label": 0
                },
                {
                    "sent": "The answer to that is used constant step size and I'll get.",
                    "label": 0
                },
                {
                    "sent": "Or something that looks like constant step size and I'll get to that momentarily.",
                    "label": 0
                },
                {
                    "sent": "Yes, definitely.",
                    "label": 0
                },
                {
                    "sent": "That's right, so that's a very common strategy.",
                    "label": 0
                },
                {
                    "sent": "Classically, the.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so often the recommended right places after one pass through the data, so right there.",
                    "label": 0
                },
                {
                    "sent": "And that's usually a pretty good approximation of where you should do it.",
                    "label": 0
                }
            ]
        },
        "clip_128": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, before we get to that trip, I just want to mention that the story is not the same for nonsmooth problems.",
                    "label": 0
                },
                {
                    "sent": "So if we think about things like SVM's, the story between.",
                    "label": 0
                }
            ]
        },
        "clip_129": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Realistic and stochastic is actually much simpler.",
                    "label": 0
                },
                {
                    "sent": "So here's the rates of what's called a subgradient method.",
                    "label": 0
                },
                {
                    "sent": "It's generalization of grading for nonsmooth problems, for non, for convex problems.",
                    "label": 0
                },
                {
                    "sent": "So if we go through the full data set on each iteration, we get 1 / sqrt, T one over T, so it's not.",
                    "label": 0
                },
                {
                    "sent": "It's not great, it's much slower than if this function is smooth.",
                    "label": 0
                },
                {
                    "sent": "But the stochastic rain actually has the same rate.",
                    "label": 0
                },
                {
                    "sent": "Which is kind of cool.",
                    "label": 0
                },
                {
                    "sent": "It's like a free lunch if your function is really.",
                    "label": 0
                },
                {
                    "sent": "If you're really optimizing a nonsmooth convex function used the castec subgradient.",
                    "label": 0
                },
                {
                    "sent": "Don't use cutting plane, don't use.",
                    "label": 0
                },
                {
                    "sent": "I think that's still in the non smooth setting.",
                    "label": 0
                },
                {
                    "sent": "You still have you still have.",
                    "label": 0
                },
                {
                    "sent": "Discontinuity's if you can show that the minimizer, the point you're converging to, that the function is smooth, then you're really in the easier case.",
                    "label": 0
                },
                {
                    "sent": "But if you're non smooth out the minimizer then you're in the hard case.",
                    "label": 0
                },
                {
                    "sent": "So there's a bunch of optimization people have been saying that we can just apply quasi Newton Smith problems and not even worry about it, but they don't work on problems like L1 regularization where you're actually not smooth at the minimizer.",
                    "label": 0
                },
                {
                    "sent": "OK, so they're convex.",
                    "label": 0
                },
                {
                    "sent": "What I mean by non smooth is that you can't take the derivative everywhere, there's there's some points where there's no gradient.",
                    "label": 0
                },
                {
                    "sent": "It's not, it does not exist.",
                    "label": 0
                },
                {
                    "sent": "Now this function so you can't talk about the gradient being Lipschitz continuous anymore.",
                    "label": 0
                },
                {
                    "sent": "So what you do is you.",
                    "label": 0
                },
                {
                    "sent": "So, so Lipschitz is kind of an upper bound on the rate of change, and strong convexity is a is a lower bound on the rate of change.",
                    "label": 0
                },
                {
                    "sent": "This happens to be a strongly convex function, so we still have the lower bound, but the upper bound we have to change now 'cause we don't have a gradient, but you assume that the sub what's called the sub gradient, which I'll get to in the next slide is bounded.",
                    "label": 0
                },
                {
                    "sent": "The subgradient can't change too quickly either and then you get analogous things.",
                    "label": 0
                },
                {
                    "sent": "In the gradient descent stuff, you only care about the gradient function doesn't have to be Lipschitz continuous, and at least squares, it's not.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "It's true, so.",
                    "label": 0
                },
                {
                    "sent": "So actually for convex functions, any nonsmooth convex function has to be differentiable almost everywhere.",
                    "label": 0
                },
                {
                    "sent": "The problem is not that you're on the non differentiable points.",
                    "label": 0
                },
                {
                    "sent": "The problem is that the gradient you sort of lose this that the gradient can change slowly when you have non differentiable points you get to you go from here to here in the gradient sort of jumps in magnitude, and that's going to prevent you from.",
                    "label": 0
                },
                {
                    "sent": "Sort of approaching it slowly and smoothly.",
                    "label": 0
                },
                {
                    "sent": "That's right.",
                    "label": 0
                },
                {
                    "sent": "I will talk about smoothing approaches next time 'cause 'cause you can beat these bounds with approaches like that.",
                    "label": 0
                },
                {
                    "sent": "I am one of the points I really make next time.",
                    "label": 0
                },
                {
                    "sent": "Is these bounds actually really pessimistic and you can.",
                    "label": 0
                },
                {
                    "sent": "You can just destroy them in practice, which is kind of like a theme of my research is showing that you can often beat these bounds under very small changes to your assumptions, but that's a very good point.",
                    "label": 0
                },
                {
                    "sent": "OK, so so.",
                    "label": 0
                },
                {
                    "sent": "So if any of you are still using like SVM, whatever structure per for light or whatever, just you stochastic gradient instead.",
                    "label": 0
                },
                {
                    "sent": "It'll work much better.",
                    "label": 0
                }
            ]
        },
        "clip_130": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So for announcement problems, determining determining methods are not faster than stochastic methods.",
                    "label": 0
                },
                {
                    "sent": "So if you truly have a black box dance with problem, you stochastic subgradient durations will be 10 times faster.",
                    "label": 1
                },
                {
                    "sent": "Convergence rates the same.",
                    "label": 0
                },
                {
                    "sent": "It really is a free lunch until we get to tomorrow.",
                    "label": 0
                }
            ]
        },
        "clip_131": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, So what is?",
                    "label": 0
                },
                {
                    "sent": "What is the subgrade in the subdifferential?",
                    "label": 0
                },
                {
                    "sent": "So that was our that was our sort of 1st order DEF.",
                    "label": 0
                }
            ]
        },
        "clip_132": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Notion of convexity and we're just going to say a subgradient is any direction.",
                    "label": 0
                },
                {
                    "sent": "D where I can plug it into that inequality and the inequality is still satisfied.",
                    "label": 0
                }
            ]
        },
        "clip_133": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you had a differential point, there's only one sub gradient which is the gradient and at non differentiable X you're going to have a whole set of sub gradients, called the subdifferential, which is confusingly used with this notation.",
                    "label": 0
                },
                {
                    "sent": "A nice property of the subdifferential is if zero is in your subdifferential, then you're at the global minimum of a convex function, so that generalizes the condition that the gradient is 0 for the.",
                    "label": 0
                }
            ]
        },
        "clip_134": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The minimum of a smooth function.",
                    "label": 0
                }
            ]
        },
        "clip_135": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As a picture.",
                    "label": 0
                }
            ]
        },
        "clip_136": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you're at a smooth point, you've got one subgradient.",
                    "label": 0
                },
                {
                    "sent": "It's the gradient.",
                    "label": 0
                }
            ]
        },
        "clip_137": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you're at a non smooth point then.",
                    "label": 0
                }
            ]
        },
        "clip_138": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You have you know that.",
                    "label": 0
                }
            ]
        },
        "clip_139": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Subgradient, that's it.",
                    "label": 0
                }
            ]
        },
        "clip_140": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Gradient that's a subgroup.",
                    "label": 0
                }
            ]
        },
        "clip_141": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Print and basically any any way you sort of tilt this line.",
                    "label": 0
                },
                {
                    "sent": "You'll get a subgradient and it turns out it doesn't.",
                    "label": 0
                },
                {
                    "sent": "Well, I'll talk about.",
                    "label": 0
                }
            ]
        },
        "clip_142": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Whether it matters which.",
                    "label": 0
                }
            ]
        },
        "clip_143": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "When you pick but essentially for stochastic subgradient it doesn't matter which one you pick.",
                    "label": 0
                },
                {
                    "sent": "So if you're doing this generalization of this for nonsmooth functions called the Clark Subdifferential, which is a very fancy way of saying that's what you guys are doing when you do Relu.",
                    "label": 0
                },
                {
                    "sent": "So if you want to make your papers sound more fancy, you should say you're taking the Clark subgradient, which is basically like a local subgradient, and that would be.",
                    "label": 0
                },
                {
                    "sent": "What would you do for revenue when you take either one or the other line?",
                    "label": 0
                },
                {
                    "sent": "If you're actually at the nonsmooth.",
                    "label": 0
                }
            ]
        },
        "clip_144": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which you may not be.",
                    "label": 0
                },
                {
                    "sent": "So sub differential absolute value function is is plus one if you're bigger than 0 -- 1.",
                    "label": 0
                },
                {
                    "sent": "If you're less than zero, and then anything in between when you're equal to 0.",
                    "label": 0
                }
            ]
        },
        "clip_145": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As a picture.",
                    "label": 0
                }
            ]
        },
        "clip_146": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sure, if you're there, it's the line with slope minus one.",
                    "label": 0
                }
            ]
        },
        "clip_147": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you're at.",
                    "label": 0
                }
            ]
        },
        "clip_148": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Zero then you.",
                    "label": 0
                }
            ]
        },
        "clip_149": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Minus one plus.",
                    "label": 0
                }
            ]
        },
        "clip_150": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "10 So this is the global minimum of the absolute value.",
                    "label": 0
                }
            ]
        },
        "clip_151": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then a whole bunch of us.",
                    "label": 0
                }
            ]
        },
        "clip_152": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thing, so any of those will work as subgradients, they're all fine.",
                    "label": 0
                }
            ]
        },
        "clip_153": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Subdifferential of Max.",
                    "label": 0
                }
            ]
        },
        "clip_154": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Function as in the Relu is you just take whichever one is the arc Max and take its gradient, assuming they're both smooth.",
                    "label": 0
                },
                {
                    "sent": "So if F1 is bigger, you take that one.",
                    "label": 0
                },
                {
                    "sent": "If F2 is bigger, you take that one.",
                    "label": 0
                },
                {
                    "sent": "If they are tide then you can take any convex combination.",
                    "label": 0
                },
                {
                    "sent": "You can take any anything that mixes between the two.",
                    "label": 0
                }
            ]
        },
        "clip_155": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK so the basic subgradient method I'm going to use this notation where DT is now some element of the sub diferente.",
                    "label": 0
                }
            ]
        },
        "clip_156": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'll if you want to talk about the best subgradient that's called the steepest descent rule, and it's given by this weird relationship where you actually take the smallest subgradient that's in some sense the direction that will give you the most improvement.",
                    "label": 0
                },
                {
                    "sent": "That's often not easy to compute if you're doing something like L1 regularization.",
                    "label": 0
                },
                {
                    "sent": "It is easy and very common, but in Gen.",
                    "label": 0
                }
            ]
        },
        "clip_157": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, it's not easy to compute.",
                    "label": 0
                },
                {
                    "sent": "If you don't pick that direction, you can actually increase the objective even for small alphas.",
                    "label": 0
                },
                {
                    "sent": "So if you there's no guarantee that you'll decrease the objective function by following a subgradient.",
                    "label": 0
                },
                {
                    "sent": "But if your step size is small enough, you can guarantee that you decrease the distance to the solution.",
                    "label": 0
                },
                {
                    "sent": "So even though you might increase the function, you still actually get closer to the solution.",
                    "label": 0
                },
                {
                    "sent": "But you still require the step size to go to 0, and that's what's going to lead to those bad convergence.",
                    "label": 0
                }
            ]
        },
        "clip_158": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I showed before.",
                    "label": 0
                },
                {
                    "sent": "The basic stochastic subgradient method is exactly what you think it would be.",
                    "label": 0
                },
                {
                    "sent": "Instead of taking the true subgradient, you just take the subgradient for one of your functions, randomly chosen, so no surprises there.",
                    "label": 0
                },
                {
                    "sent": "I'm pretty sure most people in the room have actually used this hour.",
                    "label": 0
                }
            ]
        },
        "clip_159": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so let's talk a little bit about what is known of the theory versus the practice for convex functions.",
                    "label": 0
                },
                {
                    "sent": "So if I just take this Alpha T is one over mu times T this is this is very common for SVM.",
                    "label": 0
                },
                {
                    "sent": "Is this actually works for every other problem?",
                    "label": 0
                },
                {
                    "sent": "This doesn't really work, they don't ever write that in the papers.",
                    "label": 0
                },
                {
                    "sent": "I don't know why.",
                    "label": 0
                },
                {
                    "sent": "OK, so 1 / T for smoothing functions one over log T / T for nonsmooth functions you use a log factor compared.",
                    "label": 0
                }
            ]
        },
        "clip_160": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Optimal, but it's not a big deal, but except for if you're doing binary streams, you should actually never use that version of stochastic gradient descent, so the initial steps are huge, so usually mu is something like 1 / N or 1 / sqrt N. So your initial step size is something like N. The number of data points like 15 million.",
                    "label": 0
                },
                {
                    "sent": "You can, you can easily imagine why this is a ridiculous thing to do, and you can actually prove that until some point.",
                    "label": 0
                },
                {
                    "sent": "This step size is going to be exponentially fast away from the solution, it's going to increase the objective function, so this was a comment before that often stochastic rain.",
                    "label": 0
                },
                {
                    "sent": "You don't see this sharp increase.",
                    "label": 0
                },
                {
                    "sent": "You see a big increase, and then it goes down.",
                    "label": 0
                },
                {
                    "sent": "That's usually from using some crazy stepsize like this.",
                    "label": 0
                },
                {
                    "sent": "The later steps actually get very small, so 1 / T goes to zero very quickly.",
                    "label": 0
                },
                {
                    "sent": "The convergence rate is also not robust to misspecification of mu, so there's one paper where they said well, what if he is off by a little bit and then they show that the convergence rate is incredibly slow.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Don't use this, I don't, I don't.",
                    "label": 0
                },
                {
                    "sent": "I'm not going you are using this.",
                    "label": 0
                },
                {
                    "sent": "People do this, but not not people who work on hard problems.",
                    "label": 0
                },
                {
                    "sent": "People who work on hard problems know what step sizes they should use, and we'll get to that shortly.",
                    "label": 0
                },
                {
                    "sent": ".1, yes, exactly.",
                    "label": 0
                },
                {
                    "sent": "I'll show you a theorem for .1 in two slides.",
                    "label": 0
                },
                {
                    "sent": "OK, and this is really for the worst case problem.",
                    "label": 0
                },
                {
                    "sent": "This is think about the worst possible strongly convex function you can think of, but often you're not optimizing the worst strongly convex function.",
                    "label": 0
                },
                {
                    "sent": "There's no adaptivity of the problem in the step size at all here, so this is sort of a very pessimistic.",
                    "label": 0
                }
            ]
        },
        "clip_161": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Algorithm.",
                    "label": 0
                },
                {
                    "sent": "So tricks that work both in theory and in practice 2 very simple tricks are well, use smaller initial step sizes that go to zero more slowly, and this sort of has been much more appreciated in the last few years, especially Francis Bach.",
                    "label": 0
                },
                {
                    "sent": "Published a series of papers showing that this is a good idea so you don't want to use this 15 million size initial step and you don't want it to go to 0 so quickly either.",
                    "label": 0
                },
                {
                    "sent": "Another thing is taking a weighted average of either the gradients or the iteration so you can show those have some very nice properties and I'll get to the polyak Ruppert result momentarily.",
                    "label": 0
                },
                {
                    "sent": "They're just some weights, so.",
                    "label": 0
                },
                {
                    "sent": "Non negative yeah.",
                    "label": 0
                },
                {
                    "sent": "So one common one is you.",
                    "label": 0
                },
                {
                    "sent": "You average like the second half year iterations or something like that.",
                    "label": 0
                }
            ]
        },
        "clip_162": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so there's a few works that support using large steps and averaging, so if you do what I just mentioned, you're just average the second half of the iteration.",
                    "label": 0
                },
                {
                    "sent": "That's going to achieve the 1 / T rate without the log factor.",
                    "label": 0
                },
                {
                    "sent": "It works a little bit better, or you can just average by the iteration number is another weird thing.",
                    "label": 0
                },
                {
                    "sent": "So instead of averaging 1 / N, you sort of take the iteration number T, and you normalize your step to average by that, so you focus more on the later iterations than the earlier iterations.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "I'd have to think about the first iteration would have weight proportional to one and the last one would ever weight proportional to T. And then you normalize them.",
                    "label": 0
                },
                {
                    "sent": "So I think you get a T squared in there somewhere in the weights.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Yeah, you you have the TT plus one over the old Gauss some story.",
                    "label": 0
                },
                {
                    "sent": "OK, so there's this thing called dual averaging which where you take gradient averaging and that's been shown to improve the constants and if you have a sparse regularizer that will actually identify the sparsity pattern, which is not true of stochastic gradient methods or subgrade methods.",
                    "label": 0
                },
                {
                    "sent": "So Bakken Muline showed that if you sort of a smaller steps.",
                    "label": 0
                }
            ]
        },
        "clip_163": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Guys, it's more robust to miss specifying you, and here's the result that if you're going to take one thing away from the first 2/3 of this lecture, study this line.",
                    "label": 0
                },
                {
                    "sent": "So this result is very much hidden in this paper of netishyn bertsekas, but I wrote like a three page report last year giving like a simplified like half page proof of this result in the more general setting.",
                    "label": 0
                },
                {
                    "sent": "OK, so if I use a constant stepsize, if I use .1.",
                    "label": 0
                },
                {
                    "sent": "This is the result that you get, so are my expected function value.",
                    "label": 0
                },
                {
                    "sent": "It's going to be something that forgets my initial conditions with a linear convergence rate, so I go away from my initial conditions very quickly.",
                    "label": 0
                },
                {
                    "sent": "But I don't converge.",
                    "label": 0
                },
                {
                    "sent": "I have this extra term that doesn't depend on T. It's proportional to the stepsize.",
                    "label": 0
                },
                {
                    "sent": "So basically you you go very quickly to some region, but then after that you can't make any progress anymore.",
                    "label": 0
                },
                {
                    "sent": "There's sort of this this level set this level below which you go very quickly and then after that you're stuck.",
                    "label": 0
                },
                {
                    "sent": "You don't know what's going to happen.",
                    "label": 0
                },
                {
                    "sent": "If you make the step size smaller, that region goes down and down and down.",
                    "label": 0
                },
                {
                    "sent": "So if you're using this strategy, which my understanding is, it's very common use some step size some concepts for a long time.",
                    "label": 0
                },
                {
                    "sent": "Take something smaller, use that for a long time, take something smaller, do that for a long time.",
                    "label": 0
                },
                {
                    "sent": "That's a very reasonable thing to do.",
                    "label": 0
                },
                {
                    "sent": "In fact, for classic stochastic gradient methods, I often recommend that 'cause that's very easy to tune compared to these, this decreasing sequence and it is completely justified theoretically, as long as you're willing to give up convergence and you say, well, I'm not going to get these back solution, but I'll get to someplace quite good.",
                    "label": 0
                },
                {
                    "sent": "Yes, then you're back to 1 / T. Ha.",
                    "label": 0
                }
            ]
        },
        "clip_164": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So so gradient averaging Yagi actually averaging the directions.",
                    "label": 0
                },
                {
                    "sent": "So you you know you're taking one stochastic gradients, another another another, and you take the average of all those directions you've looked at.",
                    "label": 0
                },
                {
                    "sent": "Just an magnitudes, yes.",
                    "label": 0
                },
                {
                    "sent": "And then the other one is.",
                    "label": 0
                },
                {
                    "sent": "You actually average the iterations themselves, so if you're bouncing all around the place, you actually go to the middle of where you're bouncing around.",
                    "label": 0
                },
                {
                    "sent": "Usually this is an offline thing.",
                    "label": 0
                },
                {
                    "sent": "We actually run your algorithm and then you just return the average as opposed to.",
                    "label": 0
                },
                {
                    "sent": "And then there's something called bathers method, which is not well known but has the same polyak Ruppert result, which I'll get to momentarily, which does which does online averaging and averaging in the gradients, and has very beautiful properties, but it's not well known 'cause there's no PDF of it online.",
                    "label": 0
                },
                {
                    "sent": "Who's that?",
                    "label": 0
                },
                {
                    "sent": "Maybe that's.",
                    "label": 0
                }
            ]
        },
        "clip_165": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hypothesis, or is there another question?",
                    "label": 0
                },
                {
                    "sent": "See are you saying at some point, stop and evaluate the function or approximate the function and then decide to choose the step size?",
                    "label": 0
                },
                {
                    "sent": "I think you're still going to be stuck in the 1 / T regime.",
                    "label": 0
                },
                {
                    "sent": "I think if you really want to converge, you're stuck with 1 / T. There's not really something that can solve that in the general case, unless you're talking about finite sums, which I'll get to shortly.",
                    "label": 0
                },
                {
                    "sent": "With this rate, yeah yeah.",
                    "label": 0
                },
                {
                    "sent": "So that will still work, but but this is a very nice rate 'cause you really do get this exponential convergence to some nice region.",
                    "label": 0
                },
                {
                    "sent": "Sure, yeah.",
                    "label": 0
                },
                {
                    "sent": "If it's converging then it can't be faster than one over there.",
                    "label": 0
                },
                {
                    "sent": "That's a theorem.",
                    "label": 0
                },
                {
                    "sent": "If it's constant and it's within some bound between two bounded intervals, then it, then it's in this an your Alpha is probably the Max of the interval, but if you do something more refined you might be able show it's a bit better than that as you go through the interval.",
                    "label": 0
                },
                {
                    "sent": "Are there more questions I I think this result is not well known, and perhaps is underappreciated 'cause it wasn't.",
                    "label": 0
                },
                {
                    "sent": "It's hidden in a longer paper that discusses a whole bunch of other things.",
                    "label": 0
                },
                {
                    "sent": "That's all we're talking about today.",
                    "label": 0
                },
                {
                    "sent": "If you.",
                    "label": 0
                },
                {
                    "sent": "OK, so I'll make two comments on that.",
                    "label": 0
                },
                {
                    "sent": "So First off, you actually don't need smoothness for this result.",
                    "label": 0
                },
                {
                    "sent": "If you state in terms of the distance to the solution.",
                    "label": 0
                },
                {
                    "sent": "So smoothness is not not important, but strong convexity is important to this result.",
                    "label": 0
                },
                {
                    "sent": "The second point is we don't really have any theory on what happens in that case.",
                    "label": 0
                },
                {
                    "sent": "So to say that this theory doesn't apply is true, but the same thing with everything else that anyone has said except for that very first that it can't go faster than grid search.",
                    "label": 0
                },
                {
                    "sent": "If you're talking about solving a general problem so.",
                    "label": 0
                },
                {
                    "sent": "Yes, you can make that criticism, but we have to try to find out what's understanding and we're starting with this easy case to try and understand what's happening.",
                    "label": 0
                },
                {
                    "sent": "It's true, but I'll show you function tomorrow that does not look like that at all.",
                    "label": 0
                },
                {
                    "sent": "Where this theorem still applies.",
                    "label": 0
                },
                {
                    "sent": "It's not even convex, it's not.",
                    "label": 0
                },
                {
                    "sent": "It has flat rate.",
                    "label": 0
                },
                {
                    "sent": "You know it's much more nasty.",
                    "label": 0
                }
            ]
        },
        "clip_166": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But today I just want to make my life simple, not talk with things.",
                    "label": 0
                },
                {
                    "sent": "OK, so the Poly actor engine.",
                    "label": 0
                },
                {
                    "sent": "It's key result is a very very important result and.",
                    "label": 0
                },
                {
                    "sent": "It's still not really well written.",
                    "label": 0
                },
                {
                    "sent": "It's very complicated with there's no results, which I'll talk about tomorrow, which are very interesting.",
                    "label": 0
                },
                {
                    "sent": "OK, so if you're talking about this smooth and strongly convex case, iterate averaging is asymptotically optimal in the sense that if you have the optimal estimator in terms of statistics.",
                    "label": 0
                },
                {
                    "sent": "Asymptotically, once you forget about the initial phase averaging the iterations, that's the optimal thing you can do.",
                    "label": 0
                },
                {
                    "sent": "You can also do optimal with the stochastic Newton's method, but why would you do this to castec Newtons method if you can just do iterate averaging and the 1st order gradient method.",
                    "label": 0
                },
                {
                    "sent": "So in some sense this is almost a negative result saying that maybe stochastic methods aren't the right thing to do, they certainly aren't the right thing to do asymptotically.",
                    "label": 0
                },
                {
                    "sent": "So, so I think that result is sort of underappreciated an whenever you're thinking of developing is to Gaston method, you should always.",
                    "label": 0
                },
                {
                    "sent": "Try and think about like the Polyak in Judith's key case 'cause.",
                    "label": 0
                }
            ]
        },
        "clip_167": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I think sometimes our intuition with the determinant deterministic case can mislead us in the stochastic case.",
                    "label": 0
                },
                {
                    "sent": "OK, so should we use accelerated or Newton like methods?",
                    "label": 0
                },
                {
                    "sent": "We know that they don't improve the convergence rate.",
                    "label": 0
                },
                {
                    "sent": "Those methods still have 1 / T.",
                    "label": 0
                }
            ]
        },
        "clip_168": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But there are a bunch of positive results, so acceleration or momentum or heavy ball can actually improve your dependence on other constants, so they don't improve your dependence on the number iterations T. But if you if they improve your depends on the condition number, they may still be appealing to use, and I think This is why they actually work in practice is because T may not be the bottleneck in some cases.",
                    "label": 0
                },
                {
                    "sent": "In some cases the optimization problem might just be really hard.",
                    "label": 0
                },
                {
                    "sent": "We wanted to improve our dependency on the optimization problem as opposed to the number of iterations we ran.",
                    "label": 0
                },
                {
                    "sent": "So that will improve the performance either at the start or if your noise is very small.",
                    "label": 0
                },
                {
                    "sent": "There's also this ADA grad and a sequence of works following it, whether using a step size for each coordinate.",
                    "label": 0
                },
                {
                    "sent": "Again, that's not going to get you around 1 / T. But Ducey, Al Al did show that can improve regret bounds.",
                    "label": 0
                },
                {
                    "sent": "So so if you add up your suboptimality across all iterations, you can do a little bit better using this.",
                    "label": 0
                },
                {
                    "sent": "Back in New Orleans gave sort of a Newton like method, which actually I think I mean this has seen vector products which gives the 1 / T rate without strong convexity.",
                    "label": 0
                },
                {
                    "sent": "When unfortunately I got to Frances.",
                    "label": 0
                },
                {
                    "sent": "After he submitted the version of the paper so we didn't have this nice complex number trick in the paper, but he should have, so that's kind of nice that actually we don't need the strong convexity in a lot of cases to get the 1 / T rate.",
                    "label": 0
                },
                {
                    "sent": "OK, I think that's all I have to disable stochastic methods, so maybe I'll pause there to see if there's some more questions.",
                    "label": 0
                },
                {
                    "sent": "The short answer is no.",
                    "label": 0
                },
                {
                    "sent": "The funnier answer is someone asked this to number of ski at a workshop at NIPS one year, and he got mad at them.",
                    "label": 0
                },
                {
                    "sent": "He's like how can you possibly define a distribution over possible problems you could solve?",
                    "label": 0
                },
                {
                    "sent": "If you apply conjugate gradient tool in your system that comes from random data points.",
                    "label": 0
                },
                {
                    "sent": "It actually converges way faster.",
                    "label": 0
                },
                {
                    "sent": "You can prove out much faster rate, so there may be results like that that exists.",
                    "label": 0
                },
                {
                    "sent": "But there in like Nesterov's notebook in his file cabinet drawer somewhere and I that none of them are actually out in the world as far as I'm aware, except for for linear programming there's this proof with like the smooth analysis of simplex method showing that simplex is actually polynomial time in practice.",
                    "label": 0
                },
                {
                    "sent": "Oh no, I'm just saying you can.",
                    "label": 0
                },
                {
                    "sent": "You can actually pick any subgradient the theory applies.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "You have to.",
                    "label": 0
                },
                {
                    "sent": "You have to think of like a function like this where the level.",
                    "label": 0
                },
                {
                    "sent": "So I've been showing all these like round level sets these circles but if you have something like a triangle then you can have something that actually doesn't go inside the triangle but actually moves you closer to the solution.",
                    "label": 0
                },
                {
                    "sent": "So you have to really consider like a non smooth point in your level curve and then you can get that property.",
                    "label": 0
                },
                {
                    "sent": "But seekers had some very nice illustrations in his book.",
                    "label": 0
                },
                {
                    "sent": "Right, I mean all of it's in most of his books.",
                    "label": 0
                },
                {
                    "sent": "So what I'm saying here is this is kind of a mystery.",
                    "label": 0
                },
                {
                    "sent": "I would I would say like try and find a good constant stepsize and maybe like divide that by two or 10 or something if you find that it's not working after all.",
                    "label": 0
                },
                {
                    "sent": "I mean, my understanding is that this is what people already doing and I just wanted to say that that's actually like a reasonable thing to do from a theoretical perspective.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So I mean this land guy, he wants to design out and that works for every single problem, so I'll get to his results next time where he actually addresses nonconvex problems and he gets an algorithm like works well.",
                    "label": 0
                },
                {
                    "sent": "If you're convex or non smooth or stochastic or whatever.",
                    "label": 0
                },
                {
                    "sent": "So there are people working on that.",
                    "label": 0
                },
                {
                    "sent": "The algorithms that work in every single case though tend not to be the fastest hours in specific cases and in practice we care about the algorithm works best for my problem, not for every problem.",
                    "label": 0
                },
                {
                    "sent": "So there's definitely research in both directions.",
                    "label": 0
                },
                {
                    "sent": "I think there's another question somewhere.",
                    "label": 0
                },
                {
                    "sent": "Well, not free lunch program is not for optimization.",
                    "label": 0
                },
                {
                    "sent": "For optimization, there's definitely free lunches.",
                    "label": 0
                },
                {
                    "sent": "It's great.",
                    "label": 0
                },
                {
                    "sent": "It's much nicer as a theorist.",
                    "label": 0
                }
            ]
        },
        "clip_169": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so I mean if I was talking about any function as opposed to this specific class of functions, then there would be like a no free lunch thing where you can't beat dropping down random points in general.",
                    "label": 0
                },
                {
                    "sent": "But because I'm making such strong assumptions I can actually get free lunches.",
                    "label": 0
                },
                {
                    "sent": "Well, no, he still has assumptions, but he's trying to just think of all the ones you can possibly have.",
                    "label": 0
                }
            ]
        },
        "clip_170": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so I want to get to this last thing which is which is finite sum problems.",
                    "label": 0
                },
                {
                    "sent": "So that was the problem that we.",
                    "label": 0
                }
            ]
        },
        "clip_171": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Motivating we sense to Cassie and this 1 / T rate, but they need one gradient preparation and those rates can't be improved for general stochastic.",
                    "label": 0
                }
            ]
        },
        "clip_172": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Actives whereas the Terministic methods had this linear rate but they required ingredients preparation and the reason that you can get a faster rate, you can get it around the lower bound is because the number of data points you have is finite.",
                    "label": 0
                }
            ]
        },
        "clip_173": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the question is for if you are minimizing finite sum, can we actually design A better method?",
                    "label": 0
                },
                {
                    "sent": "Do we have to look at these two?",
                    "label": 0
                }
            ]
        },
        "clip_174": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Dreams so back to this picture.",
                    "label": 0
                }
            ]
        },
        "clip_175": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We want to design something like this.",
                    "label": 0
                },
                {
                    "sent": "And there's many ways you can think of doing that, like switching or growing the batch or whatever.",
                    "label": 0
                },
                {
                    "sent": "We're actually going to get a method that actually has a better slope than the deterministic method by taking this.",
                    "label": 0
                }
            ]
        },
        "clip_176": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Perspective OK, so approach one is.",
                    "label": 0
                }
            ]
        },
        "clip_177": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Control the sample size.",
                    "label": 0
                },
                {
                    "sent": "For grading method uses all in gradients stochastic gradient methods.",
                    "label": 0
                }
            ]
        },
        "clip_178": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What uses 1 using mini batch?",
                    "label": 0
                },
                {
                    "sent": "You're kind of getting somewhere in between.",
                    "label": 0
                },
                {
                    "sent": "For example in that constant step size rule that all of Alpha term is kind of also proportional to the batch size.",
                    "label": 0
                },
                {
                    "sent": "So instead of decreasing your step size, you could also increase your batch size and get back to the exponentially converging.",
                    "label": 0
                },
                {
                    "sent": "Or you can do that bars like bro in step or quasi Newton stuff, as long as you're increasing the batch size, sort of the deterministic methods work.",
                    "label": 0
                },
                {
                    "sent": "It's kind of cheating.",
                    "label": 0
                }
            ]
        },
        "clip_179": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_180": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Perfect sample size.",
                    "label": 0
                }
            ]
        },
        "clip_181": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Rated sub linear but.",
                    "label": 0
                }
            ]
        },
        "clip_182": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Can increase the batch size and that's.",
                    "label": 0
                }
            ]
        },
        "clip_183": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Pretty common strategy, and you can actually choose to do that properly to get convergence rates if you want to sort of you start with something looks like a stochastic gradient method, but at the end it looks like a quasi Newton method.",
                    "label": 0
                }
            ]
        },
        "clip_184": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But that eventually requires full passes through the data, so it's really just sort of like hiding the fact, or maybe cleaning up the first iterations of the quasi Newton method.",
                    "label": 0
                },
                {
                    "sent": "Can we really get a rate that has linear with just one gradient parameter?",
                    "label": 0
                }
            ]
        },
        "clip_185": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And and this is work.",
                    "label": 0
                }
            ]
        },
        "clip_186": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Did with Nikola LaRue.",
                    "label": 0
                },
                {
                    "sent": "Who's a former student of Joshua's as well as Francis Bach and it's called the stochastic average gradient so.",
                    "label": 0
                },
                {
                    "sent": "This is your standard gradient step.",
                    "label": 0
                },
                {
                    "sent": "On each iteration of SAG, we're going to take one random datapoint.",
                    "label": 0
                }
            ]
        },
        "clip_187": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It it's gradient and instead of.",
                    "label": 0
                }
            ]
        },
        "clip_188": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In those gradients there I'm going to put here the last gradient that I computed for function I.",
                    "label": 0
                },
                {
                    "sent": "So we have this sort of weird memory where in each iteration I remember the gradient of every single training example, which seems crazy, but I'll say why it's not completely crazy in a moment, and then we compute a new one and replace the old one with the new one, and we're just going to assume that that's our true gradient.",
                    "label": 0
                }
            ]
        },
        "clip_189": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So, so that's a stochastic version of.",
                    "label": 0
                }
            ]
        },
        "clip_190": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "They came before where they went through cyclically.",
                    "label": 0
                },
                {
                    "sent": "It's really sort of, assuming that your gradients are not changing too quickly, but as you converge to the solution, they happen to not change very quickly because your ex is we're getting closer together, so your Lipschitz continuous gradient means that your gradients are getting closer together, so this becomes a good approximation as you go.",
                    "label": 0
                }
            ]
        },
        "clip_191": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So maybe the most technical slide today, which possibly should not be at the very end.",
                    "label": 0
                },
                {
                    "sent": "But basically it gets a linear convergence rate with a constant that's actually very good.",
                    "label": 0
                }
            ]
        },
        "clip_192": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Hi, a lot better than you would expect, so we have a linear convergence rate.",
                    "label": 1
                },
                {
                    "sent": "We just have to look at one function on each iteration so same cost as stochastic gradient method, but much faster convergence rate.",
                    "label": 0
                },
                {
                    "sent": "If you're in this setting, the well conditioned setting it means you multiply your air by .8825 after each pass through the data, which doesn't seem great, but you go .825 to the 20.",
                    "label": 0
                },
                {
                    "sent": "It gets fairly small, whereas the 1 / T can start getting slow in that regime.",
                    "label": 0
                },
                {
                    "sent": "If you're in this case, if you have a hard optimization problem, the rate is actually almost as fast as if you were doing the gradient descent where you going through the full data set on each iteration, which I think is the kind of the fascinating part.",
                    "label": 0
                },
                {
                    "sent": "This album really works for hard optimization problems.",
                    "label": 0
                }
            ]
        },
        "clip_193": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So just.",
                    "label": 0
                }
            ]
        },
        "clip_194": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some numbers there.",
                    "label": 0
                }
            ]
        },
        "clip_195": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So gradient descent, the fastest known rate, looks like this for accelerated gradient.",
                    "label": 0
                },
                {
                    "sent": "The Nesterov style method you get to this and optimization people really care about that rate, but but sag we cheat a little bit where we have a slower rate, but we can do N iterations for the cost of one of those methods, so we can actually raise the power N and get a much faster rate.",
                    "label": 0
                },
                {
                    "sent": "And if I force you to go through the full data set in every iteration, this is.",
                    "label": 0
                }
            ]
        },
        "clip_196": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The fastest rate you can get, so it's faster than any black box method that goes through the full data set each time.",
                    "label": 0
                },
                {
                    "sent": "So it's not only faster than stochastic gradient because it beats 1 / T, But for most deterministic gradient methods.",
                    "label": 0
                }
            ]
        },
        "clip_197": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Also faster.",
                    "label": 0
                }
            ]
        },
        "clip_198": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another way to look at that as number of valuations to reach epsilon.",
                    "label": 0
                },
                {
                    "sent": "So in stochastic case you've kind of got condition number divided.",
                    "label": 0
                }
            ]
        },
        "clip_199": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Epsilon gradient you've got condition number times log which is better, but then you multiply by N and then.",
                    "label": 0
                }
            ]
        },
        "clip_200": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Acceleration you put a square root and Max.",
                    "label": 0
                },
                {
                    "sent": "You take the are inside.",
                    "label": 0
                },
                {
                    "sent": "You take the Max of these two big numbers so the Max is going to be much smaller than the product.",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "You're just assuming that there's a finite number of data points, and that you solve this Lipschitz continuous and the strong convexity assumption, but they can be from some weird distribution.",
                    "label": 0
                },
                {
                    "sent": "There's no idea assumption here.",
                    "label": 0
                },
                {
                    "sent": "That's right.",
                    "label": 0
                },
                {
                    "sent": "Actually, yeah, so that's a good point.",
                    "label": 0
                },
                {
                    "sent": "So here.",
                    "label": 0
                },
                {
                    "sent": "And that's why it's a little bit hard to compare these.",
                    "label": 0
                },
                {
                    "sent": "So in this rate L is actually the L for individual data points.",
                    "label": 0
                },
                {
                    "sent": "So if you have one data point, that's really crazy.",
                    "label": 0
                },
                {
                    "sent": "It's going to kind of screw things up for everything else, but if you have two distributions with the same L value, then the theory says it works the same.",
                    "label": 0
                },
                {
                    "sent": "So you can have weird things happen.",
                    "label": 0
                },
                {
                    "sent": "Almost no result applies in that setting, so bruticus and medics have some old results that apply in that setting, but they are not good, so we have very little analysis for that setting.",
                    "label": 0
                },
                {
                    "sent": "I'll briefly mention something about that case shortly.",
                    "label": 0
                }
            ]
        },
        "clip_201": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so we did.",
                    "label": 0
                },
                {
                    "sent": "We did a lot of testing.",
                    "label": 0
                },
                {
                    "sent": "We actually compared to some pretty serious methods like LB, FGS, Nesterov.",
                    "label": 0
                },
                {
                    "sent": "We tune some stochastic grading methods like crazy and if you look at the appendix of our paper you'll see we actually compared to 14 different stochastic gradient methods including like Ada, Grad and all that stuff.",
                    "label": 0
                },
                {
                    "sent": "But we're just showing the best ones, and when you add the new.",
                    "label": 0
                }
            ]
        },
        "clip_202": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Method on the plot.",
                    "label": 0
                },
                {
                    "sent": "It works really well.",
                    "label": 0
                },
                {
                    "sent": "This method works way better than I thought.",
                    "label": 0
                },
                {
                    "sent": "I thought I was just going to theory paper, but it kind of made me rethink how we should actually solve problems in practice too.",
                    "label": 0
                },
                {
                    "sent": "I was really surprised that it beat LBF Jess.",
                    "label": 0
                },
                {
                    "sent": "I wasn't going to do that comparison but Nicola made.",
                    "label": 0
                }
            ]
        },
        "clip_203": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Do it.",
                    "label": 0
                },
                {
                    "sent": "'cause I I didn't even imagine it would work better.",
                    "label": 0
                },
                {
                    "sent": "OK, so there's been a whole bunch of subsequent the cascarones with linear rates.",
                    "label": 0
                },
                {
                    "sent": "There's this stochastic dual, core descent, SVR G saga, miso.",
                    "label": 0
                }
            ]
        },
        "clip_204": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is on there.",
                    "label": 0
                },
                {
                    "sent": "Talk about SVG momentarily.",
                    "label": 0
                },
                {
                    "sent": "The next thing would SVG in, while focus on is it doesn't have the memory requirement that the other methods have.",
                    "label": 0
                },
                {
                    "sent": "And then I guess next time I'll talk about Nonsmooth problems.",
                    "label": 0
                },
                {
                    "sent": "That's right, yeah, yeah, for sure.",
                    "label": 0
                },
                {
                    "sent": "Yes, not every up to every training point.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                }
            ]
        },
        "clip_205": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so that's what.",
                    "label": 0
                }
            ]
        },
        "clip_206": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alan looks like and I just want to emphasize a few practical issues so you can add regularization if your data is sparse, it doesn't look like this is a sparse sequence of operations, but you can implement it in a sparse way.",
                    "label": 0
                },
                {
                    "sent": "There's an automatic stepsize selection and a termination criterion, so there's no.",
                    "label": 0
                },
                {
                    "sent": "There's no tuning.",
                    "label": 0
                },
                {
                    "sent": "You can just tell the code off my web page an run it, and it just goes.",
                    "label": 0
                },
                {
                    "sent": "There's no, you don't have to step size or anything.",
                    "label": 0
                },
                {
                    "sent": "It figures out on its own there a little bit heuristic key, but there definitely less heuristically than the stuff you have to do when you have truly stochastic objective.",
                    "label": 0
                },
                {
                    "sent": "There's also.",
                    "label": 0
                }
            ]
        },
        "clip_207": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Celerated versions, but two points on emphasize.",
                    "label": 0
                },
                {
                    "sent": "One is the nonuniform sampling.",
                    "label": 0
                }
            ]
        },
        "clip_208": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we had this question briefly about this reshuffling trick where you are and permanent pass through the data anaran permanent password.",
                    "label": 0
                }
            ]
        },
        "clip_209": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Data OK does that work better?",
                    "label": 0
                },
                {
                    "sent": "For classic stochastic gradient methods, the answer is maybe.",
                    "label": 0
                },
                {
                    "sent": "There's a whole lot of empirical evidence.",
                    "label": 0
                },
                {
                    "sent": "In particular.",
                    "label": 0
                },
                {
                    "sent": "Nice report by Lambeau 2 showing that it does seem to work better and there was a paper in 2012 showing if we can show a certain inequality is true, then it's actually true that that's faster than random.",
                    "label": 0
                },
                {
                    "sent": "But this is a very complicated paper, so if you really like math and want a high impact result in, you're confident in your skills, try and prove that.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                },
                {
                    "sent": "We actually saw a version is a little bit weird.",
                    "label": 0
                },
                {
                    "sent": "I don't want to get into it, but you have to basically use agaza subroutine to solve another problem and then use a sequence of those to solve it.",
                    "label": 0
                },
                {
                    "sent": "I don't know.",
                    "label": 0
                },
                {
                    "sent": "No, people have not quite figured out how to do that.",
                    "label": 0
                },
                {
                    "sent": "It's similar, but not the same.",
                    "label": 0
                },
                {
                    "sent": "Yes, so doing you're doing going through all your data points in a random permutation and then switching it and doing another one.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so so the so the company that's actually the companies I've talked to.",
                    "label": 0
                },
                {
                    "sent": "Two companies that are actually.",
                    "label": 0
                },
                {
                    "sent": "What they do in practice, they don't want the random accesses, they do 2 random permutations and alternate between the two.",
                    "label": 0
                },
                {
                    "sent": "And that seems to work OK.",
                    "label": 0
                }
            ]
        },
        "clip_210": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK for stag it doesn't seem to actually help.",
                    "label": 0
                },
                {
                    "sent": "It gets performance intermediate between cyclic and stochastic, which means it's not as good as stochastic.",
                    "label": 0
                },
                {
                    "sent": "Some of the other algorithms that have come afterwards do seem to work with this and we have no idea why we actually know very little about this trick.",
                    "label": 0
                }
            ]
        },
        "clip_211": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One thing we do know a lot more about lately is nonuniform sampling, so we have a nice.",
                    "label": 0
                }
            ]
        },
        "clip_212": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The distribution.",
                    "label": 0
                },
                {
                    "sent": "But you actually try and pick which data points you're going to sample more often.",
                    "label": 0
                },
                {
                    "sent": "So for classic SG you can improve the constants.",
                    "label": 0
                },
                {
                    "sent": "You can improve the dependence on Ellen Mu, but not the 1 / T rate.",
                    "label": 0
                }
            ]
        },
        "clip_213": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On for say, you can actually improve the rate, and the idea is the same.",
                    "label": 0
                },
                {
                    "sent": "You're going to have Lipschitz constant for each function, so you're going to see each functions.",
                    "label": 0
                },
                {
                    "sent": "Gradient has an ally and you sample proportional to those allies, so the gradients that change quickly.",
                    "label": 0
                },
                {
                    "sent": "You want to sample them very often.",
                    "label": 0
                },
                {
                    "sent": "The ones that change slowly.",
                    "label": 0
                },
                {
                    "sent": "You don't want to marry often, and I'll answer that momentarily, but I just want to say for a lot of problems the big allies point class correspond to points you've classified well, and or at least when you start talking to local ally where's the small lies or points you haven't classified well.",
                    "label": 0
                },
                {
                    "sent": "So what this is saying is.",
                    "label": 0
                },
                {
                    "sent": "You don't want to sample the points.",
                    "label": 0
                },
                {
                    "sent": "You've already classified very well very often because you've in some sense already got them, whereas the points you don't have.",
                    "label": 0
                },
                {
                    "sent": "Well, you want to put more attention on them and that kind of just comes out of the math, which is nice.",
                    "label": 0
                },
                {
                    "sent": "OK, go.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so yes, definitely there was an IP server last year, but it improves the dependence on Ellen Mu, but not on like the epsilon and the Sigma squared.",
                    "label": 0
                },
                {
                    "sent": "So the dominant term doesn't get improved, but the sort of the optimization hardness term can get improved by this trick.",
                    "label": 0
                },
                {
                    "sent": "The nice thing with sag is those two terms kind of mixed together so you can improve on everything and so so when you do this sample, you actually depend on the average of these Lipschitz constant instead of the worst function.",
                    "label": 0
                }
            ]
        },
        "clip_214": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so for logistic regression.",
                    "label": 0
                },
                {
                    "sent": "Think of the Lipschitz constant is something that's way out there on the list logistic curve.",
                    "label": 0
                },
                {
                    "sent": "If you're really well classified, then your slope is almost zero and your gradient doesn't change very quickly as you move, so the so the method actually just learns to start ignoring these data points or it samples them very, very rarely.",
                    "label": 0
                },
                {
                    "sent": "I think this is something that could potentially be used in deep networks, is maybe trying to figure out which data points you should sample more often than others, and Yoshi has talked about this and various points in time.",
                    "label": 0
                },
                {
                    "sent": "I've been coming to see far for many years.",
                    "label": 0
                },
                {
                    "sent": "OK, so we're here stick to actually estimate those allies.",
                    "label": 0
                },
                {
                    "sent": "You go so that you can try and figure out what you're doing as you go along.",
                    "label": 0
                },
                {
                    "sent": "So we really want.",
                    "label": 0
                }
            ]
        },
        "clip_215": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Box type of things and these were two datasets from our experiments where we found that sag didn't work well in the sense that it achieved state of the art but didn't destroy state of the art.",
                    "label": 0
                }
            ]
        },
        "clip_216": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the non uniform makes that so.",
                    "label": 0
                },
                {
                    "sent": "But the the adaptive was really important though if you just sample portion of the global Lipschitz constant, it was like a minor improvement.",
                    "label": 0
                },
                {
                    "sent": "But when you really trying to estimate these local ones you try and find out which points are well class.",
                    "label": 0
                }
            ]
        },
        "clip_217": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Spired then then it really helps.",
                    "label": 0
                },
                {
                    "sent": "OK so I just want to.",
                    "label": 0
                }
            ]
        },
        "clip_218": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um, we we have an estimate for each one, we just initialize it to one when we get to that data point, we take a step in the gradient direction for that point, and we know that the function value should change by a certain amount.",
                    "label": 0
                },
                {
                    "sent": "If our Lipschitz constant is big enough.",
                    "label": 0
                },
                {
                    "sent": "If it's not big enough, we just double it until it's big enough.",
                    "label": 0
                },
                {
                    "sent": "The nice thing is, for linear models you can actually do this for free.",
                    "label": 0
                },
                {
                    "sent": "There's there's no cost for linear models, would you?",
                    "label": 0
                },
                {
                    "sent": "Yeah, well you you start reading you know your first pass through the data you're revisiting, like 60 or 40% of the data or something already so.",
                    "label": 0
                },
                {
                    "sent": "I think it yeah it does take a while to kick in.",
                    "label": 0
                },
                {
                    "sent": "That's a good point, but I haven't thought about how long that takes to kick in.",
                    "label": 0
                },
                {
                    "sent": "That's a good point that I should really update my plots.",
                    "label": 0
                },
                {
                    "sent": "'cause in the Journal version we actually do have the like the min and Max and the regions are actually non overlapping like the best run of these algorithms is better than the worst run of this algorithm.",
                    "label": 0
                },
                {
                    "sent": "So, so in the general version we have those error regions, but this this here is just one run.",
                    "label": 0
                },
                {
                    "sent": "Slower.",
                    "label": 0
                },
                {
                    "sent": "So do you.",
                    "label": 0
                },
                {
                    "sent": "I wouldn't say a lot more.",
                    "label": 0
                },
                {
                    "sent": "It's definitely a small constant factor.",
                    "label": 0
                },
                {
                    "sent": "I mean, there's just a few other extra arithmetic operations.",
                    "label": 0
                },
                {
                    "sent": "I mean, assuming like some nice model of computation, where different implementations aren't using different tricks, then then it's almost the same.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I mean, so the stochastic grading methods would definitely be a little bit faster.",
                    "label": 0
                },
                {
                    "sent": "This would be a little bit slower.",
                    "label": 0
                },
                {
                    "sent": "Some of the other methods like would also be slower too, and I think LBF's would be quite a bit faster 'cause that would use vectorized computation more effectively, 'cause it's embarrassingly parallel, but the I have I don't have this one, but on the subsequent paper we do have runtime plots and it didn't change any conclusions.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I think I've got 2.",
                    "label": 0
                }
            ]
        },
        "clip_219": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'd left, I just want to mention mini batching.",
                    "label": 0
                },
                {
                    "sent": "What am I at?",
                    "label": 0
                },
                {
                    "sent": "One minute?",
                    "label": 0
                },
                {
                    "sent": "OK, I think I have two slides reasons to use mini batch with sag.",
                    "label": 0
                }
            ]
        },
        "clip_220": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can parallelize the gradient calculation.",
                    "label": 0
                },
                {
                    "sent": "You can decrease the memory.",
                    "label": 0
                },
                {
                    "sent": "You can also increase the convergence rate.",
                    "label": 0
                }
            ]
        },
        "clip_221": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the convergence rate depends on the Lipschitz constants of the batches.",
                    "label": 0
                },
                {
                    "sent": "If you can make the Lipschitz constant, the batch is much smaller than the worst Lipschitz constant.",
                    "label": 0
                },
                {
                    "sent": "The algorithm converges faster, so you can imagine finding these these bad training examples and putting them in batches with good training examples you can prove that actually makes you go faster.",
                    "label": 0
                },
                {
                    "sent": "How do that?",
                    "label": 0
                },
                {
                    "sent": "Optimally, I don't quite know other than that heuristic.",
                    "label": 0
                }
            ]
        },
        "clip_222": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Big and small trick.",
                    "label": 0
                },
                {
                    "sent": "To deal with them.",
                    "label": 0
                }
            ]
        },
        "clip_223": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Only there's a few ways you can use me.",
                    "label": 0
                }
            ]
        },
        "clip_224": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Batches linear models CRF's it works fine.",
                    "label": 0
                }
            ]
        },
        "clip_225": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If those.",
                    "label": 0
                }
            ]
        },
        "clip_226": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Don't work, you should you.",
                    "label": 0
                }
            ]
        },
        "clip_227": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just PRG.",
                    "label": 0
                }
            ]
        },
        "clip_228": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And I'll just put this up here.",
                    "label": 0
                },
                {
                    "sent": "So one thing I'll say is the practical issues are very similar to say you can talk about acceleration, automatic step size, determination, sparsity regularization, nonuniform sampling, mini batches and so on.",
                    "label": 0
                },
                {
                    "sent": "The key difference between Saginaw CRG is that SVG does not require the gradient of every example.",
                    "label": 0
                },
                {
                    "sent": "It just requires storing 1 old parameter vector and doing.",
                    "label": 0
                },
                {
                    "sent": "Two gradient evaluations on each iteration, so you need to evaluate the old parameter vector and the new parameter vector.",
                    "label": 0
                },
                {
                    "sent": "It's a little bit slower, but it gets rid of the memory, so now you can apply it to any problem you want.",
                    "label": 0
                },
                {
                    "sent": "I'll talk a little bit more about this next time, but again, it's a very simple algorithm.",
                    "label": 0
                },
                {
                    "sent": "You can implement this out.",
                    "label": 0
                },
                {
                    "sent": "This is this afternoon.",
                    "label": 0
                },
                {
                    "sent": "Try it on whatever problem you want.",
                    "label": 0
                },
                {
                    "sent": "Constant stepsize.",
                    "label": 0
                },
                {
                    "sent": "You know, fairly easy to tune.",
                    "label": 0
                }
            ]
        },
        "clip_229": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so just to summarize part one.",
                    "label": 0
                }
            ]
        },
        "clip_230": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You need to know L or you need to have an approximation of L and so we do that same trick where we start with one and we increase it.",
                    "label": 0
                },
                {
                    "sent": "If the inequality is we want to be satisfied or not satisfied.",
                    "label": 0
                }
            ]
        },
        "clip_231": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so convex functions have special properties that let us efficiently minimize them.",
                    "label": 0
                },
                {
                    "sent": "Grading methods are good for high dimensions.",
                    "label": 0
                },
                {
                    "sent": "Stochastic rating methods are good for large training examples, but you have a slower rate.",
                    "label": 0
                },
                {
                    "sent": "And then for finite datasets, sag sort of fixes the convergence rate, but introduces the memory.",
                    "label": 0
                },
                {
                    "sent": "An SVG fixes that.",
                    "label": 0
                }
            ]
        },
        "clip_232": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Mary Ann so tomorrow will talk about non smooth test error and non convex problems.",
                    "label": 0
                }
            ]
        }
    }
}