{
    "id": "dvh2ph4yvyqqekpb4pcq3kcoilhvxsyn",
    "title": "How to discount Information: Information flow in sensing-acting systems and the emergence of heirarchies",
    "info": {
        "author": [
            "Naftali Tishby, School of Computer Science and Engineering, The Hebrew University of Jerusalem"
        ],
        "published": "Oct. 16, 2012",
        "recorded": "September 2012",
        "category": [
            "Top->Physics->Statistical Physics",
            "Top->Mathematics->Control Theory",
            "Top->Mathematics->Optimization"
        ]
    },
    "url": "http://videolectures.net/cyberstat2012_tishby_bellman_equation/",
    "segmentation": [
        [
            "Alright, good afternoon.",
            "It's really a pleasure and scary experience too.",
            "Be invited.",
            "Such a workshop and appear to people really.",
            "Not only the generators of most of the ideas I'm going to talk about probably see a lot further, and it was especially difficult to follow the previous talk of comprison 'cause you're going to see a lot of similar terminology.",
            "I just hope that.",
            "Maybe some of it will be in somewhat simpler and more understandable context, but.",
            "So I'm using the word free energy and information flow and hierarchies and many other things that are common to many of the talks here, but somewhere in between, let's say friston and and Beth trying to bring it back to the mathematics to some concrete mathematics.",
            "And maybe we are really on the way of understanding the brain, but we'll see what we really want to do is really understanding the connection with information and control, and I'm sure that this is common to many of us, so I'm also multi."
        ],
        [
            "Created by cognition and by the brain.",
            "And very much like what you just heard I, I think of a very simplified version of of the picture of our interaction with the world.",
            "Some cycle that is often drawn in many cognitive science books.",
            "In this way, there's an Organism.",
            "There's an environment, and there's some something that comes from the environment to the Organism.",
            "In terms of sensory perception, sensory information, and something else which comes back from the Organism to the environment in terms of decisions, actions, planning, and all those executive functions.",
            "So this is very simple.",
            "It's really the first page of.",
            "Cognitive science in some sense.",
            "And what is becoming more and more popular is really to think about this cycle.",
            "Off the cycle of actions and perceptions between an Organism in the environment, as in the terms of this is my favorite definition of this perception action cycle, which is taken from the book of Young Foster on the frontal cortex.",
            "The circular flow of information that takes place between the Organism in its environment in the course of a sensory guided.",
            "Sequence of behaviors towards the goal.",
            "So everything is here.",
            "Actually I'm only going to pass this sentence and expand a little bit.",
            "So essentially, right after this sentence in posters book, you see.",
            "Very good, big caveat.",
            "I don't mean here information in Shannon since we actually had some more, you know relaxed version of it.",
            "But actually I'm going to argue quite rigorously that there's no other choice.",
            "Possibly if you really want to talk about this flow of information.",
            "In any sense, then it must be Shannon sense, not because of the fact that is actually communication here.",
            "I'm actually not going to use the communication aspects of general theory, but actually from much simpler and maybe more fundamental mathematical reasoning which really follows the documents that birth given their first talk of large deviations.",
            "Essentially, we're looking for the typical behavior of a system, and there's going to be some large number here, which is going to replace the.",
            "The thermodynamic limits and some of them are still physics, and this is actually interesting to investigate.",
            "What is really going to push us towards this large deviation limit.",
            "And of course the large numbers.",
            "I'm going to assume is that this cycle is actually running many, many times when we before anything we really have many cycles of interaction with the environment.",
            "And of course we know that in some in some very basic sense.",
            "The cycle of actions and perceptions is really what the brain is doing.",
            "There's nothing else there, so the brain cortex, but not only the cortex is largely divided into important frontal and also where the frontal part is the red part here is largely responsible for what we call executive functions.",
            "This is again taken from foster this picture and the other part is largely responsible for perception.",
            "Processing perceptual information vision audition smell.",
            "Both or smells actually not in the quote is somewhere else, and actually there's not one cycle than many cycles on many times skills.",
            "Actually, if we look at the sensory motorcycle, it's order of hundreds of milliseconds.",
            "I mean when I touch the table here and actually operating, I'm acting and then sensing it's happening immediately.",
            "I mean there is some response of the table due to Newton's third law.",
            "Of that I feel immediately encloses the.",
            "When I talk to you, there is a larger cycle here and obviously during this lecture you're going to have exchange of information on many time scales, and this is really very typical for interaction with the environment, and so this hierarchy of timescales must somehow evolve in the brain.",
            "And of course Carl mentioned it several times in his talk.",
            "I'm actually trying to understand how such hierarchies can emerge from some basic mathematics, so of course.",
            "When you look at this sentence in this picture, you should think about this as some sort of channel of information.",
            "There's an information of perceptual information that comes from the environment to us, which is noisy and partial and is highly adaptive.",
            "I mean, this sensory channel or perceptual channel.",
            "There's actually a capacity here.",
            "I mean, there is a limited amount of information that we can perceive.",
            "From the world is obviously a lot less than our sensory.",
            "Input is, I mean even just the vision is a lot more than can actually perceive, and so we everything goes through some sort of bottleneck innocence.",
            "And we must do some filtering.",
            "Some selection of the relevant information in our perceptual mechanism.",
            "This actually goes back to your ideas about attentive attention, control, attentive control.",
            "It's actually the same type of this cannot be a complete full of information, only very little out of the past information.",
            "Environment information is really relevant for this other channel.",
            "The predicted channel or the action channel.",
            "I think I've been doing or in our interaction with the environment is maybe not as obvious that there is also information flow here, but when we make decisions when we do planning, we actually.",
            "Need something you can think about it in the simplest possible way as the information flow from the brain to the actuator from the controller to the actuator.",
            "This is a capacity of a controller and of course as control theorist.",
            "Many of you know that we would like to minimize this in many ways.",
            "We would like to minimize the flow of information here and there's some constraints.",
            "This constraints.",
            "Of course the ability to interact."
        ],
        [
            "So of course I can go into dive now into details of Physiology of the brain and actually show you that really different parts of the cortex and subcortical areas that Alamos in the basil, ganglia and so on correspond very nicely to this dual role of fundamental role of of the brain making useful.",
            "Collective compression if you want of the information from the sensory perception and making valuable predictions that will lead eventually to valuable decisions and valuable actions.",
            "I don't want to do this.",
            "I mean zooming into the brain now is way too complicated.",
            "Actually, going to zoom out and really think about it as a caricature in some sense, what is really the really the fundamental limits on the ability of such flow of information?",
            "Such cycles?",
            "I think it's a very special.",
            "I don't pretend to solve the whole problem, but I really want to see if there is something like statistical physics or thermodynamics that will link the flow of this information in these two channels with actual reward and cost this metabolic reward and cost the food that we eat.",
            "The energy that we consume.",
            "Maybe the computation that we need to do, and so on, which are real entities that we need to deal with.",
            "How how is this related to this?",
            "This capacity of the flow of information in these two channels.",
            "This is the basic question I want to address 1st, and then I'll fill develop some formalism for this."
        ],
        [
            "Essentially, my caricature of the brain is that all the brain is doing is doing some sort of selection compression, compressed sensing if you want, but I don't really like this this word, but some sort of compression of the past information.",
            "With respect to future actions and decisions, so it's, and that's all it starts.",
            "And of course you know that to make sense of it in order to evolve in a competitive environment like biology is all about the some constraints on physical entities, like the value of our actions and the cost of our sensing, and so on.",
            "And this constraint must be there, so we are looking for optimization principle of variational problem that will optimize this flow of information in a way that will achieve a certain value.",
            "So this is simple enough to the kind of constrained optimization problems if you're all familiar with in some of the mix in statistical physics and control theory and so on and so forth.",
            "And this is I guess while we're here notice, by the way, this is a system with feedback, cause everyone of those cycles there's actually information flow in a sense from the future to the path through the environment.",
            "Another way of saying it is that.",
            "We actually have knowledge there is information about the future.",
            "We call this predictive information and this information about the future.",
            "You can think about it as the capacity, the predicted capacity of the environment itself, how much I actually know about what's going to happen.",
            "So unlike what most people tell you that we can't predict the future.",
            "It's actually quite the opposite.",
            "We could not survive without predicting the future.",
            "Our all existence here depends on predictions and that sense of equilibrium car, but.",
            "If I come back to his first question, what really separates life from nonliving Organism, nonliving things.",
            "It's not.",
            "I don't think it's just I didn't understand exactly your separation, but there's something very.",
            "Simple cloud very closely related living Organism.",
            "Exploit the predictability of the environment for the benefits.",
            "In a sense, they on short-term front row timescale don't really act causally, they don't.",
            "They're not motivated just from the past, like the initial conditions of physical system, but they know something about the future which they exploit and the further they look, the further they know into the future the better the advantage in terms of evolutionary fitness.",
            "So it's only the exploitation of the predictive information which makes life interesting.",
            "And if you think about it, trees.",
            "Flowers for example.",
            "Know that the days are going to be longer in some sense and know that the bids are going to come and that's why they do this funny thing like getting flushing the spring and so on.",
            "I mean, of course there's some information this information was was learned and acquired through millions of years of evolution, but on a short time scale, a simple Organism, even bacteria, has some looks as if on short timescales, it's.",
            "It's predicting it has some knowledge.",
            "Its behavior actually depends on some flow of information from the future to the past.",
            "Which of course the control theorists is very familiar.",
            "This is the cost 8IN optimal control or this is something which must come back?",
            "Not so we are all acting with some causal with some causal flow due to the physical systems that we are embedded in, but we know something about the future and that's why we plan we can plan.",
            "So this feedback is actually quite tricky.",
            "It's feedback through the predicted channel of the environment.",
            "OK, so when the fundamental."
        ],
        [
            "Action in perception is of course.",
            "How do we make sense of of things like this?",
            "I mean, so this is a famous slide I took from Chris of course, but has nothing to do with this talk about consciousness.",
            "So how is this collection of pixels eventually is perceived as there is a dog there?",
            "So now this is really the fundamental question of perception, and it was there is there is a very famous paradigm given by nicely formulated.",
            "I think, originally by Hellman's but but we usually attributed to David Marr's feet forward paradigm and we start from very simple elements in the image like pixel edges, corners and so on, which correspond to nicely at least seems nicely to the different layers of the visual cortex and eventually somehow miraculously.",
            "We do this bottom up processing and we get the percept of a dog or a man or whatever it is.",
            "Now it's interesting.",
            "That's already theoretically."
        ],
        [
            "In the early 90s, John Toasters, among many others, who is theoretical computer scientists, simply did a very rough calculation of is this feedforward process possible at all visible in terms of computational mechanisms in what we know about the brain and he came to the conclusion this cannot be true.",
            "There's cannot.",
            "It cannot be that we actually see by.",
            "Starting from every pixel in the image and then do some sort of feedforward mechanism that will eventually lead to and he simply gave a really rough orders of magnitude like computer scientist, calculation of complexity and said that this is exponential in the number of pixels.",
            "There's no time for that.",
            "And at the same time or less actually, I usually quote Charleston America suffered because those friends of mine from Jerusalem, but other people as well in cognitive science and notice that, and this is actually these are two pictures taken from their their papers in nature paper in 1997.",
            "I think that and then later 2002 that essentially our perception, intelligence cycle physics in terms of reaction time.",
            "Goes actually the other way around.",
            "If I flash a little image to you.",
            "And tell you what their face there or not.",
            "Most of you will be able to say with high confidence there was a face, but if asked what was the color of the left corner mostly will be completely wrong or is was there a little tiny thing so it couldn't be that you first notice all the details and then realize that there's a face.",
            "They simply then there's no time for this and they realize actually have a reaction.",
            "Time goes down in sense that we first notice the big things and only later we are able to distinguish the little things, the details.",
            "They didn't give an explanation to this, but they call it a reverse hierarchy model and this reverse hierarchy models is very we know it.",
            "Of course even better for audition for speech recognition.",
            "For example, we couldn't understand speech at all if we didn't have a predictive model of the words anybody ever worked worked on.",
            "The engineering of speech recognizers know that we need the language model, which will essentially give us prior distributions over words and essentially we guess what we are hearing and instead of actually.",
            "Building the dog from the details were really guess there is a document or other reasons predictor is done and then go do something much simpler statistically and computationally, which is hypothesis testing rather than generating a generative model of the image.",
            "We test the hypothesis.",
            "Is there a dog or no dog?",
            "And for this we need very little information.",
            "We actually need to know if there is.",
            "So if you very few I mean log or even log log in the number of pixels observations will give us very high confidence about this.",
            "This type of question, or is there a dog?",
            "Is there a tree is their face and so on.",
            "So hypothesis testing is computationally a lot more efficient.",
            "And the first thing in speech, we do it all the time.",
            "You actually guess what I'm going to say most of the time you are more or less right about every word that maybe even if every sentence actually what you are doing when you listen to me now, you're simply checking that your predictions are right, and in some cases I may surprise you and then you re adjust your predictions.",
            "And by readjusting your predictions you actually understand.",
            "So most of the content of this talk and any other talk or paper or book or whatever it is or movie is in this corrections to your.",
            "Predictions and that's why we do it sufficiently, because most of the time you predict pretty well.",
            "OK, so again so we have a lot of psychophysics and actually electrophysiology that's supposed both this reverse hierarchy models that actually there's some backward flow from the higher level of the brain that makes this prediction.",
            "Speech, it's really quite nice.",
            "I mean recent work by my friend Alan Elkin, on auditor perception.",
            "Really verified it very nicely.",
            "You really see a cascade of the activation along the auditory hierarchy starts from the top in some sense and then only then at some lower level you really follow the details of.",
            "Mission Bay and they essentially you don't need to do much for this is it's very hard day or just have to measure the onset time, voice onset time of the D&B.",
            "It's a very little, very focused information.",
            "This is essentially how the brain works as men standing today, although there's some still some people want to mention names or we believe that we have a generative model.",
            "So this is just an illustration."
        ],
        [
            "And I mean really see what they expect to see.",
            "Maybe all of you have seen this picture before, but if you don't and I don't tell you something like domestic dog, you will never see it.",
            "But if I tell you with some effort you eventually see the dog there.",
            "How many of you know this picture?",
            "Again?",
            "You make sense of it only after I tell you something like nude.",
            "Women's back or something like this then it will take some time, but usually figure it out and it's very much like this all the time.",
            "So these are just illustration.",
            "OK so."
        ],
        [
            "My talk is not about."
        ],
        [
            "Examples like this was the high level motivation.",
            "So essentially what I really want to make sense of this claim that perception actually cycle is really a control loop with constraint information flow, and I am actually going to argue.",
            "Using using the mathematics that was already given to you by the 1st or for example, the large deviation idea and some other talks that we can actually solve this problem.",
            "Actually, there's a very important slide that I. I should should put before the outline may show it now.",
            "I."
        ],
        [
            "I don't believe that the brain solve intractable problems.",
            "If there's anybody believes this, I coming from computer science at least partially from computer science, I really believe that the main contribution of computer science to understanding the world is that they more or less tell us what are difficult and water easy problems, and we know that nature.",
            "Brain in particular cannot deal with what is probably intractable.",
            "So if something like this appears to happen, we understand the problem.",
            "Probably we don't formulated correctly or the brain is approximating it.",
            "Some other tricks using some other tricks, and that's exactly what we're looking for.",
            "The simple principles that lead to tractable algorithms."
        ],
        [
            "So.",
            "I'm going to somehow dive into this acting, sensing acting loop and especially the role of information, but again, not not my laying on you.",
            "The heavy theory of communication, but starting from a very simple assumption.",
            "I'm looking for the typical behavior of such of such a cycle in a stationary stochastic environment such that I can really talk about what I call them.",
            "I will call later on the metabolic information processing, so this was really a very nice hint.",
            "Metabolic information processing essentially is the trivial thing that you're robot that cleans your house and have something like this that actually has sensors and actuators is doing when it moves around.",
            "I'm essentially the simple sensors that simple motor controls, motor commands, and these two are balanced in a way which makes you happy eventually, which means that the overall tradeoff between the amount of information and get that this robot can get through the sensors and the amount formation he needs in order to.",
            "Act usefully is enough to for you to buy it, which is really the value function here.",
            "In some sense it cleans the house eventually somehow, and not more than that, and so the question I'm asking, what is the minimal amount of information that you really need to get from the environment in order to act with certain value of actions?",
            "This turned out to be a very simple question, and in order to actually make sense of fashion quantities, it's a lot easier to do.",
            "Despite my admiration and loves of differential equations and continuous time and infinite continuous state space, it's a lot easier to discretize things and to work with what we call Markov decision processes or partially observable ascension process where everything is finite both and time is discretized, and then we can really talk about how much information is.",
            "Extracted or absorbed in one cycle.",
            "Come on, say it.",
            "By the way, I have worked in the last year a lot on or making a continuous version of this story, and it's not that difficult.",
            "It turns out to involve all the nice mathematics that we heard about.",
            "I mean, manifolds, Lee groups, vector fields, and all these nice things immediately appear because you need what you mean by prediction.",
            "When you talk about continuous observation, essentially the flow and this flow obeys all sorts of symmetries, and so on.",
            "So there's a nice story to be told, which I partly understand now about the continuous version of these tourists.",
            "But in order to make it simple, I want to talk about of artists vector about spynet states for state space."
        ],
        [
            "And discrete time.",
            "OK, so again I want to connect large deviation with."
        ],
        [
            "With the with control it's not new.",
            "I mean the people I'm going to re discover things that were discovered before me and some of the algorithms that Emotiv discovered independent, very very similar.",
            "Just the view is slightly different and application is something different.",
            "So MDP is nothing but a collection of states with actions and a transition probability that tells us how the how are you going to move from one state to another given condition on the action.",
            "And of course on top of this tuple of state actions.",
            "Function probabilities there is also a reward.",
            "Now this rewarding control is a little bit arbitrary.",
            "I mean, what is it?",
            "I mean actually should be something meaningful, but it turns out it's not really important.",
            "It's some sort of quantity that you attached to.",
            "So if I stayed S1 and I do the action a 0, there's some probability that I will move to a 2.",
            "There's two and some other probability.",
            "I'll move to S 0, and so on, and there is reward.",
            "This emission of reward that is associated with every arc in this graph.",
            "So this is a very simple structure.",
            "And of course, the basic problem of optimal control formulated in this in this language of of of Markov decision processes or partially observed Markov decision process is exactly the same mathematics that just discretizing time.",
            "I want to find a policy which is essentially a control law.",
            "Given my knowledge about the state, which may or may not be complete, it may actually be filtered through some sort of noisy observations.",
            "What is the optimal action and this optimal action can be stochastic, so I assume some sort of probability distribution on action given state.",
            "And of course, given this pie probability or policy of action, I can in principle calculate the expected accumulated reward or the value of my policy very simple."
        ],
        [
            "We all know that this is essentially the taken from Southern about or the famous reinforcement learning is just rediscovering or rewriting of what you all know in the optimal control in terms of discrete States and rewards, and essentially so we have states we have reward.",
            "We have actually have rewards, and so on, and we everything moves in a Markov chain, which we assume to be a Dick in order to make sense of it in Infinite Horizon.",
            "Otherwise we're talking about finite horizon."
        ],
        [
            "You, I'm sure or no, there is a very elegant solution this problem calculate a value for each state.",
            "Which is essentially just expected for every given policy.",
            "Calculate developers state which discounted expected reward.",
            "With exponential discounting, this actually is going to be tricky, so I'm going to put a question mark on this gamma here, but this is what's done in Infinite Horizon formulation.",
            "All the places you put in fact less than one here and then.",
            "These things converging if R is bounded and you get this very nice Bell month, which is reincarnation of the Hamilton Jacobi equation for entirely different purpose.",
            "But you get this.",
            "Linear connection given the value and the and the dynamics between given the policy and dynamic between the value at different states physicist I always defenses.",
            "I would like to say that this is very much like the person.",
            "Equation essentially tells you that V acts like a potential.",
            "It just averaging the potential in the neighbors and adding the source source in terms of the reward or which is just the source charge or the source current.",
            "So this is very familiar equation.",
            "We all know how to solve it even on grids.",
            "Using the laplacians of losing, losing the tricks of of solving Laplace or person equations I don't want to do this, it's not interesting.",
            "What is really interesting about it.",
            "This equation allows us to fold apparently exponential complexity of following very long trajectory's into a linear equation which has the complexity of the number of states, time, the number of action, normal state squared.",
            "Then I'm going to number function so it's tractable for small number of bits and.",
            "Of course, what we all do, what?"
        ],
        [
            "Are all people do they iterate?",
            "They do this policy iteration algorithm.",
            "The iterative mean estimation of the value given the policy and then optimize the policy.",
            "So this is a nice.",
            "This is an example of what I call a tractable problem, so it's converging globally."
        ],
        [
            "And it has very nice properties.",
            "So now I want to."
        ],
        [
            "Come back to information and see if we can really bring channels idea about may solving, which he had already in the 50s with Belmans notion of dynamic programming optimality."
        ],
        [
            "And it's actually very simple if you put everything in cost, everything in terms of graphical model.",
            "So graphical models have been mentioned before the esentially discretized version of random variables and with some errors that describe the statistical connectivity.",
            "So in this case, for example, the world is described by this variable W in this three times, and it has it's a Markov chain on its own, which means given WT one WT plus 2 WTR this independent.",
            "You have everything fixed, so it's a Markov chain.",
            "And of course, as you know, it's a directed Markov chain, so essentially there are very few variables here.",
            "These are, this is.",
            "Let's say this is the mind or the mental image of the Organism, and essentially the perception action cycle is now accustomed to this infinite dynamic Bayesian network or graphical model, where these are the observations, the noise observation.",
            "These are the actions the world is evolving as a function of the actions and the mind is evolving as the functions of the observation and its memory.",
            "So I can now write a probability distribution.",
            "For all this, for a long sequence of such cycles, given essentially for quantities, the dynamics, how are states of all the function of actions, the dynamics of my memory, which I have to find out?",
            "How is the memory change the function of the stations and the policy, the policy channel or the actions channel and observation channel?",
            "So these are the four things that you would like to optimize.",
            "Let's start with the simplest possible problem.",
            "No, no noise in the observation which we called the MDP problem.",
            "So essentially the mine has full knowledge of the environment.",
            "It's a Markov decision process and only the policy is the variable.",
            "This is enough to already see the full general structure here, so again these are.",
            "This is the perceptual channel.",
            "This is the predicted channel as I called them and their two quantifiers.",
            "One is the reward associated with transition from one state to another state in the world so.",
            "When I gain some food, or you can make some money in stock market or whatever, the state of the world as far as I'm concerned is changed and they got some reward out of it.",
            "Or when I hit the wall or whatever it is.",
            "But as you see just from the symmetry of this of this graph that they must be something here.",
            "What do I gain when I actually observe something from the world and and received?",
            "Let's say I did A and received oh and I know that my memory went from empty 20 + 1 due to this interaction.",
            "Action observation this active, active, active sensing, so I argue that there's a very natural quantity here, which is going to come from the from the sun over the large deviation theorem, which is essentially.",
            "Easily interpretable, and this is only my main contribution to this meeting.",
            "I want to interpret this information in terms of quantities, which I understand in terms of the cycle, so I'm going to call this information games.",
            "I'm going to make them explicit in a second, so there's two types of quantities, not only the external reward, but also how much I really my mental state gained and both this gain is as far as I'm concerned it can be only one thing information, so this is a philosophical picture, but I'm going to go back to the mathematics in a second and make it very, very very concrete.",
            "So essentially what I'm looking is the typical.",
            "Behavior of such a graph of such a model under a constraint on the value of the action.",
            "Since the value is just a linear function of my, my dynamics and policy, I can it's going to be a linear constraint on the on the function space and everything, and I can minimize the KL divergent very easily due to son of and get very nice typical concrete answer this question what is the typical long long term behavior?",
            "Remember, I assume that there are many cycles such that I can really use this asymptotic.",
            "Large deviation theory OK. How does that compare with?",
            "System identification and how much we are proving our probability distribution perspective decision.",
            "It will get back to this in a second.",
            "I'm going to devil drill on this Delta and tell you a lot of things about it so I really find interesting both cognitively and control theoretically, so just want to remind you what do we mean by by the by the large deviation.",
            "So essentially we talk about a space of distribution, so this is generally described as some sort of simplistic, which we we."
        ],
        [
            "For simplicity, drawers strangle in two dimensions.",
            "Of course, there simply are in general more higher dimension limit and by value constraint essentially have some linear constraint, some expectation value constraining some distribution.",
            "So when I say that I start with some initial Q, might say completely random or something some prior distribution over states over some variable X, and when I give a linear constraint, logic nation is telling me that the most likely distribution in this set this is going to be.",
            "Well, let's see if this is a drunk.",
            "Random motion, random action, and this is some value.",
            "The probability that this drunk will actually achieve this value is very low.",
            "It's exponentially small in the number of steps that the drunk moves, and the value, and it's actually completely dominated by one point in this.",
            "In this convex set, which is the one which minimize the detail subject to this concern.",
            "I'm sorry there's a constraint that belongs to this set of growth constraint on the value, so this is a very simple mathematics.",
            "That's all it is.",
            "That's so simple that you can really design a very simple algorithm, and indeed it tell it's telling you the problem.",
            "If this drunk somehow got into this region with very high probability is going to be here the chance that they will find him here is exponentially small in the detail between these two things relative, so larger versions are very powerful.",
            "Very powerful tool you can apply to ID to Markov chains from a lot of stationary distributions, and essentially this is all I'm actually using.",
            "Patrol marker that's right, it's still the same game as far as I'm concerned.",
            "There is one distribution which some of it.",
            "Some of those distributions can achieve this value and I'm looking for the most likely one in this class.",
            "Of course, if if your class is this actually.",
            "Sorry, technically this is one of those water this summer.",
            "If you can transfer this bottle, it will be helpful.",
            "So technically, of course the trick that I'm using here is to work too, by optimizing the DKL you don't maximize the likelihood, and this is really the secret I believe of both statistical physics and information theory, and also this type of application to control is that the variational problem is minimizing hail divergance, which has a lot.",
            "It is a lot nicer than just maximum likelihood in many ways.",
            "In particular, such sets are convex under very general conditions, so we can easily solve this problem.",
            "Which means really, the sympathetic limit of where N here is really the.",
            "Sample size in this simple case and and sample the number of cycles in my perception action cycle, so I guess I don't need to say it here, specially not after."
        ],
        [
            "Talk that that action sequences and codes have a lot of similarity, so actually you can describe projector is on a graph using a set of actions go left, go right now.",
            "Especially I want and I can talk about the minimal description or what is the shortest path or this simplest description of less safe to get from here back home, which in my case is quite far, and so essentially eventually it's a long list of bits to right and left whenever you come to some codes in junction someplace to make decision, you can essentially such descriptions of trajectories.",
            "Obey the Kraft inequality.",
            "They behave very much like like code words and I can concatenates them.",
            "I can do all the tricks that Shannon did with codes.",
            "Information adjustment, describing projectors in the shortest possible way, so it makes perfect sense to describe the trajectory on a graph by a sequence of bits.",
            "And there is one.",
            "There are many of course, code coding scheme, but there's one minimal length.",
            "That that correspond to the shortest description of a trajectory in a graph.",
            "So somehow you already seen very clearly that there's some really nice analogy between Belmont type of tonality and what people do in information theory when they encode information.",
            "For example, Huffman code, which you're all familiar with.",
            "I hope building an optimal tree of questions that eventually reveal information or entropy reduction by minimum number of questions, or by the shortest 3 on average is just a special case of a bellman.",
            "Optimality principles are going to see immediately.",
            "Essentially, you can merge the two into into one equation, so again, so I can."
        ],
        [
            "About about interaction with the world or some sort of the world move, I move the world move, I move and then I can I can describe the number, the possible actions in my trajectory and describe this as a code word.",
            "Given the encoder, which essentially is my behavior policy, which of course includes the model of the world itself.",
            "And then it's essentially a trivial statement, which I called here a theorem, but it's insulting mathematicians that if I describe, define, define the quantity, which is nothing but the KL divergent between the posterior and prior.",
            "Given the goal, let's say accumulate certain value and the sequence in the state.",
            "So this scale divergency numark of environment.",
            "And I'll make this explicitly in a second obeys this very simple type of Berman Berman equation.",
            "The information for the missing information.",
            "This investments it's mutual information, but it doesn't have to be or conditional information will see in a minute.",
            "There are many, many different quantities that can appear, but it's this scale diversion simply comes from the Son of theorem or from logic Nation.",
            "This is what I want to minimize.",
            "If I have a Malcolm environment, which means that I can factorize my distribution over overtime into states.",
            "Conditioned on the previous days, then I can write this recursion equation.",
            "The information about my goal at the state St is the average information about my goal.",
            "The state is S, T + 1 plus what I gained in between and what again in between, which I called.",
            "The information gain is here, not arbitrary.",
            "It depends it simply by essentially cutting off."
        ],
        [
            "Log 10, so here's here's an exclusive calculation.",
            "I called this information to go because it's just like the cost to go in control, but it's actually the information they have about the future States and action of my behavior.",
            "Where is it?",
            "It wasn't an intention to be very general and call it a general goal.",
            "For example, rich home or accumulate enough value or whatever.",
            "It can be something which is finite and then you have a finite horizon planning or something like this.",
            "It can be something which are coming on the way, so it's a very abstract notation for something that you want to achieve.",
            "Think about goal at the end of the maze or something now, so this information to go is nothing but the KL divergent.",
            "Of the conditional future states, an action in the MVP case conditioned on my current state and action.",
            "My current certain my next action.",
            "This is very much like the Q function in RLI.",
            "Can, of course.",
            "Condition is another thing, but this is much easier this way and I take his prior.",
            "That's the stupidest thing that I can think of which is completely independent actions of states 'cause you actually in some other cases, whichever is later, we actually assume some sort of unconditional state transitions, very much like what you did, unconditioned, which means independent of the policy.",
            "So this you can sexy kisses the queue or uniform prior.",
            "So there is a KL divergent of conditional expectation of the log likelihood ratio likelihood of all the future given some path.",
            "Consider it's some to some point.",
            "This point I don't really worry about work that emanated, it's going to be important eventually.",
            "So think about it as finite horizon and this.",
            "Information to go very much like the value in the Bellman equation.",
            "Is factorized trivially into the information to go in the next state and action +2 terms which are simply shuffled off this log.",
            "There's nothing there but this time, which is 2 terms are interesting conceptually because that's why I know them as red and blue, just like the blue and red parts of the brain one is associated with the action and the other one is associated with the perception and actually very interesting.",
            "So the first one, which is some sort of information gain given a certain state and a certain action.",
            "This can be negative or positive, and this is the information gained in this of this.",
            "Specific is actually not the information.",
            "Again, is the control complexity.",
            "How much I really need to change my action when I know the previous state versus not knowing it?",
            "How much information is there about my action when I know the state of my system?",
            "This is nothing this is going to average of course, do nothing but the mutual information within states an action or the capacity of the predicted channel.",
            "So this is simple.",
            "The first time is simply the predictive gain or the control capacity.",
            "Using control theory for many years this is it was there is some control ability and and observe ability assumptions underneath here, which I don't want to argue it actually generalizing these concepts a little bit to stochastic combined.",
            "The second term is actually more interesting in some sense.",
            "It's the response of the environment to my action given the previous state.",
            "So let's say I was trying to drive my car to the left, but for some reason is moved to the right or move straight.",
            "This is surprising thing to me, and notice that when I want to minimize.",
            "This KL divergences in order to achieve the large deviation limit subject to the value constraint.",
            "I will want to minimize the average this and to minimize this average, just this average is actually clear why I want to minimize it?",
            "It's minimizing the control capacity.",
            "I want to send a list number of bits to the from the controller to activate.",
            "This is exactly your principle of of attention, but this is somewhat surprising exactly directly related to one of the terms in in cars talk.",
            "And when I think about it, in some cases makes perfect sense.",
            "For example, if I play an information game with you, I I play a 20 question game, for example, you choose a number and I have to choose the action.",
            "The actions which in this case are the questions that I want to ask you, so of course.",
            "Let's say you choose another thing.",
            "100 stupid question will be is it 17 and the clever question will be is it larger than 50 Huawei becausw I maximize?",
            "The entropy of the outcome in some sense I'm making.",
            "I'm keeping the options open and some people call it an annual plan for example.",
            "And actually this is directly related to what some people like colonic cause empowerment.",
            "Essentially how much I am allowing the environment too.",
            "I keep many options actually pushing my pushing the system into instabilities in a sense that the I want to maximize the entropy of the next state given the current state and the action which is against the intuition in many ways.",
            "But you think about information gains.",
            "This is precisely what you want to maximize the entropy of your outcome given the current action.",
            "This is what you want to do.",
            "Right, so so the two quantities which look opposing here.",
            "And that's again I won't call any of them surprise at this point, but this is actually related surprise, and this is a letter to control complexity.",
            "Notice that essentially they're going to average into the mutual information within the state and the action and the conditional information between the action in the next state given previous state, which is exactly some people call empowerment in control.",
            "I don't know if this is a popular term here, how much I really can affect.",
            "How much the system?",
            "How much information I have?",
            "I can affect the response of the system if I do something and it doesn't change anything in the world of my sensory perception doesn't tell me anything about the world due to my action.",
            "Then I have no empowerment.",
            "I don't, I don't.",
            "I can't do anything, but if my actions are actually changed, the world in such a way that I sense it and I have a high capacity of this action sensing both of them are actually action sensing capacities.",
            "But one of them is within the current action and the previous state.",
            "And another one is between the action in the next state.",
            "So this is the response of the world.",
            "To my actions, how much I can really learn from this response in the in simple information gains.",
            "This is precisely the entropy of the answer before you got it.",
            "OK, so this is really nice in the sense that I can justify.",
            "Of course everything is justified by large deviation.",
            "That's what I want to do, but I can give very intuitive sense for these two quantities in terms of the cycle of perception action, one is now OK, so now."
        ],
        [
            "I have this information there our L as I call it.",
            "Essentially you do some active sensing, you get information and you can play essentially every response that you get from the environment due to a measurement is shifting you on the simplex.",
            "And the simple possible, let's say 20 questions or information game you want to discover information.",
            "You simply want to reduce the entropy and push yourself to the corners eventually, as the fastest possible way, and so building optimal codes or husband causing fuel after half an algorithm.",
            "Things like this a special cases of of this special RL and those of you remember about Huffman codes?",
            "There's something very funny there.",
            "You have to start from the end and go backward, which is precisely what you do in Belmont.",
            "I mean, you have to start from the Golden Gobekli, so believe me, I'm not going to prove it.",
            "But the Huffman algorithm, the special case of rlin biscuits.",
            "OK, so this was so reassuring that maybe we're going walking in the right track here, and I can address many."
        ],
        [
            "Any different information questions like this like finding the false coin or many simple exercise in simple noiseless khodadad lossless coding and you're going to see that they're all in principle solvable by such walk on on the simplex.",
            "Of course, if you think about it, the problem is a lot more difficult than just simple because I need to in principle finding a point on simplex is already a continuous state.",
            "This is what people believe States and of course believe, so it's a hard battle.",
            "How to manage so I'm just cheating a little bit when I tell you this is structural problem, I need to discretize my belief state somehow in order to make sense of it.",
            "It's another issue, yes?",
            "This code is scheme is optimal solution under the particular criteria that you proposed.",
            "In this case it will be in the minimized number of steps on the average.",
            "Yes, it's an entropy reduction.",
            "I want to maximize enter to reduce the entropy for variable in the minimum number of steps.",
            "So the penalty here is Under Armour steps.",
            "So first of all, this was nice, because here is a very clear analogy and link between algorithms and controller algorithm information theory.",
            "I want to make them into one the same algorithm, so I of course marry the two."
        ],
        [
            "So let's."
        ],
        [
            "Skip all these details."
        ],
        [
            "And essentially we have this nice dual picture.",
            "The agent is interacting with the world through the Bellman equation.",
            "The usable manipulation accumulating reward, and then choose an action and so forth.",
            "But at the same time the same agent is accumulating knowledge by the lower triangle of this of this code.",
            "Most nicely enough, this two questions.",
            "These two quantities.",
            "The expected future reward, or the value and the information to go obey exactly the same equation, but not quiet here.",
            "Here are the reward was completely arbitrary.",
            "It should be energy.",
            "It should be something physical, but in most control theory it's more less arbitrary quadratic energy, whatever it is, it should be related to things like work and energy of control and things like this.",
            "But in many cases you Simply put numbers there.",
            "I mean, it's just.",
            "Positive and negative numbers.",
            "It works this Delta.",
            "I is a function of my policy and my dynamics, so this is unlike this.",
            "This is a linear equation V. This is a non linear equation.",
            "I I have the log P hidden in this Delta so of course it's not really clear otherwise.",
            "I mean if this were exactly the same equation then they had exactly the same solution.",
            "Nothing new will come out of it.",
            "But because this is nonlinear this has this entropic term.",
            "This logarithmic probability terms.",
            "The solution is a little more interesting.",
            "And indeed, what I want to do, based on Son of, is to minimize this.",
            "The detail subject to concern on this.",
            "How do you do this?",
            "Take Allegra."
        ],
        [
            "Multiplier.",
            "OK."
        ],
        [
            "Let me skip some."
        ],
        [
            "Philosophy slides here, especially you take something which I called the free energy, and I'm sorry I really didn't mean to.",
            "So free energy for the very simple reason it's a full advantage multiplier, very world.",
            "This information to go acts like entropy here in the sense that unlike entropy, I want to minimize it maximizes because it's the KL divergent and this looks like a physical energy.",
            "So it's a linear combination.",
            "You want to maximize this and minimize this, or you put the LaGrange multiplier which is very much like temperature.",
            "Better positive here and I called this the free energy of the state.",
            "The specific free energy at the state St and the Action 80 and.",
            "With the value better, which of course is in a one to one correspondence to the constraint value.",
            "So this is a very nice.",
            "I mean I call this frenergy simply because group growing up in statistical physics.",
            "This is information or entropy in some general general session.",
            "This is energy in some general says it's a very perfect energy, but notice of course we're not talking about any thermodynamic equilibrium, has nothing to do with some equilibrium, is as common as well.",
            "I mean, it's actually the static flow this equilibrium.",
            "Libram of Balance of information flow between us and the environment, and this is what I'm looking for.",
            "The typical flow and of course, just notice that I don't like rewards because and discounting so don't know discounting here.",
            "It's a bit cheating, but not that much.",
            "I can always do it in finite horizon and take the limits eventually.",
            "So there's a reward rate, and there's these two information flow rates.",
            "How much information I received from the environment, how information I need to give back in terms of decisions and actions.",
            "So believe me that you can simply take this and rewrite the Bellman equation in terms of the free energy.",
            "That's very simple exercise and essentially what you get is that you get a new type of reward, so the free energy at the state St is averaged over this free energy at state S T + 1 plus something which I called.",
            "Which is a combination of the information gain and better times the reward.",
            "So.",
            "Let me come."
        ],
        [
            "After this slide later."
        ],
        [
            "There's some simple, I call it first law, with all due respect and modesty, but it's not of course first low, but it's reminding me of the first law.",
            "Thermodynamics in the sense that if I just average this equation Now, this should be equal to this in equilibrium and I get a simple, simple and somehow somehow surprising connection between the average reward rate.",
            "And the capacity of these two information turns so essentially the average award multiplied by beta is the capacity of my controller plus what I call the empowerment of my system, which essentially how much my actions affect the next state of the environment given the previous state.",
            "OK, so this is nice again when you see some new connections which may be trivial, but they make sense.",
            "They come from solid mathematics.",
            "I didn't cheat anyone as far as I know, and I actually simulated it many times and it seems to work.",
            "And actually this gives you a very simple algorithm.",
            "It actually gives."
        ],
        [
            "Several interesting questions already because I link these two things together now in a unified way, so there's no real difference between the reward, the external reward and this information reward.",
            "They play exactly the same role, but one has something which I want to minimize in general, in order to ask for typicality and the other one is constrained by competition with others with my fitness.",
            "This is just, by the way, is an interesting exercise, which I'm sure many of you will immediately follow, so you can rewrite this free energy by comparing your dynamics to something which is a special type of dynamics, which is the gifts distribution in terms of the reward.",
            "Normalized, why's that because OK again I said rewards in control of usually arbitrary, but so it makes perfect sense that you should reward things more if they are less likely to happen.",
            "OK, so it's unlike the free energy which gives the solution in statistical physics which has a minus here.",
            "Here reward has to be maximized, not minimized, so that's the only difference.",
            "So it's a minimum minimum minus energy in some sense.",
            "But other than that it's a gift distribution.",
            "And then I rewrite this free energy.",
            "And you can see that not only you get an algorithm for the best policy, you also get another term here, which is the KL divergent between your troop dynamics and this optimal Gibbs dynamics.",
            "Now this is interesting because now you may ask yourself what would you like to call perfect adaptations of the environment.",
            "So perfect adaptations to environment is precisely the case where the rewards are exponential in probability of getting their notice.",
            "By the way, that this this is what we do in economy in many other places.",
            "I mean, we actually make things which are how to get more valuable while we climbed Everest.",
            "I don't know.",
            "I never understood that.",
            "But if it's hard to get the society rewards you for that.",
            "In some funny way.",
            "So essentially we're really approaching some long term evolution.",
            "This optimal gifts like value, or in other words, saying it, is that we actually adapt the rewards to relate to the log probability of the transitions.",
            "So this is again the gifts stochastic liberation and just in disguise, because it's coming here an entirely different context.",
            "It's not mechanics, it's it's actually interaction with stochastic environment.",
            "And of course you can now take the derivative of this free energy with respect to the policy.",
            "Given the dynamics and get the solution, the optimal policy is exponential in the free energy as it should be.",
            "Actually, if you break it down, you see that this algorithm, this we equations have to be self consistently satisfied.",
            "This is nothing but the blood out Orimoto algorithm.",
            "For those of you who are familiar with information theory, the rate distortion theory, so it's not.",
            "It's not much more than that, it's unique globally converging Anonymous actually discovered it's identical to.",
            "The Z iterations of M dollar off.",
            "Essentially it's a linear algorithm which can be solved very very nicely and very quickly so.",
            "Here is a way of optimizing the policy.",
            "You have free energy or partition function type of quantity, which is very naturally emerging and actually see you see that you can rewrite the free energy in terms of the lock free energy low partition function.",
            "Just as we love and know.",
            "OK so."
        ],
        [
            "Course now you can apply to many problems, for example solving mazes and you see this basic relationship between value and information.",
            "Again, something how much, how much, how much is the value of another bit of information about about the future of the world.",
            "I always teach you.",
            "Ask them how much are willing to pay.",
            "I have a crystal ball now you can ask binary questions about the future.",
            "What are your three questions to ask?",
            "So it's not that easy to think you have only three questions, but actually this is precisely what this is answering.",
            "It's telling you, OK, if essentially in order to get to the optimal solution that deterministic optimal solution of the bellman.",
            "Equation you have to take better to Infinity and in this case it's giving you this somewhat.",
            "You see that you can actually solve this maze not with 70 bits of information, but with 30,000,000 information.",
            "With losing only 5% of the value.",
            "Essentially you have this type of inverse rate distortion function and simply telling you what how much information about the future you need to know for certain value of information value.",
            "And you see that it has this upward concave but very very flat in most in most scenarios.",
            "We are not going to get much value by adding more and more information.",
            "So I'm going to give you much.",
            "For example in this simple case and this simple maze, you need to go from here to here.",
            "You see that most of the information is in the red areas where you have to be mostly almost deterministic, but in the other colors here is less, can be more, more more more stochastic, and there is really little.",
            "There's a huge.",
            "OK, Betta equals .5 somewhere here.",
            "There's you stochastic city here.",
            "Everything is simplistic in terms of where you want to walk.",
            "In here, almost everything is completely stochastic and you still get essentially the same.",
            "The same value.",
            "Not only that, and that's really the key to the next part of my talk.",
            "I don't know how much time.",
            "0.",
            "OK so I'm sorry, But anyway this is going to mark for you the interesting points on your trajectory in terms of building the hierarchies.",
            "So I just OK there's."
        ],
        [
            "Another whole story here, which I believe you've done, is going to tell us more about you can give another yet another interpretations of this DKL in terms of learning theory or what we call in learning theory.",
            "the PAC Bayes bound and actually put it the whole thing in terms of learning and generalizing from trajectories when you don't know the model.",
            "And this is actually quite interesting because it turns out that again, this KL within the posterior and prior is the thing that controls the complexity of the complexity of your learning.",
            "This isn't generalization limit, so.",
            "I know proof things are probably true from different reasons and this is just yet another way of thinking about the same."
        ],
        [
            "Mechanism exactly."
        ],
        [
            "OK, so in this case in this case is actually optimal if you have finite knowledge about the environment, there is an optimal better which is not Infinity, which will give you the best generalization in terms of in terms of this pack base."
        ],
        [
            "Bound OK so."
        ],
        [
            "It was just an exam."
        ],
        [
            "Only imagine that you need why information can actually help you.",
            "Imagine that you need to walk through a minefield.",
            "So the optimal the global optimal solution, knowing everything is working here between the minds, I'm sure that none of you will want to try.",
            "If you could give less information, this algorithm immediately finds a way around.",
            "Don't get in, you not know enough in order to do this.",
            "And this is again this.",
            "Free energy minimization is actually more robust for small changes in the environment.",
            "This is precisely what the pack based bound is telling us.",
            "OK, I think I can stop here, although I didn't tell you the the really funny part of the story, which is how to discount information.",
            "But if I'm out of time out of time, what can I do offline?",
            "There are some some interpretations, so professional control based on information student by George's ideas.",
            "I don't know if I was awful about credit here.",
            "I mean there are many, many people that should be credited for many of the things that I say.",
            "But no, I'm not familiar with this particular work.",
            "With that, many people discovered a lot of these things independently.",
            "Maybe?",
            "Some other people know about.",
            "I came to learn so this is one of the things I want to know.",
            "What I see in this equation?",
            "Terms have equal weight, so there's apparently a normal weight distribution through two.",
            "Which, well, if you think of control theory would have to work you think you would have to invent it just for the Alpha and better price, right?",
            "So the bits of control are not the same as the bitter perception.",
            "That's what you're saying.",
            "They have different values.",
            "I guess you can do it, I mean just put another log on the fire somewhere.",
            "I think this is a natural one if all you care is about one value, which is the cumulative expected reward and expected future reward.",
            "But if you have other other functions that constrain your behavior, then you may.",
            "For example, you have another cost of sensing which is different from the value.",
            "So for example, we certainly we had.",
            "Actually I see Mail paper this year on the memory.",
            "Memory capacity of memory.",
            "How much you want to remember from the past versus how much you want to invest in your sensors.",
            "It's a very fundamental question in control theory.",
            "Do you want the large camera, or do you want a better maneuverability?",
            "Better memory in your computer and you send it to Mars or whatever?",
            "Of course, it depends on the stochasticity environment, how much you can remember this is how much you really need to acquire all the time, and there's a nice trade off there that you can easily solve in this insane tricks.",
            "Question.",
            "It's very simple terms of nothing with your with your family and minimizes the divergent between the poster in the primary subject to constraints, which I don't see in your case so easily.",
            "It disappoints me there after what you just said, you may have that for free because I mean that that form a basis vector is complexity.",
            "If you go back to the NDL inscription on the message length formulations, the original version being formulations that basically is the cost of encoding.",
            "So if you associate any metabolic or physical encoding machinery, then that competitive firm is the most common cause.",
            "I have money when you're gone for free and you don't actually need your your reward.",
            "Israel weather I don't see I don't see it.",
            "I mean, I think you need some structure in this problem, otherwise you will converge to trivialities and it's just like energy.",
            "In physical systems.",
            "I mean, you can't just maximize entropy or just.",
            "Could you have your?",
            "We would have to optimize if you sent me to 0 your speed would still work and I'm what I'm asking, would you by virtue of minimizing complexity and also the metabolic costs of encoding?",
            "This will bring down costs encoding a message.",
            "No message passing with the environment.",
            "Would you not get something sense planted?",
            "Well, I'm in the truck I know exactly what you mean by message passing with environment.",
            "If by that message passing you actually percolate constraints from the environment back into the optimization, then of course you're right.",
            "But.",
            "Explicitly, there is a constraint.",
            "Otherwise, if you don't constrain your value or something like this, the minimum detail will be posterior equal to prior.",
            "That's it, and that's nothing interesting.",
            "First many details here how to do it in practice you can do it adiabatic Lee by slowly changing your value.",
            "MDL, for example is not the first principle as far as I'm concerned.",
            "It's larger version which is the first principle which leads to MDL in some cases or Bayesian inference and they're all related.",
            "But MDL is far as I'm concerned.",
            "Just like Max the original James maximum entropy.",
            "Somehow mystical principles that you need to put it in some context of some theorems that guarantees something.",
            "You know that makes sense if.",
            "Anyway, it's time to eat.",
            "Thank you.",
            "See you over lunch."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, good afternoon.",
                    "label": 0
                },
                {
                    "sent": "It's really a pleasure and scary experience too.",
                    "label": 0
                },
                {
                    "sent": "Be invited.",
                    "label": 0
                },
                {
                    "sent": "Such a workshop and appear to people really.",
                    "label": 0
                },
                {
                    "sent": "Not only the generators of most of the ideas I'm going to talk about probably see a lot further, and it was especially difficult to follow the previous talk of comprison 'cause you're going to see a lot of similar terminology.",
                    "label": 0
                },
                {
                    "sent": "I just hope that.",
                    "label": 0
                },
                {
                    "sent": "Maybe some of it will be in somewhat simpler and more understandable context, but.",
                    "label": 0
                },
                {
                    "sent": "So I'm using the word free energy and information flow and hierarchies and many other things that are common to many of the talks here, but somewhere in between, let's say friston and and Beth trying to bring it back to the mathematics to some concrete mathematics.",
                    "label": 0
                },
                {
                    "sent": "And maybe we are really on the way of understanding the brain, but we'll see what we really want to do is really understanding the connection with information and control, and I'm sure that this is common to many of us, so I'm also multi.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Created by cognition and by the brain.",
                    "label": 0
                },
                {
                    "sent": "And very much like what you just heard I, I think of a very simplified version of of the picture of our interaction with the world.",
                    "label": 0
                },
                {
                    "sent": "Some cycle that is often drawn in many cognitive science books.",
                    "label": 0
                },
                {
                    "sent": "In this way, there's an Organism.",
                    "label": 0
                },
                {
                    "sent": "There's an environment, and there's some something that comes from the environment to the Organism.",
                    "label": 0
                },
                {
                    "sent": "In terms of sensory perception, sensory information, and something else which comes back from the Organism to the environment in terms of decisions, actions, planning, and all those executive functions.",
                    "label": 0
                },
                {
                    "sent": "So this is very simple.",
                    "label": 0
                },
                {
                    "sent": "It's really the first page of.",
                    "label": 0
                },
                {
                    "sent": "Cognitive science in some sense.",
                    "label": 0
                },
                {
                    "sent": "And what is becoming more and more popular is really to think about this cycle.",
                    "label": 0
                },
                {
                    "sent": "Off the cycle of actions and perceptions between an Organism in the environment, as in the terms of this is my favorite definition of this perception action cycle, which is taken from the book of Young Foster on the frontal cortex.",
                    "label": 0
                },
                {
                    "sent": "The circular flow of information that takes place between the Organism in its environment in the course of a sensory guided.",
                    "label": 1
                },
                {
                    "sent": "Sequence of behaviors towards the goal.",
                    "label": 0
                },
                {
                    "sent": "So everything is here.",
                    "label": 0
                },
                {
                    "sent": "Actually I'm only going to pass this sentence and expand a little bit.",
                    "label": 0
                },
                {
                    "sent": "So essentially, right after this sentence in posters book, you see.",
                    "label": 0
                },
                {
                    "sent": "Very good, big caveat.",
                    "label": 0
                },
                {
                    "sent": "I don't mean here information in Shannon since we actually had some more, you know relaxed version of it.",
                    "label": 0
                },
                {
                    "sent": "But actually I'm going to argue quite rigorously that there's no other choice.",
                    "label": 0
                },
                {
                    "sent": "Possibly if you really want to talk about this flow of information.",
                    "label": 0
                },
                {
                    "sent": "In any sense, then it must be Shannon sense, not because of the fact that is actually communication here.",
                    "label": 0
                },
                {
                    "sent": "I'm actually not going to use the communication aspects of general theory, but actually from much simpler and maybe more fundamental mathematical reasoning which really follows the documents that birth given their first talk of large deviations.",
                    "label": 0
                },
                {
                    "sent": "Essentially, we're looking for the typical behavior of a system, and there's going to be some large number here, which is going to replace the.",
                    "label": 0
                },
                {
                    "sent": "The thermodynamic limits and some of them are still physics, and this is actually interesting to investigate.",
                    "label": 0
                },
                {
                    "sent": "What is really going to push us towards this large deviation limit.",
                    "label": 0
                },
                {
                    "sent": "And of course the large numbers.",
                    "label": 0
                },
                {
                    "sent": "I'm going to assume is that this cycle is actually running many, many times when we before anything we really have many cycles of interaction with the environment.",
                    "label": 0
                },
                {
                    "sent": "And of course we know that in some in some very basic sense.",
                    "label": 0
                },
                {
                    "sent": "The cycle of actions and perceptions is really what the brain is doing.",
                    "label": 0
                },
                {
                    "sent": "There's nothing else there, so the brain cortex, but not only the cortex is largely divided into important frontal and also where the frontal part is the red part here is largely responsible for what we call executive functions.",
                    "label": 0
                },
                {
                    "sent": "This is again taken from foster this picture and the other part is largely responsible for perception.",
                    "label": 0
                },
                {
                    "sent": "Processing perceptual information vision audition smell.",
                    "label": 0
                },
                {
                    "sent": "Both or smells actually not in the quote is somewhere else, and actually there's not one cycle than many cycles on many times skills.",
                    "label": 0
                },
                {
                    "sent": "Actually, if we look at the sensory motorcycle, it's order of hundreds of milliseconds.",
                    "label": 0
                },
                {
                    "sent": "I mean when I touch the table here and actually operating, I'm acting and then sensing it's happening immediately.",
                    "label": 0
                },
                {
                    "sent": "I mean there is some response of the table due to Newton's third law.",
                    "label": 0
                },
                {
                    "sent": "Of that I feel immediately encloses the.",
                    "label": 0
                },
                {
                    "sent": "When I talk to you, there is a larger cycle here and obviously during this lecture you're going to have exchange of information on many time scales, and this is really very typical for interaction with the environment, and so this hierarchy of timescales must somehow evolve in the brain.",
                    "label": 0
                },
                {
                    "sent": "And of course Carl mentioned it several times in his talk.",
                    "label": 0
                },
                {
                    "sent": "I'm actually trying to understand how such hierarchies can emerge from some basic mathematics, so of course.",
                    "label": 0
                },
                {
                    "sent": "When you look at this sentence in this picture, you should think about this as some sort of channel of information.",
                    "label": 0
                },
                {
                    "sent": "There's an information of perceptual information that comes from the environment to us, which is noisy and partial and is highly adaptive.",
                    "label": 0
                },
                {
                    "sent": "I mean, this sensory channel or perceptual channel.",
                    "label": 0
                },
                {
                    "sent": "There's actually a capacity here.",
                    "label": 0
                },
                {
                    "sent": "I mean, there is a limited amount of information that we can perceive.",
                    "label": 0
                },
                {
                    "sent": "From the world is obviously a lot less than our sensory.",
                    "label": 0
                },
                {
                    "sent": "Input is, I mean even just the vision is a lot more than can actually perceive, and so we everything goes through some sort of bottleneck innocence.",
                    "label": 0
                },
                {
                    "sent": "And we must do some filtering.",
                    "label": 0
                },
                {
                    "sent": "Some selection of the relevant information in our perceptual mechanism.",
                    "label": 0
                },
                {
                    "sent": "This actually goes back to your ideas about attentive attention, control, attentive control.",
                    "label": 0
                },
                {
                    "sent": "It's actually the same type of this cannot be a complete full of information, only very little out of the past information.",
                    "label": 0
                },
                {
                    "sent": "Environment information is really relevant for this other channel.",
                    "label": 0
                },
                {
                    "sent": "The predicted channel or the action channel.",
                    "label": 0
                },
                {
                    "sent": "I think I've been doing or in our interaction with the environment is maybe not as obvious that there is also information flow here, but when we make decisions when we do planning, we actually.",
                    "label": 0
                },
                {
                    "sent": "Need something you can think about it in the simplest possible way as the information flow from the brain to the actuator from the controller to the actuator.",
                    "label": 0
                },
                {
                    "sent": "This is a capacity of a controller and of course as control theorist.",
                    "label": 0
                },
                {
                    "sent": "Many of you know that we would like to minimize this in many ways.",
                    "label": 0
                },
                {
                    "sent": "We would like to minimize the flow of information here and there's some constraints.",
                    "label": 0
                },
                {
                    "sent": "This constraints.",
                    "label": 0
                },
                {
                    "sent": "Of course the ability to interact.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So of course I can go into dive now into details of Physiology of the brain and actually show you that really different parts of the cortex and subcortical areas that Alamos in the basil, ganglia and so on correspond very nicely to this dual role of fundamental role of of the brain making useful.",
                    "label": 0
                },
                {
                    "sent": "Collective compression if you want of the information from the sensory perception and making valuable predictions that will lead eventually to valuable decisions and valuable actions.",
                    "label": 0
                },
                {
                    "sent": "I don't want to do this.",
                    "label": 0
                },
                {
                    "sent": "I mean zooming into the brain now is way too complicated.",
                    "label": 0
                },
                {
                    "sent": "Actually, going to zoom out and really think about it as a caricature in some sense, what is really the really the fundamental limits on the ability of such flow of information?",
                    "label": 0
                },
                {
                    "sent": "Such cycles?",
                    "label": 0
                },
                {
                    "sent": "I think it's a very special.",
                    "label": 0
                },
                {
                    "sent": "I don't pretend to solve the whole problem, but I really want to see if there is something like statistical physics or thermodynamics that will link the flow of this information in these two channels with actual reward and cost this metabolic reward and cost the food that we eat.",
                    "label": 0
                },
                {
                    "sent": "The energy that we consume.",
                    "label": 0
                },
                {
                    "sent": "Maybe the computation that we need to do, and so on, which are real entities that we need to deal with.",
                    "label": 0
                },
                {
                    "sent": "How how is this related to this?",
                    "label": 0
                },
                {
                    "sent": "This capacity of the flow of information in these two channels.",
                    "label": 0
                },
                {
                    "sent": "This is the basic question I want to address 1st, and then I'll fill develop some formalism for this.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Essentially, my caricature of the brain is that all the brain is doing is doing some sort of selection compression, compressed sensing if you want, but I don't really like this this word, but some sort of compression of the past information.",
                    "label": 0
                },
                {
                    "sent": "With respect to future actions and decisions, so it's, and that's all it starts.",
                    "label": 0
                },
                {
                    "sent": "And of course you know that to make sense of it in order to evolve in a competitive environment like biology is all about the some constraints on physical entities, like the value of our actions and the cost of our sensing, and so on.",
                    "label": 0
                },
                {
                    "sent": "And this constraint must be there, so we are looking for optimization principle of variational problem that will optimize this flow of information in a way that will achieve a certain value.",
                    "label": 0
                },
                {
                    "sent": "So this is simple enough to the kind of constrained optimization problems if you're all familiar with in some of the mix in statistical physics and control theory and so on and so forth.",
                    "label": 0
                },
                {
                    "sent": "And this is I guess while we're here notice, by the way, this is a system with feedback, cause everyone of those cycles there's actually information flow in a sense from the future to the path through the environment.",
                    "label": 0
                },
                {
                    "sent": "Another way of saying it is that.",
                    "label": 0
                },
                {
                    "sent": "We actually have knowledge there is information about the future.",
                    "label": 0
                },
                {
                    "sent": "We call this predictive information and this information about the future.",
                    "label": 0
                },
                {
                    "sent": "You can think about it as the capacity, the predicted capacity of the environment itself, how much I actually know about what's going to happen.",
                    "label": 0
                },
                {
                    "sent": "So unlike what most people tell you that we can't predict the future.",
                    "label": 0
                },
                {
                    "sent": "It's actually quite the opposite.",
                    "label": 0
                },
                {
                    "sent": "We could not survive without predicting the future.",
                    "label": 0
                },
                {
                    "sent": "Our all existence here depends on predictions and that sense of equilibrium car, but.",
                    "label": 0
                },
                {
                    "sent": "If I come back to his first question, what really separates life from nonliving Organism, nonliving things.",
                    "label": 0
                },
                {
                    "sent": "It's not.",
                    "label": 0
                },
                {
                    "sent": "I don't think it's just I didn't understand exactly your separation, but there's something very.",
                    "label": 0
                },
                {
                    "sent": "Simple cloud very closely related living Organism.",
                    "label": 0
                },
                {
                    "sent": "Exploit the predictability of the environment for the benefits.",
                    "label": 1
                },
                {
                    "sent": "In a sense, they on short-term front row timescale don't really act causally, they don't.",
                    "label": 0
                },
                {
                    "sent": "They're not motivated just from the past, like the initial conditions of physical system, but they know something about the future which they exploit and the further they look, the further they know into the future the better the advantage in terms of evolutionary fitness.",
                    "label": 0
                },
                {
                    "sent": "So it's only the exploitation of the predictive information which makes life interesting.",
                    "label": 0
                },
                {
                    "sent": "And if you think about it, trees.",
                    "label": 0
                },
                {
                    "sent": "Flowers for example.",
                    "label": 0
                },
                {
                    "sent": "Know that the days are going to be longer in some sense and know that the bids are going to come and that's why they do this funny thing like getting flushing the spring and so on.",
                    "label": 0
                },
                {
                    "sent": "I mean, of course there's some information this information was was learned and acquired through millions of years of evolution, but on a short time scale, a simple Organism, even bacteria, has some looks as if on short timescales, it's.",
                    "label": 0
                },
                {
                    "sent": "It's predicting it has some knowledge.",
                    "label": 0
                },
                {
                    "sent": "Its behavior actually depends on some flow of information from the future to the past.",
                    "label": 0
                },
                {
                    "sent": "Which of course the control theorists is very familiar.",
                    "label": 0
                },
                {
                    "sent": "This is the cost 8IN optimal control or this is something which must come back?",
                    "label": 0
                },
                {
                    "sent": "Not so we are all acting with some causal with some causal flow due to the physical systems that we are embedded in, but we know something about the future and that's why we plan we can plan.",
                    "label": 0
                },
                {
                    "sent": "So this feedback is actually quite tricky.",
                    "label": 1
                },
                {
                    "sent": "It's feedback through the predicted channel of the environment.",
                    "label": 0
                },
                {
                    "sent": "OK, so when the fundamental.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Action in perception is of course.",
                    "label": 0
                },
                {
                    "sent": "How do we make sense of of things like this?",
                    "label": 0
                },
                {
                    "sent": "I mean, so this is a famous slide I took from Chris of course, but has nothing to do with this talk about consciousness.",
                    "label": 0
                },
                {
                    "sent": "So how is this collection of pixels eventually is perceived as there is a dog there?",
                    "label": 0
                },
                {
                    "sent": "So now this is really the fundamental question of perception, and it was there is there is a very famous paradigm given by nicely formulated.",
                    "label": 0
                },
                {
                    "sent": "I think, originally by Hellman's but but we usually attributed to David Marr's feet forward paradigm and we start from very simple elements in the image like pixel edges, corners and so on, which correspond to nicely at least seems nicely to the different layers of the visual cortex and eventually somehow miraculously.",
                    "label": 0
                },
                {
                    "sent": "We do this bottom up processing and we get the percept of a dog or a man or whatever it is.",
                    "label": 0
                },
                {
                    "sent": "Now it's interesting.",
                    "label": 0
                },
                {
                    "sent": "That's already theoretically.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the early 90s, John Toasters, among many others, who is theoretical computer scientists, simply did a very rough calculation of is this feedforward process possible at all visible in terms of computational mechanisms in what we know about the brain and he came to the conclusion this cannot be true.",
                    "label": 0
                },
                {
                    "sent": "There's cannot.",
                    "label": 0
                },
                {
                    "sent": "It cannot be that we actually see by.",
                    "label": 0
                },
                {
                    "sent": "Starting from every pixel in the image and then do some sort of feedforward mechanism that will eventually lead to and he simply gave a really rough orders of magnitude like computer scientist, calculation of complexity and said that this is exponential in the number of pixels.",
                    "label": 0
                },
                {
                    "sent": "There's no time for that.",
                    "label": 0
                },
                {
                    "sent": "And at the same time or less actually, I usually quote Charleston America suffered because those friends of mine from Jerusalem, but other people as well in cognitive science and notice that, and this is actually these are two pictures taken from their their papers in nature paper in 1997.",
                    "label": 0
                },
                {
                    "sent": "I think that and then later 2002 that essentially our perception, intelligence cycle physics in terms of reaction time.",
                    "label": 0
                },
                {
                    "sent": "Goes actually the other way around.",
                    "label": 0
                },
                {
                    "sent": "If I flash a little image to you.",
                    "label": 0
                },
                {
                    "sent": "And tell you what their face there or not.",
                    "label": 0
                },
                {
                    "sent": "Most of you will be able to say with high confidence there was a face, but if asked what was the color of the left corner mostly will be completely wrong or is was there a little tiny thing so it couldn't be that you first notice all the details and then realize that there's a face.",
                    "label": 0
                },
                {
                    "sent": "They simply then there's no time for this and they realize actually have a reaction.",
                    "label": 0
                },
                {
                    "sent": "Time goes down in sense that we first notice the big things and only later we are able to distinguish the little things, the details.",
                    "label": 0
                },
                {
                    "sent": "They didn't give an explanation to this, but they call it a reverse hierarchy model and this reverse hierarchy models is very we know it.",
                    "label": 0
                },
                {
                    "sent": "Of course even better for audition for speech recognition.",
                    "label": 0
                },
                {
                    "sent": "For example, we couldn't understand speech at all if we didn't have a predictive model of the words anybody ever worked worked on.",
                    "label": 0
                },
                {
                    "sent": "The engineering of speech recognizers know that we need the language model, which will essentially give us prior distributions over words and essentially we guess what we are hearing and instead of actually.",
                    "label": 0
                },
                {
                    "sent": "Building the dog from the details were really guess there is a document or other reasons predictor is done and then go do something much simpler statistically and computationally, which is hypothesis testing rather than generating a generative model of the image.",
                    "label": 0
                },
                {
                    "sent": "We test the hypothesis.",
                    "label": 0
                },
                {
                    "sent": "Is there a dog or no dog?",
                    "label": 0
                },
                {
                    "sent": "And for this we need very little information.",
                    "label": 0
                },
                {
                    "sent": "We actually need to know if there is.",
                    "label": 0
                },
                {
                    "sent": "So if you very few I mean log or even log log in the number of pixels observations will give us very high confidence about this.",
                    "label": 0
                },
                {
                    "sent": "This type of question, or is there a dog?",
                    "label": 0
                },
                {
                    "sent": "Is there a tree is their face and so on.",
                    "label": 0
                },
                {
                    "sent": "So hypothesis testing is computationally a lot more efficient.",
                    "label": 0
                },
                {
                    "sent": "And the first thing in speech, we do it all the time.",
                    "label": 0
                },
                {
                    "sent": "You actually guess what I'm going to say most of the time you are more or less right about every word that maybe even if every sentence actually what you are doing when you listen to me now, you're simply checking that your predictions are right, and in some cases I may surprise you and then you re adjust your predictions.",
                    "label": 0
                },
                {
                    "sent": "And by readjusting your predictions you actually understand.",
                    "label": 0
                },
                {
                    "sent": "So most of the content of this talk and any other talk or paper or book or whatever it is or movie is in this corrections to your.",
                    "label": 0
                },
                {
                    "sent": "Predictions and that's why we do it sufficiently, because most of the time you predict pretty well.",
                    "label": 0
                },
                {
                    "sent": "OK, so again so we have a lot of psychophysics and actually electrophysiology that's supposed both this reverse hierarchy models that actually there's some backward flow from the higher level of the brain that makes this prediction.",
                    "label": 0
                },
                {
                    "sent": "Speech, it's really quite nice.",
                    "label": 0
                },
                {
                    "sent": "I mean recent work by my friend Alan Elkin, on auditor perception.",
                    "label": 0
                },
                {
                    "sent": "Really verified it very nicely.",
                    "label": 0
                },
                {
                    "sent": "You really see a cascade of the activation along the auditory hierarchy starts from the top in some sense and then only then at some lower level you really follow the details of.",
                    "label": 0
                },
                {
                    "sent": "Mission Bay and they essentially you don't need to do much for this is it's very hard day or just have to measure the onset time, voice onset time of the D&B.",
                    "label": 0
                },
                {
                    "sent": "It's a very little, very focused information.",
                    "label": 0
                },
                {
                    "sent": "This is essentially how the brain works as men standing today, although there's some still some people want to mention names or we believe that we have a generative model.",
                    "label": 0
                },
                {
                    "sent": "So this is just an illustration.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And I mean really see what they expect to see.",
                    "label": 1
                },
                {
                    "sent": "Maybe all of you have seen this picture before, but if you don't and I don't tell you something like domestic dog, you will never see it.",
                    "label": 0
                },
                {
                    "sent": "But if I tell you with some effort you eventually see the dog there.",
                    "label": 0
                },
                {
                    "sent": "How many of you know this picture?",
                    "label": 0
                },
                {
                    "sent": "Again?",
                    "label": 0
                },
                {
                    "sent": "You make sense of it only after I tell you something like nude.",
                    "label": 0
                },
                {
                    "sent": "Women's back or something like this then it will take some time, but usually figure it out and it's very much like this all the time.",
                    "label": 0
                },
                {
                    "sent": "So these are just illustration.",
                    "label": 0
                },
                {
                    "sent": "OK so.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "My talk is not about.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Examples like this was the high level motivation.",
                    "label": 0
                },
                {
                    "sent": "So essentially what I really want to make sense of this claim that perception actually cycle is really a control loop with constraint information flow, and I am actually going to argue.",
                    "label": 0
                },
                {
                    "sent": "Using using the mathematics that was already given to you by the 1st or for example, the large deviation idea and some other talks that we can actually solve this problem.",
                    "label": 0
                },
                {
                    "sent": "Actually, there's a very important slide that I. I should should put before the outline may show it now.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I don't believe that the brain solve intractable problems.",
                    "label": 1
                },
                {
                    "sent": "If there's anybody believes this, I coming from computer science at least partially from computer science, I really believe that the main contribution of computer science to understanding the world is that they more or less tell us what are difficult and water easy problems, and we know that nature.",
                    "label": 0
                },
                {
                    "sent": "Brain in particular cannot deal with what is probably intractable.",
                    "label": 0
                },
                {
                    "sent": "So if something like this appears to happen, we understand the problem.",
                    "label": 0
                },
                {
                    "sent": "Probably we don't formulated correctly or the brain is approximating it.",
                    "label": 0
                },
                {
                    "sent": "Some other tricks using some other tricks, and that's exactly what we're looking for.",
                    "label": 0
                },
                {
                    "sent": "The simple principles that lead to tractable algorithms.",
                    "label": 1
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "I'm going to somehow dive into this acting, sensing acting loop and especially the role of information, but again, not not my laying on you.",
                    "label": 1
                },
                {
                    "sent": "The heavy theory of communication, but starting from a very simple assumption.",
                    "label": 0
                },
                {
                    "sent": "I'm looking for the typical behavior of such of such a cycle in a stationary stochastic environment such that I can really talk about what I call them.",
                    "label": 1
                },
                {
                    "sent": "I will call later on the metabolic information processing, so this was really a very nice hint.",
                    "label": 1
                },
                {
                    "sent": "Metabolic information processing essentially is the trivial thing that you're robot that cleans your house and have something like this that actually has sensors and actuators is doing when it moves around.",
                    "label": 0
                },
                {
                    "sent": "I'm essentially the simple sensors that simple motor controls, motor commands, and these two are balanced in a way which makes you happy eventually, which means that the overall tradeoff between the amount of information and get that this robot can get through the sensors and the amount formation he needs in order to.",
                    "label": 0
                },
                {
                    "sent": "Act usefully is enough to for you to buy it, which is really the value function here.",
                    "label": 0
                },
                {
                    "sent": "In some sense it cleans the house eventually somehow, and not more than that, and so the question I'm asking, what is the minimal amount of information that you really need to get from the environment in order to act with certain value of actions?",
                    "label": 0
                },
                {
                    "sent": "This turned out to be a very simple question, and in order to actually make sense of fashion quantities, it's a lot easier to do.",
                    "label": 0
                },
                {
                    "sent": "Despite my admiration and loves of differential equations and continuous time and infinite continuous state space, it's a lot easier to discretize things and to work with what we call Markov decision processes or partially observable ascension process where everything is finite both and time is discretized, and then we can really talk about how much information is.",
                    "label": 0
                },
                {
                    "sent": "Extracted or absorbed in one cycle.",
                    "label": 0
                },
                {
                    "sent": "Come on, say it.",
                    "label": 0
                },
                {
                    "sent": "By the way, I have worked in the last year a lot on or making a continuous version of this story, and it's not that difficult.",
                    "label": 0
                },
                {
                    "sent": "It turns out to involve all the nice mathematics that we heard about.",
                    "label": 0
                },
                {
                    "sent": "I mean, manifolds, Lee groups, vector fields, and all these nice things immediately appear because you need what you mean by prediction.",
                    "label": 0
                },
                {
                    "sent": "When you talk about continuous observation, essentially the flow and this flow obeys all sorts of symmetries, and so on.",
                    "label": 0
                },
                {
                    "sent": "So there's a nice story to be told, which I partly understand now about the continuous version of these tourists.",
                    "label": 0
                },
                {
                    "sent": "But in order to make it simple, I want to talk about of artists vector about spynet states for state space.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And discrete time.",
                    "label": 0
                },
                {
                    "sent": "OK, so again I want to connect large deviation with.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "With the with control it's not new.",
                    "label": 0
                },
                {
                    "sent": "I mean the people I'm going to re discover things that were discovered before me and some of the algorithms that Emotiv discovered independent, very very similar.",
                    "label": 0
                },
                {
                    "sent": "Just the view is slightly different and application is something different.",
                    "label": 0
                },
                {
                    "sent": "So MDP is nothing but a collection of states with actions and a transition probability that tells us how the how are you going to move from one state to another given condition on the action.",
                    "label": 0
                },
                {
                    "sent": "And of course on top of this tuple of state actions.",
                    "label": 0
                },
                {
                    "sent": "Function probabilities there is also a reward.",
                    "label": 0
                },
                {
                    "sent": "Now this rewarding control is a little bit arbitrary.",
                    "label": 0
                },
                {
                    "sent": "I mean, what is it?",
                    "label": 0
                },
                {
                    "sent": "I mean actually should be something meaningful, but it turns out it's not really important.",
                    "label": 0
                },
                {
                    "sent": "It's some sort of quantity that you attached to.",
                    "label": 0
                },
                {
                    "sent": "So if I stayed S1 and I do the action a 0, there's some probability that I will move to a 2.",
                    "label": 0
                },
                {
                    "sent": "There's two and some other probability.",
                    "label": 0
                },
                {
                    "sent": "I'll move to S 0, and so on, and there is reward.",
                    "label": 0
                },
                {
                    "sent": "This emission of reward that is associated with every arc in this graph.",
                    "label": 0
                },
                {
                    "sent": "So this is a very simple structure.",
                    "label": 0
                },
                {
                    "sent": "And of course, the basic problem of optimal control formulated in this in this language of of of Markov decision processes or partially observed Markov decision process is exactly the same mathematics that just discretizing time.",
                    "label": 1
                },
                {
                    "sent": "I want to find a policy which is essentially a control law.",
                    "label": 0
                },
                {
                    "sent": "Given my knowledge about the state, which may or may not be complete, it may actually be filtered through some sort of noisy observations.",
                    "label": 0
                },
                {
                    "sent": "What is the optimal action and this optimal action can be stochastic, so I assume some sort of probability distribution on action given state.",
                    "label": 0
                },
                {
                    "sent": "And of course, given this pie probability or policy of action, I can in principle calculate the expected accumulated reward or the value of my policy very simple.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We all know that this is essentially the taken from Southern about or the famous reinforcement learning is just rediscovering or rewriting of what you all know in the optimal control in terms of discrete States and rewards, and essentially so we have states we have reward.",
                    "label": 0
                },
                {
                    "sent": "We have actually have rewards, and so on, and we everything moves in a Markov chain, which we assume to be a Dick in order to make sense of it in Infinite Horizon.",
                    "label": 0
                },
                {
                    "sent": "Otherwise we're talking about finite horizon.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You, I'm sure or no, there is a very elegant solution this problem calculate a value for each state.",
                    "label": 0
                },
                {
                    "sent": "Which is essentially just expected for every given policy.",
                    "label": 0
                },
                {
                    "sent": "Calculate developers state which discounted expected reward.",
                    "label": 0
                },
                {
                    "sent": "With exponential discounting, this actually is going to be tricky, so I'm going to put a question mark on this gamma here, but this is what's done in Infinite Horizon formulation.",
                    "label": 0
                },
                {
                    "sent": "All the places you put in fact less than one here and then.",
                    "label": 0
                },
                {
                    "sent": "These things converging if R is bounded and you get this very nice Bell month, which is reincarnation of the Hamilton Jacobi equation for entirely different purpose.",
                    "label": 0
                },
                {
                    "sent": "But you get this.",
                    "label": 0
                },
                {
                    "sent": "Linear connection given the value and the and the dynamics between given the policy and dynamic between the value at different states physicist I always defenses.",
                    "label": 0
                },
                {
                    "sent": "I would like to say that this is very much like the person.",
                    "label": 0
                },
                {
                    "sent": "Equation essentially tells you that V acts like a potential.",
                    "label": 0
                },
                {
                    "sent": "It just averaging the potential in the neighbors and adding the source source in terms of the reward or which is just the source charge or the source current.",
                    "label": 0
                },
                {
                    "sent": "So this is very familiar equation.",
                    "label": 0
                },
                {
                    "sent": "We all know how to solve it even on grids.",
                    "label": 0
                },
                {
                    "sent": "Using the laplacians of losing, losing the tricks of of solving Laplace or person equations I don't want to do this, it's not interesting.",
                    "label": 0
                },
                {
                    "sent": "What is really interesting about it.",
                    "label": 0
                },
                {
                    "sent": "This equation allows us to fold apparently exponential complexity of following very long trajectory's into a linear equation which has the complexity of the number of states, time, the number of action, normal state squared.",
                    "label": 0
                },
                {
                    "sent": "Then I'm going to number function so it's tractable for small number of bits and.",
                    "label": 0
                },
                {
                    "sent": "Of course, what we all do, what?",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Are all people do they iterate?",
                    "label": 0
                },
                {
                    "sent": "They do this policy iteration algorithm.",
                    "label": 1
                },
                {
                    "sent": "The iterative mean estimation of the value given the policy and then optimize the policy.",
                    "label": 0
                },
                {
                    "sent": "So this is a nice.",
                    "label": 0
                },
                {
                    "sent": "This is an example of what I call a tractable problem, so it's converging globally.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And it has very nice properties.",
                    "label": 0
                },
                {
                    "sent": "So now I want to.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Come back to information and see if we can really bring channels idea about may solving, which he had already in the 50s with Belmans notion of dynamic programming optimality.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And it's actually very simple if you put everything in cost, everything in terms of graphical model.",
                    "label": 1
                },
                {
                    "sent": "So graphical models have been mentioned before the esentially discretized version of random variables and with some errors that describe the statistical connectivity.",
                    "label": 0
                },
                {
                    "sent": "So in this case, for example, the world is described by this variable W in this three times, and it has it's a Markov chain on its own, which means given WT one WT plus 2 WTR this independent.",
                    "label": 0
                },
                {
                    "sent": "You have everything fixed, so it's a Markov chain.",
                    "label": 0
                },
                {
                    "sent": "And of course, as you know, it's a directed Markov chain, so essentially there are very few variables here.",
                    "label": 0
                },
                {
                    "sent": "These are, this is.",
                    "label": 0
                },
                {
                    "sent": "Let's say this is the mind or the mental image of the Organism, and essentially the perception action cycle is now accustomed to this infinite dynamic Bayesian network or graphical model, where these are the observations, the noise observation.",
                    "label": 1
                },
                {
                    "sent": "These are the actions the world is evolving as a function of the actions and the mind is evolving as the functions of the observation and its memory.",
                    "label": 0
                },
                {
                    "sent": "So I can now write a probability distribution.",
                    "label": 0
                },
                {
                    "sent": "For all this, for a long sequence of such cycles, given essentially for quantities, the dynamics, how are states of all the function of actions, the dynamics of my memory, which I have to find out?",
                    "label": 0
                },
                {
                    "sent": "How is the memory change the function of the stations and the policy, the policy channel or the actions channel and observation channel?",
                    "label": 1
                },
                {
                    "sent": "So these are the four things that you would like to optimize.",
                    "label": 0
                },
                {
                    "sent": "Let's start with the simplest possible problem.",
                    "label": 0
                },
                {
                    "sent": "No, no noise in the observation which we called the MDP problem.",
                    "label": 0
                },
                {
                    "sent": "So essentially the mine has full knowledge of the environment.",
                    "label": 0
                },
                {
                    "sent": "It's a Markov decision process and only the policy is the variable.",
                    "label": 0
                },
                {
                    "sent": "This is enough to already see the full general structure here, so again these are.",
                    "label": 1
                },
                {
                    "sent": "This is the perceptual channel.",
                    "label": 0
                },
                {
                    "sent": "This is the predicted channel as I called them and their two quantifiers.",
                    "label": 0
                },
                {
                    "sent": "One is the reward associated with transition from one state to another state in the world so.",
                    "label": 0
                },
                {
                    "sent": "When I gain some food, or you can make some money in stock market or whatever, the state of the world as far as I'm concerned is changed and they got some reward out of it.",
                    "label": 0
                },
                {
                    "sent": "Or when I hit the wall or whatever it is.",
                    "label": 0
                },
                {
                    "sent": "But as you see just from the symmetry of this of this graph that they must be something here.",
                    "label": 0
                },
                {
                    "sent": "What do I gain when I actually observe something from the world and and received?",
                    "label": 0
                },
                {
                    "sent": "Let's say I did A and received oh and I know that my memory went from empty 20 + 1 due to this interaction.",
                    "label": 0
                },
                {
                    "sent": "Action observation this active, active, active sensing, so I argue that there's a very natural quantity here, which is going to come from the from the sun over the large deviation theorem, which is essentially.",
                    "label": 0
                },
                {
                    "sent": "Easily interpretable, and this is only my main contribution to this meeting.",
                    "label": 0
                },
                {
                    "sent": "I want to interpret this information in terms of quantities, which I understand in terms of the cycle, so I'm going to call this information games.",
                    "label": 1
                },
                {
                    "sent": "I'm going to make them explicit in a second, so there's two types of quantities, not only the external reward, but also how much I really my mental state gained and both this gain is as far as I'm concerned it can be only one thing information, so this is a philosophical picture, but I'm going to go back to the mathematics in a second and make it very, very very concrete.",
                    "label": 0
                },
                {
                    "sent": "So essentially what I'm looking is the typical.",
                    "label": 0
                },
                {
                    "sent": "Behavior of such a graph of such a model under a constraint on the value of the action.",
                    "label": 0
                },
                {
                    "sent": "Since the value is just a linear function of my, my dynamics and policy, I can it's going to be a linear constraint on the on the function space and everything, and I can minimize the KL divergent very easily due to son of and get very nice typical concrete answer this question what is the typical long long term behavior?",
                    "label": 0
                },
                {
                    "sent": "Remember, I assume that there are many cycles such that I can really use this asymptotic.",
                    "label": 0
                },
                {
                    "sent": "Large deviation theory OK. How does that compare with?",
                    "label": 0
                },
                {
                    "sent": "System identification and how much we are proving our probability distribution perspective decision.",
                    "label": 0
                },
                {
                    "sent": "It will get back to this in a second.",
                    "label": 0
                },
                {
                    "sent": "I'm going to devil drill on this Delta and tell you a lot of things about it so I really find interesting both cognitively and control theoretically, so just want to remind you what do we mean by by the by the large deviation.",
                    "label": 0
                },
                {
                    "sent": "So essentially we talk about a space of distribution, so this is generally described as some sort of simplistic, which we we.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For simplicity, drawers strangle in two dimensions.",
                    "label": 0
                },
                {
                    "sent": "Of course, there simply are in general more higher dimension limit and by value constraint essentially have some linear constraint, some expectation value constraining some distribution.",
                    "label": 0
                },
                {
                    "sent": "So when I say that I start with some initial Q, might say completely random or something some prior distribution over states over some variable X, and when I give a linear constraint, logic nation is telling me that the most likely distribution in this set this is going to be.",
                    "label": 0
                },
                {
                    "sent": "Well, let's see if this is a drunk.",
                    "label": 0
                },
                {
                    "sent": "Random motion, random action, and this is some value.",
                    "label": 0
                },
                {
                    "sent": "The probability that this drunk will actually achieve this value is very low.",
                    "label": 0
                },
                {
                    "sent": "It's exponentially small in the number of steps that the drunk moves, and the value, and it's actually completely dominated by one point in this.",
                    "label": 0
                },
                {
                    "sent": "In this convex set, which is the one which minimize the detail subject to this concern.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry there's a constraint that belongs to this set of growth constraint on the value, so this is a very simple mathematics.",
                    "label": 0
                },
                {
                    "sent": "That's all it is.",
                    "label": 0
                },
                {
                    "sent": "That's so simple that you can really design a very simple algorithm, and indeed it tell it's telling you the problem.",
                    "label": 0
                },
                {
                    "sent": "If this drunk somehow got into this region with very high probability is going to be here the chance that they will find him here is exponentially small in the detail between these two things relative, so larger versions are very powerful.",
                    "label": 0
                },
                {
                    "sent": "Very powerful tool you can apply to ID to Markov chains from a lot of stationary distributions, and essentially this is all I'm actually using.",
                    "label": 0
                },
                {
                    "sent": "Patrol marker that's right, it's still the same game as far as I'm concerned.",
                    "label": 0
                },
                {
                    "sent": "There is one distribution which some of it.",
                    "label": 0
                },
                {
                    "sent": "Some of those distributions can achieve this value and I'm looking for the most likely one in this class.",
                    "label": 0
                },
                {
                    "sent": "Of course, if if your class is this actually.",
                    "label": 0
                },
                {
                    "sent": "Sorry, technically this is one of those water this summer.",
                    "label": 0
                },
                {
                    "sent": "If you can transfer this bottle, it will be helpful.",
                    "label": 0
                },
                {
                    "sent": "So technically, of course the trick that I'm using here is to work too, by optimizing the DKL you don't maximize the likelihood, and this is really the secret I believe of both statistical physics and information theory, and also this type of application to control is that the variational problem is minimizing hail divergance, which has a lot.",
                    "label": 0
                },
                {
                    "sent": "It is a lot nicer than just maximum likelihood in many ways.",
                    "label": 0
                },
                {
                    "sent": "In particular, such sets are convex under very general conditions, so we can easily solve this problem.",
                    "label": 0
                },
                {
                    "sent": "Which means really, the sympathetic limit of where N here is really the.",
                    "label": 0
                },
                {
                    "sent": "Sample size in this simple case and and sample the number of cycles in my perception action cycle, so I guess I don't need to say it here, specially not after.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Talk that that action sequences and codes have a lot of similarity, so actually you can describe projector is on a graph using a set of actions go left, go right now.",
                    "label": 0
                },
                {
                    "sent": "Especially I want and I can talk about the minimal description or what is the shortest path or this simplest description of less safe to get from here back home, which in my case is quite far, and so essentially eventually it's a long list of bits to right and left whenever you come to some codes in junction someplace to make decision, you can essentially such descriptions of trajectories.",
                    "label": 0
                },
                {
                    "sent": "Obey the Kraft inequality.",
                    "label": 0
                },
                {
                    "sent": "They behave very much like like code words and I can concatenates them.",
                    "label": 0
                },
                {
                    "sent": "I can do all the tricks that Shannon did with codes.",
                    "label": 0
                },
                {
                    "sent": "Information adjustment, describing projectors in the shortest possible way, so it makes perfect sense to describe the trajectory on a graph by a sequence of bits.",
                    "label": 0
                },
                {
                    "sent": "And there is one.",
                    "label": 0
                },
                {
                    "sent": "There are many of course, code coding scheme, but there's one minimal length.",
                    "label": 0
                },
                {
                    "sent": "That that correspond to the shortest description of a trajectory in a graph.",
                    "label": 0
                },
                {
                    "sent": "So somehow you already seen very clearly that there's some really nice analogy between Belmont type of tonality and what people do in information theory when they encode information.",
                    "label": 0
                },
                {
                    "sent": "For example, Huffman code, which you're all familiar with.",
                    "label": 0
                },
                {
                    "sent": "I hope building an optimal tree of questions that eventually reveal information or entropy reduction by minimum number of questions, or by the shortest 3 on average is just a special case of a bellman.",
                    "label": 0
                },
                {
                    "sent": "Optimality principles are going to see immediately.",
                    "label": 0
                },
                {
                    "sent": "Essentially, you can merge the two into into one equation, so again, so I can.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "About about interaction with the world or some sort of the world move, I move the world move, I move and then I can I can describe the number, the possible actions in my trajectory and describe this as a code word.",
                    "label": 0
                },
                {
                    "sent": "Given the encoder, which essentially is my behavior policy, which of course includes the model of the world itself.",
                    "label": 0
                },
                {
                    "sent": "And then it's essentially a trivial statement, which I called here a theorem, but it's insulting mathematicians that if I describe, define, define the quantity, which is nothing but the KL divergent between the posterior and prior.",
                    "label": 0
                },
                {
                    "sent": "Given the goal, let's say accumulate certain value and the sequence in the state.",
                    "label": 0
                },
                {
                    "sent": "So this scale divergency numark of environment.",
                    "label": 0
                },
                {
                    "sent": "And I'll make this explicitly in a second obeys this very simple type of Berman Berman equation.",
                    "label": 0
                },
                {
                    "sent": "The information for the missing information.",
                    "label": 0
                },
                {
                    "sent": "This investments it's mutual information, but it doesn't have to be or conditional information will see in a minute.",
                    "label": 0
                },
                {
                    "sent": "There are many, many different quantities that can appear, but it's this scale diversion simply comes from the Son of theorem or from logic Nation.",
                    "label": 0
                },
                {
                    "sent": "This is what I want to minimize.",
                    "label": 0
                },
                {
                    "sent": "If I have a Malcolm environment, which means that I can factorize my distribution over overtime into states.",
                    "label": 0
                },
                {
                    "sent": "Conditioned on the previous days, then I can write this recursion equation.",
                    "label": 0
                },
                {
                    "sent": "The information about my goal at the state St is the average information about my goal.",
                    "label": 0
                },
                {
                    "sent": "The state is S, T + 1 plus what I gained in between and what again in between, which I called.",
                    "label": 0
                },
                {
                    "sent": "The information gain is here, not arbitrary.",
                    "label": 0
                },
                {
                    "sent": "It depends it simply by essentially cutting off.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Log 10, so here's here's an exclusive calculation.",
                    "label": 0
                },
                {
                    "sent": "I called this information to go because it's just like the cost to go in control, but it's actually the information they have about the future States and action of my behavior.",
                    "label": 0
                },
                {
                    "sent": "Where is it?",
                    "label": 0
                },
                {
                    "sent": "It wasn't an intention to be very general and call it a general goal.",
                    "label": 0
                },
                {
                    "sent": "For example, rich home or accumulate enough value or whatever.",
                    "label": 0
                },
                {
                    "sent": "It can be something which is finite and then you have a finite horizon planning or something like this.",
                    "label": 0
                },
                {
                    "sent": "It can be something which are coming on the way, so it's a very abstract notation for something that you want to achieve.",
                    "label": 0
                },
                {
                    "sent": "Think about goal at the end of the maze or something now, so this information to go is nothing but the KL divergent.",
                    "label": 0
                },
                {
                    "sent": "Of the conditional future states, an action in the MVP case conditioned on my current state and action.",
                    "label": 0
                },
                {
                    "sent": "My current certain my next action.",
                    "label": 0
                },
                {
                    "sent": "This is very much like the Q function in RLI.",
                    "label": 0
                },
                {
                    "sent": "Can, of course.",
                    "label": 0
                },
                {
                    "sent": "Condition is another thing, but this is much easier this way and I take his prior.",
                    "label": 0
                },
                {
                    "sent": "That's the stupidest thing that I can think of which is completely independent actions of states 'cause you actually in some other cases, whichever is later, we actually assume some sort of unconditional state transitions, very much like what you did, unconditioned, which means independent of the policy.",
                    "label": 0
                },
                {
                    "sent": "So this you can sexy kisses the queue or uniform prior.",
                    "label": 0
                },
                {
                    "sent": "So there is a KL divergent of conditional expectation of the log likelihood ratio likelihood of all the future given some path.",
                    "label": 0
                },
                {
                    "sent": "Consider it's some to some point.",
                    "label": 0
                },
                {
                    "sent": "This point I don't really worry about work that emanated, it's going to be important eventually.",
                    "label": 0
                },
                {
                    "sent": "So think about it as finite horizon and this.",
                    "label": 0
                },
                {
                    "sent": "Information to go very much like the value in the Bellman equation.",
                    "label": 0
                },
                {
                    "sent": "Is factorized trivially into the information to go in the next state and action +2 terms which are simply shuffled off this log.",
                    "label": 0
                },
                {
                    "sent": "There's nothing there but this time, which is 2 terms are interesting conceptually because that's why I know them as red and blue, just like the blue and red parts of the brain one is associated with the action and the other one is associated with the perception and actually very interesting.",
                    "label": 0
                },
                {
                    "sent": "So the first one, which is some sort of information gain given a certain state and a certain action.",
                    "label": 0
                },
                {
                    "sent": "This can be negative or positive, and this is the information gained in this of this.",
                    "label": 0
                },
                {
                    "sent": "Specific is actually not the information.",
                    "label": 0
                },
                {
                    "sent": "Again, is the control complexity.",
                    "label": 0
                },
                {
                    "sent": "How much I really need to change my action when I know the previous state versus not knowing it?",
                    "label": 0
                },
                {
                    "sent": "How much information is there about my action when I know the state of my system?",
                    "label": 0
                },
                {
                    "sent": "This is nothing this is going to average of course, do nothing but the mutual information within states an action or the capacity of the predicted channel.",
                    "label": 0
                },
                {
                    "sent": "So this is simple.",
                    "label": 0
                },
                {
                    "sent": "The first time is simply the predictive gain or the control capacity.",
                    "label": 0
                },
                {
                    "sent": "Using control theory for many years this is it was there is some control ability and and observe ability assumptions underneath here, which I don't want to argue it actually generalizing these concepts a little bit to stochastic combined.",
                    "label": 0
                },
                {
                    "sent": "The second term is actually more interesting in some sense.",
                    "label": 0
                },
                {
                    "sent": "It's the response of the environment to my action given the previous state.",
                    "label": 0
                },
                {
                    "sent": "So let's say I was trying to drive my car to the left, but for some reason is moved to the right or move straight.",
                    "label": 0
                },
                {
                    "sent": "This is surprising thing to me, and notice that when I want to minimize.",
                    "label": 0
                },
                {
                    "sent": "This KL divergences in order to achieve the large deviation limit subject to the value constraint.",
                    "label": 0
                },
                {
                    "sent": "I will want to minimize the average this and to minimize this average, just this average is actually clear why I want to minimize it?",
                    "label": 0
                },
                {
                    "sent": "It's minimizing the control capacity.",
                    "label": 0
                },
                {
                    "sent": "I want to send a list number of bits to the from the controller to activate.",
                    "label": 0
                },
                {
                    "sent": "This is exactly your principle of of attention, but this is somewhat surprising exactly directly related to one of the terms in in cars talk.",
                    "label": 0
                },
                {
                    "sent": "And when I think about it, in some cases makes perfect sense.",
                    "label": 0
                },
                {
                    "sent": "For example, if I play an information game with you, I I play a 20 question game, for example, you choose a number and I have to choose the action.",
                    "label": 0
                },
                {
                    "sent": "The actions which in this case are the questions that I want to ask you, so of course.",
                    "label": 0
                },
                {
                    "sent": "Let's say you choose another thing.",
                    "label": 0
                },
                {
                    "sent": "100 stupid question will be is it 17 and the clever question will be is it larger than 50 Huawei becausw I maximize?",
                    "label": 0
                },
                {
                    "sent": "The entropy of the outcome in some sense I'm making.",
                    "label": 0
                },
                {
                    "sent": "I'm keeping the options open and some people call it an annual plan for example.",
                    "label": 0
                },
                {
                    "sent": "And actually this is directly related to what some people like colonic cause empowerment.",
                    "label": 0
                },
                {
                    "sent": "Essentially how much I am allowing the environment too.",
                    "label": 0
                },
                {
                    "sent": "I keep many options actually pushing my pushing the system into instabilities in a sense that the I want to maximize the entropy of the next state given the current state and the action which is against the intuition in many ways.",
                    "label": 0
                },
                {
                    "sent": "But you think about information gains.",
                    "label": 0
                },
                {
                    "sent": "This is precisely what you want to maximize the entropy of your outcome given the current action.",
                    "label": 0
                },
                {
                    "sent": "This is what you want to do.",
                    "label": 0
                },
                {
                    "sent": "Right, so so the two quantities which look opposing here.",
                    "label": 0
                },
                {
                    "sent": "And that's again I won't call any of them surprise at this point, but this is actually related surprise, and this is a letter to control complexity.",
                    "label": 0
                },
                {
                    "sent": "Notice that essentially they're going to average into the mutual information within the state and the action and the conditional information between the action in the next state given previous state, which is exactly some people call empowerment in control.",
                    "label": 0
                },
                {
                    "sent": "I don't know if this is a popular term here, how much I really can affect.",
                    "label": 0
                },
                {
                    "sent": "How much the system?",
                    "label": 0
                },
                {
                    "sent": "How much information I have?",
                    "label": 0
                },
                {
                    "sent": "I can affect the response of the system if I do something and it doesn't change anything in the world of my sensory perception doesn't tell me anything about the world due to my action.",
                    "label": 0
                },
                {
                    "sent": "Then I have no empowerment.",
                    "label": 0
                },
                {
                    "sent": "I don't, I don't.",
                    "label": 0
                },
                {
                    "sent": "I can't do anything, but if my actions are actually changed, the world in such a way that I sense it and I have a high capacity of this action sensing both of them are actually action sensing capacities.",
                    "label": 0
                },
                {
                    "sent": "But one of them is within the current action and the previous state.",
                    "label": 0
                },
                {
                    "sent": "And another one is between the action in the next state.",
                    "label": 0
                },
                {
                    "sent": "So this is the response of the world.",
                    "label": 0
                },
                {
                    "sent": "To my actions, how much I can really learn from this response in the in simple information gains.",
                    "label": 0
                },
                {
                    "sent": "This is precisely the entropy of the answer before you got it.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is really nice in the sense that I can justify.",
                    "label": 0
                },
                {
                    "sent": "Of course everything is justified by large deviation.",
                    "label": 0
                },
                {
                    "sent": "That's what I want to do, but I can give very intuitive sense for these two quantities in terms of the cycle of perception action, one is now OK, so now.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I have this information there our L as I call it.",
                    "label": 0
                },
                {
                    "sent": "Essentially you do some active sensing, you get information and you can play essentially every response that you get from the environment due to a measurement is shifting you on the simplex.",
                    "label": 0
                },
                {
                    "sent": "And the simple possible, let's say 20 questions or information game you want to discover information.",
                    "label": 0
                },
                {
                    "sent": "You simply want to reduce the entropy and push yourself to the corners eventually, as the fastest possible way, and so building optimal codes or husband causing fuel after half an algorithm.",
                    "label": 0
                },
                {
                    "sent": "Things like this a special cases of of this special RL and those of you remember about Huffman codes?",
                    "label": 0
                },
                {
                    "sent": "There's something very funny there.",
                    "label": 0
                },
                {
                    "sent": "You have to start from the end and go backward, which is precisely what you do in Belmont.",
                    "label": 0
                },
                {
                    "sent": "I mean, you have to start from the Golden Gobekli, so believe me, I'm not going to prove it.",
                    "label": 0
                },
                {
                    "sent": "But the Huffman algorithm, the special case of rlin biscuits.",
                    "label": 0
                },
                {
                    "sent": "OK, so this was so reassuring that maybe we're going walking in the right track here, and I can address many.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Any different information questions like this like finding the false coin or many simple exercise in simple noiseless khodadad lossless coding and you're going to see that they're all in principle solvable by such walk on on the simplex.",
                    "label": 0
                },
                {
                    "sent": "Of course, if you think about it, the problem is a lot more difficult than just simple because I need to in principle finding a point on simplex is already a continuous state.",
                    "label": 0
                },
                {
                    "sent": "This is what people believe States and of course believe, so it's a hard battle.",
                    "label": 0
                },
                {
                    "sent": "How to manage so I'm just cheating a little bit when I tell you this is structural problem, I need to discretize my belief state somehow in order to make sense of it.",
                    "label": 0
                },
                {
                    "sent": "It's another issue, yes?",
                    "label": 0
                },
                {
                    "sent": "This code is scheme is optimal solution under the particular criteria that you proposed.",
                    "label": 0
                },
                {
                    "sent": "In this case it will be in the minimized number of steps on the average.",
                    "label": 0
                },
                {
                    "sent": "Yes, it's an entropy reduction.",
                    "label": 0
                },
                {
                    "sent": "I want to maximize enter to reduce the entropy for variable in the minimum number of steps.",
                    "label": 0
                },
                {
                    "sent": "So the penalty here is Under Armour steps.",
                    "label": 0
                },
                {
                    "sent": "So first of all, this was nice, because here is a very clear analogy and link between algorithms and controller algorithm information theory.",
                    "label": 0
                },
                {
                    "sent": "I want to make them into one the same algorithm, so I of course marry the two.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Skip all these details.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And essentially we have this nice dual picture.",
                    "label": 0
                },
                {
                    "sent": "The agent is interacting with the world through the Bellman equation.",
                    "label": 0
                },
                {
                    "sent": "The usable manipulation accumulating reward, and then choose an action and so forth.",
                    "label": 0
                },
                {
                    "sent": "But at the same time the same agent is accumulating knowledge by the lower triangle of this of this code.",
                    "label": 0
                },
                {
                    "sent": "Most nicely enough, this two questions.",
                    "label": 0
                },
                {
                    "sent": "These two quantities.",
                    "label": 0
                },
                {
                    "sent": "The expected future reward, or the value and the information to go obey exactly the same equation, but not quiet here.",
                    "label": 0
                },
                {
                    "sent": "Here are the reward was completely arbitrary.",
                    "label": 0
                },
                {
                    "sent": "It should be energy.",
                    "label": 0
                },
                {
                    "sent": "It should be something physical, but in most control theory it's more less arbitrary quadratic energy, whatever it is, it should be related to things like work and energy of control and things like this.",
                    "label": 0
                },
                {
                    "sent": "But in many cases you Simply put numbers there.",
                    "label": 0
                },
                {
                    "sent": "I mean, it's just.",
                    "label": 0
                },
                {
                    "sent": "Positive and negative numbers.",
                    "label": 0
                },
                {
                    "sent": "It works this Delta.",
                    "label": 0
                },
                {
                    "sent": "I is a function of my policy and my dynamics, so this is unlike this.",
                    "label": 0
                },
                {
                    "sent": "This is a linear equation V. This is a non linear equation.",
                    "label": 0
                },
                {
                    "sent": "I I have the log P hidden in this Delta so of course it's not really clear otherwise.",
                    "label": 0
                },
                {
                    "sent": "I mean if this were exactly the same equation then they had exactly the same solution.",
                    "label": 0
                },
                {
                    "sent": "Nothing new will come out of it.",
                    "label": 0
                },
                {
                    "sent": "But because this is nonlinear this has this entropic term.",
                    "label": 0
                },
                {
                    "sent": "This logarithmic probability terms.",
                    "label": 0
                },
                {
                    "sent": "The solution is a little more interesting.",
                    "label": 0
                },
                {
                    "sent": "And indeed, what I want to do, based on Son of, is to minimize this.",
                    "label": 0
                },
                {
                    "sent": "The detail subject to concern on this.",
                    "label": 0
                },
                {
                    "sent": "How do you do this?",
                    "label": 0
                },
                {
                    "sent": "Take Allegra.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Multiplier.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let me skip some.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Philosophy slides here, especially you take something which I called the free energy, and I'm sorry I really didn't mean to.",
                    "label": 0
                },
                {
                    "sent": "So free energy for the very simple reason it's a full advantage multiplier, very world.",
                    "label": 0
                },
                {
                    "sent": "This information to go acts like entropy here in the sense that unlike entropy, I want to minimize it maximizes because it's the KL divergent and this looks like a physical energy.",
                    "label": 0
                },
                {
                    "sent": "So it's a linear combination.",
                    "label": 0
                },
                {
                    "sent": "You want to maximize this and minimize this, or you put the LaGrange multiplier which is very much like temperature.",
                    "label": 0
                },
                {
                    "sent": "Better positive here and I called this the free energy of the state.",
                    "label": 0
                },
                {
                    "sent": "The specific free energy at the state St and the Action 80 and.",
                    "label": 0
                },
                {
                    "sent": "With the value better, which of course is in a one to one correspondence to the constraint value.",
                    "label": 0
                },
                {
                    "sent": "So this is a very nice.",
                    "label": 0
                },
                {
                    "sent": "I mean I call this frenergy simply because group growing up in statistical physics.",
                    "label": 0
                },
                {
                    "sent": "This is information or entropy in some general general session.",
                    "label": 0
                },
                {
                    "sent": "This is energy in some general says it's a very perfect energy, but notice of course we're not talking about any thermodynamic equilibrium, has nothing to do with some equilibrium, is as common as well.",
                    "label": 0
                },
                {
                    "sent": "I mean, it's actually the static flow this equilibrium.",
                    "label": 0
                },
                {
                    "sent": "Libram of Balance of information flow between us and the environment, and this is what I'm looking for.",
                    "label": 0
                },
                {
                    "sent": "The typical flow and of course, just notice that I don't like rewards because and discounting so don't know discounting here.",
                    "label": 0
                },
                {
                    "sent": "It's a bit cheating, but not that much.",
                    "label": 0
                },
                {
                    "sent": "I can always do it in finite horizon and take the limits eventually.",
                    "label": 0
                },
                {
                    "sent": "So there's a reward rate, and there's these two information flow rates.",
                    "label": 0
                },
                {
                    "sent": "How much information I received from the environment, how information I need to give back in terms of decisions and actions.",
                    "label": 0
                },
                {
                    "sent": "So believe me that you can simply take this and rewrite the Bellman equation in terms of the free energy.",
                    "label": 0
                },
                {
                    "sent": "That's very simple exercise and essentially what you get is that you get a new type of reward, so the free energy at the state St is averaged over this free energy at state S T + 1 plus something which I called.",
                    "label": 0
                },
                {
                    "sent": "Which is a combination of the information gain and better times the reward.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Let me come.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "After this slide later.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There's some simple, I call it first law, with all due respect and modesty, but it's not of course first low, but it's reminding me of the first law.",
                    "label": 1
                },
                {
                    "sent": "Thermodynamics in the sense that if I just average this equation Now, this should be equal to this in equilibrium and I get a simple, simple and somehow somehow surprising connection between the average reward rate.",
                    "label": 1
                },
                {
                    "sent": "And the capacity of these two information turns so essentially the average award multiplied by beta is the capacity of my controller plus what I call the empowerment of my system, which essentially how much my actions affect the next state of the environment given the previous state.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is nice again when you see some new connections which may be trivial, but they make sense.",
                    "label": 0
                },
                {
                    "sent": "They come from solid mathematics.",
                    "label": 0
                },
                {
                    "sent": "I didn't cheat anyone as far as I know, and I actually simulated it many times and it seems to work.",
                    "label": 0
                },
                {
                    "sent": "And actually this gives you a very simple algorithm.",
                    "label": 0
                },
                {
                    "sent": "It actually gives.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Several interesting questions already because I link these two things together now in a unified way, so there's no real difference between the reward, the external reward and this information reward.",
                    "label": 0
                },
                {
                    "sent": "They play exactly the same role, but one has something which I want to minimize in general, in order to ask for typicality and the other one is constrained by competition with others with my fitness.",
                    "label": 1
                },
                {
                    "sent": "This is just, by the way, is an interesting exercise, which I'm sure many of you will immediately follow, so you can rewrite this free energy by comparing your dynamics to something which is a special type of dynamics, which is the gifts distribution in terms of the reward.",
                    "label": 0
                },
                {
                    "sent": "Normalized, why's that because OK again I said rewards in control of usually arbitrary, but so it makes perfect sense that you should reward things more if they are less likely to happen.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's unlike the free energy which gives the solution in statistical physics which has a minus here.",
                    "label": 0
                },
                {
                    "sent": "Here reward has to be maximized, not minimized, so that's the only difference.",
                    "label": 0
                },
                {
                    "sent": "So it's a minimum minimum minus energy in some sense.",
                    "label": 0
                },
                {
                    "sent": "But other than that it's a gift distribution.",
                    "label": 0
                },
                {
                    "sent": "And then I rewrite this free energy.",
                    "label": 0
                },
                {
                    "sent": "And you can see that not only you get an algorithm for the best policy, you also get another term here, which is the KL divergent between your troop dynamics and this optimal Gibbs dynamics.",
                    "label": 1
                },
                {
                    "sent": "Now this is interesting because now you may ask yourself what would you like to call perfect adaptations of the environment.",
                    "label": 0
                },
                {
                    "sent": "So perfect adaptations to environment is precisely the case where the rewards are exponential in probability of getting their notice.",
                    "label": 0
                },
                {
                    "sent": "By the way, that this this is what we do in economy in many other places.",
                    "label": 0
                },
                {
                    "sent": "I mean, we actually make things which are how to get more valuable while we climbed Everest.",
                    "label": 0
                },
                {
                    "sent": "I don't know.",
                    "label": 0
                },
                {
                    "sent": "I never understood that.",
                    "label": 0
                },
                {
                    "sent": "But if it's hard to get the society rewards you for that.",
                    "label": 0
                },
                {
                    "sent": "In some funny way.",
                    "label": 0
                },
                {
                    "sent": "So essentially we're really approaching some long term evolution.",
                    "label": 0
                },
                {
                    "sent": "This optimal gifts like value, or in other words, saying it, is that we actually adapt the rewards to relate to the log probability of the transitions.",
                    "label": 0
                },
                {
                    "sent": "So this is again the gifts stochastic liberation and just in disguise, because it's coming here an entirely different context.",
                    "label": 0
                },
                {
                    "sent": "It's not mechanics, it's it's actually interaction with stochastic environment.",
                    "label": 0
                },
                {
                    "sent": "And of course you can now take the derivative of this free energy with respect to the policy.",
                    "label": 0
                },
                {
                    "sent": "Given the dynamics and get the solution, the optimal policy is exponential in the free energy as it should be.",
                    "label": 1
                },
                {
                    "sent": "Actually, if you break it down, you see that this algorithm, this we equations have to be self consistently satisfied.",
                    "label": 0
                },
                {
                    "sent": "This is nothing but the blood out Orimoto algorithm.",
                    "label": 0
                },
                {
                    "sent": "For those of you who are familiar with information theory, the rate distortion theory, so it's not.",
                    "label": 0
                },
                {
                    "sent": "It's not much more than that, it's unique globally converging Anonymous actually discovered it's identical to.",
                    "label": 0
                },
                {
                    "sent": "The Z iterations of M dollar off.",
                    "label": 0
                },
                {
                    "sent": "Essentially it's a linear algorithm which can be solved very very nicely and very quickly so.",
                    "label": 0
                },
                {
                    "sent": "Here is a way of optimizing the policy.",
                    "label": 1
                },
                {
                    "sent": "You have free energy or partition function type of quantity, which is very naturally emerging and actually see you see that you can rewrite the free energy in terms of the lock free energy low partition function.",
                    "label": 0
                },
                {
                    "sent": "Just as we love and know.",
                    "label": 0
                },
                {
                    "sent": "OK so.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Course now you can apply to many problems, for example solving mazes and you see this basic relationship between value and information.",
                    "label": 0
                },
                {
                    "sent": "Again, something how much, how much, how much is the value of another bit of information about about the future of the world.",
                    "label": 0
                },
                {
                    "sent": "I always teach you.",
                    "label": 0
                },
                {
                    "sent": "Ask them how much are willing to pay.",
                    "label": 0
                },
                {
                    "sent": "I have a crystal ball now you can ask binary questions about the future.",
                    "label": 0
                },
                {
                    "sent": "What are your three questions to ask?",
                    "label": 0
                },
                {
                    "sent": "So it's not that easy to think you have only three questions, but actually this is precisely what this is answering.",
                    "label": 0
                },
                {
                    "sent": "It's telling you, OK, if essentially in order to get to the optimal solution that deterministic optimal solution of the bellman.",
                    "label": 0
                },
                {
                    "sent": "Equation you have to take better to Infinity and in this case it's giving you this somewhat.",
                    "label": 0
                },
                {
                    "sent": "You see that you can actually solve this maze not with 70 bits of information, but with 30,000,000 information.",
                    "label": 0
                },
                {
                    "sent": "With losing only 5% of the value.",
                    "label": 0
                },
                {
                    "sent": "Essentially you have this type of inverse rate distortion function and simply telling you what how much information about the future you need to know for certain value of information value.",
                    "label": 0
                },
                {
                    "sent": "And you see that it has this upward concave but very very flat in most in most scenarios.",
                    "label": 0
                },
                {
                    "sent": "We are not going to get much value by adding more and more information.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to give you much.",
                    "label": 0
                },
                {
                    "sent": "For example in this simple case and this simple maze, you need to go from here to here.",
                    "label": 0
                },
                {
                    "sent": "You see that most of the information is in the red areas where you have to be mostly almost deterministic, but in the other colors here is less, can be more, more more more stochastic, and there is really little.",
                    "label": 0
                },
                {
                    "sent": "There's a huge.",
                    "label": 0
                },
                {
                    "sent": "OK, Betta equals .5 somewhere here.",
                    "label": 0
                },
                {
                    "sent": "There's you stochastic city here.",
                    "label": 0
                },
                {
                    "sent": "Everything is simplistic in terms of where you want to walk.",
                    "label": 0
                },
                {
                    "sent": "In here, almost everything is completely stochastic and you still get essentially the same.",
                    "label": 0
                },
                {
                    "sent": "The same value.",
                    "label": 0
                },
                {
                    "sent": "Not only that, and that's really the key to the next part of my talk.",
                    "label": 0
                },
                {
                    "sent": "I don't know how much time.",
                    "label": 0
                },
                {
                    "sent": "0.",
                    "label": 0
                },
                {
                    "sent": "OK so I'm sorry, But anyway this is going to mark for you the interesting points on your trajectory in terms of building the hierarchies.",
                    "label": 0
                },
                {
                    "sent": "So I just OK there's.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another whole story here, which I believe you've done, is going to tell us more about you can give another yet another interpretations of this DKL in terms of learning theory or what we call in learning theory.",
                    "label": 0
                },
                {
                    "sent": "the PAC Bayes bound and actually put it the whole thing in terms of learning and generalizing from trajectories when you don't know the model.",
                    "label": 0
                },
                {
                    "sent": "And this is actually quite interesting because it turns out that again, this KL within the posterior and prior is the thing that controls the complexity of the complexity of your learning.",
                    "label": 0
                },
                {
                    "sent": "This isn't generalization limit, so.",
                    "label": 0
                },
                {
                    "sent": "I know proof things are probably true from different reasons and this is just yet another way of thinking about the same.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Mechanism exactly.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so in this case in this case is actually optimal if you have finite knowledge about the environment, there is an optimal better which is not Infinity, which will give you the best generalization in terms of in terms of this pack base.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Bound OK so.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It was just an exam.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Only imagine that you need why information can actually help you.",
                    "label": 0
                },
                {
                    "sent": "Imagine that you need to walk through a minefield.",
                    "label": 0
                },
                {
                    "sent": "So the optimal the global optimal solution, knowing everything is working here between the minds, I'm sure that none of you will want to try.",
                    "label": 0
                },
                {
                    "sent": "If you could give less information, this algorithm immediately finds a way around.",
                    "label": 0
                },
                {
                    "sent": "Don't get in, you not know enough in order to do this.",
                    "label": 0
                },
                {
                    "sent": "And this is again this.",
                    "label": 0
                },
                {
                    "sent": "Free energy minimization is actually more robust for small changes in the environment.",
                    "label": 0
                },
                {
                    "sent": "This is precisely what the pack based bound is telling us.",
                    "label": 0
                },
                {
                    "sent": "OK, I think I can stop here, although I didn't tell you the the really funny part of the story, which is how to discount information.",
                    "label": 0
                },
                {
                    "sent": "But if I'm out of time out of time, what can I do offline?",
                    "label": 0
                },
                {
                    "sent": "There are some some interpretations, so professional control based on information student by George's ideas.",
                    "label": 0
                },
                {
                    "sent": "I don't know if I was awful about credit here.",
                    "label": 0
                },
                {
                    "sent": "I mean there are many, many people that should be credited for many of the things that I say.",
                    "label": 0
                },
                {
                    "sent": "But no, I'm not familiar with this particular work.",
                    "label": 0
                },
                {
                    "sent": "With that, many people discovered a lot of these things independently.",
                    "label": 0
                },
                {
                    "sent": "Maybe?",
                    "label": 0
                },
                {
                    "sent": "Some other people know about.",
                    "label": 0
                },
                {
                    "sent": "I came to learn so this is one of the things I want to know.",
                    "label": 0
                },
                {
                    "sent": "What I see in this equation?",
                    "label": 0
                },
                {
                    "sent": "Terms have equal weight, so there's apparently a normal weight distribution through two.",
                    "label": 0
                },
                {
                    "sent": "Which, well, if you think of control theory would have to work you think you would have to invent it just for the Alpha and better price, right?",
                    "label": 0
                },
                {
                    "sent": "So the bits of control are not the same as the bitter perception.",
                    "label": 0
                },
                {
                    "sent": "That's what you're saying.",
                    "label": 0
                },
                {
                    "sent": "They have different values.",
                    "label": 0
                },
                {
                    "sent": "I guess you can do it, I mean just put another log on the fire somewhere.",
                    "label": 0
                },
                {
                    "sent": "I think this is a natural one if all you care is about one value, which is the cumulative expected reward and expected future reward.",
                    "label": 0
                },
                {
                    "sent": "But if you have other other functions that constrain your behavior, then you may.",
                    "label": 0
                },
                {
                    "sent": "For example, you have another cost of sensing which is different from the value.",
                    "label": 0
                },
                {
                    "sent": "So for example, we certainly we had.",
                    "label": 0
                },
                {
                    "sent": "Actually I see Mail paper this year on the memory.",
                    "label": 0
                },
                {
                    "sent": "Memory capacity of memory.",
                    "label": 0
                },
                {
                    "sent": "How much you want to remember from the past versus how much you want to invest in your sensors.",
                    "label": 0
                },
                {
                    "sent": "It's a very fundamental question in control theory.",
                    "label": 0
                },
                {
                    "sent": "Do you want the large camera, or do you want a better maneuverability?",
                    "label": 0
                },
                {
                    "sent": "Better memory in your computer and you send it to Mars or whatever?",
                    "label": 0
                },
                {
                    "sent": "Of course, it depends on the stochasticity environment, how much you can remember this is how much you really need to acquire all the time, and there's a nice trade off there that you can easily solve in this insane tricks.",
                    "label": 0
                },
                {
                    "sent": "Question.",
                    "label": 0
                },
                {
                    "sent": "It's very simple terms of nothing with your with your family and minimizes the divergent between the poster in the primary subject to constraints, which I don't see in your case so easily.",
                    "label": 0
                },
                {
                    "sent": "It disappoints me there after what you just said, you may have that for free because I mean that that form a basis vector is complexity.",
                    "label": 0
                },
                {
                    "sent": "If you go back to the NDL inscription on the message length formulations, the original version being formulations that basically is the cost of encoding.",
                    "label": 0
                },
                {
                    "sent": "So if you associate any metabolic or physical encoding machinery, then that competitive firm is the most common cause.",
                    "label": 0
                },
                {
                    "sent": "I have money when you're gone for free and you don't actually need your your reward.",
                    "label": 0
                },
                {
                    "sent": "Israel weather I don't see I don't see it.",
                    "label": 0
                },
                {
                    "sent": "I mean, I think you need some structure in this problem, otherwise you will converge to trivialities and it's just like energy.",
                    "label": 0
                },
                {
                    "sent": "In physical systems.",
                    "label": 0
                },
                {
                    "sent": "I mean, you can't just maximize entropy or just.",
                    "label": 0
                },
                {
                    "sent": "Could you have your?",
                    "label": 0
                },
                {
                    "sent": "We would have to optimize if you sent me to 0 your speed would still work and I'm what I'm asking, would you by virtue of minimizing complexity and also the metabolic costs of encoding?",
                    "label": 0
                },
                {
                    "sent": "This will bring down costs encoding a message.",
                    "label": 0
                },
                {
                    "sent": "No message passing with the environment.",
                    "label": 0
                },
                {
                    "sent": "Would you not get something sense planted?",
                    "label": 0
                },
                {
                    "sent": "Well, I'm in the truck I know exactly what you mean by message passing with environment.",
                    "label": 0
                },
                {
                    "sent": "If by that message passing you actually percolate constraints from the environment back into the optimization, then of course you're right.",
                    "label": 0
                },
                {
                    "sent": "But.",
                    "label": 0
                },
                {
                    "sent": "Explicitly, there is a constraint.",
                    "label": 0
                },
                {
                    "sent": "Otherwise, if you don't constrain your value or something like this, the minimum detail will be posterior equal to prior.",
                    "label": 0
                },
                {
                    "sent": "That's it, and that's nothing interesting.",
                    "label": 0
                },
                {
                    "sent": "First many details here how to do it in practice you can do it adiabatic Lee by slowly changing your value.",
                    "label": 0
                },
                {
                    "sent": "MDL, for example is not the first principle as far as I'm concerned.",
                    "label": 0
                },
                {
                    "sent": "It's larger version which is the first principle which leads to MDL in some cases or Bayesian inference and they're all related.",
                    "label": 0
                },
                {
                    "sent": "But MDL is far as I'm concerned.",
                    "label": 0
                },
                {
                    "sent": "Just like Max the original James maximum entropy.",
                    "label": 0
                },
                {
                    "sent": "Somehow mystical principles that you need to put it in some context of some theorems that guarantees something.",
                    "label": 0
                },
                {
                    "sent": "You know that makes sense if.",
                    "label": 0
                },
                {
                    "sent": "Anyway, it's time to eat.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "See you over lunch.",
                    "label": 0
                }
            ]
        }
    }
}