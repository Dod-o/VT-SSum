{
    "id": "5wvhh6owtmi6urgdo3chmevi7pjikx3c",
    "title": "FEMA: Flexible Evolutionary Multi-faceted Analysis for Dynamic Behavioral Pattern Discovery",
    "info": {
        "author": [
            "Meng Jiang, Department of Computer Science and Technology, Tsinghua University"
        ],
        "published": "Oct. 7, 2014",
        "recorded": "August 2014",
        "category": [
            "Top->Computer Science->Data Mining",
            "Top->Computer Science->Knowledge Extraction"
        ]
    },
    "url": "http://videolectures.net/kdd2014_jiang_fema/",
    "segmentation": [
        [
            "Thank you, thank you and thank you Linda.",
            "Very nice work.",
            "Thank you for.",
            "I like the concept of compactness.",
            "I have another concept is called synchronicity.",
            "It's for the protection.",
            "It will be another work I will introduce tomorrow morning, so it's for using still graph mining algorithms.",
            "Welcome to our talk tomorrow morning.",
            "So my name is Min John.",
            "I'm from Shanghai diversity.",
            "I'm introducing our work here, our framework, FEMA.",
            "It's flexible, evolutionary multifaceted analysis.",
            "For dynamic behavior pattern discovery, this is joint work with carpentry free, one singer and she went through along with Drew and Sean Young."
        ],
        [
            "So behavior data analysis is very important.",
            "Industry and scientific research.",
            "What we human beings do everyday is just creating behavior data right?",
            "So we researchers public papers so we have DLP and Google Scholar data.",
            "We post messages and photos on Facebook on social networks.",
            "So we have Facebook and Twitter data.",
            "So we are the machines that who created data.",
            "Anne.",
            "How to understand the huge data behavior data sequence is very important.",
            "For example, I think with the step should we have three models?",
            "The first should be behavior modeling, right?",
            "For example, can we formulate the behaviors of research who published papers on KDD sorting and Katie defaulting?",
            "Our final goal is surely the behavior prediction right?",
            "We want to predict based on the historical data what is his next paper?",
            "Right?",
            "Our prediction is should be based on the patterns.",
            "I mean the parents understanding understanding his behaviors, so from his previous papers we can know that he's interested in data mining so we can see that maybe he will submit his papers to TCD Journal or perhaps KD next year.",
            "OK?",
            "So with all these three modules, we want effective and efficient frameworks for process data."
        ],
        [
            "Here at least our goal.",
            "So given us a large behavior this sequence, we want a general framework that can fast and best fit to the behavior data.",
            "Our goals are very clear.",
            "First, the framework should give a very nice presentation for our human being behavior.",
            "Second should be very should be able to capture the hidden patterns in human behaviors and the third it should be able to predict the missing behaviors accurately and fast."
        ],
        [
            "His outline of this talk.",
            "First, I will give the background and then we'll talk about the model, formulation and framework family and then I will give the experimental results and validations.",
            "Let's look at the background."
        ],
        [
            "You really with this crap human being human behavior as links between two types of objects.",
            "When we talk about writing paper behavior, we focus on the researcher and article.",
            "For example, Professor Joey Hunt on his book mining heterogeneous information at Networks about posting photos on Facebook like me and my photo of Sheraton Hotel, right as we know, most of the previous approaches, model the human being behavior into 2 dimensions."
        ],
        [
            "However, the human human behavior is actually multi faceted.",
            "To write a paper or book, researchers have their clusters and groups or departments or universities.",
            "The book about history, information, information, networks was written by Professor Jerry Hunt and his student Eagle soon.",
            "When they were in the data mining group of UIUC.",
            "Also, I'm attending Kitty with my advisor, Professor Prince Way.",
            "So when I post the photo on Facebook about Sheraton Hotel, I will check in and see with him.",
            "It shows it shows my checking and my comment is so nice.",
            "So we believe human behavior should be modelled into multiple dimensions."
        ],
        [
            "Another important feature of human behavior is dynamic pattern.",
            "Our behavior involves overtime.",
            "For example, when Professor Job was in Summer Fraser, he published papers about database.",
            "Well, he moved to you.",
            "You see he focused on the data clustering.",
            "One later when each join his group, they worked on heterogeneous information networks.",
            "They have many papers are very big impact on every topic, but we can clearly see the evolutionary pattern in their research."
        ],
        [
            "Also about the Facebook messages can change overtime everyday.",
            "Here I'm in quality, I post photos of the talks and the tea break, cookies and traveling in New York at different times in different months.",
            "This year I post the photos about my life in different places such as showing April for cheaper dub Qinghai in June and July, and hearing New York forecast."
        ],
        [
            "So now we notice that human being human behavior is multifaceted and dynamic.",
            "How can we find a very nice presentation tomorrow formulated?"
        ],
        [
            "Let's see the population."
        ],
        [
            "With human behavior data, we want to solve these problems first.",
            "Behavior modeling second will be the pattern discovery and the third will be behavior prediction behavior is multifaceted, so we can use higher order tensors to model it.",
            "Behavior is dynamic, so we have a large sequence of tensors.",
            "Then we can decompose the tensors for pattern discovery and do tensor completion to predict the missing values."
        ],
        [
            "The formulation is intuitive, but we have to face very big challenges.",
            "First is the high sparsity right?",
            "The high order tensors will bring us very high sparsity problem.",
            "The second is the high complexity problem.",
            "It costs too much time.",
            "If we decompose every tensor from the long sequence every time."
        ],
        [
            "Our idea to solve this problem is to solve that we use the auxiliary knowledge as regulations to serve the high severity problem.",
            "For example, the Co authorship data will help us to break predict the writing behavior paper behavior.",
            "Also, the social relations may help us to break predict our Facebook messages."
        ],
        [
            "And for the high convexity problem, it is too slow to update and decompose every tensor for the projection matrix again and again.",
            "But we said we want to update if we want update the projection matrix with the Newcomen pieces of data would be faster, right?",
            "Our framework should be evolutionary and should incorporate the regulations."
        ],
        [
            "So now let's see our framework for Emma."
        ],
        [
            "Give us a tensor.",
            "The previous research like Jim mentions DTI is called dynamic tensor analysis in 2008.",
            "Introduce how to decompose it.",
            "First, we do much deciding we turn the tensors into multiple metrics.",
            "2nd we decompose them into core tensors and projection matrix.",
            "The projection misses give us clusters in different dimensions.",
            "Here we want to incorporate the regulations before the competition.",
            "If that answer is continuously updated, you can see here is the coming peace.",
            "So a DTA will decompose the metric size that answer again after it's updated.",
            "We notice that this step will cost lots of time, so we use FEMA, a novel framework to update the call, tensors and preaching metrics with the new calming piece of data.",
            "Our hypothesis is that the new coming data is much smaller than previous data."
        ],
        [
            "So the way to compute optical sensors and the projection matrix is based on tensor perturbation theory.",
            "Here X for the old metric metric size tensor and that X for the update error is for the regulation and is for the vectors in the projection matrix and lubna is the agent value so that we want to solve the Delta A and the debt alumna."
        ],
        [
            "We propose famous algorithm to show how to approximate the updated core tensor and depression metrics.",
            "It also gives bounds to guarantee the performance of the approximation."
        ],
        [
            "Now let's see the experiments."
        ],
        [
            "We show performance of predicting human behaviors.",
            "I first will show our datasets and check the usefulness of leveraging multifaceted information and leveraging the flexible regulations.",
            "The last will be efficiency, loss and robustness to parameters."
        ],
        [
            "We use two datasets, ones from Microsoft Academic Research.",
            "We first search search the data, mining this keyword to get the top 100 experts that we crawled their papers and information through 22 years.",
            "The dimensions in this tensor are author affiliation and keyword.",
            "Every entry is the number of papers, so the regulation data will be Co authorship metrics.",
            "The other is from Tencent Weibo.",
            "It's a microblogging service in China.",
            "We have data in 40, three days.",
            "The behavior is that users can ask their friends in tweets so we have the user who use edge and the users who are XI mean they're mentioned in the tweets and the words in their tweets.",
            "The regulation will be the social relation metrics."
        ],
        [
            "Now we try to predict who writes paper about what keyword and predict who use edge to mention whom.",
            "So this is a prediction prediction task between 2 dimensions right?",
            "We want to know if multifaceted information can help.",
            "That means that the tensor will be better than the metrics.",
            "So here we can see the MA an RMC for FEMA aenema.",
            "They have M. It means multifaceted they use tensors so they are much better than I mean the MMC are smaller than EA which do not use multifaceted information, it's just metrics.",
            "The performance better than the precision recall also better.",
            "You can see the curves."
        ],
        [
            "Now let's see if the auxiliary knowledge here is the flexible regulations can help we predict the missing entries in tensors.",
            "We can see our method pharma, which uses regulations from Co authorship and social relation.",
            "They work better than those tensor based methods that do not incorporate auxiliary knowledge."
        ],
        [
            "The time cost is much less if we do evolution analysis instead of really composing the updated cancers while the loss is not much because it's we have given bounds to guarantee the performance.",
            "We also tested robotics through the regulation, which in the two datasets you can see the MC Curve show family is very insensitive to the weights."
        ],
        [
            "Now let's see some validation results for."
        ],
        [
            "We want to see if Emily can catch the multifaceted and dynamic patterns.",
            "We were sure what we find in I may as well not available.",
            "If you are interested, please read out.",
            "Only weighs about the Chinese text, so he."
        ],
        [
            "Here we show the largest author author clusters in Ms. Of which is Java, has group and also glad the largest value is perfectly fine and the values in author, affiliation and keyword.",
            "The vector change overtime.",
            "You can see that the board, I mean the highlight terms, users and physicians and the keywords has the largest values in vectors.",
            "So we can see in 1998 when he was inside my freezer.",
            "Relational Database was his main interest.",
            "He had papers of opposition rules and recursive query.",
            "It was working on database."
        ],
        [
            "In 2005, Joe has been moved to reduce it to be a professor.",
            "There he focused on data clustering and frequently providing.",
            "You can see his liberators, like Professor Jim pay cheaper here than physically."
        ],
        [
            "In 2012, he worked more on his Registry Information, Information, Network and social networks is relevant.",
            "Certifications and courses are different from that.",
            "In 2005 we can see the difference.",
            "So and also you can see the difference in affiliation and keywords."
        ],
        [
            "OK, let's summarize.",
            "I will talk.",
            "So we said we find we notice that the human behavior is multifaceted and dynamic.",
            "We are facing two challenges.",
            "When we build a human behavior, one is positive and the other is the high complexity.",
            "We use flexible regulations and evolutionary analysis to solve them.",
            "And then we give a framework called femmer with an approximation obvious and bonds.",
            "We conduct experiments on behavior prediction and also validations pending discovery.",
            "OK, that's fine."
        ],
        [
            "So thank you for listening."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Thank you, thank you and thank you Linda.",
                    "label": 0
                },
                {
                    "sent": "Very nice work.",
                    "label": 0
                },
                {
                    "sent": "Thank you for.",
                    "label": 0
                },
                {
                    "sent": "I like the concept of compactness.",
                    "label": 0
                },
                {
                    "sent": "I have another concept is called synchronicity.",
                    "label": 0
                },
                {
                    "sent": "It's for the protection.",
                    "label": 0
                },
                {
                    "sent": "It will be another work I will introduce tomorrow morning, so it's for using still graph mining algorithms.",
                    "label": 0
                },
                {
                    "sent": "Welcome to our talk tomorrow morning.",
                    "label": 0
                },
                {
                    "sent": "So my name is Min John.",
                    "label": 0
                },
                {
                    "sent": "I'm from Shanghai diversity.",
                    "label": 0
                },
                {
                    "sent": "I'm introducing our work here, our framework, FEMA.",
                    "label": 0
                },
                {
                    "sent": "It's flexible, evolutionary multifaceted analysis.",
                    "label": 1
                },
                {
                    "sent": "For dynamic behavior pattern discovery, this is joint work with carpentry free, one singer and she went through along with Drew and Sean Young.",
                    "label": 1
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So behavior data analysis is very important.",
                    "label": 0
                },
                {
                    "sent": "Industry and scientific research.",
                    "label": 0
                },
                {
                    "sent": "What we human beings do everyday is just creating behavior data right?",
                    "label": 0
                },
                {
                    "sent": "So we researchers public papers so we have DLP and Google Scholar data.",
                    "label": 0
                },
                {
                    "sent": "We post messages and photos on Facebook on social networks.",
                    "label": 0
                },
                {
                    "sent": "So we have Facebook and Twitter data.",
                    "label": 0
                },
                {
                    "sent": "So we are the machines that who created data.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "How to understand the huge data behavior data sequence is very important.",
                    "label": 1
                },
                {
                    "sent": "For example, I think with the step should we have three models?",
                    "label": 0
                },
                {
                    "sent": "The first should be behavior modeling, right?",
                    "label": 0
                },
                {
                    "sent": "For example, can we formulate the behaviors of research who published papers on KDD sorting and Katie defaulting?",
                    "label": 0
                },
                {
                    "sent": "Our final goal is surely the behavior prediction right?",
                    "label": 0
                },
                {
                    "sent": "We want to predict based on the historical data what is his next paper?",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "Our prediction is should be based on the patterns.",
                    "label": 0
                },
                {
                    "sent": "I mean the parents understanding understanding his behaviors, so from his previous papers we can know that he's interested in data mining so we can see that maybe he will submit his papers to TCD Journal or perhaps KD next year.",
                    "label": 0
                },
                {
                    "sent": "OK?",
                    "label": 0
                },
                {
                    "sent": "So with all these three modules, we want effective and efficient frameworks for process data.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here at least our goal.",
                    "label": 0
                },
                {
                    "sent": "So given us a large behavior this sequence, we want a general framework that can fast and best fit to the behavior data.",
                    "label": 1
                },
                {
                    "sent": "Our goals are very clear.",
                    "label": 0
                },
                {
                    "sent": "First, the framework should give a very nice presentation for our human being behavior.",
                    "label": 1
                },
                {
                    "sent": "Second should be very should be able to capture the hidden patterns in human behaviors and the third it should be able to predict the missing behaviors accurately and fast.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "His outline of this talk.",
                    "label": 0
                },
                {
                    "sent": "First, I will give the background and then we'll talk about the model, formulation and framework family and then I will give the experimental results and validations.",
                    "label": 1
                },
                {
                    "sent": "Let's look at the background.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You really with this crap human being human behavior as links between two types of objects.",
                    "label": 1
                },
                {
                    "sent": "When we talk about writing paper behavior, we focus on the researcher and article.",
                    "label": 0
                },
                {
                    "sent": "For example, Professor Joey Hunt on his book mining heterogeneous information at Networks about posting photos on Facebook like me and my photo of Sheraton Hotel, right as we know, most of the previous approaches, model the human being behavior into 2 dimensions.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "However, the human human behavior is actually multi faceted.",
                    "label": 0
                },
                {
                    "sent": "To write a paper or book, researchers have their clusters and groups or departments or universities.",
                    "label": 0
                },
                {
                    "sent": "The book about history, information, information, networks was written by Professor Jerry Hunt and his student Eagle soon.",
                    "label": 0
                },
                {
                    "sent": "When they were in the data mining group of UIUC.",
                    "label": 0
                },
                {
                    "sent": "Also, I'm attending Kitty with my advisor, Professor Prince Way.",
                    "label": 0
                },
                {
                    "sent": "So when I post the photo on Facebook about Sheraton Hotel, I will check in and see with him.",
                    "label": 1
                },
                {
                    "sent": "It shows it shows my checking and my comment is so nice.",
                    "label": 0
                },
                {
                    "sent": "So we believe human behavior should be modelled into multiple dimensions.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Another important feature of human behavior is dynamic pattern.",
                    "label": 1
                },
                {
                    "sent": "Our behavior involves overtime.",
                    "label": 0
                },
                {
                    "sent": "For example, when Professor Job was in Summer Fraser, he published papers about database.",
                    "label": 0
                },
                {
                    "sent": "Well, he moved to you.",
                    "label": 0
                },
                {
                    "sent": "You see he focused on the data clustering.",
                    "label": 0
                },
                {
                    "sent": "One later when each join his group, they worked on heterogeneous information networks.",
                    "label": 0
                },
                {
                    "sent": "They have many papers are very big impact on every topic, but we can clearly see the evolutionary pattern in their research.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Also about the Facebook messages can change overtime everyday.",
                    "label": 1
                },
                {
                    "sent": "Here I'm in quality, I post photos of the talks and the tea break, cookies and traveling in New York at different times in different months.",
                    "label": 0
                },
                {
                    "sent": "This year I post the photos about my life in different places such as showing April for cheaper dub Qinghai in June and July, and hearing New York forecast.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now we notice that human being human behavior is multifaceted and dynamic.",
                    "label": 0
                },
                {
                    "sent": "How can we find a very nice presentation tomorrow formulated?",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's see the population.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "With human behavior data, we want to solve these problems first.",
                    "label": 0
                },
                {
                    "sent": "Behavior modeling second will be the pattern discovery and the third will be behavior prediction behavior is multifaceted, so we can use higher order tensors to model it.",
                    "label": 1
                },
                {
                    "sent": "Behavior is dynamic, so we have a large sequence of tensors.",
                    "label": 0
                },
                {
                    "sent": "Then we can decompose the tensors for pattern discovery and do tensor completion to predict the missing values.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The formulation is intuitive, but we have to face very big challenges.",
                    "label": 0
                },
                {
                    "sent": "First is the high sparsity right?",
                    "label": 1
                },
                {
                    "sent": "The high order tensors will bring us very high sparsity problem.",
                    "label": 1
                },
                {
                    "sent": "The second is the high complexity problem.",
                    "label": 1
                },
                {
                    "sent": "It costs too much time.",
                    "label": 0
                },
                {
                    "sent": "If we decompose every tensor from the long sequence every time.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Our idea to solve this problem is to solve that we use the auxiliary knowledge as regulations to serve the high severity problem.",
                    "label": 1
                },
                {
                    "sent": "For example, the Co authorship data will help us to break predict the writing behavior paper behavior.",
                    "label": 0
                },
                {
                    "sent": "Also, the social relations may help us to break predict our Facebook messages.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And for the high convexity problem, it is too slow to update and decompose every tensor for the projection matrix again and again.",
                    "label": 0
                },
                {
                    "sent": "But we said we want to update if we want update the projection matrix with the Newcomen pieces of data would be faster, right?",
                    "label": 0
                },
                {
                    "sent": "Our framework should be evolutionary and should incorporate the regulations.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now let's see our framework for Emma.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Give us a tensor.",
                    "label": 0
                },
                {
                    "sent": "The previous research like Jim mentions DTI is called dynamic tensor analysis in 2008.",
                    "label": 0
                },
                {
                    "sent": "Introduce how to decompose it.",
                    "label": 0
                },
                {
                    "sent": "First, we do much deciding we turn the tensors into multiple metrics.",
                    "label": 0
                },
                {
                    "sent": "2nd we decompose them into core tensors and projection matrix.",
                    "label": 0
                },
                {
                    "sent": "The projection misses give us clusters in different dimensions.",
                    "label": 0
                },
                {
                    "sent": "Here we want to incorporate the regulations before the competition.",
                    "label": 0
                },
                {
                    "sent": "If that answer is continuously updated, you can see here is the coming peace.",
                    "label": 0
                },
                {
                    "sent": "So a DTA will decompose the metric size that answer again after it's updated.",
                    "label": 0
                },
                {
                    "sent": "We notice that this step will cost lots of time, so we use FEMA, a novel framework to update the call, tensors and preaching metrics with the new calming piece of data.",
                    "label": 0
                },
                {
                    "sent": "Our hypothesis is that the new coming data is much smaller than previous data.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the way to compute optical sensors and the projection matrix is based on tensor perturbation theory.",
                    "label": 0
                },
                {
                    "sent": "Here X for the old metric metric size tensor and that X for the update error is for the regulation and is for the vectors in the projection matrix and lubna is the agent value so that we want to solve the Delta A and the debt alumna.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We propose famous algorithm to show how to approximate the updated core tensor and depression metrics.",
                    "label": 0
                },
                {
                    "sent": "It also gives bounds to guarantee the performance of the approximation.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now let's see the experiments.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We show performance of predicting human behaviors.",
                    "label": 0
                },
                {
                    "sent": "I first will show our datasets and check the usefulness of leveraging multifaceted information and leveraging the flexible regulations.",
                    "label": 1
                },
                {
                    "sent": "The last will be efficiency, loss and robustness to parameters.",
                    "label": 1
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We use two datasets, ones from Microsoft Academic Research.",
                    "label": 0
                },
                {
                    "sent": "We first search search the data, mining this keyword to get the top 100 experts that we crawled their papers and information through 22 years.",
                    "label": 1
                },
                {
                    "sent": "The dimensions in this tensor are author affiliation and keyword.",
                    "label": 1
                },
                {
                    "sent": "Every entry is the number of papers, so the regulation data will be Co authorship metrics.",
                    "label": 0
                },
                {
                    "sent": "The other is from Tencent Weibo.",
                    "label": 0
                },
                {
                    "sent": "It's a microblogging service in China.",
                    "label": 0
                },
                {
                    "sent": "We have data in 40, three days.",
                    "label": 0
                },
                {
                    "sent": "The behavior is that users can ask their friends in tweets so we have the user who use edge and the users who are XI mean they're mentioned in the tweets and the words in their tweets.",
                    "label": 0
                },
                {
                    "sent": "The regulation will be the social relation metrics.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now we try to predict who writes paper about what keyword and predict who use edge to mention whom.",
                    "label": 0
                },
                {
                    "sent": "So this is a prediction prediction task between 2 dimensions right?",
                    "label": 0
                },
                {
                    "sent": "We want to know if multifaceted information can help.",
                    "label": 0
                },
                {
                    "sent": "That means that the tensor will be better than the metrics.",
                    "label": 0
                },
                {
                    "sent": "So here we can see the MA an RMC for FEMA aenema.",
                    "label": 0
                },
                {
                    "sent": "They have M. It means multifaceted they use tensors so they are much better than I mean the MMC are smaller than EA which do not use multifaceted information, it's just metrics.",
                    "label": 0
                },
                {
                    "sent": "The performance better than the precision recall also better.",
                    "label": 0
                },
                {
                    "sent": "You can see the curves.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now let's see if the auxiliary knowledge here is the flexible regulations can help we predict the missing entries in tensors.",
                    "label": 0
                },
                {
                    "sent": "We can see our method pharma, which uses regulations from Co authorship and social relation.",
                    "label": 0
                },
                {
                    "sent": "They work better than those tensor based methods that do not incorporate auxiliary knowledge.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The time cost is much less if we do evolution analysis instead of really composing the updated cancers while the loss is not much because it's we have given bounds to guarantee the performance.",
                    "label": 0
                },
                {
                    "sent": "We also tested robotics through the regulation, which in the two datasets you can see the MC Curve show family is very insensitive to the weights.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now let's see some validation results for.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We want to see if Emily can catch the multifaceted and dynamic patterns.",
                    "label": 0
                },
                {
                    "sent": "We were sure what we find in I may as well not available.",
                    "label": 0
                },
                {
                    "sent": "If you are interested, please read out.",
                    "label": 0
                },
                {
                    "sent": "Only weighs about the Chinese text, so he.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here we show the largest author author clusters in Ms. Of which is Java, has group and also glad the largest value is perfectly fine and the values in author, affiliation and keyword.",
                    "label": 0
                },
                {
                    "sent": "The vector change overtime.",
                    "label": 0
                },
                {
                    "sent": "You can see that the board, I mean the highlight terms, users and physicians and the keywords has the largest values in vectors.",
                    "label": 0
                },
                {
                    "sent": "So we can see in 1998 when he was inside my freezer.",
                    "label": 0
                },
                {
                    "sent": "Relational Database was his main interest.",
                    "label": 0
                },
                {
                    "sent": "He had papers of opposition rules and recursive query.",
                    "label": 0
                },
                {
                    "sent": "It was working on database.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In 2005, Joe has been moved to reduce it to be a professor.",
                    "label": 0
                },
                {
                    "sent": "There he focused on data clustering and frequently providing.",
                    "label": 0
                },
                {
                    "sent": "You can see his liberators, like Professor Jim pay cheaper here than physically.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In 2012, he worked more on his Registry Information, Information, Network and social networks is relevant.",
                    "label": 0
                },
                {
                    "sent": "Certifications and courses are different from that.",
                    "label": 0
                },
                {
                    "sent": "In 2005 we can see the difference.",
                    "label": 0
                },
                {
                    "sent": "So and also you can see the difference in affiliation and keywords.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, let's summarize.",
                    "label": 0
                },
                {
                    "sent": "I will talk.",
                    "label": 0
                },
                {
                    "sent": "So we said we find we notice that the human behavior is multifaceted and dynamic.",
                    "label": 1
                },
                {
                    "sent": "We are facing two challenges.",
                    "label": 0
                },
                {
                    "sent": "When we build a human behavior, one is positive and the other is the high complexity.",
                    "label": 1
                },
                {
                    "sent": "We use flexible regulations and evolutionary analysis to solve them.",
                    "label": 1
                },
                {
                    "sent": "And then we give a framework called femmer with an approximation obvious and bonds.",
                    "label": 0
                },
                {
                    "sent": "We conduct experiments on behavior prediction and also validations pending discovery.",
                    "label": 0
                },
                {
                    "sent": "OK, that's fine.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So thank you for listening.",
                    "label": 0
                }
            ]
        }
    }
}