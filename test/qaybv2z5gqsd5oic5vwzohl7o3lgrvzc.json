{
    "id": "qaybv2z5gqsd5oic5vwzohl7o3lgrvzc",
    "title": "Tree Based Ensemble Models Regularization by Convex Optimization",
    "info": {
        "author": [
            "Bertrand Cornelusse, University of Li\u00e8ge"
        ],
        "published": "Jan. 19, 2010",
        "recorded": "December 2009",
        "category": [
            "Top->Computer Science->Optimization Methods",
            "Top->Computer Science->Machine Learning->Ensemble Methods"
        ]
    },
    "url": "http://videolectures.net/nipsworkshops09_cornelusse_tbe/",
    "segmentation": [
        [
            "Do some work we've done on how to regularize tree based unstable models using some convex optimization formulations.",
            "So this is some joint work with.",
            "Can I get an with Uncle from the University of Georgia?",
            "So in the classical setting of supervised learning, we want to learn a mapping from an input SpaceX to an output space Y using a sample of an observations of XY pairs and.",
            "However, sometimes we have some.",
            "We face some unusual instances of the problem.",
            "For example in survival analysis we have.",
            "In addition to this sample we have.",
            "Points for which we only know a lower bound on the output value.",
            "And.",
            "Another example is in semi supervised learning, in which we don't even know this output values.",
            "So what we would like to do is to in the case of sensor data is to try to learn a function F which satisfy F of X greater or equal to Y for this."
        ],
        [
            "Set for this sample of central points, and in the case of semi supervised learning we want to exploit some regularity assumptions about the input output relation to bias the learning of F. So here we propose to a way to incorporate this kind of information in three based on sample meters.",
            "So first start with."
        ],
        [
            "A short review of three.",
            "Addition of regression trees and ensemble methods, and in particular, the way to see."
        ],
        [
            "As a grown up.",
            "So one way to induce a single regression tree from training sample here recursively his training example.",
            "You some tests on the input feature.",
            "In order to reduce the empirical loss as quickly as possible cases, a greedy algorithm and.",
            "In the case of a quadratic loss, we will choose the input feature and the test threshold so as to maximize.",
            "The decrease of variance between.",
            "The sample which is attached to this node and the sum of the variances of the two samples resulting of this test.",
            "And once.",
            "We have met a stopping condition.",
            "We have to attach some values to the leave.",
            "Anne.",
            "Once more indicative of quadratic loss, the best value to assign is the average of the.",
            "Output values of the object reaching one particular leave leave.",
            "So you are a bit of notation.",
            "If L is a number of leaves in the tree, an LG fix is an indicator function which is equal to 1 if X, which is leave jayanne 0 otherwise, and if there is a number of objects."
        ],
        [
            "Reaching leave J then we can compute the label assigned to each leaf using this formula.",
            "Ann, well, this is justified too.",
            "To show you that regression tree assigns some constant values to partitions of the input space.",
            "And using the notation that I I've just introduced, we can compute the prediction of the tree."
        ],
        [
            "By summing over over leaves.",
            "The value assigned to these leaves times vindictive indicator function of this need.",
            "Another alternative you to see to see that is to.",
            "To see that the tree structure defines a mapping from the input space to space of the leaves.",
            "Mapping, which I will call verify.",
            "Fireworks and if we can also from this from this mapping we can define a kernel between two input space observations, which is the dot product of this input space observation in.",
            "The feature space induced by the tree.",
            "And then we can predict value using sample outputs.",
            "Values and kernel evaluations.",
            "Then ensemble methods have been introduced to improve the accuracy of regression trees, an.",
            "What they do is they grow M Percher version imperative trees and combine the outputs in a given way, and this is shown to improve the accuracy by decreasing the variance of single trees.",
            "But it also destroys the interpretability of single regression tree.",
            "So as I did for a single regression trees, we can also define the mapping."
        ],
        [
            "Which is for the N symbol, which is the concatenation of.",
            "The mappings of all the trees.",
            "Waited by.",
            "Sum of values W. Anne.",
            "Then define the kernel which is once more the dot product in the feature space induced by the mapping capital file.",
            "And then we can use.",
            "Sample output values and kernel evaluations to compute the prediction of the ensemble.",
            "Or we can use.",
            "Sum over all the."
        ],
        [
            "Of the tree.",
            "So now I'll explain our simple scheme to regularize this.",
            "If you can sample models."
        ],
        [
            "So we chose not to modify the tree induction algorithm so we don't modify the structure of the tree, but we have two ways to modify a prediction.",
            "The first one is.",
            "Do a.",
            "Modify the.",
            "Value which is assigned to each leaf using a variable Delta Z and the second one is to modify.",
            "The outputs of training sample if we have reasons to believe that they may be corrupted by noise.",
            "So this is a more global effect since it affects all the trees."
        ],
        [
            "Assemble and here is the problems that we proposed to solve.",
            "Top ten, somebody 5 modified version of the trees of the ensemble.",
            "So Ky plus KL Delta V is.",
            "The prediction of the corrective model.",
            "Here, why is the vector of sample outputs that LK&L are respectively the gram matrix of the kernel defined by the tree over the training sample, and L is up to some normalizations and matrix partitioning the input space.",
            "So.",
            "As I mentioned, K&L are not fixed because we don't modify the structure of the tree.",
            "And if.",
            "The objective function capital Omega is chosen."
        ],
        [
            "Completely new measures.",
            "The training sample error of the corrected model.",
            "An capital Omega also allows to.",
            "Express different compromises between the regularization term.",
            "And the last line is.",
            "Indeed, the way that we have to introduce a new information to.",
            "Regularize the model, so C is just the physical sets.",
            "Of all the constraints that we can add to the problem.",
            "So the problem is."
        ],
        [
            "+2 and variables too, and linear constraints, plus the constraint defining C and as long as the objective function ANSI remain convex, other problems remains convex."
        ],
        [
            "And we have two applications to illustrate this.",
            "The first is.",
            "Pencil data how in addition to."
        ],
        [
            "Classical training sample.",
            "We see points for which we know only a lower lower bound on the output value and we decide.",
            "This information is incorporated into problem by the last constraint.",
            "In which you see measures.",
            "The error on the sensor points and it measures on the error.",
            "When the corrected model.",
            "Predicts a value which is too low.",
            "So this.",
            "These variables are penalized in the objective function as well as error of the model on the training sample and the questions that we make to the model."
        ],
        [
            "And there are some results we obtain on four data sets of the R package on survival survival analysis.",
            "So we compared our formulation.",
            "23 authors, three other models.",
            "The first one.",
            "It is a. Uptain with an algorithm to build ensemble of trees.",
            "And which uses only the uncensored part of the data to grow this model, each star is using the same algorithm but also, but if.",
            "The model is built using the sensor data in addition to the uncensored ones to compute the model and the uncensored data is a sensor data.",
            "It is considered as uncensored.",
            "And.",
            "The fourth model is.",
            "I support vector regression algorithm which is dedicated to sensor data.",
            "And our model is the third, the third one, and corresponds to the regularization of the first model.",
            "So on the first data set which contains 7% of sensor data, we see no clear differences between all the formulations between all the models on the 3rd.",
            "On the second model we see a small improvement of the second and third models.",
            "On the 3rd I said this is a bit amplified.",
            "This phenomenon is a bit amplified, another for that asset where we have a proportion of 86% of sensor data.",
            "Our formulation yields the best of the best results.",
            "And.",
            "A second application."
        ],
        [
            "Of this work is for example in semi supervised learning so.",
            "If axis the matrix.",
            "Gathering all of our input observations an WHI if?",
            "Associated output, so here L denotes the label label.",
            "Part of the data and you, you know the unlabeled part.",
            "Then we arbitrarily.",
            "We don't know why mu, so we set it to zero and we would like to.",
            "Compute this, see this labels using our formulation.",
            "So we introduce a vector of variables Delta, Y and we also set.",
            "Delta Y Delta 0.",
            "Because we this is not mandatory, but if there is no noise on the input that are we, there is no need to compute the Delta Y for this spot.",
            "And then we try to label innovations.",
            "Ex knew why?",
            "While minimizing the training sample error which is written here and the term.",
            "Which aims at predicting.",
            "Close very close values for objects whose inputs are closed according to a graph, and the graph is provided here by its operation L. So we have not yet results for for this part, so I will come to the conclusion.",
            "So we've proposed a generic way to extend."
        ],
        [
            "Tree based on several methods to central programs and semi supervised problem and but we can.",
            "We could use other kinds of prior information too."
        ],
        [
            "Solarize the model.",
            "We probably propose the convex formulation of.",
            "Of this algorithm.",
            "And we propose to correct two ways to correct the model.",
            "For the first one is to.",
            "Modify sample outputs using vector that Delta, Y and the second one is to directly add biases to the leaves of the tree.",
            "How the first experiment showed some satisfying results and us this approach was originally motivated by particular practical application.",
            "We would like to validate it on practical problems and also to validate it on all the test sets on other data sets and we would like maybe who tried to incorporate regularization in the tree induction process.",
            "Thank you for your attention.",
            "Yeah.",
            "OK. Yeah.",
            "This one.",
            "It depends on the algorithm which is used to build some sample here.",
            "Each model.",
            "In fact these W's are obtained by.",
            "I don't modify them in this algorithm.",
            "These are obtained by using the ensemble.",
            "Meet and then sample.",
            "Algorithm, for example random forests or things like or boosting or.",
            "So I don't.",
            "I don't act on these variables in this problem, but it may be a good idea to do so.",
            "Yeah.",
            "Yeah.",
            "Add one more.",
            "Oh, I don't know.",
            "Maybe?",
            "I have no I've not seen about this.",
            "Yeah, maybe.",
            "Yes, it would be possible.",
            "Let's take the speaker again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Do some work we've done on how to regularize tree based unstable models using some convex optimization formulations.",
                    "label": 1
                },
                {
                    "sent": "So this is some joint work with.",
                    "label": 0
                },
                {
                    "sent": "Can I get an with Uncle from the University of Georgia?",
                    "label": 0
                },
                {
                    "sent": "So in the classical setting of supervised learning, we want to learn a mapping from an input SpaceX to an output space Y using a sample of an observations of XY pairs and.",
                    "label": 0
                },
                {
                    "sent": "However, sometimes we have some.",
                    "label": 0
                },
                {
                    "sent": "We face some unusual instances of the problem.",
                    "label": 0
                },
                {
                    "sent": "For example in survival analysis we have.",
                    "label": 0
                },
                {
                    "sent": "In addition to this sample we have.",
                    "label": 0
                },
                {
                    "sent": "Points for which we only know a lower bound on the output value.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Another example is in semi supervised learning, in which we don't even know this output values.",
                    "label": 0
                },
                {
                    "sent": "So what we would like to do is to in the case of sensor data is to try to learn a function F which satisfy F of X greater or equal to Y for this.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Set for this sample of central points, and in the case of semi supervised learning we want to exploit some regularity assumptions about the input output relation to bias the learning of F. So here we propose to a way to incorporate this kind of information in three based on sample meters.",
                    "label": 0
                },
                {
                    "sent": "So first start with.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A short review of three.",
                    "label": 0
                },
                {
                    "sent": "Addition of regression trees and ensemble methods, and in particular, the way to see.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As a grown up.",
                    "label": 0
                },
                {
                    "sent": "So one way to induce a single regression tree from training sample here recursively his training example.",
                    "label": 1
                },
                {
                    "sent": "You some tests on the input feature.",
                    "label": 0
                },
                {
                    "sent": "In order to reduce the empirical loss as quickly as possible cases, a greedy algorithm and.",
                    "label": 1
                },
                {
                    "sent": "In the case of a quadratic loss, we will choose the input feature and the test threshold so as to maximize.",
                    "label": 0
                },
                {
                    "sent": "The decrease of variance between.",
                    "label": 0
                },
                {
                    "sent": "The sample which is attached to this node and the sum of the variances of the two samples resulting of this test.",
                    "label": 0
                },
                {
                    "sent": "And once.",
                    "label": 0
                },
                {
                    "sent": "We have met a stopping condition.",
                    "label": 0
                },
                {
                    "sent": "We have to attach some values to the leave.",
                    "label": 1
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "Once more indicative of quadratic loss, the best value to assign is the average of the.",
                    "label": 0
                },
                {
                    "sent": "Output values of the object reaching one particular leave leave.",
                    "label": 0
                },
                {
                    "sent": "So you are a bit of notation.",
                    "label": 0
                },
                {
                    "sent": "If L is a number of leaves in the tree, an LG fix is an indicator function which is equal to 1 if X, which is leave jayanne 0 otherwise, and if there is a number of objects.",
                    "label": 1
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Reaching leave J then we can compute the label assigned to each leaf using this formula.",
                    "label": 0
                },
                {
                    "sent": "Ann, well, this is justified too.",
                    "label": 0
                },
                {
                    "sent": "To show you that regression tree assigns some constant values to partitions of the input space.",
                    "label": 1
                },
                {
                    "sent": "And using the notation that I I've just introduced, we can compute the prediction of the tree.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "By summing over over leaves.",
                    "label": 0
                },
                {
                    "sent": "The value assigned to these leaves times vindictive indicator function of this need.",
                    "label": 0
                },
                {
                    "sent": "Another alternative you to see to see that is to.",
                    "label": 0
                },
                {
                    "sent": "To see that the tree structure defines a mapping from the input space to space of the leaves.",
                    "label": 1
                },
                {
                    "sent": "Mapping, which I will call verify.",
                    "label": 0
                },
                {
                    "sent": "Fireworks and if we can also from this from this mapping we can define a kernel between two input space observations, which is the dot product of this input space observation in.",
                    "label": 0
                },
                {
                    "sent": "The feature space induced by the tree.",
                    "label": 0
                },
                {
                    "sent": "And then we can predict value using sample outputs.",
                    "label": 0
                },
                {
                    "sent": "Values and kernel evaluations.",
                    "label": 0
                },
                {
                    "sent": "Then ensemble methods have been introduced to improve the accuracy of regression trees, an.",
                    "label": 0
                },
                {
                    "sent": "What they do is they grow M Percher version imperative trees and combine the outputs in a given way, and this is shown to improve the accuracy by decreasing the variance of single trees.",
                    "label": 0
                },
                {
                    "sent": "But it also destroys the interpretability of single regression tree.",
                    "label": 0
                },
                {
                    "sent": "So as I did for a single regression trees, we can also define the mapping.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which is for the N symbol, which is the concatenation of.",
                    "label": 0
                },
                {
                    "sent": "The mappings of all the trees.",
                    "label": 0
                },
                {
                    "sent": "Waited by.",
                    "label": 0
                },
                {
                    "sent": "Sum of values W. Anne.",
                    "label": 0
                },
                {
                    "sent": "Then define the kernel which is once more the dot product in the feature space induced by the mapping capital file.",
                    "label": 0
                },
                {
                    "sent": "And then we can use.",
                    "label": 0
                },
                {
                    "sent": "Sample output values and kernel evaluations to compute the prediction of the ensemble.",
                    "label": 0
                },
                {
                    "sent": "Or we can use.",
                    "label": 0
                },
                {
                    "sent": "Sum over all the.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of the tree.",
                    "label": 0
                },
                {
                    "sent": "So now I'll explain our simple scheme to regularize this.",
                    "label": 0
                },
                {
                    "sent": "If you can sample models.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we chose not to modify the tree induction algorithm so we don't modify the structure of the tree, but we have two ways to modify a prediction.",
                    "label": 0
                },
                {
                    "sent": "The first one is.",
                    "label": 0
                },
                {
                    "sent": "Do a.",
                    "label": 0
                },
                {
                    "sent": "Modify the.",
                    "label": 0
                },
                {
                    "sent": "Value which is assigned to each leaf using a variable Delta Z and the second one is to modify.",
                    "label": 0
                },
                {
                    "sent": "The outputs of training sample if we have reasons to believe that they may be corrupted by noise.",
                    "label": 0
                },
                {
                    "sent": "So this is a more global effect since it affects all the trees.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Assemble and here is the problems that we proposed to solve.",
                    "label": 0
                },
                {
                    "sent": "Top ten, somebody 5 modified version of the trees of the ensemble.",
                    "label": 0
                },
                {
                    "sent": "So Ky plus KL Delta V is.",
                    "label": 0
                },
                {
                    "sent": "The prediction of the corrective model.",
                    "label": 0
                },
                {
                    "sent": "Here, why is the vector of sample outputs that LK&L are respectively the gram matrix of the kernel defined by the tree over the training sample, and L is up to some normalizations and matrix partitioning the input space.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "As I mentioned, K&L are not fixed because we don't modify the structure of the tree.",
                    "label": 0
                },
                {
                    "sent": "And if.",
                    "label": 0
                },
                {
                    "sent": "The objective function capital Omega is chosen.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Completely new measures.",
                    "label": 0
                },
                {
                    "sent": "The training sample error of the corrected model.",
                    "label": 1
                },
                {
                    "sent": "An capital Omega also allows to.",
                    "label": 1
                },
                {
                    "sent": "Express different compromises between the regularization term.",
                    "label": 0
                },
                {
                    "sent": "And the last line is.",
                    "label": 0
                },
                {
                    "sent": "Indeed, the way that we have to introduce a new information to.",
                    "label": 0
                },
                {
                    "sent": "Regularize the model, so C is just the physical sets.",
                    "label": 0
                },
                {
                    "sent": "Of all the constraints that we can add to the problem.",
                    "label": 0
                },
                {
                    "sent": "So the problem is.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "+2 and variables too, and linear constraints, plus the constraint defining C and as long as the objective function ANSI remain convex, other problems remains convex.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we have two applications to illustrate this.",
                    "label": 0
                },
                {
                    "sent": "The first is.",
                    "label": 0
                },
                {
                    "sent": "Pencil data how in addition to.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Classical training sample.",
                    "label": 0
                },
                {
                    "sent": "We see points for which we know only a lower lower bound on the output value and we decide.",
                    "label": 1
                },
                {
                    "sent": "This information is incorporated into problem by the last constraint.",
                    "label": 0
                },
                {
                    "sent": "In which you see measures.",
                    "label": 0
                },
                {
                    "sent": "The error on the sensor points and it measures on the error.",
                    "label": 0
                },
                {
                    "sent": "When the corrected model.",
                    "label": 0
                },
                {
                    "sent": "Predicts a value which is too low.",
                    "label": 0
                },
                {
                    "sent": "So this.",
                    "label": 0
                },
                {
                    "sent": "These variables are penalized in the objective function as well as error of the model on the training sample and the questions that we make to the model.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And there are some results we obtain on four data sets of the R package on survival survival analysis.",
                    "label": 1
                },
                {
                    "sent": "So we compared our formulation.",
                    "label": 0
                },
                {
                    "sent": "23 authors, three other models.",
                    "label": 0
                },
                {
                    "sent": "The first one.",
                    "label": 0
                },
                {
                    "sent": "It is a. Uptain with an algorithm to build ensemble of trees.",
                    "label": 0
                },
                {
                    "sent": "And which uses only the uncensored part of the data to grow this model, each star is using the same algorithm but also, but if.",
                    "label": 0
                },
                {
                    "sent": "The model is built using the sensor data in addition to the uncensored ones to compute the model and the uncensored data is a sensor data.",
                    "label": 0
                },
                {
                    "sent": "It is considered as uncensored.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "The fourth model is.",
                    "label": 0
                },
                {
                    "sent": "I support vector regression algorithm which is dedicated to sensor data.",
                    "label": 0
                },
                {
                    "sent": "And our model is the third, the third one, and corresponds to the regularization of the first model.",
                    "label": 0
                },
                {
                    "sent": "So on the first data set which contains 7% of sensor data, we see no clear differences between all the formulations between all the models on the 3rd.",
                    "label": 0
                },
                {
                    "sent": "On the second model we see a small improvement of the second and third models.",
                    "label": 0
                },
                {
                    "sent": "On the 3rd I said this is a bit amplified.",
                    "label": 0
                },
                {
                    "sent": "This phenomenon is a bit amplified, another for that asset where we have a proportion of 86% of sensor data.",
                    "label": 0
                },
                {
                    "sent": "Our formulation yields the best of the best results.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "A second application.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Of this work is for example in semi supervised learning so.",
                    "label": 0
                },
                {
                    "sent": "If axis the matrix.",
                    "label": 0
                },
                {
                    "sent": "Gathering all of our input observations an WHI if?",
                    "label": 0
                },
                {
                    "sent": "Associated output, so here L denotes the label label.",
                    "label": 0
                },
                {
                    "sent": "Part of the data and you, you know the unlabeled part.",
                    "label": 0
                },
                {
                    "sent": "Then we arbitrarily.",
                    "label": 0
                },
                {
                    "sent": "We don't know why mu, so we set it to zero and we would like to.",
                    "label": 0
                },
                {
                    "sent": "Compute this, see this labels using our formulation.",
                    "label": 0
                },
                {
                    "sent": "So we introduce a vector of variables Delta, Y and we also set.",
                    "label": 0
                },
                {
                    "sent": "Delta Y Delta 0.",
                    "label": 0
                },
                {
                    "sent": "Because we this is not mandatory, but if there is no noise on the input that are we, there is no need to compute the Delta Y for this spot.",
                    "label": 0
                },
                {
                    "sent": "And then we try to label innovations.",
                    "label": 0
                },
                {
                    "sent": "Ex knew why?",
                    "label": 0
                },
                {
                    "sent": "While minimizing the training sample error which is written here and the term.",
                    "label": 1
                },
                {
                    "sent": "Which aims at predicting.",
                    "label": 0
                },
                {
                    "sent": "Close very close values for objects whose inputs are closed according to a graph, and the graph is provided here by its operation L. So we have not yet results for for this part, so I will come to the conclusion.",
                    "label": 1
                },
                {
                    "sent": "So we've proposed a generic way to extend.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Tree based on several methods to central programs and semi supervised problem and but we can.",
                    "label": 0
                },
                {
                    "sent": "We could use other kinds of prior information too.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Solarize the model.",
                    "label": 0
                },
                {
                    "sent": "We probably propose the convex formulation of.",
                    "label": 0
                },
                {
                    "sent": "Of this algorithm.",
                    "label": 0
                },
                {
                    "sent": "And we propose to correct two ways to correct the model.",
                    "label": 0
                },
                {
                    "sent": "For the first one is to.",
                    "label": 0
                },
                {
                    "sent": "Modify sample outputs using vector that Delta, Y and the second one is to directly add biases to the leaves of the tree.",
                    "label": 0
                },
                {
                    "sent": "How the first experiment showed some satisfying results and us this approach was originally motivated by particular practical application.",
                    "label": 0
                },
                {
                    "sent": "We would like to validate it on practical problems and also to validate it on all the test sets on other data sets and we would like maybe who tried to incorporate regularization in the tree induction process.",
                    "label": 1
                },
                {
                    "sent": "Thank you for your attention.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "OK. Yeah.",
                    "label": 0
                },
                {
                    "sent": "This one.",
                    "label": 0
                },
                {
                    "sent": "It depends on the algorithm which is used to build some sample here.",
                    "label": 0
                },
                {
                    "sent": "Each model.",
                    "label": 0
                },
                {
                    "sent": "In fact these W's are obtained by.",
                    "label": 0
                },
                {
                    "sent": "I don't modify them in this algorithm.",
                    "label": 0
                },
                {
                    "sent": "These are obtained by using the ensemble.",
                    "label": 0
                },
                {
                    "sent": "Meet and then sample.",
                    "label": 0
                },
                {
                    "sent": "Algorithm, for example random forests or things like or boosting or.",
                    "label": 0
                },
                {
                    "sent": "So I don't.",
                    "label": 0
                },
                {
                    "sent": "I don't act on these variables in this problem, but it may be a good idea to do so.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Add one more.",
                    "label": 0
                },
                {
                    "sent": "Oh, I don't know.",
                    "label": 0
                },
                {
                    "sent": "Maybe?",
                    "label": 0
                },
                {
                    "sent": "I have no I've not seen about this.",
                    "label": 0
                },
                {
                    "sent": "Yeah, maybe.",
                    "label": 0
                },
                {
                    "sent": "Yes, it would be possible.",
                    "label": 0
                },
                {
                    "sent": "Let's take the speaker again.",
                    "label": 0
                }
            ]
        }
    }
}