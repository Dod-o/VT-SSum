{
    "id": "3om7kirbeipglmhqcpgsf4a42v3byqwf",
    "title": "Learning to Combine Distances for Complex Representations",
    "info": {
        "author": [
            "Adam Woznica, University of Geneva"
        ],
        "published": "June 23, 2007",
        "recorded": "June 2007",
        "category": [
            "Top->Computer Science->Machine Learning->Structured Data",
            "Top->Computer Science->Machine Learning->Structured Output",
            "Top->Computer Science->Machine Learning->Instance-based Learning"
        ]
    },
    "url": "http://videolectures.net/icml07_woznica_lcdf/",
    "segmentation": [
        [
            "Salanter Department of computer science.",
            "So.",
            "Sorry.",
            "There is no by Earth, no microphone at this one.",
            "OK, OK, OK, so I will be talking today about learning how to combine distances for complex representations.",
            "A.",
            "Does it work now?"
        ],
        [
            "So this is the motivation of my of my work.",
            "Usually K nearest neighbor algorithm is a good choice for learning.",
            "But I do.",
            "Sorry.",
            "The red one.",
            "OK, usually Canaan is a good choice for the as a learning algorithm because it has a good synthetical behavior and can be adapted for incremental learning.",
            "And it has a nice representations.",
            "But when we try to apply again in a complex domain, there are two problems.",
            "First problem is that usually it's hard to represent complex data, for example.",
            "Graphs can be represented as a set of trees, set of works, set of cyclic patterns, set of any other substructures, and second of all.",
            "Let's assume that we have this representation of complex objects.",
            "Then it's difficult to define the distance on this complex objects.",
            "So for example, let's assume we have representation based on sets of trees.",
            "Then we can apply any set distance on this representation.",
            "So it's very difficult to know appear which representation is good and which distance measure should be applied on this representation.",
            "So in this work I will try to give an algorithm which would.",
            "Automatically combine different representations of complex objects and different.",
            "Distance is on applied on this representation."
        ],
        [
            "So this is the outline of my talk and the first I would define how I combine different distances and then I will define different methods.",
            "How which would enable to lend the combinations and methods are straightforward extension of well known networks from metric learning.",
            "So in this work I particularly focus on the exact method McMillan, NCA.",
            "Of course I will mention later, but any other methods basically.",
            "Most of the other methods can be also applied in this settings, and then I will talk a bit about the regularization and I will provide some experimental results and I will conclude my work with some future directions."
        ],
        [
            "So the.",
            "Formulation of this combination is a straightforward one.",
            "It's you can consider.",
            "This is straightforward extension of Mahalanobis distance.",
            "So the main difference is that in distance you have a vector of real numbers and you define the parameters are defined in the form of positive semidefinite matrix.",
            "And here I assume that I have a vector of of complex subparts of complex objects, so in particular.",
            "Each of the subparts it's in, the in the SpaceX L when the space Excel can be spaced.",
            "For example, set of trees, set of works, set of cyclic patterns.",
            "When we consider graphs.",
            "And we assume that on each of the.",
            "Complex the decomposition we define as a distance measure and the quadratic combination of distance distance measure is defined as following.",
            "It's a, it's a quadratic form of the vectors of distances, and of course this can be represent represent arise by by using the decomposition of matrix A by W. So we always know that when this is something positive definite, we can always do it.",
            "And as I mentioned, this is straightforward extension of Mahalanobis distance so.",
            "When we want to obtain malanaphy distance, so each each of the Excel should be real number and each of the distance DL.",
            "It's a.",
            "It's an absolute value of difference of corresponding numbers.",
            "OK, so this is how I define the combination of distances."
        ],
        [
            "So in this work.",
            "The information that the knowledge about.",
            "All the metrics are based on the equivalent relations, in particular in the classification settings that I mean, straightforward.",
            "To do it you take, you define two sets as in D&S are all the parts which are in the same class, and they are all the pairs which are in different classes.",
            "And we define it.",
            "Virginal definition of the of the distance combination algorithm is defined as the following optimization task.",
            "When I have a differential function F which depends on the matrix that which is a or W as defined before.",
            "And this optimization problem is constraints.",
            "For example, when I put a ZI have to make sure that I is positive semidefinite.",
            "Of course it can be other constraint as well."
        ],
        [
            "So in this work we didn't define a new algorithm, we just exploit existing algorithm for learning distance measure over standard vectorial data and we exploit as I mentioned before, three different associations of this framework, seeing McMillan, NCA, of course, any other algorithm which explicit depends on this equivalence constraints as and can be easily, I mean straightforward, extended in our framework.",
            "And.",
            "I have to mention that I use conjugate gradients, all my experiments, and in order to be sure that the Matrix A is positive semidefinite, if I reprima tries it.",
            "According to a, I use the iterative projection approach."
        ],
        [
            "So I don't know whether you are familiar with the existing methods for a metric learning, but I will just briefly, I mean present them.",
            "The first method, the first method method is exceeding methods and the objective the overall objective, the the thing we want to make sure of is that point in the same class are together as far as close as possible, but in order I mean if we if we is our only objective is that then?",
            "I mean, the matrix will be 0, so we have to be sure that the matrix is not zero, so this is the following constraint that elements from different classes are are far apart.",
            "In some sense it's easy to show that this optimization problem is convex, and so these are the implicit assumption in this method is that.",
            "Does in each of the class are former compact connected cluster?",
            "And in particular, we have data with multimodal distribution.",
            "This cost function will be heavily.",
            "The objective function will be heavily penalized."
        ],
        [
            "For the second method is maximally collapsing metric learning and the main idea is to collapse points in the same class to a single point, which the points will be infinitely far apart from points of other classes, and it's based on the.",
            "The underlying idea is that we have to distribution.",
            "One is our distribution which is the softmax.",
            "The.",
            "Distribution and the ideal distribution can be shown to be the following that it's a conditional distribution that.",
            "If I take 2 pairs of points, there is a like.",
            "Bumpy tile distribution is that.",
            "I get 4 points in the same class.",
            "There is one probability is one that they are, so it's easy to show that this optimization problem if we want to.",
            "You want to keep this tool distribution that's as close as possible, so in our work we use carbon, a callback divergance, and it's easy to show that it's convex, and it's not parametric, but it assumes that the unimodal unimodality.",
            "So in particular, for classes with multimodal distribution it also be penalized."
        ],
        [
            "So the third method is the neighborhood component analysis, it's based.",
            "The objective is to directly optimize continuous version of K and then leave one out error and it's based on the similar ideas and the previous one.",
            "But we have different different distributions you want to keep together so but at the end we do.",
            "The objective function is the following and it's also to see that is not convex, so we don't know whether it will will get the global optimal and.",
            "In particular, it's not parametric and there is no assumption about the data distribution, so we can apply it for a multimodal distribution as well."
        ],
        [
            "So we don't all the above problems.",
            "There is a four M components, so let's assume that our complex objects are decomposed into M different subparts.",
            "So then we have M ^2 parameters to estimate and this could be problematic in for cases when.",
            "Is large with respect to the number of training part in the in the training data set.",
            "And yeah, we define the there are two methods to solve this problem and the first method is to add the regularised term and in particular for.",
            "For Matrix A, which is positive indefinite, we assume that this is a trace of matrix and for W, which is for business normal and it is to show that this is actually equivalent to this one.",
            "And the the other solution is very simple one.",
            "We simply restrict the matrix A or W to be diagonal so that we limit the number of.",
            "Parameters to estimate from M squared to M."
        ],
        [
            "So we now are experiments.",
            "Anne.",
            "OK, now we're experiments.",
            "We focused on the following problem that we know the representation of complex objects.",
            "In particular, these are sets, and the problem is to combine different distance bill defined on sets.",
            "So in all the distances distances are based on the following idea that we have two sets and we define a mapping.",
            "Between two sets.",
            "So we match points.",
            "Different points between the two sets, and it's our previous work showed that it's in general is very difficult to define this mapping a priority.",
            "So in this world will try to somehow learn this mapping by combining different set distance measures.",
            "And OK, in particular we combine 7 distance measures and all of them are normalized.",
            "This normalization is crucial if you want to Furthermore visualize the results, and we applied for on five different datasets.",
            "So there are two versions of mask that which are example of.",
            "But instance problems, and one would modernize data set, which is the problem, is to classify components.",
            "And the set consists of bounds with two adjacent adjacent atoms.",
            "OK, so we have set of very simple substructures and the next is a D Turpin data set, which is a set is a.",
            "It's a spectrum of.",
            "Uptain spectrum and the points are the elements of the spectrum.",
            "And the last one is a protein fingerprint.",
            "So basically a given protein fingerprint is a set of motives, and motives are defined by the sequences of corresponding constituent proteins.",
            "Yeah, so this is all the details about the experimental setup and we used we cross validated K over over values 139 an in all the experiments used enfocus validation."
        ],
        [
            "So we experimented with.",
            "With the three algorithms defined before and we've experimented with full matrixes and diagonal matrix as well.",
            "And we define two baselines methods.",
            "So the first one is, we call it K&N best, which is obtained by selecting the best set distance measure.",
            "By the cross validated tenfold cross validation, but the performance is obtained on the full data set, so in particular means that this method is optically optimistically biased in the sense that I select the best one after seeing the test data set and the third one is a is a modification of this one, but I select the best set distance, measuring the inner loop with validation.",
            "And when you consider the optimization of a full matrix, is I defined the two different values of the regularization parameter, and in particular for small datasets, small, so small number of of elements with respect to the number of parameters.",
            "So in particular mask data set and mutagenesis data set, we put we put a higher value of Lambda and for other data set we put the lower value of Lambda."
        ],
        [
            "So these are the results and what we can see.",
            "OK, we have our six different methods.",
            "4 /, 5 different datasets and two baseline methods.",
            "So we can see that here is the.",
            "The best set distance measure returned by this method and the blue color corresponds to the value which is statistically better than this one, the second one and the red color corresponds to a method which is statistically better both over this this baseline and the other baseline.",
            "So by looking at this table we can see we can draw two conclusions.",
            "First of all, there is advantage of MCM Allen NCA methods of working methods, and in particular usually there are.",
            "These formatters are never statistically worse than the two baseline methods where asking methods.",
            "Sometimes we get results which are statistically worse.",
            "Anne.",
            "So.",
            "The poor performance of some method can be explained.",
            "On the basis that it's not suited for a multimodal distributions, and in particular for mask.",
            "2 version of mass Converter Genesis.",
            "We know that this is sort of multimodal distribution.",
            "And the.",
            "Then particularly must data set.",
            "We know that negative clause contains any examples which are not labeled as positive.",
            "So in particular, we know that somehow we have positive class surrounded by all the other points which are which have don't have this property encoded in positive cloud.",
            "So in particular also sing method.",
            "The objective function is.",
            "The matter will be heavily penalized and.",
            "We have to know that these two results on the terpenes are the best results in the literature so far."
        ],
        [
            "So the results can be quite nicely visualized by.",
            "And the validation that the goal of the validation is to measure the relative importance of different set distance measures.",
            "And this particular values visualization is for the agonal matrix and we have OK three different methods.",
            "And these are the normalized weights assigned for each of the set distance measure.",
            "And of course, these are seven distances, seven different set distance measures.",
            "The numbers here corresponds to the performance accuracy of KNN algorithm.",
            "When only this set distance measure is used.",
            "And of course, Igrec accesses the relative importance of different set distance measures by taking a look at the elements of the diagonal matrix, right?",
            "So what we can see is that, for example, sync methods assigns a very high importance to rib method, which appears to be very.",
            "I mean, the performance of rib is very poor.",
            "On the other hand, the other methods McMillan Sea tried to combine different.",
            "Set distance measures and by combining them we we saw in the previous slides that the accuracy is better, right?"
        ],
        [
            "So this is the visualization for full matrixes.",
            "And this is in particular for NCA matrix, and we can see that the highest weights are assigned for.",
            "Matching set distance measure Hausdorff said this measure as well as combinations of this measures right.",
            "So here we can see that the even the by if there is no restriction that the matrix A or W it's it's a full matrix.",
            "Then we can somehow make it more general so that it accounts for interactions between different set distance measures."
        ],
        [
            "And also we can reduce the size of the problem by first ranking the first top set distance measures, then sorting them out and selecting for example, the first with the highest coefficients, the two first with the highest coefficients and so on so forth.",
            "So these are for the three different methods over diagonal matrixes, and we have two baselines and we can see that we don't necessarily have to consider all the.",
            "Said distance measures, but it's enough to consider, let's say 5.",
            "Four of them right out of seven.",
            "Because maybe five?",
            "OK, because this difference I guess is statistically significant."
        ],
        [
            "So let me wrap up the work in this work.",
            "I propose a framework which allows to combine different representation of complex objects and different distances defined of the presentations.",
            "And.",
            "I'm it was really straightforward extension of the existing metric methods for learning metrics over a vectorial datasets.",
            "So the main goal is it was defined the proper way.",
            "Distances and representations were combined.",
            "Anne.",
            "So we we, we show the the utility of this approach in domains where complex object assets and we try to combine different set distance measures.",
            "And it's one of the first according to our best knowledge is one of the first approach is to define distance measures over no victory of data because there are other approaches like kernelized some of the metric learning algorithms analyze.",
            "So in particular you can use kernels of a complex structure which implicitly defines Lance metric in the feature space.",
            "But in the previous work we also saw that this is not the best approach for the complex object 'cause all the kernels where are defined.",
            "On the basis of averaging, so in particular you decompose your complex object into.",
            "Supports an you take into account all the possible supports and for complex objects.",
            "We show it in the previous work that it's not the best approach because most of the substructures will be public.",
            "Relate with the target value.",
            "And in the future work, of course we can.",
            "Check the performance of other metric learning approaches.",
            "We can experiment with local methods, which would, I guess, increase the performance of the of the methods and we can also play with other regularization strategies like the one used in LA.",
            "So when I regularize the sort of L1 norm of the matrix, so this would cause it would result in a very sparse matrix of weights, so only few.",
            "Set distance will be combined."
        ],
        [
            "OK, thank you.",
            "Maybe I missed.",
            "Combining distance versus one more distance measure.",
            "And when you look at NCA for that matter.",
            "And you take me combination.",
            "You want this matrix W you projected to some Julia projection to some space space.",
            "This is a well find me information such that nearby points like.",
            "Posted one.",
            "Combining the.",
            "Are you wearing different WS or I?",
            "I'll end the WS or a switch are defined.",
            "The combination of this different distances so you can consider OK. One interpretation of NCA on the MCML is that you project your points to some feature space and then you apply standard Euclidean distance.",
            "Here it's not possible to do it because.",
            "Because we consider sort of different distances, right?",
            "We don't.",
            "We don't consider this kleidion.",
            "Euclidean space anymore, so there is no such interpretation.",
            "But on the other hand you can consider McMillan NCA as a combination of very simple distances, which are.",
            "Absolute value of differences of different elements and you want to combine this one so this sort of different representations of metric learning algorithm?",
            "OK.",
            "Try to keep.",
            "Same classes compactly together as possible behaviors.",
            "They wouldn't really care right?",
            "In one years neighborhood very spread out class and the class could spiral around each other and one year doesn't care.",
            "So I'm wondering if there's a way to find a way to optimize the distance function that would match the assumptions, opinions, neighborhood better thought about that.",
            "Or if you think this is actually what actually the NCA algorithm directly optimizes the Canaan objective because it's minimizes the live without error of Canaan.",
            "So we just, you know, the objective of this work is not to come up with some new objective function which was, which will be the better.",
            "But to exploit existing objective functions.",
            "So this sense.",
            "I mean we tried, we only saw what happened.",
            "We exploit existing algorithm."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Salanter Department of computer science.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "There is no by Earth, no microphone at this one.",
                    "label": 0
                },
                {
                    "sent": "OK, OK, OK, so I will be talking today about learning how to combine distances for complex representations.",
                    "label": 1
                },
                {
                    "sent": "A.",
                    "label": 0
                },
                {
                    "sent": "Does it work now?",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is the motivation of my of my work.",
                    "label": 0
                },
                {
                    "sent": "Usually K nearest neighbor algorithm is a good choice for learning.",
                    "label": 0
                },
                {
                    "sent": "But I do.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "The red one.",
                    "label": 0
                },
                {
                    "sent": "OK, usually Canaan is a good choice for the as a learning algorithm because it has a good synthetical behavior and can be adapted for incremental learning.",
                    "label": 0
                },
                {
                    "sent": "And it has a nice representations.",
                    "label": 0
                },
                {
                    "sent": "But when we try to apply again in a complex domain, there are two problems.",
                    "label": 0
                },
                {
                    "sent": "First problem is that usually it's hard to represent complex data, for example.",
                    "label": 1
                },
                {
                    "sent": "Graphs can be represented as a set of trees, set of works, set of cyclic patterns, set of any other substructures, and second of all.",
                    "label": 0
                },
                {
                    "sent": "Let's assume that we have this representation of complex objects.",
                    "label": 1
                },
                {
                    "sent": "Then it's difficult to define the distance on this complex objects.",
                    "label": 0
                },
                {
                    "sent": "So for example, let's assume we have representation based on sets of trees.",
                    "label": 0
                },
                {
                    "sent": "Then we can apply any set distance on this representation.",
                    "label": 0
                },
                {
                    "sent": "So it's very difficult to know appear which representation is good and which distance measure should be applied on this representation.",
                    "label": 0
                },
                {
                    "sent": "So in this work I will try to give an algorithm which would.",
                    "label": 0
                },
                {
                    "sent": "Automatically combine different representations of complex objects and different.",
                    "label": 1
                },
                {
                    "sent": "Distance is on applied on this representation.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is the outline of my talk and the first I would define how I combine different distances and then I will define different methods.",
                    "label": 0
                },
                {
                    "sent": "How which would enable to lend the combinations and methods are straightforward extension of well known networks from metric learning.",
                    "label": 0
                },
                {
                    "sent": "So in this work I particularly focus on the exact method McMillan, NCA.",
                    "label": 0
                },
                {
                    "sent": "Of course I will mention later, but any other methods basically.",
                    "label": 0
                },
                {
                    "sent": "Most of the other methods can be also applied in this settings, and then I will talk a bit about the regularization and I will provide some experimental results and I will conclude my work with some future directions.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the.",
                    "label": 0
                },
                {
                    "sent": "Formulation of this combination is a straightforward one.",
                    "label": 1
                },
                {
                    "sent": "It's you can consider.",
                    "label": 0
                },
                {
                    "sent": "This is straightforward extension of Mahalanobis distance.",
                    "label": 0
                },
                {
                    "sent": "So the main difference is that in distance you have a vector of real numbers and you define the parameters are defined in the form of positive semidefinite matrix.",
                    "label": 0
                },
                {
                    "sent": "And here I assume that I have a vector of of complex subparts of complex objects, so in particular.",
                    "label": 1
                },
                {
                    "sent": "Each of the subparts it's in, the in the SpaceX L when the space Excel can be spaced.",
                    "label": 0
                },
                {
                    "sent": "For example, set of trees, set of works, set of cyclic patterns.",
                    "label": 0
                },
                {
                    "sent": "When we consider graphs.",
                    "label": 0
                },
                {
                    "sent": "And we assume that on each of the.",
                    "label": 1
                },
                {
                    "sent": "Complex the decomposition we define as a distance measure and the quadratic combination of distance distance measure is defined as following.",
                    "label": 1
                },
                {
                    "sent": "It's a, it's a quadratic form of the vectors of distances, and of course this can be represent represent arise by by using the decomposition of matrix A by W. So we always know that when this is something positive definite, we can always do it.",
                    "label": 0
                },
                {
                    "sent": "And as I mentioned, this is straightforward extension of Mahalanobis distance so.",
                    "label": 0
                },
                {
                    "sent": "When we want to obtain malanaphy distance, so each each of the Excel should be real number and each of the distance DL.",
                    "label": 0
                },
                {
                    "sent": "It's a.",
                    "label": 0
                },
                {
                    "sent": "It's an absolute value of difference of corresponding numbers.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is how I define the combination of distances.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in this work.",
                    "label": 0
                },
                {
                    "sent": "The information that the knowledge about.",
                    "label": 0
                },
                {
                    "sent": "All the metrics are based on the equivalent relations, in particular in the classification settings that I mean, straightforward.",
                    "label": 1
                },
                {
                    "sent": "To do it you take, you define two sets as in D&S are all the parts which are in the same class, and they are all the pairs which are in different classes.",
                    "label": 0
                },
                {
                    "sent": "And we define it.",
                    "label": 1
                },
                {
                    "sent": "Virginal definition of the of the distance combination algorithm is defined as the following optimization task.",
                    "label": 1
                },
                {
                    "sent": "When I have a differential function F which depends on the matrix that which is a or W as defined before.",
                    "label": 0
                },
                {
                    "sent": "And this optimization problem is constraints.",
                    "label": 0
                },
                {
                    "sent": "For example, when I put a ZI have to make sure that I is positive semidefinite.",
                    "label": 0
                },
                {
                    "sent": "Of course it can be other constraint as well.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in this work we didn't define a new algorithm, we just exploit existing algorithm for learning distance measure over standard vectorial data and we exploit as I mentioned before, three different associations of this framework, seeing McMillan, NCA, of course, any other algorithm which explicit depends on this equivalence constraints as and can be easily, I mean straightforward, extended in our framework.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "I have to mention that I use conjugate gradients, all my experiments, and in order to be sure that the Matrix A is positive semidefinite, if I reprima tries it.",
                    "label": 0
                },
                {
                    "sent": "According to a, I use the iterative projection approach.",
                    "label": 1
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I don't know whether you are familiar with the existing methods for a metric learning, but I will just briefly, I mean present them.",
                    "label": 0
                },
                {
                    "sent": "The first method, the first method method is exceeding methods and the objective the overall objective, the the thing we want to make sure of is that point in the same class are together as far as close as possible, but in order I mean if we if we is our only objective is that then?",
                    "label": 0
                },
                {
                    "sent": "I mean, the matrix will be 0, so we have to be sure that the matrix is not zero, so this is the following constraint that elements from different classes are are far apart.",
                    "label": 0
                },
                {
                    "sent": "In some sense it's easy to show that this optimization problem is convex, and so these are the implicit assumption in this method is that.",
                    "label": 1
                },
                {
                    "sent": "Does in each of the class are former compact connected cluster?",
                    "label": 0
                },
                {
                    "sent": "And in particular, we have data with multimodal distribution.",
                    "label": 1
                },
                {
                    "sent": "This cost function will be heavily.",
                    "label": 0
                },
                {
                    "sent": "The objective function will be heavily penalized.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For the second method is maximally collapsing metric learning and the main idea is to collapse points in the same class to a single point, which the points will be infinitely far apart from points of other classes, and it's based on the.",
                    "label": 1
                },
                {
                    "sent": "The underlying idea is that we have to distribution.",
                    "label": 0
                },
                {
                    "sent": "One is our distribution which is the softmax.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "Distribution and the ideal distribution can be shown to be the following that it's a conditional distribution that.",
                    "label": 0
                },
                {
                    "sent": "If I take 2 pairs of points, there is a like.",
                    "label": 0
                },
                {
                    "sent": "Bumpy tile distribution is that.",
                    "label": 1
                },
                {
                    "sent": "I get 4 points in the same class.",
                    "label": 0
                },
                {
                    "sent": "There is one probability is one that they are, so it's easy to show that this optimization problem if we want to.",
                    "label": 0
                },
                {
                    "sent": "You want to keep this tool distribution that's as close as possible, so in our work we use carbon, a callback divergance, and it's easy to show that it's convex, and it's not parametric, but it assumes that the unimodal unimodality.",
                    "label": 0
                },
                {
                    "sent": "So in particular, for classes with multimodal distribution it also be penalized.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the third method is the neighborhood component analysis, it's based.",
                    "label": 1
                },
                {
                    "sent": "The objective is to directly optimize continuous version of K and then leave one out error and it's based on the similar ideas and the previous one.",
                    "label": 1
                },
                {
                    "sent": "But we have different different distributions you want to keep together so but at the end we do.",
                    "label": 1
                },
                {
                    "sent": "The objective function is the following and it's also to see that is not convex, so we don't know whether it will will get the global optimal and.",
                    "label": 0
                },
                {
                    "sent": "In particular, it's not parametric and there is no assumption about the data distribution, so we can apply it for a multimodal distribution as well.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we don't all the above problems.",
                    "label": 0
                },
                {
                    "sent": "There is a four M components, so let's assume that our complex objects are decomposed into M different subparts.",
                    "label": 0
                },
                {
                    "sent": "So then we have M ^2 parameters to estimate and this could be problematic in for cases when.",
                    "label": 0
                },
                {
                    "sent": "Is large with respect to the number of training part in the in the training data set.",
                    "label": 1
                },
                {
                    "sent": "And yeah, we define the there are two methods to solve this problem and the first method is to add the regularised term and in particular for.",
                    "label": 0
                },
                {
                    "sent": "For Matrix A, which is positive indefinite, we assume that this is a trace of matrix and for W, which is for business normal and it is to show that this is actually equivalent to this one.",
                    "label": 0
                },
                {
                    "sent": "And the the other solution is very simple one.",
                    "label": 1
                },
                {
                    "sent": "We simply restrict the matrix A or W to be diagonal so that we limit the number of.",
                    "label": 0
                },
                {
                    "sent": "Parameters to estimate from M squared to M.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we now are experiments.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "OK, now we're experiments.",
                    "label": 0
                },
                {
                    "sent": "We focused on the following problem that we know the representation of complex objects.",
                    "label": 0
                },
                {
                    "sent": "In particular, these are sets, and the problem is to combine different distance bill defined on sets.",
                    "label": 1
                },
                {
                    "sent": "So in all the distances distances are based on the following idea that we have two sets and we define a mapping.",
                    "label": 0
                },
                {
                    "sent": "Between two sets.",
                    "label": 0
                },
                {
                    "sent": "So we match points.",
                    "label": 0
                },
                {
                    "sent": "Different points between the two sets, and it's our previous work showed that it's in general is very difficult to define this mapping a priority.",
                    "label": 1
                },
                {
                    "sent": "So in this world will try to somehow learn this mapping by combining different set distance measures.",
                    "label": 1
                },
                {
                    "sent": "And OK, in particular we combine 7 distance measures and all of them are normalized.",
                    "label": 1
                },
                {
                    "sent": "This normalization is crucial if you want to Furthermore visualize the results, and we applied for on five different datasets.",
                    "label": 0
                },
                {
                    "sent": "So there are two versions of mask that which are example of.",
                    "label": 0
                },
                {
                    "sent": "But instance problems, and one would modernize data set, which is the problem, is to classify components.",
                    "label": 0
                },
                {
                    "sent": "And the set consists of bounds with two adjacent adjacent atoms.",
                    "label": 0
                },
                {
                    "sent": "OK, so we have set of very simple substructures and the next is a D Turpin data set, which is a set is a.",
                    "label": 0
                },
                {
                    "sent": "It's a spectrum of.",
                    "label": 0
                },
                {
                    "sent": "Uptain spectrum and the points are the elements of the spectrum.",
                    "label": 0
                },
                {
                    "sent": "And the last one is a protein fingerprint.",
                    "label": 0
                },
                {
                    "sent": "So basically a given protein fingerprint is a set of motives, and motives are defined by the sequences of corresponding constituent proteins.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so this is all the details about the experimental setup and we used we cross validated K over over values 139 an in all the experiments used enfocus validation.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we experimented with.",
                    "label": 0
                },
                {
                    "sent": "With the three algorithms defined before and we've experimented with full matrixes and diagonal matrix as well.",
                    "label": 0
                },
                {
                    "sent": "And we define two baselines methods.",
                    "label": 1
                },
                {
                    "sent": "So the first one is, we call it K&N best, which is obtained by selecting the best set distance measure.",
                    "label": 1
                },
                {
                    "sent": "By the cross validated tenfold cross validation, but the performance is obtained on the full data set, so in particular means that this method is optically optimistically biased in the sense that I select the best one after seeing the test data set and the third one is a is a modification of this one, but I select the best set distance, measuring the inner loop with validation.",
                    "label": 1
                },
                {
                    "sent": "And when you consider the optimization of a full matrix, is I defined the two different values of the regularization parameter, and in particular for small datasets, small, so small number of of elements with respect to the number of parameters.",
                    "label": 0
                },
                {
                    "sent": "So in particular mask data set and mutagenesis data set, we put we put a higher value of Lambda and for other data set we put the lower value of Lambda.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So these are the results and what we can see.",
                    "label": 0
                },
                {
                    "sent": "OK, we have our six different methods.",
                    "label": 0
                },
                {
                    "sent": "4 /, 5 different datasets and two baseline methods.",
                    "label": 1
                },
                {
                    "sent": "So we can see that here is the.",
                    "label": 0
                },
                {
                    "sent": "The best set distance measure returned by this method and the blue color corresponds to the value which is statistically better than this one, the second one and the red color corresponds to a method which is statistically better both over this this baseline and the other baseline.",
                    "label": 0
                },
                {
                    "sent": "So by looking at this table we can see we can draw two conclusions.",
                    "label": 0
                },
                {
                    "sent": "First of all, there is advantage of MCM Allen NCA methods of working methods, and in particular usually there are.",
                    "label": 0
                },
                {
                    "sent": "These formatters are never statistically worse than the two baseline methods where asking methods.",
                    "label": 0
                },
                {
                    "sent": "Sometimes we get results which are statistically worse.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The poor performance of some method can be explained.",
                    "label": 1
                },
                {
                    "sent": "On the basis that it's not suited for a multimodal distributions, and in particular for mask.",
                    "label": 1
                },
                {
                    "sent": "2 version of mass Converter Genesis.",
                    "label": 0
                },
                {
                    "sent": "We know that this is sort of multimodal distribution.",
                    "label": 0
                },
                {
                    "sent": "And the.",
                    "label": 0
                },
                {
                    "sent": "Then particularly must data set.",
                    "label": 0
                },
                {
                    "sent": "We know that negative clause contains any examples which are not labeled as positive.",
                    "label": 1
                },
                {
                    "sent": "So in particular, we know that somehow we have positive class surrounded by all the other points which are which have don't have this property encoded in positive cloud.",
                    "label": 0
                },
                {
                    "sent": "So in particular also sing method.",
                    "label": 0
                },
                {
                    "sent": "The objective function is.",
                    "label": 0
                },
                {
                    "sent": "The matter will be heavily penalized and.",
                    "label": 1
                },
                {
                    "sent": "We have to know that these two results on the terpenes are the best results in the literature so far.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the results can be quite nicely visualized by.",
                    "label": 0
                },
                {
                    "sent": "And the validation that the goal of the validation is to measure the relative importance of different set distance measures.",
                    "label": 1
                },
                {
                    "sent": "And this particular values visualization is for the agonal matrix and we have OK three different methods.",
                    "label": 1
                },
                {
                    "sent": "And these are the normalized weights assigned for each of the set distance measure.",
                    "label": 0
                },
                {
                    "sent": "And of course, these are seven distances, seven different set distance measures.",
                    "label": 0
                },
                {
                    "sent": "The numbers here corresponds to the performance accuracy of KNN algorithm.",
                    "label": 0
                },
                {
                    "sent": "When only this set distance measure is used.",
                    "label": 0
                },
                {
                    "sent": "And of course, Igrec accesses the relative importance of different set distance measures by taking a look at the elements of the diagonal matrix, right?",
                    "label": 0
                },
                {
                    "sent": "So what we can see is that, for example, sync methods assigns a very high importance to rib method, which appears to be very.",
                    "label": 0
                },
                {
                    "sent": "I mean, the performance of rib is very poor.",
                    "label": 1
                },
                {
                    "sent": "On the other hand, the other methods McMillan Sea tried to combine different.",
                    "label": 0
                },
                {
                    "sent": "Set distance measures and by combining them we we saw in the previous slides that the accuracy is better, right?",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is the visualization for full matrixes.",
                    "label": 0
                },
                {
                    "sent": "And this is in particular for NCA matrix, and we can see that the highest weights are assigned for.",
                    "label": 0
                },
                {
                    "sent": "Matching set distance measure Hausdorff said this measure as well as combinations of this measures right.",
                    "label": 0
                },
                {
                    "sent": "So here we can see that the even the by if there is no restriction that the matrix A or W it's it's a full matrix.",
                    "label": 0
                },
                {
                    "sent": "Then we can somehow make it more general so that it accounts for interactions between different set distance measures.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And also we can reduce the size of the problem by first ranking the first top set distance measures, then sorting them out and selecting for example, the first with the highest coefficients, the two first with the highest coefficients and so on so forth.",
                    "label": 1
                },
                {
                    "sent": "So these are for the three different methods over diagonal matrixes, and we have two baselines and we can see that we don't necessarily have to consider all the.",
                    "label": 0
                },
                {
                    "sent": "Said distance measures, but it's enough to consider, let's say 5.",
                    "label": 0
                },
                {
                    "sent": "Four of them right out of seven.",
                    "label": 0
                },
                {
                    "sent": "Because maybe five?",
                    "label": 0
                },
                {
                    "sent": "OK, because this difference I guess is statistically significant.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let me wrap up the work in this work.",
                    "label": 0
                },
                {
                    "sent": "I propose a framework which allows to combine different representation of complex objects and different distances defined of the presentations.",
                    "label": 1
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "I'm it was really straightforward extension of the existing metric methods for learning metrics over a vectorial datasets.",
                    "label": 0
                },
                {
                    "sent": "So the main goal is it was defined the proper way.",
                    "label": 0
                },
                {
                    "sent": "Distances and representations were combined.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 1
                },
                {
                    "sent": "So we we, we show the the utility of this approach in domains where complex object assets and we try to combine different set distance measures.",
                    "label": 0
                },
                {
                    "sent": "And it's one of the first according to our best knowledge is one of the first approach is to define distance measures over no victory of data because there are other approaches like kernelized some of the metric learning algorithms analyze.",
                    "label": 0
                },
                {
                    "sent": "So in particular you can use kernels of a complex structure which implicitly defines Lance metric in the feature space.",
                    "label": 0
                },
                {
                    "sent": "But in the previous work we also saw that this is not the best approach for the complex object 'cause all the kernels where are defined.",
                    "label": 0
                },
                {
                    "sent": "On the basis of averaging, so in particular you decompose your complex object into.",
                    "label": 0
                },
                {
                    "sent": "Supports an you take into account all the possible supports and for complex objects.",
                    "label": 0
                },
                {
                    "sent": "We show it in the previous work that it's not the best approach because most of the substructures will be public.",
                    "label": 1
                },
                {
                    "sent": "Relate with the target value.",
                    "label": 1
                },
                {
                    "sent": "And in the future work, of course we can.",
                    "label": 0
                },
                {
                    "sent": "Check the performance of other metric learning approaches.",
                    "label": 0
                },
                {
                    "sent": "We can experiment with local methods, which would, I guess, increase the performance of the of the methods and we can also play with other regularization strategies like the one used in LA.",
                    "label": 0
                },
                {
                    "sent": "So when I regularize the sort of L1 norm of the matrix, so this would cause it would result in a very sparse matrix of weights, so only few.",
                    "label": 0
                },
                {
                    "sent": "Set distance will be combined.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, thank you.",
                    "label": 0
                },
                {
                    "sent": "Maybe I missed.",
                    "label": 0
                },
                {
                    "sent": "Combining distance versus one more distance measure.",
                    "label": 0
                },
                {
                    "sent": "And when you look at NCA for that matter.",
                    "label": 0
                },
                {
                    "sent": "And you take me combination.",
                    "label": 0
                },
                {
                    "sent": "You want this matrix W you projected to some Julia projection to some space space.",
                    "label": 0
                },
                {
                    "sent": "This is a well find me information such that nearby points like.",
                    "label": 0
                },
                {
                    "sent": "Posted one.",
                    "label": 0
                },
                {
                    "sent": "Combining the.",
                    "label": 0
                },
                {
                    "sent": "Are you wearing different WS or I?",
                    "label": 0
                },
                {
                    "sent": "I'll end the WS or a switch are defined.",
                    "label": 0
                },
                {
                    "sent": "The combination of this different distances so you can consider OK. One interpretation of NCA on the MCML is that you project your points to some feature space and then you apply standard Euclidean distance.",
                    "label": 0
                },
                {
                    "sent": "Here it's not possible to do it because.",
                    "label": 0
                },
                {
                    "sent": "Because we consider sort of different distances, right?",
                    "label": 0
                },
                {
                    "sent": "We don't.",
                    "label": 0
                },
                {
                    "sent": "We don't consider this kleidion.",
                    "label": 0
                },
                {
                    "sent": "Euclidean space anymore, so there is no such interpretation.",
                    "label": 0
                },
                {
                    "sent": "But on the other hand you can consider McMillan NCA as a combination of very simple distances, which are.",
                    "label": 0
                },
                {
                    "sent": "Absolute value of differences of different elements and you want to combine this one so this sort of different representations of metric learning algorithm?",
                    "label": 1
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Try to keep.",
                    "label": 0
                },
                {
                    "sent": "Same classes compactly together as possible behaviors.",
                    "label": 0
                },
                {
                    "sent": "They wouldn't really care right?",
                    "label": 0
                },
                {
                    "sent": "In one years neighborhood very spread out class and the class could spiral around each other and one year doesn't care.",
                    "label": 0
                },
                {
                    "sent": "So I'm wondering if there's a way to find a way to optimize the distance function that would match the assumptions, opinions, neighborhood better thought about that.",
                    "label": 0
                },
                {
                    "sent": "Or if you think this is actually what actually the NCA algorithm directly optimizes the Canaan objective because it's minimizes the live without error of Canaan.",
                    "label": 0
                },
                {
                    "sent": "So we just, you know, the objective of this work is not to come up with some new objective function which was, which will be the better.",
                    "label": 0
                },
                {
                    "sent": "But to exploit existing objective functions.",
                    "label": 0
                },
                {
                    "sent": "So this sense.",
                    "label": 0
                },
                {
                    "sent": "I mean we tried, we only saw what happened.",
                    "label": 0
                },
                {
                    "sent": "We exploit existing algorithm.",
                    "label": 0
                }
            ]
        }
    }
}