{
    "id": "ya7jsgv553znqlcqolws4zb66uay4ug3",
    "title": "Dynamic Captioning: Video Accessibility Enhancement for Hearing Impairment",
    "info": {
        "author": [
            "Richang Hong, School of Computing, National University of Singapore"
        ],
        "published": "Feb. 1, 2011",
        "recorded": "October 2010",
        "category": [
            "Top->Computer Science"
        ]
    },
    "url": "http://videolectures.net/acmmm2010_hong_dcv/",
    "segmentation": [
        [
            "So we got a continuing our next contender for the best paper award is Richard Hung, postdoctoral fellow at the National University of Singapore, and he will present his work, dynamic captioning, video Accessibility enhancement for hearing impairment.",
            "Sorry I need to install my laptop.",
            "OK so my my laser cannot reach another Side Story for the audience over there.",
            "Yeah so start start our talk so my name is reaching home from National University of Singapore.",
            "In this presentation I will introduce a work them the dynamical captioning video Accessibility for enhancement.",
            "So my collaborators move on Monday, she streets and Jen and Tyson Shaw."
        ],
        [
            "Today people are consuming more and more videos from the movie, television and."
        ],
        [
            "Ever.",
            "When watching video, three types of information, audio test and view content will be transmitted to audience.",
            "There are about 66 million people suffering from hearing impairment when changing scenario trace, hearing impaired audience, all your information is lost.",
            "Current temperature current captioning techniques can partially activate this.",
            "Commission loss, however, hearing impaired audience tended to focus on either text or via content at one moment.",
            "So the perception of attacks in video content will be weekend.",
            "Next will show more limitations of current captioning techniques."
        ],
        [
            "Let's see this video clip.",
            "There are more than one person involved in the scene.",
            "For hearing impaired audience is difficult to quickly tell who is speaking."
        ],
        [
            "Another example, we see the speaking speed can vary significantly, so the duration of the script presentation will also vary over a wide range.",
            "It brings difficulty for hearing impaired audience to track the caption."
        ],
        [
            "Finally, as we know, the voice information is one of the key factors to reflect human emotion.",
            "The loss of voice volume information certainly degrade their enjoyment in watching video, or these limitations cannot be tackled by current capture."
        ],
        [
            "So tackle this limitation.",
            "We designed three components of script location, script, speech, alignment and voice."
        ],
        [
            "Volume estimation script location is designed to determine the Association between face and script and then determine a region in which the script will be presented."
        ],
        [
            "Scrape the speech.",
            "Alignment aims to temporarily highlights the speech world by."
        ],
        [
            "Word.",
            "Voice volume estimation is used to demonstrate the variation of voice volume."
        ],
        [
            "This independent component comprises the framework of Dynamic caption.",
            "Here we use a dynamic.",
            "Is in contrast to current caption, would define Current caption As Static caption, Since it is simply demonstrated in a fixed region and illustrated statically.",
            "We see our dynamic action is a pure multimedia issue and it can include many multimedia techniques such as face detection, face recognition, script alignment, speech recognition, something like that."
        ],
        [
            "OK, let's talk about the first component of script location.",
            "Before determining a region in which the present the script will be present, we need to determine a region.",
            "OK, we first perform the face detection and then we combine the script clues and the new promotion analysis to directly determine the Association.",
            "For example.",
            "If the frame contains face, a single face with Leap Motion and the script clues indicate she is rose.",
            "However, in more cases we have to resort to face recognition for face recognition.",
            "We can group Lee, we can group continuously detecting faces of a particular person as a face track.",
            "We can directly label some fixed tracks using the recognizer faces by script clues and Leap Motion analysis.",
            "Such labeled fixed track can be used as training data with an employee multitask joined sparse representation model to recognize the unlabeled face tracks in experiments.",
            "Our approach can achieve the accuracy of about 89%."
        ],
        [
            "After establishing the Association between face and script.",
            "We need to detect a region to insert the script here.",
            "Seeing the first analyzed.",
            "We then design a way to temper data based on the identified speaker information.",
            "Finally, we combine this senior see analysis and weight tablet to find an uninteresting region for script.",
            "So far we have accompanied the process of identifying where to put the script and who is speaking."
        ],
        [
            "OK, let's talk about component of script, speech, alignment.",
            "This component aims to temporally matched each piece of script with the with the corresponding speech segment.",
            "Here we employ the open source tools things to recognize the speech.",
            "During alignment.",
            "We started from the words matched with high confidence loan as hypothesized world.",
            "We then employ dynamic programming to iteratively find more mixed words until all the words are aligned in experiment.",
            "This approach can achieve the accuracy of about 90%."
        ],
        [
            "How is the voice volume estimation?",
            "For this part, we simply compute the power of the audio singular in a small local window.",
            "The size of the window is set to certain millisecond.",
            "We then normalize the audio signal power over the video clip and visualize it near the script with the designer indicator."
        ],
        [
            "OK, let's go to the experiment.",
            "For data sets, were connect 20 video clips, 15 from movie and five from."
        ],
        [
            "Give me your drummer.",
            "A total number of 16 real hearing impaired persons joy."
        ],
        [
            "The user study.",
            "We design three experimental schemes.",
            "Close Caption, Static caption And dynamic caption.",
            "In evaluation we use quality of perception, score, user impression and preference.",
            "Here we emphasize the quality of perception score equals to the percentage of correctly answered questions within 50 carefully designed questions.",
            "Hopefully it may reflect the users understand story understanding and information."
        ],
        [
            "And reception.",
            "This chart is a QP scores for the three schemes we see the scheme of Low caption is far behind."
        ],
        [
            "Another"
        ],
        [
            "Two schemes.",
            "The perception quality of a dynamical caption is enhanced greedier compared with Static caption.",
            "We may see it more."
        ],
        [
            "Clearly, from the average scores."
        ],
        [
            "OK, we conclude our experiments.",
            "The Dynamical caption is really helpful for hearing impaired audience video story understanding.",
            "Secondly, although the pop like rendering, we may look intrusive with.",
            "Our solution has elevated and made it acceptable.",
            "Certainly most participants prefer dynamical caption."
        ],
        [
            "OK, let's shoot live demo from the movie Titanic.",
            "Many persons are involved in a scene.",
            "We don't know who hearing impaired, honest don't know who is speaking.",
            "Two persons are speaking at the same time."
        ],
        [
            "OK, we conclude that our proposed dynamic captioning aiming to enhance the video Accessibility for people with hearing impairment.",
            "It is a solution with integrated multimedia technology.",
            "Also large number of real hearing impaired audience joined the user study."
        ],
        [
            "OK, our current schemes requires the script of the source video.",
            "However, it's easy to extend it to General general videos we can employ automatical, speech recognition, speaker clustering, and identification for script and script face Association.",
            "So we can extend it to general radio such as web videos.",
            "We are working on that."
        ],
        [
            "Another work is that we can using Dynamic caption As a sensitive tour so we can manually adjust script content and depression.",
            "OK, that's all, thanks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we got a continuing our next contender for the best paper award is Richard Hung, postdoctoral fellow at the National University of Singapore, and he will present his work, dynamic captioning, video Accessibility enhancement for hearing impairment.",
                    "label": 0
                },
                {
                    "sent": "Sorry I need to install my laptop.",
                    "label": 0
                },
                {
                    "sent": "OK so my my laser cannot reach another Side Story for the audience over there.",
                    "label": 0
                },
                {
                    "sent": "Yeah so start start our talk so my name is reaching home from National University of Singapore.",
                    "label": 1
                },
                {
                    "sent": "In this presentation I will introduce a work them the dynamical captioning video Accessibility for enhancement.",
                    "label": 0
                },
                {
                    "sent": "So my collaborators move on Monday, she streets and Jen and Tyson Shaw.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Today people are consuming more and more videos from the movie, television and.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Ever.",
                    "label": 0
                },
                {
                    "sent": "When watching video, three types of information, audio test and view content will be transmitted to audience.",
                    "label": 0
                },
                {
                    "sent": "There are about 66 million people suffering from hearing impairment when changing scenario trace, hearing impaired audience, all your information is lost.",
                    "label": 0
                },
                {
                    "sent": "Current temperature current captioning techniques can partially activate this.",
                    "label": 0
                },
                {
                    "sent": "Commission loss, however, hearing impaired audience tended to focus on either text or via content at one moment.",
                    "label": 1
                },
                {
                    "sent": "So the perception of attacks in video content will be weekend.",
                    "label": 0
                },
                {
                    "sent": "Next will show more limitations of current captioning techniques.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's see this video clip.",
                    "label": 0
                },
                {
                    "sent": "There are more than one person involved in the scene.",
                    "label": 0
                },
                {
                    "sent": "For hearing impaired audience is difficult to quickly tell who is speaking.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another example, we see the speaking speed can vary significantly, so the duration of the script presentation will also vary over a wide range.",
                    "label": 0
                },
                {
                    "sent": "It brings difficulty for hearing impaired audience to track the caption.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Finally, as we know, the voice information is one of the key factors to reflect human emotion.",
                    "label": 0
                },
                {
                    "sent": "The loss of voice volume information certainly degrade their enjoyment in watching video, or these limitations cannot be tackled by current capture.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So tackle this limitation.",
                    "label": 0
                },
                {
                    "sent": "We designed three components of script location, script, speech, alignment and voice.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Volume estimation script location is designed to determine the Association between face and script and then determine a region in which the script will be presented.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Scrape the speech.",
                    "label": 0
                },
                {
                    "sent": "Alignment aims to temporarily highlights the speech world by.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Word.",
                    "label": 0
                },
                {
                    "sent": "Voice volume estimation is used to demonstrate the variation of voice volume.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This independent component comprises the framework of Dynamic caption.",
                    "label": 1
                },
                {
                    "sent": "Here we use a dynamic.",
                    "label": 0
                },
                {
                    "sent": "Is in contrast to current caption, would define Current caption As Static caption, Since it is simply demonstrated in a fixed region and illustrated statically.",
                    "label": 0
                },
                {
                    "sent": "We see our dynamic action is a pure multimedia issue and it can include many multimedia techniques such as face detection, face recognition, script alignment, speech recognition, something like that.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, let's talk about the first component of script location.",
                    "label": 1
                },
                {
                    "sent": "Before determining a region in which the present the script will be present, we need to determine a region.",
                    "label": 0
                },
                {
                    "sent": "OK, we first perform the face detection and then we combine the script clues and the new promotion analysis to directly determine the Association.",
                    "label": 0
                },
                {
                    "sent": "For example.",
                    "label": 0
                },
                {
                    "sent": "If the frame contains face, a single face with Leap Motion and the script clues indicate she is rose.",
                    "label": 0
                },
                {
                    "sent": "However, in more cases we have to resort to face recognition for face recognition.",
                    "label": 1
                },
                {
                    "sent": "We can group Lee, we can group continuously detecting faces of a particular person as a face track.",
                    "label": 0
                },
                {
                    "sent": "We can directly label some fixed tracks using the recognizer faces by script clues and Leap Motion analysis.",
                    "label": 0
                },
                {
                    "sent": "Such labeled fixed track can be used as training data with an employee multitask joined sparse representation model to recognize the unlabeled face tracks in experiments.",
                    "label": 0
                },
                {
                    "sent": "Our approach can achieve the accuracy of about 89%.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "After establishing the Association between face and script.",
                    "label": 0
                },
                {
                    "sent": "We need to detect a region to insert the script here.",
                    "label": 0
                },
                {
                    "sent": "Seeing the first analyzed.",
                    "label": 0
                },
                {
                    "sent": "We then design a way to temper data based on the identified speaker information.",
                    "label": 0
                },
                {
                    "sent": "Finally, we combine this senior see analysis and weight tablet to find an uninteresting region for script.",
                    "label": 1
                },
                {
                    "sent": "So far we have accompanied the process of identifying where to put the script and who is speaking.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, let's talk about component of script, speech, alignment.",
                    "label": 0
                },
                {
                    "sent": "This component aims to temporally matched each piece of script with the with the corresponding speech segment.",
                    "label": 0
                },
                {
                    "sent": "Here we employ the open source tools things to recognize the speech.",
                    "label": 0
                },
                {
                    "sent": "During alignment.",
                    "label": 0
                },
                {
                    "sent": "We started from the words matched with high confidence loan as hypothesized world.",
                    "label": 0
                },
                {
                    "sent": "We then employ dynamic programming to iteratively find more mixed words until all the words are aligned in experiment.",
                    "label": 0
                },
                {
                    "sent": "This approach can achieve the accuracy of about 90%.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "How is the voice volume estimation?",
                    "label": 1
                },
                {
                    "sent": "For this part, we simply compute the power of the audio singular in a small local window.",
                    "label": 0
                },
                {
                    "sent": "The size of the window is set to certain millisecond.",
                    "label": 0
                },
                {
                    "sent": "We then normalize the audio signal power over the video clip and visualize it near the script with the designer indicator.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, let's go to the experiment.",
                    "label": 0
                },
                {
                    "sent": "For data sets, were connect 20 video clips, 15 from movie and five from.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Give me your drummer.",
                    "label": 0
                },
                {
                    "sent": "A total number of 16 real hearing impaired persons joy.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The user study.",
                    "label": 0
                },
                {
                    "sent": "We design three experimental schemes.",
                    "label": 0
                },
                {
                    "sent": "Close Caption, Static caption And dynamic caption.",
                    "label": 1
                },
                {
                    "sent": "In evaluation we use quality of perception, score, user impression and preference.",
                    "label": 1
                },
                {
                    "sent": "Here we emphasize the quality of perception score equals to the percentage of correctly answered questions within 50 carefully designed questions.",
                    "label": 0
                },
                {
                    "sent": "Hopefully it may reflect the users understand story understanding and information.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And reception.",
                    "label": 0
                },
                {
                    "sent": "This chart is a QP scores for the three schemes we see the scheme of Low caption is far behind.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Two schemes.",
                    "label": 0
                },
                {
                    "sent": "The perception quality of a dynamical caption is enhanced greedier compared with Static caption.",
                    "label": 1
                },
                {
                    "sent": "We may see it more.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Clearly, from the average scores.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, we conclude our experiments.",
                    "label": 0
                },
                {
                    "sent": "The Dynamical caption is really helpful for hearing impaired audience video story understanding.",
                    "label": 0
                },
                {
                    "sent": "Secondly, although the pop like rendering, we may look intrusive with.",
                    "label": 0
                },
                {
                    "sent": "Our solution has elevated and made it acceptable.",
                    "label": 0
                },
                {
                    "sent": "Certainly most participants prefer dynamical caption.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, let's shoot live demo from the movie Titanic.",
                    "label": 0
                },
                {
                    "sent": "Many persons are involved in a scene.",
                    "label": 0
                },
                {
                    "sent": "We don't know who hearing impaired, honest don't know who is speaking.",
                    "label": 0
                },
                {
                    "sent": "Two persons are speaking at the same time.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, we conclude that our proposed dynamic captioning aiming to enhance the video Accessibility for people with hearing impairment.",
                    "label": 0
                },
                {
                    "sent": "It is a solution with integrated multimedia technology.",
                    "label": 0
                },
                {
                    "sent": "Also large number of real hearing impaired audience joined the user study.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, our current schemes requires the script of the source video.",
                    "label": 0
                },
                {
                    "sent": "However, it's easy to extend it to General general videos we can employ automatical, speech recognition, speaker clustering, and identification for script and script face Association.",
                    "label": 0
                },
                {
                    "sent": "So we can extend it to general radio such as web videos.",
                    "label": 0
                },
                {
                    "sent": "We are working on that.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another work is that we can using Dynamic caption As a sensitive tour so we can manually adjust script content and depression.",
                    "label": 0
                },
                {
                    "sent": "OK, that's all, thanks.",
                    "label": 0
                }
            ]
        }
    }
}