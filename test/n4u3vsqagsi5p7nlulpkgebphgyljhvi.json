{
    "id": "n4u3vsqagsi5p7nlulpkgebphgyljhvi",
    "title": "Distributed Indexing for Semantic Search",
    "info": {
        "author": [
            "Peter Mika, Yahoo! Research"
        ],
        "published": "May 17, 2010",
        "recorded": "April 2010",
        "category": [
            "Top->Computer Science->Semantic Search"
        ]
    },
    "url": "http://videolectures.net/www2010_mika_dis/",
    "segmentation": [
        [
            "So thank you everyone now switching slightly topics and I'm going to tell you about distributed indexing for semantic search, which is of course related to ranking.",
            "Indexing is what you need to do before you can do ranking.",
            "This is a fairly practical paper, so I'm actually sharing our own practical experiences with trying to use a MapReduce and Hadoop to do indexing of RDF data."
        ],
        [
            "For semantic search.",
            "So, so typically when people do this, of course you do distributed computation, so you need a distributed file system.",
            "And most map reduce paradigm and dismisses file system is implemented as part of Hadoop, which is an open source software that anyone can install and it runs on commodity hardware.",
            "So whenever you have a set of a set of machines, you can just download Hadoop, install the software and it gives you these two things.",
            "The distributed file system and this computational framework where you can create, map and reduce jobs and apply them to large sets of data."
        ],
        [
            "Now, what does this have to do with indexing?",
            "Well, information she will, and this is again well known, relies on the notion of inverted indices.",
            "An inverted index is a map from the terms in the collection to the documents which contain that term.",
            "Very caring proceeds by resolving each term in the query against this index right?",
            "Emerging the resulting document sets now produce is actually the perfect model for building is inverted indices.",
            "I'm not sure if it was invented for this purpose, but it is certainly a great fit for this problem, and that's because you can break down the building of an inverted index into 2 steps.",
            "One is which the Mapper will do is to read the document and end to tokenize the document right so.",
            "To take out the terms that you want to index and then create this term document pairs and then in the reduce phase you collect such term document pairs.",
            "Well system does it for you and you basically get what you need, which is which is the inverted index for each term you know in which documents it appears.",
            "And that's that's of course, all great.",
            "There are some known issues that that have already come up.",
            "If you if you just try to do text indexing.",
            "So for example, distribution of your terms can be a problem.",
            "It's bad on that some terms stop.",
            "Words typically are very frequent.",
            "And when you do this term by term processing, it can of course happen that the machine that actually gets to process a very common term like that will have to work much harder and longer than some of your other machines in the cluster.",
            "There's also an another part which which actually comes afterwards.",
            "So so if you if you if you create distributed indexes, indexes this way.",
            "You still have to merge the resulting subindices afterwards, so each reducer will build a sub index and this sub indices needs to merge, but typically it's a fairly fast operation.",
            "A basic ideas is described in modern information retrieval textbooks, and there were the existing implementation for text retrieval.",
            "For example, to build Lucene indices, there is an open source project called Cotton."
        ],
        [
            "Now DF of course is a slightly different story.",
            "Data is a much richer structure, and of course we expect to to carry out more sophisticated queries, which again in turn require more sophisticated indices.",
            "Now of course there is no clear agreement as to what exactly is expressive.",
            "It is that we would require from our from our query languages.",
            "If you just look at what is on the web, current web search queries, we see very limited structure, right?",
            "So this paper that will be presented to the main conference by Jeff found on Friday contains some analysis on on what kind of structure we find in keyword queries.",
            "But keyword queries, you know are just a few words and very often just contain the name of an entity, for example.",
            "And of course, it's a question whether end users will want to type in more sophisticated queries and in what form.",
            "So it's clear that they will certainly not type in full sparkle queries into search engine anytime soon.",
            "But putting that issue aside, I think what is what is a common requirement for most most scenarios that I've seen is to be able to index and retrieve.",
            "Objects or entities.",
            "If you will buy the values of properties right?",
            "So simple example would be giving objects their value of of the name property is Peter McKinnon an in some pseudo query language?",
            "You would.",
            "You would write it down like this.",
            "And you might want to enforce of course positions so that the words Peter and Mika appear one after another.",
            "As well, you might want to do joins, so at this early example shows a query where the user is looking for Peter Mika and only Peter MC's who have an age of 32.",
            "So this is the kind of expressivity that that all will be taught."
        ],
        [
            "Getting in my indexing.",
            "Now very simple and I'm very cheap.",
            "You know no brain solution is is what I would call post fixing so.",
            "So instead of instead of the individual words just bands to divert the name of the property, right?",
            "And that's that's very cheap.",
            "You can use any kind of search engine to do that.",
            "You actually get the benefit that there's going to be less queue, because now you're indexing verts per field, right per property.",
            "The disadvantage is that your dictionary expands quite rapidly because now you will have not only one vertical depth, but you will have the in every possible property, and typically in RDF data as you know the number of properties is fairly large.",
            "So this this really works when you have a small number of of fields or properties to index.",
            "For example in named entity recognition.",
            "Typically people you know recognize four or five types of entities in text, and that you can index with this method."
        ],
        [
            "Families.",
            "Now, So what are some of the other options?",
            "Well, so the next logical option is to really just put everything in one field in terms of the text and put the properties into another field right over the index.",
            "So this is what you see here at the bottom.",
            "And the trick here is if you want to.",
            "If you want to have the same capability is to is to align the two indices.",
            "So for each position in the in the token index on the same position in the property index, you store the name or identifier of the property for which that word is a value.",
            "Now what you need from your query engine is this alignment operator, which exists in.",
            "I'm not sure if it's a crystal scene.",
            "We've been using MG for J exists, and it's it's.",
            "A symbol is this^ so you can say now.",
            "You know, I wonder where Peter and at the same position in the other index there should be.",
            "There should be the name property and I'm on the word Mecca and at the other index at the same position that should be the property name again.",
            "This works will return to to what it costs an and what the performance is.",
            "The dictionary is basically the number of unique terms that you have plus the number of properties, right?",
            "So in this in this one this is going to be a small dictionary because it's only us largest as the size of your dictionary.",
            "There's as much Q as in this in traditional text indexing, since since you just basically added one more field."
        ],
        [
            "The other natural idea would say is is to have only one field their property right one index per property, so that's what you see here at the bottom and in this case your query engine really only is to support multiple indices or fields.",
            "So it needs to be able to parse such a query and know that it needs to need to retrieve the word Peter from the index whose name is the name property.",
            "In this case, it looks very good.",
            "Dictionaries is just the number of unique terms, the number of occurrences is really just the number of tokens, and there's less Q since you again divided your index into into sub indices by property.",
            "Bother other problems and I'm going to return to this and namely the number of fields becomes a problem for for merging and query performance."
        ],
        [
            "So, so we did some experimentation as to see you know what does it really cost to build these indices and what is the performance that you're getting.",
            "If you're showing this type of berries.",
            "So, so we implemented ourselves and the reality is a bit more complex than the textbooks would like you to believe.",
            "One thing you definitely need to do, and this somewhat vanillin information retrieval, is that you need to.",
            "You need to hash your document identifiers.",
            "In this case your object, you arise.",
            "OMG for JS minimal perfect hash functionality.",
            "And on the data which which we use, which is the billion triples challenge collection which was also used for the entity search track.",
            "This function actually occupies only 300 megabytes.",
            "Hundreds 20,000,000 documents or so.",
            "So it fits in memory for now, but it might not fit in memory later, right?",
            "So here the problem becomes that each of your nodes needs to needs to load this.",
            "This map basically this dysfunction from subject URS the document identifiers and at some point in the future you know we will run out of out of memory and the nodes.",
            "And then of course we needed to implement fields and positions.",
            "So from the basic textbook example, things get a bit more complicated.",
            "The keys are now field and term pairs, and the values are not just document IDs, but document IDs and positions.",
            "And there are some additional requirements which are basically imposed by the by the indexing by the index server using which is Angie for J.",
            "But I think it would have been very same with other with other libraries.",
            "One is that the documents need to come in increasing order of document ID.",
            "So basically your posting lists needs to be sorted by document ID.",
            "And that will be solved by a secondary sort, which is fairly advanced technique to get to get the framework to give you the values in this in this list in in some order."
        ],
        [
            "Not go into details but but you can look in the paper.",
            "Another limitation is that when we start to write out the posting list, so we start to write out the document identifiers forgiven term, we need to know in advance.",
            "The number of documents that we're going to be writing out, and again we solve this and I'll refer the details to the paper.",
            "We had some memory problems to solve it with unbalanced execution, so this is the this is the skew problem.",
            "We had problems in the vertical case with the number of indices.",
            "So basically for the index rating to be efficient you need to you need to have a cache for each field in memory, and that limits limits the number of fields you can index.",
            "Right and then of course there are tradeoffs in the in the system between how much memory you're using and how much memory the system is using on each of them."
        ],
        [
            "Not for the valuation very quickly.",
            "Sylvester mentioned already used the BTC will in triples Challenge 2009 data set.",
            "Um?",
            "It's a fairly large data set, 100 and 1020 million euros.",
            "Something like that.",
            "Just a reminder, if index subject your eyes are not document URLs and in order to do that we need to collect all the triples by subject UI.",
            "So so you started for that as well.",
            "We index only data type properties, so we did not index object properties or links between objects.",
            "And for the vertical indexing we also needed to select the number of properties to next, and that's because of the aforementioned limitations.",
            "So we choose three hundreds data type properties.",
            "And again, the reverse face.",
            "To do this, one of the simplest ways is just to look at the frequency.",
            "So index the most frequent properties.",
            "This is not so great in practice, actually, because you index things that are that are very frequent but almost no one would ever query for them.",
            "So a better idea would be to index the fields that are most likely to match based on based on some kind of very log.",
            "And we measured in this experiment indexing cost and query performance.",
            "We did not factor in the cost of merging."
        ],
        [
            "Some industries so so.",
            "Here's also in terms of indexing costs some observations.",
            "So basically the number of mappers which you see here solely depends on the size of the input.",
            "But if you want four barrels and then of course with increasing amounts of data you wanted more machines, so that basically tells you how many machines you need.",
            "In the reduce phase, we actually only use 20 machines, and that's because the tradeoff there is between the number of indices you build.",
            "And the cost of merging, right?",
            "So if you build many, many very very small indices.",
            "You will have to.",
            "You have to merge them.",
            "If you build very few indices, you have less parallelization, right?",
            "So?",
            "So the tradeoff there is between is between those two.",
            "One of the reviewers asked how much a single machine next thing would have taken, and I don't know, but at least a week here.",
            "The real time that we measured was was three hours, 4 hours in next time.",
            "We found the vertical next to be less efficient, though do not much.",
            "More."
        ],
        [
            "In terms of credit performance and this is something very are still looking at the results because we don't fully understand what is going on.",
            "So we have the horizontal index for fewer keyword queries with no with no property restrictions.",
            "We have the horizontal indexing performing better which we expected."
        ],
        [
            "For fielder St Fairies and these are queries where we look for a single word in a single field.",
            "We still find horizontally indexing winning with the alignment operator an.",
            "This is somewhat counter.",
            "It is intuitive to art or expectations, so we're still looking into into into why that is."
        ],
        [
            "So in conclusions for now, the horizontal next structure seems to be more more efficient for keyword queries, and field restricts, we want to really verify this under understand more ideal setting very controlled memory, abit bit more than we did for the paper.",
            "In its current form, and you want to check for for not just single word, but multiverse queries and also joins.",
            "So do to kind of fairies that I've shown at the beginning so you know, looking for a name and some other attribute together.",
            "And of course trying this on different datasets so datasets in the in the semantic web world are fairly different in their in their characteristics in terms of harmony.",
            "How, for example, the data is distributed across across properties.",
            "They are also very clear efficiency improvements that we haven't tried yet, so one is language detection.",
            "One thing I notice is since since we're not doing tokenization properly for other languages for Japanese, for example, we consider entire entire values of literals as a single vert and of course blows up the dictionary because large pieces of Japanese text now become a single term.",
            "So we should either do language detection or or actually proper tokenization in different languages and other techniques that we haven't tried yet.",
            "So for example, pushing some of the sorting into into the map phase.",
            "So, so that's so much for now, and I'm open for questions or comments if someone has related experiences with indexing using product, thank you.",
            "Very bad, very bad.",
            "So yeah, I given the time after Rush but this is basically the number of queries so overtime right?",
            "So we should 4300 queries right?",
            "And measure the performance overtime.",
            "So just to just to look if there is there is any.",
            "In effect on the.",
            "On the depending on number of queries.",
            "And the Y axis is time.",
            "So about the post fixing, how can you go back to the slide where you described the post fixing?",
            "How if I want all the properties for Peter?",
            "How do I get them?",
            "You want all the all the properties for Peter.",
            "You cannot get that, so you cannot get it with any of these index structures, right?",
            "So that's a query for which you would need to build a different index.",
            "May have one more.",
            "Sorry, one more question, sure.",
            "So in the table where you show the times in the number of Maps in map number of video sis, do you know what was the time for the longest map and the longest reduce?",
            "This would give us an indication of how paralyzable this index making case.",
            "Yeah, so I didn't go into detail, but actually measuring execution time on Hadoop is almost impossible.",
            "Yeah, I know.",
            "In the latest version they they report something called slots Maps, Millis and slots Reduce Millis, which is the average.",
            "No, it's the total execution time of all of the Maps that that are executing.",
            "Now you can divide it by the number of Maps and by that you can get an average time per map or produce the total time depends on a lot of things because we're using speculative execution.",
            "For example, if you speculative execution.",
            "Then of course it starts new Maps.",
            "It kills them right beside that it doesn't need them anymore, so it becomes a lot more lot more complicated.",
            "So the longest map you can use as an approximation of how long it would take if you would have an infinite number of processors.",
            "So, or at least as many as your Maps and as many as you reduce.",
            "I would have to think about that, so I reported the real time which would give you an indication of of roughly how long things take in total.",
            "That's better, that's that's true.",
            "I'm not sure.",
            "OK, thanks just a small technical idea inspired by your talk.",
            "Could you reduce SKU by century randomizing?",
            "So if you had like the if you've got some words but you basically make it instead of be the sort of its dot 1.2, the three with some sort of random thing.",
            "So then you're basically just partner making introducing a fine grained exist and these recovered emerge time indexing interesting.",
            "Yeah, yeah.",
            "Yeah, we have to measure that whether that sufficient right.",
            "You have to work harder than at query time and and less at indexing time.",
            "Yeah no, you don't work hard at query time 'cause you can then once once you've done your reduce you can then do next pass and merge it back.",
            "Oh, I see it's no different, query just enables more parallelism.",
            "And then yeah.",
            "OK, let's thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So thank you everyone now switching slightly topics and I'm going to tell you about distributed indexing for semantic search, which is of course related to ranking.",
                    "label": 1
                },
                {
                    "sent": "Indexing is what you need to do before you can do ranking.",
                    "label": 0
                },
                {
                    "sent": "This is a fairly practical paper, so I'm actually sharing our own practical experiences with trying to use a MapReduce and Hadoop to do indexing of RDF data.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For semantic search.",
                    "label": 0
                },
                {
                    "sent": "So, so typically when people do this, of course you do distributed computation, so you need a distributed file system.",
                    "label": 0
                },
                {
                    "sent": "And most map reduce paradigm and dismisses file system is implemented as part of Hadoop, which is an open source software that anyone can install and it runs on commodity hardware.",
                    "label": 1
                },
                {
                    "sent": "So whenever you have a set of a set of machines, you can just download Hadoop, install the software and it gives you these two things.",
                    "label": 0
                },
                {
                    "sent": "The distributed file system and this computational framework where you can create, map and reduce jobs and apply them to large sets of data.",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now, what does this have to do with indexing?",
                    "label": 0
                },
                {
                    "sent": "Well, information she will, and this is again well known, relies on the notion of inverted indices.",
                    "label": 0
                },
                {
                    "sent": "An inverted index is a map from the terms in the collection to the documents which contain that term.",
                    "label": 1
                },
                {
                    "sent": "Very caring proceeds by resolving each term in the query against this index right?",
                    "label": 0
                },
                {
                    "sent": "Emerging the resulting document sets now produce is actually the perfect model for building is inverted indices.",
                    "label": 1
                },
                {
                    "sent": "I'm not sure if it was invented for this purpose, but it is certainly a great fit for this problem, and that's because you can break down the building of an inverted index into 2 steps.",
                    "label": 0
                },
                {
                    "sent": "One is which the Mapper will do is to read the document and end to tokenize the document right so.",
                    "label": 0
                },
                {
                    "sent": "To take out the terms that you want to index and then create this term document pairs and then in the reduce phase you collect such term document pairs.",
                    "label": 1
                },
                {
                    "sent": "Well system does it for you and you basically get what you need, which is which is the inverted index for each term you know in which documents it appears.",
                    "label": 0
                },
                {
                    "sent": "And that's that's of course, all great.",
                    "label": 0
                },
                {
                    "sent": "There are some known issues that that have already come up.",
                    "label": 0
                },
                {
                    "sent": "If you if you just try to do text indexing.",
                    "label": 0
                },
                {
                    "sent": "So for example, distribution of your terms can be a problem.",
                    "label": 0
                },
                {
                    "sent": "It's bad on that some terms stop.",
                    "label": 0
                },
                {
                    "sent": "Words typically are very frequent.",
                    "label": 0
                },
                {
                    "sent": "And when you do this term by term processing, it can of course happen that the machine that actually gets to process a very common term like that will have to work much harder and longer than some of your other machines in the cluster.",
                    "label": 0
                },
                {
                    "sent": "There's also an another part which which actually comes afterwards.",
                    "label": 0
                },
                {
                    "sent": "So so if you if you if you create distributed indexes, indexes this way.",
                    "label": 0
                },
                {
                    "sent": "You still have to merge the resulting subindices afterwards, so each reducer will build a sub index and this sub indices needs to merge, but typically it's a fairly fast operation.",
                    "label": 0
                },
                {
                    "sent": "A basic ideas is described in modern information retrieval textbooks, and there were the existing implementation for text retrieval.",
                    "label": 0
                },
                {
                    "sent": "For example, to build Lucene indices, there is an open source project called Cotton.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now DF of course is a slightly different story.",
                    "label": 0
                },
                {
                    "sent": "Data is a much richer structure, and of course we expect to to carry out more sophisticated queries, which again in turn require more sophisticated indices.",
                    "label": 1
                },
                {
                    "sent": "Now of course there is no clear agreement as to what exactly is expressive.",
                    "label": 0
                },
                {
                    "sent": "It is that we would require from our from our query languages.",
                    "label": 1
                },
                {
                    "sent": "If you just look at what is on the web, current web search queries, we see very limited structure, right?",
                    "label": 0
                },
                {
                    "sent": "So this paper that will be presented to the main conference by Jeff found on Friday contains some analysis on on what kind of structure we find in keyword queries.",
                    "label": 1
                },
                {
                    "sent": "But keyword queries, you know are just a few words and very often just contain the name of an entity, for example.",
                    "label": 0
                },
                {
                    "sent": "And of course, it's a question whether end users will want to type in more sophisticated queries and in what form.",
                    "label": 0
                },
                {
                    "sent": "So it's clear that they will certainly not type in full sparkle queries into search engine anytime soon.",
                    "label": 0
                },
                {
                    "sent": "But putting that issue aside, I think what is what is a common requirement for most most scenarios that I've seen is to be able to index and retrieve.",
                    "label": 0
                },
                {
                    "sent": "Objects or entities.",
                    "label": 0
                },
                {
                    "sent": "If you will buy the values of properties right?",
                    "label": 0
                },
                {
                    "sent": "So simple example would be giving objects their value of of the name property is Peter McKinnon an in some pseudo query language?",
                    "label": 0
                },
                {
                    "sent": "You would.",
                    "label": 0
                },
                {
                    "sent": "You would write it down like this.",
                    "label": 0
                },
                {
                    "sent": "And you might want to enforce of course positions so that the words Peter and Mika appear one after another.",
                    "label": 0
                },
                {
                    "sent": "As well, you might want to do joins, so at this early example shows a query where the user is looking for Peter Mika and only Peter MC's who have an age of 32.",
                    "label": 0
                },
                {
                    "sent": "So this is the kind of expressivity that that all will be taught.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Getting in my indexing.",
                    "label": 0
                },
                {
                    "sent": "Now very simple and I'm very cheap.",
                    "label": 0
                },
                {
                    "sent": "You know no brain solution is is what I would call post fixing so.",
                    "label": 0
                },
                {
                    "sent": "So instead of instead of the individual words just bands to divert the name of the property, right?",
                    "label": 1
                },
                {
                    "sent": "And that's that's very cheap.",
                    "label": 0
                },
                {
                    "sent": "You can use any kind of search engine to do that.",
                    "label": 0
                },
                {
                    "sent": "You actually get the benefit that there's going to be less queue, because now you're indexing verts per field, right per property.",
                    "label": 0
                },
                {
                    "sent": "The disadvantage is that your dictionary expands quite rapidly because now you will have not only one vertical depth, but you will have the in every possible property, and typically in RDF data as you know the number of properties is fairly large.",
                    "label": 1
                },
                {
                    "sent": "So this this really works when you have a small number of of fields or properties to index.",
                    "label": 1
                },
                {
                    "sent": "For example in named entity recognition.",
                    "label": 0
                },
                {
                    "sent": "Typically people you know recognize four or five types of entities in text, and that you can index with this method.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Families.",
                    "label": 0
                },
                {
                    "sent": "Now, So what are some of the other options?",
                    "label": 0
                },
                {
                    "sent": "Well, so the next logical option is to really just put everything in one field in terms of the text and put the properties into another field right over the index.",
                    "label": 0
                },
                {
                    "sent": "So this is what you see here at the bottom.",
                    "label": 0
                },
                {
                    "sent": "And the trick here is if you want to.",
                    "label": 0
                },
                {
                    "sent": "If you want to have the same capability is to is to align the two indices.",
                    "label": 0
                },
                {
                    "sent": "So for each position in the in the token index on the same position in the property index, you store the name or identifier of the property for which that word is a value.",
                    "label": 1
                },
                {
                    "sent": "Now what you need from your query engine is this alignment operator, which exists in.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure if it's a crystal scene.",
                    "label": 0
                },
                {
                    "sent": "We've been using MG for J exists, and it's it's.",
                    "label": 0
                },
                {
                    "sent": "A symbol is this^ so you can say now.",
                    "label": 0
                },
                {
                    "sent": "You know, I wonder where Peter and at the same position in the other index there should be.",
                    "label": 0
                },
                {
                    "sent": "There should be the name property and I'm on the word Mecca and at the other index at the same position that should be the property name again.",
                    "label": 0
                },
                {
                    "sent": "This works will return to to what it costs an and what the performance is.",
                    "label": 1
                },
                {
                    "sent": "The dictionary is basically the number of unique terms that you have plus the number of properties, right?",
                    "label": 1
                },
                {
                    "sent": "So in this in this one this is going to be a small dictionary because it's only us largest as the size of your dictionary.",
                    "label": 0
                },
                {
                    "sent": "There's as much Q as in this in traditional text indexing, since since you just basically added one more field.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The other natural idea would say is is to have only one field their property right one index per property, so that's what you see here at the bottom and in this case your query engine really only is to support multiple indices or fields.",
                    "label": 1
                },
                {
                    "sent": "So it needs to be able to parse such a query and know that it needs to need to retrieve the word Peter from the index whose name is the name property.",
                    "label": 0
                },
                {
                    "sent": "In this case, it looks very good.",
                    "label": 0
                },
                {
                    "sent": "Dictionaries is just the number of unique terms, the number of occurrences is really just the number of tokens, and there's less Q since you again divided your index into into sub indices by property.",
                    "label": 1
                },
                {
                    "sent": "Bother other problems and I'm going to return to this and namely the number of fields becomes a problem for for merging and query performance.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, so we did some experimentation as to see you know what does it really cost to build these indices and what is the performance that you're getting.",
                    "label": 0
                },
                {
                    "sent": "If you're showing this type of berries.",
                    "label": 0
                },
                {
                    "sent": "So, so we implemented ourselves and the reality is a bit more complex than the textbooks would like you to believe.",
                    "label": 1
                },
                {
                    "sent": "One thing you definitely need to do, and this somewhat vanillin information retrieval, is that you need to.",
                    "label": 0
                },
                {
                    "sent": "You need to hash your document identifiers.",
                    "label": 0
                },
                {
                    "sent": "In this case your object, you arise.",
                    "label": 1
                },
                {
                    "sent": "OMG for JS minimal perfect hash functionality.",
                    "label": 1
                },
                {
                    "sent": "And on the data which which we use, which is the billion triples challenge collection which was also used for the entity search track.",
                    "label": 0
                },
                {
                    "sent": "This function actually occupies only 300 megabytes.",
                    "label": 0
                },
                {
                    "sent": "Hundreds 20,000,000 documents or so.",
                    "label": 1
                },
                {
                    "sent": "So it fits in memory for now, but it might not fit in memory later, right?",
                    "label": 0
                },
                {
                    "sent": "So here the problem becomes that each of your nodes needs to needs to load this.",
                    "label": 0
                },
                {
                    "sent": "This map basically this dysfunction from subject URS the document identifiers and at some point in the future you know we will run out of out of memory and the nodes.",
                    "label": 1
                },
                {
                    "sent": "And then of course we needed to implement fields and positions.",
                    "label": 0
                },
                {
                    "sent": "So from the basic textbook example, things get a bit more complicated.",
                    "label": 0
                },
                {
                    "sent": "The keys are now field and term pairs, and the values are not just document IDs, but document IDs and positions.",
                    "label": 0
                },
                {
                    "sent": "And there are some additional requirements which are basically imposed by the by the indexing by the index server using which is Angie for J.",
                    "label": 0
                },
                {
                    "sent": "But I think it would have been very same with other with other libraries.",
                    "label": 0
                },
                {
                    "sent": "One is that the documents need to come in increasing order of document ID.",
                    "label": 1
                },
                {
                    "sent": "So basically your posting lists needs to be sorted by document ID.",
                    "label": 0
                },
                {
                    "sent": "And that will be solved by a secondary sort, which is fairly advanced technique to get to get the framework to give you the values in this in this list in in some order.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Not go into details but but you can look in the paper.",
                    "label": 0
                },
                {
                    "sent": "Another limitation is that when we start to write out the posting list, so we start to write out the document identifiers forgiven term, we need to know in advance.",
                    "label": 1
                },
                {
                    "sent": "The number of documents that we're going to be writing out, and again we solve this and I'll refer the details to the paper.",
                    "label": 1
                },
                {
                    "sent": "We had some memory problems to solve it with unbalanced execution, so this is the this is the skew problem.",
                    "label": 0
                },
                {
                    "sent": "We had problems in the vertical case with the number of indices.",
                    "label": 1
                },
                {
                    "sent": "So basically for the index rating to be efficient you need to you need to have a cache for each field in memory, and that limits limits the number of fields you can index.",
                    "label": 1
                },
                {
                    "sent": "Right and then of course there are tradeoffs in the in the system between how much memory you're using and how much memory the system is using on each of them.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Not for the valuation very quickly.",
                    "label": 0
                },
                {
                    "sent": "Sylvester mentioned already used the BTC will in triples Challenge 2009 data set.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "It's a fairly large data set, 100 and 1020 million euros.",
                    "label": 0
                },
                {
                    "sent": "Something like that.",
                    "label": 0
                },
                {
                    "sent": "Just a reminder, if index subject your eyes are not document URLs and in order to do that we need to collect all the triples by subject UI.",
                    "label": 1
                },
                {
                    "sent": "So so you started for that as well.",
                    "label": 0
                },
                {
                    "sent": "We index only data type properties, so we did not index object properties or links between objects.",
                    "label": 0
                },
                {
                    "sent": "And for the vertical indexing we also needed to select the number of properties to next, and that's because of the aforementioned limitations.",
                    "label": 0
                },
                {
                    "sent": "So we choose three hundreds data type properties.",
                    "label": 0
                },
                {
                    "sent": "And again, the reverse face.",
                    "label": 0
                },
                {
                    "sent": "To do this, one of the simplest ways is just to look at the frequency.",
                    "label": 0
                },
                {
                    "sent": "So index the most frequent properties.",
                    "label": 0
                },
                {
                    "sent": "This is not so great in practice, actually, because you index things that are that are very frequent but almost no one would ever query for them.",
                    "label": 0
                },
                {
                    "sent": "So a better idea would be to index the fields that are most likely to match based on based on some kind of very log.",
                    "label": 0
                },
                {
                    "sent": "And we measured in this experiment indexing cost and query performance.",
                    "label": 1
                },
                {
                    "sent": "We did not factor in the cost of merging.",
                    "label": 1
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Some industries so so.",
                    "label": 0
                },
                {
                    "sent": "Here's also in terms of indexing costs some observations.",
                    "label": 0
                },
                {
                    "sent": "So basically the number of mappers which you see here solely depends on the size of the input.",
                    "label": 1
                },
                {
                    "sent": "But if you want four barrels and then of course with increasing amounts of data you wanted more machines, so that basically tells you how many machines you need.",
                    "label": 0
                },
                {
                    "sent": "In the reduce phase, we actually only use 20 machines, and that's because the tradeoff there is between the number of indices you build.",
                    "label": 0
                },
                {
                    "sent": "And the cost of merging, right?",
                    "label": 0
                },
                {
                    "sent": "So if you build many, many very very small indices.",
                    "label": 1
                },
                {
                    "sent": "You will have to.",
                    "label": 0
                },
                {
                    "sent": "You have to merge them.",
                    "label": 0
                },
                {
                    "sent": "If you build very few indices, you have less parallelization, right?",
                    "label": 0
                },
                {
                    "sent": "So?",
                    "label": 1
                },
                {
                    "sent": "So the tradeoff there is between is between those two.",
                    "label": 0
                },
                {
                    "sent": "One of the reviewers asked how much a single machine next thing would have taken, and I don't know, but at least a week here.",
                    "label": 0
                },
                {
                    "sent": "The real time that we measured was was three hours, 4 hours in next time.",
                    "label": 1
                },
                {
                    "sent": "We found the vertical next to be less efficient, though do not much.",
                    "label": 0
                },
                {
                    "sent": "More.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In terms of credit performance and this is something very are still looking at the results because we don't fully understand what is going on.",
                    "label": 0
                },
                {
                    "sent": "So we have the horizontal index for fewer keyword queries with no with no property restrictions.",
                    "label": 0
                },
                {
                    "sent": "We have the horizontal indexing performing better which we expected.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For fielder St Fairies and these are queries where we look for a single word in a single field.",
                    "label": 0
                },
                {
                    "sent": "We still find horizontally indexing winning with the alignment operator an.",
                    "label": 0
                },
                {
                    "sent": "This is somewhat counter.",
                    "label": 0
                },
                {
                    "sent": "It is intuitive to art or expectations, so we're still looking into into into why that is.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in conclusions for now, the horizontal next structure seems to be more more efficient for keyword queries, and field restricts, we want to really verify this under understand more ideal setting very controlled memory, abit bit more than we did for the paper.",
                    "label": 1
                },
                {
                    "sent": "In its current form, and you want to check for for not just single word, but multiverse queries and also joins.",
                    "label": 0
                },
                {
                    "sent": "So do to kind of fairies that I've shown at the beginning so you know, looking for a name and some other attribute together.",
                    "label": 0
                },
                {
                    "sent": "And of course trying this on different datasets so datasets in the in the semantic web world are fairly different in their in their characteristics in terms of harmony.",
                    "label": 0
                },
                {
                    "sent": "How, for example, the data is distributed across across properties.",
                    "label": 0
                },
                {
                    "sent": "They are also very clear efficiency improvements that we haven't tried yet, so one is language detection.",
                    "label": 0
                },
                {
                    "sent": "One thing I notice is since since we're not doing tokenization properly for other languages for Japanese, for example, we consider entire entire values of literals as a single vert and of course blows up the dictionary because large pieces of Japanese text now become a single term.",
                    "label": 0
                },
                {
                    "sent": "So we should either do language detection or or actually proper tokenization in different languages and other techniques that we haven't tried yet.",
                    "label": 0
                },
                {
                    "sent": "So for example, pushing some of the sorting into into the map phase.",
                    "label": 0
                },
                {
                    "sent": "So, so that's so much for now, and I'm open for questions or comments if someone has related experiences with indexing using product, thank you.",
                    "label": 0
                },
                {
                    "sent": "Very bad, very bad.",
                    "label": 0
                },
                {
                    "sent": "So yeah, I given the time after Rush but this is basically the number of queries so overtime right?",
                    "label": 0
                },
                {
                    "sent": "So we should 4300 queries right?",
                    "label": 0
                },
                {
                    "sent": "And measure the performance overtime.",
                    "label": 0
                },
                {
                    "sent": "So just to just to look if there is there is any.",
                    "label": 0
                },
                {
                    "sent": "In effect on the.",
                    "label": 0
                },
                {
                    "sent": "On the depending on number of queries.",
                    "label": 0
                },
                {
                    "sent": "And the Y axis is time.",
                    "label": 0
                },
                {
                    "sent": "So about the post fixing, how can you go back to the slide where you described the post fixing?",
                    "label": 0
                },
                {
                    "sent": "How if I want all the properties for Peter?",
                    "label": 0
                },
                {
                    "sent": "How do I get them?",
                    "label": 0
                },
                {
                    "sent": "You want all the all the properties for Peter.",
                    "label": 0
                },
                {
                    "sent": "You cannot get that, so you cannot get it with any of these index structures, right?",
                    "label": 0
                },
                {
                    "sent": "So that's a query for which you would need to build a different index.",
                    "label": 0
                },
                {
                    "sent": "May have one more.",
                    "label": 0
                },
                {
                    "sent": "Sorry, one more question, sure.",
                    "label": 0
                },
                {
                    "sent": "So in the table where you show the times in the number of Maps in map number of video sis, do you know what was the time for the longest map and the longest reduce?",
                    "label": 0
                },
                {
                    "sent": "This would give us an indication of how paralyzable this index making case.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so I didn't go into detail, but actually measuring execution time on Hadoop is almost impossible.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I know.",
                    "label": 0
                },
                {
                    "sent": "In the latest version they they report something called slots Maps, Millis and slots Reduce Millis, which is the average.",
                    "label": 0
                },
                {
                    "sent": "No, it's the total execution time of all of the Maps that that are executing.",
                    "label": 0
                },
                {
                    "sent": "Now you can divide it by the number of Maps and by that you can get an average time per map or produce the total time depends on a lot of things because we're using speculative execution.",
                    "label": 0
                },
                {
                    "sent": "For example, if you speculative execution.",
                    "label": 0
                },
                {
                    "sent": "Then of course it starts new Maps.",
                    "label": 0
                },
                {
                    "sent": "It kills them right beside that it doesn't need them anymore, so it becomes a lot more lot more complicated.",
                    "label": 0
                },
                {
                    "sent": "So the longest map you can use as an approximation of how long it would take if you would have an infinite number of processors.",
                    "label": 0
                },
                {
                    "sent": "So, or at least as many as your Maps and as many as you reduce.",
                    "label": 0
                },
                {
                    "sent": "I would have to think about that, so I reported the real time which would give you an indication of of roughly how long things take in total.",
                    "label": 0
                },
                {
                    "sent": "That's better, that's that's true.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure.",
                    "label": 0
                },
                {
                    "sent": "OK, thanks just a small technical idea inspired by your talk.",
                    "label": 0
                },
                {
                    "sent": "Could you reduce SKU by century randomizing?",
                    "label": 0
                },
                {
                    "sent": "So if you had like the if you've got some words but you basically make it instead of be the sort of its dot 1.2, the three with some sort of random thing.",
                    "label": 0
                },
                {
                    "sent": "So then you're basically just partner making introducing a fine grained exist and these recovered emerge time indexing interesting.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah, we have to measure that whether that sufficient right.",
                    "label": 0
                },
                {
                    "sent": "You have to work harder than at query time and and less at indexing time.",
                    "label": 0
                },
                {
                    "sent": "Yeah no, you don't work hard at query time 'cause you can then once once you've done your reduce you can then do next pass and merge it back.",
                    "label": 0
                },
                {
                    "sent": "Oh, I see it's no different, query just enables more parallelism.",
                    "label": 0
                },
                {
                    "sent": "And then yeah.",
                    "label": 0
                },
                {
                    "sent": "OK, let's thank you.",
                    "label": 0
                }
            ]
        }
    }
}