{
    "id": "zde4kuhnxh43zugdniiwldugu5cn2foo",
    "title": "Time Dependent Stick Breaking Processes",
    "info": {
        "author": [
            "Jim Griffin, University of Kent"
        ],
        "published": "Aug. 4, 2008",
        "recorded": "July 2008",
        "category": [
            "Top->Computer Science->Machine Learning->Bayesian Learning"
        ]
    },
    "url": "http://videolectures.net/icml08_griffin_tds/",
    "segmentation": [
        [
            "OK so I just like to thank the organizers for inviting me and for putting together a really interesting program.",
            "So this is some joint work with.",
            "Mark steel at the.",
            "At the University of Warwick.",
            "How do I workout how to use it?"
        ],
        [
            "OK, so this is the outline of what I'm going to be talking about, so I'm going to give a brief introduction about how we might think about building nonparametric processes when the thing that we're interested in making inference about is distributions that change overtime.",
            "So I kind of give a brief introduction to that and talk about a fairly simple kind of construction which turns out to be connected to the judicial process.",
            "Then I'll talk about how we might go about developing more general processes, and in that case we can develop a process which is related to the plus under each day or the Pitman yor process which people have used as an alternative to the jury selection process.",
            "And then I'll look at some examples.",
            "A couple of examples from Accona metrics.",
            "And at the end I'll just make a few comments about."
        ],
        [
            "What we do?",
            "So the idea is that we want to flexibly model a distribution that changes overtime.",
            "And So what we imagine we observe is a whole series of observations which are drawn from those distributions of various different time points.",
            "So the observations will be wise.",
            "Wine up to YN, and the time it will be T1 up to TN, and so one way to go about modeling that.",
            "Would be to extend the idea of infinite mixture models so people often using mixture density estimation and so at least one way in which we might build an infinite mixture model that varies overtime, is to think of the components as kind of fixed.",
            "So in the mean for the mixture model we have components and have weights.",
            "And so one thing we might do is to fix the components.",
            "The positions of our kind of normal kernels or or whatever we're using in our infinite mixture model to make things kind of continuous to allow the weights to change overtime, and so that's what we're doing here.",
            "So we can write it in terms of this way in terms of an integral with respect to this distribution, FTI.",
            "And all that means is that we have some weights which are given by this discrete distribution F. Is white they're changing with respect to TI, so that's the basic idea.",
            "And so that's a fairly general structure, and something that a lot of people have looked at.",
            "Ask you really also using time and date and dictation.",
            "I'm getting on it right choice so I do think there's something that'll be great again.",
            "In the same stuff.",
            "Anne.",
            "I think.",
            "In terms of perhaps the types of things we're going to be looking at, I think it is perhaps is natural in the sense that we're not observing, kind of.",
            "Along to tune your data, we're observing observations.",
            "But I think there is an arbitrariness to it.",
            "So we could allow the weights, for example to stay the same and allow.",
            "These things often being normals to be kind of Gaussian processes, for example, and then we would have something some other type of structure.",
            "Um?",
            "I think at least one nice thing about doing it this way is that if we kind of look infinitely far into the future.",
            "Then ultimately, what will happen is if we construct it kind of in a sensible way, the weights that we see at a particular time now will be go will go to zero as we go infinitely far into the future.",
            "Whereas if we kind of have Gaussian processes here, these weights will stay the same for all eternity, and it may be that.",
            "We don't want that because when we learn about things now, maybe we don't want that to influence.",
            "What we think about things in the future.",
            "I'm."
        ],
        [
            "So.",
            "There's a number of ways defining this FT, and So what people usually do is to think about generalizing kind of standard constructions, standard representations of the jury, say process.",
            "And looking at how in some way you can introduce time into that.",
            "And so there's a number of different ways that we could go about doing that.",
            "So perhaps the most attractive way is to think about the polirone scheme representation.",
            "So the Chinese restaurant algorithm type representation of the jury say process.",
            "Then that has a very nice form in the sense that.",
            "The whites in our polirone scheme are related to the number of observations that we've already seen in that cluster.",
            "And so we can imagine why ease of allowing that to change with time, and so there's a few kinds of examples in the literature, and I think there's another example.",
            "Someone's giving a talk later in this section about how we might go and do that.",
            "Yeah, so we might also think about it that reshape process in terms of a normalized random measure an so we can think about building random measures that change overtime.",
            "But what I'm going to look at today is to think about having using the stick breaking representation, so that is kind of a nice representation in terms of the fact that we have a sequence of independent things that we transform into a distribution.",
            "And so that makes it easy to work with.",
            "And in this case, I think it has it arises rather as a as a kind of natural type of model for time dependent distribution."
        ],
        [
            "So just to kind of.",
            "Review on the stick breaking processes, so I think a lot of people here would have seen this type of thing before, but this is just to kind of go over it.",
            "So the idea is that our distribution F. It is.",
            "So kind of the distribution F which is related to the weights of each component that has this infinite representation here in terms of a series of weights WJ place that positions the to J.",
            "And the particular thing about the stick breaking construction that gives this name is the way that we construct these weights.",
            "So the WJ is equal to Vijay times this product.",
            "So if we think about the first weight, the first weight is V1.",
            "And then we look at the remainder, which is 1 -- V one and multiply that by another hour V V2 to get a second wait.",
            "We get V 2 * 1 -- V one, and So what we have is that always the remainder that we have has this form here and then we just divide the remainder by something BJ which is between zero and one and beta distributed.",
            "That's this idea that we take a stick and slowly we break off bits to get our weights.",
            "That means the weights are in some way ordered.",
            "They're ordered in terms of their expected value.",
            "So we assume that the V1 up to V3 are independent and that potentially in its most general form, that the VJS come from a beta distribution with parameters AJ and BJ.",
            "Adjust the theater one at the well.",
            "This infinite sequences of feet as they just IID draws from some distribution H."
        ],
        [
            "So there's a few examples that reset process arises as a very simple case.",
            "So if we want to process with concentration parameter N, then that means that the VJS are beta distributed with parameters one and M. So the parameters don't depend on this index J.",
            "And the person to reach die or Pitman Yor process arises if the VJS have this form here.",
            "So we have a beta 1 -- B Now.",
            "So and we have a parameter M plus BJ here.",
            "So this allows kind of more general shape because of course it includes the Doris Day process.",
            "As a subcase, when B is equal to 0."
        ],
        [
            "So one way to build to think about building time dependent random measures would be to think about how we might go about defining a random walk on discrete distributions.",
            "And so if we just think about defining a random walk.",
            "On just real valued observations, this kind of random what we can think of then.",
            "One way that we construct it is in terms of thinking that the next observation YT plus one.",
            "Is normally distributed around our current observation, Whitey with some variance Sigma squared, so that's one way that we can come up with a random walk and the 2nd way is to think of it in exactly the same of course, but think of it in a slightly different way that YT plus one is our previous observation plus some kind of innovation which we call epsilon T. These two things are equivalent.",
            "But when we come to thinking about random distributions, if we if we kind of think about perhaps natural analogs won that round log would be to make FT plus one beer each day process.",
            "So this tree shape process will be centered around FT. And we would use them to control the variability.",
            "Come in will play the same role as Sigma squared.",
            "That would be down log of this one here.",
            "The analogue of this one would be the FT plus one is FT plus some innovation, but because these distributions we can't just take FT plus some innovation.",
            "We have to take a weighted sum of our current distribution and innovation.",
            "Epsilon T. In order for FT plus one to be a distribution itself, so we can justify and weights BT and 1 -- V T. In order to define FT plus one.",
            "And so, of course, this isn't kind of well, it is a bit like a random walk, but this was a bit like an autoregressive process because we have this parameter here which is multiplying FT. And so in discrete distributions these two things are kind of pretty different actually.",
            "Because what happens is that in this case, as.",
            "If we were to look at this process conditioning on the value of FT and look at it as we go through time into the future.",
            "Then this kind of construction will lead to a distribution that generates to a single point a single Atom with all the mass.",
            "And that's rather like people are familiar with particle filtering.",
            "You get a similar problem in particle filtering that if you kind of particle filter a lot and you keep selecting in the end, you would end up with one Atom.",
            "And the way that people go about getting around that in particle filtering is the idea that they introduced new randomness at every time point.",
            "And so this kind of construction is a little bit like that at every time point we potentially entry into ring.",
            "Sorry, introducing a new part of the distribution epsilon T. And So what I'm trying to argue is that this is a more natural kind of construction than this construction here.",
            "And so I'll concentrate on building models.",
            "In a way using this idea.",
            "Right?",
            "Yeah, so you mean that this thing would be some compromise?",
            "This would be DfT.",
            "Basement.",
            "Yeah, so basically that's what this thing is doing.",
            "So epsilon T will be related to the base measure.",
            "Right, so you could combine the two you mean they put this in here.",
            "Basically and then yeah, then you could combine the two and you would have.",
            "Then you would have something almost like a hierarchical to reset process.",
            "I think so then you would have an extra.",
            "Maybe I'm misunderstanding what you're saying.",
            "What will?",
            "Yeah.",
            "Under a influence of sort of hold.",
            "Hi.",
            "Yeah.",
            "It may be useful to have.",
            "Depends on the actual video.",
            "Yeah, so so yeah, so that's that's true and we can do something a bit like that so we can have processes with that decay changes.",
            "So that would be, but we do it in a slightly different way, perhaps to the way that you were talking about.",
            "So that's interesting what you're saying."
        ],
        [
            "I'm OK.",
            "So, um.",
            "So if our epsilon TR innovation were to just be a single Atom at a point V to T. Then RFT is going to have this form here.",
            "Be cause essentially we just multiply by by Vt and then we also multiply by 1 -- v T. So if we look at."
        ],
        [
            "If we look at this kind of thing here, and if we look at F T + 1 and that's going to be Vt times kind of.",
            "The.",
            "But 1 -- V T times the innovation and then FTF T + 1 in terms of FT lefty we can write in this way again and so we're going to FT is going to be tee times 1 -- B T minus one and epsilon T -- 1 and we keep having this structure like."
        ],
        [
            "That and so.",
            "Naturally this defines a kind of stick breaking process.",
            "So here we have the phone with the stick breaking process, where rather than thinking just about breaking the stick, we're thinking about now for a time point T and then we just count backwards through time.",
            "I'm going backwards through time.",
            "We we break the stick according to the Vis that we come across going backwards in time.",
            "And so that's a natural way to think about generating the jury.",
            "Say the break is generating a stick breaking process.",
            "But that type of structure is a little bit inflexible because what we're doing is we're introducing innovations one at a time, every time point.",
            "And so it may be that we don't really want to do that, because it may be that either our process.",
            "Isn't changing very quickly overtime and so we don't want to always be introducing new randomness becausw the way that this process is constructed.",
            "Those points will arrive at the start of our stick breaking process, so they will tend to have new innovations.",
            "Will tend to have large weights, and that's kind of an important.",
            "Point about this type of construction and this type of process.",
            "And it may be that we want to introduce more than one Atom at a particular time point, because our process is changing very quickly with time, and so one way to do that is to assume that rather than these new atoms arriving just constantly in time.",
            "That we assume that they arrive according to Opossum process.",
            "So I'll pass on process is the simplest type of point process overtime say.",
            "And that allows us to have something rather more flexible and kind of rather more sensible."
        ],
        [
            "And so, as I was saying earlier, the simplest type of construction like that is what we call the DPA are so that reshape process our process.",
            "And so one of the nice properties of this type of construction generating this type of stick breaking process through time is that we can try and think about controlling the marginal marginal process.",
            "So our marginal process is stick breaking.",
            "And so at anytime point we can think about how FT is generated.",
            "And so FT is generated from.",
            "Yes, we can then think about how we can control the process to have particularly given marginals at time FT.",
            "Through different values of take.",
            "So.",
            "This is our infinite kind of mixture model.",
            "So we have whites and we have features and so the weights.",
            "Given by the J, that's the way associated with the J Tatum, and then we just need to find out how many atoms are between that or are these points of this point process that we've introduced?",
            "So the J Tatum is introduced to time Tor J and we just need to find how many atoms are between time T Ant or J and that's the number of breaks that we have before.",
            "Vijay in our stick breaking process backwards in time.",
            "So for those to restate process construction V1 up to the air, well these are just from a beta 1M.",
            "These follow Opossum process with intensity Lambda and the theaters once again are drawn from just some base measure H. Yeah.",
            "Construction will.",
            "Make the distribution tab jumps, yeah?",
            "Yeah.",
            "Yeah yeah, that's the construction, so it's a little bit like kind of change point models or switching type models, yeah?",
            "Guys.",
            "No, no, there's an infinite mixture, so an infinite number of these are sorry.",
            "Yeah.",
            "So an infinite number of zero and infinite number are nonzero.",
            "So from my sorry sorry this should go from minus Infinity.",
            "Well now it goes from one to Infinity, but these are these are arriving according to this person process or minus Infinity to Infinity.",
            "So there's an infinite number between minus Infinity and T on that into.",
            "OSC will vary overtime this, but the marginal process safety will be drawn from additional process.",
            "But appointment.",
            "He yeah.",
            "Ask the same right like this.",
            "Yeah, so you don't need that.",
            "Doesn't really matter.",
            "You can make Lambda being homogeneous.",
            "It wouldn't.",
            "This thing is just it doesn't matter.",
            "Actually, as long as well, especially as long as you subordinate it in a proper way then this will always substantially as long as you have some increasing process that defines the tours then this thing will always be to reset process.",
            "Traffic.",
            "Yeah.",
            "Yeah, that's what happens in this case.",
            "So we can, yeah, so that's what happens in this case, and we could do.",
            "Other."
        ],
        [
            "Laws as well.",
            "So this is just a kind of little graphic of how the process works.",
            "So this is the process at time T0.",
            "This is the processor time T1 and so.",
            "In this case we have three increments, so this is the time that they're introduced.",
            "This is our tour, and this is the V and then the numbers here are the values of Theta that we have.",
            "So we have one introduced very close to time, one with the value of feature of North Point 9 seven, and that has quite a big fee and you can see that is this mask that gets introduced here.",
            "A.",
            "So.",
            "Then we have two masses introduced here, one at no.",
            ".115.",
            "At that point there for that.",
            "We have another one at No 9 seven and for that gets in there so our other ones here get shrunken.",
            "This one seems to have disappeared.",
            "Not quite sure why that happened.",
            "There should be a little bit of math here."
        ],
        [
            "And so as we move from kind P = 1 time T = 2, then we can see that this seems to work better because this one and this one.",
            "They've all been shrunken a little bit.",
            "And then we've introduced new masses at .8 six, 1.56.",
            "And so the .561 is bigger.",
            "It has a slightly larger V, and so that's the .561 and the .861.",
            "So our distribution is just going through time drawing these kind of increment distributions.",
            "If you think about it in discrete time and then we're getting new distributions just by reweighting these and introducing new atoms."
        ],
        [
            "And so the properties of this thing is that the FT in this case will be at the recently process marginally at every time point with concentration parameter M and base measure H. So we have some idea that this process is kind of stationary.",
            "And filter correlation has kind of a nice form for the auto correlation doesn't depend on the set B.",
            "And it has this kind of exponential form.",
            "Where it just depends on this ratio here.",
            "Ratio depending on the intensity of the pass on process and the concentration parameter, and it's just decaying exponentially overtime."
        ],
        [
            "So one thing that we can do is to is to roll.",
            "This is the representation is kind of useful, but it would be nice to have a finite representation.",
            "By that I mean in the Chinese restaurant algorithm we just have to worry about the clusters that have had points allocated to them and also the probability of generating a new point, and so that's very useful for computation, because then we always have a finite.",
            "A mixture model.",
            "And So what we can do here is, of course the Chinese wrecked Ronnies restaurant algorithm.",
            "It's about generating exchangeable processes for.",
            "This process is not exchangeable because we now have this type of information.",
            "And what we what we can do is to integrate over those atoms which don't have any points allocated to them in our mixture to get this finite representation.",
            "In order to do that, it's useful to have.",
            "What we call the non active set at time are so that just counts the number of points if we look at time are this counts the number of points which could be allocated to a cluster at time?",
            "Are they for which TJ is greater than our?",
            "But which for all the observable which haven't been allocated to that point?",
            "So Tor, SJ.",
            "So this is kind of the allocation observation.",
            "So the allocation is the thing that we're building.",
            "the Chinese restaurant algorithm on.",
            "So we can look at all the ones that we've seen so far and see which ones could have been allocated to a point at time are or which weren't, and which were allocated at a time before.",
            "We also have this MJ which counts the number of observations that have been allocated to the J cluster.",
            "So Tor N is going to be the times at which we observe these.",
            "Clusters and we're going to define SN to be equal to Turin and all the times that we've observed the T1 up to TH.",
            "Videos are just implying or attempting to make sense.",
            "No, no.",
            "So this is counting over the observations that I've observed, so I look at all the observations up to time in they've been allocated to times.",
            "So I'm a new point T. They've all been allocated times here say and then my active set is telling me OK from before.",
            "So if it if an observation has been introduced at time T, it's allocated at time T1.",
            "There could be a load of points in between to which it hasn't been allocated, and so the active set counts.",
            "Basically, how many haven't been allocated appointee, so it looks at this interval between TI and Tor SJC.",
            "And counts so the maximum value you can get for the active cities is dead.",
            "Ha.",
            "OK."
        ],
        [
            "And so, um.",
            "We can then think about kind of the equivalent of a Chinese restaurant algorithm is to think about having this type of thing, so we can either allocate our new observation to tables to these points here.",
            "Or we can come up with a new table.",
            "By introducing the table either in this time period here, this time period here, this time period here.",
            "And so the probabilities of these various things happening.",
            "They inherit this stick breaking structure that we had before.",
            "So the points the probability being allocated into this interval is 1 minus this C0.",
            "And so Co. We can think about in terms of row.",
            "Here is the correlation.",
            "The auto correlation.",
            "So E to the minus Lambda divided by N + 1.",
            "If we don't allocate there, if we have seen ought, then we have one minus the one which is the probability of allocating here.",
            "So this thing is wrong actually.",
            "So this thing should be M plus this should be.",
            "This part should be on the numerator.",
            "There should be N + a town J.",
            "So 1 -- D One is this one minus die.",
            "Is this thing here?",
            "So the probability of being allocated to this observation here is proportional to this thing here times by 1 minus this thing.",
            "And then we can carry on doing that.",
            "Using these particular weights, of course, once we get to a point where there's going to be some point, some minimum value of Tor for which we after which we have no points allocated to values of the time.",
            "And then we have some kind of tail value to see, but we can work out all these things and there's only going to be a finite number of them.",
            "The useful thing is that it only depends on this value row here.",
            "So for example, if Rovers won all these seas.",
            "All these seas would be.",
            "1.",
            "So anyway, so it depends on this value row, and so the larger the value of row, the less likely.",
            "We are to see things in this interval here, and that's kind of make sense because we think things are more correlated and so they're changing less overtime, and so there's more chance that we get points allocated to clusters along time in the past as we increase the correlation.",
            "And as we decrease the correlation, we tend to see things very close to T. Well, at least we get high correlation and so then we tend to see points along time in the past.",
            "But the probabilities that we allocate are here are.",
            "Depend on the size of the clusters.",
            "So.",
            "It's slightly different from the Chinese restaurant algorithm, but you can generate the Chinese restaurant algorithm from the stick breaking process and this kind of arises as an intermediate step where we rather than just thinking about the tables as purely exchangeable.",
            "We think about the tables in terms of where they come in the stick breaking construction."
        ],
        [
            "OK, so.",
            "So we can think about the distribution of a new point.",
            "So if we have a new point drawn in some interval, then the value of the new point is going to be exponentially distributed.",
            "And truncated to be in this interval with the parameter that depends on the value of Lambda, Ann and the sizes of these active sets."
        ],
        [
            "So kind of very quickly if we want to extend beyond that reached a process to have other types of marginal process, then we're going to have to have some way of allowing the distribution of the vis to change overtime because the positions of our atoms in the stick breaking process of say FT as T changes that position and we introduce new atoms, that position is going to be moving further and further.",
            "Back and since the for things like the Prasanta reached a process, that distribution depends on the value of J, then we need to define a stochastic process for the vis to allow them to change overtime."
        ],
        [
            "And so in the more the part will be called a pie.",
            "I am so we can put any type of marginal process here.",
            "Essentially that has stick breaking form.",
            "Then the only difference from before when we had the DPR is that now we allow these vis to depend on time.",
            "So we have completely the same construction.",
            "But these are allowed to depend on time."
        ],
        [
            "And we can construct that in quite a simple way.",
            "So if we have so our eyes in our stick breaking construction, we have an infinite sequence of days, an infinite sequence of bees.",
            "And so if we have a nondecreasing sequence.",
            "Then then we can kind of come up with this nice structure.",
            "We can do it for any type of sequence of Asian bees, but for the non decreasing one it has this kind of mixture representation again that we take a weighted sum of our previous value of the and and innovation.",
            "And so the weights have these particular forms.",
            "Here is that guarantees that Vijay is always distributed beta AJ BJ this is a nice form for computation because we have a mixture.",
            "And we know generally how to deal with."
        ],
        [
            "Mixtures.",
            "So further press under each lay.",
            "For that particular case being simplified.",
            "Because."
        ],
        [
            "The eyes are fixed are constant.",
            "So this difference here becomes zero, and so epsilon itself becomes is always zero, and so we just have this part here.",
            "So Vijay plus one is equal to WJ times feed."
        ],
        [
            "I.",
            "And so we can just write the VJS in terms of this.",
            "Infinite sorry this this finite product of terms.",
            "And so this guarantees that all the VJS are correct for the Apostle for each day."
        ],
        [
            "We can see a little bit here.",
            "The impact of having different values of B.",
            "So B = 0.",
            "Is that reached a process?",
            "And so as B increases, this is becoming increasingly unlike after each day process and So what we have here is suppose we draw 20 observations from our process and condition on the fact that we have C clusters, so 2, four or eight clusters.",
            "What is the probability?",
            "What if we were to draw 20 at the next time point?",
            "What is the?",
            "What is the number of clusters we would have?",
            "That's kind of giving us some idea of the dependence that is generated through these processes in terms of the number of clusters we see at one time point and the number of clusters that we see at another time point.",
            "And So what we can see is that as we increase this parameter, the right hand tail of its distribution is getting longer.",
            "So here we are, conditioned on having two Tier 2 clusters at particular time and then at the next time this is the kind of number and so influence of the number of clusters we see at a particular time is kind of decreasing.",
            "As we increase this parameter B.",
            "And so that's kind of one way of thinking about what we gain in terms of going from the drishtee process to pass on to reset process in this type of MoD."
        ],
        [
            "So.",
            "In terms of computation, we can extend the ideas of the retrospective sampler developed by purposefully Opulus Ann Roberts.",
            "For the person to reach the IRL process.",
            "The main problem is that we don't really have a standard stick breaking type of construction because our way asked.",
            "Stick breaks themselves made up of a product.",
            "But what we can do is we can use.",
            "A trick developed by David Dunson and some other people for matrix stick breaking processes that allow us to do that efficiently."
        ],
        [
            "So I just want to go quickly through a couple of examples.",
            "So one example is stochastic volatility models, so we assume that our observations are the daily returns.",
            "The difference in the log prices of an index, and we assume that really the interesting thing is that variance that we can write that as a normal times and variance, and we assume that the variance itself follows an AR process.",
            "And we're going to assume that this distribution here is the thing that we're interested in modeling, as this time varying infinite mixture model.",
            "So that's kind of this return distribution."
        ],
        [
            "This is the data.",
            "This is the standard and poors index.",
            "Are the early 80s up to 1988 including?",
            "The big crash in 80."
        ],
        [
            "88"
        ],
        [
            "Yeah, so this thing.",
            "We don't have an intercept.",
            "So in a standard SVM model, we would have an intercept, so we can.",
            "Kind of identified."
        ],
        [
            "Some sense that way.",
            "And so this is what we get if we try and fit the model to that data.",
            "This is a heat plot of the density overtime, and these are the values of the density and so you can see we have these various different periods where the volatility the distribution is roughly constant and then we have periods where it gets very large.",
            "And here when we have the crash it gets very wide indeed."
        ],
        [
            "Where is the results?",
            "These are some plots of various time points taken from that graph to show you kind of the differences in shape that we get.",
            "So we get something that has heavier tails than a normal and here we get a little bit of kind of Biome."
        ],
        [
            "Dalati and if we were to look at the variance of the predictive distribution overtime, then we would see that that is changing like this.",
            "And so we can see that roughly what this is telling us is that the way that the volatility model is falling down.",
            "Is that?",
            "Essentially, the kind of long run average.",
            "Of the volatility, the variance of our return distribution is non constant.",
            "And that should be allowed to change overtime.",
            "And so that's not an unusual thing for people to think in financial modeling.",
            "That that thing is."
        ],
        [
            "Constant.",
            "The second example, he looks at the rule.",
            "Per capita GDP taking logs over 110 EU regions from 1977 to 1996, and so these are.",
            "Density estimates for each of those years using a mixture of Theresa May process model doing that independently for each of the different years.",
            "And so you can see we have kind of a variety of different shapes.",
            "It's a bit unclear or these go."
        ],
        [
            "No.",
            "So if we use this DPA, our model and what we find roughly is that we have two periods, one period pre 1988 and one period post 1988 or in the shape of the distribution."
        ],
        [
            "Changing and so these are the density estimates.",
            "Using this model for the different years and you can see that they are roughly the same well, but there's two different groups essentially, and that they're roughly the same within each group."
        ],
        [
            "And so if we look at.",
            "The independent density estimates that we had at the start.",
            "Then these are the two groups throughout kind of identified one in green and one in blue, and you can see that roughly the shapes are kind of rather similar.",
            "For this.",
            "The green.",
            "Which is the later period and for the blue period, which is the early pick."
        ],
        [
            "So this is what I talked about.",
            "We can develop these \u03c0 R processes which will work for a wide range of marginal big breaking processes.",
            "For the DPR we can develop a kind of Chinese restaurant type representation which may be useful both for MCMC methods and for non MCMC methods like the the.",
            "The Heller and Ghahramani type methods for agglomerative clustering.",
            "And the process defines a jump process on probability measures and therefore it is quite useful at finding change points in distribution.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK so I just like to thank the organizers for inviting me and for putting together a really interesting program.",
                    "label": 0
                },
                {
                    "sent": "So this is some joint work with.",
                    "label": 0
                },
                {
                    "sent": "Mark steel at the.",
                    "label": 0
                },
                {
                    "sent": "At the University of Warwick.",
                    "label": 1
                },
                {
                    "sent": "How do I workout how to use it?",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so this is the outline of what I'm going to be talking about, so I'm going to give a brief introduction about how we might think about building nonparametric processes when the thing that we're interested in making inference about is distributions that change overtime.",
                    "label": 0
                },
                {
                    "sent": "So I kind of give a brief introduction to that and talk about a fairly simple kind of construction which turns out to be connected to the judicial process.",
                    "label": 0
                },
                {
                    "sent": "Then I'll talk about how we might go about developing more general processes, and in that case we can develop a process which is related to the plus under each day or the Pitman yor process which people have used as an alternative to the jury selection process.",
                    "label": 1
                },
                {
                    "sent": "And then I'll look at some examples.",
                    "label": 0
                },
                {
                    "sent": "A couple of examples from Accona metrics.",
                    "label": 0
                },
                {
                    "sent": "And at the end I'll just make a few comments about.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What we do?",
                    "label": 0
                },
                {
                    "sent": "So the idea is that we want to flexibly model a distribution that changes overtime.",
                    "label": 0
                },
                {
                    "sent": "And So what we imagine we observe is a whole series of observations which are drawn from those distributions of various different time points.",
                    "label": 1
                },
                {
                    "sent": "So the observations will be wise.",
                    "label": 0
                },
                {
                    "sent": "Wine up to YN, and the time it will be T1 up to TN, and so one way to go about modeling that.",
                    "label": 0
                },
                {
                    "sent": "Would be to extend the idea of infinite mixture models so people often using mixture density estimation and so at least one way in which we might build an infinite mixture model that varies overtime, is to think of the components as kind of fixed.",
                    "label": 0
                },
                {
                    "sent": "So in the mean for the mixture model we have components and have weights.",
                    "label": 0
                },
                {
                    "sent": "And so one thing we might do is to fix the components.",
                    "label": 0
                },
                {
                    "sent": "The positions of our kind of normal kernels or or whatever we're using in our infinite mixture model to make things kind of continuous to allow the weights to change overtime, and so that's what we're doing here.",
                    "label": 1
                },
                {
                    "sent": "So we can write it in terms of this way in terms of an integral with respect to this distribution, FTI.",
                    "label": 0
                },
                {
                    "sent": "And all that means is that we have some weights which are given by this discrete distribution F. Is white they're changing with respect to TI, so that's the basic idea.",
                    "label": 0
                },
                {
                    "sent": "And so that's a fairly general structure, and something that a lot of people have looked at.",
                    "label": 0
                },
                {
                    "sent": "Ask you really also using time and date and dictation.",
                    "label": 0
                },
                {
                    "sent": "I'm getting on it right choice so I do think there's something that'll be great again.",
                    "label": 0
                },
                {
                    "sent": "In the same stuff.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "I think.",
                    "label": 0
                },
                {
                    "sent": "In terms of perhaps the types of things we're going to be looking at, I think it is perhaps is natural in the sense that we're not observing, kind of.",
                    "label": 0
                },
                {
                    "sent": "Along to tune your data, we're observing observations.",
                    "label": 0
                },
                {
                    "sent": "But I think there is an arbitrariness to it.",
                    "label": 0
                },
                {
                    "sent": "So we could allow the weights, for example to stay the same and allow.",
                    "label": 0
                },
                {
                    "sent": "These things often being normals to be kind of Gaussian processes, for example, and then we would have something some other type of structure.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "I think at least one nice thing about doing it this way is that if we kind of look infinitely far into the future.",
                    "label": 0
                },
                {
                    "sent": "Then ultimately, what will happen is if we construct it kind of in a sensible way, the weights that we see at a particular time now will be go will go to zero as we go infinitely far into the future.",
                    "label": 0
                },
                {
                    "sent": "Whereas if we kind of have Gaussian processes here, these weights will stay the same for all eternity, and it may be that.",
                    "label": 0
                },
                {
                    "sent": "We don't want that because when we learn about things now, maybe we don't want that to influence.",
                    "label": 0
                },
                {
                    "sent": "What we think about things in the future.",
                    "label": 0
                },
                {
                    "sent": "I'm.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "There's a number of ways defining this FT, and So what people usually do is to think about generalizing kind of standard constructions, standard representations of the jury, say process.",
                    "label": 1
                },
                {
                    "sent": "And looking at how in some way you can introduce time into that.",
                    "label": 0
                },
                {
                    "sent": "And so there's a number of different ways that we could go about doing that.",
                    "label": 0
                },
                {
                    "sent": "So perhaps the most attractive way is to think about the polirone scheme representation.",
                    "label": 0
                },
                {
                    "sent": "So the Chinese restaurant algorithm type representation of the jury say process.",
                    "label": 1
                },
                {
                    "sent": "Then that has a very nice form in the sense that.",
                    "label": 0
                },
                {
                    "sent": "The whites in our polirone scheme are related to the number of observations that we've already seen in that cluster.",
                    "label": 0
                },
                {
                    "sent": "And so we can imagine why ease of allowing that to change with time, and so there's a few kinds of examples in the literature, and I think there's another example.",
                    "label": 0
                },
                {
                    "sent": "Someone's giving a talk later in this section about how we might go and do that.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so we might also think about it that reshape process in terms of a normalized random measure an so we can think about building random measures that change overtime.",
                    "label": 0
                },
                {
                    "sent": "But what I'm going to look at today is to think about having using the stick breaking representation, so that is kind of a nice representation in terms of the fact that we have a sequence of independent things that we transform into a distribution.",
                    "label": 0
                },
                {
                    "sent": "And so that makes it easy to work with.",
                    "label": 0
                },
                {
                    "sent": "And in this case, I think it has it arises rather as a as a kind of natural type of model for time dependent distribution.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So just to kind of.",
                    "label": 0
                },
                {
                    "sent": "Review on the stick breaking processes, so I think a lot of people here would have seen this type of thing before, but this is just to kind of go over it.",
                    "label": 0
                },
                {
                    "sent": "So the idea is that our distribution F. It is.",
                    "label": 0
                },
                {
                    "sent": "So kind of the distribution F which is related to the weights of each component that has this infinite representation here in terms of a series of weights WJ place that positions the to J.",
                    "label": 0
                },
                {
                    "sent": "And the particular thing about the stick breaking construction that gives this name is the way that we construct these weights.",
                    "label": 0
                },
                {
                    "sent": "So the WJ is equal to Vijay times this product.",
                    "label": 0
                },
                {
                    "sent": "So if we think about the first weight, the first weight is V1.",
                    "label": 0
                },
                {
                    "sent": "And then we look at the remainder, which is 1 -- V one and multiply that by another hour V V2 to get a second wait.",
                    "label": 0
                },
                {
                    "sent": "We get V 2 * 1 -- V one, and So what we have is that always the remainder that we have has this form here and then we just divide the remainder by something BJ which is between zero and one and beta distributed.",
                    "label": 0
                },
                {
                    "sent": "That's this idea that we take a stick and slowly we break off bits to get our weights.",
                    "label": 0
                },
                {
                    "sent": "That means the weights are in some way ordered.",
                    "label": 0
                },
                {
                    "sent": "They're ordered in terms of their expected value.",
                    "label": 0
                },
                {
                    "sent": "So we assume that the V1 up to V3 are independent and that potentially in its most general form, that the VJS come from a beta distribution with parameters AJ and BJ.",
                    "label": 1
                },
                {
                    "sent": "Adjust the theater one at the well.",
                    "label": 0
                },
                {
                    "sent": "This infinite sequences of feet as they just IID draws from some distribution H.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So there's a few examples that reset process arises as a very simple case.",
                    "label": 0
                },
                {
                    "sent": "So if we want to process with concentration parameter N, then that means that the VJS are beta distributed with parameters one and M. So the parameters don't depend on this index J.",
                    "label": 1
                },
                {
                    "sent": "And the person to reach die or Pitman Yor process arises if the VJS have this form here.",
                    "label": 1
                },
                {
                    "sent": "So we have a beta 1 -- B Now.",
                    "label": 0
                },
                {
                    "sent": "So and we have a parameter M plus BJ here.",
                    "label": 0
                },
                {
                    "sent": "So this allows kind of more general shape because of course it includes the Doris Day process.",
                    "label": 0
                },
                {
                    "sent": "As a subcase, when B is equal to 0.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So one way to build to think about building time dependent random measures would be to think about how we might go about defining a random walk on discrete distributions.",
                    "label": 1
                },
                {
                    "sent": "And so if we just think about defining a random walk.",
                    "label": 1
                },
                {
                    "sent": "On just real valued observations, this kind of random what we can think of then.",
                    "label": 0
                },
                {
                    "sent": "One way that we construct it is in terms of thinking that the next observation YT plus one.",
                    "label": 0
                },
                {
                    "sent": "Is normally distributed around our current observation, Whitey with some variance Sigma squared, so that's one way that we can come up with a random walk and the 2nd way is to think of it in exactly the same of course, but think of it in a slightly different way that YT plus one is our previous observation plus some kind of innovation which we call epsilon T. These two things are equivalent.",
                    "label": 0
                },
                {
                    "sent": "But when we come to thinking about random distributions, if we if we kind of think about perhaps natural analogs won that round log would be to make FT plus one beer each day process.",
                    "label": 0
                },
                {
                    "sent": "So this tree shape process will be centered around FT. And we would use them to control the variability.",
                    "label": 0
                },
                {
                    "sent": "Come in will play the same role as Sigma squared.",
                    "label": 0
                },
                {
                    "sent": "That would be down log of this one here.",
                    "label": 1
                },
                {
                    "sent": "The analogue of this one would be the FT plus one is FT plus some innovation, but because these distributions we can't just take FT plus some innovation.",
                    "label": 0
                },
                {
                    "sent": "We have to take a weighted sum of our current distribution and innovation.",
                    "label": 0
                },
                {
                    "sent": "Epsilon T. In order for FT plus one to be a distribution itself, so we can justify and weights BT and 1 -- V T. In order to define FT plus one.",
                    "label": 0
                },
                {
                    "sent": "And so, of course, this isn't kind of well, it is a bit like a random walk, but this was a bit like an autoregressive process because we have this parameter here which is multiplying FT. And so in discrete distributions these two things are kind of pretty different actually.",
                    "label": 0
                },
                {
                    "sent": "Because what happens is that in this case, as.",
                    "label": 0
                },
                {
                    "sent": "If we were to look at this process conditioning on the value of FT and look at it as we go through time into the future.",
                    "label": 0
                },
                {
                    "sent": "Then this kind of construction will lead to a distribution that generates to a single point a single Atom with all the mass.",
                    "label": 0
                },
                {
                    "sent": "And that's rather like people are familiar with particle filtering.",
                    "label": 0
                },
                {
                    "sent": "You get a similar problem in particle filtering that if you kind of particle filter a lot and you keep selecting in the end, you would end up with one Atom.",
                    "label": 0
                },
                {
                    "sent": "And the way that people go about getting around that in particle filtering is the idea that they introduced new randomness at every time point.",
                    "label": 0
                },
                {
                    "sent": "And so this kind of construction is a little bit like that at every time point we potentially entry into ring.",
                    "label": 0
                },
                {
                    "sent": "Sorry, introducing a new part of the distribution epsilon T. And So what I'm trying to argue is that this is a more natural kind of construction than this construction here.",
                    "label": 0
                },
                {
                    "sent": "And so I'll concentrate on building models.",
                    "label": 0
                },
                {
                    "sent": "In a way using this idea.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "Yeah, so you mean that this thing would be some compromise?",
                    "label": 0
                },
                {
                    "sent": "This would be DfT.",
                    "label": 0
                },
                {
                    "sent": "Basement.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so basically that's what this thing is doing.",
                    "label": 0
                },
                {
                    "sent": "So epsilon T will be related to the base measure.",
                    "label": 0
                },
                {
                    "sent": "Right, so you could combine the two you mean they put this in here.",
                    "label": 0
                },
                {
                    "sent": "Basically and then yeah, then you could combine the two and you would have.",
                    "label": 0
                },
                {
                    "sent": "Then you would have something almost like a hierarchical to reset process.",
                    "label": 0
                },
                {
                    "sent": "I think so then you would have an extra.",
                    "label": 0
                },
                {
                    "sent": "Maybe I'm misunderstanding what you're saying.",
                    "label": 0
                },
                {
                    "sent": "What will?",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Under a influence of sort of hold.",
                    "label": 0
                },
                {
                    "sent": "Hi.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "It may be useful to have.",
                    "label": 0
                },
                {
                    "sent": "Depends on the actual video.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so so yeah, so that's that's true and we can do something a bit like that so we can have processes with that decay changes.",
                    "label": 0
                },
                {
                    "sent": "So that would be, but we do it in a slightly different way, perhaps to the way that you were talking about.",
                    "label": 0
                },
                {
                    "sent": "So that's interesting what you're saying.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm OK.",
                    "label": 0
                },
                {
                    "sent": "So, um.",
                    "label": 0
                },
                {
                    "sent": "So if our epsilon TR innovation were to just be a single Atom at a point V to T. Then RFT is going to have this form here.",
                    "label": 1
                },
                {
                    "sent": "Be cause essentially we just multiply by by Vt and then we also multiply by 1 -- v T. So if we look at.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If we look at this kind of thing here, and if we look at F T + 1 and that's going to be Vt times kind of.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "But 1 -- V T times the innovation and then FTF T + 1 in terms of FT lefty we can write in this way again and so we're going to FT is going to be tee times 1 -- B T minus one and epsilon T -- 1 and we keep having this structure like.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That and so.",
                    "label": 0
                },
                {
                    "sent": "Naturally this defines a kind of stick breaking process.",
                    "label": 0
                },
                {
                    "sent": "So here we have the phone with the stick breaking process, where rather than thinking just about breaking the stick, we're thinking about now for a time point T and then we just count backwards through time.",
                    "label": 0
                },
                {
                    "sent": "I'm going backwards through time.",
                    "label": 0
                },
                {
                    "sent": "We we break the stick according to the Vis that we come across going backwards in time.",
                    "label": 1
                },
                {
                    "sent": "And so that's a natural way to think about generating the jury.",
                    "label": 0
                },
                {
                    "sent": "Say the break is generating a stick breaking process.",
                    "label": 0
                },
                {
                    "sent": "But that type of structure is a little bit inflexible because what we're doing is we're introducing innovations one at a time, every time point.",
                    "label": 0
                },
                {
                    "sent": "And so it may be that we don't really want to do that, because it may be that either our process.",
                    "label": 0
                },
                {
                    "sent": "Isn't changing very quickly overtime and so we don't want to always be introducing new randomness becausw the way that this process is constructed.",
                    "label": 0
                },
                {
                    "sent": "Those points will arrive at the start of our stick breaking process, so they will tend to have new innovations.",
                    "label": 0
                },
                {
                    "sent": "Will tend to have large weights, and that's kind of an important.",
                    "label": 0
                },
                {
                    "sent": "Point about this type of construction and this type of process.",
                    "label": 1
                },
                {
                    "sent": "And it may be that we want to introduce more than one Atom at a particular time point, because our process is changing very quickly with time, and so one way to do that is to assume that rather than these new atoms arriving just constantly in time.",
                    "label": 0
                },
                {
                    "sent": "That we assume that they arrive according to Opossum process.",
                    "label": 0
                },
                {
                    "sent": "So I'll pass on process is the simplest type of point process overtime say.",
                    "label": 0
                },
                {
                    "sent": "And that allows us to have something rather more flexible and kind of rather more sensible.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so, as I was saying earlier, the simplest type of construction like that is what we call the DPA are so that reshape process our process.",
                    "label": 0
                },
                {
                    "sent": "And so one of the nice properties of this type of construction generating this type of stick breaking process through time is that we can try and think about controlling the marginal marginal process.",
                    "label": 0
                },
                {
                    "sent": "So our marginal process is stick breaking.",
                    "label": 0
                },
                {
                    "sent": "And so at anytime point we can think about how FT is generated.",
                    "label": 0
                },
                {
                    "sent": "And so FT is generated from.",
                    "label": 0
                },
                {
                    "sent": "Yes, we can then think about how we can control the process to have particularly given marginals at time FT.",
                    "label": 0
                },
                {
                    "sent": "Through different values of take.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "This is our infinite kind of mixture model.",
                    "label": 0
                },
                {
                    "sent": "So we have whites and we have features and so the weights.",
                    "label": 0
                },
                {
                    "sent": "Given by the J, that's the way associated with the J Tatum, and then we just need to find out how many atoms are between that or are these points of this point process that we've introduced?",
                    "label": 0
                },
                {
                    "sent": "So the J Tatum is introduced to time Tor J and we just need to find how many atoms are between time T Ant or J and that's the number of breaks that we have before.",
                    "label": 0
                },
                {
                    "sent": "Vijay in our stick breaking process backwards in time.",
                    "label": 0
                },
                {
                    "sent": "So for those to restate process construction V1 up to the air, well these are just from a beta 1M.",
                    "label": 0
                },
                {
                    "sent": "These follow Opossum process with intensity Lambda and the theaters once again are drawn from just some base measure H. Yeah.",
                    "label": 1
                },
                {
                    "sent": "Construction will.",
                    "label": 0
                },
                {
                    "sent": "Make the distribution tab jumps, yeah?",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah yeah, that's the construction, so it's a little bit like kind of change point models or switching type models, yeah?",
                    "label": 0
                },
                {
                    "sent": "Guys.",
                    "label": 0
                },
                {
                    "sent": "No, no, there's an infinite mixture, so an infinite number of these are sorry.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "So an infinite number of zero and infinite number are nonzero.",
                    "label": 0
                },
                {
                    "sent": "So from my sorry sorry this should go from minus Infinity.",
                    "label": 0
                },
                {
                    "sent": "Well now it goes from one to Infinity, but these are these are arriving according to this person process or minus Infinity to Infinity.",
                    "label": 0
                },
                {
                    "sent": "So there's an infinite number between minus Infinity and T on that into.",
                    "label": 0
                },
                {
                    "sent": "OSC will vary overtime this, but the marginal process safety will be drawn from additional process.",
                    "label": 0
                },
                {
                    "sent": "But appointment.",
                    "label": 0
                },
                {
                    "sent": "He yeah.",
                    "label": 0
                },
                {
                    "sent": "Ask the same right like this.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so you don't need that.",
                    "label": 0
                },
                {
                    "sent": "Doesn't really matter.",
                    "label": 0
                },
                {
                    "sent": "You can make Lambda being homogeneous.",
                    "label": 0
                },
                {
                    "sent": "It wouldn't.",
                    "label": 0
                },
                {
                    "sent": "This thing is just it doesn't matter.",
                    "label": 0
                },
                {
                    "sent": "Actually, as long as well, especially as long as you subordinate it in a proper way then this will always substantially as long as you have some increasing process that defines the tours then this thing will always be to reset process.",
                    "label": 0
                },
                {
                    "sent": "Traffic.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that's what happens in this case.",
                    "label": 0
                },
                {
                    "sent": "So we can, yeah, so that's what happens in this case, and we could do.",
                    "label": 0
                },
                {
                    "sent": "Other.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Laws as well.",
                    "label": 0
                },
                {
                    "sent": "So this is just a kind of little graphic of how the process works.",
                    "label": 0
                },
                {
                    "sent": "So this is the process at time T0.",
                    "label": 0
                },
                {
                    "sent": "This is the processor time T1 and so.",
                    "label": 0
                },
                {
                    "sent": "In this case we have three increments, so this is the time that they're introduced.",
                    "label": 0
                },
                {
                    "sent": "This is our tour, and this is the V and then the numbers here are the values of Theta that we have.",
                    "label": 0
                },
                {
                    "sent": "So we have one introduced very close to time, one with the value of feature of North Point 9 seven, and that has quite a big fee and you can see that is this mask that gets introduced here.",
                    "label": 0
                },
                {
                    "sent": "A.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Then we have two masses introduced here, one at no.",
                    "label": 0
                },
                {
                    "sent": ".115.",
                    "label": 0
                },
                {
                    "sent": "At that point there for that.",
                    "label": 0
                },
                {
                    "sent": "We have another one at No 9 seven and for that gets in there so our other ones here get shrunken.",
                    "label": 0
                },
                {
                    "sent": "This one seems to have disappeared.",
                    "label": 0
                },
                {
                    "sent": "Not quite sure why that happened.",
                    "label": 0
                },
                {
                    "sent": "There should be a little bit of math here.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so as we move from kind P = 1 time T = 2, then we can see that this seems to work better because this one and this one.",
                    "label": 0
                },
                {
                    "sent": "They've all been shrunken a little bit.",
                    "label": 0
                },
                {
                    "sent": "And then we've introduced new masses at .8 six, 1.56.",
                    "label": 0
                },
                {
                    "sent": "And so the .561 is bigger.",
                    "label": 0
                },
                {
                    "sent": "It has a slightly larger V, and so that's the .561 and the .861.",
                    "label": 0
                },
                {
                    "sent": "So our distribution is just going through time drawing these kind of increment distributions.",
                    "label": 0
                },
                {
                    "sent": "If you think about it in discrete time and then we're getting new distributions just by reweighting these and introducing new atoms.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so the properties of this thing is that the FT in this case will be at the recently process marginally at every time point with concentration parameter M and base measure H. So we have some idea that this process is kind of stationary.",
                    "label": 0
                },
                {
                    "sent": "And filter correlation has kind of a nice form for the auto correlation doesn't depend on the set B.",
                    "label": 0
                },
                {
                    "sent": "And it has this kind of exponential form.",
                    "label": 0
                },
                {
                    "sent": "Where it just depends on this ratio here.",
                    "label": 0
                },
                {
                    "sent": "Ratio depending on the intensity of the pass on process and the concentration parameter, and it's just decaying exponentially overtime.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So one thing that we can do is to is to roll.",
                    "label": 0
                },
                {
                    "sent": "This is the representation is kind of useful, but it would be nice to have a finite representation.",
                    "label": 0
                },
                {
                    "sent": "By that I mean in the Chinese restaurant algorithm we just have to worry about the clusters that have had points allocated to them and also the probability of generating a new point, and so that's very useful for computation, because then we always have a finite.",
                    "label": 0
                },
                {
                    "sent": "A mixture model.",
                    "label": 0
                },
                {
                    "sent": "And So what we can do here is, of course the Chinese wrecked Ronnies restaurant algorithm.",
                    "label": 0
                },
                {
                    "sent": "It's about generating exchangeable processes for.",
                    "label": 0
                },
                {
                    "sent": "This process is not exchangeable because we now have this type of information.",
                    "label": 0
                },
                {
                    "sent": "And what we what we can do is to integrate over those atoms which don't have any points allocated to them in our mixture to get this finite representation.",
                    "label": 0
                },
                {
                    "sent": "In order to do that, it's useful to have.",
                    "label": 0
                },
                {
                    "sent": "What we call the non active set at time are so that just counts the number of points if we look at time are this counts the number of points which could be allocated to a cluster at time?",
                    "label": 0
                },
                {
                    "sent": "Are they for which TJ is greater than our?",
                    "label": 0
                },
                {
                    "sent": "But which for all the observable which haven't been allocated to that point?",
                    "label": 1
                },
                {
                    "sent": "So Tor, SJ.",
                    "label": 0
                },
                {
                    "sent": "So this is kind of the allocation observation.",
                    "label": 0
                },
                {
                    "sent": "So the allocation is the thing that we're building.",
                    "label": 0
                },
                {
                    "sent": "the Chinese restaurant algorithm on.",
                    "label": 0
                },
                {
                    "sent": "So we can look at all the ones that we've seen so far and see which ones could have been allocated to a point at time are or which weren't, and which were allocated at a time before.",
                    "label": 0
                },
                {
                    "sent": "We also have this MJ which counts the number of observations that have been allocated to the J cluster.",
                    "label": 0
                },
                {
                    "sent": "So Tor N is going to be the times at which we observe these.",
                    "label": 0
                },
                {
                    "sent": "Clusters and we're going to define SN to be equal to Turin and all the times that we've observed the T1 up to TH.",
                    "label": 0
                },
                {
                    "sent": "Videos are just implying or attempting to make sense.",
                    "label": 0
                },
                {
                    "sent": "No, no.",
                    "label": 0
                },
                {
                    "sent": "So this is counting over the observations that I've observed, so I look at all the observations up to time in they've been allocated to times.",
                    "label": 0
                },
                {
                    "sent": "So I'm a new point T. They've all been allocated times here say and then my active set is telling me OK from before.",
                    "label": 0
                },
                {
                    "sent": "So if it if an observation has been introduced at time T, it's allocated at time T1.",
                    "label": 0
                },
                {
                    "sent": "There could be a load of points in between to which it hasn't been allocated, and so the active set counts.",
                    "label": 0
                },
                {
                    "sent": "Basically, how many haven't been allocated appointee, so it looks at this interval between TI and Tor SJC.",
                    "label": 0
                },
                {
                    "sent": "And counts so the maximum value you can get for the active cities is dead.",
                    "label": 0
                },
                {
                    "sent": "Ha.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so, um.",
                    "label": 0
                },
                {
                    "sent": "We can then think about kind of the equivalent of a Chinese restaurant algorithm is to think about having this type of thing, so we can either allocate our new observation to tables to these points here.",
                    "label": 0
                },
                {
                    "sent": "Or we can come up with a new table.",
                    "label": 0
                },
                {
                    "sent": "By introducing the table either in this time period here, this time period here, this time period here.",
                    "label": 0
                },
                {
                    "sent": "And so the probabilities of these various things happening.",
                    "label": 0
                },
                {
                    "sent": "They inherit this stick breaking structure that we had before.",
                    "label": 0
                },
                {
                    "sent": "So the points the probability being allocated into this interval is 1 minus this C0.",
                    "label": 0
                },
                {
                    "sent": "And so Co. We can think about in terms of row.",
                    "label": 0
                },
                {
                    "sent": "Here is the correlation.",
                    "label": 0
                },
                {
                    "sent": "The auto correlation.",
                    "label": 0
                },
                {
                    "sent": "So E to the minus Lambda divided by N + 1.",
                    "label": 0
                },
                {
                    "sent": "If we don't allocate there, if we have seen ought, then we have one minus the one which is the probability of allocating here.",
                    "label": 0
                },
                {
                    "sent": "So this thing is wrong actually.",
                    "label": 0
                },
                {
                    "sent": "So this thing should be M plus this should be.",
                    "label": 0
                },
                {
                    "sent": "This part should be on the numerator.",
                    "label": 0
                },
                {
                    "sent": "There should be N + a town J.",
                    "label": 0
                },
                {
                    "sent": "So 1 -- D One is this one minus die.",
                    "label": 0
                },
                {
                    "sent": "Is this thing here?",
                    "label": 0
                },
                {
                    "sent": "So the probability of being allocated to this observation here is proportional to this thing here times by 1 minus this thing.",
                    "label": 0
                },
                {
                    "sent": "And then we can carry on doing that.",
                    "label": 1
                },
                {
                    "sent": "Using these particular weights, of course, once we get to a point where there's going to be some point, some minimum value of Tor for which we after which we have no points allocated to values of the time.",
                    "label": 1
                },
                {
                    "sent": "And then we have some kind of tail value to see, but we can work out all these things and there's only going to be a finite number of them.",
                    "label": 0
                },
                {
                    "sent": "The useful thing is that it only depends on this value row here.",
                    "label": 0
                },
                {
                    "sent": "So for example, if Rovers won all these seas.",
                    "label": 0
                },
                {
                    "sent": "All these seas would be.",
                    "label": 0
                },
                {
                    "sent": "1.",
                    "label": 0
                },
                {
                    "sent": "So anyway, so it depends on this value row, and so the larger the value of row, the less likely.",
                    "label": 0
                },
                {
                    "sent": "We are to see things in this interval here, and that's kind of make sense because we think things are more correlated and so they're changing less overtime, and so there's more chance that we get points allocated to clusters along time in the past as we increase the correlation.",
                    "label": 0
                },
                {
                    "sent": "And as we decrease the correlation, we tend to see things very close to T. Well, at least we get high correlation and so then we tend to see points along time in the past.",
                    "label": 0
                },
                {
                    "sent": "But the probabilities that we allocate are here are.",
                    "label": 0
                },
                {
                    "sent": "Depend on the size of the clusters.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "It's slightly different from the Chinese restaurant algorithm, but you can generate the Chinese restaurant algorithm from the stick breaking process and this kind of arises as an intermediate step where we rather than just thinking about the tables as purely exchangeable.",
                    "label": 0
                },
                {
                    "sent": "We think about the tables in terms of where they come in the stick breaking construction.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "So we can think about the distribution of a new point.",
                    "label": 0
                },
                {
                    "sent": "So if we have a new point drawn in some interval, then the value of the new point is going to be exponentially distributed.",
                    "label": 0
                },
                {
                    "sent": "And truncated to be in this interval with the parameter that depends on the value of Lambda, Ann and the sizes of these active sets.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So kind of very quickly if we want to extend beyond that reached a process to have other types of marginal process, then we're going to have to have some way of allowing the distribution of the vis to change overtime because the positions of our atoms in the stick breaking process of say FT as T changes that position and we introduce new atoms, that position is going to be moving further and further.",
                    "label": 0
                },
                {
                    "sent": "Back and since the for things like the Prasanta reached a process, that distribution depends on the value of J, then we need to define a stochastic process for the vis to allow them to change overtime.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so in the more the part will be called a pie.",
                    "label": 0
                },
                {
                    "sent": "I am so we can put any type of marginal process here.",
                    "label": 0
                },
                {
                    "sent": "Essentially that has stick breaking form.",
                    "label": 0
                },
                {
                    "sent": "Then the only difference from before when we had the DPR is that now we allow these vis to depend on time.",
                    "label": 0
                },
                {
                    "sent": "So we have completely the same construction.",
                    "label": 1
                },
                {
                    "sent": "But these are allowed to depend on time.",
                    "label": 1
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we can construct that in quite a simple way.",
                    "label": 0
                },
                {
                    "sent": "So if we have so our eyes in our stick breaking construction, we have an infinite sequence of days, an infinite sequence of bees.",
                    "label": 0
                },
                {
                    "sent": "And so if we have a nondecreasing sequence.",
                    "label": 0
                },
                {
                    "sent": "Then then we can kind of come up with this nice structure.",
                    "label": 0
                },
                {
                    "sent": "We can do it for any type of sequence of Asian bees, but for the non decreasing one it has this kind of mixture representation again that we take a weighted sum of our previous value of the and and innovation.",
                    "label": 0
                },
                {
                    "sent": "And so the weights have these particular forms.",
                    "label": 0
                },
                {
                    "sent": "Here is that guarantees that Vijay is always distributed beta AJ BJ this is a nice form for computation because we have a mixture.",
                    "label": 0
                },
                {
                    "sent": "And we know generally how to deal with.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Mixtures.",
                    "label": 0
                },
                {
                    "sent": "So further press under each lay.",
                    "label": 0
                },
                {
                    "sent": "For that particular case being simplified.",
                    "label": 0
                },
                {
                    "sent": "Because.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The eyes are fixed are constant.",
                    "label": 0
                },
                {
                    "sent": "So this difference here becomes zero, and so epsilon itself becomes is always zero, and so we just have this part here.",
                    "label": 0
                },
                {
                    "sent": "So Vijay plus one is equal to WJ times feed.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I.",
                    "label": 0
                },
                {
                    "sent": "And so we can just write the VJS in terms of this.",
                    "label": 0
                },
                {
                    "sent": "Infinite sorry this this finite product of terms.",
                    "label": 0
                },
                {
                    "sent": "And so this guarantees that all the VJS are correct for the Apostle for each day.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We can see a little bit here.",
                    "label": 0
                },
                {
                    "sent": "The impact of having different values of B.",
                    "label": 0
                },
                {
                    "sent": "So B = 0.",
                    "label": 0
                },
                {
                    "sent": "Is that reached a process?",
                    "label": 0
                },
                {
                    "sent": "And so as B increases, this is becoming increasingly unlike after each day process and So what we have here is suppose we draw 20 observations from our process and condition on the fact that we have C clusters, so 2, four or eight clusters.",
                    "label": 0
                },
                {
                    "sent": "What is the probability?",
                    "label": 0
                },
                {
                    "sent": "What if we were to draw 20 at the next time point?",
                    "label": 0
                },
                {
                    "sent": "What is the?",
                    "label": 0
                },
                {
                    "sent": "What is the number of clusters we would have?",
                    "label": 0
                },
                {
                    "sent": "That's kind of giving us some idea of the dependence that is generated through these processes in terms of the number of clusters we see at one time point and the number of clusters that we see at another time point.",
                    "label": 0
                },
                {
                    "sent": "And So what we can see is that as we increase this parameter, the right hand tail of its distribution is getting longer.",
                    "label": 0
                },
                {
                    "sent": "So here we are, conditioned on having two Tier 2 clusters at particular time and then at the next time this is the kind of number and so influence of the number of clusters we see at a particular time is kind of decreasing.",
                    "label": 0
                },
                {
                    "sent": "As we increase this parameter B.",
                    "label": 0
                },
                {
                    "sent": "And so that's kind of one way of thinking about what we gain in terms of going from the drishtee process to pass on to reset process in this type of MoD.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "In terms of computation, we can extend the ideas of the retrospective sampler developed by purposefully Opulus Ann Roberts.",
                    "label": 0
                },
                {
                    "sent": "For the person to reach the IRL process.",
                    "label": 0
                },
                {
                    "sent": "The main problem is that we don't really have a standard stick breaking type of construction because our way asked.",
                    "label": 0
                },
                {
                    "sent": "Stick breaks themselves made up of a product.",
                    "label": 0
                },
                {
                    "sent": "But what we can do is we can use.",
                    "label": 0
                },
                {
                    "sent": "A trick developed by David Dunson and some other people for matrix stick breaking processes that allow us to do that efficiently.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I just want to go quickly through a couple of examples.",
                    "label": 0
                },
                {
                    "sent": "So one example is stochastic volatility models, so we assume that our observations are the daily returns.",
                    "label": 0
                },
                {
                    "sent": "The difference in the log prices of an index, and we assume that really the interesting thing is that variance that we can write that as a normal times and variance, and we assume that the variance itself follows an AR process.",
                    "label": 0
                },
                {
                    "sent": "And we're going to assume that this distribution here is the thing that we're interested in modeling, as this time varying infinite mixture model.",
                    "label": 0
                },
                {
                    "sent": "So that's kind of this return distribution.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is the data.",
                    "label": 0
                },
                {
                    "sent": "This is the standard and poors index.",
                    "label": 0
                },
                {
                    "sent": "Are the early 80s up to 1988 including?",
                    "label": 0
                },
                {
                    "sent": "The big crash in 80.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "88",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, so this thing.",
                    "label": 0
                },
                {
                    "sent": "We don't have an intercept.",
                    "label": 0
                },
                {
                    "sent": "So in a standard SVM model, we would have an intercept, so we can.",
                    "label": 0
                },
                {
                    "sent": "Kind of identified.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some sense that way.",
                    "label": 0
                },
                {
                    "sent": "And so this is what we get if we try and fit the model to that data.",
                    "label": 0
                },
                {
                    "sent": "This is a heat plot of the density overtime, and these are the values of the density and so you can see we have these various different periods where the volatility the distribution is roughly constant and then we have periods where it gets very large.",
                    "label": 0
                },
                {
                    "sent": "And here when we have the crash it gets very wide indeed.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Where is the results?",
                    "label": 0
                },
                {
                    "sent": "These are some plots of various time points taken from that graph to show you kind of the differences in shape that we get.",
                    "label": 0
                },
                {
                    "sent": "So we get something that has heavier tails than a normal and here we get a little bit of kind of Biome.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Dalati and if we were to look at the variance of the predictive distribution overtime, then we would see that that is changing like this.",
                    "label": 0
                },
                {
                    "sent": "And so we can see that roughly what this is telling us is that the way that the volatility model is falling down.",
                    "label": 0
                },
                {
                    "sent": "Is that?",
                    "label": 0
                },
                {
                    "sent": "Essentially, the kind of long run average.",
                    "label": 0
                },
                {
                    "sent": "Of the volatility, the variance of our return distribution is non constant.",
                    "label": 0
                },
                {
                    "sent": "And that should be allowed to change overtime.",
                    "label": 0
                },
                {
                    "sent": "And so that's not an unusual thing for people to think in financial modeling.",
                    "label": 0
                },
                {
                    "sent": "That that thing is.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Constant.",
                    "label": 0
                },
                {
                    "sent": "The second example, he looks at the rule.",
                    "label": 0
                },
                {
                    "sent": "Per capita GDP taking logs over 110 EU regions from 1977 to 1996, and so these are.",
                    "label": 1
                },
                {
                    "sent": "Density estimates for each of those years using a mixture of Theresa May process model doing that independently for each of the different years.",
                    "label": 0
                },
                {
                    "sent": "And so you can see we have kind of a variety of different shapes.",
                    "label": 0
                },
                {
                    "sent": "It's a bit unclear or these go.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "So if we use this DPA, our model and what we find roughly is that we have two periods, one period pre 1988 and one period post 1988 or in the shape of the distribution.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Changing and so these are the density estimates.",
                    "label": 0
                },
                {
                    "sent": "Using this model for the different years and you can see that they are roughly the same well, but there's two different groups essentially, and that they're roughly the same within each group.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so if we look at.",
                    "label": 0
                },
                {
                    "sent": "The independent density estimates that we had at the start.",
                    "label": 0
                },
                {
                    "sent": "Then these are the two groups throughout kind of identified one in green and one in blue, and you can see that roughly the shapes are kind of rather similar.",
                    "label": 0
                },
                {
                    "sent": "For this.",
                    "label": 0
                },
                {
                    "sent": "The green.",
                    "label": 0
                },
                {
                    "sent": "Which is the later period and for the blue period, which is the early pick.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is what I talked about.",
                    "label": 0
                },
                {
                    "sent": "We can develop these \u03c0 R processes which will work for a wide range of marginal big breaking processes.",
                    "label": 0
                },
                {
                    "sent": "For the DPR we can develop a kind of Chinese restaurant type representation which may be useful both for MCMC methods and for non MCMC methods like the the.",
                    "label": 1
                },
                {
                    "sent": "The Heller and Ghahramani type methods for agglomerative clustering.",
                    "label": 0
                },
                {
                    "sent": "And the process defines a jump process on probability measures and therefore it is quite useful at finding change points in distribution.",
                    "label": 1
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}