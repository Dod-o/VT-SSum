{
    "id": "gy2o2lwmab2z7257rv2qoj2ftzbk2h3o",
    "title": "Theoretical Neuroscience and Deep Learning Theory",
    "info": {
        "author": [
            "Surya Ganguli, Department of Applied Physics, Stanford University"
        ],
        "published": "July 27, 2017",
        "recorded": "June 2017",
        "category": [
            "Top->Computer Science->Machine Learning->Deep Learning",
            "Top->Computer Science->Machine Learning->Reinforcement Learning",
            "Top->Computer Science->Machine Learning->Unsupervised Learning"
        ]
    },
    "url": "http://videolectures.net/deeplearning2017_ganguli_deep_learning_theory/",
    "segmentation": [
        [
            "Yeah, so it's really great to give a talk right after Blake.",
            "Actually, I think biology possible.",
            "Deep learning is a very important topic not only for its scientific interests but also.",
            "I mean if you can really do it then you can parallelize deep learning.",
            "So we kind of coordinated.",
            "I'm not going to talk about biology, possible deep learning, but I'm going to talk about some other stuff so I'm."
        ],
        [
            "Basically a theoretical neuroscientist, though I also work in deep learning for reasons that I'll explain.",
            "But what is theoretical neuroscience and why is it such an exciting subject?",
            "At the moment, there's just like there's a lot of excitement in deep learning or machine learning in general.",
            "There's also a lot of excitement in neuroscience right now because we have been experiencing lots of experimental revolutions in our ability to record the brain at multiple levels of complexity in space and time across multiple scales.",
            "And so we're getting huge amounts of data from the brain.",
            "And we have to try to make sense of it.",
            "We'd like to extract a conceptual understanding of how how the brain works.",
            "So to confront this complexity, it's really useful to turn to subjects from the physical Sciences that have themselves develop powerful methods to deal with complexity in physical systems and try to adapt those ideas to analyze neural systems.",
            "But also neural circuits aren't simply tangled webs of complexity that exist for their own sake.",
            "They've actually been evolved over years of evolution to solve computational tasks.",
            "So it's useful to turn to ideas from the computational Sciences, both as ways to analyze their data, but also to search for inspirations as to what kinds of computation computational tasks the brain is solving.",
            "I should actually probably put deep learning in here.",
            "That's kind of an old slide, but you'll see that it's allowed it next time.",
            "So anyways, we actually work in all of these subjects, but you know, we kind of take a very expansive view of what theoretical neuroscience is, but what might the intersection to deep learning be well?"
        ],
        [
            "Also, these are for example some of the projects we work on.",
            "I spend a lot of time collaborating with experimental neuro scientists working in how flies see how mice navigate, how monkeys reach, how mutant mice can get smarter, for example.",
            "Um?",
            "But I won't talk about any of that.",
            "Today I will talk about one part of it where it intersects with deep learning, but but why do I think there should be an intersection between deep learning and neural?"
        ],
        [
            "Science I think there's multiple reasons and because of advances in both fields, I think there's an interesting motivation for a new type of alliance between neuroscience and deep learning or theoretical machine learning, which is the following.",
            "To some extent, we all want to understand how neural circuits work, how the brain works, but what does it mean, right?",
            "Well, in some sense we'd like to understand how the connectivity and dynamics of a neural circuit gives rise to behavior.",
            "And also learning is extremely important.",
            "We'd like to understand how neural activity and synaptic learning rules conspire to self organize useful connectivity that subserves behavior.",
            "OK, this is to make fun of physicists who work in neuroscience.",
            "Sometimes we sometimes like to analyze random networks, but that's not good enough 'cause they don't have function.",
            "However, the field of machine learning is actually generated.",
            "Lots of interesting neural networks that accomplish really interesting functions functions that we know of no other way to do as well in any artificial system, right?",
            "What's really exciting is that neural networks are winning the competitions at the moment.",
            "OK, but a scary thing is that we know everything about these neural systems.",
            "We know their connectivity.",
            "Scary from reflexive neuroscience.",
            "We know their connectivity.",
            "We know their dynamics.",
            "We know their learning rule.",
            "We know their entire developmental experience from the from when they were baby random networks to grown up trade networks through their exposure to training stimuli.",
            "Yet we don't have a meaningful understanding of how they learn and work, nor do we even have a benchmark for what such an understanding would even look like.",
            "Right, so we kind of laid out so you know, actually deep learning provides a really interesting warmup problem for neuroscience.",
            "And you know, I don't think that if we directly understand how these deep networks work will understand the brain works.",
            "But the methods that we used to arrive at that understanding, the things that we decide are important to measure and not important to measure in deep networks.",
            "To understand them might be similar to what we'd like to measure in the brain.",
            "So we kind of laid this out in an opinion piece if you're interested in a more fleshed out version of this argument.",
            "But also a deeper scientific understanding of deep networks will of course help deep learning as well, right in the history of interaction between engineering and science.",
            "It's always kind of followed the following pattern.",
            "The engineers are head of this are ahead of the scientist.",
            "So for example, the Steam engine was built in 17.",
            "The first steam engine was built in 1712, long before physicists had figured out the laws of thermodynamics.",
            "But you know, the science of thermodynamics developed and you know things like the Carnot engine and upper bounds, and thermodynamic efficiency came along, and that helped us design much better.",
            "Steam engine's right?",
            "We're right now in a situation where the engineering is way ahead of the science, but that doesn't mean we should forgo the science in deep learning, because, again, given the history of the interaction between science and engineering, it has never been the case.",
            "The deeper understanding of the science does not lead to better engineering.",
            "So although right now we're really far behind.",
            "So what can we do?",
            "Although experimentally you're way ahead of neuroscience, 'cause we don't, although we have a lot of data in neuroscience, we don't have all the data yet, so it's a very interesting interaction between science, neuroscience and machine learning.",
            "And I think these two fields will go hand in hand for quite awhile."
        ],
        [
            "So, so let me just give you the talk outline so it's kind of three.",
            "Maybe one more thing.",
            "So there's kind of three kind of branches to this talk.",
            "One is, you know, what can deep learning do for neuroscience?",
            "You know how you know you're having a lot of success solving problems in machine learning, but you also have the power to help us in neuroscience.",
            "And I just wanted to give you some sense of that.",
            "You can actually use deep and recurrent neural networks to successfully model different parts of the brain.",
            "Then we'll move on to a theory of deep learning.",
            "And of course, this is in its infancy, but I think three of the most interesting topics in the theory of deep learning, our optimization.",
            "You know why is it that we can optimize these networks, and how can we use that understanding to better optimize them expressivity?",
            "Why is depth useful?",
            "What can deep networks bias in terms of expressing functions, that shallow networks cannot, and the most vexing one is generalization.",
            "Why is it that these deep networks can generalize even when you use much less data than the number of parameters?",
            "Then the third part will turn to inspiration from neuroscience.",
            "What does the brain have that we're currently missing in deep learning?",
            "And I'll talk about some ingredients that we may want to try to incorporate into our deep learning models and some ingredients that we've already incorporated that have helped.",
            "OK, so let's start with applying deep learning to the brain so that there's some exciting work."
        ],
        [
            "Done by several labs.",
            "Where they've actually modeled the brain using deep neural networks and actually gotten some insight into how those brain regions operate.",
            "So here's a work by David's Asilo, Monticello coming out of Krishnan Bill Newsome's lab at Stanford, where what this is kind of an overview slide, but so it's a bit hard to see, but what they did was they asked a monkey to do what's called a context dependent discrimination task.",
            "So in this task you have a bunch of dots there, either red or green or some fraction of dots are red, some fraction of green.",
            "And some fraction are moving to the right and some fraction are moving to the left.",
            "OK, and there's.",
            "So there's two contexts in context one the monkey is supposed to report the majority direction of motion of the dots in context to the monkey is supposed to report the majority color of the dots.",
            "It reports them through eye movements.",
            "So and the fractions are very close to 5050, so the monkey needs to stare at it for awhile and integrate evidence overtime in favor of a hypothesis.",
            "For the majority color are the majority motion, so it's a relatively complicated task because you have to integrate evidence overtime.",
            "You have to do different things depending on the context and so on and so forth.",
            "And they recorded from all the neural a whole bunch of neurons like hundreds of neurons in the monkey's brain, and each neuron itself displayed a complex dependence on context, color, motion, choice and so on.",
            "There was no simple kind of explanation at the single neuron level of what was going on.",
            "So then what they did was they trained a recurrent neural network to solve the same task.",
            "It had a motion signal that had a color signal.",
            "These were now just scalar signals.",
            "Overtime that had a nonzero mean reflecting the fractional difference data context signal coming in.",
            "They had a readout and they trained the network to solve the same task that the monkey did.",
            "OK. Then the analyze the network.",
            "They did dimensionality reduction on the on the dynamics of this network and they actually looked inside the network to look at what kind of dynamical system got learned.",
            "And they found that it actually learned two integrator networks, orlina tractors.",
            "These manifolds of fixed points.",
            "So you know what does it mean to integrate a signal.",
            "If the signal is on, then you know there's activity that's changing overtime in the network.",
            "But if you shut the signal off, an integrator will stay at the same point, right?",
            "So you have to have an entire manifold of fixed points.",
            "There were two mutually exclusive manifolds of fixed points and the network learn to integrate one while ignoring the other in one context.",
            "But then for the other integrator it was the opposite.",
            "OK, then they did dimensionality reduction or did principal components analysis on the dynamics of this network.",
            "You know, while it was operating and then they did the same thing on the monkey's brain and they found a beautiful match.",
            "OK, so basically at the population level, there are certain patterns in the monkeys brain that are essentially predetermined by what you would need to do to solve this task.",
            "Now there's some interesting things where if you regularize the network.",
            "Only if you regularize the network does it match the monkeys brain.",
            "If you don't regularize it, you get much more chaotic patterns, and it doesn't match the monkeys brain.",
            "Moreover, the regularised network is more robust to perturbations, suggesting that this dynamics is probably also robusta perturbations.",
            "You could potentially test that using optogenetics, because we can stimulate the brain as well as record from it, but this is a basic basic kind of pattern that's occurring if you train a network to solve the same task as the monkey, it gives you a mechanism for generating hypothesis.",
            "As to how that brain region is working?",
            "Um, yeah.",
            "The recurrent weights are trained.",
            "Yeah yeah, the recurrent.",
            "Yeah those are definitely trained.",
            "Everything is trained.",
            "Yeah back well he in this work he used Hessian free optimization, so slightly older older work.",
            "Um, yeah.",
            "He used as David Solo.",
            "He used the Jacobian regularization where he tried to penalize the norm of the vector field.",
            "That is the dynamical system.",
            "It's a continuous time firing rate network, so there's a Jacobian for the dynamics, which is essentially the linearized vector field, and it penalizes the norm of that.",
            "So it's basically trying to get a smooth dynamics as possible.",
            "It turns out that's actually quite important for matching the brain.",
            "Without it, you get these Rube Goldberg like devices that don't look like the brain.",
            "Um?",
            "You also see that when you try to match the motor cortex during reaching tasks."
        ],
        [
            "Here's another kind of a famous one by Dan Yamen, so this was done in gym to Carlos Lab at MIT.",
            "He's now at Stanford, where they took again.",
            "It's the same philosophy you now this is to mimic inference in Pearl Cortex, which is at the apex of the ventral visual stream.",
            "It does sort of general object recognition and whatnot.",
            "We don't know what task the monkey is doing or what evolution designed it in for temporal cortex to do.",
            "So Yamens followed a bold hypothesis that maybe if we just train a network on an object recognition or object categorization, something like image net.",
            "And if we look at the internal representations of that network, it might mimic what's going on in the brain, and that's what they actually found.",
            "They had a multi layer network and you know it was.",
            "It was trained on image Net and they looked at activity in the high level layers and what they found is they could find linear combinations of a small number of neurons in the high level layers.",
            "That match the activity of an individual neuron.",
            "It say a fraction of variance explained about 50 to 60, which was a significant advance at that time, getting a 60% of variance explained of a single neuron so many synapses away from the sensory periphery was quite difficult.",
            "But Interestingly enough, if you go earlier on.",
            "You know, and you try to find linear combinations of neurons here that match V4 in the earlier layer.",
            "Then you get a good match, but only if you look at the earlier layer and then V1 only if you look at the earlier layer, so it's as if the cascaded computation in the circuit is mimicking to some extent what's going on in the ventral visual stream.",
            "This of course raises a lot more questions, is 60% of variance good enough?",
            "What is the upper limit?",
            "Why do we have to take linear combinations neurons?",
            "Are we just learning a kind of an interesting basis set?",
            "That's similar to the basis set in the brain.",
            "Should we expect a more detailed match at the level of 1 to one correspondence between neurons?",
            "Is that even unrealistic to expect?",
            "I mean, there's a lot more work to be done here, but it's a very intriguing direction where deep learning helped us sort of start to understand, or at least statistically explain what we see in the brain.",
            "We've all."
        ],
        [
            "So played that game in my lab in the retina where you can actually get a much more fine scale match, and you can actually know if what you're doing is correct because of the Accessibility of the retina, so we also were coming up with deep neural network models of the retina.",
            "Now you might think the retina is very simple, right?",
            "It just does center surround receptive fields and that's it.",
            "We kind of knew that from many years ago, but."
        ],
        [
            "It's not actually true.",
            "Your retinas an extremely sophisticated preprocessing device.",
            "That actually is itself kind of a deep neural network in the sense that it has 1 hidden layer, you have photo receptors that are sensitive to light.",
            "It propagates through a hidden layer of neurons that have both lateral connections in terms of horizontal cells and Ameren cells, and these are the bipolar cells and then the bipolar cells connected the ganglion cells.",
            "It's extremely easy to shine light in the retina and record from the ganglion cells, but it's very hard to record from the interior of the retina.",
            "It's just a bit more experimentally inaccessible."
        ],
        [
            "The classic model of the retina is what I mentioned, just a spatio temporal filter and a non linearity.",
            "Clearly the retina is much more structured than the simple models that have been used."
        ],
        [
            "These simple models have worked pretty well.",
            "You know, on explaining the retinal response to white noise, but if you show more structured stimuli, you see a really bad match.",
            "You know you get Pearson correlation coefficients of about .36 between the predicted firing rate of these models.",
            "These simple models and the actual frame rate of the retina in response to natural stimuli, the stimuli for which the retina was evolved to process."
        ],
        [
            "So we decided to try to model these retinal ganglion cells using convolutional neural networks.",
            "I know there's many reasons to think this is a horrible idea, OK?",
            "We just train the model to minimize the the error in predictions between between the models.",
            "Predictions of recorded data."
        ],
        [
            "Why might this be a horrible, horrible idea?",
            "We might not be able to train the network, we don't have lots and lots of data.",
            "We can only record from the retina for about 30 to 40 minutes, so we might not even be able to train the network in a way that Gen."
        ],
        [
            "Ulyses Furthermore, even if we were to train the network, there's no guarantee that the interior structure of our model will match the interior structure of the retina.",
            "It may solve the problem in a different way."
        ],
        [
            "So we won't learn anything.",
            "Even the algorithms identified by the model may not be the same as those used by the retina."
        ],
        [
            "And but actually, it turns out all of these fears were surprisingly unfounded.",
            "You know how it is?",
            "The grad students go ahead and do it even when the advisor tells him not to.",
            "Actually, they did it without telling me first, and then that was smart so.",
            "Anyway, it works pretty well so.",
            "They actually captured these now form state of the art models of the retina.",
            "They generalize better than the simpler models.",
            "The interior structure of the retina corresponds to interneurons of the retinal circuitry, and we can capture other aspects of retinal computation as well.",
            "So this."
        ],
        [
            "This is basically the model architecture.",
            "These are the photoreceptors a set of hidden units, a dense layer, and then the predicted responses."
        ],
        [
            "The CNN's do pretty well compared to similar models, generalized linear models and LM models.",
            "We actually know the upper limit because we can play the same stimulus multiple times and measure the intrinsic variability of the retina.",
            "So typical retinal spike train to the same stimulus has a correlation coefficient of .8 with any other spike train.",
            "So we're getting up to six and actually in more recent work we're up to .7.",
            "So we're actually getting quite close to the upper limit set by intrinsic noise in the retina as far as predictability."
        ],
        [
            "Those.",
            "Um?",
            "You know, we don't need that much data to to learn these are these are accuracy as a function of the amount of training data and actually the CNN generalizes much better than these these.",
            "These simpler models.",
            "Now what's wrong?"
        ],
        [
            "Really interesting is we can look are the cells in the interior of our model.",
            "These were never directly trained.",
            "These are the hidden units, their receptive fields or I either learned filters, look a lot like what we know about bipolar cells.",
            "When we record from bipolar cells directly, and what we could do is, we could do an experiment where in the same retina we recorded from a very specific bipolar cell and then we matched in our model, the bipolar cell that has the closest receptive field.",
            "It's a convolutional models.",
            "We just.",
            "Find the cell that has the receptive field center at the same place as the one that we recorded, and then you can see that the C and the blue is the model's prediction and the black is the actual retinal response.",
            "So this is a proof of principle that if you only have the inputs and outputs of the network, you can actually computationally reconstructed a high level of accuracy.",
            "What's going on in the interior of the network, which is which is good news for these kinds of modeling approaches in neuroscience."
        ],
        [
            "Um?",
            "There's something called sub Passan variability in neurons.",
            "We can capture that and we understand theoretically now how it happens we."
        ],
        [
            "And capture that in the model by adding noise."
        ],
        [
            "I'll skip those."
        ],
        [
            "Details, but we get a nice match between the model and the simulation."
        ],
        [
            "We can also capture adaptation so you know your photon flux into your retina can vary almost 10 orders of magnitude in between nighttime and sunlight full sunlight.",
            "So your retina adapts to luminance and contrast overtime.",
            "So basically, if you crank up the contrast, the retina will go wild for a little bit, and then it'll come back down so we can capture the and that happens over long timescales so we can capture that using an LTM.",
            "We put an LS TM in there.",
            "And we can actually reproduce the most of the contrast experiments and actually."
        ],
        [
            "So basically, in summary, they capture a lot of the.",
            "You know we do well in accuracy and they capture both an algorithmic level and a structural level.",
            "The interior of the retina, which we never directly trained on.",
            "OK."
        ],
        [
            "So.",
            "So we need to keep going.",
            "OK, so that's sort of quick summary of applying deep learning to the brain.",
            "I figured for this audience we want to get to the next parts so.",
            "So let's talk about that."
        ],
        [
            "The theory of deep learning, so there's so I kind of divide it up into a selection of topics.",
            "Trainability, which is, you know if a good neural network solution exists with small training error.",
            "How do we find it and what makes the problem difficult?",
            "Then there's expressivity.",
            "What kinds of functions can a deep network express in a shallow network cannot?",
            "And then there's generalizability.",
            "What principles do deep networks used to place probability or make decisions in regions of input space where you have very little data?",
            "The generalizability one is still very much an open question.",
            "I just want to summarize kind of what we know about that at the moment.",
            "There's kind of a bias survey through work that you know I've been involved in, but I'll talk about, you know, sort of other stuff along the way, so the way I started thinking about this stuff will start with the trainability.",
            "The way I started thinking about this stuff was actually starting from trying to understand infant level learning in psychology.",
            "Believe it or not, so I have a colleague at Stanford, J. McLeod."
        ],
        [
            "Lens and this is joint work with Andrew Sachs.",
            "Where Jay has spent a lot of time at, you know we mentioned in the previous talk that even in the 2000s, people were using deep networks to try to understand the brain, and so JJ spent a lot of time working on that in the 2000s."
        ],
        [
            "Earlier and he was focused on a topic called Human Semantic Cognition, which is basically it's our ability to learn, recognize, comprehend, and reproduce inferences about objects and events that are in the world, especially ones that are not in our current perceptual stimulus.",
            "So, for example, I could ask you all the questions.",
            "All the question.",
            "Does a cat have fur and you can all answer that question despite the fact that there's no cat in the room.",
            "It's because you have these internal categories in your brain and you have facts associated with these categories.",
            "And you know, you never see the same cat twice, but once you see a cat, it creates the categorical representation of cat in your brain and you can recall all sorts of information and activates based on that.",
            "So our ability to do semantic cognition relies on our ability to form an internal representation of categories in the world."
        ],
        [
            "So there's been a lot of psychology experiments on.",
            "On, you know, when do infants learn categories, right?",
            "So I'm going to focus on the category learning.",
            "There's a whole bunch of other stuff that we've worked on that we won't have time to talk about, but you can actually ask an infant like a preverbal infant a 6 month old.",
            "You know, kind of like this."
        ],
        [
            "One my son went back when he was six months old.",
            "You can ask him and I did ask him.",
            "You know, when can you distinguish between two categories.",
            "So how do you ask an infant?",
            "How do you ask an infant when they can do that?",
            "If they can't talk now he talks up a storm and but anyways.",
            "You do these looking time studies, so for example, you'll show them a picture of a horse in the first time they see a horse, they'll look at it for a long time, 'cause it's novel.",
            "OK then the looking time goes down.",
            "You know, after, say the 5th or 6th presentation the horse, then you show the Macao OK.",
            "If the infant is old enough the looking time will go up OK and then it'll go down again.",
            "So that suggests that the infant can discriminate between cow and horse.",
            "It knows the cow is novel where the spectral horse, but if the infant is too young.",
            "The looking time will not go up on the 1st presentation of the cow because it can't really discriminate those two categories.",
            "It doesn't think they're two different categories.",
            "So based on looking time studies you can infer at what age various categorical distinctions are learned, and then you can put these categorical distinctions into a hierarchical tree, where the higher you go up is the earlier at which they are learned, and that hierarchical tree looks very much like a semantic tree that we would have as adults in our brain.",
            "OK, so it's quite remarkable."
        ],
        [
            "So there's an entire book about this called semantic cognition.",
            "There's a whole bunch of other phenomena that we've also modeled, but I'm only going to focus on this sort of progressive differentiation of concepts in our brain."
        ],
        [
            "OK, so how did they model it back then?",
            "They just had a toy data set where they had a neural network and they had a set of objects, right?",
            "Say different types of animals and plants and it was a deep neural network and the networks just was just trained to output the various semantic features of animals and plants.",
            "OK and they trained it overtime and what they found was a striking progressive differentiation."
        ],
        [
            "Of structure, so now we're getting into the dynamics of learning or training of these networks.",
            "So initially you start with random weights.",
            "OK, so."
        ],
        [
            "Basically what you can do is you can take the internal representations of the network in this representation layer, and you can hierarchically cluster them."
        ],
        [
            "At different points in training and initially with random weights, there's no harkle clusters.",
            "Then what happens is that some intermediate time at first discriminates between animals and plants, then it discriminates between different types of animals and different types of plants, and eventually it discriminates between individual items.",
            "So you can see the same kind of dynamics in a multidimensional scaling plot where you take the high dimensional interruption representation and try to plot it in a 2 dimensional space while preserving distances.",
            "And you see the same hierarchical differentiation of structure.",
            "OK, so the first time I saw this I was at once both astounded and disturbed.",
            "I was astounded that it actually mimics kind of what goes on in an infant's brain.",
            "But I was disturbed because there was no theoretical understanding of why this was happening, right?",
            "Why is it that the dynamics of learning in these networks behave the way they do?",
            "This will eventually connect to very recent works in generalization at the very end of the talk, which so the basic idea is the following."
        ],
        [
            "By the way, this hierarchical structure is actually present in adult brains both in the adult brains of humans and monkeys.",
            "This is a famous plot that comes out of work by Craig Nichols, Chris Korte and also Roozbeh Kiani, who did the Monkey recordings.",
            "You can show a whole bunch of images both to the human and the monkey, and you get this interesting hierarchical similarity structure that's basically the same across human and monkey.",
            "In the human, the similarity was measured using the similarity of.",
            "Sorry, in the human it was measured using similarity of fMRI voxel activity patterns in it and in the monkey it was measured using the similarity of neural representations of firing rates of individual neurons in monkey it.",
            "We can actually prove a theorem that, at least for simple neural networks, it must be this way under certain optimality conditions.",
            "I'll talk about that next, but this suggests that these two systems are solving the same task, potentially both optimally.",
            "I'll elaborate that on a little bit."
        ],
        [
            "This is the same picture, but using hierarchical clustering of the objects.",
            "Um?"
        ],
        [
            "Also, certain objects have learned earlier than others, so so we'd like to understand the speed of learning in the system."
        ],
        [
            "OK, so the questions we asked are what really are the mathematical principles underlying this hierarchical self organization event representations of the network?",
            "What is the role of various elements of the network?",
            "The nonlinearities of the input output map the learning rule, the emphasis sticks and so on.",
            "So."
        ],
        [
            "What we did was we did something that might seem like we're throwing the baby out with the bathwater.",
            "We analyze, you know, when you look at the activations of these networks, they don't strongly go into the saturating regime during training, so we decided to analyze the learning dynamics of deep linear network.",
            "Now, of course, the expressive power of a deep linear network cannot grow with depth because the composition of linear functions is linear, so there are horrible model for the expressivity of deep networks, but they turn out to be a pretty good model for the learning dynamics of deep networks because.",
            "Even in a deep network, the learning dynamics is gradient descent on a non convex error landscape, and it's a nonlinear learning dynamics just to Illes."
        ],
        [
            "Rate this you know this is learning dynamics of the error in a deep nonlinear network and you see these interesting plateaus and then sudden drops.",
            "Oh sorry, this isn't a linear network.",
            "You see a plateau and then a sudden drop in learning.",
            "But if you for example in same deep linear network, you do greedy unsupervised pre training and then do learning you get a sudden drop right now.",
            "Of course this was the empirical phenomenon that first started deep learning that if you do greedy unsupervised pretraining then you can you can actually train these networks.",
            "So the very empirical phenomenon that gave rise to deep learning is already present in deep linear networks.",
            "So these deep linear networks are an interesting model for understanding learning dynamics.",
            "OK.",
            "So we want to build intuition for the nonlinear case by Anna."
        ],
        [
            "In linear case now, why is the learning dynamics linear?",
            "It's because.",
            "You know, if you imagine that just."
        ],
        [
            "The square loss function.",
            "It's the actual output minus the predicted output squared, but the predicted output has a product of two weights.",
            "So then after you square it, the error surface is quartic.",
            "In the weights, it has four powers of the weights.",
            "When you do gradient descent, you get a cubic equation on the right hand side, and so it's a complicated non convex function."
        ],
        [
            "We can analyze that non convex function by going to the limit of very slow learning rates.",
            "So we get a different."
        ],
        [
            "Equation this is the dynamics of the weight matrices from layer 1, two and three to two to three.",
            "As I promised it, the right hand side is cubic in the weights OK, but one simplification that occurs is that the input statistics that drives learning becomes only the 2nd order statistics in the system because a linear network is only sensitive to 2nd order statistics.",
            "In particular, the input output correlations and the and the input input correlations.",
            "We imagine that the input input correlations are white, so that we kind of have an orthogonal perceptual representation.",
            "Which often happens, you know.",
            "As signals propagate through the brain before they go to an associative system.",
            "So."
        ],
        [
            "So it turns out that we can express the learning dynamics in terms of the statistical structure of the input, right?",
            "Like in general, what we would love to have is we love to have an understanding of how the training data, how the statistical structure in the training data determines the dynamics of learning in the networks.",
            "Here we can get a perfect or complete characterization of that.",
            "All that matters is the input output correlation matrix.",
            "It has a particular singular value decomposition, OK, and what we can show is that."
        ],
        [
            "At the actual input output map of the network builds up overtime.",
            "The singular value decomposition of the input output correlation matrix.",
            "So this is an exact analytical solution to those nonlinear differential equations.",
            "Where the product of weights from inputs and output has the same singular vectors as the input output covariance matrix, but the effective singular value is growing as a sigmoid with time.",
            "Right, the so each of these.",
            "Each of these effective singular values of the input output map grows to the final singular value of the input output statistics, but it does this sudden sharp transition.",
            "The time of this transition occurs at a time given by one over the singular value.",
            "So just intuitively this means stronger statistical structure as measured by input output.",
            "Singular values get learned earlier.",
            "OK, and it turns out these modes evolve linearly, so the blue is the theory and the red is simulations of networks.",
            "Why do we get these these periods of time when there's nothing that's being learned and then a sudden transition?",
            "By the way, these sudden transitions also occur in infants, you know, as they're growing up.",
            "OK."
        ],
        [
            "The reason is there's a simple higher dimensional explanation of what's going on.",
            "You can trade off the strength of weights in the first layer against the second layer, so if we think about, you know this is a schematic of the strength of weights in the first layer versus the second layer.",
            "There's this tradeoff so that there's this manifold of solutions of 0 error and at the center there's a saddle point where the learning dynamics gets attracted to the saddle point and then eventually gets repelled OK.",
            "The error is roughly the distance to this manifold of 0 error solution.",
            "So while you're being attracted to the saddle point, your error is not decreasing appreciably.",
            "But then as you suddenly get repelled, your error will drop suddenly and it will go to zero those times at which you get repelled by these saddle points are the times at which the singular value rapidly goes up in the air are rapidly goes down, so these plateaus are a consequence of having these saddle points essentially.",
            "So let me."
        ],
        [
            "State the takehome messages.",
            "Stronger statistical structure is learned earlier.",
            "That's a very intuitive statement.",
            "We think that holds true for nonlinear networks as well, but for nonlinear networks we don't know how to quantify the strong signal structure, and we don't know how to translate that into learning time.",
            "But for this system, statistical structure is simply singular value and the associated singular vectors and the learning time is one over the singular value.",
            "Now what does all this have to do with the hierarchical differentiation of concepts?",
            "I'm."
        ],
        [
            "The preceding analysis, or the preceding simulations, dealt with a specific data set.",
            "Can we go beyond specific datasets to general principles of 1A?",
            "Neural network is exposed to hierarchical structure.",
            "So what we the way we attack this was we came up with a model for hierarchically structured data, basically through a hierarchical generative model.",
            "I'm.",
            "OK, so here's the basic idea.",
            "We imagined a branching diffusion process that mimics the process of evolution, right?",
            "So here's kind of this ancestral node, or this primordial node, and some feature will diffuse down the tree, and each time it goes down a branch it might mutate right?",
            "And then eventually it will settle down and you'll be able to assign one feature to every item, and the items are objects at the leaves of the tree."
        ],
        [
            "So it's literally like an evolutionary tree, and then each feature diffuses independently.",
            "So what you get is you get a bunch of feature vectors for each of these leaves.",
            "Each of these objects and two objects are more similar to each other.",
            "If they have a lower common ancestor, right?",
            "So you know this could be like you know, two different birds, and this could be like a flower that's very different from the two different birds, and this could be another animal.",
            "OK, so then we feed this data generated from a hierarchical generative model to the neural network.",
            "And we try to understand how the statistical structure of this model is embedded in this in this deep neural network."
        ],
        [
            "Sorry, so yeah.",
            "So this is the basic description of these of these branching diffusions.",
            "And so."
        ],
        [
            "But we also now we know of course, that if we feed it to a deep linear network, all that matters is a singular value decomposition of the input output covariance matrix.",
            "The covariance matrix has at least across objects in feature space.",
            "Has this blocks within blocks structure, where two objects that are nearby each other are very similar to each other, but less similar as you go across as you traverse the tree.",
            "It turns out that you can compute the singular vectors of this harkavy structured covariance matrix, and they respect the hierarchical structure of the tree in the sense that the largest well there's a uniform singular vector.",
            "Right, the second singular vector over here makes the coarsest grained distinctions across the tree.",
            "It can discriminate, say, between animals and plants OK?",
            "The next singular vectors of slightly smaller singular value make finer scale discriminations, say different types of animals in different types of plans and then the finer singular vectors make individual item discriminations.",
            "OK, so basically.",
            "If you put the two and two together because the strongest singular values are associated with singular vectors that make the most coarse grained distinctions on the tree, the internal representations, the network will evolve so as to only make the most coarse grained distinctions OK, and then it will.",
            "Overtime it will make finer and finer scale distinctions.",
            "You can read about all of this in sort of published paper."
        ],
        [
            "First, we can compute the singular values theory and experiment match up."
        ],
        [
            "Well, so basically yeah, so this is what I was saying.",
            "The network learns stronger singular values first, the associated singular vectors progress from course define.",
            "So internal Rep."
        ],
        [
            "Stations the network will progress from coarse to fine, so this is an analytically derived.",
            "Multidimensional scaling plot of the learning dynamics in the deep linear network, and."
        ],
        [
            "You place it next to the simulations of these nonlinear neural networks.",
            "You see, there's a.",
            "There's a very nice qualitative match.",
            "OK, so this is kind of the difference between simulation and theory.",
            "The theory gives you sort of conceptual insight into why the nonlinear simulations worked the way they did.",
            "OK, and I'll come back to this when we discuss generalization in deep networks later on.",
            "OK, so by the way, you know as we want."
        ],
        [
            "I do science in deep learning.",
            "I just wanted to highlight this method where.",
            "You know, the only way we could do science is when we had a mathematically well defined model of the data set.",
            "I know that in machine learning there's a strong culture of winning competitions.",
            "OK, I kind of said this last year and I thought I was going to get eggs thrown at me, but I didn't.",
            "So I'll say it again.",
            "It's a horrible culture, right?",
            "It's because you overfit to the.",
            "Yoshua started the applause and he did last last time, so he saved me.",
            "But but I'm glad.",
            "I mean, that's why ya shinai collaborate?",
            "Because we see eye to eye on a bunch of things.",
            "But but basically, why is it a horrible culture?",
            "You're rewarded for tuning hyperparameters to no end to get good performance in a very narrow regime of hyperparameter space.",
            "OK, we saw beautiful talk by Phil Bun somewhere.",
            "You know, if you really tune hyperparameters, LS teams do better than all the other highfalutin methods on sequence processing, that's great.",
            "But he also said something really interesting.",
            "Every single child with a normal upbringing learns language.",
            "They never get screwed up and never not learn language 'cause their hyperparameter was slightly wrong or they got a bad in it, right?",
            "So the brain is extremely robust.",
            "Two choices of hyperparameters likely because there is individual variability across brains.",
            "Yet we can all communicate with each other.",
            "So the goal should be to get algorithms that may be achieved slightly worse performance, but our robust across hyperparameters, or even better, if we really want to understand what's going on in our systems, we should look at toy problems.",
            "Toy problems where the task is mathematically well defined, you're not going to build a reason about learning dynamics on image net because image net is not a mathematically well defined data set.",
            "But you might be able to reason about learning dynamics in datasets that mimic the essential structure of Imagenet, but maybe at a toy level, right?",
            "So there should be a lot of work in this field on the Genesis of mathematically well defined datasets that may not be the competition datasets, but we can start to reason about how networks.",
            "Learn represent the data and generalize right so when you're reviewing a paper and you see a paper like that, don't write it off.",
            "And also you'll improve your daily lives because I know a lot of grad students are just tuning hyperparameters all the time.",
            "You don't enjoy that, do you?",
            "Let's start thinking alright anyways.",
            "So sorry I didn't mean to go that far.",
            "I let me walk back that statement.",
            "I'm going to stop now and go back to, uh, not doing polemics.",
            "OK, so.",
            "OK, so you do."
        ],
        [
            "Yeah.",
            "Maybe?",
            "Very similar to what?",
            "Paper.",
            "Very close.",
            "Yeah.",
            "Yeah.",
            "Yeah it.",
            ", expected, yeah, you don't need multiple scales to get the saddle point for any data set where you have any set of non trivial single values, you'll have a saddle point associated with each of those.",
            "I mean.",
            "Potentially I don't see an immediate connection but but we can talk about that afterwards.",
            "There's a whole bunch of stuff and like when things are learned and so on.",
            "There's just one.",
            "Let's you do have time.",
            "I'm going to skip."
        ],
        [
            "I'm going to skip this as well.",
            "We'll come back to it that there is this notion of, like you know, there are certain things called coherent categories.",
            "An incoherent categories, right?",
            "So for example.",
            "You know the set of all things that are blue is intuitively an incoherent category.",
            "The set of all things that are dogs is a very coherent category.",
            "We have a name for the latter, but not a name for the former, and so the question is like, what is it that makes a category coherent and?",
            "Understand.",
            "Is incoherent OK?",
            "Let me go through this section 'cause it's actually kind of interesting and it also talks about learning dynamics and statistical structure.",
            "So let me explain.",
            "Yeah, you're right, that's a very good question because I haven't defined in coherent or coherent right that was a problem in the psychology literature.",
            "It was just this intuitive notion that there are some categories that are natural IE coherent, and some categories that are not.",
            "So.",
            "And you can see this in like a bunch of psychology phenomena.",
            "If you ask questions about Korean categories, you get answers more quickly.",
            "But if you ask questions about inquiring categories, get answers more slowly so.",
            "So you know, in defining any category, you kind of have to solve these two matched problems, right?",
            "A you need to identify the objects that belong to the category.",
            "But you know, in order to do that, you need to know which features are important for the category.",
            "For example, the color of a bird is often not important for determining whether something is a bird, because color varies across the set of birds.",
            "Quite a lot.",
            "Of course, wings is very important for being a bird.",
            "OK so but what if you could identify the features that are important for category?",
            "Well, you can't do that until you know which objects are part of the category, so there's a sort of Gordian knot, right?",
            "So.",
            "How might even simple neural networks simultaneously bootstrap and solve this Gordian knot to both simultaneously simultaneously identify which objects are part of the category and which features are belong to the category, right so?"
        ],
        [
            "Here's an example of a simple data set where you have a.",
            "It's just a bunch of feature vectors, right?",
            "So you have about 1000 objects and 1600 features, and they appear to occur randomly, right?",
            "This mimics the structure of experience where you just see one object at a time, and you don't see a bunch of objects from the same category.",
            "You just see one object at a time, so this is again my son.",
            "My lab gave him a pink Unicorn as a gift.",
            "His looking time went up when he saw this pink Unicorn, but he's seeing a whole bunch of features, right one at a time.",
            "It kind of mimics that.",
            "I don't really understand."
        ],
        [
            "My son works, so I'll replace him with something.",
            "I do understand.",
            "Deep linear network.",
            "So what if we expose a deep linear network to this?",
            "This analysis of this data set so we can look at the learning dynamics.",
            "And as you can see, so color indexes time you can.",
            "So this is a multidimensional scaling plot of the initial representations, the color.",
            "So there's a whole bunch of objects that didn't get learned.",
            "They stayed at the center of the space, but there's three groups of objects that got learned OK.",
            "So why did they get learned?",
            "You can look at the singular vectors or weight matrices of learn neural network and reorder both the objects and feed."
        ],
        [
            "Is according to that and you find that actually hidden."
        ],
        [
            "In this data set, there were three clusters where within one cluster there was a subset of features and a subset of objects that had high probability of occurring and not otherwise yeah.",
            "This is an autoencoder.",
            "Yeah, it's unsupervised learning autoencoder.",
            "Yep.",
            "OK, so this raises an interesting question, right?",
            "How long did it take to learn each category, like when did it separate?",
            "See that the biggest."
        ],
        [
            "Category separated the earliest OK and then other categories.",
            "Smaller categories separated later, and so on and so forth.",
            "It turns out we."
        ],
        [
            "Come up with a very simple theory for when these categories get learned.",
            "Basically, if you have a universe of some number of objects and some category of a certain size of a number of objects coherently varying, yeah.",
            "So so K0 is the number of objects in the category.",
            "KF is a number of features in the category, and then there's a signal to noise ratio.",
            "Let's say P is the probability of a feature being present an object if the categories within the category feature both in the category.",
            "If the feature an object are both in the category.",
            "And Q is the probability if it's outside, right?",
            "So there's a signal to noise ratio, which is the difference in means over the standard deviation of the noise, and as long as the product or the size of the category of the product of the number of objects and features is bigger than the square root of the total size of the universe, the total number of objects and the total number of features, then and only then can this network learn this category.",
            "OK, it turns out this is related to the singular value of the of the input output covariance matrix.",
            "So this is a quantitative measure of category coherence.",
            "So a coherent category, at least in this simple model is a large set of objects that simultaneously share a large set of features.",
            "That's why the set of all things that are blue is incoherent, because there is not a large set of objects that not only share the property of blue, but also share a whole bunch of properties that Co occur with blue.",
            "But the set of dogs is a coherent category because there's a large set of objects out there, dogs that all have fur, all have four legs.",
            "All bark, all are cute.",
            "We evolve them to be man humans best friend, right?",
            "Like so dogs is a very large Co occurring cluster.",
            "By the way, this is strong low rank structure in this matrix, and this is what neural networks do.",
            "They're very good at picking up low rank structure.",
            "Even the nonlinear ones.",
            "OK, yeah.",
            "So the categories.",
            "Yeah, yeah, yeah, that's right.",
            "Well.",
            "I have a question.",
            "These areas holding much together, I wonder where was that map?",
            "Both in that map, both math and theoretical computer science.",
            "Then this last thing you are mentioning is related to the.",
            "Yeah yeah, yeah.",
            "Yes yes yes.",
            "Understand their relationship with this.",
            "Yes yes.",
            "Yeah.",
            "This one is, but they don't work and they may be better in the same yeah.",
            "Yeah, so it's a very astute question.",
            "Actually, this inequality does mark the onset of a phase transition actually, and that's how we derived it.",
            "It's a phase transition in random matrix theory where if you have a singular value that rises above this threshold and the associated singular vector will match the associate singular vectors will match object membership and feature membership.",
            "But if you're below this threshold, that will not.",
            "So this is related to eigen singular value transitions in random matrix theory in this phase.",
            "If you want we can talk about in much more detail afterwards, but I just don't have time to derive it here, but I can give you the answer because the final answer is extremely intuitive.",
            "Note that it places you can detect very tiny categories in a very large universe because there's a square root here, right?",
            "But there's no square root here, so even when the SNR is only one like, you know, a category that has maybe 20 objects with 20 covarying features can be easily detected among 1600 objects or 1600 features and 1000 objects.",
            "So even these deep linear networks are quite powerful at detecting this kind of structure, buried in noise.",
            "OK, but of course there are limits OK?"
        ],
        [
            "We can generalize this to hierarchically struck."
        ],
        [
            "Your data and so on.",
            "I'm going to skip the analysis of nonlinear networks, but that led to interesting initializations."
        ],
        [
            "These are orthogonal installations, and we're actually continuing to work on that.",
            "I think we can resurrect the teenage.",
            "With that we were kind of doing some that some of that right now, so any case."
        ],
        [
            "Let's move onto OK. 12:30 is my OK perfect alright so.",
            "Oh sorry OK so so, OK what about nonlinear networks and trainability, right?",
            "So there's a kind of this classic question of why can we even train these networks?",
            "The error landscape is horribly nonconvex.",
            "Why don't we get stuck in local minima at high error?",
            "And there's been."
        ],
        [
            "A bunch of work on this recently.",
            "You know we had some work with Yoshua Bengio on this unichrome Oscar with Jan Lacune had a slightly different perspective, but we essentially get to the same conclusions, right?",
            "So the basic idea is often thought that local minimum at high error stand as a major impediment to nonconvex optimization, and this is this is a non convex error landscape over a low dimensional space and indeed you do have local minimum at high error, right?",
            "But actually, we know that our sort of geometric intuition derived from living and moving within a low dimensional world is woefully inadequate for thinking about high dimensional spaces.",
            "And it turns out that error landscapes over high dimensional spaces.",
            "Don't have this property.",
            "Instead you get a whole bunch of saddle points.",
            "The same saddle points that we talked about earlier show up.",
            "And then we developed an algorithm that can rapidly escape saddle points."
        ],
        [
            "So, so here's the basic intuition.",
            "OK, let's say that you have an error landscape over the weights of a neural network where you have millions of parameters, right, millions of weights OK.",
            "So this is a scalar error function over over 1,000,000 dimensions.",
            "Let's say the gradient vanishes, so you're at a critical point.",
            "What are the chances that that critical point is a local minimum so that the error landscape curves up in all 1,000,000 directions?",
            "Because there's a million directions, it's highly unlikely that the error landscape will generically curve up in all 1 million directions.",
            "Unless you're already near the bottom, OK.",
            "So this can be made more quantitative and Cisco physicists made this quantitative not for deep neural networks, but for.",
            "But for random landscape, so imagine that you just have a random Gaussian error landscape.",
            "So think of this as a single draw from a Gaussian process.",
            "OK, over a million variables.",
            "So it's like this random wiggly landscape.",
            "That's kind of smoothed over some length scale.",
            "OK, so you have the single random landscape.",
            "It's going to have many, many critical points where the gradient vanish is OK. You can take each critical point and put it in a 2 dimensional feature space.",
            "One is it's errorlevel or its height.",
            "The height of the critical point and let F be the fraction of negative curvature directions, right?",
            "The fraction of directions that are eigenvalues, the Hessian that are negative versus positive where it curves up.",
            "OK, so you might think a priority that critical points could appear anywhere in this 2 dimensional feature space, but actually there's an interesting concentration of measure phenomenon where they tend to concentrate on a monotonically increasing curve, OK?",
            "So.",
            "So of course the global minimum lies here.",
            "It has the lowest error and all the directions curve up, so the fraction of negative directions is 0.",
            "The global maximum sits here, so that's the highest error and all the directions curve down, so the fraction negative eigenvalues is 1.",
            "But basically as you go up and up, what happens is the critical point develops more and more negative curvature directions so that the number of negative curvature directions is tightly correlated with the error.",
            "The error level.",
            "This has two major implications.",
            "There are no local minima at high error, IE.",
            "There's nothing over here.",
            "And if you get stuck in a global minimum, your errorlevel is sorry if you get stuck in a local minimum, your error level is close to that of the global minimum.",
            "OK, IE that you'd be over here, OK?",
            "So now this is a strong prediction, right?",
            "But it's a prediction generated from random landscape theory.",
            "Physicists are used to the idea that there are certain questions whose answers don't depend on the details.",
            "That's why we can make.",
            "That's why certain properties of water and ferromagnets have the same quantitative characteristics.",
            "So.",
            "So I predicted this sort of qualitative curve would be similar for deep neural networks.",
            "Of course, computer scientists are a little different.",
            "They think what they're doing is special all the time, and so they would say no, no, no.",
            "Our deep neural network landscapes are very, very special.",
            "They're not anything like your random landscapes.",
            "It won't look at all like this.",
            "OK, but this essential concentration of measure phenomenon comes from a very simple universal argument in a high dimensional space, it's highly unlikely for all directions to curve up unless you're already near the bottom.",
            "That intuition should generalize to neural networks, and it turns."
        ],
        [
            "It does so so so you know.",
            "Collaborated with Yoshua Bengio slab some very talented grad students in his lab tested the prediction from random landscape theory, and they did indeed.",
            "So you can use Newton's method to search for these critical points once, and you do indeed find this concentration of measure phenomenon, where as the error level goes up, the fraction of negative eigenvalues goes up both for an endless problem and on cifar 10 problem.",
            "For all the eigenvalues.",
            "Positive exactly.",
            "It.",
            "This comes out of the model way where you model each of the eigenvalues as independent.",
            "No, we don't model the eigenvalues is independent.",
            "We model the landscape is correlated.",
            "But in any case these are just numerical results and problems that people care about, right?",
            "So this is just a simulation, right?",
            "The more general argument, though, is yeah.",
            "Based on them being independent, but it's no not at all.",
            "Actually, if you take just a random symmetric matrix, OK?",
            "Very famous result that the eigenvalue distribution density obeys of ignore semi circular law.",
            "But there's eigenvalue repulsion.",
            "So the joint distribution of is not independent but you do get this density.",
            "So both the physics derivation and the random matrix theory ideas do not assume independent eigen values.",
            "We can talk more about that in detail.",
            "Um?",
            "OK, what can we do about this?"
        ],
        [
            "So the basic idea is so actually, why does Newton's method find saddle points?",
            "Of any index or fraction negative eigenvalues.",
            "It's because Newton's method does gradient descent.",
            "It does gradient descent, but it pre multiplied by the inverse Hessian, right?",
            "So if your Hessian so this is a very good idea.",
            "If your local model for your function is a quadratic bowl, because Newton's method will descend a quadratic bowl in one step.",
            "That's how it was derived.",
            "But if we know that there are all these negative curvature directions, the additional negative sign in the Hessian turns you around and makes you go uphill, right?",
            "So for example in this eigen direction, the Hessian has a positive eigenvalue.",
            "So following Newton's method you go downhill.",
            "But here you have a negative eigenvalue, so the negative gradient would go this way.",
            "But the extra - turns around and makes you go up.",
            "That's why Newton's method gets attracted to saddle points, which is why we could use it to generate the curves in the previous.",
            "Previous plot OK so a very simple fix is just to divide by the absolute value of the Hessian, which is by definition a matrix that has the same eigenvectors but all the eigenvalues are replaced with their absolute value.",
            "And there's a way to think about this in terms of a trust region method."
        ],
        [
            "And so this actually, you know, this is just more evidence that saddle Points might indeed be an impediment.",
            "Optimization, which is that you know if we do stochastic gradient descent on the deep auto encoder problem in a recurrent neural network problem, we find that stochastic gradient descent gets stuck in a plateau OK.",
            "Uh, but if you snow this plateau might be seen as evidence of a local minimum, but actually that's an illusion because if you switch to the saddle Free Newton method, you suddenly see a drop.",
            "OK, so basically you are stuck in the plateau surrounding a saddle point and stochastic gradient method couldn't rapidly escape it and exploit the negative pressure directions to turn make the error go down, but saddle free Newton could.",
            "Now that's good news.",
            "What's the bad news?",
            "This is a second order algorithm, so it's very difficult to scale up.",
            "There could be interesting research to be done in marrying approximate 2nd order methods with saddle Free Newton and I don't think either yashan are working on that, so that's a good good take home project, yeah?",
            "Respect by just lowering the learning rate.",
            "Once you get this kind of flash, yeah, yeah that's yeah, seems like.",
            "That wouldn't work if what you were.",
            "So here's an alternate explanation for the lowering the learning rate, so in lowering the learning rate you may be bouncing around, right?",
            "You know over different things, but then if you lower the learning rate then you won't bounce around and you'll go down.",
            "Saddle point so I'm kind of curious, is this what you're seeing here?",
            "Like maybe it isn't that you're out of Saddle Point, it's that your your method is actually adopting.",
            "Yeah, effectively lower.",
            "We never changed the learning rate.",
            "I mean we did pre multiply by Hessian so.",
            "Usually what happens is that increases the learning rate because what you do is you use the shallow curvature directions and escaped them.",
            "But you're right, we should.",
            "We could look at the trajectory and see if it preferentially aligns along the small eigenvalues and absolute value of the Hessian or the large eigenvalues.",
            "If it's a large ones, we're lowering the learning rate.",
            "If it's a small ones were increasing the learning rate, that would be the test.",
            "It's a good test to do.",
            "Like like so the the argues that lowering the learning rate, that's sort of like finding this narrow minima.",
            "If that's the case, then I guess you would expect this to decrease the learning rate as well.",
            "Can you be going from like low curvature to the icon return?",
            "Yeah, OK, so there was further simulations that Yoshi's Group did, which was we looked at the spectrum of eigenvalues.",
            "Each time we saw this drop of the Hessian and when we saw this drop we found that the maximum negative eigenvalue went.",
            "Up in absolute value, right?",
            "So it did seem that while this drop was happening, the local region around the function had lots of negative curvature OK?",
            "We didn't look at the inner product between the gradient and the eigen directions, which would be a finer resolution analysis to do.",
            "Yep."
        ],
        [
            "Yeah.",
            "Yeah.",
            "That fixes the - problem.",
            "There's a.",
            "There's another derivation of that, using trust regions, but I want to get on to other others.",
            "There's lots more fun stuff to do."
        ],
        [
            "OK, so.",
            "OK, but for generalization you may not want to optimize very well.",
            "That's a theme that's going to come up later on, so that's another issue.",
            "Well, we'll talk about that.",
            "OK, so now what about expressivity?",
            "OK, so why is it that suddenly when you go deeper you can do more stuff?",
            "What is it that a deep function can buy you?",
            "The shallow function cannot.",
            "OK, so we worked.",
            "We did some work on this and there's also other work that I'll talk about where we actually connected deep learning to the theory of chaos so it actually turns out that Chaos Theory is a special case of deep learning.",
            "Now that's I don't know if that's good news or bad news for deep learning theory, but it's important to know that deep networks can have a chaotic phase, and you may wish to avoid it, but it has.",
            "It has a dual viewpoint.",
            "The chaos can be the origin of high expressivity as well.",
            "So I'll talk.",
            "I'll tell you what I mean about that.",
            "So that's all in this, you know.",
            "Luckily like, I'm just trying to give you a flavor of everything.",
            "I don't expect you to understand everything in this talk, but almost everything I'm talking about is published.",
            "So if you're interested, you can see the detail."
        ],
        [
            "OK, so this is work with my grad student Ben Poole.",
            "He's kind of the ringleader of this work and it's also collaboration with my friend Josh, who also had a companion paper.",
            "Looking at Relu Networks, and we looked at NH Networks in a different different kind of theory.",
            "OK, so the basic question again is what kind of function can deep networks expresses?",
            "Shallow networks cannot so."
        ],
        [
            "Course we know that networks with one hidden layer are universal function approximators.",
            "So why do we even need depth well?",
            "In general, the universal function approximation theorems yield no guarantee on the size of the hidden layer required to approximate any particular function well.",
            "OK, so the overall idea is that maybe there exist special functions that can be computed very efficiently using a deep neural network using a polynomial number of neurons in the input dimension say, but not by a shallow network.",
            "IE you require exponential number of neurons OK?",
            "So this goes back to intellectual traditions and Boolean circuit theory and circuit complexity.",
            "The parity function is such a function.",
            "You know, if you have if you have a certain depth of logic gates, you can compute the parity function easily using a small number of logic gates, but not if you have limited depth logical depth in your in your circuit."
        ],
        [
            "OK, so there's been a bunch of work that kinds of has the following flavor.",
            "They look at a particular non linearity and they have a particular measure of functional complexity, say Ray Lewis and the number of linear regions.",
            "So if you have a rail network with one neuron, is the output in a high dimensional input that computes a piecewise linear function over input space so one potential measure of functional complexity is the number of linear regions and what they can show is that they can show that there exists a special function computable by a deep network.",
            "Sorry there exists a special function where the number of linear regions is exponential in the depth.",
            "And so in order to approximate this function with a shallow Relu network, you would need exponentially many Relu units.",
            "But using a deep network, you only need a polynomial number of units, and the basic idea is you construct these tent functions and then you recurse it.",
            "OK, you can find the details on this in this picture, but basically what this is showing is that there exists one function OK that has this depth efficiency.",
            "OK."
        ],
        [
            "There's other examples, for example a some product network.",
            "You know, some product network computes high degree polynomials, right?",
            "And a natural measure of the complexity of a polynomial is a number of monomial's the number of terms.",
            "If you just have a shallow some product network, or you can show that there exists individual sum product networks where you can compute polynomials that are exponential in the depth just by composing polynomials, you can get the degree of the polynomial be exponential adept, but if you do it with one layer of some product, you need exponentially many some product units.",
            "OK, so again, that's one function that has this depth efficiency."
        ],
        [
            "OK, but this raises natural questions how, how?",
            "Natural are these functions from the perspective of AI?",
            "Right are these functions rare?",
            "Curiosity's, and they're not really the types of functions we actually want to compute in practice.",
            "Or is this phenomenon much more generic than these?",
            "Then these specific examples is in some sense, any function.",
            "Computed by a generic deep network not efficiently computable by shallow network.",
            "Right, if so, we would like a theory of deep neural expressivity that does this for arbitrary nonlinearities.",
            "Is not tide to any particular non linearity.",
            "And it's an we use potentially a more natural general measure of functional complexity."
        ],
        [
            "OK, so another way to think about it is various previous theoretical techniques.",
            "Because of a limited theoretical technique, there were tide to a particular linearity in a particular measure, functional complexity.",
            "What we do is we use a slightly more general set of techniques.",
            "We combine Romanian geometry, which is the, which is a theory of curvature and geometry with dynamical mean field theory, and this is powerful enough to analyze the expressivity of arbitrary nonlinearities.",
            "And we use extrinsic curvature as a measure of complexity, and we will show what will show is that.",
            "Even in a generic random deep network, here's the physicist comes out in me.",
            "I'm now analyzing a random network which I said was not a good thing to do, but for expressivity it's OK. Alright, so we.",
            "We show that a random deep network the functional curvature can grow exponentially with depth but not width.",
            "And the origins of this exponential growth can be related to chaos theory.",
            "So basically that's the strategy we're going to show a random deep network and do stuff that no shallow network can."
        ],
        [
            "OK, and by the way, this is relates to disentangle ING of neural representations, but I won't have time to talk about that."
        ],
        [
            "OK, so here's the basic idea.",
            "Just pick a random network where the weights and biases are iid Gaussian.",
            "That's it, and you have an arbitrary non linearity, which I'll call Fi.",
            "OK, so the weights are iid Gaussian.",
            "They're scaled by 1 / N so that the weights and biases operate on equal footing.",
            "And as N goes to Infinity, there's a well defined limit, OK?",
            "When is the width so ensival is the number of layers neurons in layer L?",
            "We can ask very basic questions."
        ],
        [
            "Like if you have a single point that propagates through the network you know does it grow or shrink, i.e.",
            "You put in a single feature vector.",
            "Here an input vector here just its length grow or shrink as it propagates through the network.",
            "More importantly, if you take a pair of points.",
            "So if you take 2 inputs that are might be close to each other as they propagate through the network, do they become more similar to each other overtime or do they decorrelate and become more different overtime?",
            "OK, that's a very basic question.",
            "As they become more similar.",
            "That's what I call the ordered regime where basically the network makes everything similar.",
            "If you even take nearby inputs and as they propagate through the network, if they decorrelated become more different than the network is fundamentally amplifying small initial differences and making them very different.",
            "That's the very definition of chaos.",
            "A sensitivity to small changes and initial conditions.",
            "So that's the chaotic regime.",
            "Yeah, it's like it's like I have an, you know, an image, net, image and a very tiny perturbation of the image.",
            "Net image.",
            "Yeah, so that's two input vectors, right?",
            "An image.",
            "So you can equate image with a point or a vector in this language, OK?",
            "And then also a smooth smooth manifold.",
            "OK, so I'm going to skip the issue of a thing I'm just going to tell you the answer.",
            "OK, I'm going to skip the derivate.",
            "Basically we can analyze that.",
            "We can analytically compute how similarity structure propagates the network and it makes these predictions OK. Oh, where'd it go.",
            "Sorry.",
            "Yeah, purf."
        ],
        [
            "OK, so there's a phase diagram for this network, so this is the standard deviation of the weights.",
            "This is the standard deviation of the biases OK?",
            "This is the correlation coefficient between two inputs as they propagate through the network, it reaches a fixed point.",
            "And what happens is there's a boundary between order and chaos.",
            "So here what happens is so if the biases are large.",
            "So what biases do?",
            "Biases are independent of the input, so they push your state of the network in the same direction regardless of what the two inputs were.",
            "So biases will always tend to align two different inputs and make them similar to each other.",
            "However, as you crank up the weights and you have a non linearity, a teenage non linearity.",
            "The large weights can overwhelm the common bias, and eventually it'll decorrelate the inputs and make them dissimilar from each other.",
            "So basically when the weights are large by an amount that depends on the bias, the simplest one is when the bias is 0, the weights have to have a standard deviation of 1.",
            "Then you're in this chaotic regime where two inputs will decorrelate.",
            "However, if you're in this regime, two inputs will correlate.",
            "OK, so this is the edge of chaos.",
            "A boundary between a chaotic regime and ordered regime.",
            "What is the?",
            "OK, let me now.",
            "Discuss what happens to a smooth manifold as it propagates to the network, because that will give you a more visceral image of what the case."
        ],
        [
            "It looks like so now.",
            "Let's imagine that you have a manifold of images.",
            "Let's say it's like a cat at different orientations or positions or something like that.",
            "OK, as this manifold propagates through the network OK. You can ask how does its geometry change."
        ],
        [
            "OK.",
            "So this is what it looks like in the ordered regime when the weights are small.",
            "Right, this is a tannage non linearity.",
            "So when the weights are small, you're basically exploring the linear range of the teenage.",
            "And the teenagers are compressive non linearity, so it ends in the sense that it's slope is always less than or equal to 1.",
            "So it tends to compress things and the weights are small so tends to compress things.",
            "So basically the circle propagates through in a linear manner and it remains a circle.",
            "But what happens is the weights get larger so that you explore the nonlinear regime of the teenage.",
            "Then what happens is the circle every pair of points on the circle will decorrelate and the circuit becomes circle becomes more and more ruffled.",
            "OK, and at a larger weights it becomes more ruffled, more quickly.",
            "OK, so this is what the chaos does to inputs.",
            "OK, intuitively, why is this happening?",
            "Just imagine the circle propagating through the network, right?",
            "You have these large weights that expand the circle, but then you go through the non linearity which folds the circle.",
            "So you have this expansion, folding, expansion, folding, and that's the origin of the roughly OK. All of this English can be translated to math and you can get a quantitative match between theory and experiment.",
            "That's what we see here.",
            "This is the autocorrelation.",
            "The solid curves are theory.",
            "The dots are simulations, and there's a nice match, but I'm just giving you the essential intuition behind what goes on in the chaotic regime.",
            "OK."
        ],
        [
            "This is another example of what goes on.",
            "Let's.",
            "You think that this is an artifact of linear dimensionality reduction.",
            "What happens is.",
            "The the this is a teapot of the circle in the chaotic regime, and you can see that it gets more and more ruffled now just to make a Long story short, what we can show is that the global curvature of the circle for a wide range of nonlinearities grows exponentially with depth, and also the length of the circle grows exponentially with depth.",
            "As you get this iterated expansion and folding expansion folding and that gives you this exponential growth, then we."
        ],
        [
            "Yeah.",
            "You know it's not learned, it's just a random network, just a random network, yeah?"
        ],
        [
            "We can quantify the curvature using ideas from Romanian geometry, but I'll skip it.",
            "I'll just tell you the."
        ],
        [
            "This is the match between the propagation of curvature, both theoretically."
        ],
        [
            "And numerically, but what I'll tell you is now the depth separation.",
            "Let's say that you take the same circle and you propagate it through one layer.",
            "Right, so this is like your shallow network and you can make this layer as wide as you want.",
            "OK, we can prove a theorem that says no matter how you choose the weights of this of the shallow network, no matter how you choose them, you can never get the length of the circle to grow faster than the square root of the width.",
            "OK.",
            "So the result, the spirit of the result is the following.",
            "Pick any random deep network.",
            "If it's in the chaotic phase.",
            "The global curvature in length of a circle will grow exponentially with depth.",
            "Doesn't matter which weights you choose with high probability for any random weights that will happen, But if you limit yourself to death one, no matter what weights you choose, the corresponding quantities can't grow faster than square root of the width.",
            "So depth and width have very different effects, especially in this chaotic regime.",
            "OK, so."
        ],
        [
            "By the way, the same goes for decision boundaries.",
            "We can show that decision boundaries can acquire exponential curvature."
        ],
        [
            "And we have to look at the curvature of codimension of N -- 1 dimensional manifolds."
        ],
        [
            "And we quantify that and so on."
        ],
        [
            "OK, so so.",
            "So deep neural networks can have this expressivity if they go into this chaotic regime."
        ],
        [
            "OK, so now let's discuss what time.",
            "OK, good a few more minutes and it will end generalizable.",
            "It is easy 'cause we don't really know nothing about it.",
            "OK, so."
        ],
        [
            "So I will tell you one situation where we recently worked out everything about General Zhao generalizability, but for a shallow net for shallow network, OK, not for a deep network.",
            "So generalizability is intimately related to the field of high dimensional statistics, right?",
            "So there's been kind of a revolution in the way that we do experiments before we used to carefully figure out what we want to measure.",
            "And then we take many, many data points.",
            "So this is situation with a number of data points is going to Infinity and the dimensionality of the data is order one.",
            "Now we're in a situation where both are large and the ratio is less than one or order one right.",
            "In particular for neural networks we overparameterized our system so the dimensionality of over which of the space over which we're learning can be many, many millions of parameters, and the amount of training data can actually be less than that.",
            "The amount of training data can be less than the number of parameters were trying to learn.",
            "That's the so called high dimensional regime and we've been working a lot.",
            "This is very relevant to neuroscience because in neuroscience we can now record from hundreds to thousands of neurons, but we don't get that many trials.",
            "We get hundreds of trials, so neuroscientific data is in the high dimensional regime.",
            "Deep learning training is in the high dimensional regime.",
            "We need a theory for that.",
            "So we recently worked out a theory of the best way to do regression in the high dimensional regime.",
            "That's the physical review X paper, and I'll just tell you the basic idea, 'cause I think there's some lessons.",
            "That we can take away to deeper networks there so."
        ],
        [
            "Here's the basic idea.",
            "You have a just doing regression OK, linear regression.",
            "Actually it's not OK.",
            "The general model is linear, but the estimation algorithm is not not linear.",
            "So basically imagine that you have some unknown set of regression coefficients.",
            "So this is just like a one layer neural network with one one output neuron, S 0 is a set of weights.",
            "You get some training data.",
            "The output is the input dotted with S0 plus some noise.",
            "OK, you don't get to see the unknown regression coefficients.",
            "You only get to see the training data and from that you have to estimate S at.",
            "There's a wide variety of estimators in statistics known as M. Estimators were basically what you do is you minimize some cost function.",
            "Right where you penalize the difference between your output and what you'd get.",
            "If your regression conferences were S. Right, and you optimize that over S and maybe you add a regularizer to your unknown regression coefficients S so your estimated regression coefficients reflect a compromise between matching the training data and regularising.",
            "OK, we're familiar with that.",
            "That's what we do in deep learning as well.",
            "OK, but the key issue is what loss function do we use row, and what regularizer should we use OK?",
            "To get the best performance, OK, the best performances, of course.",
            "Minimizing generalization error.",
            "OK, for this simple scenario, generalization error is directly in monotonically related to the L2 error between our estimated regression coefficients and our actual regression coefficients.",
            "So we want to minimize L2 error OK.",
            "So now there's a ton of algorithms out there for doing this, and they both correspond to different choices of the measurement penalty or loss function and the regularizer, right?",
            "So, for example, lease you have least squares maximum likelihood, Ridge regression, lasso, elastic net map estimation.",
            "They're all special cases of this very general framework.",
            "But which algorithm is the best one OK?",
            "So we answered this question recently, OK?",
            "Where again best is minimizing this L2 estimation error, which is equivalent to minimizing generalization error in this setup.",
            "OK, so."
        ],
        [
            "I'll tell you what the answer is.",
            "It depends on how much data you have.",
            "The right thing to do depends on how much data you have.",
            "There's no data independent answer to this question.",
            "OK, so the basic and So what do I mean by the?"
        ],
        [
            "Out of data we're in this high dimensional setting where we have P unknown regression coefficients and end measurements, right?",
            "So the measurement density is the ratio of the number of data points to the number of variables you're trying to estimate.",
            "Get this ratio.",
            "Alpha is the all important ratio when Alpha is large you have lots of data.",
            "High measurement density when Alpha small, which is where we live.",
            "In deep learning you have not many training points.",
            "Lots of parameters to estimate OK."
        ],
        [
            "It turns out.",
            "So this is an example where of course it depends on the signal and noise distribution as well.",
            "Let's say the signal and noise are Laplace distributed, then maximum likelihood corresponds to an absolute value penalty and an absolute value loss regularizer, right?",
            "It turns out at large measurement density.",
            "Sorry, that's map estimation right at large measurement density map estimation is optimal.",
            "You cannot do better than map.",
            "That's what we show.",
            "But at lower measurement density, it turns out that you don't want to do map anymore.",
            "You actually want a smooth, not nonlinearly, smooth.",
            "Your your loss function in your regularizer.",
            "And Interestingly enough, when Alpha gets close to 0 or less than one, this nonlinear smoothing leads to a quadratic loss and a quadratic regularizer.",
            "Independent of the signal and noise distribution, as long as they're log concave.",
            "OK, so actually Ridge regression is the best thing to do.",
            "When you have very little data.",
            "So ironically, you ignore the distribution of signal and noise when you have very little data and you'll do better.",
            "So we were able to analytically compute the generalization error as a function of the amount of measurement density.",
            "And we did indeed find that and so the solid curves are theory.",
            "The dots are simulations, they match up, and we do find that at high measurement density map is best at low measurement density, quadratic is best, and quadratic matches the performance of the best algorithm whatsoever.",
            "OK.",
            "So that's kind of what it's saying is.",
            "At low measurement density, you don't want to solve the original map problem.",
            "You want to solve a mucked up fuzzy smooth version of the map problem.",
            "IE bad optimization is good generalization.",
            "We can show that analytically in the simple scenario, but of course in deep learning we can't show anything but I."
        ],
        [
            "Just wanted to see what time is it.",
            "We started about 5 minutes.",
            "I'll end in two minutes and then you can ask questions if I end in two minutes I'll be on time so.",
            "There have been some recent results in deep learning that yields surprising properties about generalization deep networks I think are very interesting now.",
            "Why are they surprising?",
            "Of course, anything is surprising if and only if it mismatches theorems that you already know, or intuitions that you already have.",
            "So what are the theorems that we know about?",
            "Controlling generalization error.",
            "The basic idea is we know that the error on the training set will always be.",
            "Less.",
            "Sorry, the error on the generalization error will always be larger than the training error, right?",
            "The only issue is by how much OK.",
            "So there are various measures or upper bounds on the generalization error in terms of the training error plus some complexity measure.",
            "One particular complexity measure is Rademacher complexity, which basically tells you how well can you memorize a data set with a bunch of random labels.",
            "This Rademacher complexity is the correlation coefficient between after you train how well the output correlate with the random labels, so typically.",
            "What happens?",
            "Is.",
            "If this is the the number of training examples with a small number of training examples, you can memorize anything so the Rademacher complexity will stay at one.",
            "But as the amount of training data gets larger and larger, it will typically fall off like one over root N and so for example for linear decision boundaries.",
            "This is the end at which it falls off.",
            "Is the VC dimension.",
            "For example, if you're familiar with the dimension, but basically what it's saying is if you're in nine seconds point OK if you.",
            "If you're in this training regime was overkill, so if you're in this training regime where you can memorize the data, then you shouldn't be able to.",
            "Well, this theorem provides no guarantees on generalization, right?",
            "Because this is for a two way classification, so an error of 1 an error.",
            "Probably if one is awful right there, if the Rademacher complexity is 1 then you're in big trouble.",
            "Right, but only when you can no longer memorize can then generalization set in OK, so that's one measure of you know.",
            "So you kind of this is like Occam's Razor.",
            "You want to find the simplest model that explains your data.",
            "There's another notion of controlling generalization error, which is the stability.",
            "I won't go into this into detail, but the basic idea is, let's say you want to change one data point alittle bit right or change it to become a new data point.",
            "And let's say you re learn with the just one data point changed.",
            "If you're if the learned function that you get from your training procedure is very very different then it's not robust to changes in the data.",
            "And if it's not robust to changes in the data you won't generalize.",
            "So there are various quantitative measures of robustness and they also provide upper bounds on generalization error so within this."
        ],
        [
            "Lens we can understand we can start to appreciate four recent works that came out.",
            "So here what they showed is.",
            "That deep networks in the regimes in which we operate them few data points.",
            "Many more parameters you can actually memorize random labels.",
            "Yet for structured data you still generalize well.",
            "OK, and so this recent work took a closer look at this and what's happening is these theorems are all about that."
        ],
        [
            "Training error of the best model in the training set, but in deep learning we're not good at optimizing, so even though we have lots of expressivity as I discussed, we can compute these chaotic functions.",
            "Because we're bad at optimizing.",
            "The space of accessible functions that we can get to may not be as large as we think it is given by our expressivity results.",
            "So then our ability to generalize is all tide up not only with the space of functions, but with optimization.",
            "So basically generalization is now intimately related to both expressivity and optimize ability in a weird way, and so these interesting."
        ],
        [
            "Experiments that look at that now also from the stability perspective right?",
            "So what they find here is so if you train with small mini batches that adds noise to your gradient.",
            "It turns out you generalize better.",
            "But if you train with large mini batches, you might think that's better 'cause you get a better gradient, but you actually generalize worse.",
            "So these guys came up with a picture of that.",
            "Which is the following?",
            "They found that if you train with large mini batches.",
            "You can and so this is your error landscape.",
            "If you train with large mini batches you tend to end up at sharp minima, but if you train with small mini batches you have alot of stochastic city.",
            "The stochastic city might be so large that it doesn't allow you to find these sharp minima and you preferentially end up in shallow minima.",
            "Now this is the training error.",
            "What we really care about is the test error and the tester may not change that much here, but it may change a lot here right?",
            "So this is again related to the notion of stability.",
            "If you end up in a flat minima, what does that mean?",
            "That means if you change your parameters, you don't change the loss, but from a dual perspective, if you don't change, that might also mean that if you change your data you don't change the loss and so you get stability and therefore you get generalization.",
            "So anyway, these are all hand waving arguments, but this is kind of the research frontier right when you guys are tuning hyperparameters and you want to win the competition, it's all about generalization error, right?",
            "And so you know, we have to start thinking about these things.",
            "I don't think any of these works have sort of theoretically nailed what's going on, but there's lots of really intriguing simulations anyways, so let me end."
        ],
        [
            "Sorry, oh crap, there was a whole other part about inspiration from your side.",
            "I."
        ],
        [
            "I got about the third part.",
            "OK Selavy, let me just just two things in 30 seconds, OK?",
            "There's these cortical.",
            "There's a lot of structure in our brain.",
            "Blake actually kind of talked about it a bit, but there's this.",
            "These Canonical cortical microcircuits that the primary mode of evolution has to be has been to increase the surface area of our cortex without like changing the elements too much.",
            "These are these Canonical micro cortical circuits.",
            "We don't actually have a good sense of what they're for, But an interesting direction to go would be for all the deep learning groups in the world to do Journal clubs on this thing.",
            "And see if the topology and structure of these Canonical micro cortical circuits provide inspiration for architectures that would help in deep learning.",
            "Very general like you can rewire the visual system of a ferret and have the I go to where the year would go to and then the ferret starts seeing with its ear or its cortical region that they used to process this year.",
            "So it's a very adaptable system that can rewire.",
            "OK, that's an interesting direction."
        ],
        [
            "I think these nested loop architectures are a very interesting direction to go where if you're doing motor control, what happens in the brain is you have these fast dumb loops that rapidly correct errors, but they can only correct sort of simple errors.",
            "Then you have these slower, smarter loops that can correct more complicated errors, but they're slower and probably this kind of an architecture might make learning and generalization easy, and so we need to think about nested loop architectures.",
            "And there's a bunch of work on that."
        ],
        [
            "The other thing that I think is is really missing is synaptic complexity.",
            "OK, for us synapses are just WI JA scalar value, but actually there's a lot of complexity hiding inside synapses.",
            "For example, this is a network of chemicals hiding inside every synapse in your hippocampus.",
            "We've shown recently that we've proven no go theorems that you cannot avoid catastrophic forgetting if you don't have the synaptic complexity you need to treat synapses.",
            "The dynamical systems in their own right, not a simple scalar values.",
            "So this no go theorem was proven in this NIPS paper an well anyways and then."
        ],
        [
            "And then we've actually been able to use synaptic complexity recently."
        ],
        [
            "A paper that will appear DCML to avoid catastrophic forgetting, and we can do about as well as deep mind using a much simpler algorithm.",
            "At least on this on these."
        ],
        [
            "Just said so again, let me just end the summary.",
            "And."
        ],
        [
            "For sure everything I talked about is in these references.",
            "Alright, thanks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, so it's really great to give a talk right after Blake.",
                    "label": 0
                },
                {
                    "sent": "Actually, I think biology possible.",
                    "label": 0
                },
                {
                    "sent": "Deep learning is a very important topic not only for its scientific interests but also.",
                    "label": 0
                },
                {
                    "sent": "I mean if you can really do it then you can parallelize deep learning.",
                    "label": 0
                },
                {
                    "sent": "So we kind of coordinated.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to talk about biology, possible deep learning, but I'm going to talk about some other stuff so I'm.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Basically a theoretical neuroscientist, though I also work in deep learning for reasons that I'll explain.",
                    "label": 0
                },
                {
                    "sent": "But what is theoretical neuroscience and why is it such an exciting subject?",
                    "label": 0
                },
                {
                    "sent": "At the moment, there's just like there's a lot of excitement in deep learning or machine learning in general.",
                    "label": 0
                },
                {
                    "sent": "There's also a lot of excitement in neuroscience right now because we have been experiencing lots of experimental revolutions in our ability to record the brain at multiple levels of complexity in space and time across multiple scales.",
                    "label": 0
                },
                {
                    "sent": "And so we're getting huge amounts of data from the brain.",
                    "label": 0
                },
                {
                    "sent": "And we have to try to make sense of it.",
                    "label": 0
                },
                {
                    "sent": "We'd like to extract a conceptual understanding of how how the brain works.",
                    "label": 0
                },
                {
                    "sent": "So to confront this complexity, it's really useful to turn to subjects from the physical Sciences that have themselves develop powerful methods to deal with complexity in physical systems and try to adapt those ideas to analyze neural systems.",
                    "label": 0
                },
                {
                    "sent": "But also neural circuits aren't simply tangled webs of complexity that exist for their own sake.",
                    "label": 0
                },
                {
                    "sent": "They've actually been evolved over years of evolution to solve computational tasks.",
                    "label": 0
                },
                {
                    "sent": "So it's useful to turn to ideas from the computational Sciences, both as ways to analyze their data, but also to search for inspirations as to what kinds of computation computational tasks the brain is solving.",
                    "label": 0
                },
                {
                    "sent": "I should actually probably put deep learning in here.",
                    "label": 0
                },
                {
                    "sent": "That's kind of an old slide, but you'll see that it's allowed it next time.",
                    "label": 0
                },
                {
                    "sent": "So anyways, we actually work in all of these subjects, but you know, we kind of take a very expansive view of what theoretical neuroscience is, but what might the intersection to deep learning be well?",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Also, these are for example some of the projects we work on.",
                    "label": 0
                },
                {
                    "sent": "I spend a lot of time collaborating with experimental neuro scientists working in how flies see how mice navigate, how monkeys reach, how mutant mice can get smarter, for example.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "But I won't talk about any of that.",
                    "label": 0
                },
                {
                    "sent": "Today I will talk about one part of it where it intersects with deep learning, but but why do I think there should be an intersection between deep learning and neural?",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Science I think there's multiple reasons and because of advances in both fields, I think there's an interesting motivation for a new type of alliance between neuroscience and deep learning or theoretical machine learning, which is the following.",
                    "label": 0
                },
                {
                    "sent": "To some extent, we all want to understand how neural circuits work, how the brain works, but what does it mean, right?",
                    "label": 1
                },
                {
                    "sent": "Well, in some sense we'd like to understand how the connectivity and dynamics of a neural circuit gives rise to behavior.",
                    "label": 1
                },
                {
                    "sent": "And also learning is extremely important.",
                    "label": 0
                },
                {
                    "sent": "We'd like to understand how neural activity and synaptic learning rules conspire to self organize useful connectivity that subserves behavior.",
                    "label": 1
                },
                {
                    "sent": "OK, this is to make fun of physicists who work in neuroscience.",
                    "label": 1
                },
                {
                    "sent": "Sometimes we sometimes like to analyze random networks, but that's not good enough 'cause they don't have function.",
                    "label": 0
                },
                {
                    "sent": "However, the field of machine learning is actually generated.",
                    "label": 0
                },
                {
                    "sent": "Lots of interesting neural networks that accomplish really interesting functions functions that we know of no other way to do as well in any artificial system, right?",
                    "label": 0
                },
                {
                    "sent": "What's really exciting is that neural networks are winning the competitions at the moment.",
                    "label": 0
                },
                {
                    "sent": "OK, but a scary thing is that we know everything about these neural systems.",
                    "label": 0
                },
                {
                    "sent": "We know their connectivity.",
                    "label": 0
                },
                {
                    "sent": "Scary from reflexive neuroscience.",
                    "label": 1
                },
                {
                    "sent": "We know their connectivity.",
                    "label": 0
                },
                {
                    "sent": "We know their dynamics.",
                    "label": 0
                },
                {
                    "sent": "We know their learning rule.",
                    "label": 1
                },
                {
                    "sent": "We know their entire developmental experience from the from when they were baby random networks to grown up trade networks through their exposure to training stimuli.",
                    "label": 0
                },
                {
                    "sent": "Yet we don't have a meaningful understanding of how they learn and work, nor do we even have a benchmark for what such an understanding would even look like.",
                    "label": 0
                },
                {
                    "sent": "Right, so we kind of laid out so you know, actually deep learning provides a really interesting warmup problem for neuroscience.",
                    "label": 0
                },
                {
                    "sent": "And you know, I don't think that if we directly understand how these deep networks work will understand the brain works.",
                    "label": 0
                },
                {
                    "sent": "But the methods that we used to arrive at that understanding, the things that we decide are important to measure and not important to measure in deep networks.",
                    "label": 0
                },
                {
                    "sent": "To understand them might be similar to what we'd like to measure in the brain.",
                    "label": 0
                },
                {
                    "sent": "So we kind of laid this out in an opinion piece if you're interested in a more fleshed out version of this argument.",
                    "label": 0
                },
                {
                    "sent": "But also a deeper scientific understanding of deep networks will of course help deep learning as well, right in the history of interaction between engineering and science.",
                    "label": 0
                },
                {
                    "sent": "It's always kind of followed the following pattern.",
                    "label": 0
                },
                {
                    "sent": "The engineers are head of this are ahead of the scientist.",
                    "label": 0
                },
                {
                    "sent": "So for example, the Steam engine was built in 17.",
                    "label": 0
                },
                {
                    "sent": "The first steam engine was built in 1712, long before physicists had figured out the laws of thermodynamics.",
                    "label": 0
                },
                {
                    "sent": "But you know, the science of thermodynamics developed and you know things like the Carnot engine and upper bounds, and thermodynamic efficiency came along, and that helped us design much better.",
                    "label": 0
                },
                {
                    "sent": "Steam engine's right?",
                    "label": 0
                },
                {
                    "sent": "We're right now in a situation where the engineering is way ahead of the science, but that doesn't mean we should forgo the science in deep learning, because, again, given the history of the interaction between science and engineering, it has never been the case.",
                    "label": 0
                },
                {
                    "sent": "The deeper understanding of the science does not lead to better engineering.",
                    "label": 0
                },
                {
                    "sent": "So although right now we're really far behind.",
                    "label": 0
                },
                {
                    "sent": "So what can we do?",
                    "label": 0
                },
                {
                    "sent": "Although experimentally you're way ahead of neuroscience, 'cause we don't, although we have a lot of data in neuroscience, we don't have all the data yet, so it's a very interesting interaction between science, neuroscience and machine learning.",
                    "label": 0
                },
                {
                    "sent": "And I think these two fields will go hand in hand for quite awhile.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, so let me just give you the talk outline so it's kind of three.",
                    "label": 0
                },
                {
                    "sent": "Maybe one more thing.",
                    "label": 0
                },
                {
                    "sent": "So there's kind of three kind of branches to this talk.",
                    "label": 0
                },
                {
                    "sent": "One is, you know, what can deep learning do for neuroscience?",
                    "label": 0
                },
                {
                    "sent": "You know how you know you're having a lot of success solving problems in machine learning, but you also have the power to help us in neuroscience.",
                    "label": 0
                },
                {
                    "sent": "And I just wanted to give you some sense of that.",
                    "label": 0
                },
                {
                    "sent": "You can actually use deep and recurrent neural networks to successfully model different parts of the brain.",
                    "label": 1
                },
                {
                    "sent": "Then we'll move on to a theory of deep learning.",
                    "label": 0
                },
                {
                    "sent": "And of course, this is in its infancy, but I think three of the most interesting topics in the theory of deep learning, our optimization.",
                    "label": 0
                },
                {
                    "sent": "You know why is it that we can optimize these networks, and how can we use that understanding to better optimize them expressivity?",
                    "label": 0
                },
                {
                    "sent": "Why is depth useful?",
                    "label": 0
                },
                {
                    "sent": "What can deep networks bias in terms of expressing functions, that shallow networks cannot, and the most vexing one is generalization.",
                    "label": 1
                },
                {
                    "sent": "Why is it that these deep networks can generalize even when you use much less data than the number of parameters?",
                    "label": 0
                },
                {
                    "sent": "Then the third part will turn to inspiration from neuroscience.",
                    "label": 0
                },
                {
                    "sent": "What does the brain have that we're currently missing in deep learning?",
                    "label": 0
                },
                {
                    "sent": "And I'll talk about some ingredients that we may want to try to incorporate into our deep learning models and some ingredients that we've already incorporated that have helped.",
                    "label": 1
                },
                {
                    "sent": "OK, so let's start with applying deep learning to the brain so that there's some exciting work.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Done by several labs.",
                    "label": 0
                },
                {
                    "sent": "Where they've actually modeled the brain using deep neural networks and actually gotten some insight into how those brain regions operate.",
                    "label": 0
                },
                {
                    "sent": "So here's a work by David's Asilo, Monticello coming out of Krishnan Bill Newsome's lab at Stanford, where what this is kind of an overview slide, but so it's a bit hard to see, but what they did was they asked a monkey to do what's called a context dependent discrimination task.",
                    "label": 0
                },
                {
                    "sent": "So in this task you have a bunch of dots there, either red or green or some fraction of dots are red, some fraction of green.",
                    "label": 0
                },
                {
                    "sent": "And some fraction are moving to the right and some fraction are moving to the left.",
                    "label": 0
                },
                {
                    "sent": "OK, and there's.",
                    "label": 0
                },
                {
                    "sent": "So there's two contexts in context one the monkey is supposed to report the majority direction of motion of the dots in context to the monkey is supposed to report the majority color of the dots.",
                    "label": 0
                },
                {
                    "sent": "It reports them through eye movements.",
                    "label": 0
                },
                {
                    "sent": "So and the fractions are very close to 5050, so the monkey needs to stare at it for awhile and integrate evidence overtime in favor of a hypothesis.",
                    "label": 0
                },
                {
                    "sent": "For the majority color are the majority motion, so it's a relatively complicated task because you have to integrate evidence overtime.",
                    "label": 0
                },
                {
                    "sent": "You have to do different things depending on the context and so on and so forth.",
                    "label": 0
                },
                {
                    "sent": "And they recorded from all the neural a whole bunch of neurons like hundreds of neurons in the monkey's brain, and each neuron itself displayed a complex dependence on context, color, motion, choice and so on.",
                    "label": 0
                },
                {
                    "sent": "There was no simple kind of explanation at the single neuron level of what was going on.",
                    "label": 0
                },
                {
                    "sent": "So then what they did was they trained a recurrent neural network to solve the same task.",
                    "label": 0
                },
                {
                    "sent": "It had a motion signal that had a color signal.",
                    "label": 0
                },
                {
                    "sent": "These were now just scalar signals.",
                    "label": 0
                },
                {
                    "sent": "Overtime that had a nonzero mean reflecting the fractional difference data context signal coming in.",
                    "label": 0
                },
                {
                    "sent": "They had a readout and they trained the network to solve the same task that the monkey did.",
                    "label": 1
                },
                {
                    "sent": "OK. Then the analyze the network.",
                    "label": 0
                },
                {
                    "sent": "They did dimensionality reduction on the on the dynamics of this network and they actually looked inside the network to look at what kind of dynamical system got learned.",
                    "label": 0
                },
                {
                    "sent": "And they found that it actually learned two integrator networks, orlina tractors.",
                    "label": 0
                },
                {
                    "sent": "These manifolds of fixed points.",
                    "label": 0
                },
                {
                    "sent": "So you know what does it mean to integrate a signal.",
                    "label": 0
                },
                {
                    "sent": "If the signal is on, then you know there's activity that's changing overtime in the network.",
                    "label": 0
                },
                {
                    "sent": "But if you shut the signal off, an integrator will stay at the same point, right?",
                    "label": 0
                },
                {
                    "sent": "So you have to have an entire manifold of fixed points.",
                    "label": 0
                },
                {
                    "sent": "There were two mutually exclusive manifolds of fixed points and the network learn to integrate one while ignoring the other in one context.",
                    "label": 0
                },
                {
                    "sent": "But then for the other integrator it was the opposite.",
                    "label": 0
                },
                {
                    "sent": "OK, then they did dimensionality reduction or did principal components analysis on the dynamics of this network.",
                    "label": 0
                },
                {
                    "sent": "You know, while it was operating and then they did the same thing on the monkey's brain and they found a beautiful match.",
                    "label": 0
                },
                {
                    "sent": "OK, so basically at the population level, there are certain patterns in the monkeys brain that are essentially predetermined by what you would need to do to solve this task.",
                    "label": 0
                },
                {
                    "sent": "Now there's some interesting things where if you regularize the network.",
                    "label": 0
                },
                {
                    "sent": "Only if you regularize the network does it match the monkeys brain.",
                    "label": 0
                },
                {
                    "sent": "If you don't regularize it, you get much more chaotic patterns, and it doesn't match the monkeys brain.",
                    "label": 0
                },
                {
                    "sent": "Moreover, the regularised network is more robust to perturbations, suggesting that this dynamics is probably also robusta perturbations.",
                    "label": 0
                },
                {
                    "sent": "You could potentially test that using optogenetics, because we can stimulate the brain as well as record from it, but this is a basic basic kind of pattern that's occurring if you train a network to solve the same task as the monkey, it gives you a mechanism for generating hypothesis.",
                    "label": 0
                },
                {
                    "sent": "As to how that brain region is working?",
                    "label": 0
                },
                {
                    "sent": "Um, yeah.",
                    "label": 0
                },
                {
                    "sent": "The recurrent weights are trained.",
                    "label": 1
                },
                {
                    "sent": "Yeah yeah, the recurrent.",
                    "label": 0
                },
                {
                    "sent": "Yeah those are definitely trained.",
                    "label": 0
                },
                {
                    "sent": "Everything is trained.",
                    "label": 0
                },
                {
                    "sent": "Yeah back well he in this work he used Hessian free optimization, so slightly older older work.",
                    "label": 0
                },
                {
                    "sent": "Um, yeah.",
                    "label": 0
                },
                {
                    "sent": "He used as David Solo.",
                    "label": 0
                },
                {
                    "sent": "He used the Jacobian regularization where he tried to penalize the norm of the vector field.",
                    "label": 0
                },
                {
                    "sent": "That is the dynamical system.",
                    "label": 0
                },
                {
                    "sent": "It's a continuous time firing rate network, so there's a Jacobian for the dynamics, which is essentially the linearized vector field, and it penalizes the norm of that.",
                    "label": 0
                },
                {
                    "sent": "So it's basically trying to get a smooth dynamics as possible.",
                    "label": 0
                },
                {
                    "sent": "It turns out that's actually quite important for matching the brain.",
                    "label": 0
                },
                {
                    "sent": "Without it, you get these Rube Goldberg like devices that don't look like the brain.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "You also see that when you try to match the motor cortex during reaching tasks.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here's another kind of a famous one by Dan Yamen, so this was done in gym to Carlos Lab at MIT.",
                    "label": 0
                },
                {
                    "sent": "He's now at Stanford, where they took again.",
                    "label": 0
                },
                {
                    "sent": "It's the same philosophy you now this is to mimic inference in Pearl Cortex, which is at the apex of the ventral visual stream.",
                    "label": 0
                },
                {
                    "sent": "It does sort of general object recognition and whatnot.",
                    "label": 0
                },
                {
                    "sent": "We don't know what task the monkey is doing or what evolution designed it in for temporal cortex to do.",
                    "label": 0
                },
                {
                    "sent": "So Yamens followed a bold hypothesis that maybe if we just train a network on an object recognition or object categorization, something like image net.",
                    "label": 0
                },
                {
                    "sent": "And if we look at the internal representations of that network, it might mimic what's going on in the brain, and that's what they actually found.",
                    "label": 0
                },
                {
                    "sent": "They had a multi layer network and you know it was.",
                    "label": 0
                },
                {
                    "sent": "It was trained on image Net and they looked at activity in the high level layers and what they found is they could find linear combinations of a small number of neurons in the high level layers.",
                    "label": 0
                },
                {
                    "sent": "That match the activity of an individual neuron.",
                    "label": 0
                },
                {
                    "sent": "It say a fraction of variance explained about 50 to 60, which was a significant advance at that time, getting a 60% of variance explained of a single neuron so many synapses away from the sensory periphery was quite difficult.",
                    "label": 0
                },
                {
                    "sent": "But Interestingly enough, if you go earlier on.",
                    "label": 0
                },
                {
                    "sent": "You know, and you try to find linear combinations of neurons here that match V4 in the earlier layer.",
                    "label": 0
                },
                {
                    "sent": "Then you get a good match, but only if you look at the earlier layer and then V1 only if you look at the earlier layer, so it's as if the cascaded computation in the circuit is mimicking to some extent what's going on in the ventral visual stream.",
                    "label": 0
                },
                {
                    "sent": "This of course raises a lot more questions, is 60% of variance good enough?",
                    "label": 0
                },
                {
                    "sent": "What is the upper limit?",
                    "label": 0
                },
                {
                    "sent": "Why do we have to take linear combinations neurons?",
                    "label": 0
                },
                {
                    "sent": "Are we just learning a kind of an interesting basis set?",
                    "label": 0
                },
                {
                    "sent": "That's similar to the basis set in the brain.",
                    "label": 0
                },
                {
                    "sent": "Should we expect a more detailed match at the level of 1 to one correspondence between neurons?",
                    "label": 0
                },
                {
                    "sent": "Is that even unrealistic to expect?",
                    "label": 0
                },
                {
                    "sent": "I mean, there's a lot more work to be done here, but it's a very intriguing direction where deep learning helped us sort of start to understand, or at least statistically explain what we see in the brain.",
                    "label": 0
                },
                {
                    "sent": "We've all.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So played that game in my lab in the retina where you can actually get a much more fine scale match, and you can actually know if what you're doing is correct because of the Accessibility of the retina, so we also were coming up with deep neural network models of the retina.",
                    "label": 1
                },
                {
                    "sent": "Now you might think the retina is very simple, right?",
                    "label": 0
                },
                {
                    "sent": "It just does center surround receptive fields and that's it.",
                    "label": 0
                },
                {
                    "sent": "We kind of knew that from many years ago, but.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It's not actually true.",
                    "label": 0
                },
                {
                    "sent": "Your retinas an extremely sophisticated preprocessing device.",
                    "label": 0
                },
                {
                    "sent": "That actually is itself kind of a deep neural network in the sense that it has 1 hidden layer, you have photo receptors that are sensitive to light.",
                    "label": 0
                },
                {
                    "sent": "It propagates through a hidden layer of neurons that have both lateral connections in terms of horizontal cells and Ameren cells, and these are the bipolar cells and then the bipolar cells connected the ganglion cells.",
                    "label": 0
                },
                {
                    "sent": "It's extremely easy to shine light in the retina and record from the ganglion cells, but it's very hard to record from the interior of the retina.",
                    "label": 1
                },
                {
                    "sent": "It's just a bit more experimentally inaccessible.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The classic model of the retina is what I mentioned, just a spatio temporal filter and a non linearity.",
                    "label": 0
                },
                {
                    "sent": "Clearly the retina is much more structured than the simple models that have been used.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "These simple models have worked pretty well.",
                    "label": 0
                },
                {
                    "sent": "You know, on explaining the retinal response to white noise, but if you show more structured stimuli, you see a really bad match.",
                    "label": 0
                },
                {
                    "sent": "You know you get Pearson correlation coefficients of about .36 between the predicted firing rate of these models.",
                    "label": 1
                },
                {
                    "sent": "These simple models and the actual frame rate of the retina in response to natural stimuli, the stimuli for which the retina was evolved to process.",
                    "label": 1
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we decided to try to model these retinal ganglion cells using convolutional neural networks.",
                    "label": 1
                },
                {
                    "sent": "I know there's many reasons to think this is a horrible idea, OK?",
                    "label": 1
                },
                {
                    "sent": "We just train the model to minimize the the error in predictions between between the models.",
                    "label": 0
                },
                {
                    "sent": "Predictions of recorded data.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Why might this be a horrible, horrible idea?",
                    "label": 0
                },
                {
                    "sent": "We might not be able to train the network, we don't have lots and lots of data.",
                    "label": 0
                },
                {
                    "sent": "We can only record from the retina for about 30 to 40 minutes, so we might not even be able to train the network in a way that Gen.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Ulyses Furthermore, even if we were to train the network, there's no guarantee that the interior structure of our model will match the interior structure of the retina.",
                    "label": 0
                },
                {
                    "sent": "It may solve the problem in a different way.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we won't learn anything.",
                    "label": 0
                },
                {
                    "sent": "Even the algorithms identified by the model may not be the same as those used by the retina.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And but actually, it turns out all of these fears were surprisingly unfounded.",
                    "label": 0
                },
                {
                    "sent": "You know how it is?",
                    "label": 0
                },
                {
                    "sent": "The grad students go ahead and do it even when the advisor tells him not to.",
                    "label": 0
                },
                {
                    "sent": "Actually, they did it without telling me first, and then that was smart so.",
                    "label": 0
                },
                {
                    "sent": "Anyway, it works pretty well so.",
                    "label": 0
                },
                {
                    "sent": "They actually captured these now form state of the art models of the retina.",
                    "label": 0
                },
                {
                    "sent": "They generalize better than the simpler models.",
                    "label": 1
                },
                {
                    "sent": "The interior structure of the retina corresponds to interneurons of the retinal circuitry, and we can capture other aspects of retinal computation as well.",
                    "label": 1
                },
                {
                    "sent": "So this.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is basically the model architecture.",
                    "label": 0
                },
                {
                    "sent": "These are the photoreceptors a set of hidden units, a dense layer, and then the predicted responses.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The CNN's do pretty well compared to similar models, generalized linear models and LM models.",
                    "label": 0
                },
                {
                    "sent": "We actually know the upper limit because we can play the same stimulus multiple times and measure the intrinsic variability of the retina.",
                    "label": 1
                },
                {
                    "sent": "So typical retinal spike train to the same stimulus has a correlation coefficient of .8 with any other spike train.",
                    "label": 1
                },
                {
                    "sent": "So we're getting up to six and actually in more recent work we're up to .7.",
                    "label": 0
                },
                {
                    "sent": "So we're actually getting quite close to the upper limit set by intrinsic noise in the retina as far as predictability.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Those.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "You know, we don't need that much data to to learn these are these are accuracy as a function of the amount of training data and actually the CNN generalizes much better than these these.",
                    "label": 0
                },
                {
                    "sent": "These simpler models.",
                    "label": 0
                },
                {
                    "sent": "Now what's wrong?",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Really interesting is we can look are the cells in the interior of our model.",
                    "label": 0
                },
                {
                    "sent": "These were never directly trained.",
                    "label": 0
                },
                {
                    "sent": "These are the hidden units, their receptive fields or I either learned filters, look a lot like what we know about bipolar cells.",
                    "label": 0
                },
                {
                    "sent": "When we record from bipolar cells directly, and what we could do is, we could do an experiment where in the same retina we recorded from a very specific bipolar cell and then we matched in our model, the bipolar cell that has the closest receptive field.",
                    "label": 0
                },
                {
                    "sent": "It's a convolutional models.",
                    "label": 0
                },
                {
                    "sent": "We just.",
                    "label": 0
                },
                {
                    "sent": "Find the cell that has the receptive field center at the same place as the one that we recorded, and then you can see that the C and the blue is the model's prediction and the black is the actual retinal response.",
                    "label": 0
                },
                {
                    "sent": "So this is a proof of principle that if you only have the inputs and outputs of the network, you can actually computationally reconstructed a high level of accuracy.",
                    "label": 0
                },
                {
                    "sent": "What's going on in the interior of the network, which is which is good news for these kinds of modeling approaches in neuroscience.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "There's something called sub Passan variability in neurons.",
                    "label": 0
                },
                {
                    "sent": "We can capture that and we understand theoretically now how it happens we.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And capture that in the model by adding noise.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'll skip those.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Details, but we get a nice match between the model and the simulation.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We can also capture adaptation so you know your photon flux into your retina can vary almost 10 orders of magnitude in between nighttime and sunlight full sunlight.",
                    "label": 0
                },
                {
                    "sent": "So your retina adapts to luminance and contrast overtime.",
                    "label": 0
                },
                {
                    "sent": "So basically, if you crank up the contrast, the retina will go wild for a little bit, and then it'll come back down so we can capture the and that happens over long timescales so we can capture that using an LTM.",
                    "label": 0
                },
                {
                    "sent": "We put an LS TM in there.",
                    "label": 0
                },
                {
                    "sent": "And we can actually reproduce the most of the contrast experiments and actually.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So basically, in summary, they capture a lot of the.",
                    "label": 0
                },
                {
                    "sent": "You know we do well in accuracy and they capture both an algorithmic level and a structural level.",
                    "label": 0
                },
                {
                    "sent": "The interior of the retina, which we never directly trained on.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So we need to keep going.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's sort of quick summary of applying deep learning to the brain.",
                    "label": 1
                },
                {
                    "sent": "I figured for this audience we want to get to the next parts so.",
                    "label": 0
                },
                {
                    "sent": "So let's talk about that.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The theory of deep learning, so there's so I kind of divide it up into a selection of topics.",
                    "label": 0
                },
                {
                    "sent": "Trainability, which is, you know if a good neural network solution exists with small training error.",
                    "label": 1
                },
                {
                    "sent": "How do we find it and what makes the problem difficult?",
                    "label": 0
                },
                {
                    "sent": "Then there's expressivity.",
                    "label": 1
                },
                {
                    "sent": "What kinds of functions can a deep network express in a shallow network cannot?",
                    "label": 0
                },
                {
                    "sent": "And then there's generalizability.",
                    "label": 0
                },
                {
                    "sent": "What principles do deep networks used to place probability or make decisions in regions of input space where you have very little data?",
                    "label": 1
                },
                {
                    "sent": "The generalizability one is still very much an open question.",
                    "label": 0
                },
                {
                    "sent": "I just want to summarize kind of what we know about that at the moment.",
                    "label": 0
                },
                {
                    "sent": "There's kind of a bias survey through work that you know I've been involved in, but I'll talk about, you know, sort of other stuff along the way, so the way I started thinking about this stuff will start with the trainability.",
                    "label": 0
                },
                {
                    "sent": "The way I started thinking about this stuff was actually starting from trying to understand infant level learning in psychology.",
                    "label": 0
                },
                {
                    "sent": "Believe it or not, so I have a colleague at Stanford, J. McLeod.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Lens and this is joint work with Andrew Sachs.",
                    "label": 0
                },
                {
                    "sent": "Where Jay has spent a lot of time at, you know we mentioned in the previous talk that even in the 2000s, people were using deep networks to try to understand the brain, and so JJ spent a lot of time working on that in the 2000s.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Earlier and he was focused on a topic called Human Semantic Cognition, which is basically it's our ability to learn, recognize, comprehend, and reproduce inferences about objects and events that are in the world, especially ones that are not in our current perceptual stimulus.",
                    "label": 1
                },
                {
                    "sent": "So, for example, I could ask you all the questions.",
                    "label": 0
                },
                {
                    "sent": "All the question.",
                    "label": 0
                },
                {
                    "sent": "Does a cat have fur and you can all answer that question despite the fact that there's no cat in the room.",
                    "label": 0
                },
                {
                    "sent": "It's because you have these internal categories in your brain and you have facts associated with these categories.",
                    "label": 0
                },
                {
                    "sent": "And you know, you never see the same cat twice, but once you see a cat, it creates the categorical representation of cat in your brain and you can recall all sorts of information and activates based on that.",
                    "label": 1
                },
                {
                    "sent": "So our ability to do semantic cognition relies on our ability to form an internal representation of categories in the world.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So there's been a lot of psychology experiments on.",
                    "label": 0
                },
                {
                    "sent": "On, you know, when do infants learn categories, right?",
                    "label": 0
                },
                {
                    "sent": "So I'm going to focus on the category learning.",
                    "label": 0
                },
                {
                    "sent": "There's a whole bunch of other stuff that we've worked on that we won't have time to talk about, but you can actually ask an infant like a preverbal infant a 6 month old.",
                    "label": 0
                },
                {
                    "sent": "You know, kind of like this.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One my son went back when he was six months old.",
                    "label": 0
                },
                {
                    "sent": "You can ask him and I did ask him.",
                    "label": 0
                },
                {
                    "sent": "You know, when can you distinguish between two categories.",
                    "label": 0
                },
                {
                    "sent": "So how do you ask an infant?",
                    "label": 0
                },
                {
                    "sent": "How do you ask an infant when they can do that?",
                    "label": 0
                },
                {
                    "sent": "If they can't talk now he talks up a storm and but anyways.",
                    "label": 0
                },
                {
                    "sent": "You do these looking time studies, so for example, you'll show them a picture of a horse in the first time they see a horse, they'll look at it for a long time, 'cause it's novel.",
                    "label": 0
                },
                {
                    "sent": "OK then the looking time goes down.",
                    "label": 0
                },
                {
                    "sent": "You know, after, say the 5th or 6th presentation the horse, then you show the Macao OK.",
                    "label": 0
                },
                {
                    "sent": "If the infant is old enough the looking time will go up OK and then it'll go down again.",
                    "label": 0
                },
                {
                    "sent": "So that suggests that the infant can discriminate between cow and horse.",
                    "label": 0
                },
                {
                    "sent": "It knows the cow is novel where the spectral horse, but if the infant is too young.",
                    "label": 0
                },
                {
                    "sent": "The looking time will not go up on the 1st presentation of the cow because it can't really discriminate those two categories.",
                    "label": 0
                },
                {
                    "sent": "It doesn't think they're two different categories.",
                    "label": 0
                },
                {
                    "sent": "So based on looking time studies you can infer at what age various categorical distinctions are learned, and then you can put these categorical distinctions into a hierarchical tree, where the higher you go up is the earlier at which they are learned, and that hierarchical tree looks very much like a semantic tree that we would have as adults in our brain.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's quite remarkable.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So there's an entire book about this called semantic cognition.",
                    "label": 0
                },
                {
                    "sent": "There's a whole bunch of other phenomena that we've also modeled, but I'm only going to focus on this sort of progressive differentiation of concepts in our brain.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so how did they model it back then?",
                    "label": 0
                },
                {
                    "sent": "They just had a toy data set where they had a neural network and they had a set of objects, right?",
                    "label": 0
                },
                {
                    "sent": "Say different types of animals and plants and it was a deep neural network and the networks just was just trained to output the various semantic features of animals and plants.",
                    "label": 0
                },
                {
                    "sent": "OK and they trained it overtime and what they found was a striking progressive differentiation.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of structure, so now we're getting into the dynamics of learning or training of these networks.",
                    "label": 0
                },
                {
                    "sent": "So initially you start with random weights.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Basically what you can do is you can take the internal representations of the network in this representation layer, and you can hierarchically cluster them.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At different points in training and initially with random weights, there's no harkle clusters.",
                    "label": 0
                },
                {
                    "sent": "Then what happens is that some intermediate time at first discriminates between animals and plants, then it discriminates between different types of animals and different types of plants, and eventually it discriminates between individual items.",
                    "label": 0
                },
                {
                    "sent": "So you can see the same kind of dynamics in a multidimensional scaling plot where you take the high dimensional interruption representation and try to plot it in a 2 dimensional space while preserving distances.",
                    "label": 0
                },
                {
                    "sent": "And you see the same hierarchical differentiation of structure.",
                    "label": 0
                },
                {
                    "sent": "OK, so the first time I saw this I was at once both astounded and disturbed.",
                    "label": 0
                },
                {
                    "sent": "I was astounded that it actually mimics kind of what goes on in an infant's brain.",
                    "label": 0
                },
                {
                    "sent": "But I was disturbed because there was no theoretical understanding of why this was happening, right?",
                    "label": 0
                },
                {
                    "sent": "Why is it that the dynamics of learning in these networks behave the way they do?",
                    "label": 0
                },
                {
                    "sent": "This will eventually connect to very recent works in generalization at the very end of the talk, which so the basic idea is the following.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "By the way, this hierarchical structure is actually present in adult brains both in the adult brains of humans and monkeys.",
                    "label": 0
                },
                {
                    "sent": "This is a famous plot that comes out of work by Craig Nichols, Chris Korte and also Roozbeh Kiani, who did the Monkey recordings.",
                    "label": 0
                },
                {
                    "sent": "You can show a whole bunch of images both to the human and the monkey, and you get this interesting hierarchical similarity structure that's basically the same across human and monkey.",
                    "label": 1
                },
                {
                    "sent": "In the human, the similarity was measured using the similarity of.",
                    "label": 0
                },
                {
                    "sent": "Sorry, in the human it was measured using similarity of fMRI voxel activity patterns in it and in the monkey it was measured using the similarity of neural representations of firing rates of individual neurons in monkey it.",
                    "label": 0
                },
                {
                    "sent": "We can actually prove a theorem that, at least for simple neural networks, it must be this way under certain optimality conditions.",
                    "label": 0
                },
                {
                    "sent": "I'll talk about that next, but this suggests that these two systems are solving the same task, potentially both optimally.",
                    "label": 0
                },
                {
                    "sent": "I'll elaborate that on a little bit.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is the same picture, but using hierarchical clustering of the objects.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Also, certain objects have learned earlier than others, so so we'd like to understand the speed of learning in the system.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so the questions we asked are what really are the mathematical principles underlying this hierarchical self organization event representations of the network?",
                    "label": 1
                },
                {
                    "sent": "What is the role of various elements of the network?",
                    "label": 0
                },
                {
                    "sent": "The nonlinearities of the input output map the learning rule, the emphasis sticks and so on.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What we did was we did something that might seem like we're throwing the baby out with the bathwater.",
                    "label": 0
                },
                {
                    "sent": "We analyze, you know, when you look at the activations of these networks, they don't strongly go into the saturating regime during training, so we decided to analyze the learning dynamics of deep linear network.",
                    "label": 0
                },
                {
                    "sent": "Now, of course, the expressive power of a deep linear network cannot grow with depth because the composition of linear functions is linear, so there are horrible model for the expressivity of deep networks, but they turn out to be a pretty good model for the learning dynamics of deep networks because.",
                    "label": 0
                },
                {
                    "sent": "Even in a deep network, the learning dynamics is gradient descent on a non convex error landscape, and it's a nonlinear learning dynamics just to Illes.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Rate this you know this is learning dynamics of the error in a deep nonlinear network and you see these interesting plateaus and then sudden drops.",
                    "label": 1
                },
                {
                    "sent": "Oh sorry, this isn't a linear network.",
                    "label": 0
                },
                {
                    "sent": "You see a plateau and then a sudden drop in learning.",
                    "label": 0
                },
                {
                    "sent": "But if you for example in same deep linear network, you do greedy unsupervised pre training and then do learning you get a sudden drop right now.",
                    "label": 0
                },
                {
                    "sent": "Of course this was the empirical phenomenon that first started deep learning that if you do greedy unsupervised pretraining then you can you can actually train these networks.",
                    "label": 0
                },
                {
                    "sent": "So the very empirical phenomenon that gave rise to deep learning is already present in deep linear networks.",
                    "label": 0
                },
                {
                    "sent": "So these deep linear networks are an interesting model for understanding learning dynamics.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 1
                },
                {
                    "sent": "So we want to build intuition for the nonlinear case by Anna.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In linear case now, why is the learning dynamics linear?",
                    "label": 0
                },
                {
                    "sent": "It's because.",
                    "label": 0
                },
                {
                    "sent": "You know, if you imagine that just.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The square loss function.",
                    "label": 0
                },
                {
                    "sent": "It's the actual output minus the predicted output squared, but the predicted output has a product of two weights.",
                    "label": 0
                },
                {
                    "sent": "So then after you square it, the error surface is quartic.",
                    "label": 0
                },
                {
                    "sent": "In the weights, it has four powers of the weights.",
                    "label": 0
                },
                {
                    "sent": "When you do gradient descent, you get a cubic equation on the right hand side, and so it's a complicated non convex function.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We can analyze that non convex function by going to the limit of very slow learning rates.",
                    "label": 0
                },
                {
                    "sent": "So we get a different.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Equation this is the dynamics of the weight matrices from layer 1, two and three to two to three.",
                    "label": 0
                },
                {
                    "sent": "As I promised it, the right hand side is cubic in the weights OK, but one simplification that occurs is that the input statistics that drives learning becomes only the 2nd order statistics in the system because a linear network is only sensitive to 2nd order statistics.",
                    "label": 0
                },
                {
                    "sent": "In particular, the input output correlations and the and the input input correlations.",
                    "label": 0
                },
                {
                    "sent": "We imagine that the input input correlations are white, so that we kind of have an orthogonal perceptual representation.",
                    "label": 0
                },
                {
                    "sent": "Which often happens, you know.",
                    "label": 0
                },
                {
                    "sent": "As signals propagate through the brain before they go to an associative system.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So it turns out that we can express the learning dynamics in terms of the statistical structure of the input, right?",
                    "label": 0
                },
                {
                    "sent": "Like in general, what we would love to have is we love to have an understanding of how the training data, how the statistical structure in the training data determines the dynamics of learning in the networks.",
                    "label": 0
                },
                {
                    "sent": "Here we can get a perfect or complete characterization of that.",
                    "label": 0
                },
                {
                    "sent": "All that matters is the input output correlation matrix.",
                    "label": 0
                },
                {
                    "sent": "It has a particular singular value decomposition, OK, and what we can show is that.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At the actual input output map of the network builds up overtime.",
                    "label": 0
                },
                {
                    "sent": "The singular value decomposition of the input output correlation matrix.",
                    "label": 0
                },
                {
                    "sent": "So this is an exact analytical solution to those nonlinear differential equations.",
                    "label": 0
                },
                {
                    "sent": "Where the product of weights from inputs and output has the same singular vectors as the input output covariance matrix, but the effective singular value is growing as a sigmoid with time.",
                    "label": 0
                },
                {
                    "sent": "Right, the so each of these.",
                    "label": 0
                },
                {
                    "sent": "Each of these effective singular values of the input output map grows to the final singular value of the input output statistics, but it does this sudden sharp transition.",
                    "label": 0
                },
                {
                    "sent": "The time of this transition occurs at a time given by one over the singular value.",
                    "label": 0
                },
                {
                    "sent": "So just intuitively this means stronger statistical structure as measured by input output.",
                    "label": 0
                },
                {
                    "sent": "Singular values get learned earlier.",
                    "label": 0
                },
                {
                    "sent": "OK, and it turns out these modes evolve linearly, so the blue is the theory and the red is simulations of networks.",
                    "label": 0
                },
                {
                    "sent": "Why do we get these these periods of time when there's nothing that's being learned and then a sudden transition?",
                    "label": 0
                },
                {
                    "sent": "By the way, these sudden transitions also occur in infants, you know, as they're growing up.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The reason is there's a simple higher dimensional explanation of what's going on.",
                    "label": 0
                },
                {
                    "sent": "You can trade off the strength of weights in the first layer against the second layer, so if we think about, you know this is a schematic of the strength of weights in the first layer versus the second layer.",
                    "label": 0
                },
                {
                    "sent": "There's this tradeoff so that there's this manifold of solutions of 0 error and at the center there's a saddle point where the learning dynamics gets attracted to the saddle point and then eventually gets repelled OK.",
                    "label": 0
                },
                {
                    "sent": "The error is roughly the distance to this manifold of 0 error solution.",
                    "label": 0
                },
                {
                    "sent": "So while you're being attracted to the saddle point, your error is not decreasing appreciably.",
                    "label": 0
                },
                {
                    "sent": "But then as you suddenly get repelled, your error will drop suddenly and it will go to zero those times at which you get repelled by these saddle points are the times at which the singular value rapidly goes up in the air are rapidly goes down, so these plateaus are a consequence of having these saddle points essentially.",
                    "label": 0
                },
                {
                    "sent": "So let me.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "State the takehome messages.",
                    "label": 0
                },
                {
                    "sent": "Stronger statistical structure is learned earlier.",
                    "label": 1
                },
                {
                    "sent": "That's a very intuitive statement.",
                    "label": 0
                },
                {
                    "sent": "We think that holds true for nonlinear networks as well, but for nonlinear networks we don't know how to quantify the strong signal structure, and we don't know how to translate that into learning time.",
                    "label": 0
                },
                {
                    "sent": "But for this system, statistical structure is simply singular value and the associated singular vectors and the learning time is one over the singular value.",
                    "label": 0
                },
                {
                    "sent": "Now what does all this have to do with the hierarchical differentiation of concepts?",
                    "label": 1
                },
                {
                    "sent": "I'm.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The preceding analysis, or the preceding simulations, dealt with a specific data set.",
                    "label": 1
                },
                {
                    "sent": "Can we go beyond specific datasets to general principles of 1A?",
                    "label": 1
                },
                {
                    "sent": "Neural network is exposed to hierarchical structure.",
                    "label": 0
                },
                {
                    "sent": "So what we the way we attack this was we came up with a model for hierarchically structured data, basically through a hierarchical generative model.",
                    "label": 0
                },
                {
                    "sent": "I'm.",
                    "label": 0
                },
                {
                    "sent": "OK, so here's the basic idea.",
                    "label": 0
                },
                {
                    "sent": "We imagined a branching diffusion process that mimics the process of evolution, right?",
                    "label": 0
                },
                {
                    "sent": "So here's kind of this ancestral node, or this primordial node, and some feature will diffuse down the tree, and each time it goes down a branch it might mutate right?",
                    "label": 0
                },
                {
                    "sent": "And then eventually it will settle down and you'll be able to assign one feature to every item, and the items are objects at the leaves of the tree.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So it's literally like an evolutionary tree, and then each feature diffuses independently.",
                    "label": 0
                },
                {
                    "sent": "So what you get is you get a bunch of feature vectors for each of these leaves.",
                    "label": 0
                },
                {
                    "sent": "Each of these objects and two objects are more similar to each other.",
                    "label": 0
                },
                {
                    "sent": "If they have a lower common ancestor, right?",
                    "label": 0
                },
                {
                    "sent": "So you know this could be like you know, two different birds, and this could be like a flower that's very different from the two different birds, and this could be another animal.",
                    "label": 0
                },
                {
                    "sent": "OK, so then we feed this data generated from a hierarchical generative model to the neural network.",
                    "label": 0
                },
                {
                    "sent": "And we try to understand how the statistical structure of this model is embedded in this in this deep neural network.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sorry, so yeah.",
                    "label": 0
                },
                {
                    "sent": "So this is the basic description of these of these branching diffusions.",
                    "label": 0
                },
                {
                    "sent": "And so.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But we also now we know of course, that if we feed it to a deep linear network, all that matters is a singular value decomposition of the input output covariance matrix.",
                    "label": 0
                },
                {
                    "sent": "The covariance matrix has at least across objects in feature space.",
                    "label": 0
                },
                {
                    "sent": "Has this blocks within blocks structure, where two objects that are nearby each other are very similar to each other, but less similar as you go across as you traverse the tree.",
                    "label": 0
                },
                {
                    "sent": "It turns out that you can compute the singular vectors of this harkavy structured covariance matrix, and they respect the hierarchical structure of the tree in the sense that the largest well there's a uniform singular vector.",
                    "label": 0
                },
                {
                    "sent": "Right, the second singular vector over here makes the coarsest grained distinctions across the tree.",
                    "label": 0
                },
                {
                    "sent": "It can discriminate, say, between animals and plants OK?",
                    "label": 0
                },
                {
                    "sent": "The next singular vectors of slightly smaller singular value make finer scale discriminations, say different types of animals in different types of plans and then the finer singular vectors make individual item discriminations.",
                    "label": 0
                },
                {
                    "sent": "OK, so basically.",
                    "label": 0
                },
                {
                    "sent": "If you put the two and two together because the strongest singular values are associated with singular vectors that make the most coarse grained distinctions on the tree, the internal representations, the network will evolve so as to only make the most coarse grained distinctions OK, and then it will.",
                    "label": 0
                },
                {
                    "sent": "Overtime it will make finer and finer scale distinctions.",
                    "label": 0
                },
                {
                    "sent": "You can read about all of this in sort of published paper.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "First, we can compute the singular values theory and experiment match up.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, so basically yeah, so this is what I was saying.",
                    "label": 0
                },
                {
                    "sent": "The network learns stronger singular values first, the associated singular vectors progress from course define.",
                    "label": 0
                },
                {
                    "sent": "So internal Rep.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Stations the network will progress from coarse to fine, so this is an analytically derived.",
                    "label": 0
                },
                {
                    "sent": "Multidimensional scaling plot of the learning dynamics in the deep linear network, and.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You place it next to the simulations of these nonlinear neural networks.",
                    "label": 0
                },
                {
                    "sent": "You see, there's a.",
                    "label": 0
                },
                {
                    "sent": "There's a very nice qualitative match.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is kind of the difference between simulation and theory.",
                    "label": 0
                },
                {
                    "sent": "The theory gives you sort of conceptual insight into why the nonlinear simulations worked the way they did.",
                    "label": 0
                },
                {
                    "sent": "OK, and I'll come back to this when we discuss generalization in deep networks later on.",
                    "label": 0
                },
                {
                    "sent": "OK, so by the way, you know as we want.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I do science in deep learning.",
                    "label": 0
                },
                {
                    "sent": "I just wanted to highlight this method where.",
                    "label": 0
                },
                {
                    "sent": "You know, the only way we could do science is when we had a mathematically well defined model of the data set.",
                    "label": 0
                },
                {
                    "sent": "I know that in machine learning there's a strong culture of winning competitions.",
                    "label": 0
                },
                {
                    "sent": "OK, I kind of said this last year and I thought I was going to get eggs thrown at me, but I didn't.",
                    "label": 0
                },
                {
                    "sent": "So I'll say it again.",
                    "label": 0
                },
                {
                    "sent": "It's a horrible culture, right?",
                    "label": 0
                },
                {
                    "sent": "It's because you overfit to the.",
                    "label": 0
                },
                {
                    "sent": "Yoshua started the applause and he did last last time, so he saved me.",
                    "label": 0
                },
                {
                    "sent": "But but I'm glad.",
                    "label": 0
                },
                {
                    "sent": "I mean, that's why ya shinai collaborate?",
                    "label": 0
                },
                {
                    "sent": "Because we see eye to eye on a bunch of things.",
                    "label": 0
                },
                {
                    "sent": "But but basically, why is it a horrible culture?",
                    "label": 0
                },
                {
                    "sent": "You're rewarded for tuning hyperparameters to no end to get good performance in a very narrow regime of hyperparameter space.",
                    "label": 0
                },
                {
                    "sent": "OK, we saw beautiful talk by Phil Bun somewhere.",
                    "label": 0
                },
                {
                    "sent": "You know, if you really tune hyperparameters, LS teams do better than all the other highfalutin methods on sequence processing, that's great.",
                    "label": 0
                },
                {
                    "sent": "But he also said something really interesting.",
                    "label": 0
                },
                {
                    "sent": "Every single child with a normal upbringing learns language.",
                    "label": 0
                },
                {
                    "sent": "They never get screwed up and never not learn language 'cause their hyperparameter was slightly wrong or they got a bad in it, right?",
                    "label": 0
                },
                {
                    "sent": "So the brain is extremely robust.",
                    "label": 0
                },
                {
                    "sent": "Two choices of hyperparameters likely because there is individual variability across brains.",
                    "label": 0
                },
                {
                    "sent": "Yet we can all communicate with each other.",
                    "label": 0
                },
                {
                    "sent": "So the goal should be to get algorithms that may be achieved slightly worse performance, but our robust across hyperparameters, or even better, if we really want to understand what's going on in our systems, we should look at toy problems.",
                    "label": 0
                },
                {
                    "sent": "Toy problems where the task is mathematically well defined, you're not going to build a reason about learning dynamics on image net because image net is not a mathematically well defined data set.",
                    "label": 0
                },
                {
                    "sent": "But you might be able to reason about learning dynamics in datasets that mimic the essential structure of Imagenet, but maybe at a toy level, right?",
                    "label": 0
                },
                {
                    "sent": "So there should be a lot of work in this field on the Genesis of mathematically well defined datasets that may not be the competition datasets, but we can start to reason about how networks.",
                    "label": 0
                },
                {
                    "sent": "Learn represent the data and generalize right so when you're reviewing a paper and you see a paper like that, don't write it off.",
                    "label": 0
                },
                {
                    "sent": "And also you'll improve your daily lives because I know a lot of grad students are just tuning hyperparameters all the time.",
                    "label": 0
                },
                {
                    "sent": "You don't enjoy that, do you?",
                    "label": 0
                },
                {
                    "sent": "Let's start thinking alright anyways.",
                    "label": 0
                },
                {
                    "sent": "So sorry I didn't mean to go that far.",
                    "label": 0
                },
                {
                    "sent": "I let me walk back that statement.",
                    "label": 0
                },
                {
                    "sent": "I'm going to stop now and go back to, uh, not doing polemics.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "OK, so you do.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Maybe?",
                    "label": 0
                },
                {
                    "sent": "Very similar to what?",
                    "label": 0
                },
                {
                    "sent": "Paper.",
                    "label": 0
                },
                {
                    "sent": "Very close.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah it.",
                    "label": 0
                },
                {
                    "sent": ", expected, yeah, you don't need multiple scales to get the saddle point for any data set where you have any set of non trivial single values, you'll have a saddle point associated with each of those.",
                    "label": 0
                },
                {
                    "sent": "I mean.",
                    "label": 0
                },
                {
                    "sent": "Potentially I don't see an immediate connection but but we can talk about that afterwards.",
                    "label": 0
                },
                {
                    "sent": "There's a whole bunch of stuff and like when things are learned and so on.",
                    "label": 0
                },
                {
                    "sent": "There's just one.",
                    "label": 0
                },
                {
                    "sent": "Let's you do have time.",
                    "label": 0
                },
                {
                    "sent": "I'm going to skip.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm going to skip this as well.",
                    "label": 0
                },
                {
                    "sent": "We'll come back to it that there is this notion of, like you know, there are certain things called coherent categories.",
                    "label": 0
                },
                {
                    "sent": "An incoherent categories, right?",
                    "label": 0
                },
                {
                    "sent": "So for example.",
                    "label": 0
                },
                {
                    "sent": "You know the set of all things that are blue is intuitively an incoherent category.",
                    "label": 1
                },
                {
                    "sent": "The set of all things that are dogs is a very coherent category.",
                    "label": 0
                },
                {
                    "sent": "We have a name for the latter, but not a name for the former, and so the question is like, what is it that makes a category coherent and?",
                    "label": 0
                },
                {
                    "sent": "Understand.",
                    "label": 0
                },
                {
                    "sent": "Is incoherent OK?",
                    "label": 0
                },
                {
                    "sent": "Let me go through this section 'cause it's actually kind of interesting and it also talks about learning dynamics and statistical structure.",
                    "label": 0
                },
                {
                    "sent": "So let me explain.",
                    "label": 0
                },
                {
                    "sent": "Yeah, you're right, that's a very good question because I haven't defined in coherent or coherent right that was a problem in the psychology literature.",
                    "label": 0
                },
                {
                    "sent": "It was just this intuitive notion that there are some categories that are natural IE coherent, and some categories that are not.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "And you can see this in like a bunch of psychology phenomena.",
                    "label": 0
                },
                {
                    "sent": "If you ask questions about Korean categories, you get answers more quickly.",
                    "label": 0
                },
                {
                    "sent": "But if you ask questions about inquiring categories, get answers more slowly so.",
                    "label": 1
                },
                {
                    "sent": "So you know, in defining any category, you kind of have to solve these two matched problems, right?",
                    "label": 1
                },
                {
                    "sent": "A you need to identify the objects that belong to the category.",
                    "label": 0
                },
                {
                    "sent": "But you know, in order to do that, you need to know which features are important for the category.",
                    "label": 1
                },
                {
                    "sent": "For example, the color of a bird is often not important for determining whether something is a bird, because color varies across the set of birds.",
                    "label": 0
                },
                {
                    "sent": "Quite a lot.",
                    "label": 1
                },
                {
                    "sent": "Of course, wings is very important for being a bird.",
                    "label": 0
                },
                {
                    "sent": "OK so but what if you could identify the features that are important for category?",
                    "label": 0
                },
                {
                    "sent": "Well, you can't do that until you know which objects are part of the category, so there's a sort of Gordian knot, right?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "How might even simple neural networks simultaneously bootstrap and solve this Gordian knot to both simultaneously simultaneously identify which objects are part of the category and which features are belong to the category, right so?",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here's an example of a simple data set where you have a.",
                    "label": 0
                },
                {
                    "sent": "It's just a bunch of feature vectors, right?",
                    "label": 0
                },
                {
                    "sent": "So you have about 1000 objects and 1600 features, and they appear to occur randomly, right?",
                    "label": 0
                },
                {
                    "sent": "This mimics the structure of experience where you just see one object at a time, and you don't see a bunch of objects from the same category.",
                    "label": 0
                },
                {
                    "sent": "You just see one object at a time, so this is again my son.",
                    "label": 0
                },
                {
                    "sent": "My lab gave him a pink Unicorn as a gift.",
                    "label": 0
                },
                {
                    "sent": "His looking time went up when he saw this pink Unicorn, but he's seeing a whole bunch of features, right one at a time.",
                    "label": 0
                },
                {
                    "sent": "It kind of mimics that.",
                    "label": 0
                },
                {
                    "sent": "I don't really understand.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "My son works, so I'll replace him with something.",
                    "label": 0
                },
                {
                    "sent": "I do understand.",
                    "label": 0
                },
                {
                    "sent": "Deep linear network.",
                    "label": 0
                },
                {
                    "sent": "So what if we expose a deep linear network to this?",
                    "label": 0
                },
                {
                    "sent": "This analysis of this data set so we can look at the learning dynamics.",
                    "label": 0
                },
                {
                    "sent": "And as you can see, so color indexes time you can.",
                    "label": 0
                },
                {
                    "sent": "So this is a multidimensional scaling plot of the initial representations, the color.",
                    "label": 0
                },
                {
                    "sent": "So there's a whole bunch of objects that didn't get learned.",
                    "label": 0
                },
                {
                    "sent": "They stayed at the center of the space, but there's three groups of objects that got learned OK.",
                    "label": 0
                },
                {
                    "sent": "So why did they get learned?",
                    "label": 0
                },
                {
                    "sent": "You can look at the singular vectors or weight matrices of learn neural network and reorder both the objects and feed.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is according to that and you find that actually hidden.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In this data set, there were three clusters where within one cluster there was a subset of features and a subset of objects that had high probability of occurring and not otherwise yeah.",
                    "label": 1
                },
                {
                    "sent": "This is an autoencoder.",
                    "label": 0
                },
                {
                    "sent": "Yeah, it's unsupervised learning autoencoder.",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "OK, so this raises an interesting question, right?",
                    "label": 0
                },
                {
                    "sent": "How long did it take to learn each category, like when did it separate?",
                    "label": 0
                },
                {
                    "sent": "See that the biggest.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Category separated the earliest OK and then other categories.",
                    "label": 0
                },
                {
                    "sent": "Smaller categories separated later, and so on and so forth.",
                    "label": 0
                },
                {
                    "sent": "It turns out we.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Come up with a very simple theory for when these categories get learned.",
                    "label": 0
                },
                {
                    "sent": "Basically, if you have a universe of some number of objects and some category of a certain size of a number of objects coherently varying, yeah.",
                    "label": 0
                },
                {
                    "sent": "So so K0 is the number of objects in the category.",
                    "label": 1
                },
                {
                    "sent": "KF is a number of features in the category, and then there's a signal to noise ratio.",
                    "label": 1
                },
                {
                    "sent": "Let's say P is the probability of a feature being present an object if the categories within the category feature both in the category.",
                    "label": 1
                },
                {
                    "sent": "If the feature an object are both in the category.",
                    "label": 0
                },
                {
                    "sent": "And Q is the probability if it's outside, right?",
                    "label": 0
                },
                {
                    "sent": "So there's a signal to noise ratio, which is the difference in means over the standard deviation of the noise, and as long as the product or the size of the category of the product of the number of objects and features is bigger than the square root of the total size of the universe, the total number of objects and the total number of features, then and only then can this network learn this category.",
                    "label": 1
                },
                {
                    "sent": "OK, it turns out this is related to the singular value of the of the input output covariance matrix.",
                    "label": 0
                },
                {
                    "sent": "So this is a quantitative measure of category coherence.",
                    "label": 0
                },
                {
                    "sent": "So a coherent category, at least in this simple model is a large set of objects that simultaneously share a large set of features.",
                    "label": 0
                },
                {
                    "sent": "That's why the set of all things that are blue is incoherent, because there is not a large set of objects that not only share the property of blue, but also share a whole bunch of properties that Co occur with blue.",
                    "label": 0
                },
                {
                    "sent": "But the set of dogs is a coherent category because there's a large set of objects out there, dogs that all have fur, all have four legs.",
                    "label": 0
                },
                {
                    "sent": "All bark, all are cute.",
                    "label": 0
                },
                {
                    "sent": "We evolve them to be man humans best friend, right?",
                    "label": 0
                },
                {
                    "sent": "Like so dogs is a very large Co occurring cluster.",
                    "label": 0
                },
                {
                    "sent": "By the way, this is strong low rank structure in this matrix, and this is what neural networks do.",
                    "label": 0
                },
                {
                    "sent": "They're very good at picking up low rank structure.",
                    "label": 0
                },
                {
                    "sent": "Even the nonlinear ones.",
                    "label": 0
                },
                {
                    "sent": "OK, yeah.",
                    "label": 0
                },
                {
                    "sent": "So the categories.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah, yeah, that's right.",
                    "label": 0
                },
                {
                    "sent": "Well.",
                    "label": 0
                },
                {
                    "sent": "I have a question.",
                    "label": 0
                },
                {
                    "sent": "These areas holding much together, I wonder where was that map?",
                    "label": 0
                },
                {
                    "sent": "Both in that map, both math and theoretical computer science.",
                    "label": 0
                },
                {
                    "sent": "Then this last thing you are mentioning is related to the.",
                    "label": 0
                },
                {
                    "sent": "Yeah yeah, yeah.",
                    "label": 0
                },
                {
                    "sent": "Yes yes yes.",
                    "label": 0
                },
                {
                    "sent": "Understand their relationship with this.",
                    "label": 0
                },
                {
                    "sent": "Yes yes.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "This one is, but they don't work and they may be better in the same yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so it's a very astute question.",
                    "label": 0
                },
                {
                    "sent": "Actually, this inequality does mark the onset of a phase transition actually, and that's how we derived it.",
                    "label": 0
                },
                {
                    "sent": "It's a phase transition in random matrix theory where if you have a singular value that rises above this threshold and the associated singular vector will match the associate singular vectors will match object membership and feature membership.",
                    "label": 0
                },
                {
                    "sent": "But if you're below this threshold, that will not.",
                    "label": 0
                },
                {
                    "sent": "So this is related to eigen singular value transitions in random matrix theory in this phase.",
                    "label": 0
                },
                {
                    "sent": "If you want we can talk about in much more detail afterwards, but I just don't have time to derive it here, but I can give you the answer because the final answer is extremely intuitive.",
                    "label": 0
                },
                {
                    "sent": "Note that it places you can detect very tiny categories in a very large universe because there's a square root here, right?",
                    "label": 0
                },
                {
                    "sent": "But there's no square root here, so even when the SNR is only one like, you know, a category that has maybe 20 objects with 20 covarying features can be easily detected among 1600 objects or 1600 features and 1000 objects.",
                    "label": 0
                },
                {
                    "sent": "So even these deep linear networks are quite powerful at detecting this kind of structure, buried in noise.",
                    "label": 0
                },
                {
                    "sent": "OK, but of course there are limits OK?",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We can generalize this to hierarchically struck.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Your data and so on.",
                    "label": 0
                },
                {
                    "sent": "I'm going to skip the analysis of nonlinear networks, but that led to interesting initializations.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "These are orthogonal installations, and we're actually continuing to work on that.",
                    "label": 0
                },
                {
                    "sent": "I think we can resurrect the teenage.",
                    "label": 0
                },
                {
                    "sent": "With that we were kind of doing some that some of that right now, so any case.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's move onto OK. 12:30 is my OK perfect alright so.",
                    "label": 0
                },
                {
                    "sent": "Oh sorry OK so so, OK what about nonlinear networks and trainability, right?",
                    "label": 0
                },
                {
                    "sent": "So there's a kind of this classic question of why can we even train these networks?",
                    "label": 0
                },
                {
                    "sent": "The error landscape is horribly nonconvex.",
                    "label": 0
                },
                {
                    "sent": "Why don't we get stuck in local minima at high error?",
                    "label": 0
                },
                {
                    "sent": "And there's been.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A bunch of work on this recently.",
                    "label": 0
                },
                {
                    "sent": "You know we had some work with Yoshua Bengio on this unichrome Oscar with Jan Lacune had a slightly different perspective, but we essentially get to the same conclusions, right?",
                    "label": 0
                },
                {
                    "sent": "So the basic idea is often thought that local minimum at high error stand as a major impediment to nonconvex optimization, and this is this is a non convex error landscape over a low dimensional space and indeed you do have local minimum at high error, right?",
                    "label": 1
                },
                {
                    "sent": "But actually, we know that our sort of geometric intuition derived from living and moving within a low dimensional world is woefully inadequate for thinking about high dimensional spaces.",
                    "label": 1
                },
                {
                    "sent": "And it turns out that error landscapes over high dimensional spaces.",
                    "label": 0
                },
                {
                    "sent": "Don't have this property.",
                    "label": 0
                },
                {
                    "sent": "Instead you get a whole bunch of saddle points.",
                    "label": 0
                },
                {
                    "sent": "The same saddle points that we talked about earlier show up.",
                    "label": 1
                },
                {
                    "sent": "And then we developed an algorithm that can rapidly escape saddle points.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, so here's the basic intuition.",
                    "label": 0
                },
                {
                    "sent": "OK, let's say that you have an error landscape over the weights of a neural network where you have millions of parameters, right, millions of weights OK.",
                    "label": 0
                },
                {
                    "sent": "So this is a scalar error function over over 1,000,000 dimensions.",
                    "label": 0
                },
                {
                    "sent": "Let's say the gradient vanishes, so you're at a critical point.",
                    "label": 0
                },
                {
                    "sent": "What are the chances that that critical point is a local minimum so that the error landscape curves up in all 1,000,000 directions?",
                    "label": 0
                },
                {
                    "sent": "Because there's a million directions, it's highly unlikely that the error landscape will generically curve up in all 1 million directions.",
                    "label": 0
                },
                {
                    "sent": "Unless you're already near the bottom, OK.",
                    "label": 0
                },
                {
                    "sent": "So this can be made more quantitative and Cisco physicists made this quantitative not for deep neural networks, but for.",
                    "label": 0
                },
                {
                    "sent": "But for random landscape, so imagine that you just have a random Gaussian error landscape.",
                    "label": 1
                },
                {
                    "sent": "So think of this as a single draw from a Gaussian process.",
                    "label": 0
                },
                {
                    "sent": "OK, over a million variables.",
                    "label": 0
                },
                {
                    "sent": "So it's like this random wiggly landscape.",
                    "label": 0
                },
                {
                    "sent": "That's kind of smoothed over some length scale.",
                    "label": 0
                },
                {
                    "sent": "OK, so you have the single random landscape.",
                    "label": 0
                },
                {
                    "sent": "It's going to have many, many critical points where the gradient vanish is OK. You can take each critical point and put it in a 2 dimensional feature space.",
                    "label": 0
                },
                {
                    "sent": "One is it's errorlevel or its height.",
                    "label": 0
                },
                {
                    "sent": "The height of the critical point and let F be the fraction of negative curvature directions, right?",
                    "label": 1
                },
                {
                    "sent": "The fraction of directions that are eigenvalues, the Hessian that are negative versus positive where it curves up.",
                    "label": 0
                },
                {
                    "sent": "OK, so you might think a priority that critical points could appear anywhere in this 2 dimensional feature space, but actually there's an interesting concentration of measure phenomenon where they tend to concentrate on a monotonically increasing curve, OK?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So of course the global minimum lies here.",
                    "label": 0
                },
                {
                    "sent": "It has the lowest error and all the directions curve up, so the fraction of negative directions is 0.",
                    "label": 0
                },
                {
                    "sent": "The global maximum sits here, so that's the highest error and all the directions curve down, so the fraction negative eigenvalues is 1.",
                    "label": 0
                },
                {
                    "sent": "But basically as you go up and up, what happens is the critical point develops more and more negative curvature directions so that the number of negative curvature directions is tightly correlated with the error.",
                    "label": 0
                },
                {
                    "sent": "The error level.",
                    "label": 0
                },
                {
                    "sent": "This has two major implications.",
                    "label": 0
                },
                {
                    "sent": "There are no local minima at high error, IE.",
                    "label": 0
                },
                {
                    "sent": "There's nothing over here.",
                    "label": 0
                },
                {
                    "sent": "And if you get stuck in a global minimum, your errorlevel is sorry if you get stuck in a local minimum, your error level is close to that of the global minimum.",
                    "label": 0
                },
                {
                    "sent": "OK, IE that you'd be over here, OK?",
                    "label": 0
                },
                {
                    "sent": "So now this is a strong prediction, right?",
                    "label": 0
                },
                {
                    "sent": "But it's a prediction generated from random landscape theory.",
                    "label": 0
                },
                {
                    "sent": "Physicists are used to the idea that there are certain questions whose answers don't depend on the details.",
                    "label": 0
                },
                {
                    "sent": "That's why we can make.",
                    "label": 0
                },
                {
                    "sent": "That's why certain properties of water and ferromagnets have the same quantitative characteristics.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So I predicted this sort of qualitative curve would be similar for deep neural networks.",
                    "label": 0
                },
                {
                    "sent": "Of course, computer scientists are a little different.",
                    "label": 0
                },
                {
                    "sent": "They think what they're doing is special all the time, and so they would say no, no, no.",
                    "label": 0
                },
                {
                    "sent": "Our deep neural network landscapes are very, very special.",
                    "label": 0
                },
                {
                    "sent": "They're not anything like your random landscapes.",
                    "label": 0
                },
                {
                    "sent": "It won't look at all like this.",
                    "label": 0
                },
                {
                    "sent": "OK, but this essential concentration of measure phenomenon comes from a very simple universal argument in a high dimensional space, it's highly unlikely for all directions to curve up unless you're already near the bottom.",
                    "label": 0
                },
                {
                    "sent": "That intuition should generalize to neural networks, and it turns.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It does so so so you know.",
                    "label": 0
                },
                {
                    "sent": "Collaborated with Yoshua Bengio slab some very talented grad students in his lab tested the prediction from random landscape theory, and they did indeed.",
                    "label": 0
                },
                {
                    "sent": "So you can use Newton's method to search for these critical points once, and you do indeed find this concentration of measure phenomenon, where as the error level goes up, the fraction of negative eigenvalues goes up both for an endless problem and on cifar 10 problem.",
                    "label": 0
                },
                {
                    "sent": "For all the eigenvalues.",
                    "label": 0
                },
                {
                    "sent": "Positive exactly.",
                    "label": 0
                },
                {
                    "sent": "It.",
                    "label": 0
                },
                {
                    "sent": "This comes out of the model way where you model each of the eigenvalues as independent.",
                    "label": 0
                },
                {
                    "sent": "No, we don't model the eigenvalues is independent.",
                    "label": 0
                },
                {
                    "sent": "We model the landscape is correlated.",
                    "label": 0
                },
                {
                    "sent": "But in any case these are just numerical results and problems that people care about, right?",
                    "label": 0
                },
                {
                    "sent": "So this is just a simulation, right?",
                    "label": 0
                },
                {
                    "sent": "The more general argument, though, is yeah.",
                    "label": 0
                },
                {
                    "sent": "Based on them being independent, but it's no not at all.",
                    "label": 0
                },
                {
                    "sent": "Actually, if you take just a random symmetric matrix, OK?",
                    "label": 0
                },
                {
                    "sent": "Very famous result that the eigenvalue distribution density obeys of ignore semi circular law.",
                    "label": 0
                },
                {
                    "sent": "But there's eigenvalue repulsion.",
                    "label": 0
                },
                {
                    "sent": "So the joint distribution of is not independent but you do get this density.",
                    "label": 0
                },
                {
                    "sent": "So both the physics derivation and the random matrix theory ideas do not assume independent eigen values.",
                    "label": 0
                },
                {
                    "sent": "We can talk more about that in detail.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "OK, what can we do about this?",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the basic idea is so actually, why does Newton's method find saddle points?",
                    "label": 1
                },
                {
                    "sent": "Of any index or fraction negative eigenvalues.",
                    "label": 0
                },
                {
                    "sent": "It's because Newton's method does gradient descent.",
                    "label": 1
                },
                {
                    "sent": "It does gradient descent, but it pre multiplied by the inverse Hessian, right?",
                    "label": 0
                },
                {
                    "sent": "So if your Hessian so this is a very good idea.",
                    "label": 1
                },
                {
                    "sent": "If your local model for your function is a quadratic bowl, because Newton's method will descend a quadratic bowl in one step.",
                    "label": 0
                },
                {
                    "sent": "That's how it was derived.",
                    "label": 0
                },
                {
                    "sent": "But if we know that there are all these negative curvature directions, the additional negative sign in the Hessian turns you around and makes you go uphill, right?",
                    "label": 1
                },
                {
                    "sent": "So for example in this eigen direction, the Hessian has a positive eigenvalue.",
                    "label": 0
                },
                {
                    "sent": "So following Newton's method you go downhill.",
                    "label": 0
                },
                {
                    "sent": "But here you have a negative eigenvalue, so the negative gradient would go this way.",
                    "label": 1
                },
                {
                    "sent": "But the extra - turns around and makes you go up.",
                    "label": 0
                },
                {
                    "sent": "That's why Newton's method gets attracted to saddle points, which is why we could use it to generate the curves in the previous.",
                    "label": 0
                },
                {
                    "sent": "Previous plot OK so a very simple fix is just to divide by the absolute value of the Hessian, which is by definition a matrix that has the same eigenvectors but all the eigenvalues are replaced with their absolute value.",
                    "label": 0
                },
                {
                    "sent": "And there's a way to think about this in terms of a trust region method.",
                    "label": 1
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so this actually, you know, this is just more evidence that saddle Points might indeed be an impediment.",
                    "label": 0
                },
                {
                    "sent": "Optimization, which is that you know if we do stochastic gradient descent on the deep auto encoder problem in a recurrent neural network problem, we find that stochastic gradient descent gets stuck in a plateau OK.",
                    "label": 0
                },
                {
                    "sent": "Uh, but if you snow this plateau might be seen as evidence of a local minimum, but actually that's an illusion because if you switch to the saddle Free Newton method, you suddenly see a drop.",
                    "label": 0
                },
                {
                    "sent": "OK, so basically you are stuck in the plateau surrounding a saddle point and stochastic gradient method couldn't rapidly escape it and exploit the negative pressure directions to turn make the error go down, but saddle free Newton could.",
                    "label": 1
                },
                {
                    "sent": "Now that's good news.",
                    "label": 0
                },
                {
                    "sent": "What's the bad news?",
                    "label": 0
                },
                {
                    "sent": "This is a second order algorithm, so it's very difficult to scale up.",
                    "label": 0
                },
                {
                    "sent": "There could be interesting research to be done in marrying approximate 2nd order methods with saddle Free Newton and I don't think either yashan are working on that, so that's a good good take home project, yeah?",
                    "label": 0
                },
                {
                    "sent": "Respect by just lowering the learning rate.",
                    "label": 0
                },
                {
                    "sent": "Once you get this kind of flash, yeah, yeah that's yeah, seems like.",
                    "label": 0
                },
                {
                    "sent": "That wouldn't work if what you were.",
                    "label": 0
                },
                {
                    "sent": "So here's an alternate explanation for the lowering the learning rate, so in lowering the learning rate you may be bouncing around, right?",
                    "label": 0
                },
                {
                    "sent": "You know over different things, but then if you lower the learning rate then you won't bounce around and you'll go down.",
                    "label": 0
                },
                {
                    "sent": "Saddle point so I'm kind of curious, is this what you're seeing here?",
                    "label": 0
                },
                {
                    "sent": "Like maybe it isn't that you're out of Saddle Point, it's that your your method is actually adopting.",
                    "label": 0
                },
                {
                    "sent": "Yeah, effectively lower.",
                    "label": 0
                },
                {
                    "sent": "We never changed the learning rate.",
                    "label": 0
                },
                {
                    "sent": "I mean we did pre multiply by Hessian so.",
                    "label": 0
                },
                {
                    "sent": "Usually what happens is that increases the learning rate because what you do is you use the shallow curvature directions and escaped them.",
                    "label": 0
                },
                {
                    "sent": "But you're right, we should.",
                    "label": 0
                },
                {
                    "sent": "We could look at the trajectory and see if it preferentially aligns along the small eigenvalues and absolute value of the Hessian or the large eigenvalues.",
                    "label": 0
                },
                {
                    "sent": "If it's a large ones, we're lowering the learning rate.",
                    "label": 0
                },
                {
                    "sent": "If it's a small ones were increasing the learning rate, that would be the test.",
                    "label": 0
                },
                {
                    "sent": "It's a good test to do.",
                    "label": 0
                },
                {
                    "sent": "Like like so the the argues that lowering the learning rate, that's sort of like finding this narrow minima.",
                    "label": 0
                },
                {
                    "sent": "If that's the case, then I guess you would expect this to decrease the learning rate as well.",
                    "label": 0
                },
                {
                    "sent": "Can you be going from like low curvature to the icon return?",
                    "label": 0
                },
                {
                    "sent": "Yeah, OK, so there was further simulations that Yoshi's Group did, which was we looked at the spectrum of eigenvalues.",
                    "label": 0
                },
                {
                    "sent": "Each time we saw this drop of the Hessian and when we saw this drop we found that the maximum negative eigenvalue went.",
                    "label": 0
                },
                {
                    "sent": "Up in absolute value, right?",
                    "label": 0
                },
                {
                    "sent": "So it did seem that while this drop was happening, the local region around the function had lots of negative curvature OK?",
                    "label": 0
                },
                {
                    "sent": "We didn't look at the inner product between the gradient and the eigen directions, which would be a finer resolution analysis to do.",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "That fixes the - problem.",
                    "label": 0
                },
                {
                    "sent": "There's a.",
                    "label": 0
                },
                {
                    "sent": "There's another derivation of that, using trust regions, but I want to get on to other others.",
                    "label": 0
                },
                {
                    "sent": "There's lots more fun stuff to do.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "OK, but for generalization you may not want to optimize very well.",
                    "label": 0
                },
                {
                    "sent": "That's a theme that's going to come up later on, so that's another issue.",
                    "label": 0
                },
                {
                    "sent": "Well, we'll talk about that.",
                    "label": 0
                },
                {
                    "sent": "OK, so now what about expressivity?",
                    "label": 0
                },
                {
                    "sent": "OK, so why is it that suddenly when you go deeper you can do more stuff?",
                    "label": 0
                },
                {
                    "sent": "What is it that a deep function can buy you?",
                    "label": 0
                },
                {
                    "sent": "The shallow function cannot.",
                    "label": 0
                },
                {
                    "sent": "OK, so we worked.",
                    "label": 0
                },
                {
                    "sent": "We did some work on this and there's also other work that I'll talk about where we actually connected deep learning to the theory of chaos so it actually turns out that Chaos Theory is a special case of deep learning.",
                    "label": 0
                },
                {
                    "sent": "Now that's I don't know if that's good news or bad news for deep learning theory, but it's important to know that deep networks can have a chaotic phase, and you may wish to avoid it, but it has.",
                    "label": 0
                },
                {
                    "sent": "It has a dual viewpoint.",
                    "label": 0
                },
                {
                    "sent": "The chaos can be the origin of high expressivity as well.",
                    "label": 0
                },
                {
                    "sent": "So I'll talk.",
                    "label": 0
                },
                {
                    "sent": "I'll tell you what I mean about that.",
                    "label": 0
                },
                {
                    "sent": "So that's all in this, you know.",
                    "label": 0
                },
                {
                    "sent": "Luckily like, I'm just trying to give you a flavor of everything.",
                    "label": 0
                },
                {
                    "sent": "I don't expect you to understand everything in this talk, but almost everything I'm talking about is published.",
                    "label": 0
                },
                {
                    "sent": "So if you're interested, you can see the detail.",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so this is work with my grad student Ben Poole.",
                    "label": 0
                },
                {
                    "sent": "He's kind of the ringleader of this work and it's also collaboration with my friend Josh, who also had a companion paper.",
                    "label": 0
                },
                {
                    "sent": "Looking at Relu Networks, and we looked at NH Networks in a different different kind of theory.",
                    "label": 0
                },
                {
                    "sent": "OK, so the basic question again is what kind of function can deep networks expresses?",
                    "label": 0
                },
                {
                    "sent": "Shallow networks cannot so.",
                    "label": 0
                }
            ]
        },
        "clip_80": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Course we know that networks with one hidden layer are universal function approximators.",
                    "label": 1
                },
                {
                    "sent": "So why do we even need depth well?",
                    "label": 1
                },
                {
                    "sent": "In general, the universal function approximation theorems yield no guarantee on the size of the hidden layer required to approximate any particular function well.",
                    "label": 1
                },
                {
                    "sent": "OK, so the overall idea is that maybe there exist special functions that can be computed very efficiently using a deep neural network using a polynomial number of neurons in the input dimension say, but not by a shallow network.",
                    "label": 1
                },
                {
                    "sent": "IE you require exponential number of neurons OK?",
                    "label": 0
                },
                {
                    "sent": "So this goes back to intellectual traditions and Boolean circuit theory and circuit complexity.",
                    "label": 0
                },
                {
                    "sent": "The parity function is such a function.",
                    "label": 0
                },
                {
                    "sent": "You know, if you have if you have a certain depth of logic gates, you can compute the parity function easily using a small number of logic gates, but not if you have limited depth logical depth in your in your circuit.",
                    "label": 0
                }
            ]
        },
        "clip_81": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so there's been a bunch of work that kinds of has the following flavor.",
                    "label": 0
                },
                {
                    "sent": "They look at a particular non linearity and they have a particular measure of functional complexity, say Ray Lewis and the number of linear regions.",
                    "label": 0
                },
                {
                    "sent": "So if you have a rail network with one neuron, is the output in a high dimensional input that computes a piecewise linear function over input space so one potential measure of functional complexity is the number of linear regions and what they can show is that they can show that there exists a special function computable by a deep network.",
                    "label": 1
                },
                {
                    "sent": "Sorry there exists a special function where the number of linear regions is exponential in the depth.",
                    "label": 1
                },
                {
                    "sent": "And so in order to approximate this function with a shallow Relu network, you would need exponentially many Relu units.",
                    "label": 0
                },
                {
                    "sent": "But using a deep network, you only need a polynomial number of units, and the basic idea is you construct these tent functions and then you recurse it.",
                    "label": 0
                },
                {
                    "sent": "OK, you can find the details on this in this picture, but basically what this is showing is that there exists one function OK that has this depth efficiency.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_82": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There's other examples, for example a some product network.",
                    "label": 0
                },
                {
                    "sent": "You know, some product network computes high degree polynomials, right?",
                    "label": 0
                },
                {
                    "sent": "And a natural measure of the complexity of a polynomial is a number of monomial's the number of terms.",
                    "label": 1
                },
                {
                    "sent": "If you just have a shallow some product network, or you can show that there exists individual sum product networks where you can compute polynomials that are exponential in the depth just by composing polynomials, you can get the degree of the polynomial be exponential adept, but if you do it with one layer of some product, you need exponentially many some product units.",
                    "label": 1
                },
                {
                    "sent": "OK, so again, that's one function that has this depth efficiency.",
                    "label": 0
                }
            ]
        },
        "clip_83": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, but this raises natural questions how, how?",
                    "label": 0
                },
                {
                    "sent": "Natural are these functions from the perspective of AI?",
                    "label": 1
                },
                {
                    "sent": "Right are these functions rare?",
                    "label": 0
                },
                {
                    "sent": "Curiosity's, and they're not really the types of functions we actually want to compute in practice.",
                    "label": 1
                },
                {
                    "sent": "Or is this phenomenon much more generic than these?",
                    "label": 0
                },
                {
                    "sent": "Then these specific examples is in some sense, any function.",
                    "label": 0
                },
                {
                    "sent": "Computed by a generic deep network not efficiently computable by shallow network.",
                    "label": 1
                },
                {
                    "sent": "Right, if so, we would like a theory of deep neural expressivity that does this for arbitrary nonlinearities.",
                    "label": 1
                },
                {
                    "sent": "Is not tide to any particular non linearity.",
                    "label": 0
                },
                {
                    "sent": "And it's an we use potentially a more natural general measure of functional complexity.",
                    "label": 0
                }
            ]
        },
        "clip_84": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so another way to think about it is various previous theoretical techniques.",
                    "label": 0
                },
                {
                    "sent": "Because of a limited theoretical technique, there were tide to a particular linearity in a particular measure, functional complexity.",
                    "label": 0
                },
                {
                    "sent": "What we do is we use a slightly more general set of techniques.",
                    "label": 0
                },
                {
                    "sent": "We combine Romanian geometry, which is the, which is a theory of curvature and geometry with dynamical mean field theory, and this is powerful enough to analyze the expressivity of arbitrary nonlinearities.",
                    "label": 0
                },
                {
                    "sent": "And we use extrinsic curvature as a measure of complexity, and we will show what will show is that.",
                    "label": 1
                },
                {
                    "sent": "Even in a generic random deep network, here's the physicist comes out in me.",
                    "label": 0
                },
                {
                    "sent": "I'm now analyzing a random network which I said was not a good thing to do, but for expressivity it's OK. Alright, so we.",
                    "label": 0
                },
                {
                    "sent": "We show that a random deep network the functional curvature can grow exponentially with depth but not width.",
                    "label": 1
                },
                {
                    "sent": "And the origins of this exponential growth can be related to chaos theory.",
                    "label": 0
                },
                {
                    "sent": "So basically that's the strategy we're going to show a random deep network and do stuff that no shallow network can.",
                    "label": 0
                }
            ]
        },
        "clip_85": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and by the way, this is relates to disentangle ING of neural representations, but I won't have time to talk about that.",
                    "label": 0
                }
            ]
        },
        "clip_86": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so here's the basic idea.",
                    "label": 0
                },
                {
                    "sent": "Just pick a random network where the weights and biases are iid Gaussian.",
                    "label": 1
                },
                {
                    "sent": "That's it, and you have an arbitrary non linearity, which I'll call Fi.",
                    "label": 0
                },
                {
                    "sent": "OK, so the weights are iid Gaussian.",
                    "label": 0
                },
                {
                    "sent": "They're scaled by 1 / N so that the weights and biases operate on equal footing.",
                    "label": 0
                },
                {
                    "sent": "And as N goes to Infinity, there's a well defined limit, OK?",
                    "label": 1
                },
                {
                    "sent": "When is the width so ensival is the number of layers neurons in layer L?",
                    "label": 0
                },
                {
                    "sent": "We can ask very basic questions.",
                    "label": 0
                }
            ]
        },
        "clip_87": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Like if you have a single point that propagates through the network you know does it grow or shrink, i.e.",
                    "label": 0
                },
                {
                    "sent": "You put in a single feature vector.",
                    "label": 1
                },
                {
                    "sent": "Here an input vector here just its length grow or shrink as it propagates through the network.",
                    "label": 1
                },
                {
                    "sent": "More importantly, if you take a pair of points.",
                    "label": 0
                },
                {
                    "sent": "So if you take 2 inputs that are might be close to each other as they propagate through the network, do they become more similar to each other overtime or do they decorrelate and become more different overtime?",
                    "label": 1
                },
                {
                    "sent": "OK, that's a very basic question.",
                    "label": 0
                },
                {
                    "sent": "As they become more similar.",
                    "label": 0
                },
                {
                    "sent": "That's what I call the ordered regime where basically the network makes everything similar.",
                    "label": 0
                },
                {
                    "sent": "If you even take nearby inputs and as they propagate through the network, if they decorrelated become more different than the network is fundamentally amplifying small initial differences and making them very different.",
                    "label": 0
                },
                {
                    "sent": "That's the very definition of chaos.",
                    "label": 0
                },
                {
                    "sent": "A sensitivity to small changes and initial conditions.",
                    "label": 0
                },
                {
                    "sent": "So that's the chaotic regime.",
                    "label": 0
                },
                {
                    "sent": "Yeah, it's like it's like I have an, you know, an image, net, image and a very tiny perturbation of the image.",
                    "label": 0
                },
                {
                    "sent": "Net image.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so that's two input vectors, right?",
                    "label": 1
                },
                {
                    "sent": "An image.",
                    "label": 0
                },
                {
                    "sent": "So you can equate image with a point or a vector in this language, OK?",
                    "label": 0
                },
                {
                    "sent": "And then also a smooth smooth manifold.",
                    "label": 0
                },
                {
                    "sent": "OK, so I'm going to skip the issue of a thing I'm just going to tell you the answer.",
                    "label": 0
                },
                {
                    "sent": "OK, I'm going to skip the derivate.",
                    "label": 0
                },
                {
                    "sent": "Basically we can analyze that.",
                    "label": 0
                },
                {
                    "sent": "We can analytically compute how similarity structure propagates the network and it makes these predictions OK. Oh, where'd it go.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "Yeah, purf.",
                    "label": 0
                }
            ]
        },
        "clip_88": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so there's a phase diagram for this network, so this is the standard deviation of the weights.",
                    "label": 0
                },
                {
                    "sent": "This is the standard deviation of the biases OK?",
                    "label": 0
                },
                {
                    "sent": "This is the correlation coefficient between two inputs as they propagate through the network, it reaches a fixed point.",
                    "label": 0
                },
                {
                    "sent": "And what happens is there's a boundary between order and chaos.",
                    "label": 0
                },
                {
                    "sent": "So here what happens is so if the biases are large.",
                    "label": 0
                },
                {
                    "sent": "So what biases do?",
                    "label": 0
                },
                {
                    "sent": "Biases are independent of the input, so they push your state of the network in the same direction regardless of what the two inputs were.",
                    "label": 0
                },
                {
                    "sent": "So biases will always tend to align two different inputs and make them similar to each other.",
                    "label": 0
                },
                {
                    "sent": "However, as you crank up the weights and you have a non linearity, a teenage non linearity.",
                    "label": 0
                },
                {
                    "sent": "The large weights can overwhelm the common bias, and eventually it'll decorrelate the inputs and make them dissimilar from each other.",
                    "label": 0
                },
                {
                    "sent": "So basically when the weights are large by an amount that depends on the bias, the simplest one is when the bias is 0, the weights have to have a standard deviation of 1.",
                    "label": 0
                },
                {
                    "sent": "Then you're in this chaotic regime where two inputs will decorrelate.",
                    "label": 0
                },
                {
                    "sent": "However, if you're in this regime, two inputs will correlate.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is the edge of chaos.",
                    "label": 0
                },
                {
                    "sent": "A boundary between a chaotic regime and ordered regime.",
                    "label": 0
                },
                {
                    "sent": "What is the?",
                    "label": 0
                },
                {
                    "sent": "OK, let me now.",
                    "label": 0
                },
                {
                    "sent": "Discuss what happens to a smooth manifold as it propagates to the network, because that will give you a more visceral image of what the case.",
                    "label": 0
                }
            ]
        },
        "clip_89": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It looks like so now.",
                    "label": 0
                },
                {
                    "sent": "Let's imagine that you have a manifold of images.",
                    "label": 0
                },
                {
                    "sent": "Let's say it's like a cat at different orientations or positions or something like that.",
                    "label": 0
                },
                {
                    "sent": "OK, as this manifold propagates through the network OK. You can ask how does its geometry change.",
                    "label": 0
                }
            ]
        },
        "clip_90": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So this is what it looks like in the ordered regime when the weights are small.",
                    "label": 0
                },
                {
                    "sent": "Right, this is a tannage non linearity.",
                    "label": 0
                },
                {
                    "sent": "So when the weights are small, you're basically exploring the linear range of the teenage.",
                    "label": 0
                },
                {
                    "sent": "And the teenagers are compressive non linearity, so it ends in the sense that it's slope is always less than or equal to 1.",
                    "label": 0
                },
                {
                    "sent": "So it tends to compress things and the weights are small so tends to compress things.",
                    "label": 0
                },
                {
                    "sent": "So basically the circle propagates through in a linear manner and it remains a circle.",
                    "label": 0
                },
                {
                    "sent": "But what happens is the weights get larger so that you explore the nonlinear regime of the teenage.",
                    "label": 0
                },
                {
                    "sent": "Then what happens is the circle every pair of points on the circle will decorrelate and the circuit becomes circle becomes more and more ruffled.",
                    "label": 0
                },
                {
                    "sent": "OK, and at a larger weights it becomes more ruffled, more quickly.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is what the chaos does to inputs.",
                    "label": 0
                },
                {
                    "sent": "OK, intuitively, why is this happening?",
                    "label": 0
                },
                {
                    "sent": "Just imagine the circle propagating through the network, right?",
                    "label": 0
                },
                {
                    "sent": "You have these large weights that expand the circle, but then you go through the non linearity which folds the circle.",
                    "label": 0
                },
                {
                    "sent": "So you have this expansion, folding, expansion, folding, and that's the origin of the roughly OK. All of this English can be translated to math and you can get a quantitative match between theory and experiment.",
                    "label": 0
                },
                {
                    "sent": "That's what we see here.",
                    "label": 0
                },
                {
                    "sent": "This is the autocorrelation.",
                    "label": 0
                },
                {
                    "sent": "The solid curves are theory.",
                    "label": 0
                },
                {
                    "sent": "The dots are simulations, and there's a nice match, but I'm just giving you the essential intuition behind what goes on in the chaotic regime.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_91": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is another example of what goes on.",
                    "label": 0
                },
                {
                    "sent": "Let's.",
                    "label": 0
                },
                {
                    "sent": "You think that this is an artifact of linear dimensionality reduction.",
                    "label": 0
                },
                {
                    "sent": "What happens is.",
                    "label": 0
                },
                {
                    "sent": "The the this is a teapot of the circle in the chaotic regime, and you can see that it gets more and more ruffled now just to make a Long story short, what we can show is that the global curvature of the circle for a wide range of nonlinearities grows exponentially with depth, and also the length of the circle grows exponentially with depth.",
                    "label": 0
                },
                {
                    "sent": "As you get this iterated expansion and folding expansion folding and that gives you this exponential growth, then we.",
                    "label": 0
                }
            ]
        },
        "clip_92": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "You know it's not learned, it's just a random network, just a random network, yeah?",
                    "label": 0
                }
            ]
        },
        "clip_93": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We can quantify the curvature using ideas from Romanian geometry, but I'll skip it.",
                    "label": 0
                },
                {
                    "sent": "I'll just tell you the.",
                    "label": 0
                }
            ]
        },
        "clip_94": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is the match between the propagation of curvature, both theoretically.",
                    "label": 0
                }
            ]
        },
        "clip_95": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And numerically, but what I'll tell you is now the depth separation.",
                    "label": 0
                },
                {
                    "sent": "Let's say that you take the same circle and you propagate it through one layer.",
                    "label": 0
                },
                {
                    "sent": "Right, so this is like your shallow network and you can make this layer as wide as you want.",
                    "label": 0
                },
                {
                    "sent": "OK, we can prove a theorem that says no matter how you choose the weights of this of the shallow network, no matter how you choose them, you can never get the length of the circle to grow faster than the square root of the width.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So the result, the spirit of the result is the following.",
                    "label": 0
                },
                {
                    "sent": "Pick any random deep network.",
                    "label": 0
                },
                {
                    "sent": "If it's in the chaotic phase.",
                    "label": 0
                },
                {
                    "sent": "The global curvature in length of a circle will grow exponentially with depth.",
                    "label": 0
                },
                {
                    "sent": "Doesn't matter which weights you choose with high probability for any random weights that will happen, But if you limit yourself to death one, no matter what weights you choose, the corresponding quantities can't grow faster than square root of the width.",
                    "label": 0
                },
                {
                    "sent": "So depth and width have very different effects, especially in this chaotic regime.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_96": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "By the way, the same goes for decision boundaries.",
                    "label": 0
                },
                {
                    "sent": "We can show that decision boundaries can acquire exponential curvature.",
                    "label": 0
                }
            ]
        },
        "clip_97": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we have to look at the curvature of codimension of N -- 1 dimensional manifolds.",
                    "label": 0
                }
            ]
        },
        "clip_98": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we quantify that and so on.",
                    "label": 0
                }
            ]
        },
        "clip_99": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so so.",
                    "label": 0
                },
                {
                    "sent": "So deep neural networks can have this expressivity if they go into this chaotic regime.",
                    "label": 0
                }
            ]
        },
        "clip_100": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so now let's discuss what time.",
                    "label": 0
                },
                {
                    "sent": "OK, good a few more minutes and it will end generalizable.",
                    "label": 0
                },
                {
                    "sent": "It is easy 'cause we don't really know nothing about it.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_101": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I will tell you one situation where we recently worked out everything about General Zhao generalizability, but for a shallow net for shallow network, OK, not for a deep network.",
                    "label": 0
                },
                {
                    "sent": "So generalizability is intimately related to the field of high dimensional statistics, right?",
                    "label": 1
                },
                {
                    "sent": "So there's been kind of a revolution in the way that we do experiments before we used to carefully figure out what we want to measure.",
                    "label": 0
                },
                {
                    "sent": "And then we take many, many data points.",
                    "label": 0
                },
                {
                    "sent": "So this is situation with a number of data points is going to Infinity and the dimensionality of the data is order one.",
                    "label": 1
                },
                {
                    "sent": "Now we're in a situation where both are large and the ratio is less than one or order one right.",
                    "label": 0
                },
                {
                    "sent": "In particular for neural networks we overparameterized our system so the dimensionality of over which of the space over which we're learning can be many, many millions of parameters, and the amount of training data can actually be less than that.",
                    "label": 0
                },
                {
                    "sent": "The amount of training data can be less than the number of parameters were trying to learn.",
                    "label": 0
                },
                {
                    "sent": "That's the so called high dimensional regime and we've been working a lot.",
                    "label": 0
                },
                {
                    "sent": "This is very relevant to neuroscience because in neuroscience we can now record from hundreds to thousands of neurons, but we don't get that many trials.",
                    "label": 1
                },
                {
                    "sent": "We get hundreds of trials, so neuroscientific data is in the high dimensional regime.",
                    "label": 0
                },
                {
                    "sent": "Deep learning training is in the high dimensional regime.",
                    "label": 0
                },
                {
                    "sent": "We need a theory for that.",
                    "label": 1
                },
                {
                    "sent": "So we recently worked out a theory of the best way to do regression in the high dimensional regime.",
                    "label": 0
                },
                {
                    "sent": "That's the physical review X paper, and I'll just tell you the basic idea, 'cause I think there's some lessons.",
                    "label": 0
                },
                {
                    "sent": "That we can take away to deeper networks there so.",
                    "label": 0
                }
            ]
        },
        "clip_102": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here's the basic idea.",
                    "label": 0
                },
                {
                    "sent": "You have a just doing regression OK, linear regression.",
                    "label": 0
                },
                {
                    "sent": "Actually it's not OK.",
                    "label": 0
                },
                {
                    "sent": "The general model is linear, but the estimation algorithm is not not linear.",
                    "label": 1
                },
                {
                    "sent": "So basically imagine that you have some unknown set of regression coefficients.",
                    "label": 0
                },
                {
                    "sent": "So this is just like a one layer neural network with one one output neuron, S 0 is a set of weights.",
                    "label": 0
                },
                {
                    "sent": "You get some training data.",
                    "label": 0
                },
                {
                    "sent": "The output is the input dotted with S0 plus some noise.",
                    "label": 1
                },
                {
                    "sent": "OK, you don't get to see the unknown regression coefficients.",
                    "label": 0
                },
                {
                    "sent": "You only get to see the training data and from that you have to estimate S at.",
                    "label": 0
                },
                {
                    "sent": "There's a wide variety of estimators in statistics known as M. Estimators were basically what you do is you minimize some cost function.",
                    "label": 0
                },
                {
                    "sent": "Right where you penalize the difference between your output and what you'd get.",
                    "label": 0
                },
                {
                    "sent": "If your regression conferences were S. Right, and you optimize that over S and maybe you add a regularizer to your unknown regression coefficients S so your estimated regression coefficients reflect a compromise between matching the training data and regularising.",
                    "label": 0
                },
                {
                    "sent": "OK, we're familiar with that.",
                    "label": 0
                },
                {
                    "sent": "That's what we do in deep learning as well.",
                    "label": 0
                },
                {
                    "sent": "OK, but the key issue is what loss function do we use row, and what regularizer should we use OK?",
                    "label": 1
                },
                {
                    "sent": "To get the best performance, OK, the best performances, of course.",
                    "label": 0
                },
                {
                    "sent": "Minimizing generalization error.",
                    "label": 0
                },
                {
                    "sent": "OK, for this simple scenario, generalization error is directly in monotonically related to the L2 error between our estimated regression coefficients and our actual regression coefficients.",
                    "label": 0
                },
                {
                    "sent": "So we want to minimize L2 error OK.",
                    "label": 0
                },
                {
                    "sent": "So now there's a ton of algorithms out there for doing this, and they both correspond to different choices of the measurement penalty or loss function and the regularizer, right?",
                    "label": 0
                },
                {
                    "sent": "So, for example, lease you have least squares maximum likelihood, Ridge regression, lasso, elastic net map estimation.",
                    "label": 0
                },
                {
                    "sent": "They're all special cases of this very general framework.",
                    "label": 0
                },
                {
                    "sent": "But which algorithm is the best one OK?",
                    "label": 0
                },
                {
                    "sent": "So we answered this question recently, OK?",
                    "label": 0
                },
                {
                    "sent": "Where again best is minimizing this L2 estimation error, which is equivalent to minimizing generalization error in this setup.",
                    "label": 1
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_103": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'll tell you what the answer is.",
                    "label": 0
                },
                {
                    "sent": "It depends on how much data you have.",
                    "label": 0
                },
                {
                    "sent": "The right thing to do depends on how much data you have.",
                    "label": 0
                },
                {
                    "sent": "There's no data independent answer to this question.",
                    "label": 0
                },
                {
                    "sent": "OK, so the basic and So what do I mean by the?",
                    "label": 0
                }
            ]
        },
        "clip_104": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Out of data we're in this high dimensional setting where we have P unknown regression coefficients and end measurements, right?",
                    "label": 0
                },
                {
                    "sent": "So the measurement density is the ratio of the number of data points to the number of variables you're trying to estimate.",
                    "label": 0
                },
                {
                    "sent": "Get this ratio.",
                    "label": 0
                },
                {
                    "sent": "Alpha is the all important ratio when Alpha is large you have lots of data.",
                    "label": 0
                },
                {
                    "sent": "High measurement density when Alpha small, which is where we live.",
                    "label": 0
                },
                {
                    "sent": "In deep learning you have not many training points.",
                    "label": 0
                },
                {
                    "sent": "Lots of parameters to estimate OK.",
                    "label": 0
                }
            ]
        },
        "clip_105": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It turns out.",
                    "label": 0
                },
                {
                    "sent": "So this is an example where of course it depends on the signal and noise distribution as well.",
                    "label": 0
                },
                {
                    "sent": "Let's say the signal and noise are Laplace distributed, then maximum likelihood corresponds to an absolute value penalty and an absolute value loss regularizer, right?",
                    "label": 0
                },
                {
                    "sent": "It turns out at large measurement density.",
                    "label": 1
                },
                {
                    "sent": "Sorry, that's map estimation right at large measurement density map estimation is optimal.",
                    "label": 0
                },
                {
                    "sent": "You cannot do better than map.",
                    "label": 0
                },
                {
                    "sent": "That's what we show.",
                    "label": 0
                },
                {
                    "sent": "But at lower measurement density, it turns out that you don't want to do map anymore.",
                    "label": 0
                },
                {
                    "sent": "You actually want a smooth, not nonlinearly, smooth.",
                    "label": 0
                },
                {
                    "sent": "Your your loss function in your regularizer.",
                    "label": 1
                },
                {
                    "sent": "And Interestingly enough, when Alpha gets close to 0 or less than one, this nonlinear smoothing leads to a quadratic loss and a quadratic regularizer.",
                    "label": 0
                },
                {
                    "sent": "Independent of the signal and noise distribution, as long as they're log concave.",
                    "label": 1
                },
                {
                    "sent": "OK, so actually Ridge regression is the best thing to do.",
                    "label": 0
                },
                {
                    "sent": "When you have very little data.",
                    "label": 0
                },
                {
                    "sent": "So ironically, you ignore the distribution of signal and noise when you have very little data and you'll do better.",
                    "label": 0
                },
                {
                    "sent": "So we were able to analytically compute the generalization error as a function of the amount of measurement density.",
                    "label": 0
                },
                {
                    "sent": "And we did indeed find that and so the solid curves are theory.",
                    "label": 0
                },
                {
                    "sent": "The dots are simulations, they match up, and we do find that at high measurement density map is best at low measurement density, quadratic is best, and quadratic matches the performance of the best algorithm whatsoever.",
                    "label": 1
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So that's kind of what it's saying is.",
                    "label": 0
                },
                {
                    "sent": "At low measurement density, you don't want to solve the original map problem.",
                    "label": 0
                },
                {
                    "sent": "You want to solve a mucked up fuzzy smooth version of the map problem.",
                    "label": 0
                },
                {
                    "sent": "IE bad optimization is good generalization.",
                    "label": 0
                },
                {
                    "sent": "We can show that analytically in the simple scenario, but of course in deep learning we can't show anything but I.",
                    "label": 0
                }
            ]
        },
        "clip_106": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Just wanted to see what time is it.",
                    "label": 0
                },
                {
                    "sent": "We started about 5 minutes.",
                    "label": 0
                },
                {
                    "sent": "I'll end in two minutes and then you can ask questions if I end in two minutes I'll be on time so.",
                    "label": 0
                },
                {
                    "sent": "There have been some recent results in deep learning that yields surprising properties about generalization deep networks I think are very interesting now.",
                    "label": 0
                },
                {
                    "sent": "Why are they surprising?",
                    "label": 0
                },
                {
                    "sent": "Of course, anything is surprising if and only if it mismatches theorems that you already know, or intuitions that you already have.",
                    "label": 0
                },
                {
                    "sent": "So what are the theorems that we know about?",
                    "label": 0
                },
                {
                    "sent": "Controlling generalization error.",
                    "label": 0
                },
                {
                    "sent": "The basic idea is we know that the error on the training set will always be.",
                    "label": 0
                },
                {
                    "sent": "Less.",
                    "label": 0
                },
                {
                    "sent": "Sorry, the error on the generalization error will always be larger than the training error, right?",
                    "label": 0
                },
                {
                    "sent": "The only issue is by how much OK.",
                    "label": 0
                },
                {
                    "sent": "So there are various measures or upper bounds on the generalization error in terms of the training error plus some complexity measure.",
                    "label": 0
                },
                {
                    "sent": "One particular complexity measure is Rademacher complexity, which basically tells you how well can you memorize a data set with a bunch of random labels.",
                    "label": 1
                },
                {
                    "sent": "This Rademacher complexity is the correlation coefficient between after you train how well the output correlate with the random labels, so typically.",
                    "label": 0
                },
                {
                    "sent": "What happens?",
                    "label": 0
                },
                {
                    "sent": "Is.",
                    "label": 0
                },
                {
                    "sent": "If this is the the number of training examples with a small number of training examples, you can memorize anything so the Rademacher complexity will stay at one.",
                    "label": 0
                },
                {
                    "sent": "But as the amount of training data gets larger and larger, it will typically fall off like one over root N and so for example for linear decision boundaries.",
                    "label": 0
                },
                {
                    "sent": "This is the end at which it falls off.",
                    "label": 0
                },
                {
                    "sent": "Is the VC dimension.",
                    "label": 0
                },
                {
                    "sent": "For example, if you're familiar with the dimension, but basically what it's saying is if you're in nine seconds point OK if you.",
                    "label": 0
                },
                {
                    "sent": "If you're in this training regime was overkill, so if you're in this training regime where you can memorize the data, then you shouldn't be able to.",
                    "label": 0
                },
                {
                    "sent": "Well, this theorem provides no guarantees on generalization, right?",
                    "label": 0
                },
                {
                    "sent": "Because this is for a two way classification, so an error of 1 an error.",
                    "label": 0
                },
                {
                    "sent": "Probably if one is awful right there, if the Rademacher complexity is 1 then you're in big trouble.",
                    "label": 0
                },
                {
                    "sent": "Right, but only when you can no longer memorize can then generalization set in OK, so that's one measure of you know.",
                    "label": 0
                },
                {
                    "sent": "So you kind of this is like Occam's Razor.",
                    "label": 0
                },
                {
                    "sent": "You want to find the simplest model that explains your data.",
                    "label": 0
                },
                {
                    "sent": "There's another notion of controlling generalization error, which is the stability.",
                    "label": 0
                },
                {
                    "sent": "I won't go into this into detail, but the basic idea is, let's say you want to change one data point alittle bit right or change it to become a new data point.",
                    "label": 0
                },
                {
                    "sent": "And let's say you re learn with the just one data point changed.",
                    "label": 0
                },
                {
                    "sent": "If you're if the learned function that you get from your training procedure is very very different then it's not robust to changes in the data.",
                    "label": 1
                },
                {
                    "sent": "And if it's not robust to changes in the data you won't generalize.",
                    "label": 0
                },
                {
                    "sent": "So there are various quantitative measures of robustness and they also provide upper bounds on generalization error so within this.",
                    "label": 0
                }
            ]
        },
        "clip_107": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Lens we can understand we can start to appreciate four recent works that came out.",
                    "label": 0
                },
                {
                    "sent": "So here what they showed is.",
                    "label": 0
                },
                {
                    "sent": "That deep networks in the regimes in which we operate them few data points.",
                    "label": 1
                },
                {
                    "sent": "Many more parameters you can actually memorize random labels.",
                    "label": 1
                },
                {
                    "sent": "Yet for structured data you still generalize well.",
                    "label": 0
                },
                {
                    "sent": "OK, and so this recent work took a closer look at this and what's happening is these theorems are all about that.",
                    "label": 1
                }
            ]
        },
        "clip_108": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Training error of the best model in the training set, but in deep learning we're not good at optimizing, so even though we have lots of expressivity as I discussed, we can compute these chaotic functions.",
                    "label": 0
                },
                {
                    "sent": "Because we're bad at optimizing.",
                    "label": 0
                },
                {
                    "sent": "The space of accessible functions that we can get to may not be as large as we think it is given by our expressivity results.",
                    "label": 0
                },
                {
                    "sent": "So then our ability to generalize is all tide up not only with the space of functions, but with optimization.",
                    "label": 0
                },
                {
                    "sent": "So basically generalization is now intimately related to both expressivity and optimize ability in a weird way, and so these interesting.",
                    "label": 0
                }
            ]
        },
        "clip_109": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Experiments that look at that now also from the stability perspective right?",
                    "label": 0
                },
                {
                    "sent": "So what they find here is so if you train with small mini batches that adds noise to your gradient.",
                    "label": 0
                },
                {
                    "sent": "It turns out you generalize better.",
                    "label": 0
                },
                {
                    "sent": "But if you train with large mini batches, you might think that's better 'cause you get a better gradient, but you actually generalize worse.",
                    "label": 0
                },
                {
                    "sent": "So these guys came up with a picture of that.",
                    "label": 0
                },
                {
                    "sent": "Which is the following?",
                    "label": 0
                },
                {
                    "sent": "They found that if you train with large mini batches.",
                    "label": 0
                },
                {
                    "sent": "You can and so this is your error landscape.",
                    "label": 0
                },
                {
                    "sent": "If you train with large mini batches you tend to end up at sharp minima, but if you train with small mini batches you have alot of stochastic city.",
                    "label": 0
                },
                {
                    "sent": "The stochastic city might be so large that it doesn't allow you to find these sharp minima and you preferentially end up in shallow minima.",
                    "label": 0
                },
                {
                    "sent": "Now this is the training error.",
                    "label": 0
                },
                {
                    "sent": "What we really care about is the test error and the tester may not change that much here, but it may change a lot here right?",
                    "label": 0
                },
                {
                    "sent": "So this is again related to the notion of stability.",
                    "label": 0
                },
                {
                    "sent": "If you end up in a flat minima, what does that mean?",
                    "label": 0
                },
                {
                    "sent": "That means if you change your parameters, you don't change the loss, but from a dual perspective, if you don't change, that might also mean that if you change your data you don't change the loss and so you get stability and therefore you get generalization.",
                    "label": 0
                },
                {
                    "sent": "So anyway, these are all hand waving arguments, but this is kind of the research frontier right when you guys are tuning hyperparameters and you want to win the competition, it's all about generalization error, right?",
                    "label": 0
                },
                {
                    "sent": "And so you know, we have to start thinking about these things.",
                    "label": 0
                },
                {
                    "sent": "I don't think any of these works have sort of theoretically nailed what's going on, but there's lots of really intriguing simulations anyways, so let me end.",
                    "label": 0
                }
            ]
        },
        "clip_110": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sorry, oh crap, there was a whole other part about inspiration from your side.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                }
            ]
        },
        "clip_111": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I got about the third part.",
                    "label": 0
                },
                {
                    "sent": "OK Selavy, let me just just two things in 30 seconds, OK?",
                    "label": 1
                },
                {
                    "sent": "There's these cortical.",
                    "label": 0
                },
                {
                    "sent": "There's a lot of structure in our brain.",
                    "label": 0
                },
                {
                    "sent": "Blake actually kind of talked about it a bit, but there's this.",
                    "label": 0
                },
                {
                    "sent": "These Canonical cortical microcircuits that the primary mode of evolution has to be has been to increase the surface area of our cortex without like changing the elements too much.",
                    "label": 0
                },
                {
                    "sent": "These are these Canonical micro cortical circuits.",
                    "label": 1
                },
                {
                    "sent": "We don't actually have a good sense of what they're for, But an interesting direction to go would be for all the deep learning groups in the world to do Journal clubs on this thing.",
                    "label": 0
                },
                {
                    "sent": "And see if the topology and structure of these Canonical micro cortical circuits provide inspiration for architectures that would help in deep learning.",
                    "label": 0
                },
                {
                    "sent": "Very general like you can rewire the visual system of a ferret and have the I go to where the year would go to and then the ferret starts seeing with its ear or its cortical region that they used to process this year.",
                    "label": 0
                },
                {
                    "sent": "So it's a very adaptable system that can rewire.",
                    "label": 0
                },
                {
                    "sent": "OK, that's an interesting direction.",
                    "label": 0
                }
            ]
        },
        "clip_112": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I think these nested loop architectures are a very interesting direction to go where if you're doing motor control, what happens in the brain is you have these fast dumb loops that rapidly correct errors, but they can only correct sort of simple errors.",
                    "label": 1
                },
                {
                    "sent": "Then you have these slower, smarter loops that can correct more complicated errors, but they're slower and probably this kind of an architecture might make learning and generalization easy, and so we need to think about nested loop architectures.",
                    "label": 0
                },
                {
                    "sent": "And there's a bunch of work on that.",
                    "label": 0
                }
            ]
        },
        "clip_113": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The other thing that I think is is really missing is synaptic complexity.",
                    "label": 0
                },
                {
                    "sent": "OK, for us synapses are just WI JA scalar value, but actually there's a lot of complexity hiding inside synapses.",
                    "label": 0
                },
                {
                    "sent": "For example, this is a network of chemicals hiding inside every synapse in your hippocampus.",
                    "label": 1
                },
                {
                    "sent": "We've shown recently that we've proven no go theorems that you cannot avoid catastrophic forgetting if you don't have the synaptic complexity you need to treat synapses.",
                    "label": 0
                },
                {
                    "sent": "The dynamical systems in their own right, not a simple scalar values.",
                    "label": 0
                },
                {
                    "sent": "So this no go theorem was proven in this NIPS paper an well anyways and then.",
                    "label": 0
                }
            ]
        },
        "clip_114": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we've actually been able to use synaptic complexity recently.",
                    "label": 0
                }
            ]
        },
        "clip_115": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A paper that will appear DCML to avoid catastrophic forgetting, and we can do about as well as deep mind using a much simpler algorithm.",
                    "label": 0
                },
                {
                    "sent": "At least on this on these.",
                    "label": 0
                }
            ]
        },
        "clip_116": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just said so again, let me just end the summary.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_117": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For sure everything I talked about is in these references.",
                    "label": 0
                },
                {
                    "sent": "Alright, thanks.",
                    "label": 0
                }
            ]
        }
    }
}