{
    "id": "xspgfrsx2tyhknlgwtdskwm22nqm5uqr",
    "title": "Gentle Introduction to Signal Processing and Classi\ufb01cation for Single-Trial EEG Analysis",
    "info": {
        "author": [
            "Benjamin Blankertz, Machine Learning and Intelligent Data Analysis Group, TU Berlin"
        ],
        "published": "June 17, 2013",
        "recorded": "September 2012",
        "category": [
            "Top->Medicine->Neuroscience",
            "Top->Technology->Neurotechnology"
        ]
    },
    "url": "http://videolectures.net/bbci2012_blankertz_eeg_analysis/",
    "segmentation": [
        [
            "In this classification, these five trials."
        ],
        [
            "Be classified as non targets and these as targets, so we see that there are.",
            "These classifications on this site to non targets of the blue ones have been classified as target and two targets have been misclassified as non targets.",
            "And in fact, this.",
            "Such a feature?",
            "It's called univariate features.",
            "This means that you only have one value, so this is just.",
            "Fun.",
            "Scarlet valued variable, so this is what you release investigated in in your Physiology and the big step here in data analysis for Bcis to go to towards multivariate.",
            "Features and classification and.",
            "Preview.",
            "Go to now, but first.",
            "I would like to show you one measure of discriminability.",
            "So in here it is important in order to estimate the performance to have a measure of how well these two distributions point the distribution of the various fork.",
            "Target trials and phonon transfer.",
            "How well these are separated so one can calculate an error rate but.",
            "Yeah, baby.",
            "Take another measure that is.",
            "Independent classification or itself.",
            "So this is called the receiver operator characteristic.",
            "And you get this graph as follows.",
            "So here I have again the 10 points as we have before.",
            "These are the amplitudes of these epox.",
            "It's."
        ],
        [
            "Peak latency and this was a threshold that we had, so these are classified as targets as orange and these are classified as blue.",
            "In this graph.",
            "For this.",
            "Classification for this threshold we make a point where on the X axis we.",
            "Marks are missed orange detection and on the Y axis the true of the hits of the blue detection services threshold.",
            "We missed.",
            "22 orange, so the orange should all be above the threshold, but these two are below so we missed these two and two out of five is ratio of .4.",
            "So we are here on the X axis and for the blue.",
            "True.",
            "True blue detections.",
            "Blue should be below the threshold.",
            "We have three out of five, so this is .6, so we."
        ],
        [
            "At this point in the graph, and then we shift.",
            "There's a hypothetical threshold one below so.",
            "Yeah, nothing changed on the Y axis.",
            "You still have three true detections through detection of blue, but now we have.",
            "We missed only one orange, so now the ratio is only .2, so we get another point here."
        ],
        [
            "And for yet another threshold, now you will decrease the true blue detection or this blue above the threshold is classified as orange.",
            "So here we go down one step."
        ],
        [
            "And this you do for all different thresholds, and then you get this.",
            "Our C receiver operator curve."
        ],
        [
            "And.",
            "A measure for for the discriminant ability is the area under this curve.",
            "So with this gratings it's a 25 squares, and 18 of them are below the.",
            "Curve so this would be a area under the curve of 18 / 25.",
            "And this is a measure of how well these are separate."
        ],
        [
            "Separate so if I do this for all trials of this example of this oddball example, you would get this smoother curve, and then the accuracy is 0.7.",
            "So for the.",
            "People that have have a more background in data analysis, here's a remark that this area under the curve.",
            "Is equal to the probability that a random point from the orange distribution is ranked higher, has a higher value than randomly picked blue point."
        ],
        [
            "And if we would do this kind of curve for random variable, so here it's just randomly orange and blue dots.",
            "Then you would get here step like curve that's approximately the diagonal.",
            "So then you get the area under the curve."
        ],
        [
            "It's .5.",
            "And if it's perfectly separated, then you go up here and you raise the threshold, you just increase it through blue detections and you don't miss any orange, and only if you are here at one for the two detection, then you go this way.",
            "Since the area is 1.",
            "4 perfect separated.",
            "And distributions, if it would be the other way around, then you would work like this and then the area under the curve would be 0.",
            "So this is a kind of performance measure.",
            "It's .5 if there's no information in the variable that we look at, and it's zero or one for perfect separation."
        ],
        [
            "So now we do the important step as I announced and we go from this univariate feature where we only look at at one value, one valued variable to multivariate features.",
            "So on on one.",
            "So before we looked only at one channel at one time point.",
            "But of course we could also look at the earpiece signal for multiple time points.",
            "In one channel, or we could.",
            "Look at one time point and multiple channels.",
            "Or we can do both and use multiple channels and multiple time points, so this would be called temporal features is what we called spatial features and the combination spatial temporal features."
        ],
        [
            "So here, for our speller experiment from before, we would now have.",
            "Multiple channels and get many continuous time signals from which we cut out the epoch.",
            "Now epoch contains signals from many channels.",
            "So why is this very useful for classification?",
            "So here I've shown you signals from epithetical sources in the."
        ],
        [
            "Brain so say we have one cognitive source that makes this positive peak after the.",
            "Um?",
            "Target stimuli, so this is what we classify on.",
            "This is first peak time point.",
            "And then there's a interfering source it has has nothing to do in this case with the task.",
            "This is visual algorithm, so this is from the visual area and there's a 10 Hertz rhythm.",
            "Or if we would have access to this true source in the brain, and this would be very nice and we can classify."
        ],
        [
            "Is this correctly?",
            "But what we measure in EG is a superposition of the signals from all the sources.",
            "So what we would measure at the Z, which is a. Electrode centralny and.",
            "Raffi, above this source.",
            "You would not only measure this signal on this cognitive source, but we would also measure overlay from the visual idle reason.",
            "So here I just deliberately took factor point half for this and also the cognitive source goes with factor point.",
            ".5 or 1/2 enthusiest channel offset which is over the visual area."
        ],
        [
            "And now we realize that here it is at this time point that we define this feature to classify targets and non targets.",
            "This is now in a in a Valley and another negative peak of this visual idealism, and therefore it is below our threshold.",
            "So here we would not realize that this is from the target people."
        ],
        [
            "But one one can fix this problem if one has a appropriate spatial filter.",
            "So here's a can calculate the spatial filter that reconstructs the signal here from the source.",
            "So it's like this, and then I get the source again, and then I can classify.",
            "But I can do this only because I have a multivariate signal.",
            "I have signal from 2 channels and I join them in an appropriate way, so this is called a spatial filter.",
            "So here very simple spatial filter.",
            "It's two weights because I only have two channels and then I get back the true signal and then I can classify correct?"
        ],
        [
            "And similarly it it works for temporal features, so temporal features can help.",
            "If you don't look only at one time point, but at several we take the same example.",
            "So here again, there's a misclassification due to the overlay from from the visual idle rhythm, but now."
        ],
        [
            "If you do our classification based on several time points, say these four around the peak and we would use a very simple temporal filter and say we just average.",
            "Then from these four measurement points, we would calculate the average and then again in this classifier above, so special.",
            "So also this is temporal filter we would have.",
            "Saved classification.",
            "And or a different example, when we have some Sunday."
        ],
        [
            "The drift, so this also happens often in e.g.",
            "Measurements if you don't have a high pass filter at least and then you get this kind of drift so you would not measure.",
            "Here's a.",
            "The true signal from the source, but here's a purple signal.",
            "And then again here, the our feature is below the threshold, so it would be."
        ],
        [
            "Misclassified and if one would have a special filter, for example with features from before at the peak and after the peak.",
            "Then one.",
            "Maybe with the classifier would have waiting like this.",
            "Before and after a weighted with minus .5 and at the peak with weight 1.",
            "And if you calculate the value with this temporal filter, that means multiplying the measured signal with these weights.",
            "Then you would get the same result, almost the same result from the grace or original source signal an from the one with the drift.",
            "So then would have.",
            "A different classifier, different threshold.",
            "But then you would see that you would have classified this correctly.",
            "So this is motivation why it helps to go from this univariate feature to multivariate features."
        ],
        [
            "It will be before we go under in need to type a little bit into the EG signals so this is from some visual speller.",
            "Experiment the data.",
            "So this is one of the way how to to display the results.",
            "So as before this, each of these plots shows the epoch set are averaged across our target E. Pox or epoch setter cut out with respect to the target stimulus and INGREZZA one for non targets.",
            "This is done now for for many channels because we want to go for multivariate signals.",
            "This is done for many channels and here they are arranged as on this car.",
            "Approximately when you look from.",
            "Top onto the Skype noses up here.",
            "And we are interested in the difference between the target and some non target epoch.",
            "So this is an area that is shaded here in purple."
        ],
        [
            "So before I show another representation, so 11 remark.",
            "So usually you look at time serious like this.",
            "It's a signals itself, but often it's also helpful to look at A at such a matrix representation or color representation.",
            "So this is exactly the same same signals, but now it's not shown as a curve, but each value is translated according to this color bar into one color and then.",
            "You see the Colosseum."
        ],
        [
            "And another thing thing, if we have these data matrices for each of these epochs, we have target nontarget epox with a blue frame and some target epoch's with the orange frame.",
            "Then we can calculate exactly this AR AUC value area under the curve that I introduced above for each.",
            "A point in this matrix that means for a fixed time point and the fixed channel we calculate now across the trials the AOC.",
            "So in this in this matrix each point here is 1 univariate feature.",
            "Each time point corresponds to 1 channel.",
            "Here on the Y axis anta one time point.",
            "So each point here.",
            "Exactly the Union weight feature univariate feature that we discussed before.",
            "So if we go across the trials, we can calculate this AUC curve.",
            "And we get one AUC value and then we can put all these values.",
            "If you did this for all channels or time phones in this matrix.",
            "So here you see the color bars or why it is 0.5.",
            "This means that feature is no information for the discrimination target non target.",
            "And the Blues are small, various.",
            "This means the target is below, so non targets the distribution is shifted below and red means it's above."
        ],
        [
            "So now we can use this in in these ERP plots and now this is just another way of arranging the channels or not.",
            "It's in a in a grid plot what we had before on the on the head.",
            "And again, this has a frontal channels, these other on the back of the head.",
            "These are the channels on the left hemisphere.",
            "These are the ones on the right hemisphere.",
            "The same curves and now I added just for each Channel 1 bar and thesis.",
            "One you excuse me?",
            "Exactly one row from this matrix, so this is."
        ],
        [
            "For one channel, the AUC values for each time point."
        ],
        [
            "So here you have four channels.",
            "These at the AOC for each time point.",
            "So then you not only see here how well that means are separated.",
            "This you see from the curves, but also which is 4 in view of classification more important.",
            "So how well as it 2 distributions separated?",
            "So it could be, for example, that this difference in mean is only due to some few trials with blinking artifacts or so.",
            "Then you could also get a big difference in the means, but maybe the distribution is not separated very well, so then you could see these in the.",
            "This color bars.",
            "And then you directly get quite good overview.",
            "You see that here some positive component components.",
            "It's more positive for targets which is concentrated or focused more on the central area.",
            "And here is a dark Blues as a negative component.",
            "On the back of set."
        ],
        [
            "So in order to get this overview of other spatial distribution even in a better way, one should look at those typographies so, but let's start here at the top.",
            "So this is mainly the same thing as we have seen before this.",
            "PC's ERP curves for channel sees at this as a thick lines and our edit P or 7 which is here.",
            "It's a back on the left side of the back of the head.",
            "These are the two thin lines.",
            "And then here you see shaded for different intervals and in order to get for example this topography.",
            "The values within these intervals averaged across this time interval, and then you get one value for each channel.",
            "And this defines a color for each channel according to this color bar.",
            "And then this is interpolated to give a surface plot.",
            "And T on top.",
            "This is done for the target earpiece and on the bottom for nontarget earpiece.",
            "So yes, very nicely with where you see the different components that discriminate.",
            "So there's an early negative component with the focus here.",
            "Occipital, left, lateralized, and the positive.",
            "This is central."
        ],
        [
            "Again, that plot before we are just these averages so they could be not so informative for classification.",
            "The difference in the averages or you can also look at topography's of these A or C various.",
            "This is just the same concept you will, you say, receive areas as well time series.",
            "So now you don't have two classes because this is more or less a different target minus minus non target.",
            "So we only have one time series here shown 14 ZZ and one for PO7.",
            "Again, here we have C for intervals and if you average within these time intervals you get one value for each electrode and you can interpolate this to get this topography.",
            "So in this case it was very clean data, so here's a different looks.",
            "Very much like the targets here, so non targets are almost zero everywhere and these were clean data so it looks the same but with other data it could be.",
            "But it looks also."
        ],
        [
            "Quite different.",
            "So from the plot before."
        ],
        [
            "So I go back so this only shows now the topography's for this.",
            "Few time intervals until time time calls only for two channels, so it could be that we that we miss something that says maybe here in this time interval.",
            "Also something interesting going on, but in other channels so we wouldn't see this here because this time is not shown as topography and here only these two channels.",
            "So therefore if you don't know what to expect you should always look at this full matrix of AOC values.",
            "And then."
        ],
        [
            "You have an overview of everywhere that.",
            "An interesting difference could be.",
            "And then based on this matrix, you can select those intervals of interest.",
            "And here's these intervals are shown as this apostrophe, so this is like the step before.",
            "So this maybe you wouldn't plot in your in your paper, but in order to if you investigate first time the data you maybe look should look better.",
            "This matrix then pick up the intervals and then make pictures like you've seen before."
        ],
        [
            "So now in this matrix, as I said before each, each cell is a univariate feature, as we've seen before, and now we want to combine them to multivariate features.",
            "So we have one single trial, so now I explain."
        ],
        [
            "What kind of features we expect, so we have one single trial.",
            "We show this as a."
        ],
        [
            "The matrix as before, and now these are the three different kind of features that I introduced in the overview before.",
            "Let's first look here.",
            "So if we select from this matrix only one channel, this is a purely temporal feature.",
            "We don't have any spatial information, just where it is but not distribution in space.",
            "So this feature would be or feature vector you would say in data analysis.",
            "This corresponds to the time course at one channel.",
            "If you take one column of this matrix.",
            "You would get a purely spatial feature.",
            "You have no information about the time course, but distribution.",
            "Or you do both.",
            "You take some channels and some time points or time intervals and you get a matrix.",
            "So of course is this matrix itself is also spatial.",
            "Temporal feature just might be too high dimensional to really work with, so therefore of the month.",
            "Subsamples at least a little bit in the time domain."
        ],
        [
            "So now before when we only have univariate features and it's quite clear how to classify, you just have the choice to use your to choose this threshold somewhere.",
            "Now if you go to multivariate feature, you have a multi dimensional distribution so it gets more complicated.",
            "So here we make this step first to two dimensions.",
            "And in order to get a overview of the distribution, one can look at scatter plots and here I explain how you get to this scatter plots.",
            "It would I take.",
            "Channel Ozette and early time Point, where this is negative peak latency and another channel sees it and timepoint abit later.",
            "But this was a positive peak latency.",
            "And now I turn this channel, I rotate it."
        ],
        [
            "60 degrees.",
            "And then.",
            "So here is the mean.",
            "I get one value here from this representation and I would put this on the Y axis of this plot that will become the scatter plot and I take the amplitude here.",
            "These at and take this as a X axis of this plot."
        ],
        [
            "Then I if I have so this work for the averages across.",
            "If I do this for the single trial, so I get.",
            "From one single trial I get one time point here or one one point here in the set.",
            "And here I get this from the same single trial I get a value here, and by this I get these five points in this."
        ],
        [
            "Get a plot.",
            "And then I do this for all the single trials that I have.",
            "And these are often these two, indicated by by ellipsoids, which correspond to Gaussian distributions, but we will come to that a bit later.",
            "So, but here we have this distribution of all these single trials, which are somehow scattered around this this mean?"
        ],
        [
            "And then we have the other distribution for the nontarget trials we have and have another mean.",
            "Of course we have seen before.",
            "It's a means are different, so we get the cross at another position.",
            "And the distribution of those.",
            "The two distributions targets and non target features in.",
            "At 2 dimensions.",
            "And yeah, usually you would."
        ],
        [
            "Plot it, not with a rotation like I did.",
            "You have target tries nontarget trials in two different channels.",
            "You get these two features and then you make this scatterplot.",
            "So now our.",
            "Next task would be to find out how to best classify between the orange and blue."
        ],
        [
            "Distribution here.",
            "So, um.",
            "Man."
        ],
        [
            "So as I said, this is I have indicated here is a distribution around this as mean as caution."
        ],
        [
            "Distribution so with this scatter plot in order to.",
            "Took to make more meaning of this scatter plot and.",
            "We can look at a very simple model of these event related potentials, so there's an idea that what we measure.",
            "So this is what we measure.",
            "In one trial is a superposition of 1 signal, which is a pure ERP that we also get when we average across many trials plus some noise.",
            "Because there are many.",
            "Things ongoing in the brain that are not related to the.",
            "To the task so this.",
            "Component this is a time series P1.",
            "That is.",
            "The brain activity related to the.",
            "I'm processing of the target and this is unrelated activity.",
            "So now we would according to whether the stimulus was a target stimulus or non target.",
            "We would have two different time series, so this is a ERP for the target and this is the ERP for the non target and in each single trial index by K. Here this is overlaid by some noise.",
            "So this is some random variable which produces noise.",
            "So in this.",
            "And this is a Gaussian distribution with mean zero.",
            "So in this scatter plot that I introduce before the mean of the distribution, this corresponds to the to the ERP to this one.",
            "So there's a blue one corresponds to condition one.",
            "This version non targets before and Orange the ERP of condition.",
            "2.",
            "So remember this word.",
            "Just the average value.",
            "So that's exactly what you would also call ERP.",
            "And.",
            "The.",
            "The noise here.",
            "This is what makes the scatter around the mean, so the.",
            "What is indicated here by the ellipsoid is a trial to trial variation that is not related to the stimulus.",
            "So this is just the noise that is not related to the processing of some of the target.",
            "So now I'll go back to the point.",
            "I became surprised.",
            "And.",
            "He"
        ],
        [
            "Um?",
            "I show that I investigated that if we have high dimensional ERP features, that would be what we get is a distribution really looks like like a Gaussian distribution set.",
            "It is satisfied to to make this nice plots with the ellipsoids.",
            "So here I projected two components in this high dimensional space, there's a.",
            "Highest variance was found, and if I look at these projections, this look or.",
            "Scatters has his ellipsoidal shape.",
            "This all looks like.",
            "What was one cause Gaussian distribution?",
            "But now he."
        ],
        [
            "In order to.",
            "To find out what these distributions would look like, so again, this is first univariate Gaussian distribution.",
            "So then I have something like this.",
            "This is what you would find if you.",
            "Look at the distribution of the amplitude at one where you would get such a distribution is a mean, and this is.",
            "As a standard deviation.",
            "And maybe for another component this is a bit more Peaky.",
            "But now."
        ],
        [
            "If we go to a 2 dimensional.",
            "Distribution there are several possibilities, so it could be that these two components are univariate uncorrelated.",
            "Then we would get a joint distribution which looks like this.",
            "So there's no connection between the variable on the horizontal axis and on the vertical axis.",
            "Or they could be correlated.",
            "So in this case, if I measure a high value from one variable, I would also get a high value from the other variable.",
            "So this is correlated, but you cannot see this if you only look at the variables in one dimension, you don't see the difference.",
            "So the if you project it to this.",
            "If you only look at this variable, it looks in both cases the same.",
            "And if you only look at the variables it's on the Y axis.",
            "It looks also the same.",
            "So we really need to look into the high dimensional data to find out what it looks like and for."
        ],
        [
            "For EG, it's very known that the signals are very much correlated, so this is from famous simulation of newness.",
            "No, this is my own simulation from data, so here took just any.",
            "Some EG data set and I calculated from each channel the correlation coefficient to the channels is set.",
            "In the middle and you see even from channels that are quite far apart from the Middle Channel, we get correlations of over .9.",
            "So the signals are very highly correlated, so."
        ],
        [
            "Going back to this picture, we are more.",
            "In such a distribution.",
            "So."
        ],
        [
            "That means we need to think more about these Gaussian distributions, so this is a 2 dimensional Gaussian distribution.",
            "So we have two variables here and this would be.",
            "These are the density.",
            "How much points you would get from one area here, so usually would.",
            "Plus this is a surface and this is a formula of the Gaussian distribution, but.",
            "For a representation, it's nicer to have her 2 dimensional representation and then for indication you only take one of these contour lines, which are all ellipsoids, and then you would plot.",
            "And.",
            "This distribution.",
            "Taxes.",
            "It's all in the three dimensional thing this."
        ],
        [
            "This mountain would not come out of the of the wall like this and this is one of their control lines.",
            "And in order to to find out from from given data.",
            "How this ellipsoid looks like?",
            "One has to do a."
        ],
        [
            "I can value decomposition.",
            "And so this is a mathematical part, but I will explain this also.",
            "And.",
            "In the representation, so mathematically, given the matrix C that is quadratic and symmetric and positive definite.",
            "So this matrix season you can find another representation as a product of these four matrices where.",
            "We is a also normal matrix and these are diagonal matrix, so this C. Can be represented at such and.",
            "This covariance matrices that were denoted by Sigma.",
            "Before that we find in this multi dimensional multivariate Gaussian distributions, these are exactly fulfilled.",
            "This properties they are symmetric and positive definite.",
            "All covariance matrices are like this, so any covariance matrix that we estimate from the data.",
            "We can make this representation and this is very easy calculation and."
        ],
        [
            "Um?",
            "The nice thing if we have this representation then we can see how we plot this ellipsoid, namely this in this matrix V. This is a matrix and I have P column vectors in it.",
            "And because it's also normal, each vector has length one, and they're all orthogonal.",
            "To each other, and these are the the principal axis of this distribution of this ellipsoid.",
            "So here are funds, so it's only two dimensions.",
            "So if we one and 3, two and so organized and this.",
            "Tell me what are the axes of the ellipsoid that I have to draw if I want to visualize this distribution?",
            "And then I have this diagonal matrix D and this elements on the diagonal.",
            "These are called the eigenvalues.",
            "And this, say, tell me what is the standard deviation along this direction for this?",
            "D1 is a standard deviation of all my data points in this direction, and the D2, the standard deviation along the direction of V2.",
            "Not exactly so I have to.",
            "Takes a square root of set so the square root of these eigenvalue is equal to the standard deviation.",
            "So value itself is a variance.",
            "So that means if you want.",
            "To draw such a picture from from your Gaussian distribution you have to calculate the covariance matrix.",
            "This is a very simple formula and then you make this eigenvalue decomposition.",
            "You get the eigenvectors and you know the direction and from the eigenvalues you know the length of the axis, so you.",
            "If you make this.",
            "Contour ellipsoids, then the length of these axis has to coincide with the standard deviation.",
            "That means the square root from the eigenvalues."
        ],
        [
            "So now with this background we can talk about classification so that we.",
            "Start very very simple.",
            "So let's assume we want to classify these two classes, the blue and the orange.",
            "No 2 dimensional and we only know the means, so we know only knew one that knew too.",
            "If you don't have any more information and there's not so much we can do.",
            "If we should tell what these X is, what belong, does it belong to class one or Class 2?",
            "The only choice is that we measure."
        ],
        [
            "Distance to the means and say it's this one's plus two because it's.",
            "Um?",
            "The distance is less than."
        ],
        [
            "Us too.",
            "So this this rule would lead to this kind of separation of the plane.",
            "This one would be.",
            "Classify this orange on this side and the other blue.",
            "So this separation line is perpendicular to the line that connects the two means and crosses this in the in the middle."
        ],
        [
            "And.",
            "And in the mathematical formulation one formalizes by means of a of a normal vector.",
            "This is a vector W and normal means that it's perpendicular to the to the separating line.",
            "And here for the visualization, I normalize it also so this is length one.",
            "And then.",
            "This part is written here.",
            "W transpose times X is a scalar product.",
            "This means these are both vectors W&X and this means I multiplies a corresponding elements and I sum them up and geometrically this.",
            "This means, for example, if I put this color product between W&X.",
            "This corresponds to the length.",
            "Here when I Project X perpendicular on this vector W. So at this point, XI projected onto W and then I measure the distance to the origin.",
            "So this.",
            "Lengthy of this projected X on W this is.",
            "W transpose times X.",
            "And now if we want to formalize this, one has to look at this quantity W transpose times X -- B.",
            "Cause this W transpose times X is.",
            "This distance and B is a distance along this.",
            "Vector W2 The separation line and then we have to look whether this point X visits on that side.",
            "So if this is.",
            "If this is positive or if it's on this side, it's negative.",
            "So this is a.",
            "Mathematical formalism, but so if you are not familiar with this kind of algebra, it doesn't matter.",
            "So this was just a side remark, so it's.",
            "Important that you understand the concept.",
            "So if you only know the means then we can only.",
            "To this uninformed classification, but as I pointed out before these distributions here.",
            "Error code."
        ],
        [
            "So there's the signals are correlated, so we get Gaussian distributions that have these ellipsoids tilted ellipsoid's like this.",
            "In all, in this case, if we are asked what to what class, does X belong?",
            "I assume that anyone would would answer blue because it clearly lies into this blue dots.",
            "I hope you see them also in the black in the back and not in the orange.",
            "So here we are."
        ],
        [
            "Now a different situation.",
            "Now we know not only the means, but we also know this scatter.",
            "You know more about the distribution, so here are indicated this essay.",
            "Ellipsoids, again, is cautions, and then if you see this plot then it would be clear that X belongs to the blue class.",
            "And.",
            "In fact, this is a classification that one gets from from linear discriminant analysis when estimates is distribution as from the covariance matrix, and then we get these other separation.",
            "This is normal vector that's S before Mewtwo minus mu one, but now multiply it with the inverse of this covariance matrix.",
            "And."
        ],
        [
            "So I don't.",
            "That's the time to explain this today, but this inverse of the covariance matrix.",
            "This is something that makes a whitening.",
            "This means we.",
            "Transform this space into a space where there is a variance.",
            "Now of this, each distribution is 1 in every direction.",
            "So the variance of the blue distribution is 1 in every direction, so therefore these are now circles.",
            "This distribution variance is the same in.",
            "In any direction and then in this white in space we can now do our our original simple classification.",
            "I didn't give it a name, so this one is called nearest centroid classifier.",
            "So your classifier according to the."
        ],
        [
            "Century tickets"
        ],
        [
            "What's news?",
            "And if one has white in this data, then one can use his nearest century classifier, because then this distribution of the noises in an informative it's not informative anymore.",
            "If it's white and.",
            "And so this now corresponds to the nearest neighbor classifications of light in space and.",
            "To do LDA in the original space.",
            "But UF soul don't do do nearest neighbor classification."
        ],
        [
            "This out quietly.",
            "So to give some some background for this linear discriminant analysis.",
            "One should consider the following assumptions.",
            "Following three, the first assumption of LDA is features of each class are Gaussian distributed?",
            "Then the second is these Gaussian distributions of all classes have the same covariance matrix and the search.",
            "Is that it?",
            "True class distributions are known so that we know the mean answer covariance matrix.",
            "So I call this assumptions because one can then show a.",
            "In probability theory, if these assumptions are met, then one can show that.",
            "Um?",
            "OK, this is missing what one can say, so then one can say that this LDA that is defined like this.",
            "This is the normal vector is optimal.",
            "So then one can show this is a best classification you can do on average.",
            "Causes assumption are never fully met and you can apply it if this assumptions are not fulfilled.",
            "But these theorems gives the orientation of when LDA is supposed to work very well.",
            "If these are men.",
            "So therefore we should discuss these assumptions."
        ],
        [
            "1st.",
            "Is that the?",
            "A Gaussian distributed Gaussian distributions are characterized by mean and covariance matrix.",
            "So if on, for the example I take a spatial feature because it is nice to visualize.",
            "So if we have a spatial feature, then the mean for the targets and non targets I can visualize and this is.",
            "Just these two Skype Maps, so we have two different means that is important.",
            "But the assumption before, was it the covariance is the same.",
            "The covariance is high dimensional matrix, so it's difficult to visualize, but I've shown you this eigenvalue decomposition before.",
            "So one way to look at this is to look at the eigenvalue spectrum.",
            "So these are the eigenvalues sorted.",
            "So if you remember the eigenvalues as a variance along this direction of the ellipsoid.",
            "And then you see there are some directions is very high variance and as a low.",
            "And if you compare this, at least these eigenvalues look very different, very much the same in these two classes.",
            "And so now in my.",
            "My so this as I said before, this reordering went wrong, so now there should be this.",
            "Scott said.",
            "Irritate"
        ],
        [
            "Me before, so now I look at the projection onto these.",
            "Components of the highest variance, and then I see these.",
            "These plots and I can only.",
            "Say no, that this look very much like oceans.",
            "So this was he.",
            "Assumption."
        ],
        [
            "Feature of each class adult Gaussian distributed so this by eyeballing this looks net quite well.",
            "The second one is that they have the same code."
        ],
        [
            "Parents matrix so therefore.",
            "We see that it has the same eigenvalue spectrum is in this."
        ],
        [
            "One data set, so I only look at one data set and now I can also look at the eigenvectors so the covariance matrix is characterized by this eigen values and so eigenvectors.",
            "And each eigenvector I can again visualize as a Skype topography.",
            "So this is in the feature space, so I can visualize this as a Skype topography and these are the topography is corresponding to the eigenvectors with three highest eigenvalues.",
            "So these are the directions in this.",
            "Feature space where we find my SMS variants or this should be the most critical ones.",
            "And these are I plot for the target distribution and the non target.",
            "And here you see they correspond quite well, at least for these.",
            "So empirically.",
            "These two assumptions seem to be met, so maybe you can assume that if I make these plots, it's always that it looks."
        ],
        [
            "Very much the same, but here this is an example from completely different datasets and here show you that here.",
            "This assumption that the two covariance matrices are equal is not met at all.",
            "This is a data set from handwritten digit recognition.",
            "This our future zeros hit Route 7.",
            "This is if I average overall health written digital digits, so you'll see very nicely this is zero.",
            "This is A7.",
            "And here I can also visualize these eigenvectors that correspond to most variants.",
            "These are again pictures that I can visualize and now here you see, if this assumption is not met or these pictures look very different like these.",
            "So here for example.",
            "This variation comes from that some till the 7 little bit more a little bit less and this gives a completely different variation than if I tilt to zero in another way.",
            "So here's the noise.",
            "In the data surveyed, variation in the data really depends on the class itself.",
            "But in the in the earpiece, the class only defines the mean and there's the noise is a ongoing noise.",
            "It has nothing to do with the task with target or non target.",
            "So therefore it's.",
            "It's quite a good assumption to say the covariance matrix in Reg data is equal.",
            "And therefore this LDA, which is a comparably simple classifier because it's a linear classifier, is supposed to work.",
            "Um, quite good."
        ],
        [
            "OK, then now that we have the background folk for classification.",
            "I need to tell.",
            "Maybe at least one one remark about validation.",
            "Who if we validated classifiers on our set LDA is good, but if we validate it and one has two.",
            "Expect certain certain things and so to validate a classifier, you need to have a training set and validation set in the first take.",
            "Some data is a training set and then you can train your classifier on estimate is covariance matrix and the means, and then you get this W for the classifier.",
            "Or if you start from the G data, maybe you you select some features, you select channels you select time intervals.",
            "This you do on the training set and then you need to have another set which is disjoint and independent and this is your validation set and on this set you do the same processing steps.",
            "You extract the same features that you found informative on the training set you apply the classifier and then you estimate the performance.",
            "So if these sets are not independent and your.",
            "Estimated performance will not met reality meet reality.",
            "So this is a.",
            "Delicate topic and one paper is given here that gives quite some details on."
        ],
        [
            "Oh, you should do the validation.",
            "And one specific thing that you should keep in mind if you do a validation for this oddball type of experiments isn't following.",
            "There we have the situation that one class has much more samples than the other class.",
            "Because you have much more non targets and targets.",
            "And then you should calculate at least a weighted error for the following reason.",
            "So here in this example we have 900 samples from class one and 100 from Class 2.",
            "And.",
            "If one makes a classification like this, then the unweighted errors 26% and so weighted is 22.",
            "But if I would make a classification like this so the orange is a big class.",
            "So this means I label almost everything is orange.",
            "Then the unweighted errors only .9 or if I would classify everything as orange, then the error would be exactly 10% because there are only 10% in the smaller class.",
            "So if you would get this result then you would maybe be surprised and say OK, my classifier works very well, only 10% of error.",
            "Although it's it's a nonsense classification.",
            "So therefore.",
            "You should calculate a weighted airline.",
            "You calculate the error on all samples of plus one and on our samples of +2, and then you take their say average.",
            "If you do that, then here in the.",
            "In the reasonable classification, you get the same result, but if you make classification like this and related error in this case behind.",
            "Or you can use this A or C. Measure that I introduced before and map it to to the range between 0 and 100 and this would be then a performance measure that's independent of this bias.",
            "Of how you exactly shift your hyperplane.",
            "So therefore this measures the same everywhere."
        ],
        [
            "So now as I said, we go to two classification.",
            "So first we had this this temporal features, so these features have only one time series from one channel, so we cannot expect that this classification is.",
            "It's very good, but still this classification can be.",
            "Can provide some interesting information if we if we have many channels and we can separately do for each channel.",
            "Such a classification on each channel separately, I do a classification on these temporal features.",
            "And I do the validation correctly and then I get to get the error rate for each channel.",
            "Then I can map this on the on this card.",
            "So this then gives such a nice representation an shows where discriminative information comes from.",
            "So in this case we see two folky one is here, left occipitale and maybe you remember there was his early negative components that was discriminative.",
            "And here's a another central Fitnesses positive peak.",
            "So this gives some."
        ],
        [
            "Weather discriminative information spatially comes from and when we look at the spatial features we can do with the other way around, we can.",
            "Take from from each time point we takes a special feature and then make a classification of these special features.",
            "We get a error rate or accuracy and for each time point.",
            "So now we know in time, whereas the discriminative information distributed.",
            "And also if one for example we take this this time point where the best discrimination is achieved so.",
            "Classification this is mainly characterized by this weight vector W. And this can also be visualized as a Skype map.",
            "So then you can try to find out."
        ],
        [
            "Your classifier does.",
            "But this is very hard to make an interpretation of it, and that's it.",
            "I will tell you later."
        ],
        [
            "So now here is.",
            "This is a little bit different paradigm, some some speller where we have more discriminative components.",
            "Yeah, there's classification performed on.",
            "Seven different intervals, and this is the error rate.",
            "That were achieved and now we turn to to the spatial temporal feature.",
            "So we combine spatial feature and temporal features.",
            "And classify on all the same.",
            "So we increase the information.",
            "So then we should expect.",
            "Um?"
        ],
        [
            "To get a better look."
        ],
        [
            "Suffication, but if we do this.",
            "Then for this spatial temporal feature we get 25% error, but in one before if we go back.",
            "On on the best."
        ],
        [
            "Best.",
            "Interval here there are."
        ],
        [
            "It's only 14%.",
            "So what what happened here?",
            "We add information, but nevertheless a classification gets.",
            "Get."
        ],
        [
            "It's worth.",
            "And the problem here is that if we go to high dimensional features or now the dimensionality is much higher, then we get a problem in estimating the data as a distribution was a Gaussian distribution, we need to estimate the mean of the distribution and this covariance matrix.",
            "The scatter and.",
            "This covariance matrix has many many parameters, and if we have 100 dimensional features, we need to estimate 5000 variables in the covariance matrix and."
        ],
        [
            "So you have errors here and there and then you get a miss estimated.",
            "Covariance matrix and therefore the classification with LDA, which crucially depends on that we have a estimate for the covariance matrix.",
            "This goes then really bad.",
            "But the good thing here, although we have a problem that there's a bias misestimation, is that there's a systematic bias, namely the large eigenvalues of this estimated covariance matrix are too large, and small eigenvalues are too small.",
            "And if you.",
            "Remember what large and small eigenvalues mean?"
        ],
        [
            "Trying various is the variance along the direction with high variance and so that small eigenvalues is a variance in the direction of small variants.",
            "So if this green green is the true covariance and we make the misestimation as indicated on the slide before we would estimate like sushi on blue covariance matrix in the direction of large variance.",
            "We overestimate the variance too large and in direction of the.",
            "Smaller variance, we underestimate the variance.",
            "This is so this is just a cartoon because in two dimensions we could could estimate the distribution very well with this many data, but this year is an estimation.",
            "Wears a black shows the eigenvalue spectrum of the true covariance matrix.",
            "So this is 200 dimensions and these are estimation from restricted data.",
            "This is red with 500 data points and purple only with 50 data points.",
            "And tears is eigenvalue spectrum is a magnitude of psych and various so we see here is a high eigenvalues overestimated and solo underestimated.",
            "So this."
        ],
        [
            "Shows that this kind of bias exists in real data, and then the the idea of fixing this misestimation is first place.",
            "Simple.",
            "So if we have the blue one.",
            "Well, we know that there is this misestimation.",
            "Then we could make a linear interpolation to a sphere which is shown in black.",
            "The orange for example is.",
            "This is a morphing in between the blue and and the black.",
            "Now it makes it variance along the.",
            "Long direction, smaller and the other way we make it larger.",
            "So then we could hope that if we.",
            "Meet the real covariance matrix."
        ],
        [
            "So then when when one can do some math and see that this exactly counteracts balance, so the direction of this?",
            "I can vector stays the same and I just linearly interpolate between the estimated eigenvalue and the average eigenvalues.",
            "So I make exactly this.",
            "Transformation at our target, and if I use this fix."
        ],
        [
            "488 we would use for early ages classifier, so before he was here.",
            "Covariance matrix that I estimate from the data and now I do this modification with gamma is a number between zero and one and this makes a morphing between the estimated covariance matrix and this spherical.",
            "So if we have, equals zero, then it means we take our.",
            "Estimated covariance matrix and if gamma is 1.",
            "Then we take assume this spherical distribution.",
            "This corresponds to the identity matrix.",
            "So then we would have as bait vector U2 minus new one.",
            "And if you remember the introduction to classification, then this is the nearest centroid classifier.",
            "So this.",
            "Well, onward shoes, equals zero if one has.",
            "This is such a amount of data that can reliably estimate the structure of the noise.",
            "This covariance matrix and we should use it and, equals 1 means we don't have a good estimation of the noise, and it's better not to use any of those.",
            "But there are also.",
            "Many"
        ],
        [
            "Various in between."
        ],
        [
            "And here.",
            "These values are varied.",
            "This, between zero and one.",
            "And here you see the error, so one increases, and the error goes down, down, down, down down and then goes up again.",
            "So one needs to."
        ],
        [
            "To find the optimal.",
            "The parimeter here.",
            "And this depends on the dimensionality of the data and the number of samples you have.",
            "So there's not A and also how much noise there is so.",
            "In former Times funded cross validation for many.",
            "Values of, and then one picks so, with the lowest cross validation."
        ],
        [
            "Or um.",
            "But so Fortunately now there's a analytical method to do it.",
            "So yes, essentially nothing new, so here's the.",
            "This.",
            "Equation for the for this shrinkage.",
            "So this is the.",
            "Estimated covariance is identity and we need to.",
            "Determine this this value."
        ],
        [
            "To do the shrinkage.",
            "And so the details doesn't matter here, but here's a formula that comes out finally from this paper of little Wolf and chef orange trimmer.",
            "You can calculate the optimal gamma with this formula.",
            "That's comparably simple.",
            "Um?",
            "And it's yeah, there are few assumptions behind that, but if you remember what happens here, it's quite astonishing that it's possible to calculate this analytically, because so we want to find the best approximation here with the gamma to the true covariance matrix and the Sigma without any sign on top.",
            "This is a true covariance matrix, and this is.",
            "This is unknown.",
            "Of course we don't know it.",
            "But nevertheless, one can find the camera that's such a tease.",
            "Sigma Theater of Gamma Best approximates the unknown covariance matrix.",
            "And there's a very simple formula and you just calculate it and put it in your.",
            "Pacifier."
        ],
        [
            "So this this summarizes what happens.",
            "We have seen the estimated covariance matrix here with the dashed line.",
            "This is Sigma head.",
            "And presumably, if we have not enough data then we overestimate the variance in this long direction.",
            "So we need to make it more spherical like the grey sphere here.",
            "Enter that we can do with this.",
            "What is called shrinkage?",
            "The Sigma tiller versus parameter, and we can.",
            "Um?",
            "By this formula shown you before we can determine this, stars that gives the best classification error or the optimization work such as this best.",
            "Patrick Proximates it true, unknown covariance matrix and in most cases then this also gives the best classification error.",
            "And."
        ],
        [
            "So this was the situation before here we have classification on spatial features for different components and we get this different error rates if we put all features together in this high dimensional feature and we just apply in a naive way LDA, then we get this error rate of 25% which is higher than for the best single components."
        ],
        [
            "But now if we apply this LDA with his shrinkage with his formula, then for this specific data set it works very well.",
            "And there's only 4% error.",
            "So now we really increased here.",
            "Because we've used all this information, we increased and got a smaller classification now.",
            "So this.",
            "Mean says this high potential in in going to multivariate signals and also to in particular 2 uses spatial temporal features with much information included.",
            "But as you've seen you have to be careful in the classification.",
            "Maybe pure LDA doesn't work very well.",
            "And if you now go back to the assumptions under which LDA works optimal, we can also see why it was.",
            "Wrong here, of course there was a service.",
            "Assumption that we did not discuss so far.",
            "They said that's a true.",
            "And distributions are known.",
            "And of course they are in real application.",
            "There are never known and if you if your features are too high dimensional then they.",
            "But your estimate from the data is too far apart from the two covariance matrix, and therefore LDA is not optimal.",
            "And in order to get back close to optimality, at least you can do this.",
            "This shrinkage and the good message here is that you can do it quite easily with this simple formula.",
            "OK um."
        ],
        [
            "So from from this this part I skipped most of upset presentation, but at least I tell you the essence because I announced this before.",
            "So when you.",
            "Have a classifier from spatial features and the weight vector can be can be visualized as a topography.",
            "Since you have your weight for each each channel and this can be visualized and this is a this is a space.",
            "This is called a spatial filter, but the interpretation of spatial filters.",
            "Is not so straightforward, so in this case one could look at this and this was a guest from early time interval.",
            "And here's a strongest weights and most of what happens here in the filter.",
            "Something here in the back left.",
            "So one can assume that there's some information exploited from the from the visual area causes over the visual area and these kind of interpretations are very often done also in papers that they look at spatial filters and say these are the highest weights.",
            "So that means the classifier exploits signals from here.",
            "And."
        ],
        [
            "But this is not necessarily the case and so I don't.",
            "Give you the full presentation, but at least one example that shows you that is.",
            "This is not necessarily true, so in this example we assume that we have two.",
            "Two sources in the brain sources, one and S2, and now these are.",
            "Um, projected to the to the e.g signals that we measure with these two patterns A1 and A2.",
            "And.",
            "So now we want to find the spatial filter, so this is a 2 dimensional vector.",
            "Um?",
            "Where we, for example, want to recover source one?",
            "So usually you have one source that you are interested in that makes it discrimination between the task and another interference.",
            "So if we want to have a spatial, so applying a spatial filter W onto this.",
            "X This is a easy data that we observe, so we don't know how this is composed.",
            "So if we apply this to X.",
            "Then this goes linear like this, so this in this source space that we don't know these spatial filters applied to the first component into the second component.",
            "So now we can discriminate 2 cases about this propagation vectors of the sources.",
            "So either these are orthogonal.",
            "That means this product is 0, so the vectors are perpendicular and this product is 0.",
            "And in this case, when we choose our spatial filter WS A1, then this is this is fine.",
            "So then here we would have a one times a one, so this isn't the norm of a one.",
            "This is a positive value.",
            "And here if we put in a one here we have a one transpose times a two and this is 0.",
            "So second source cancels out.",
            "We only have source one time some factor.",
            "So then so in this case.",
            "Be choosing the space of filter axis is very nice, but.",
            "So typically these are not not orthogonal.",
            "This is very special case and then if we want to recover source S1 then we need to choose this this filter such that these interfering sources cancelled out.",
            "So we need to cancel this out.",
            "So we need to choose W subset W transpose times a two is 0.",
            "This cancels out and we only have this.",
            "But the interesting point here, and for that you don't need this math, is that in order to to extract these source one, we need to choose the filter W in a way that only depends on A2 and S2.",
            "So this only depends on the interference.",
            "So that means if we go Kopec so this is."
        ],
        [
            "Like visualization of W. And if you make an interpretation of this, it may be.",
            "This more reflects the interference and noise and the signal you are actually interested in.",
            "So it could be that we're not classifying on a signal from visual cortex, and I think in this case it's really versus spatial filter for the PS3 component which comes from the central area here.",
            "And it just needs to cancel out the interference from from visual cortex.",
            "Therefore it has the weights here.",
            "So in this."
        ],
        [
            "Says the W only depends on a 2 interfering source, but not at all on the signal itself.",
            "So this is maybe extreme so, but usually in spatial filters you have both aspects.",
            "You have weights that correspond to the signal and weights it cause."
        ],
        [
            "Come to the to the noise.",
            "So and this just says it, S1 is a cognitive P3 component and as two is interference from the visual area in order to.",
            "To extract information about CP3 component, it could be that your filter only depends on.",
            "On the interference.",
            "And this one cannot."
        ],
        [
            "To see in in simulations.",
            "You need in order to get a good classifier, you need also information or you can explode poet information from areas that are not this informative."
        ],
        [
            "So in this case.",
            "Yeah, I have two distributions.",
            "CPS at and FC set.",
            "PC component and then I made a simulation where I added some interference from the visual areas or yeah, simulated Alpha rhythm and I edit this.",
            "This point 4 factor on CPU set and this factor .2 on FC set and this obviously has nothing to do with the target non target discrimination."
        ],
        [
            "So then.",
            "Because then we look again at the same scatter plot.",
            "Now we have much more noise due to this interference.",
            "If we classify here, the error is 15%.",
            "If we classify here error is 33%.",
            "But if I add here to this classification, the channel ozette.",
            "And the classifier can use also information from ozette.",
            "Then one obtains again 16% error.",
            "So then we again have success here.",
            "All those what I added here was just noise, so that has no information about both the task.",
            "But it has exactly this kind of noise that makes a problem here, and therefore I can use this noise to subtractive boots.",
            "In a way, it's it's it's obvious thing, so I need to subtract this noise, so I need this channel, but this is important for interpretations or the the classifier would depend on this channel or that although it has no information in itself."
        ],
        [
            "There's one.",
            "Paper here single trial analysis and classification of ERP components or several parts of this presentation are more or less described there, so this is.",
            "A bit more high levels.",
            "So this is like the more high level part of the.",
            "Presentation.",
            "Mr Shrinkage and also I prepared with some some colleagues more LAX is gentle introduction style with the univariate features and more more basic and this will also be submitted soon and.",
            "And you can also read this in the paper.",
            "OK so no questions anymore then.",
            "I thank you for your attention.",
            "We will have a short coffee break and then we start with the lecture of Peter December.",
            "Think."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In this classification, these five trials.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Be classified as non targets and these as targets, so we see that there are.",
                    "label": 0
                },
                {
                    "sent": "These classifications on this site to non targets of the blue ones have been classified as target and two targets have been misclassified as non targets.",
                    "label": 0
                },
                {
                    "sent": "And in fact, this.",
                    "label": 0
                },
                {
                    "sent": "Such a feature?",
                    "label": 0
                },
                {
                    "sent": "It's called univariate features.",
                    "label": 0
                },
                {
                    "sent": "This means that you only have one value, so this is just.",
                    "label": 0
                },
                {
                    "sent": "Fun.",
                    "label": 0
                },
                {
                    "sent": "Scarlet valued variable, so this is what you release investigated in in your Physiology and the big step here in data analysis for Bcis to go to towards multivariate.",
                    "label": 0
                },
                {
                    "sent": "Features and classification and.",
                    "label": 0
                },
                {
                    "sent": "Preview.",
                    "label": 0
                },
                {
                    "sent": "Go to now, but first.",
                    "label": 0
                },
                {
                    "sent": "I would like to show you one measure of discriminability.",
                    "label": 0
                },
                {
                    "sent": "So in here it is important in order to estimate the performance to have a measure of how well these two distributions point the distribution of the various fork.",
                    "label": 0
                },
                {
                    "sent": "Target trials and phonon transfer.",
                    "label": 0
                },
                {
                    "sent": "How well these are separated so one can calculate an error rate but.",
                    "label": 0
                },
                {
                    "sent": "Yeah, baby.",
                    "label": 0
                },
                {
                    "sent": "Take another measure that is.",
                    "label": 0
                },
                {
                    "sent": "Independent classification or itself.",
                    "label": 0
                },
                {
                    "sent": "So this is called the receiver operator characteristic.",
                    "label": 0
                },
                {
                    "sent": "And you get this graph as follows.",
                    "label": 0
                },
                {
                    "sent": "So here I have again the 10 points as we have before.",
                    "label": 0
                },
                {
                    "sent": "These are the amplitudes of these epox.",
                    "label": 0
                },
                {
                    "sent": "It's.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Peak latency and this was a threshold that we had, so these are classified as targets as orange and these are classified as blue.",
                    "label": 0
                },
                {
                    "sent": "In this graph.",
                    "label": 0
                },
                {
                    "sent": "For this.",
                    "label": 0
                },
                {
                    "sent": "Classification for this threshold we make a point where on the X axis we.",
                    "label": 0
                },
                {
                    "sent": "Marks are missed orange detection and on the Y axis the true of the hits of the blue detection services threshold.",
                    "label": 0
                },
                {
                    "sent": "We missed.",
                    "label": 0
                },
                {
                    "sent": "22 orange, so the orange should all be above the threshold, but these two are below so we missed these two and two out of five is ratio of .4.",
                    "label": 0
                },
                {
                    "sent": "So we are here on the X axis and for the blue.",
                    "label": 0
                },
                {
                    "sent": "True.",
                    "label": 0
                },
                {
                    "sent": "True blue detections.",
                    "label": 0
                },
                {
                    "sent": "Blue should be below the threshold.",
                    "label": 0
                },
                {
                    "sent": "We have three out of five, so this is .6, so we.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At this point in the graph, and then we shift.",
                    "label": 0
                },
                {
                    "sent": "There's a hypothetical threshold one below so.",
                    "label": 0
                },
                {
                    "sent": "Yeah, nothing changed on the Y axis.",
                    "label": 0
                },
                {
                    "sent": "You still have three true detections through detection of blue, but now we have.",
                    "label": 0
                },
                {
                    "sent": "We missed only one orange, so now the ratio is only .2, so we get another point here.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And for yet another threshold, now you will decrease the true blue detection or this blue above the threshold is classified as orange.",
                    "label": 0
                },
                {
                    "sent": "So here we go down one step.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this you do for all different thresholds, and then you get this.",
                    "label": 0
                },
                {
                    "sent": "Our C receiver operator curve.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "A measure for for the discriminant ability is the area under this curve.",
                    "label": 1
                },
                {
                    "sent": "So with this gratings it's a 25 squares, and 18 of them are below the.",
                    "label": 0
                },
                {
                    "sent": "Curve so this would be a area under the curve of 18 / 25.",
                    "label": 1
                },
                {
                    "sent": "And this is a measure of how well these are separate.",
                    "label": 1
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Separate so if I do this for all trials of this example of this oddball example, you would get this smoother curve, and then the accuracy is 0.7.",
                    "label": 1
                },
                {
                    "sent": "So for the.",
                    "label": 1
                },
                {
                    "sent": "People that have have a more background in data analysis, here's a remark that this area under the curve.",
                    "label": 0
                },
                {
                    "sent": "Is equal to the probability that a random point from the orange distribution is ranked higher, has a higher value than randomly picked blue point.",
                    "label": 1
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And if we would do this kind of curve for random variable, so here it's just randomly orange and blue dots.",
                    "label": 1
                },
                {
                    "sent": "Then you would get here step like curve that's approximately the diagonal.",
                    "label": 1
                },
                {
                    "sent": "So then you get the area under the curve.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It's .5.",
                    "label": 0
                },
                {
                    "sent": "And if it's perfectly separated, then you go up here and you raise the threshold, you just increase it through blue detections and you don't miss any orange, and only if you are here at one for the two detection, then you go this way.",
                    "label": 1
                },
                {
                    "sent": "Since the area is 1.",
                    "label": 1
                },
                {
                    "sent": "4 perfect separated.",
                    "label": 0
                },
                {
                    "sent": "And distributions, if it would be the other way around, then you would work like this and then the area under the curve would be 0.",
                    "label": 1
                },
                {
                    "sent": "So this is a kind of performance measure.",
                    "label": 0
                },
                {
                    "sent": "It's .5 if there's no information in the variable that we look at, and it's zero or one for perfect separation.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now we do the important step as I announced and we go from this univariate feature where we only look at at one value, one valued variable to multivariate features.",
                    "label": 1
                },
                {
                    "sent": "So on on one.",
                    "label": 0
                },
                {
                    "sent": "So before we looked only at one channel at one time point.",
                    "label": 0
                },
                {
                    "sent": "But of course we could also look at the earpiece signal for multiple time points.",
                    "label": 0
                },
                {
                    "sent": "In one channel, or we could.",
                    "label": 0
                },
                {
                    "sent": "Look at one time point and multiple channels.",
                    "label": 0
                },
                {
                    "sent": "Or we can do both and use multiple channels and multiple time points, so this would be called temporal features is what we called spatial features and the combination spatial temporal features.",
                    "label": 1
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here, for our speller experiment from before, we would now have.",
                    "label": 0
                },
                {
                    "sent": "Multiple channels and get many continuous time signals from which we cut out the epoch.",
                    "label": 0
                },
                {
                    "sent": "Now epoch contains signals from many channels.",
                    "label": 0
                },
                {
                    "sent": "So why is this very useful for classification?",
                    "label": 0
                },
                {
                    "sent": "So here I've shown you signals from epithetical sources in the.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Brain so say we have one cognitive source that makes this positive peak after the.",
                    "label": 1
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Target stimuli, so this is what we classify on.",
                    "label": 0
                },
                {
                    "sent": "This is first peak time point.",
                    "label": 0
                },
                {
                    "sent": "And then there's a interfering source it has has nothing to do in this case with the task.",
                    "label": 0
                },
                {
                    "sent": "This is visual algorithm, so this is from the visual area and there's a 10 Hertz rhythm.",
                    "label": 0
                },
                {
                    "sent": "Or if we would have access to this true source in the brain, and this would be very nice and we can classify.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is this correctly?",
                    "label": 0
                },
                {
                    "sent": "But what we measure in EG is a superposition of the signals from all the sources.",
                    "label": 0
                },
                {
                    "sent": "So what we would measure at the Z, which is a. Electrode centralny and.",
                    "label": 0
                },
                {
                    "sent": "Raffi, above this source.",
                    "label": 0
                },
                {
                    "sent": "You would not only measure this signal on this cognitive source, but we would also measure overlay from the visual idle reason.",
                    "label": 1
                },
                {
                    "sent": "So here I just deliberately took factor point half for this and also the cognitive source goes with factor point.",
                    "label": 0
                },
                {
                    "sent": ".5 or 1/2 enthusiest channel offset which is over the visual area.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And now we realize that here it is at this time point that we define this feature to classify targets and non targets.",
                    "label": 0
                },
                {
                    "sent": "This is now in a in a Valley and another negative peak of this visual idealism, and therefore it is below our threshold.",
                    "label": 0
                },
                {
                    "sent": "So here we would not realize that this is from the target people.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But one one can fix this problem if one has a appropriate spatial filter.",
                    "label": 0
                },
                {
                    "sent": "So here's a can calculate the spatial filter that reconstructs the signal here from the source.",
                    "label": 0
                },
                {
                    "sent": "So it's like this, and then I get the source again, and then I can classify.",
                    "label": 0
                },
                {
                    "sent": "But I can do this only because I have a multivariate signal.",
                    "label": 0
                },
                {
                    "sent": "I have signal from 2 channels and I join them in an appropriate way, so this is called a spatial filter.",
                    "label": 0
                },
                {
                    "sent": "So here very simple spatial filter.",
                    "label": 1
                },
                {
                    "sent": "It's two weights because I only have two channels and then I get back the true signal and then I can classify correct?",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And similarly it it works for temporal features, so temporal features can help.",
                    "label": 1
                },
                {
                    "sent": "If you don't look only at one time point, but at several we take the same example.",
                    "label": 0
                },
                {
                    "sent": "So here again, there's a misclassification due to the overlay from from the visual idle rhythm, but now.",
                    "label": 1
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If you do our classification based on several time points, say these four around the peak and we would use a very simple temporal filter and say we just average.",
                    "label": 1
                },
                {
                    "sent": "Then from these four measurement points, we would calculate the average and then again in this classifier above, so special.",
                    "label": 0
                },
                {
                    "sent": "So also this is temporal filter we would have.",
                    "label": 0
                },
                {
                    "sent": "Saved classification.",
                    "label": 0
                },
                {
                    "sent": "And or a different example, when we have some Sunday.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The drift, so this also happens often in e.g.",
                    "label": 0
                },
                {
                    "sent": "Measurements if you don't have a high pass filter at least and then you get this kind of drift so you would not measure.",
                    "label": 0
                },
                {
                    "sent": "Here's a.",
                    "label": 0
                },
                {
                    "sent": "The true signal from the source, but here's a purple signal.",
                    "label": 0
                },
                {
                    "sent": "And then again here, the our feature is below the threshold, so it would be.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Misclassified and if one would have a special filter, for example with features from before at the peak and after the peak.",
                    "label": 0
                },
                {
                    "sent": "Then one.",
                    "label": 0
                },
                {
                    "sent": "Maybe with the classifier would have waiting like this.",
                    "label": 0
                },
                {
                    "sent": "Before and after a weighted with minus .5 and at the peak with weight 1.",
                    "label": 0
                },
                {
                    "sent": "And if you calculate the value with this temporal filter, that means multiplying the measured signal with these weights.",
                    "label": 1
                },
                {
                    "sent": "Then you would get the same result, almost the same result from the grace or original source signal an from the one with the drift.",
                    "label": 0
                },
                {
                    "sent": "So then would have.",
                    "label": 0
                },
                {
                    "sent": "A different classifier, different threshold.",
                    "label": 0
                },
                {
                    "sent": "But then you would see that you would have classified this correctly.",
                    "label": 0
                },
                {
                    "sent": "So this is motivation why it helps to go from this univariate feature to multivariate features.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It will be before we go under in need to type a little bit into the EG signals so this is from some visual speller.",
                    "label": 0
                },
                {
                    "sent": "Experiment the data.",
                    "label": 0
                },
                {
                    "sent": "So this is one of the way how to to display the results.",
                    "label": 0
                },
                {
                    "sent": "So as before this, each of these plots shows the epoch set are averaged across our target E. Pox or epoch setter cut out with respect to the target stimulus and INGREZZA one for non targets.",
                    "label": 0
                },
                {
                    "sent": "This is done now for for many channels because we want to go for multivariate signals.",
                    "label": 0
                },
                {
                    "sent": "This is done for many channels and here they are arranged as on this car.",
                    "label": 0
                },
                {
                    "sent": "Approximately when you look from.",
                    "label": 0
                },
                {
                    "sent": "Top onto the Skype noses up here.",
                    "label": 0
                },
                {
                    "sent": "And we are interested in the difference between the target and some non target epoch.",
                    "label": 0
                },
                {
                    "sent": "So this is an area that is shaded here in purple.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So before I show another representation, so 11 remark.",
                    "label": 0
                },
                {
                    "sent": "So usually you look at time serious like this.",
                    "label": 0
                },
                {
                    "sent": "It's a signals itself, but often it's also helpful to look at A at such a matrix representation or color representation.",
                    "label": 0
                },
                {
                    "sent": "So this is exactly the same same signals, but now it's not shown as a curve, but each value is translated according to this color bar into one color and then.",
                    "label": 0
                },
                {
                    "sent": "You see the Colosseum.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And another thing thing, if we have these data matrices for each of these epochs, we have target nontarget epox with a blue frame and some target epoch's with the orange frame.",
                    "label": 0
                },
                {
                    "sent": "Then we can calculate exactly this AR AUC value area under the curve that I introduced above for each.",
                    "label": 0
                },
                {
                    "sent": "A point in this matrix that means for a fixed time point and the fixed channel we calculate now across the trials the AOC.",
                    "label": 0
                },
                {
                    "sent": "So in this in this matrix each point here is 1 univariate feature.",
                    "label": 0
                },
                {
                    "sent": "Each time point corresponds to 1 channel.",
                    "label": 0
                },
                {
                    "sent": "Here on the Y axis anta one time point.",
                    "label": 0
                },
                {
                    "sent": "So each point here.",
                    "label": 0
                },
                {
                    "sent": "Exactly the Union weight feature univariate feature that we discussed before.",
                    "label": 0
                },
                {
                    "sent": "So if we go across the trials, we can calculate this AUC curve.",
                    "label": 0
                },
                {
                    "sent": "And we get one AUC value and then we can put all these values.",
                    "label": 0
                },
                {
                    "sent": "If you did this for all channels or time phones in this matrix.",
                    "label": 0
                },
                {
                    "sent": "So here you see the color bars or why it is 0.5.",
                    "label": 0
                },
                {
                    "sent": "This means that feature is no information for the discrimination target non target.",
                    "label": 0
                },
                {
                    "sent": "And the Blues are small, various.",
                    "label": 0
                },
                {
                    "sent": "This means the target is below, so non targets the distribution is shifted below and red means it's above.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now we can use this in in these ERP plots and now this is just another way of arranging the channels or not.",
                    "label": 0
                },
                {
                    "sent": "It's in a in a grid plot what we had before on the on the head.",
                    "label": 1
                },
                {
                    "sent": "And again, this has a frontal channels, these other on the back of the head.",
                    "label": 0
                },
                {
                    "sent": "These are the channels on the left hemisphere.",
                    "label": 0
                },
                {
                    "sent": "These are the ones on the right hemisphere.",
                    "label": 0
                },
                {
                    "sent": "The same curves and now I added just for each Channel 1 bar and thesis.",
                    "label": 0
                },
                {
                    "sent": "One you excuse me?",
                    "label": 0
                },
                {
                    "sent": "Exactly one row from this matrix, so this is.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For one channel, the AUC values for each time point.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here you have four channels.",
                    "label": 0
                },
                {
                    "sent": "These at the AOC for each time point.",
                    "label": 0
                },
                {
                    "sent": "So then you not only see here how well that means are separated.",
                    "label": 0
                },
                {
                    "sent": "This you see from the curves, but also which is 4 in view of classification more important.",
                    "label": 0
                },
                {
                    "sent": "So how well as it 2 distributions separated?",
                    "label": 0
                },
                {
                    "sent": "So it could be, for example, that this difference in mean is only due to some few trials with blinking artifacts or so.",
                    "label": 0
                },
                {
                    "sent": "Then you could also get a big difference in the means, but maybe the distribution is not separated very well, so then you could see these in the.",
                    "label": 0
                },
                {
                    "sent": "This color bars.",
                    "label": 0
                },
                {
                    "sent": "And then you directly get quite good overview.",
                    "label": 0
                },
                {
                    "sent": "You see that here some positive component components.",
                    "label": 0
                },
                {
                    "sent": "It's more positive for targets which is concentrated or focused more on the central area.",
                    "label": 0
                },
                {
                    "sent": "And here is a dark Blues as a negative component.",
                    "label": 0
                },
                {
                    "sent": "On the back of set.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in order to get this overview of other spatial distribution even in a better way, one should look at those typographies so, but let's start here at the top.",
                    "label": 0
                },
                {
                    "sent": "So this is mainly the same thing as we have seen before this.",
                    "label": 0
                },
                {
                    "sent": "PC's ERP curves for channel sees at this as a thick lines and our edit P or 7 which is here.",
                    "label": 0
                },
                {
                    "sent": "It's a back on the left side of the back of the head.",
                    "label": 0
                },
                {
                    "sent": "These are the two thin lines.",
                    "label": 0
                },
                {
                    "sent": "And then here you see shaded for different intervals and in order to get for example this topography.",
                    "label": 0
                },
                {
                    "sent": "The values within these intervals averaged across this time interval, and then you get one value for each channel.",
                    "label": 0
                },
                {
                    "sent": "And this defines a color for each channel according to this color bar.",
                    "label": 0
                },
                {
                    "sent": "And then this is interpolated to give a surface plot.",
                    "label": 0
                },
                {
                    "sent": "And T on top.",
                    "label": 0
                },
                {
                    "sent": "This is done for the target earpiece and on the bottom for nontarget earpiece.",
                    "label": 0
                },
                {
                    "sent": "So yes, very nicely with where you see the different components that discriminate.",
                    "label": 0
                },
                {
                    "sent": "So there's an early negative component with the focus here.",
                    "label": 0
                },
                {
                    "sent": "Occipital, left, lateralized, and the positive.",
                    "label": 0
                },
                {
                    "sent": "This is central.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Again, that plot before we are just these averages so they could be not so informative for classification.",
                    "label": 0
                },
                {
                    "sent": "The difference in the averages or you can also look at topography's of these A or C various.",
                    "label": 0
                },
                {
                    "sent": "This is just the same concept you will, you say, receive areas as well time series.",
                    "label": 0
                },
                {
                    "sent": "So now you don't have two classes because this is more or less a different target minus minus non target.",
                    "label": 0
                },
                {
                    "sent": "So we only have one time series here shown 14 ZZ and one for PO7.",
                    "label": 0
                },
                {
                    "sent": "Again, here we have C for intervals and if you average within these time intervals you get one value for each electrode and you can interpolate this to get this topography.",
                    "label": 0
                },
                {
                    "sent": "So in this case it was very clean data, so here's a different looks.",
                    "label": 0
                },
                {
                    "sent": "Very much like the targets here, so non targets are almost zero everywhere and these were clean data so it looks the same but with other data it could be.",
                    "label": 0
                },
                {
                    "sent": "But it looks also.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Quite different.",
                    "label": 0
                },
                {
                    "sent": "So from the plot before.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I go back so this only shows now the topography's for this.",
                    "label": 0
                },
                {
                    "sent": "Few time intervals until time time calls only for two channels, so it could be that we that we miss something that says maybe here in this time interval.",
                    "label": 0
                },
                {
                    "sent": "Also something interesting going on, but in other channels so we wouldn't see this here because this time is not shown as topography and here only these two channels.",
                    "label": 0
                },
                {
                    "sent": "So therefore if you don't know what to expect you should always look at this full matrix of AOC values.",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You have an overview of everywhere that.",
                    "label": 0
                },
                {
                    "sent": "An interesting difference could be.",
                    "label": 0
                },
                {
                    "sent": "And then based on this matrix, you can select those intervals of interest.",
                    "label": 0
                },
                {
                    "sent": "And here's these intervals are shown as this apostrophe, so this is like the step before.",
                    "label": 0
                },
                {
                    "sent": "So this maybe you wouldn't plot in your in your paper, but in order to if you investigate first time the data you maybe look should look better.",
                    "label": 0
                },
                {
                    "sent": "This matrix then pick up the intervals and then make pictures like you've seen before.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now in this matrix, as I said before each, each cell is a univariate feature, as we've seen before, and now we want to combine them to multivariate features.",
                    "label": 0
                },
                {
                    "sent": "So we have one single trial, so now I explain.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What kind of features we expect, so we have one single trial.",
                    "label": 0
                },
                {
                    "sent": "We show this as a.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The matrix as before, and now these are the three different kind of features that I introduced in the overview before.",
                    "label": 0
                },
                {
                    "sent": "Let's first look here.",
                    "label": 0
                },
                {
                    "sent": "So if we select from this matrix only one channel, this is a purely temporal feature.",
                    "label": 1
                },
                {
                    "sent": "We don't have any spatial information, just where it is but not distribution in space.",
                    "label": 0
                },
                {
                    "sent": "So this feature would be or feature vector you would say in data analysis.",
                    "label": 0
                },
                {
                    "sent": "This corresponds to the time course at one channel.",
                    "label": 0
                },
                {
                    "sent": "If you take one column of this matrix.",
                    "label": 1
                },
                {
                    "sent": "You would get a purely spatial feature.",
                    "label": 0
                },
                {
                    "sent": "You have no information about the time course, but distribution.",
                    "label": 0
                },
                {
                    "sent": "Or you do both.",
                    "label": 0
                },
                {
                    "sent": "You take some channels and some time points or time intervals and you get a matrix.",
                    "label": 0
                },
                {
                    "sent": "So of course is this matrix itself is also spatial.",
                    "label": 0
                },
                {
                    "sent": "Temporal feature just might be too high dimensional to really work with, so therefore of the month.",
                    "label": 0
                },
                {
                    "sent": "Subsamples at least a little bit in the time domain.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now before when we only have univariate features and it's quite clear how to classify, you just have the choice to use your to choose this threshold somewhere.",
                    "label": 0
                },
                {
                    "sent": "Now if you go to multivariate feature, you have a multi dimensional distribution so it gets more complicated.",
                    "label": 0
                },
                {
                    "sent": "So here we make this step first to two dimensions.",
                    "label": 0
                },
                {
                    "sent": "And in order to get a overview of the distribution, one can look at scatter plots and here I explain how you get to this scatter plots.",
                    "label": 0
                },
                {
                    "sent": "It would I take.",
                    "label": 0
                },
                {
                    "sent": "Channel Ozette and early time Point, where this is negative peak latency and another channel sees it and timepoint abit later.",
                    "label": 0
                },
                {
                    "sent": "But this was a positive peak latency.",
                    "label": 0
                },
                {
                    "sent": "And now I turn this channel, I rotate it.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "60 degrees.",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 0
                },
                {
                    "sent": "So here is the mean.",
                    "label": 0
                },
                {
                    "sent": "I get one value here from this representation and I would put this on the Y axis of this plot that will become the scatter plot and I take the amplitude here.",
                    "label": 0
                },
                {
                    "sent": "These at and take this as a X axis of this plot.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then I if I have so this work for the averages across.",
                    "label": 0
                },
                {
                    "sent": "If I do this for the single trial, so I get.",
                    "label": 0
                },
                {
                    "sent": "From one single trial I get one time point here or one one point here in the set.",
                    "label": 0
                },
                {
                    "sent": "And here I get this from the same single trial I get a value here, and by this I get these five points in this.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Get a plot.",
                    "label": 0
                },
                {
                    "sent": "And then I do this for all the single trials that I have.",
                    "label": 0
                },
                {
                    "sent": "And these are often these two, indicated by by ellipsoids, which correspond to Gaussian distributions, but we will come to that a bit later.",
                    "label": 0
                },
                {
                    "sent": "So, but here we have this distribution of all these single trials, which are somehow scattered around this this mean?",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we have the other distribution for the nontarget trials we have and have another mean.",
                    "label": 0
                },
                {
                    "sent": "Of course we have seen before.",
                    "label": 0
                },
                {
                    "sent": "It's a means are different, so we get the cross at another position.",
                    "label": 0
                },
                {
                    "sent": "And the distribution of those.",
                    "label": 0
                },
                {
                    "sent": "The two distributions targets and non target features in.",
                    "label": 0
                },
                {
                    "sent": "At 2 dimensions.",
                    "label": 0
                },
                {
                    "sent": "And yeah, usually you would.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Plot it, not with a rotation like I did.",
                    "label": 0
                },
                {
                    "sent": "You have target tries nontarget trials in two different channels.",
                    "label": 0
                },
                {
                    "sent": "You get these two features and then you make this scatterplot.",
                    "label": 0
                },
                {
                    "sent": "So now our.",
                    "label": 0
                },
                {
                    "sent": "Next task would be to find out how to best classify between the orange and blue.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Distribution here.",
                    "label": 0
                },
                {
                    "sent": "So, um.",
                    "label": 0
                },
                {
                    "sent": "Man.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So as I said, this is I have indicated here is a distribution around this as mean as caution.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Distribution so with this scatter plot in order to.",
                    "label": 0
                },
                {
                    "sent": "Took to make more meaning of this scatter plot and.",
                    "label": 0
                },
                {
                    "sent": "We can look at a very simple model of these event related potentials, so there's an idea that what we measure.",
                    "label": 0
                },
                {
                    "sent": "So this is what we measure.",
                    "label": 0
                },
                {
                    "sent": "In one trial is a superposition of 1 signal, which is a pure ERP that we also get when we average across many trials plus some noise.",
                    "label": 0
                },
                {
                    "sent": "Because there are many.",
                    "label": 0
                },
                {
                    "sent": "Things ongoing in the brain that are not related to the.",
                    "label": 0
                },
                {
                    "sent": "To the task so this.",
                    "label": 0
                },
                {
                    "sent": "Component this is a time series P1.",
                    "label": 0
                },
                {
                    "sent": "That is.",
                    "label": 0
                },
                {
                    "sent": "The brain activity related to the.",
                    "label": 0
                },
                {
                    "sent": "I'm processing of the target and this is unrelated activity.",
                    "label": 0
                },
                {
                    "sent": "So now we would according to whether the stimulus was a target stimulus or non target.",
                    "label": 1
                },
                {
                    "sent": "We would have two different time series, so this is a ERP for the target and this is the ERP for the non target and in each single trial index by K. Here this is overlaid by some noise.",
                    "label": 0
                },
                {
                    "sent": "So this is some random variable which produces noise.",
                    "label": 0
                },
                {
                    "sent": "So in this.",
                    "label": 0
                },
                {
                    "sent": "And this is a Gaussian distribution with mean zero.",
                    "label": 0
                },
                {
                    "sent": "So in this scatter plot that I introduce before the mean of the distribution, this corresponds to the to the ERP to this one.",
                    "label": 1
                },
                {
                    "sent": "So there's a blue one corresponds to condition one.",
                    "label": 0
                },
                {
                    "sent": "This version non targets before and Orange the ERP of condition.",
                    "label": 1
                },
                {
                    "sent": "2.",
                    "label": 0
                },
                {
                    "sent": "So remember this word.",
                    "label": 0
                },
                {
                    "sent": "Just the average value.",
                    "label": 0
                },
                {
                    "sent": "So that's exactly what you would also call ERP.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "The noise here.",
                    "label": 0
                },
                {
                    "sent": "This is what makes the scatter around the mean, so the.",
                    "label": 0
                },
                {
                    "sent": "What is indicated here by the ellipsoid is a trial to trial variation that is not related to the stimulus.",
                    "label": 0
                },
                {
                    "sent": "So this is just the noise that is not related to the processing of some of the target.",
                    "label": 0
                },
                {
                    "sent": "So now I'll go back to the point.",
                    "label": 0
                },
                {
                    "sent": "I became surprised.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "He",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "I show that I investigated that if we have high dimensional ERP features, that would be what we get is a distribution really looks like like a Gaussian distribution set.",
                    "label": 0
                },
                {
                    "sent": "It is satisfied to to make this nice plots with the ellipsoids.",
                    "label": 0
                },
                {
                    "sent": "So here I projected two components in this high dimensional space, there's a.",
                    "label": 0
                },
                {
                    "sent": "Highest variance was found, and if I look at these projections, this look or.",
                    "label": 0
                },
                {
                    "sent": "Scatters has his ellipsoidal shape.",
                    "label": 0
                },
                {
                    "sent": "This all looks like.",
                    "label": 0
                },
                {
                    "sent": "What was one cause Gaussian distribution?",
                    "label": 0
                },
                {
                    "sent": "But now he.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In order to.",
                    "label": 0
                },
                {
                    "sent": "To find out what these distributions would look like, so again, this is first univariate Gaussian distribution.",
                    "label": 1
                },
                {
                    "sent": "So then I have something like this.",
                    "label": 0
                },
                {
                    "sent": "This is what you would find if you.",
                    "label": 0
                },
                {
                    "sent": "Look at the distribution of the amplitude at one where you would get such a distribution is a mean, and this is.",
                    "label": 0
                },
                {
                    "sent": "As a standard deviation.",
                    "label": 0
                },
                {
                    "sent": "And maybe for another component this is a bit more Peaky.",
                    "label": 0
                },
                {
                    "sent": "But now.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If we go to a 2 dimensional.",
                    "label": 0
                },
                {
                    "sent": "Distribution there are several possibilities, so it could be that these two components are univariate uncorrelated.",
                    "label": 0
                },
                {
                    "sent": "Then we would get a joint distribution which looks like this.",
                    "label": 0
                },
                {
                    "sent": "So there's no connection between the variable on the horizontal axis and on the vertical axis.",
                    "label": 0
                },
                {
                    "sent": "Or they could be correlated.",
                    "label": 0
                },
                {
                    "sent": "So in this case, if I measure a high value from one variable, I would also get a high value from the other variable.",
                    "label": 0
                },
                {
                    "sent": "So this is correlated, but you cannot see this if you only look at the variables in one dimension, you don't see the difference.",
                    "label": 0
                },
                {
                    "sent": "So the if you project it to this.",
                    "label": 0
                },
                {
                    "sent": "If you only look at this variable, it looks in both cases the same.",
                    "label": 0
                },
                {
                    "sent": "And if you only look at the variables it's on the Y axis.",
                    "label": 0
                },
                {
                    "sent": "It looks also the same.",
                    "label": 0
                },
                {
                    "sent": "So we really need to look into the high dimensional data to find out what it looks like and for.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For EG, it's very known that the signals are very much correlated, so this is from famous simulation of newness.",
                    "label": 0
                },
                {
                    "sent": "No, this is my own simulation from data, so here took just any.",
                    "label": 0
                },
                {
                    "sent": "Some EG data set and I calculated from each channel the correlation coefficient to the channels is set.",
                    "label": 0
                },
                {
                    "sent": "In the middle and you see even from channels that are quite far apart from the Middle Channel, we get correlations of over .9.",
                    "label": 0
                },
                {
                    "sent": "So the signals are very highly correlated, so.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Going back to this picture, we are more.",
                    "label": 0
                },
                {
                    "sent": "In such a distribution.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That means we need to think more about these Gaussian distributions, so this is a 2 dimensional Gaussian distribution.",
                    "label": 0
                },
                {
                    "sent": "So we have two variables here and this would be.",
                    "label": 0
                },
                {
                    "sent": "These are the density.",
                    "label": 0
                },
                {
                    "sent": "How much points you would get from one area here, so usually would.",
                    "label": 0
                },
                {
                    "sent": "Plus this is a surface and this is a formula of the Gaussian distribution, but.",
                    "label": 0
                },
                {
                    "sent": "For a representation, it's nicer to have her 2 dimensional representation and then for indication you only take one of these contour lines, which are all ellipsoids, and then you would plot.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "This distribution.",
                    "label": 0
                },
                {
                    "sent": "Taxes.",
                    "label": 0
                },
                {
                    "sent": "It's all in the three dimensional thing this.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This mountain would not come out of the of the wall like this and this is one of their control lines.",
                    "label": 0
                },
                {
                    "sent": "And in order to to find out from from given data.",
                    "label": 0
                },
                {
                    "sent": "How this ellipsoid looks like?",
                    "label": 0
                },
                {
                    "sent": "One has to do a.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I can value decomposition.",
                    "label": 0
                },
                {
                    "sent": "And so this is a mathematical part, but I will explain this also.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "In the representation, so mathematically, given the matrix C that is quadratic and symmetric and positive definite.",
                    "label": 1
                },
                {
                    "sent": "So this matrix season you can find another representation as a product of these four matrices where.",
                    "label": 0
                },
                {
                    "sent": "We is a also normal matrix and these are diagonal matrix, so this C. Can be represented at such and.",
                    "label": 0
                },
                {
                    "sent": "This covariance matrices that were denoted by Sigma.",
                    "label": 0
                },
                {
                    "sent": "Before that we find in this multi dimensional multivariate Gaussian distributions, these are exactly fulfilled.",
                    "label": 0
                },
                {
                    "sent": "This properties they are symmetric and positive definite.",
                    "label": 0
                },
                {
                    "sent": "All covariance matrices are like this, so any covariance matrix that we estimate from the data.",
                    "label": 0
                },
                {
                    "sent": "We can make this representation and this is very easy calculation and.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "The nice thing if we have this representation then we can see how we plot this ellipsoid, namely this in this matrix V. This is a matrix and I have P column vectors in it.",
                    "label": 0
                },
                {
                    "sent": "And because it's also normal, each vector has length one, and they're all orthogonal.",
                    "label": 0
                },
                {
                    "sent": "To each other, and these are the the principal axis of this distribution of this ellipsoid.",
                    "label": 0
                },
                {
                    "sent": "So here are funds, so it's only two dimensions.",
                    "label": 0
                },
                {
                    "sent": "So if we one and 3, two and so organized and this.",
                    "label": 0
                },
                {
                    "sent": "Tell me what are the axes of the ellipsoid that I have to draw if I want to visualize this distribution?",
                    "label": 0
                },
                {
                    "sent": "And then I have this diagonal matrix D and this elements on the diagonal.",
                    "label": 0
                },
                {
                    "sent": "These are called the eigenvalues.",
                    "label": 0
                },
                {
                    "sent": "And this, say, tell me what is the standard deviation along this direction for this?",
                    "label": 0
                },
                {
                    "sent": "D1 is a standard deviation of all my data points in this direction, and the D2, the standard deviation along the direction of V2.",
                    "label": 0
                },
                {
                    "sent": "Not exactly so I have to.",
                    "label": 0
                },
                {
                    "sent": "Takes a square root of set so the square root of these eigenvalue is equal to the standard deviation.",
                    "label": 0
                },
                {
                    "sent": "So value itself is a variance.",
                    "label": 0
                },
                {
                    "sent": "So that means if you want.",
                    "label": 0
                },
                {
                    "sent": "To draw such a picture from from your Gaussian distribution you have to calculate the covariance matrix.",
                    "label": 0
                },
                {
                    "sent": "This is a very simple formula and then you make this eigenvalue decomposition.",
                    "label": 0
                },
                {
                    "sent": "You get the eigenvectors and you know the direction and from the eigenvalues you know the length of the axis, so you.",
                    "label": 0
                },
                {
                    "sent": "If you make this.",
                    "label": 0
                },
                {
                    "sent": "Contour ellipsoids, then the length of these axis has to coincide with the standard deviation.",
                    "label": 0
                },
                {
                    "sent": "That means the square root from the eigenvalues.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now with this background we can talk about classification so that we.",
                    "label": 0
                },
                {
                    "sent": "Start very very simple.",
                    "label": 0
                },
                {
                    "sent": "So let's assume we want to classify these two classes, the blue and the orange.",
                    "label": 0
                },
                {
                    "sent": "No 2 dimensional and we only know the means, so we know only knew one that knew too.",
                    "label": 0
                },
                {
                    "sent": "If you don't have any more information and there's not so much we can do.",
                    "label": 0
                },
                {
                    "sent": "If we should tell what these X is, what belong, does it belong to class one or Class 2?",
                    "label": 0
                },
                {
                    "sent": "The only choice is that we measure.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Distance to the means and say it's this one's plus two because it's.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "The distance is less than.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Us too.",
                    "label": 0
                },
                {
                    "sent": "So this this rule would lead to this kind of separation of the plane.",
                    "label": 1
                },
                {
                    "sent": "This one would be.",
                    "label": 0
                },
                {
                    "sent": "Classify this orange on this side and the other blue.",
                    "label": 0
                },
                {
                    "sent": "So this separation line is perpendicular to the line that connects the two means and crosses this in the in the middle.",
                    "label": 1
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "And in the mathematical formulation one formalizes by means of a of a normal vector.",
                    "label": 1
                },
                {
                    "sent": "This is a vector W and normal means that it's perpendicular to the to the separating line.",
                    "label": 0
                },
                {
                    "sent": "And here for the visualization, I normalize it also so this is length one.",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 0
                },
                {
                    "sent": "This part is written here.",
                    "label": 0
                },
                {
                    "sent": "W transpose times X is a scalar product.",
                    "label": 0
                },
                {
                    "sent": "This means these are both vectors W&X and this means I multiplies a corresponding elements and I sum them up and geometrically this.",
                    "label": 0
                },
                {
                    "sent": "This means, for example, if I put this color product between W&X.",
                    "label": 0
                },
                {
                    "sent": "This corresponds to the length.",
                    "label": 0
                },
                {
                    "sent": "Here when I Project X perpendicular on this vector W. So at this point, XI projected onto W and then I measure the distance to the origin.",
                    "label": 0
                },
                {
                    "sent": "So this.",
                    "label": 0
                },
                {
                    "sent": "Lengthy of this projected X on W this is.",
                    "label": 0
                },
                {
                    "sent": "W transpose times X.",
                    "label": 0
                },
                {
                    "sent": "And now if we want to formalize this, one has to look at this quantity W transpose times X -- B.",
                    "label": 0
                },
                {
                    "sent": "Cause this W transpose times X is.",
                    "label": 0
                },
                {
                    "sent": "This distance and B is a distance along this.",
                    "label": 1
                },
                {
                    "sent": "Vector W2 The separation line and then we have to look whether this point X visits on that side.",
                    "label": 0
                },
                {
                    "sent": "So if this is.",
                    "label": 0
                },
                {
                    "sent": "If this is positive or if it's on this side, it's negative.",
                    "label": 0
                },
                {
                    "sent": "So this is a.",
                    "label": 0
                },
                {
                    "sent": "Mathematical formalism, but so if you are not familiar with this kind of algebra, it doesn't matter.",
                    "label": 0
                },
                {
                    "sent": "So this was just a side remark, so it's.",
                    "label": 0
                },
                {
                    "sent": "Important that you understand the concept.",
                    "label": 0
                },
                {
                    "sent": "So if you only know the means then we can only.",
                    "label": 0
                },
                {
                    "sent": "To this uninformed classification, but as I pointed out before these distributions here.",
                    "label": 0
                },
                {
                    "sent": "Error code.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So there's the signals are correlated, so we get Gaussian distributions that have these ellipsoids tilted ellipsoid's like this.",
                    "label": 0
                },
                {
                    "sent": "In all, in this case, if we are asked what to what class, does X belong?",
                    "label": 0
                },
                {
                    "sent": "I assume that anyone would would answer blue because it clearly lies into this blue dots.",
                    "label": 0
                },
                {
                    "sent": "I hope you see them also in the black in the back and not in the orange.",
                    "label": 0
                },
                {
                    "sent": "So here we are.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now a different situation.",
                    "label": 0
                },
                {
                    "sent": "Now we know not only the means, but we also know this scatter.",
                    "label": 0
                },
                {
                    "sent": "You know more about the distribution, so here are indicated this essay.",
                    "label": 0
                },
                {
                    "sent": "Ellipsoids, again, is cautions, and then if you see this plot then it would be clear that X belongs to the blue class.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "In fact, this is a classification that one gets from from linear discriminant analysis when estimates is distribution as from the covariance matrix, and then we get these other separation.",
                    "label": 1
                },
                {
                    "sent": "This is normal vector that's S before Mewtwo minus mu one, but now multiply it with the inverse of this covariance matrix.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I don't.",
                    "label": 0
                },
                {
                    "sent": "That's the time to explain this today, but this inverse of the covariance matrix.",
                    "label": 1
                },
                {
                    "sent": "This is something that makes a whitening.",
                    "label": 0
                },
                {
                    "sent": "This means we.",
                    "label": 0
                },
                {
                    "sent": "Transform this space into a space where there is a variance.",
                    "label": 0
                },
                {
                    "sent": "Now of this, each distribution is 1 in every direction.",
                    "label": 0
                },
                {
                    "sent": "So the variance of the blue distribution is 1 in every direction, so therefore these are now circles.",
                    "label": 0
                },
                {
                    "sent": "This distribution variance is the same in.",
                    "label": 0
                },
                {
                    "sent": "In any direction and then in this white in space we can now do our our original simple classification.",
                    "label": 0
                },
                {
                    "sent": "I didn't give it a name, so this one is called nearest centroid classifier.",
                    "label": 0
                },
                {
                    "sent": "So your classifier according to the.",
                    "label": 1
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Century tickets",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What's news?",
                    "label": 0
                },
                {
                    "sent": "And if one has white in this data, then one can use his nearest century classifier, because then this distribution of the noises in an informative it's not informative anymore.",
                    "label": 0
                },
                {
                    "sent": "If it's white and.",
                    "label": 0
                },
                {
                    "sent": "And so this now corresponds to the nearest neighbor classifications of light in space and.",
                    "label": 0
                },
                {
                    "sent": "To do LDA in the original space.",
                    "label": 0
                },
                {
                    "sent": "But UF soul don't do do nearest neighbor classification.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This out quietly.",
                    "label": 0
                },
                {
                    "sent": "So to give some some background for this linear discriminant analysis.",
                    "label": 0
                },
                {
                    "sent": "One should consider the following assumptions.",
                    "label": 0
                },
                {
                    "sent": "Following three, the first assumption of LDA is features of each class are Gaussian distributed?",
                    "label": 1
                },
                {
                    "sent": "Then the second is these Gaussian distributions of all classes have the same covariance matrix and the search.",
                    "label": 1
                },
                {
                    "sent": "Is that it?",
                    "label": 0
                },
                {
                    "sent": "True class distributions are known so that we know the mean answer covariance matrix.",
                    "label": 0
                },
                {
                    "sent": "So I call this assumptions because one can then show a.",
                    "label": 0
                },
                {
                    "sent": "In probability theory, if these assumptions are met, then one can show that.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "OK, this is missing what one can say, so then one can say that this LDA that is defined like this.",
                    "label": 0
                },
                {
                    "sent": "This is the normal vector is optimal.",
                    "label": 0
                },
                {
                    "sent": "So then one can show this is a best classification you can do on average.",
                    "label": 0
                },
                {
                    "sent": "Causes assumption are never fully met and you can apply it if this assumptions are not fulfilled.",
                    "label": 0
                },
                {
                    "sent": "But these theorems gives the orientation of when LDA is supposed to work very well.",
                    "label": 0
                },
                {
                    "sent": "If these are men.",
                    "label": 0
                },
                {
                    "sent": "So therefore we should discuss these assumptions.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "1st.",
                    "label": 0
                },
                {
                    "sent": "Is that the?",
                    "label": 0
                },
                {
                    "sent": "A Gaussian distributed Gaussian distributions are characterized by mean and covariance matrix.",
                    "label": 1
                },
                {
                    "sent": "So if on, for the example I take a spatial feature because it is nice to visualize.",
                    "label": 0
                },
                {
                    "sent": "So if we have a spatial feature, then the mean for the targets and non targets I can visualize and this is.",
                    "label": 0
                },
                {
                    "sent": "Just these two Skype Maps, so we have two different means that is important.",
                    "label": 0
                },
                {
                    "sent": "But the assumption before, was it the covariance is the same.",
                    "label": 0
                },
                {
                    "sent": "The covariance is high dimensional matrix, so it's difficult to visualize, but I've shown you this eigenvalue decomposition before.",
                    "label": 1
                },
                {
                    "sent": "So one way to look at this is to look at the eigenvalue spectrum.",
                    "label": 0
                },
                {
                    "sent": "So these are the eigenvalues sorted.",
                    "label": 0
                },
                {
                    "sent": "So if you remember the eigenvalues as a variance along this direction of the ellipsoid.",
                    "label": 0
                },
                {
                    "sent": "And then you see there are some directions is very high variance and as a low.",
                    "label": 0
                },
                {
                    "sent": "And if you compare this, at least these eigenvalues look very different, very much the same in these two classes.",
                    "label": 0
                },
                {
                    "sent": "And so now in my.",
                    "label": 0
                },
                {
                    "sent": "My so this as I said before, this reordering went wrong, so now there should be this.",
                    "label": 0
                },
                {
                    "sent": "Scott said.",
                    "label": 0
                },
                {
                    "sent": "Irritate",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Me before, so now I look at the projection onto these.",
                    "label": 0
                },
                {
                    "sent": "Components of the highest variance, and then I see these.",
                    "label": 0
                },
                {
                    "sent": "These plots and I can only.",
                    "label": 0
                },
                {
                    "sent": "Say no, that this look very much like oceans.",
                    "label": 0
                },
                {
                    "sent": "So this was he.",
                    "label": 0
                },
                {
                    "sent": "Assumption.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Feature of each class adult Gaussian distributed so this by eyeballing this looks net quite well.",
                    "label": 0
                },
                {
                    "sent": "The second one is that they have the same code.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Parents matrix so therefore.",
                    "label": 0
                },
                {
                    "sent": "We see that it has the same eigenvalue spectrum is in this.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One data set, so I only look at one data set and now I can also look at the eigenvectors so the covariance matrix is characterized by this eigen values and so eigenvectors.",
                    "label": 0
                },
                {
                    "sent": "And each eigenvector I can again visualize as a Skype topography.",
                    "label": 0
                },
                {
                    "sent": "So this is in the feature space, so I can visualize this as a Skype topography and these are the topography is corresponding to the eigenvectors with three highest eigenvalues.",
                    "label": 0
                },
                {
                    "sent": "So these are the directions in this.",
                    "label": 0
                },
                {
                    "sent": "Feature space where we find my SMS variants or this should be the most critical ones.",
                    "label": 0
                },
                {
                    "sent": "And these are I plot for the target distribution and the non target.",
                    "label": 0
                },
                {
                    "sent": "And here you see they correspond quite well, at least for these.",
                    "label": 0
                },
                {
                    "sent": "So empirically.",
                    "label": 0
                },
                {
                    "sent": "These two assumptions seem to be met, so maybe you can assume that if I make these plots, it's always that it looks.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Very much the same, but here this is an example from completely different datasets and here show you that here.",
                    "label": 0
                },
                {
                    "sent": "This assumption that the two covariance matrices are equal is not met at all.",
                    "label": 0
                },
                {
                    "sent": "This is a data set from handwritten digit recognition.",
                    "label": 0
                },
                {
                    "sent": "This our future zeros hit Route 7.",
                    "label": 0
                },
                {
                    "sent": "This is if I average overall health written digital digits, so you'll see very nicely this is zero.",
                    "label": 0
                },
                {
                    "sent": "This is A7.",
                    "label": 0
                },
                {
                    "sent": "And here I can also visualize these eigenvectors that correspond to most variants.",
                    "label": 0
                },
                {
                    "sent": "These are again pictures that I can visualize and now here you see, if this assumption is not met or these pictures look very different like these.",
                    "label": 0
                },
                {
                    "sent": "So here for example.",
                    "label": 0
                },
                {
                    "sent": "This variation comes from that some till the 7 little bit more a little bit less and this gives a completely different variation than if I tilt to zero in another way.",
                    "label": 0
                },
                {
                    "sent": "So here's the noise.",
                    "label": 0
                },
                {
                    "sent": "In the data surveyed, variation in the data really depends on the class itself.",
                    "label": 0
                },
                {
                    "sent": "But in the in the earpiece, the class only defines the mean and there's the noise is a ongoing noise.",
                    "label": 0
                },
                {
                    "sent": "It has nothing to do with the task with target or non target.",
                    "label": 0
                },
                {
                    "sent": "So therefore it's.",
                    "label": 0
                },
                {
                    "sent": "It's quite a good assumption to say the covariance matrix in Reg data is equal.",
                    "label": 0
                },
                {
                    "sent": "And therefore this LDA, which is a comparably simple classifier because it's a linear classifier, is supposed to work.",
                    "label": 0
                },
                {
                    "sent": "Um, quite good.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, then now that we have the background folk for classification.",
                    "label": 0
                },
                {
                    "sent": "I need to tell.",
                    "label": 0
                },
                {
                    "sent": "Maybe at least one one remark about validation.",
                    "label": 0
                },
                {
                    "sent": "Who if we validated classifiers on our set LDA is good, but if we validate it and one has two.",
                    "label": 0
                },
                {
                    "sent": "Expect certain certain things and so to validate a classifier, you need to have a training set and validation set in the first take.",
                    "label": 1
                },
                {
                    "sent": "Some data is a training set and then you can train your classifier on estimate is covariance matrix and the means, and then you get this W for the classifier.",
                    "label": 0
                },
                {
                    "sent": "Or if you start from the G data, maybe you you select some features, you select channels you select time intervals.",
                    "label": 0
                },
                {
                    "sent": "This you do on the training set and then you need to have another set which is disjoint and independent and this is your validation set and on this set you do the same processing steps.",
                    "label": 0
                },
                {
                    "sent": "You extract the same features that you found informative on the training set you apply the classifier and then you estimate the performance.",
                    "label": 1
                },
                {
                    "sent": "So if these sets are not independent and your.",
                    "label": 0
                },
                {
                    "sent": "Estimated performance will not met reality meet reality.",
                    "label": 0
                },
                {
                    "sent": "So this is a.",
                    "label": 0
                },
                {
                    "sent": "Delicate topic and one paper is given here that gives quite some details on.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Oh, you should do the validation.",
                    "label": 0
                },
                {
                    "sent": "And one specific thing that you should keep in mind if you do a validation for this oddball type of experiments isn't following.",
                    "label": 0
                },
                {
                    "sent": "There we have the situation that one class has much more samples than the other class.",
                    "label": 0
                },
                {
                    "sent": "Because you have much more non targets and targets.",
                    "label": 0
                },
                {
                    "sent": "And then you should calculate at least a weighted error for the following reason.",
                    "label": 0
                },
                {
                    "sent": "So here in this example we have 900 samples from class one and 100 from Class 2.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "If one makes a classification like this, then the unweighted errors 26% and so weighted is 22.",
                    "label": 0
                },
                {
                    "sent": "But if I would make a classification like this so the orange is a big class.",
                    "label": 0
                },
                {
                    "sent": "So this means I label almost everything is orange.",
                    "label": 0
                },
                {
                    "sent": "Then the unweighted errors only .9 or if I would classify everything as orange, then the error would be exactly 10% because there are only 10% in the smaller class.",
                    "label": 0
                },
                {
                    "sent": "So if you would get this result then you would maybe be surprised and say OK, my classifier works very well, only 10% of error.",
                    "label": 0
                },
                {
                    "sent": "Although it's it's a nonsense classification.",
                    "label": 0
                },
                {
                    "sent": "So therefore.",
                    "label": 0
                },
                {
                    "sent": "You should calculate a weighted airline.",
                    "label": 0
                },
                {
                    "sent": "You calculate the error on all samples of plus one and on our samples of +2, and then you take their say average.",
                    "label": 0
                },
                {
                    "sent": "If you do that, then here in the.",
                    "label": 0
                },
                {
                    "sent": "In the reasonable classification, you get the same result, but if you make classification like this and related error in this case behind.",
                    "label": 0
                },
                {
                    "sent": "Or you can use this A or C. Measure that I introduced before and map it to to the range between 0 and 100 and this would be then a performance measure that's independent of this bias.",
                    "label": 0
                },
                {
                    "sent": "Of how you exactly shift your hyperplane.",
                    "label": 0
                },
                {
                    "sent": "So therefore this measures the same everywhere.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now as I said, we go to two classification.",
                    "label": 0
                },
                {
                    "sent": "So first we had this this temporal features, so these features have only one time series from one channel, so we cannot expect that this classification is.",
                    "label": 1
                },
                {
                    "sent": "It's very good, but still this classification can be.",
                    "label": 1
                },
                {
                    "sent": "Can provide some interesting information if we if we have many channels and we can separately do for each channel.",
                    "label": 1
                },
                {
                    "sent": "Such a classification on each channel separately, I do a classification on these temporal features.",
                    "label": 0
                },
                {
                    "sent": "And I do the validation correctly and then I get to get the error rate for each channel.",
                    "label": 1
                },
                {
                    "sent": "Then I can map this on the on this card.",
                    "label": 0
                },
                {
                    "sent": "So this then gives such a nice representation an shows where discriminative information comes from.",
                    "label": 0
                },
                {
                    "sent": "So in this case we see two folky one is here, left occipitale and maybe you remember there was his early negative components that was discriminative.",
                    "label": 0
                },
                {
                    "sent": "And here's a another central Fitnesses positive peak.",
                    "label": 0
                },
                {
                    "sent": "So this gives some.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Weather discriminative information spatially comes from and when we look at the spatial features we can do with the other way around, we can.",
                    "label": 1
                },
                {
                    "sent": "Take from from each time point we takes a special feature and then make a classification of these special features.",
                    "label": 0
                },
                {
                    "sent": "We get a error rate or accuracy and for each time point.",
                    "label": 1
                },
                {
                    "sent": "So now we know in time, whereas the discriminative information distributed.",
                    "label": 0
                },
                {
                    "sent": "And also if one for example we take this this time point where the best discrimination is achieved so.",
                    "label": 0
                },
                {
                    "sent": "Classification this is mainly characterized by this weight vector W. And this can also be visualized as a Skype map.",
                    "label": 0
                },
                {
                    "sent": "So then you can try to find out.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Your classifier does.",
                    "label": 0
                },
                {
                    "sent": "But this is very hard to make an interpretation of it, and that's it.",
                    "label": 0
                },
                {
                    "sent": "I will tell you later.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now here is.",
                    "label": 0
                },
                {
                    "sent": "This is a little bit different paradigm, some some speller where we have more discriminative components.",
                    "label": 0
                },
                {
                    "sent": "Yeah, there's classification performed on.",
                    "label": 0
                },
                {
                    "sent": "Seven different intervals, and this is the error rate.",
                    "label": 0
                },
                {
                    "sent": "That were achieved and now we turn to to the spatial temporal feature.",
                    "label": 0
                },
                {
                    "sent": "So we combine spatial feature and temporal features.",
                    "label": 0
                },
                {
                    "sent": "And classify on all the same.",
                    "label": 0
                },
                {
                    "sent": "So we increase the information.",
                    "label": 0
                },
                {
                    "sent": "So then we should expect.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To get a better look.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Suffication, but if we do this.",
                    "label": 0
                },
                {
                    "sent": "Then for this spatial temporal feature we get 25% error, but in one before if we go back.",
                    "label": 0
                },
                {
                    "sent": "On on the best.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Best.",
                    "label": 0
                },
                {
                    "sent": "Interval here there are.",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's only 14%.",
                    "label": 0
                },
                {
                    "sent": "So what what happened here?",
                    "label": 0
                },
                {
                    "sent": "We add information, but nevertheless a classification gets.",
                    "label": 0
                },
                {
                    "sent": "Get.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It's worth.",
                    "label": 0
                },
                {
                    "sent": "And the problem here is that if we go to high dimensional features or now the dimensionality is much higher, then we get a problem in estimating the data as a distribution was a Gaussian distribution, we need to estimate the mean of the distribution and this covariance matrix.",
                    "label": 1
                },
                {
                    "sent": "The scatter and.",
                    "label": 0
                },
                {
                    "sent": "This covariance matrix has many many parameters, and if we have 100 dimensional features, we need to estimate 5000 variables in the covariance matrix and.",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So you have errors here and there and then you get a miss estimated.",
                    "label": 0
                },
                {
                    "sent": "Covariance matrix and therefore the classification with LDA, which crucially depends on that we have a estimate for the covariance matrix.",
                    "label": 1
                },
                {
                    "sent": "This goes then really bad.",
                    "label": 0
                },
                {
                    "sent": "But the good thing here, although we have a problem that there's a bias misestimation, is that there's a systematic bias, namely the large eigenvalues of this estimated covariance matrix are too large, and small eigenvalues are too small.",
                    "label": 1
                },
                {
                    "sent": "And if you.",
                    "label": 0
                },
                {
                    "sent": "Remember what large and small eigenvalues mean?",
                    "label": 0
                }
            ]
        },
        "clip_80": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Trying various is the variance along the direction with high variance and so that small eigenvalues is a variance in the direction of small variants.",
                    "label": 0
                },
                {
                    "sent": "So if this green green is the true covariance and we make the misestimation as indicated on the slide before we would estimate like sushi on blue covariance matrix in the direction of large variance.",
                    "label": 0
                },
                {
                    "sent": "We overestimate the variance too large and in direction of the.",
                    "label": 0
                },
                {
                    "sent": "Smaller variance, we underestimate the variance.",
                    "label": 0
                },
                {
                    "sent": "This is so this is just a cartoon because in two dimensions we could could estimate the distribution very well with this many data, but this year is an estimation.",
                    "label": 0
                },
                {
                    "sent": "Wears a black shows the eigenvalue spectrum of the true covariance matrix.",
                    "label": 0
                },
                {
                    "sent": "So this is 200 dimensions and these are estimation from restricted data.",
                    "label": 0
                },
                {
                    "sent": "This is red with 500 data points and purple only with 50 data points.",
                    "label": 0
                },
                {
                    "sent": "And tears is eigenvalue spectrum is a magnitude of psych and various so we see here is a high eigenvalues overestimated and solo underestimated.",
                    "label": 0
                },
                {
                    "sent": "So this.",
                    "label": 0
                }
            ]
        },
        "clip_81": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Shows that this kind of bias exists in real data, and then the the idea of fixing this misestimation is first place.",
                    "label": 0
                },
                {
                    "sent": "Simple.",
                    "label": 0
                },
                {
                    "sent": "So if we have the blue one.",
                    "label": 0
                },
                {
                    "sent": "Well, we know that there is this misestimation.",
                    "label": 0
                },
                {
                    "sent": "Then we could make a linear interpolation to a sphere which is shown in black.",
                    "label": 0
                },
                {
                    "sent": "The orange for example is.",
                    "label": 0
                },
                {
                    "sent": "This is a morphing in between the blue and and the black.",
                    "label": 0
                },
                {
                    "sent": "Now it makes it variance along the.",
                    "label": 0
                },
                {
                    "sent": "Long direction, smaller and the other way we make it larger.",
                    "label": 0
                },
                {
                    "sent": "So then we could hope that if we.",
                    "label": 0
                },
                {
                    "sent": "Meet the real covariance matrix.",
                    "label": 0
                }
            ]
        },
        "clip_82": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_83": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So then when when one can do some math and see that this exactly counteracts balance, so the direction of this?",
                    "label": 0
                },
                {
                    "sent": "I can vector stays the same and I just linearly interpolate between the estimated eigenvalue and the average eigenvalues.",
                    "label": 0
                },
                {
                    "sent": "So I make exactly this.",
                    "label": 0
                },
                {
                    "sent": "Transformation at our target, and if I use this fix.",
                    "label": 0
                }
            ]
        },
        "clip_84": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "488 we would use for early ages classifier, so before he was here.",
                    "label": 0
                },
                {
                    "sent": "Covariance matrix that I estimate from the data and now I do this modification with gamma is a number between zero and one and this makes a morphing between the estimated covariance matrix and this spherical.",
                    "label": 1
                },
                {
                    "sent": "So if we have, equals zero, then it means we take our.",
                    "label": 0
                },
                {
                    "sent": "Estimated covariance matrix and if gamma is 1.",
                    "label": 0
                },
                {
                    "sent": "Then we take assume this spherical distribution.",
                    "label": 0
                },
                {
                    "sent": "This corresponds to the identity matrix.",
                    "label": 0
                },
                {
                    "sent": "So then we would have as bait vector U2 minus new one.",
                    "label": 0
                },
                {
                    "sent": "And if you remember the introduction to classification, then this is the nearest centroid classifier.",
                    "label": 0
                },
                {
                    "sent": "So this.",
                    "label": 0
                },
                {
                    "sent": "Well, onward shoes, equals zero if one has.",
                    "label": 0
                },
                {
                    "sent": "This is such a amount of data that can reliably estimate the structure of the noise.",
                    "label": 1
                },
                {
                    "sent": "This covariance matrix and we should use it and, equals 1 means we don't have a good estimation of the noise, and it's better not to use any of those.",
                    "label": 0
                },
                {
                    "sent": "But there are also.",
                    "label": 0
                },
                {
                    "sent": "Many",
                    "label": 0
                }
            ]
        },
        "clip_85": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Various in between.",
                    "label": 0
                }
            ]
        },
        "clip_86": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here.",
                    "label": 0
                },
                {
                    "sent": "These values are varied.",
                    "label": 0
                },
                {
                    "sent": "This, between zero and one.",
                    "label": 0
                },
                {
                    "sent": "And here you see the error, so one increases, and the error goes down, down, down, down down and then goes up again.",
                    "label": 0
                },
                {
                    "sent": "So one needs to.",
                    "label": 0
                }
            ]
        },
        "clip_87": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To find the optimal.",
                    "label": 0
                },
                {
                    "sent": "The parimeter here.",
                    "label": 0
                },
                {
                    "sent": "And this depends on the dimensionality of the data and the number of samples you have.",
                    "label": 0
                },
                {
                    "sent": "So there's not A and also how much noise there is so.",
                    "label": 0
                },
                {
                    "sent": "In former Times funded cross validation for many.",
                    "label": 0
                },
                {
                    "sent": "Values of, and then one picks so, with the lowest cross validation.",
                    "label": 0
                }
            ]
        },
        "clip_88": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or um.",
                    "label": 0
                },
                {
                    "sent": "But so Fortunately now there's a analytical method to do it.",
                    "label": 0
                },
                {
                    "sent": "So yes, essentially nothing new, so here's the.",
                    "label": 0
                },
                {
                    "sent": "This.",
                    "label": 0
                },
                {
                    "sent": "Equation for the for this shrinkage.",
                    "label": 0
                },
                {
                    "sent": "So this is the.",
                    "label": 0
                },
                {
                    "sent": "Estimated covariance is identity and we need to.",
                    "label": 0
                },
                {
                    "sent": "Determine this this value.",
                    "label": 0
                }
            ]
        },
        "clip_89": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To do the shrinkage.",
                    "label": 0
                },
                {
                    "sent": "And so the details doesn't matter here, but here's a formula that comes out finally from this paper of little Wolf and chef orange trimmer.",
                    "label": 0
                },
                {
                    "sent": "You can calculate the optimal gamma with this formula.",
                    "label": 0
                },
                {
                    "sent": "That's comparably simple.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And it's yeah, there are few assumptions behind that, but if you remember what happens here, it's quite astonishing that it's possible to calculate this analytically, because so we want to find the best approximation here with the gamma to the true covariance matrix and the Sigma without any sign on top.",
                    "label": 0
                },
                {
                    "sent": "This is a true covariance matrix, and this is.",
                    "label": 0
                },
                {
                    "sent": "This is unknown.",
                    "label": 0
                },
                {
                    "sent": "Of course we don't know it.",
                    "label": 0
                },
                {
                    "sent": "But nevertheless, one can find the camera that's such a tease.",
                    "label": 0
                },
                {
                    "sent": "Sigma Theater of Gamma Best approximates the unknown covariance matrix.",
                    "label": 0
                },
                {
                    "sent": "And there's a very simple formula and you just calculate it and put it in your.",
                    "label": 0
                },
                {
                    "sent": "Pacifier.",
                    "label": 0
                }
            ]
        },
        "clip_90": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this this summarizes what happens.",
                    "label": 0
                },
                {
                    "sent": "We have seen the estimated covariance matrix here with the dashed line.",
                    "label": 0
                },
                {
                    "sent": "This is Sigma head.",
                    "label": 0
                },
                {
                    "sent": "And presumably, if we have not enough data then we overestimate the variance in this long direction.",
                    "label": 0
                },
                {
                    "sent": "So we need to make it more spherical like the grey sphere here.",
                    "label": 0
                },
                {
                    "sent": "Enter that we can do with this.",
                    "label": 0
                },
                {
                    "sent": "What is called shrinkage?",
                    "label": 0
                },
                {
                    "sent": "The Sigma tiller versus parameter, and we can.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "By this formula shown you before we can determine this, stars that gives the best classification error or the optimization work such as this best.",
                    "label": 0
                },
                {
                    "sent": "Patrick Proximates it true, unknown covariance matrix and in most cases then this also gives the best classification error.",
                    "label": 1
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_91": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this was the situation before here we have classification on spatial features for different components and we get this different error rates if we put all features together in this high dimensional feature and we just apply in a naive way LDA, then we get this error rate of 25% which is higher than for the best single components.",
                    "label": 0
                }
            ]
        },
        "clip_92": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But now if we apply this LDA with his shrinkage with his formula, then for this specific data set it works very well.",
                    "label": 1
                },
                {
                    "sent": "And there's only 4% error.",
                    "label": 1
                },
                {
                    "sent": "So now we really increased here.",
                    "label": 0
                },
                {
                    "sent": "Because we've used all this information, we increased and got a smaller classification now.",
                    "label": 0
                },
                {
                    "sent": "So this.",
                    "label": 0
                },
                {
                    "sent": "Mean says this high potential in in going to multivariate signals and also to in particular 2 uses spatial temporal features with much information included.",
                    "label": 0
                },
                {
                    "sent": "But as you've seen you have to be careful in the classification.",
                    "label": 0
                },
                {
                    "sent": "Maybe pure LDA doesn't work very well.",
                    "label": 0
                },
                {
                    "sent": "And if you now go back to the assumptions under which LDA works optimal, we can also see why it was.",
                    "label": 0
                },
                {
                    "sent": "Wrong here, of course there was a service.",
                    "label": 0
                },
                {
                    "sent": "Assumption that we did not discuss so far.",
                    "label": 0
                },
                {
                    "sent": "They said that's a true.",
                    "label": 0
                },
                {
                    "sent": "And distributions are known.",
                    "label": 0
                },
                {
                    "sent": "And of course they are in real application.",
                    "label": 0
                },
                {
                    "sent": "There are never known and if you if your features are too high dimensional then they.",
                    "label": 0
                },
                {
                    "sent": "But your estimate from the data is too far apart from the two covariance matrix, and therefore LDA is not optimal.",
                    "label": 0
                },
                {
                    "sent": "And in order to get back close to optimality, at least you can do this.",
                    "label": 0
                },
                {
                    "sent": "This shrinkage and the good message here is that you can do it quite easily with this simple formula.",
                    "label": 0
                },
                {
                    "sent": "OK um.",
                    "label": 0
                }
            ]
        },
        "clip_93": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So from from this this part I skipped most of upset presentation, but at least I tell you the essence because I announced this before.",
                    "label": 0
                },
                {
                    "sent": "So when you.",
                    "label": 0
                },
                {
                    "sent": "Have a classifier from spatial features and the weight vector can be can be visualized as a topography.",
                    "label": 1
                },
                {
                    "sent": "Since you have your weight for each each channel and this can be visualized and this is a this is a space.",
                    "label": 1
                },
                {
                    "sent": "This is called a spatial filter, but the interpretation of spatial filters.",
                    "label": 0
                },
                {
                    "sent": "Is not so straightforward, so in this case one could look at this and this was a guest from early time interval.",
                    "label": 0
                },
                {
                    "sent": "And here's a strongest weights and most of what happens here in the filter.",
                    "label": 0
                },
                {
                    "sent": "Something here in the back left.",
                    "label": 0
                },
                {
                    "sent": "So one can assume that there's some information exploited from the from the visual area causes over the visual area and these kind of interpretations are very often done also in papers that they look at spatial filters and say these are the highest weights.",
                    "label": 0
                },
                {
                    "sent": "So that means the classifier exploits signals from here.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_94": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But this is not necessarily the case and so I don't.",
                    "label": 0
                },
                {
                    "sent": "Give you the full presentation, but at least one example that shows you that is.",
                    "label": 0
                },
                {
                    "sent": "This is not necessarily true, so in this example we assume that we have two.",
                    "label": 0
                },
                {
                    "sent": "Two sources in the brain sources, one and S2, and now these are.",
                    "label": 0
                },
                {
                    "sent": "Um, projected to the to the e.g signals that we measure with these two patterns A1 and A2.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "So now we want to find the spatial filter, so this is a 2 dimensional vector.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Where we, for example, want to recover source one?",
                    "label": 0
                },
                {
                    "sent": "So usually you have one source that you are interested in that makes it discrimination between the task and another interference.",
                    "label": 0
                },
                {
                    "sent": "So if we want to have a spatial, so applying a spatial filter W onto this.",
                    "label": 1
                },
                {
                    "sent": "X This is a easy data that we observe, so we don't know how this is composed.",
                    "label": 1
                },
                {
                    "sent": "So if we apply this to X.",
                    "label": 1
                },
                {
                    "sent": "Then this goes linear like this, so this in this source space that we don't know these spatial filters applied to the first component into the second component.",
                    "label": 0
                },
                {
                    "sent": "So now we can discriminate 2 cases about this propagation vectors of the sources.",
                    "label": 1
                },
                {
                    "sent": "So either these are orthogonal.",
                    "label": 0
                },
                {
                    "sent": "That means this product is 0, so the vectors are perpendicular and this product is 0.",
                    "label": 0
                },
                {
                    "sent": "And in this case, when we choose our spatial filter WS A1, then this is this is fine.",
                    "label": 0
                },
                {
                    "sent": "So then here we would have a one times a one, so this isn't the norm of a one.",
                    "label": 0
                },
                {
                    "sent": "This is a positive value.",
                    "label": 0
                },
                {
                    "sent": "And here if we put in a one here we have a one transpose times a two and this is 0.",
                    "label": 0
                },
                {
                    "sent": "So second source cancels out.",
                    "label": 0
                },
                {
                    "sent": "We only have source one time some factor.",
                    "label": 0
                },
                {
                    "sent": "So then so in this case.",
                    "label": 1
                },
                {
                    "sent": "Be choosing the space of filter axis is very nice, but.",
                    "label": 0
                },
                {
                    "sent": "So typically these are not not orthogonal.",
                    "label": 0
                },
                {
                    "sent": "This is very special case and then if we want to recover source S1 then we need to choose this this filter such that these interfering sources cancelled out.",
                    "label": 0
                },
                {
                    "sent": "So we need to cancel this out.",
                    "label": 0
                },
                {
                    "sent": "So we need to choose W subset W transpose times a two is 0.",
                    "label": 0
                },
                {
                    "sent": "This cancels out and we only have this.",
                    "label": 0
                },
                {
                    "sent": "But the interesting point here, and for that you don't need this math, is that in order to to extract these source one, we need to choose the filter W in a way that only depends on A2 and S2.",
                    "label": 0
                },
                {
                    "sent": "So this only depends on the interference.",
                    "label": 0
                },
                {
                    "sent": "So that means if we go Kopec so this is.",
                    "label": 0
                }
            ]
        },
        "clip_95": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Like visualization of W. And if you make an interpretation of this, it may be.",
                    "label": 0
                },
                {
                    "sent": "This more reflects the interference and noise and the signal you are actually interested in.",
                    "label": 0
                },
                {
                    "sent": "So it could be that we're not classifying on a signal from visual cortex, and I think in this case it's really versus spatial filter for the PS3 component which comes from the central area here.",
                    "label": 0
                },
                {
                    "sent": "And it just needs to cancel out the interference from from visual cortex.",
                    "label": 0
                },
                {
                    "sent": "Therefore it has the weights here.",
                    "label": 0
                },
                {
                    "sent": "So in this.",
                    "label": 0
                }
            ]
        },
        "clip_96": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Says the W only depends on a 2 interfering source, but not at all on the signal itself.",
                    "label": 0
                },
                {
                    "sent": "So this is maybe extreme so, but usually in spatial filters you have both aspects.",
                    "label": 0
                },
                {
                    "sent": "You have weights that correspond to the signal and weights it cause.",
                    "label": 0
                }
            ]
        },
        "clip_97": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Come to the to the noise.",
                    "label": 0
                },
                {
                    "sent": "So and this just says it, S1 is a cognitive P3 component and as two is interference from the visual area in order to.",
                    "label": 1
                },
                {
                    "sent": "To extract information about CP3 component, it could be that your filter only depends on.",
                    "label": 0
                },
                {
                    "sent": "On the interference.",
                    "label": 0
                },
                {
                    "sent": "And this one cannot.",
                    "label": 0
                }
            ]
        },
        "clip_98": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To see in in simulations.",
                    "label": 0
                },
                {
                    "sent": "You need in order to get a good classifier, you need also information or you can explode poet information from areas that are not this informative.",
                    "label": 0
                }
            ]
        },
        "clip_99": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in this case.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I have two distributions.",
                    "label": 0
                },
                {
                    "sent": "CPS at and FC set.",
                    "label": 0
                },
                {
                    "sent": "PC component and then I made a simulation where I added some interference from the visual areas or yeah, simulated Alpha rhythm and I edit this.",
                    "label": 0
                },
                {
                    "sent": "This point 4 factor on CPU set and this factor .2 on FC set and this obviously has nothing to do with the target non target discrimination.",
                    "label": 0
                }
            ]
        },
        "clip_100": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So then.",
                    "label": 0
                },
                {
                    "sent": "Because then we look again at the same scatter plot.",
                    "label": 0
                },
                {
                    "sent": "Now we have much more noise due to this interference.",
                    "label": 0
                },
                {
                    "sent": "If we classify here, the error is 15%.",
                    "label": 0
                },
                {
                    "sent": "If we classify here error is 33%.",
                    "label": 0
                },
                {
                    "sent": "But if I add here to this classification, the channel ozette.",
                    "label": 0
                },
                {
                    "sent": "And the classifier can use also information from ozette.",
                    "label": 0
                },
                {
                    "sent": "Then one obtains again 16% error.",
                    "label": 0
                },
                {
                    "sent": "So then we again have success here.",
                    "label": 0
                },
                {
                    "sent": "All those what I added here was just noise, so that has no information about both the task.",
                    "label": 0
                },
                {
                    "sent": "But it has exactly this kind of noise that makes a problem here, and therefore I can use this noise to subtractive boots.",
                    "label": 0
                },
                {
                    "sent": "In a way, it's it's it's obvious thing, so I need to subtract this noise, so I need this channel, but this is important for interpretations or the the classifier would depend on this channel or that although it has no information in itself.",
                    "label": 0
                }
            ]
        },
        "clip_101": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There's one.",
                    "label": 0
                },
                {
                    "sent": "Paper here single trial analysis and classification of ERP components or several parts of this presentation are more or less described there, so this is.",
                    "label": 0
                },
                {
                    "sent": "A bit more high levels.",
                    "label": 0
                },
                {
                    "sent": "So this is like the more high level part of the.",
                    "label": 0
                },
                {
                    "sent": "Presentation.",
                    "label": 0
                },
                {
                    "sent": "Mr Shrinkage and also I prepared with some some colleagues more LAX is gentle introduction style with the univariate features and more more basic and this will also be submitted soon and.",
                    "label": 0
                },
                {
                    "sent": "And you can also read this in the paper.",
                    "label": 0
                },
                {
                    "sent": "OK so no questions anymore then.",
                    "label": 0
                },
                {
                    "sent": "I thank you for your attention.",
                    "label": 0
                },
                {
                    "sent": "We will have a short coffee break and then we start with the lecture of Peter December.",
                    "label": 0
                },
                {
                    "sent": "Think.",
                    "label": 0
                }
            ]
        }
    }
}