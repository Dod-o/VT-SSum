{
    "id": "tfilivindj5nfg7iutyhxx6rysyjoa5w",
    "title": "Stochastic optimization with non-i.id. noise",
    "info": {
        "author": [
            "Alekh Agarwal, Microsoft Research"
        ],
        "published": "Jan. 25, 2012",
        "recorded": "December 2011",
        "category": [
            "Top->Computer Science->Optimization Methods->Stochastic Optimization"
        ]
    },
    "url": "http://videolectures.net/nipsworkshops2011_agarwal_noise/",
    "segmentation": [
        [
            "OK, so this is joint work with John Duchi and we're going to be interested in doing solving stochastic optimization problems where the noise processes non."
        ],
        [
            "ID So what do we mean by that?",
            "We are interested in solving minimizing convex functions, but the functions are not just given to us.",
            "The functions are defined as an expectation over some random process, and these capital F's are going to denote the random functions whose role is going to become clear in a moment.",
            "But this is sort of the standard stochastic optimization setting where you don't have access directly to F, But you get some noisy information about the function.",
            "So for instance.",
            "You could have a function F and maybe you're trying to run gradient descent on the function and you would like to your at a point X one you would like to know the gradient of F at X1.",
            "What you see is not the gradient of F, but maybe you see one of these two red dotted lines which you can think of as the gradient of a noisy version of the function F and.",
            "This is a.",
            "This is a well studied problem, except that most most or a lot of the work would make crit."
        ],
        [
            "Assumption that.",
            "This distribution pie that is defining the expectation we gotta be able to sample IID from it.",
            "So what I mean by that is that OK?",
            "So we."
        ],
        [
            "The point X one we see the random gradient at X1 and we take a take a step based on that gradient.",
            "Maybe we get to this point X2 and then we see another random gradient, this time with the noise variable Omega two.",
            "So Omegas are going to denote the randomness that I'm observing and what the standard theory would often demand.",
            "Is that Omega one, Omega two should be independent of each other and should have the same distribution, namely, they should both be sampled from the distribution \u03c0."
        ],
        [
            "And the question that we want to ask in the stock is what if one of these two assumptions is violated?",
            "So what if by such a distribution that you cannot sample from, so I could be a distribution over some high dimensional combinatorial space and you just can't sample from it.",
            "Or it could be that IID samples are just not available due to whatever underlying noise generating process there is.",
            "And how do you do stochastic optimization when that's the source of randomness in your gradients or in your function value estimates?",
            "And so on."
        ],
        [
            "So one sort of natural approach that you might try or a lot of people familiar with the literature might think of is that of online convex optimization.",
            "This is a very nice formalism, 'cause it just assumes that you have an arbitrary sequence of functions, and these functions the.",
            "If you parameterized these functions again with Omega T, just like we did in the stochastic case, we do not need to assume any stochastic structure on the Omega, so omegas do not need to be ID, they do not.",
            "Need to have any statistical structure at all, but of course then the nature of guarantees that you can prove on such an optimization procedure changes.",
            "So in particular people will show that this quantity called a regret, which is your cumulative loss at the .60, that you're playing, is close to the minimum of the sum of the function values, and that's great."
        ],
        [
            "But if at the end of the day you're interested in solving the stochastic optimization problem."
        ],
        [
            "You got to ask what happens if if I solve this problem, does it give me something for the stochastic optimization problem.",
            "So this question has been looked at both in both in the optimization literature and in the more recent machine learning and online learning literature."
        ],
        [
            "And sort of the most accessible answer can be found in the very nice work of just Bianchi and Co.",
            "Authors who show that any algorithm that has a low value for this regret quantity will have a low optimization error on the expected function F, But when the noise variables are sampled IID according to \u03c0.",
            "So again you have the same issue that when you have IID noise, everything is kind of well understood.",
            "But what happens when one of these sampling assumptions breaks an?",
            "The the thing that motivates this war."
        ],
        [
            "Is that the breaking of the idea?",
            "Assumption is not that hard to imagine actually, so non IID noise just arises naturally in several different contexts.",
            "If you're doing stochastic optimization over data that comes from a time series or financial market, or you're solving a robotics problem where the robot, the position of the robot at time T and T + 1 is usually very heavily correlated, you're trying to optimize the parameters of a dynamical system.",
            "All these problems dependence is just very natural.",
            "Parameters and as I mentioned before, if you're trying to solve optimization problems over combinatorial spaces, you just can sample from the desired distribution Pi quite often, even if you were able, if you wanted to draw independent samples, that's just not possible in a computationally feasible manner quite often."
        ],
        [
            "So.",
            "Before before I kind of go into a bit more details, I'll just take a single slide to set up some notation.",
            "Formal setup is going to be that we have some stochastic process PT that describes the state of our random process at time T, and we have a noise sequence Omega one through T, which is, which are the samples drawn from this.",
            "From running this stochastic process.",
            "Now, of course, if this process P is again completely ill behaved, then doing stochastic optimization with it.",
            "Becomes a little less meaningful and a little harder, so we'll assume some regularity for it, and in particular will.",
            "It's gotta be related to the underlying distribution Pi that we're interested in in some way, so we're going to assume that the process PT converges to \u03c0 in a certain sense.",
            "So to see the simplest example of that sense for the first ID scenario, the classical scenario, you can just set PT to be equal to \u03c0 at each and every stage, and all the samples are drawn IID, so their PT is just equal to \u03c0, so this is.",
            "This statement is trivially true, but in a more general."
        ],
        [
            "Interesting case will assume the notion of so called free mixing and what that says is not all the notation, so I'll just describe it in words.",
            "If you take your stochastic process, you condition it up to the randomness at time T, and then you ask what is the distribution of my noise variables at at time T + K conditioning on time T an I want to ask in particular, how close is that distribution to pie in the sense of total variation distance.",
            "So then I want a uniform bound overall.",
            "All times T for this quantity.",
            "So this coefficient kind of tries to capture how fast sort of the correlations or the dependence in my process decay.",
            "And if I start the process and let it run for a few steps, does the distribution start looking similar to the stationary distribution Pi after a few steps, and in particular, if you look at the at this point that we just visited for the ID case, then just by simply substituting into the definition of fee, you can see that few of one is always going to be 0.",
            "For IID sampling, 'cause this distribution PT plus one condition Don T is just going to be equal to \u03c0 in that case.",
            "But we're going to be interested in a bit bit more exciting examples so."
        ],
        [
            "Let's see the first example.",
            "This is a very simple distributed optimization algorithm that was proposed in online by Michaela Johansson and coauthors an.",
            "The idea is that they have a distributed network of nodes, and each node has an associated convex function FI, and the goal is to try and minimize the average of these functions OK, and the way they do it is they say, OK, we're going to run a random walk on this graph, and there's going to be a token ID that moves according to the random walk.",
            "So you can now think of each functions.",
            "Each function FI as this capital F but index with the variable I and now capital F index with a variable.",
            "It will kind of correspond to the random function that I'm interested in, so they will."
        ],
        [
            "Run this random walk on the graph.",
            "Now you can design A suitable random walk such that the process PT converges to the uniform distribution over nodes and Moreover it you can design A process as that.",
            "This happens at a geometric rate, so the process converges exponentially fast, so I'm not going to again this.",
            "This convergence is going to depend on the properties of the random walk, but I'm not going to go into the details of that.",
            "Just want you to realize that this this fee coefficient is not interesting.",
            "Only for the ideal scenarios, but is going to be also computable in lots of other cases."
        ],
        [
            "And now they run a very simple algorithm.",
            "They say, OK, we're interested in optimizing this function F. What we're going to do is we're going to take the current token it so we're going to take whichever node we are on.",
            "Right now, we're going to evaluate the gradient there, and we're going to just take a gradient step at that node's gradient.",
            "So this is just a completely local gradient.",
            "This is this is not an IED stochastic sampling anymore, and for instance our theory is going to help understand convergence of algorithms such as this."
        ],
        [
            "Another very simple example you can think of is you just have data coming from an autoregressive process, so this is a dependent noise process where at time T you're unavailable is generated by taking random variable at time T -- 1, hitting it with some matrix A and then adding some ID noisy to it.",
            "And if you run this process for long enough under some regularity conditions on a, the process will converge to a stationary distribution Pi.",
            "Again that people know how to compute an.",
            "This is a natural model in a lot of cases for.",
            "Time series or dynamical systems, and so on.",
            "And you can imagine very easily where such scenarios might arise.",
            "So you can have regression problems, for instance where the where your coefficient vectors are evolving according to an autoregressive process and the labels are coming just according to the linear model.",
            "And then you're trying to minimize the least squares loss on the sequence of non IID data.",
            "And in order to minimize this again you need to solve the.",
            "Stochastic optimization problem with non IID sampling.",
            "OK so just that's just some brief motivation of why we are interested in these problem."
        ],
        [
            "To convince you that they are actually realistic now we're not going to talk about just one specific algorithm that works for this problem, but we're going to give you a whole class of algorithms that actually work well on these problems.",
            "For for these stochastic optimization problems, so we're going to take a class of online learning algorithms.",
            "The same sort of algorithms that I talked about before, which do not assume any statistical structure on the noise sequence, and we're going to assume that in particular this is a low regret.",
            "Online algorithm so we know some bound on what they regret is going to be after running the process 40 steps.",
            "So this is a fairly mild condition because for almost all interesting algorithms that people have, they have actually studied such regret bounds.",
            "One additional assumption we're going to make is that the algorithm is stable in the sense that it iterates do not change much from round to round, and again, this is not a very restrictive assumption because for a lot of algorithms, in order to establish the first guarantee, you kind of go through the second one, either explicitly or implicitly so.",
            "Subs."
        ],
        [
            "I got confused.",
            "So here's the thing, we want to estimate, not time.",
            "Area know the you want to.",
            "You want to optimize the expected function at the end of the day under the stationary distribution of the process.",
            "But the but the you are the data you're receiving is right.",
            "So you have your fixed parameter, but you're receiving an eye."
        ],
        [
            "The data OK and just to give you example that this class of algorithms is interesting.",
            "For instance, two very common algorithms that fall into this framework are online gradient descent and regularise dual averaging.",
            "Both of them have found a lot of use in machine learning recently."
        ],
        [
            "OK, so with this I I can now state our first result, so we assume that we have iterates X, one through D coming from a stable online algorithm.",
            "We take the average of these iterates and what we prove is that this average can optimize the function F's.",
            "In particular, the optimization error is bounded by the sum of three terms.",
            "The first term is just the average regret of the online algorithm, so your error at the average is bounded by the average regret.",
            "The second term is a deviation term cause this is going to be.",
            "This is a random process, so the bound is going to hold with high probability and the second term depends on how higher probability you wanted to hold with and the third term is really the one that comes up due to the non ID nature of the sequence and comprises of 2 two parts, 1 being the average stability of the online algorithm.",
            "So here we see that stability is kind of crucial for this part and the second one that reflects the how fast the process mixes so.",
            "Again, that reflects that how the correlations in the process might come and hurt you.",
            "Copper is the stability of the online algorithm, the how much your exchange between two successive rounds.",
            "We'll see, we'll see it in a couple of slides, so I'm going to actually show you specific bound."
        ],
        [
            "And the first time we reject you can do is to plug type equals one and five.",
            "We called sphere of one is equal to 0 for IID sampling, which recovers the bound that was derived by just Bianchi and Co authors and by many other people in stochastic optimization.",
            "For for ID sampling.",
            "Because this term just goes away, this term becomes 1 / 1 over log one over Delta, and that's exactly the bond that was known before.",
            "OK, now as Ben asked what this has too many algorithm dependent.",
            "Amateur, so how do we actually make some sense?"
        ],
        [
            "Out of this bound well, we do it by plugging in specific examples.",
            "So if we take the algorithm to be online, gradient descent or regularize, dual averaging then and take the step size that decays as 1 / sqrt T, then it's known for these algorithms that they regret grows a square root T the disability decays as one over root tea, and just by plugging quantities in you see that you kind of have this one over root tea style convergence rate.",
            "Although I'd be lying if it, I'd say it's one over root cause the first 2 terms are really only order.",
            "Now, but the third term can actually be significantly bigger and depends on the mixing properties of your process, and in particular, it might seem like this term can actually blow up as T goes to Infinity.",
            "Well, don't worry about that part, because as long as you're assured that fee of K goes to zero and K goes to Infinity.",
            "And be shown with a little work that we always have almost sure convergence for stochastic optimization for these algorithms, But in particular, again, this is still a bit hard to make sense out of because there is this fear of Tau quantity sitting here, and we don't quite understand it, or at least when I first got it, I didn't understand it.",
            "So what we do is."
        ],
        [
            "We make some more assumptions.",
            "We take a particular instance of the mixing rate.",
            "We assume that the mixing happens geometrically.",
            "An everything becomes very nice.",
            "We up to this locked factor.",
            "We essentially recover the same rate that we had for IID sampling.",
            "We have basically order log two over root convergence, and this is the rate for IID sampling.",
            "So we see that for things like the Markov chain example, we saw a few slides earlier, and then I'll recap.",
            "In a minute we actually do not have any significant penalty for having this non IID data, but let's not fool you.",
            "There will be cases where you will not be able to get to \u20b91 rate where the rate will be significantly slower if the mixing properties of the process are bad, but that's not on there."
        ],
        [
            "Under for today, so we can actually test this empirically.",
            "We ran an autoregressive process on a least squares regression problem.",
            "The optimization algorithm, I believe online gradient descent and this is the expected convergence.",
            "These are the deviations around the expectation.",
            "We see that it does seem to converge and maybe with some imagination you could see that this looks kind of like 1 route.",
            "I'm not going to put my money on that part, not yet anyways, OK?"
        ],
        [
            "So, so that's good.",
            "Let's go back to this Markov chain example and see how."
        ],
        [
            "Fits into the framework so."
        ],
        [
            "And recall we have these local functions have eyes.",
            "We are running a random walk.",
            "We receive a stochastic gradient according to the token of the random walk and."
        ],
        [
            "And.",
            "Now we now we just see that oh, this Markov gradient descent is actually just running online gradient descent on a sequence of non iid gradients, right?",
            "So the stability of online gradient descent and low regret guarantee just directly imply that everything is going to work an just plugging this into our rates of convergence and using the fact that a Markov chain mixes exponentially fast, we get a very simple regret bound, very simple convergence rate.",
            "That goes is 100 T, but depends on the spectral properties of the graph.",
            "So in particular, again, you can test this empirically and this is a.",
            "This is a pretty quantitative."
        ],
        [
            "Addiction so we ran this algorithm for different network topologies for different graph graph layouts and what we observed was that the convergence of the algorithm was fastest for expander graphs last four cycles, and this is.",
            "This makes sense because the mixing properties of random walk our best on expanders inversion cycles OK."
        ],
        [
            "And now, just before I drop of one last thing I want to introduce is what happens when we have more structure.",
            "So a common thing in optimization is to make some curvature isms function.",
            "And then people can typically show that the rates of convergence are fast and this is interesting in machine learning cause this arises in all kinds of regularised problems like regularise SVM, regression, and so on.",
            "And what we can show is that even with non iid noise you do not lose the gains that come with added curvature."
        ],
        [
            "Functions, so use assuming that the sample functions capital F are strongly convex.",
            "For instance, you can argue that online gradient descent and regularize dual averaging have one.",
            "I have a log P regret guarantee and using that, and you know doing some doing some more hard work you can actually show the process kind of looks like one on T convergence rate model over to factor, and again there is this T5 to factor in this case.",
            "This is like the root T5 now we had before.",
            "But what we can see."
        ],
        [
            "Very quickly from this bound is that in general it's going to be faster than the one root bound we get for convex losses.",
            "If we set our equals one and fear of 1 = 0 before as before, this term kind of goes away.",
            "So we only have one Auntie style or log tiante style convergence rate.",
            "And if we make the geometric mixing assumption as before, we get almost as good rates as we get Friday mixing one more."
        ],
        [
            "Our extension that I quickly want to mention is that a lot of problems of interest in machine learning unfortunately do not satisfy strong convexity because they have this structure that they involve a loss in applied to a linear form to a dot product such as least squares regression logistic regression."
        ],
        [
            "Boosting and so on and it just cannot be strongly convex in this scenarios cause it only contains One Direction, so you can't have curvature in all directions, which is a pretty big cause.",
            "Often this loss function L the scalar loss itself is strongly convex in its scalar parameter, and we kind of want to use that curvature.",
            "And what we can actually show is that we do get fast rates.",
            "One Auntie style rates.",
            "Even in this case, although in this case the story is not quite as simple, the standard algorithms don't quite satisfy the assumptions that we need and.",
            "We need to make a slight tweak to the existing algorithms, but it's still close enough and has the same computational cost.",
            "Unfortunately, the details of this take some time to set up, so I won't go."
        ],
        [
            "So that today?",
            "OK, so to wrap up, we saw at a very fast pace.",
            "Today convergence rates for stochastic optimization with non IID data.",
            "The nice part is that the theory does not apply just one algorithm, but to a large class of stable online algorithms, which includes things like gradient descent and dual averaging.",
            "The analysis covers a large class of mixing processes.",
            "Free mixing processes are very well studies in the Markov chain, literature and results.",
            "Just reply to them.",
            "In particular, we see that we have similar rates as I did it under geometric mixing, and we saw fast rates for strongly convex objectives and under linear."
        ],
        [
            "Action we can we weaken the mixing assumptions even further, and the paper.",
            "I can't remember the workshop version or not, but the long version definitely talks about weaker mixing conditions and how you can still prove similar results.",
            "And we also consider a lot of other applications for stochastic optimization with non.",
            "I."
        ],
        [
            "The noise and the long free prints are available online.",
            "If you want to take a look, thanks.",
            "Can you say something about the case where CX represents para meters over graphical model and fine depends actually on X, so that's very good question.",
            "That's kind of.",
            "Formally, the the assumption we're making here is that the noise process, even though it has dependence, it's exogenous noise.",
            "It does not depend on your current parameter and the moment you have that.",
            "Things become very very different because kind of here we use martingale techniques and you just can't use them anymore.",
            "So it's something that's on our plate that we would like to look at in future work, but we haven't done so far.",
            "So.",
            "Sample ID from the distribution with.",
            "Exactly, and that's that's one scenario to which these results will apply quite often because people have studied cases under which murder.",
            "Testing samplers will satisfy free mixing orbital mixing conditions in particular instance so one."
        ],
        [
            "Example we talked about in the paper is learning a ranking function from partially ordered samples where you might want to sample from the set of permutations that are consistent with some observed partial orders and that sort of set that's hard to sample from, but it's known how to design Markov chains that converge to the uniform distribution over that set, and we can just directly apply results to such things.",
            "For instance.",
            "Yes, that's that's a very interesting application for us."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so this is joint work with John Duchi and we're going to be interested in doing solving stochastic optimization problems where the noise processes non.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "ID So what do we mean by that?",
                    "label": 0
                },
                {
                    "sent": "We are interested in solving minimizing convex functions, but the functions are not just given to us.",
                    "label": 0
                },
                {
                    "sent": "The functions are defined as an expectation over some random process, and these capital F's are going to denote the random functions whose role is going to become clear in a moment.",
                    "label": 0
                },
                {
                    "sent": "But this is sort of the standard stochastic optimization setting where you don't have access directly to F, But you get some noisy information about the function.",
                    "label": 0
                },
                {
                    "sent": "So for instance.",
                    "label": 0
                },
                {
                    "sent": "You could have a function F and maybe you're trying to run gradient descent on the function and you would like to your at a point X one you would like to know the gradient of F at X1.",
                    "label": 0
                },
                {
                    "sent": "What you see is not the gradient of F, but maybe you see one of these two red dotted lines which you can think of as the gradient of a noisy version of the function F and.",
                    "label": 0
                },
                {
                    "sent": "This is a.",
                    "label": 0
                },
                {
                    "sent": "This is a well studied problem, except that most most or a lot of the work would make crit.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Assumption that.",
                    "label": 0
                },
                {
                    "sent": "This distribution pie that is defining the expectation we gotta be able to sample IID from it.",
                    "label": 0
                },
                {
                    "sent": "So what I mean by that is that OK?",
                    "label": 0
                },
                {
                    "sent": "So we.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The point X one we see the random gradient at X1 and we take a take a step based on that gradient.",
                    "label": 0
                },
                {
                    "sent": "Maybe we get to this point X2 and then we see another random gradient, this time with the noise variable Omega two.",
                    "label": 0
                },
                {
                    "sent": "So Omegas are going to denote the randomness that I'm observing and what the standard theory would often demand.",
                    "label": 0
                },
                {
                    "sent": "Is that Omega one, Omega two should be independent of each other and should have the same distribution, namely, they should both be sampled from the distribution \u03c0.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the question that we want to ask in the stock is what if one of these two assumptions is violated?",
                    "label": 1
                },
                {
                    "sent": "So what if by such a distribution that you cannot sample from, so I could be a distribution over some high dimensional combinatorial space and you just can't sample from it.",
                    "label": 0
                },
                {
                    "sent": "Or it could be that IID samples are just not available due to whatever underlying noise generating process there is.",
                    "label": 1
                },
                {
                    "sent": "And how do you do stochastic optimization when that's the source of randomness in your gradients or in your function value estimates?",
                    "label": 0
                },
                {
                    "sent": "And so on.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So one sort of natural approach that you might try or a lot of people familiar with the literature might think of is that of online convex optimization.",
                    "label": 1
                },
                {
                    "sent": "This is a very nice formalism, 'cause it just assumes that you have an arbitrary sequence of functions, and these functions the.",
                    "label": 1
                },
                {
                    "sent": "If you parameterized these functions again with Omega T, just like we did in the stochastic case, we do not need to assume any stochastic structure on the Omega, so omegas do not need to be ID, they do not.",
                    "label": 0
                },
                {
                    "sent": "Need to have any statistical structure at all, but of course then the nature of guarantees that you can prove on such an optimization procedure changes.",
                    "label": 0
                },
                {
                    "sent": "So in particular people will show that this quantity called a regret, which is your cumulative loss at the .60, that you're playing, is close to the minimum of the sum of the function values, and that's great.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But if at the end of the day you're interested in solving the stochastic optimization problem.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You got to ask what happens if if I solve this problem, does it give me something for the stochastic optimization problem.",
                    "label": 0
                },
                {
                    "sent": "So this question has been looked at both in both in the optimization literature and in the more recent machine learning and online learning literature.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And sort of the most accessible answer can be found in the very nice work of just Bianchi and Co.",
                    "label": 0
                },
                {
                    "sent": "Authors who show that any algorithm that has a low value for this regret quantity will have a low optimization error on the expected function F, But when the noise variables are sampled IID according to \u03c0.",
                    "label": 1
                },
                {
                    "sent": "So again you have the same issue that when you have IID noise, everything is kind of well understood.",
                    "label": 0
                },
                {
                    "sent": "But what happens when one of these sampling assumptions breaks an?",
                    "label": 0
                },
                {
                    "sent": "The the thing that motivates this war.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is that the breaking of the idea?",
                    "label": 0
                },
                {
                    "sent": "Assumption is not that hard to imagine actually, so non IID noise just arises naturally in several different contexts.",
                    "label": 1
                },
                {
                    "sent": "If you're doing stochastic optimization over data that comes from a time series or financial market, or you're solving a robotics problem where the robot, the position of the robot at time T and T + 1 is usually very heavily correlated, you're trying to optimize the parameters of a dynamical system.",
                    "label": 0
                },
                {
                    "sent": "All these problems dependence is just very natural.",
                    "label": 0
                },
                {
                    "sent": "Parameters and as I mentioned before, if you're trying to solve optimization problems over combinatorial spaces, you just can sample from the desired distribution Pi quite often, even if you were able, if you wanted to draw independent samples, that's just not possible in a computationally feasible manner quite often.",
                    "label": 1
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Before before I kind of go into a bit more details, I'll just take a single slide to set up some notation.",
                    "label": 0
                },
                {
                    "sent": "Formal setup is going to be that we have some stochastic process PT that describes the state of our random process at time T, and we have a noise sequence Omega one through T, which is, which are the samples drawn from this.",
                    "label": 1
                },
                {
                    "sent": "From running this stochastic process.",
                    "label": 0
                },
                {
                    "sent": "Now, of course, if this process P is again completely ill behaved, then doing stochastic optimization with it.",
                    "label": 0
                },
                {
                    "sent": "Becomes a little less meaningful and a little harder, so we'll assume some regularity for it, and in particular will.",
                    "label": 0
                },
                {
                    "sent": "It's gotta be related to the underlying distribution Pi that we're interested in in some way, so we're going to assume that the process PT converges to \u03c0 in a certain sense.",
                    "label": 0
                },
                {
                    "sent": "So to see the simplest example of that sense for the first ID scenario, the classical scenario, you can just set PT to be equal to \u03c0 at each and every stage, and all the samples are drawn IID, so their PT is just equal to \u03c0, so this is.",
                    "label": 0
                },
                {
                    "sent": "This statement is trivially true, but in a more general.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Interesting case will assume the notion of so called free mixing and what that says is not all the notation, so I'll just describe it in words.",
                    "label": 0
                },
                {
                    "sent": "If you take your stochastic process, you condition it up to the randomness at time T, and then you ask what is the distribution of my noise variables at at time T + K conditioning on time T an I want to ask in particular, how close is that distribution to pie in the sense of total variation distance.",
                    "label": 1
                },
                {
                    "sent": "So then I want a uniform bound overall.",
                    "label": 0
                },
                {
                    "sent": "All times T for this quantity.",
                    "label": 0
                },
                {
                    "sent": "So this coefficient kind of tries to capture how fast sort of the correlations or the dependence in my process decay.",
                    "label": 0
                },
                {
                    "sent": "And if I start the process and let it run for a few steps, does the distribution start looking similar to the stationary distribution Pi after a few steps, and in particular, if you look at the at this point that we just visited for the ID case, then just by simply substituting into the definition of fee, you can see that few of one is always going to be 0.",
                    "label": 0
                },
                {
                    "sent": "For IID sampling, 'cause this distribution PT plus one condition Don T is just going to be equal to \u03c0 in that case.",
                    "label": 0
                },
                {
                    "sent": "But we're going to be interested in a bit bit more exciting examples so.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's see the first example.",
                    "label": 0
                },
                {
                    "sent": "This is a very simple distributed optimization algorithm that was proposed in online by Michaela Johansson and coauthors an.",
                    "label": 0
                },
                {
                    "sent": "The idea is that they have a distributed network of nodes, and each node has an associated convex function FI, and the goal is to try and minimize the average of these functions OK, and the way they do it is they say, OK, we're going to run a random walk on this graph, and there's going to be a token ID that moves according to the random walk.",
                    "label": 0
                },
                {
                    "sent": "So you can now think of each functions.",
                    "label": 0
                },
                {
                    "sent": "Each function FI as this capital F but index with the variable I and now capital F index with a variable.",
                    "label": 0
                },
                {
                    "sent": "It will kind of correspond to the random function that I'm interested in, so they will.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Run this random walk on the graph.",
                    "label": 0
                },
                {
                    "sent": "Now you can design A suitable random walk such that the process PT converges to the uniform distribution over nodes and Moreover it you can design A process as that.",
                    "label": 0
                },
                {
                    "sent": "This happens at a geometric rate, so the process converges exponentially fast, so I'm not going to again this.",
                    "label": 0
                },
                {
                    "sent": "This convergence is going to depend on the properties of the random walk, but I'm not going to go into the details of that.",
                    "label": 0
                },
                {
                    "sent": "Just want you to realize that this this fee coefficient is not interesting.",
                    "label": 0
                },
                {
                    "sent": "Only for the ideal scenarios, but is going to be also computable in lots of other cases.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And now they run a very simple algorithm.",
                    "label": 0
                },
                {
                    "sent": "They say, OK, we're interested in optimizing this function F. What we're going to do is we're going to take the current token it so we're going to take whichever node we are on.",
                    "label": 0
                },
                {
                    "sent": "Right now, we're going to evaluate the gradient there, and we're going to just take a gradient step at that node's gradient.",
                    "label": 0
                },
                {
                    "sent": "So this is just a completely local gradient.",
                    "label": 0
                },
                {
                    "sent": "This is this is not an IED stochastic sampling anymore, and for instance our theory is going to help understand convergence of algorithms such as this.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Another very simple example you can think of is you just have data coming from an autoregressive process, so this is a dependent noise process where at time T you're unavailable is generated by taking random variable at time T -- 1, hitting it with some matrix A and then adding some ID noisy to it.",
                    "label": 0
                },
                {
                    "sent": "And if you run this process for long enough under some regularity conditions on a, the process will converge to a stationary distribution Pi.",
                    "label": 0
                },
                {
                    "sent": "Again that people know how to compute an.",
                    "label": 0
                },
                {
                    "sent": "This is a natural model in a lot of cases for.",
                    "label": 0
                },
                {
                    "sent": "Time series or dynamical systems, and so on.",
                    "label": 1
                },
                {
                    "sent": "And you can imagine very easily where such scenarios might arise.",
                    "label": 0
                },
                {
                    "sent": "So you can have regression problems, for instance where the where your coefficient vectors are evolving according to an autoregressive process and the labels are coming just according to the linear model.",
                    "label": 0
                },
                {
                    "sent": "And then you're trying to minimize the least squares loss on the sequence of non IID data.",
                    "label": 0
                },
                {
                    "sent": "And in order to minimize this again you need to solve the.",
                    "label": 0
                },
                {
                    "sent": "Stochastic optimization problem with non IID sampling.",
                    "label": 0
                },
                {
                    "sent": "OK so just that's just some brief motivation of why we are interested in these problem.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To convince you that they are actually realistic now we're not going to talk about just one specific algorithm that works for this problem, but we're going to give you a whole class of algorithms that actually work well on these problems.",
                    "label": 0
                },
                {
                    "sent": "For for these stochastic optimization problems, so we're going to take a class of online learning algorithms.",
                    "label": 0
                },
                {
                    "sent": "The same sort of algorithms that I talked about before, which do not assume any statistical structure on the noise sequence, and we're going to assume that in particular this is a low regret.",
                    "label": 0
                },
                {
                    "sent": "Online algorithm so we know some bound on what they regret is going to be after running the process 40 steps.",
                    "label": 0
                },
                {
                    "sent": "So this is a fairly mild condition because for almost all interesting algorithms that people have, they have actually studied such regret bounds.",
                    "label": 0
                },
                {
                    "sent": "One additional assumption we're going to make is that the algorithm is stable in the sense that it iterates do not change much from round to round, and again, this is not a very restrictive assumption because for a lot of algorithms, in order to establish the first guarantee, you kind of go through the second one, either explicitly or implicitly so.",
                    "label": 0
                },
                {
                    "sent": "Subs.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I got confused.",
                    "label": 0
                },
                {
                    "sent": "So here's the thing, we want to estimate, not time.",
                    "label": 0
                },
                {
                    "sent": "Area know the you want to.",
                    "label": 0
                },
                {
                    "sent": "You want to optimize the expected function at the end of the day under the stationary distribution of the process.",
                    "label": 0
                },
                {
                    "sent": "But the but the you are the data you're receiving is right.",
                    "label": 0
                },
                {
                    "sent": "So you have your fixed parameter, but you're receiving an eye.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The data OK and just to give you example that this class of algorithms is interesting.",
                    "label": 0
                },
                {
                    "sent": "For instance, two very common algorithms that fall into this framework are online gradient descent and regularise dual averaging.",
                    "label": 1
                },
                {
                    "sent": "Both of them have found a lot of use in machine learning recently.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so with this I I can now state our first result, so we assume that we have iterates X, one through D coming from a stable online algorithm.",
                    "label": 1
                },
                {
                    "sent": "We take the average of these iterates and what we prove is that this average can optimize the function F's.",
                    "label": 0
                },
                {
                    "sent": "In particular, the optimization error is bounded by the sum of three terms.",
                    "label": 0
                },
                {
                    "sent": "The first term is just the average regret of the online algorithm, so your error at the average is bounded by the average regret.",
                    "label": 0
                },
                {
                    "sent": "The second term is a deviation term cause this is going to be.",
                    "label": 0
                },
                {
                    "sent": "This is a random process, so the bound is going to hold with high probability and the second term depends on how higher probability you wanted to hold with and the third term is really the one that comes up due to the non ID nature of the sequence and comprises of 2 two parts, 1 being the average stability of the online algorithm.",
                    "label": 0
                },
                {
                    "sent": "So here we see that stability is kind of crucial for this part and the second one that reflects the how fast the process mixes so.",
                    "label": 0
                },
                {
                    "sent": "Again, that reflects that how the correlations in the process might come and hurt you.",
                    "label": 0
                },
                {
                    "sent": "Copper is the stability of the online algorithm, the how much your exchange between two successive rounds.",
                    "label": 0
                },
                {
                    "sent": "We'll see, we'll see it in a couple of slides, so I'm going to actually show you specific bound.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the first time we reject you can do is to plug type equals one and five.",
                    "label": 0
                },
                {
                    "sent": "We called sphere of one is equal to 0 for IID sampling, which recovers the bound that was derived by just Bianchi and Co authors and by many other people in stochastic optimization.",
                    "label": 0
                },
                {
                    "sent": "For for ID sampling.",
                    "label": 0
                },
                {
                    "sent": "Because this term just goes away, this term becomes 1 / 1 over log one over Delta, and that's exactly the bond that was known before.",
                    "label": 0
                },
                {
                    "sent": "OK, now as Ben asked what this has too many algorithm dependent.",
                    "label": 0
                },
                {
                    "sent": "Amateur, so how do we actually make some sense?",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Out of this bound well, we do it by plugging in specific examples.",
                    "label": 0
                },
                {
                    "sent": "So if we take the algorithm to be online, gradient descent or regularize, dual averaging then and take the step size that decays as 1 / sqrt T, then it's known for these algorithms that they regret grows a square root T the disability decays as one over root tea, and just by plugging quantities in you see that you kind of have this one over root tea style convergence rate.",
                    "label": 0
                },
                {
                    "sent": "Although I'd be lying if it, I'd say it's one over root cause the first 2 terms are really only order.",
                    "label": 0
                },
                {
                    "sent": "Now, but the third term can actually be significantly bigger and depends on the mixing properties of your process, and in particular, it might seem like this term can actually blow up as T goes to Infinity.",
                    "label": 0
                },
                {
                    "sent": "Well, don't worry about that part, because as long as you're assured that fee of K goes to zero and K goes to Infinity.",
                    "label": 0
                },
                {
                    "sent": "And be shown with a little work that we always have almost sure convergence for stochastic optimization for these algorithms, But in particular, again, this is still a bit hard to make sense out of because there is this fear of Tau quantity sitting here, and we don't quite understand it, or at least when I first got it, I didn't understand it.",
                    "label": 0
                },
                {
                    "sent": "So what we do is.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We make some more assumptions.",
                    "label": 0
                },
                {
                    "sent": "We take a particular instance of the mixing rate.",
                    "label": 0
                },
                {
                    "sent": "We assume that the mixing happens geometrically.",
                    "label": 0
                },
                {
                    "sent": "An everything becomes very nice.",
                    "label": 0
                },
                {
                    "sent": "We up to this locked factor.",
                    "label": 0
                },
                {
                    "sent": "We essentially recover the same rate that we had for IID sampling.",
                    "label": 0
                },
                {
                    "sent": "We have basically order log two over root convergence, and this is the rate for IID sampling.",
                    "label": 0
                },
                {
                    "sent": "So we see that for things like the Markov chain example, we saw a few slides earlier, and then I'll recap.",
                    "label": 0
                },
                {
                    "sent": "In a minute we actually do not have any significant penalty for having this non IID data, but let's not fool you.",
                    "label": 0
                },
                {
                    "sent": "There will be cases where you will not be able to get to \u20b91 rate where the rate will be significantly slower if the mixing properties of the process are bad, but that's not on there.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Under for today, so we can actually test this empirically.",
                    "label": 0
                },
                {
                    "sent": "We ran an autoregressive process on a least squares regression problem.",
                    "label": 0
                },
                {
                    "sent": "The optimization algorithm, I believe online gradient descent and this is the expected convergence.",
                    "label": 0
                },
                {
                    "sent": "These are the deviations around the expectation.",
                    "label": 0
                },
                {
                    "sent": "We see that it does seem to converge and maybe with some imagination you could see that this looks kind of like 1 route.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to put my money on that part, not yet anyways, OK?",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So, so that's good.",
                    "label": 0
                },
                {
                    "sent": "Let's go back to this Markov chain example and see how.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Fits into the framework so.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And recall we have these local functions have eyes.",
                    "label": 0
                },
                {
                    "sent": "We are running a random walk.",
                    "label": 0
                },
                {
                    "sent": "We receive a stochastic gradient according to the token of the random walk and.",
                    "label": 1
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Now we now we just see that oh, this Markov gradient descent is actually just running online gradient descent on a sequence of non iid gradients, right?",
                    "label": 0
                },
                {
                    "sent": "So the stability of online gradient descent and low regret guarantee just directly imply that everything is going to work an just plugging this into our rates of convergence and using the fact that a Markov chain mixes exponentially fast, we get a very simple regret bound, very simple convergence rate.",
                    "label": 0
                },
                {
                    "sent": "That goes is 100 T, but depends on the spectral properties of the graph.",
                    "label": 0
                },
                {
                    "sent": "So in particular, again, you can test this empirically and this is a.",
                    "label": 0
                },
                {
                    "sent": "This is a pretty quantitative.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Addiction so we ran this algorithm for different network topologies for different graph graph layouts and what we observed was that the convergence of the algorithm was fastest for expander graphs last four cycles, and this is.",
                    "label": 0
                },
                {
                    "sent": "This makes sense because the mixing properties of random walk our best on expanders inversion cycles OK.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And now, just before I drop of one last thing I want to introduce is what happens when we have more structure.",
                    "label": 0
                },
                {
                    "sent": "So a common thing in optimization is to make some curvature isms function.",
                    "label": 0
                },
                {
                    "sent": "And then people can typically show that the rates of convergence are fast and this is interesting in machine learning cause this arises in all kinds of regularised problems like regularise SVM, regression, and so on.",
                    "label": 0
                },
                {
                    "sent": "And what we can show is that even with non iid noise you do not lose the gains that come with added curvature.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Functions, so use assuming that the sample functions capital F are strongly convex.",
                    "label": 0
                },
                {
                    "sent": "For instance, you can argue that online gradient descent and regularize dual averaging have one.",
                    "label": 0
                },
                {
                    "sent": "I have a log P regret guarantee and using that, and you know doing some doing some more hard work you can actually show the process kind of looks like one on T convergence rate model over to factor, and again there is this T5 to factor in this case.",
                    "label": 0
                },
                {
                    "sent": "This is like the root T5 now we had before.",
                    "label": 0
                },
                {
                    "sent": "But what we can see.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Very quickly from this bound is that in general it's going to be faster than the one root bound we get for convex losses.",
                    "label": 0
                },
                {
                    "sent": "If we set our equals one and fear of 1 = 0 before as before, this term kind of goes away.",
                    "label": 0
                },
                {
                    "sent": "So we only have one Auntie style or log tiante style convergence rate.",
                    "label": 0
                },
                {
                    "sent": "And if we make the geometric mixing assumption as before, we get almost as good rates as we get Friday mixing one more.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Our extension that I quickly want to mention is that a lot of problems of interest in machine learning unfortunately do not satisfy strong convexity because they have this structure that they involve a loss in applied to a linear form to a dot product such as least squares regression logistic regression.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Boosting and so on and it just cannot be strongly convex in this scenarios cause it only contains One Direction, so you can't have curvature in all directions, which is a pretty big cause.",
                    "label": 0
                },
                {
                    "sent": "Often this loss function L the scalar loss itself is strongly convex in its scalar parameter, and we kind of want to use that curvature.",
                    "label": 0
                },
                {
                    "sent": "And what we can actually show is that we do get fast rates.",
                    "label": 1
                },
                {
                    "sent": "One Auntie style rates.",
                    "label": 0
                },
                {
                    "sent": "Even in this case, although in this case the story is not quite as simple, the standard algorithms don't quite satisfy the assumptions that we need and.",
                    "label": 0
                },
                {
                    "sent": "We need to make a slight tweak to the existing algorithms, but it's still close enough and has the same computational cost.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately, the details of this take some time to set up, so I won't go.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So that today?",
                    "label": 0
                },
                {
                    "sent": "OK, so to wrap up, we saw at a very fast pace.",
                    "label": 0
                },
                {
                    "sent": "Today convergence rates for stochastic optimization with non IID data.",
                    "label": 0
                },
                {
                    "sent": "The nice part is that the theory does not apply just one algorithm, but to a large class of stable online algorithms, which includes things like gradient descent and dual averaging.",
                    "label": 0
                },
                {
                    "sent": "The analysis covers a large class of mixing processes.",
                    "label": 0
                },
                {
                    "sent": "Free mixing processes are very well studies in the Markov chain, literature and results.",
                    "label": 0
                },
                {
                    "sent": "Just reply to them.",
                    "label": 0
                },
                {
                    "sent": "In particular, we see that we have similar rates as I did it under geometric mixing, and we saw fast rates for strongly convex objectives and under linear.",
                    "label": 1
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Action we can we weaken the mixing assumptions even further, and the paper.",
                    "label": 0
                },
                {
                    "sent": "I can't remember the workshop version or not, but the long version definitely talks about weaker mixing conditions and how you can still prove similar results.",
                    "label": 0
                },
                {
                    "sent": "And we also consider a lot of other applications for stochastic optimization with non.",
                    "label": 1
                },
                {
                    "sent": "I.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The noise and the long free prints are available online.",
                    "label": 0
                },
                {
                    "sent": "If you want to take a look, thanks.",
                    "label": 0
                },
                {
                    "sent": "Can you say something about the case where CX represents para meters over graphical model and fine depends actually on X, so that's very good question.",
                    "label": 0
                },
                {
                    "sent": "That's kind of.",
                    "label": 0
                },
                {
                    "sent": "Formally, the the assumption we're making here is that the noise process, even though it has dependence, it's exogenous noise.",
                    "label": 0
                },
                {
                    "sent": "It does not depend on your current parameter and the moment you have that.",
                    "label": 0
                },
                {
                    "sent": "Things become very very different because kind of here we use martingale techniques and you just can't use them anymore.",
                    "label": 0
                },
                {
                    "sent": "So it's something that's on our plate that we would like to look at in future work, but we haven't done so far.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Sample ID from the distribution with.",
                    "label": 0
                },
                {
                    "sent": "Exactly, and that's that's one scenario to which these results will apply quite often because people have studied cases under which murder.",
                    "label": 0
                },
                {
                    "sent": "Testing samplers will satisfy free mixing orbital mixing conditions in particular instance so one.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Example we talked about in the paper is learning a ranking function from partially ordered samples where you might want to sample from the set of permutations that are consistent with some observed partial orders and that sort of set that's hard to sample from, but it's known how to design Markov chains that converge to the uniform distribution over that set, and we can just directly apply results to such things.",
                    "label": 0
                },
                {
                    "sent": "For instance.",
                    "label": 0
                },
                {
                    "sent": "Yes, that's that's a very interesting application for us.",
                    "label": 0
                }
            ]
        }
    }
}