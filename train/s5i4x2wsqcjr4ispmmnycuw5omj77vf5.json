{
    "id": "s5i4x2wsqcjr4ispmmnycuw5omj77vf5",
    "title": "On Multi-View Active Learning and the Combination with Semi-Supervised Learning",
    "info": {
        "author": [
            "Zhi-Hua Zhou, State Key Laboratory for Novel Software Technology, Nanjing University"
        ],
        "published": "Aug. 1, 2008",
        "recorded": "July 2008",
        "category": [
            "Top->Computer Science->Machine Learning->Semi-supervised Learning",
            "Top->Computer Science->Machine Learning->Active Learning"
        ]
    },
    "url": "http://videolectures.net/icml08_zhou_mval/",
    "segmentation": [
        [
            "OK, hello everyone, that over presentation is amount of active learning and the combination with me surprise learning.",
            "I'm way one is the joint work with my surprise store so we both come from Law Group National Key Laboratory for Normal software.",
            "Technology menu."
        ],
        [
            "Today China.",
            "Combination of amount of active learning and semi supervised learning has been very very effective in some applications.",
            "But this method is still like theoretical support.",
            "In this paper, we theoretically study what is combination into excellent performance.",
            "We can analyze amount of active learning at the post and then analyze the introduction of semi supervised learning.",
            "Work is the first theoretical analysis amount of active learning and the first theoretical analysis on active learning process.",
            "Word learning."
        ],
        [
            "It is the outline."
        ],
        [
            "The first part of introduction."
        ],
        [
            "In many practical applications on labeled training, examples are readily available, but the labeled ones are very expensive to obtain because the library unable examples require human efforts.",
            "So there are two popular paradigms for using unlabeled examples to a compliment, the labeled ones.",
            "The 1st Way is active learning.",
            "In this way, the learner active respect some online for examples to query from an Oracle.",
            "The second one is the same list price learning.",
            "In this way the learner try to exploit implies the unlabeled example by its."
        ],
        [
            "Yeah.",
            "In some applications that traditionally don't know values, that is to attribute sets in service is sufficient for learning that concept.",
            "For example, this is.",
            "For example, there are two views for web page classification.",
            "The first where is the text appearing on this page and another view is the hyperlink is pointless paging."
        ],
        [
            "Is there a lot of work about Mount?",
            "Will active learning and semi supervised learning model we learning our useful in active learning and semi supervised learning.",
            "In for explanation, protecting worker is contesting for semi supervised learning.",
            "Very protective worker is called training.",
            "The influence of a multiview learning does not unstrained too much views, so because some single view methods can also take benefits from the mechanics of multiview learning.",
            "Mystery Mountain View, active learning plus, Semi supervised learning, helping in.",
            "Found effective in some applications.",
            "For example the interactive image."
        ],
        [
            "Retrieval his approach of amount of active learning plus semi supervised learning.",
            "The data set has to use both values.",
            "Initial labor examples to try to learn and learn one, and true then why you say Mr Price darling to level?",
            "The most competent examples following two, then learner true also use the same supply.",
            "Learning to label the most complete examples for number one.",
            "Meanwhile the two learners work on the label examples and ask user to labeled mostly disagreed examples.",
            "And then we use the unit level examples and initial level examples to update to learner.",
            "Such a process is repeated on preset arounds."
        ],
        [
            "List is combination.",
            "Amount of active learning and semi supervised learning multiple safety and it works well, but it is like theoretically supports forests and as much of active learning false.",
            "Then we analyze the introduction of semi supervised learning.",
            "Impressive previously yes and no.",
            "Semantical study on multiple actions."
        ],
        [
            "Any?",
            "The next part is somewhat relaxed."
        ],
        [
            "Walker.",
            "Previously there some more theoretical active learning.",
            "Does group target across sample complexity bound for reliable active learning?",
            "An illustrated that for learning task where the hypothesis class is linear separates in 2 dimensional space and the data distribution is some density supported on the perimeter of the unit circle.",
            "As it is the only government or absolute levels are needed to find the episode approximation of some target hypothesis.",
            "But under strong assumptions that the hypothesis is linear, separates origin, the data is distributed uniformly over the universe, appear, and then pass code is reliable case.",
            "The sample complexity can be potentially improve the 202 the Dlog Manor episode.",
            "But all these results are obtained in single resetting."
        ],
        [
            "The next part of introduce ourselves ready to study."
        ],
        [
            "First we need some notation.",
            "Examples that X composed of X 1 * X Two is with some unknown unknown distribution, while the label space.",
            "The underline target concept C composed of C1 and C2 where C1C2.",
            "As the ground shows in the two views respectively, we suppose that.",
            "Example special is consistent.",
            "This means that there is no such example X which the two gun shows have different labels on it.",
            "For any classifier, an example, we set that example beyond to discuss by if I if and only if the classifier and ground truth have the same label on it.",
            "In this way, any hypothesis can be thought of as a subset of the example."
        ],
        [
            "Best.",
            "Mountain View Active learning focus on the convention points.",
            "This contention points are correctly predicts about one of the views so far.",
            "Successful multiview active learning the constant set of 1 value should be expanding by considering the other view together.",
            "So we can use the iPhone pension assumption in our analysis test definition on Argonne impression.",
            "This dimension means that the disagreement between the two views should be should have a lower bound.",
            "Here S 1 S to denote examples correctly classified in each view.",
            "PS1 S to denote the probability mass on examples correctly classified in both views.",
            "PS1 process to denote the probability mass on examples correctly classify.",
            "The only one will.",
            "This also means the disagreement between the two views."
        ],
        [
            "IPhone impression had been employed by Belk and his colleagues.",
            "They assume that learning is confident about being positive.",
            "And it's labeled.",
            "Able to learn from positive example only and the distribution D plus over the positive examples is expanding.",
            "But there are many hypothesis class that are not learnable from positive example only.",
            "So we assume that correctly predicted example is expanding.",
            "Well, apparently a programmer said he's the best at historical definition.",
            "Also says satisfy our definition."
        ],
        [
            "There are many strategies to combine the two classifier in Mountain View.",
            "Setting English people assume that the classifier command as follows so so area that can be expressed as PRPS one.",
            "I button SY bar plus half of half of the disagreements.",
            "There, SYISY correspond to the classifier in the surrounding."
        ],
        [
            "Now we will give our metadata German one.",
            "Is there is there a theorem means that?",
            "Cindy I understand you is without respect to a hypothesis class.",
            "Each round of amount of active learning.",
            "If I labeled query to Oracle at most after srom the matter with active learning can get a classifier with error right normal edition.",
            "This is the theorem implies that the sample complexity of multiview active learning is O log one or absolute log log one or episode.",
            "It means that the sample complexity is influential, improved."
        ],
        [
            "Now given the proof sketch of 01.",
            "The error rate of a combined classifier.",
            "It's equal to PS1 bar and S2.",
            "IBA plus half of the disagreement, which is normal and PSYINSY bar.",
            "Initially we have Mo level examples so arbitrary.",
            "Classify SGI being consistent with initial label.",
            "Examples had error rates at most I for over 60 with probability models that are over four X + 1.",
            "So we have that PSYINSY is not less than one minus iOS.",
            "We are at a loss of generality we considered considered, as I found Alpha is bigger than they are and not more than one.",
            "So therefore.",
            "Example 1 minus iOS is bigger than 0.5.",
            "That's the iPhone.",
            "He suggested that the disagreement between the two classifier 2 views is no less than iPhone multiply PSYI bar and I store bound."
        ],
        [
            "Why is Iceland Merle level the acquired randomly from the disagreement region in the eye minus ones one according to the concept?",
            "Similarly, we have that.",
            "The error rate of two classifiers in a disagreement region.",
            "Is this normal?",
            "Then iPhone or ads?",
            "Consider the following formula.",
            "We have that the error the error rate of the card fire in ice round is not more than Alpha or four multiplier disagreement.",
            "Pass the error rate in the areas of classifier in the eye minus one round.",
            "Now consider considering the impression condition, the disagreements between the two views is is is not less than I for multiply PS1 I banesto I bar we have that the error rate of the areas of the classifier in the on the over the air out of the car fire in I minus.",
            "Minus one round is.",
            "And normalize value."
        ],
        [
            "So we can get the upper bound of the classifier in the eye song.",
            "1S is equal to this value.",
            "We can we can find that PS1 as an extra small S bar is normal episode.",
            "In other words, we get a classifier with error rate is normal edition.",
            "Now, under the impression assumptions model active learning, it can get.",
            "Can we use the sample complexity?",
            "International."
        ],
        [
            "If I buy, impressions are not hold, we will give up on our classifier.",
            "First we make a definition on the impression region.",
            "Disparaging gamma is equal to PSIO NS-20 minus PSYI bonez.",
            "As to Eibar, this impending region can be thought of as the approximation of some of the disagree disagreement."
        ],
        [
            "Now we give our result 2.",
            "German to provide a pound and implies that the improvement of amount of active learning Department depending on the region and the disagreement between the initial two classifiers.",
            "And our Guild from hands of Chairman.",
            "True, considering that the error rate of cost by age, I is equal to PS1 eyeball esto IBA plus half of this agreement and disagreement is less than epsilon theory.",
            "Terminate multiple active learning.",
            "So we have that the error rate of classified, 0 minus the average age of classifier, I is larger than the dependent region plus half of the disagreement."
        ],
        [
            "Now we can introduce me spy learning on about it out to analyze multiple active learning processes, surprise, learning.",
            "For simplicity, we consider the following case.",
            "The hypothesis class is the subset of mappings for more examples that through an interval from negative one to one label is sign of the outputs.",
            "Well, without that for any class by F&J there exists some constant.",
            "I want to hold that the difference between two classifier outputs is normal L. One multiply the disagreements, multiply the second normal, for example.",
            "Without loss of generality, we supposed that the second normal example have an upper bound.",
            "Oh well too."
        ],
        [
            "Now we can give our real tree Cemetery in ceremony implied that the sample complexity of amount of active learning process prior learning is Mo plus some of anyone I. I hear I hear anyone I is smaller than MI in someone.",
            "This is also implies that the sample complexity of multiple active learning processes prior learning is much smaller than that of a matter with active learning.",
            "So we can find a sweater support for.",
            "So now finding surgical support.",
            "Why must be active learning and practice by learning excellent performance."
        ],
        [
            "Now we use our product gets over symmetry.",
            "Generally we have that arbitrary caused by SGI being consistent with initial label examples and always at most 1 / L. So for any example X we have that the difference between classified and ground truth is normal, then L. I'm multiplying too much by this agreement so we can ask threshold if the output of the qualifier is lost.",
            "An issue threshold classifier, ground truth.",
            "Make some prediction on this example.",
            "So from the proof of theorem one we can we know that after this round we can get the classifier.",
            "Found the operator is the Epson."
        ],
        [
            "The next part is some experiments."
        ],
        [
            "In our experiments we used cost data sets.",
            "This data set have two views, the pages and links.",
            "Will we use Smol newmaker as the best learner?",
            "Will love the 25% data as a test set an error rate of 20 round is reported."
        ],
        [
            "Image of active learning.",
            "We pick up the two contact points randomly to query in the Iceland.",
            "In March, will actively participate, learning let you delete the unlabeled data and QID network connection problems.",
            "We use active learning to query 2 examples, label the two examples are the ones with the with the smallest absolute sum of the two classifier outputs in Qi and the completely complementary set of Qi respectively.",
            "We also the same supply learning to level 2 example which has the largest absolute sum of the classifier output in Qin U -- Q R."
        ],
        [
            "His head is a real history out.",
            "Pharmacy without a week and found that with the same number of queries the performance of multi active learning processes running is the best.",
            "Is also verified that monthly active learning and supervised learning.",
            "We have a smaller complexity, sample complexities and multiple active learning."
        ],
        [
            "And at last we will conclude our paper."
        ],
        [
            "Our work is the first theoretical study amount of active learning.",
            "When I found in pension assumptions holds we get any financial improvement in the sample compressive from oh oh.",
            "Episode 20, epsilon.",
            "Donald Holder, we give up about the operator for Mountain View active learning.",
            "And this application assumptions is much weaker than previous assumptions such that hypothesis class is homogeneous, linear separates and the data is.",
            "Distributed uniformly over the junior severe.",
            "Now that is the 1st circle study amount of active learning paths for learning."
        ],
        [
            "In future we will analyze multiview active learning process for learning by analyzing multiple falls and then introduce active learning will also extend extend our analysis on multiple active learning into non reliable cases."
        ],
        [
            "That's all, thank you.",
            "Thank you very much.",
            "Are there any questions?",
            "Um?",
            "Any questions at all?",
            "I've got a small question.",
            "I mean, you already hinted at this in your future work that you would want to look at the non real."
        ],
        [
            "Possible case, yeah, so have you got any intuition how much of your analysis will follow through?",
            "Because I mean the assumption that you have two sets of features, both of which will allow to bowl classify correctly with 0 error is actually an extremely strong one.",
            "So have you got any intuition what you will be able to rescue?",
            "If that's not the case?",
            "Pardon.",
            "Wood.",
            "So I'm asking in the future work, the second item that you listed.",
            "Have you got any idea what you will be able to show?",
            "Sorry my students listening English is not very good, so let me briefly explain this to this from the multiview.",
            "Learning is required as each view is sufficient.",
            "So if we start from this case, it's not not feasible to do.",
            "Not realizable active learning cases.",
            "So for this we have to release two that for each view.",
            "Maybe we can only achieve such as 90% efficient.",
            "So after doing some such kind of relaxation is made possible to do non realizable active learning analysis.",
            "Yeah.",
            "Thank you any other questions?",
            "OK, well then I think we're about 5 minutes early to break for lunch.",
            "Let's thank all the speakers again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, hello everyone, that over presentation is amount of active learning and the combination with me surprise learning.",
                    "label": 1
                },
                {
                    "sent": "I'm way one is the joint work with my surprise store so we both come from Law Group National Key Laboratory for Normal software.",
                    "label": 0
                },
                {
                    "sent": "Technology menu.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Today China.",
                    "label": 0
                },
                {
                    "sent": "Combination of amount of active learning and semi supervised learning has been very very effective in some applications.",
                    "label": 1
                },
                {
                    "sent": "But this method is still like theoretical support.",
                    "label": 1
                },
                {
                    "sent": "In this paper, we theoretically study what is combination into excellent performance.",
                    "label": 0
                },
                {
                    "sent": "We can analyze amount of active learning at the post and then analyze the introduction of semi supervised learning.",
                    "label": 1
                },
                {
                    "sent": "Work is the first theoretical analysis amount of active learning and the first theoretical analysis on active learning process.",
                    "label": 0
                },
                {
                    "sent": "Word learning.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It is the outline.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The first part of introduction.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In many practical applications on labeled training, examples are readily available, but the labeled ones are very expensive to obtain because the library unable examples require human efforts.",
                    "label": 1
                },
                {
                    "sent": "So there are two popular paradigms for using unlabeled examples to a compliment, the labeled ones.",
                    "label": 0
                },
                {
                    "sent": "The 1st Way is active learning.",
                    "label": 1
                },
                {
                    "sent": "In this way, the learner active respect some online for examples to query from an Oracle.",
                    "label": 0
                },
                {
                    "sent": "The second one is the same list price learning.",
                    "label": 0
                },
                {
                    "sent": "In this way the learner try to exploit implies the unlabeled example by its.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "In some applications that traditionally don't know values, that is to attribute sets in service is sufficient for learning that concept.",
                    "label": 1
                },
                {
                    "sent": "For example, this is.",
                    "label": 1
                },
                {
                    "sent": "For example, there are two views for web page classification.",
                    "label": 1
                },
                {
                    "sent": "The first where is the text appearing on this page and another view is the hyperlink is pointless paging.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is there a lot of work about Mount?",
                    "label": 0
                },
                {
                    "sent": "Will active learning and semi supervised learning model we learning our useful in active learning and semi supervised learning.",
                    "label": 0
                },
                {
                    "sent": "In for explanation, protecting worker is contesting for semi supervised learning.",
                    "label": 0
                },
                {
                    "sent": "Very protective worker is called training.",
                    "label": 0
                },
                {
                    "sent": "The influence of a multiview learning does not unstrained too much views, so because some single view methods can also take benefits from the mechanics of multiview learning.",
                    "label": 1
                },
                {
                    "sent": "Mystery Mountain View, active learning plus, Semi supervised learning, helping in.",
                    "label": 1
                },
                {
                    "sent": "Found effective in some applications.",
                    "label": 0
                },
                {
                    "sent": "For example the interactive image.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Retrieval his approach of amount of active learning plus semi supervised learning.",
                    "label": 0
                },
                {
                    "sent": "The data set has to use both values.",
                    "label": 0
                },
                {
                    "sent": "Initial labor examples to try to learn and learn one, and true then why you say Mr Price darling to level?",
                    "label": 0
                },
                {
                    "sent": "The most competent examples following two, then learner true also use the same supply.",
                    "label": 0
                },
                {
                    "sent": "Learning to label the most complete examples for number one.",
                    "label": 1
                },
                {
                    "sent": "Meanwhile the two learners work on the label examples and ask user to labeled mostly disagreed examples.",
                    "label": 0
                },
                {
                    "sent": "And then we use the unit level examples and initial level examples to update to learner.",
                    "label": 0
                },
                {
                    "sent": "Such a process is repeated on preset arounds.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "List is combination.",
                    "label": 0
                },
                {
                    "sent": "Amount of active learning and semi supervised learning multiple safety and it works well, but it is like theoretically supports forests and as much of active learning false.",
                    "label": 0
                },
                {
                    "sent": "Then we analyze the introduction of semi supervised learning.",
                    "label": 1
                },
                {
                    "sent": "Impressive previously yes and no.",
                    "label": 0
                },
                {
                    "sent": "Semantical study on multiple actions.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Any?",
                    "label": 0
                },
                {
                    "sent": "The next part is somewhat relaxed.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Walker.",
                    "label": 0
                },
                {
                    "sent": "Previously there some more theoretical active learning.",
                    "label": 0
                },
                {
                    "sent": "Does group target across sample complexity bound for reliable active learning?",
                    "label": 1
                },
                {
                    "sent": "An illustrated that for learning task where the hypothesis class is linear separates in 2 dimensional space and the data distribution is some density supported on the perimeter of the unit circle.",
                    "label": 1
                },
                {
                    "sent": "As it is the only government or absolute levels are needed to find the episode approximation of some target hypothesis.",
                    "label": 1
                },
                {
                    "sent": "But under strong assumptions that the hypothesis is linear, separates origin, the data is distributed uniformly over the universe, appear, and then pass code is reliable case.",
                    "label": 0
                },
                {
                    "sent": "The sample complexity can be potentially improve the 202 the Dlog Manor episode.",
                    "label": 0
                },
                {
                    "sent": "But all these results are obtained in single resetting.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The next part of introduce ourselves ready to study.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "First we need some notation.",
                    "label": 0
                },
                {
                    "sent": "Examples that X composed of X 1 * X Two is with some unknown unknown distribution, while the label space.",
                    "label": 1
                },
                {
                    "sent": "The underline target concept C composed of C1 and C2 where C1C2.",
                    "label": 0
                },
                {
                    "sent": "As the ground shows in the two views respectively, we suppose that.",
                    "label": 0
                },
                {
                    "sent": "Example special is consistent.",
                    "label": 1
                },
                {
                    "sent": "This means that there is no such example X which the two gun shows have different labels on it.",
                    "label": 0
                },
                {
                    "sent": "For any classifier, an example, we set that example beyond to discuss by if I if and only if the classifier and ground truth have the same label on it.",
                    "label": 0
                },
                {
                    "sent": "In this way, any hypothesis can be thought of as a subset of the example.",
                    "label": 1
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Best.",
                    "label": 0
                },
                {
                    "sent": "Mountain View Active learning focus on the convention points.",
                    "label": 0
                },
                {
                    "sent": "This contention points are correctly predicts about one of the views so far.",
                    "label": 0
                },
                {
                    "sent": "Successful multiview active learning the constant set of 1 value should be expanding by considering the other view together.",
                    "label": 1
                },
                {
                    "sent": "So we can use the iPhone pension assumption in our analysis test definition on Argonne impression.",
                    "label": 0
                },
                {
                    "sent": "This dimension means that the disagreement between the two views should be should have a lower bound.",
                    "label": 0
                },
                {
                    "sent": "Here S 1 S to denote examples correctly classified in each view.",
                    "label": 0
                },
                {
                    "sent": "PS1 S to denote the probability mass on examples correctly classified in both views.",
                    "label": 0
                },
                {
                    "sent": "PS1 process to denote the probability mass on examples correctly classify.",
                    "label": 0
                },
                {
                    "sent": "The only one will.",
                    "label": 0
                },
                {
                    "sent": "This also means the disagreement between the two views.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "IPhone impression had been employed by Belk and his colleagues.",
                    "label": 0
                },
                {
                    "sent": "They assume that learning is confident about being positive.",
                    "label": 0
                },
                {
                    "sent": "And it's labeled.",
                    "label": 0
                },
                {
                    "sent": "Able to learn from positive example only and the distribution D plus over the positive examples is expanding.",
                    "label": 0
                },
                {
                    "sent": "But there are many hypothesis class that are not learnable from positive example only.",
                    "label": 0
                },
                {
                    "sent": "So we assume that correctly predicted example is expanding.",
                    "label": 0
                },
                {
                    "sent": "Well, apparently a programmer said he's the best at historical definition.",
                    "label": 0
                },
                {
                    "sent": "Also says satisfy our definition.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There are many strategies to combine the two classifier in Mountain View.",
                    "label": 0
                },
                {
                    "sent": "Setting English people assume that the classifier command as follows so so area that can be expressed as PRPS one.",
                    "label": 1
                },
                {
                    "sent": "I button SY bar plus half of half of the disagreements.",
                    "label": 1
                },
                {
                    "sent": "There, SYISY correspond to the classifier in the surrounding.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now we will give our metadata German one.",
                    "label": 0
                },
                {
                    "sent": "Is there is there a theorem means that?",
                    "label": 0
                },
                {
                    "sent": "Cindy I understand you is without respect to a hypothesis class.",
                    "label": 0
                },
                {
                    "sent": "Each round of amount of active learning.",
                    "label": 0
                },
                {
                    "sent": "If I labeled query to Oracle at most after srom the matter with active learning can get a classifier with error right normal edition.",
                    "label": 0
                },
                {
                    "sent": "This is the theorem implies that the sample complexity of multiview active learning is O log one or absolute log log one or episode.",
                    "label": 1
                },
                {
                    "sent": "It means that the sample complexity is influential, improved.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now given the proof sketch of 01.",
                    "label": 1
                },
                {
                    "sent": "The error rate of a combined classifier.",
                    "label": 1
                },
                {
                    "sent": "It's equal to PS1 bar and S2.",
                    "label": 0
                },
                {
                    "sent": "IBA plus half of the disagreement, which is normal and PSYINSY bar.",
                    "label": 0
                },
                {
                    "sent": "Initially we have Mo level examples so arbitrary.",
                    "label": 1
                },
                {
                    "sent": "Classify SGI being consistent with initial label.",
                    "label": 0
                },
                {
                    "sent": "Examples had error rates at most I for over 60 with probability models that are over four X + 1.",
                    "label": 0
                },
                {
                    "sent": "So we have that PSYINSY is not less than one minus iOS.",
                    "label": 0
                },
                {
                    "sent": "We are at a loss of generality we considered considered, as I found Alpha is bigger than they are and not more than one.",
                    "label": 0
                },
                {
                    "sent": "So therefore.",
                    "label": 0
                },
                {
                    "sent": "Example 1 minus iOS is bigger than 0.5.",
                    "label": 0
                },
                {
                    "sent": "That's the iPhone.",
                    "label": 0
                },
                {
                    "sent": "He suggested that the disagreement between the two classifier 2 views is no less than iPhone multiply PSYI bar and I store bound.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Why is Iceland Merle level the acquired randomly from the disagreement region in the eye minus ones one according to the concept?",
                    "label": 1
                },
                {
                    "sent": "Similarly, we have that.",
                    "label": 0
                },
                {
                    "sent": "The error rate of two classifiers in a disagreement region.",
                    "label": 0
                },
                {
                    "sent": "Is this normal?",
                    "label": 0
                },
                {
                    "sent": "Then iPhone or ads?",
                    "label": 0
                },
                {
                    "sent": "Consider the following formula.",
                    "label": 0
                },
                {
                    "sent": "We have that the error the error rate of the card fire in ice round is not more than Alpha or four multiplier disagreement.",
                    "label": 0
                },
                {
                    "sent": "Pass the error rate in the areas of classifier in the eye minus one round.",
                    "label": 0
                },
                {
                    "sent": "Now consider considering the impression condition, the disagreements between the two views is is is not less than I for multiply PS1 I banesto I bar we have that the error rate of the areas of the classifier in the on the over the air out of the car fire in I minus.",
                    "label": 0
                },
                {
                    "sent": "Minus one round is.",
                    "label": 0
                },
                {
                    "sent": "And normalize value.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we can get the upper bound of the classifier in the eye song.",
                    "label": 0
                },
                {
                    "sent": "1S is equal to this value.",
                    "label": 0
                },
                {
                    "sent": "We can we can find that PS1 as an extra small S bar is normal episode.",
                    "label": 0
                },
                {
                    "sent": "In other words, we get a classifier with error rate is normal edition.",
                    "label": 1
                },
                {
                    "sent": "Now, under the impression assumptions model active learning, it can get.",
                    "label": 0
                },
                {
                    "sent": "Can we use the sample complexity?",
                    "label": 0
                },
                {
                    "sent": "International.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If I buy, impressions are not hold, we will give up on our classifier.",
                    "label": 0
                },
                {
                    "sent": "First we make a definition on the impression region.",
                    "label": 0
                },
                {
                    "sent": "Disparaging gamma is equal to PSIO NS-20 minus PSYI bonez.",
                    "label": 0
                },
                {
                    "sent": "As to Eibar, this impending region can be thought of as the approximation of some of the disagree disagreement.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now we give our result 2.",
                    "label": 1
                },
                {
                    "sent": "German to provide a pound and implies that the improvement of amount of active learning Department depending on the region and the disagreement between the initial two classifiers.",
                    "label": 1
                },
                {
                    "sent": "And our Guild from hands of Chairman.",
                    "label": 0
                },
                {
                    "sent": "True, considering that the error rate of cost by age, I is equal to PS1 eyeball esto IBA plus half of this agreement and disagreement is less than epsilon theory.",
                    "label": 0
                },
                {
                    "sent": "Terminate multiple active learning.",
                    "label": 0
                },
                {
                    "sent": "So we have that the error rate of classified, 0 minus the average age of classifier, I is larger than the dependent region plus half of the disagreement.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now we can introduce me spy learning on about it out to analyze multiple active learning processes, surprise, learning.",
                    "label": 0
                },
                {
                    "sent": "For simplicity, we consider the following case.",
                    "label": 1
                },
                {
                    "sent": "The hypothesis class is the subset of mappings for more examples that through an interval from negative one to one label is sign of the outputs.",
                    "label": 1
                },
                {
                    "sent": "Well, without that for any class by F&J there exists some constant.",
                    "label": 0
                },
                {
                    "sent": "I want to hold that the difference between two classifier outputs is normal L. One multiply the disagreements, multiply the second normal, for example.",
                    "label": 0
                },
                {
                    "sent": "Without loss of generality, we supposed that the second normal example have an upper bound.",
                    "label": 0
                },
                {
                    "sent": "Oh well too.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now we can give our real tree Cemetery in ceremony implied that the sample complexity of amount of active learning process prior learning is Mo plus some of anyone I. I hear I hear anyone I is smaller than MI in someone.",
                    "label": 0
                },
                {
                    "sent": "This is also implies that the sample complexity of multiple active learning processes prior learning is much smaller than that of a matter with active learning.",
                    "label": 1
                },
                {
                    "sent": "So we can find a sweater support for.",
                    "label": 0
                },
                {
                    "sent": "So now finding surgical support.",
                    "label": 0
                },
                {
                    "sent": "Why must be active learning and practice by learning excellent performance.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now we use our product gets over symmetry.",
                    "label": 0
                },
                {
                    "sent": "Generally we have that arbitrary caused by SGI being consistent with initial label examples and always at most 1 / L. So for any example X we have that the difference between classified and ground truth is normal, then L. I'm multiplying too much by this agreement so we can ask threshold if the output of the qualifier is lost.",
                    "label": 1
                },
                {
                    "sent": "An issue threshold classifier, ground truth.",
                    "label": 1
                },
                {
                    "sent": "Make some prediction on this example.",
                    "label": 1
                },
                {
                    "sent": "So from the proof of theorem one we can we know that after this round we can get the classifier.",
                    "label": 0
                },
                {
                    "sent": "Found the operator is the Epson.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The next part is some experiments.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In our experiments we used cost data sets.",
                    "label": 0
                },
                {
                    "sent": "This data set have two views, the pages and links.",
                    "label": 1
                },
                {
                    "sent": "Will we use Smol newmaker as the best learner?",
                    "label": 0
                },
                {
                    "sent": "Will love the 25% data as a test set an error rate of 20 round is reported.",
                    "label": 1
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Image of active learning.",
                    "label": 0
                },
                {
                    "sent": "We pick up the two contact points randomly to query in the Iceland.",
                    "label": 1
                },
                {
                    "sent": "In March, will actively participate, learning let you delete the unlabeled data and QID network connection problems.",
                    "label": 0
                },
                {
                    "sent": "We use active learning to query 2 examples, label the two examples are the ones with the with the smallest absolute sum of the two classifier outputs in Qi and the completely complementary set of Qi respectively.",
                    "label": 0
                },
                {
                    "sent": "We also the same supply learning to level 2 example which has the largest absolute sum of the classifier output in Qin U -- Q R.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "His head is a real history out.",
                    "label": 0
                },
                {
                    "sent": "Pharmacy without a week and found that with the same number of queries the performance of multi active learning processes running is the best.",
                    "label": 0
                },
                {
                    "sent": "Is also verified that monthly active learning and supervised learning.",
                    "label": 0
                },
                {
                    "sent": "We have a smaller complexity, sample complexities and multiple active learning.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And at last we will conclude our paper.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Our work is the first theoretical study amount of active learning.",
                    "label": 1
                },
                {
                    "sent": "When I found in pension assumptions holds we get any financial improvement in the sample compressive from oh oh.",
                    "label": 1
                },
                {
                    "sent": "Episode 20, epsilon.",
                    "label": 0
                },
                {
                    "sent": "Donald Holder, we give up about the operator for Mountain View active learning.",
                    "label": 0
                },
                {
                    "sent": "And this application assumptions is much weaker than previous assumptions such that hypothesis class is homogeneous, linear separates and the data is.",
                    "label": 0
                },
                {
                    "sent": "Distributed uniformly over the junior severe.",
                    "label": 0
                },
                {
                    "sent": "Now that is the 1st circle study amount of active learning paths for learning.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In future we will analyze multiview active learning process for learning by analyzing multiple falls and then introduce active learning will also extend extend our analysis on multiple active learning into non reliable cases.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's all, thank you.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                },
                {
                    "sent": "Are there any questions?",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Any questions at all?",
                    "label": 0
                },
                {
                    "sent": "I've got a small question.",
                    "label": 0
                },
                {
                    "sent": "I mean, you already hinted at this in your future work that you would want to look at the non real.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Possible case, yeah, so have you got any intuition how much of your analysis will follow through?",
                    "label": 0
                },
                {
                    "sent": "Because I mean the assumption that you have two sets of features, both of which will allow to bowl classify correctly with 0 error is actually an extremely strong one.",
                    "label": 0
                },
                {
                    "sent": "So have you got any intuition what you will be able to rescue?",
                    "label": 0
                },
                {
                    "sent": "If that's not the case?",
                    "label": 0
                },
                {
                    "sent": "Pardon.",
                    "label": 0
                },
                {
                    "sent": "Wood.",
                    "label": 0
                },
                {
                    "sent": "So I'm asking in the future work, the second item that you listed.",
                    "label": 0
                },
                {
                    "sent": "Have you got any idea what you will be able to show?",
                    "label": 0
                },
                {
                    "sent": "Sorry my students listening English is not very good, so let me briefly explain this to this from the multiview.",
                    "label": 0
                },
                {
                    "sent": "Learning is required as each view is sufficient.",
                    "label": 0
                },
                {
                    "sent": "So if we start from this case, it's not not feasible to do.",
                    "label": 0
                },
                {
                    "sent": "Not realizable active learning cases.",
                    "label": 0
                },
                {
                    "sent": "So for this we have to release two that for each view.",
                    "label": 0
                },
                {
                    "sent": "Maybe we can only achieve such as 90% efficient.",
                    "label": 0
                },
                {
                    "sent": "So after doing some such kind of relaxation is made possible to do non realizable active learning analysis.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Thank you any other questions?",
                    "label": 0
                },
                {
                    "sent": "OK, well then I think we're about 5 minutes early to break for lunch.",
                    "label": 0
                },
                {
                    "sent": "Let's thank all the speakers again.",
                    "label": 0
                }
            ]
        }
    }
}