{
    "id": "33fgncytklswa7esnjadfdi5rzkqu5lm",
    "title": "A snapshot of the OWL Web",
    "info": {
        "author": [
            "Nicolas Matentzoglu, School of Computer Science, University of Manchester"
        ],
        "published": "Nov. 28, 2013",
        "recorded": "October 2013",
        "category": [
            "Top->Computer Science->Semantic Web",
            "Top->Computer Science->Databases"
        ]
    },
    "url": "http://videolectures.net/iswc2013_matentzoglu_owl_web/",
    "segmentation": [
        [
            "Hello everyone, I'm going to present to you some joint work with Samantha Beilinson parser from the University of Manchester and as we have heard this morning I'll or ontologies in general might be off a little bit lesser interest, but I saw also that the graph I think was rising towards the end of it.",
            "But anyways I'm going to talk."
        ],
        [
            "It's about in the same line as to my previous previous speaker about experiments and what we can do in order to improve the datasets that we use for our experimentation so.",
            "Some assumptions about the Web ontology language.",
            "We use your eyes for virtually everything for identifiers for individuals, for classes, for properties, and we have some web based features such as the old import statement which refers to another web resource, another ontology that is imported, and we use even kind of more savvy things that, for example, like relative, your eye resolution.",
            "So we believe that publishing out on the web is generally encouraged and that we can actually find.",
            "Most hours somewhere on the web we know this not everything, of course, but most of it.",
            "And in order to understand it for us as our researchers, for example, like math, later we want to understand about what kind of constructs people are using generally, and very often we first must find a suitable set for."
        ],
        [
            "Research, So what people generally do they resort to certain, like, for example exemplars, they look at important ontologies such as snow met, or they look at for particular purposes.",
            "Particularly difficult ontology, such as gaining, for example, if they want to evaluate reasoners, they can look at curated collections like Bio Portal, which is probably the most important real corpus that we have with roughly around 350 downloadable ontologies in there, or some handcrafted.",
            "The corpora such as tones and the Oxford Ontology Library, which are meant to help with empirical or which provides some interesting ontologies for empirical research.",
            "Or, Alternatively, we can resort to like large scale repository's.",
            "These two accrual based Swoogle semantic web search engine.",
            "We could say randomly sample from what's Google has to offer or what the search engine has to offer and then do our study based on that."
        ],
        [
            "But they're generally problems with this.",
            "We have obviously not only ontologies and there we have a lot of semantic Web documents.",
            "We have versions of ontologies we have ontologies that our path published in a faceted way, and we don't want to treat each facet as a separate ontology, so."
        ],
        [
            "Might be not very suitable for this purpose, so we ask ourselves, can we create a somehow more representative collection of."
        ],
        [
            "Paula geez, so the goal of this reset?"
        ],
        [
            "I should take a snapshot of the our web so as we perceive, we say we think of a snapshot as a collection of somehow distinct ontologies of arbitrary, but in some way representative origins.",
            "So from various domains not only for example from the biomedical domain at some given point in time, and we want to get such a snapshot because we want to improve our empirical work we want."
        ],
        [
            "To raise the generalizability of the of our findings, when we, for example, make surveys about modular structure of ontologies, we want to test our tools and techniques and we want to make informed decisions such as whether we want to employ a language extent, which whether we should put forward a language extension or invest money in developing a certain feature for offer tool or some."
        ],
        [
            "Like that, So what I'm going to talk to you about for a bit is the process by which we reached to this corpus, and by talking a bit about how we gathered the data initially, how we curated it.",
            "Various steps and then how we are actually using it at the moment."
        ],
        [
            "So the data gap."
        ],
        [
            "During process is straightforward.",
            "We have a standard open source crawler that is fueled with a with a very wide range of seats.",
            "Obviously we cannot crawl the entire web, so we're controlling this by using a lot of seeds, for example from swoogle or from Google meta crawling and these kind of things and the crawler is just basically looking for."
        ],
        [
            "For your eye patterns that match ontologies like Dot old RDF dot TTL or another 20 or 30 different types of extensions."
        ],
        [
            "Stores them somewhere and then we have a downloader.",
            "Regularly looking whether the they can weather this candidate.",
            "URLs can be downloaded into and restore them."
        ],
        [
            "At summer and then it gets shorter."
        ],
        [
            "To the filtering process.",
            "So in the filtering process."
        ],
        [
            "As in our initial study, that is also in the paper we looked at 200, so we downloaded 270 thousand candidates.",
            "We first started to weed out by some simple syntactic heuristics, basically matching all the different syntactic variants of the Owl namespace declaration, and if that wasn't there, or some other little things, then we just threw them out.",
            "So this was basically we've got rid of 30 around 37 thousand of them, and then we pairwise compared to the rest of the candidates, and we checked out all the ones that were.",
            "Provide identical.",
            "After that we started loading, so parsing them.",
            "We use the OWL API for this purpose because it's as far as we know the most comprehensible comprehensive API that we have and 5000 were not possible usually due to unloadable imports but also some syntactic problems, and after that we did another round of deduplication by tracking out all the ones that had the same owl XML serialization.",
            "So we."
        ],
        [
            "Serialized to a common format.",
            "And yeah, so the main and most painful part of this study was basically then what do we do with the rest?",
            "There is still a very big amount of files in our our corpus at this point.",
            "200,000, and just eyeballing it shows that they are still.",
            "There are a lot of, let's say, Semantic Media Wiki documents in there that they are just a lot of kind of files that we don't want to consider as ontologies when we do our research so.",
            "What we do here is we basically randomly sample 100 ontologies at a time.",
            "Are researchers doing that?",
            "He's looking at it and then he clusters this sample according to file size, file naming and URL patterns.",
            "And then he's just sees OK there.",
            "Let's say a big cluster of files that come from Semantic Mediawiki and we just throw all of this out so that we basically reach to a more set of something that we consider more like distinct ontologies."
        ],
        [
            "And for our particular purpose we also because we created this corpus in the 1st place to fuel studies on description.",
            "So on the DL on our DL and for a reason or benchmarking and things like that.",
            "So we also then removed everything that was just our DFS and our full after that point and we ended up with 4547 unique in some way and non."
        ],
        [
            "Via our DL files.",
            "So yeah, how do we evaluate that kind of thing?",
            "That is not very straightforward.",
            "This is just some sort of indication random sample of the.",
            "Of the ontologies before the curation, the same amount of ontologies in here than in the in the corpus.",
            "Afterwards this is just a graph where the dots represent all of the edges resent represent some similarity relation which is basically based on signature overlap and you can see that there are still like really really big clusters before the curation and after decorations looks much better.",
            "There's still clusters in there, but generally at least the fragmentation is.",
            "Much higher so."
        ],
        [
            "That's OK, just to say again, this filtering part was a bit time consuming and we know it's it's not really easy to evaluate whether that's fine, but it's also still not 100% complete, so if anyone has already seen this corpus, then they will find that there are still some copies of the Koala ontologies in various forms in there.",
            "And of course, in this way we cannot really get rid of them.",
            "So the problem of automation is here.",
            "Still a bit unsolved.",
            "So."
        ],
        [
            "So in terms of corpus comparison, we wanted to then see how does this corpus look like in relation to other existing corpora.",
            "So we compared it to bioportal a dump from November 2012 and two.",
            "Oxford Ontology Library that we downloaded in April 2013 told that owns repository that has more than 205 items, but 205 items will table at that point and smooth as swoogle sample from a kind of a bit biased dump of swoogle towards owl and scores ontologies.",
            "I think yeah.",
            "So with 2002 thousand items in there and OK."
        ],
        [
            "And due to the time detail, a lot about what we find out what we found out about.",
            "This is a lot about all the different things that you can compare like data type, profile violations were kind of logical entities they used, but just to get a flavor, how this looks like so we can see here that for example, in terms of class.",
            "A class based axioms.",
            "We have subclass of axioms in the crawl in Oxford are roughly around 80% in Bio Portland tones.",
            "There are more towards 100% and in swoogle there's almost none of that, so very few that actually have star plus of axiom and the same thing, just with 40%.",
            "Here you can see for equivalent classes and in terms of profiles just to point out maybe the most interesting things is the crawl has a very high amount of pure DL in there that so.",
            "This bar represents the L that is not in another profile.",
            "These here represent the profiles, but they don't add up because they have intersection as well.",
            "So yeah, and also what is a bit.",
            "It may be interesting to see if that both the crawl and Oxford, which are really big.",
            "The bigger repository's here have only very little El in there, but there's just one thing that we noticed."
        ],
        [
            "OK, some rivers have complained a bit about that.",
            "We don't actually look at how these corpora intersect, and since we don't have enough metadata to really compare that perfectly, we did some.",
            "Study where we basically pairwise compared all the ontologies and the one corpus with the other corpus.",
            "It again with the similarity metrics that the that that I said before where we compare the signatures and if the signature intersection is more than 90% and we say OK these are similar or with a containment relation where we say OK if the one signature contains the other or vice versa, then they are also similar and according to these two metrics we can see for example that.",
            "The crawl and swoogle have still a lot of similarity.",
            "This is probably due to the fact that we've used heavily the seeds from Swoogle.",
            "When we were crawling in, there might still be a lot.",
            "There might still be some ontologies that were just found by this crawl, and they're not included in all the other repositories, and there's this interesting similarity between tones and Oxford on both.",
            "Both of these metrics basically also probably due to the fact that they were can't crafted for the purpose of experimentation, and they might actually have a lot of overlap because of that.",
            "OK, so."
        ],
        [
            "How are we using this at the moment?",
            "So for example, this year we have conducted the reasner evaluation.",
            "The Reason Evaluation Workshop or the reason the contest and the Reason Evaluation Workshop that was Co located with the DL.",
            "It's with this data set, so the this crawl was the main contributor to the data set that was used in this competition and it was really, really great.",
            "I think experience for most people that were there and we got a lot of good feedback on that.",
            "We use this for our study on regional robustness, which is which we also presented at DL, but will that will also be presented later on in the poster session today.",
            "And some other works of colleagues benefits of refinements.",
            "Performance prediction of reasoners and other web services service that are currently being."
        ],
        [
            "OK, So what what do we want to achieve with this?",
            "We want to in the end create a well indexed repository of ontologies in the same way that that Watson was repository that you could basically use an API to retrieve ontologies from.",
            "We want to use a lot of variety of metrics so that queries such as give me ontologies that have more than 100 axioms and RNA else.",
            "Are possible and you can then, so this is the idea we want to allow to download these kind of datasets and then enable sharing datasets by creating an identifier for that data set that can just be put in the paper.",
            "For example.",
            "And yeah, the crawl is now an ongoing crawl.",
            "Took away to set this up properly, but now it's an ongoing crawl as well and we are currently playing around with ideas on how we could automate the manual cleaning.",
            "Maybe, or maybe if that is not really possible to enable some more cluster based sampling to get to interesting sets of ontologies."
        ],
        [
            "OK, with that I want to close if anyone is interested you can go to the.",
            "URL there yeah.",
            "Or write an email and thank you very much for that."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hello everyone, I'm going to present to you some joint work with Samantha Beilinson parser from the University of Manchester and as we have heard this morning I'll or ontologies in general might be off a little bit lesser interest, but I saw also that the graph I think was rising towards the end of it.",
                    "label": 0
                },
                {
                    "sent": "But anyways I'm going to talk.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It's about in the same line as to my previous previous speaker about experiments and what we can do in order to improve the datasets that we use for our experimentation so.",
                    "label": 0
                },
                {
                    "sent": "Some assumptions about the Web ontology language.",
                    "label": 1
                },
                {
                    "sent": "We use your eyes for virtually everything for identifiers for individuals, for classes, for properties, and we have some web based features such as the old import statement which refers to another web resource, another ontology that is imported, and we use even kind of more savvy things that, for example, like relative, your eye resolution.",
                    "label": 0
                },
                {
                    "sent": "So we believe that publishing out on the web is generally encouraged and that we can actually find.",
                    "label": 0
                },
                {
                    "sent": "Most hours somewhere on the web we know this not everything, of course, but most of it.",
                    "label": 0
                },
                {
                    "sent": "And in order to understand it for us as our researchers, for example, like math, later we want to understand about what kind of constructs people are using generally, and very often we first must find a suitable set for.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Research, So what people generally do they resort to certain, like, for example exemplars, they look at important ontologies such as snow met, or they look at for particular purposes.",
                    "label": 0
                },
                {
                    "sent": "Particularly difficult ontology, such as gaining, for example, if they want to evaluate reasoners, they can look at curated collections like Bio Portal, which is probably the most important real corpus that we have with roughly around 350 downloadable ontologies in there, or some handcrafted.",
                    "label": 0
                },
                {
                    "sent": "The corpora such as tones and the Oxford Ontology Library, which are meant to help with empirical or which provides some interesting ontologies for empirical research.",
                    "label": 0
                },
                {
                    "sent": "Or, Alternatively, we can resort to like large scale repository's.",
                    "label": 0
                },
                {
                    "sent": "These two accrual based Swoogle semantic web search engine.",
                    "label": 0
                },
                {
                    "sent": "We could say randomly sample from what's Google has to offer or what the search engine has to offer and then do our study based on that.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But they're generally problems with this.",
                    "label": 0
                },
                {
                    "sent": "We have obviously not only ontologies and there we have a lot of semantic Web documents.",
                    "label": 0
                },
                {
                    "sent": "We have versions of ontologies we have ontologies that our path published in a faceted way, and we don't want to treat each facet as a separate ontology, so.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Might be not very suitable for this purpose, so we ask ourselves, can we create a somehow more representative collection of.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Paula geez, so the goal of this reset?",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I should take a snapshot of the our web so as we perceive, we say we think of a snapshot as a collection of somehow distinct ontologies of arbitrary, but in some way representative origins.",
                    "label": 0
                },
                {
                    "sent": "So from various domains not only for example from the biomedical domain at some given point in time, and we want to get such a snapshot because we want to improve our empirical work we want.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To raise the generalizability of the of our findings, when we, for example, make surveys about modular structure of ontologies, we want to test our tools and techniques and we want to make informed decisions such as whether we want to employ a language extent, which whether we should put forward a language extension or invest money in developing a certain feature for offer tool or some.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Like that, So what I'm going to talk to you about for a bit is the process by which we reached to this corpus, and by talking a bit about how we gathered the data initially, how we curated it.",
                    "label": 0
                },
                {
                    "sent": "Various steps and then how we are actually using it at the moment.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the data gap.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "During process is straightforward.",
                    "label": 0
                },
                {
                    "sent": "We have a standard open source crawler that is fueled with a with a very wide range of seats.",
                    "label": 0
                },
                {
                    "sent": "Obviously we cannot crawl the entire web, so we're controlling this by using a lot of seeds, for example from swoogle or from Google meta crawling and these kind of things and the crawler is just basically looking for.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For your eye patterns that match ontologies like Dot old RDF dot TTL or another 20 or 30 different types of extensions.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Stores them somewhere and then we have a downloader.",
                    "label": 0
                },
                {
                    "sent": "Regularly looking whether the they can weather this candidate.",
                    "label": 0
                },
                {
                    "sent": "URLs can be downloaded into and restore them.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At summer and then it gets shorter.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To the filtering process.",
                    "label": 0
                },
                {
                    "sent": "So in the filtering process.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As in our initial study, that is also in the paper we looked at 200, so we downloaded 270 thousand candidates.",
                    "label": 0
                },
                {
                    "sent": "We first started to weed out by some simple syntactic heuristics, basically matching all the different syntactic variants of the Owl namespace declaration, and if that wasn't there, or some other little things, then we just threw them out.",
                    "label": 0
                },
                {
                    "sent": "So this was basically we've got rid of 30 around 37 thousand of them, and then we pairwise compared to the rest of the candidates, and we checked out all the ones that were.",
                    "label": 0
                },
                {
                    "sent": "Provide identical.",
                    "label": 0
                },
                {
                    "sent": "After that we started loading, so parsing them.",
                    "label": 0
                },
                {
                    "sent": "We use the OWL API for this purpose because it's as far as we know the most comprehensible comprehensive API that we have and 5000 were not possible usually due to unloadable imports but also some syntactic problems, and after that we did another round of deduplication by tracking out all the ones that had the same owl XML serialization.",
                    "label": 0
                },
                {
                    "sent": "So we.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Serialized to a common format.",
                    "label": 0
                },
                {
                    "sent": "And yeah, so the main and most painful part of this study was basically then what do we do with the rest?",
                    "label": 0
                },
                {
                    "sent": "There is still a very big amount of files in our our corpus at this point.",
                    "label": 0
                },
                {
                    "sent": "200,000, and just eyeballing it shows that they are still.",
                    "label": 0
                },
                {
                    "sent": "There are a lot of, let's say, Semantic Media Wiki documents in there that they are just a lot of kind of files that we don't want to consider as ontologies when we do our research so.",
                    "label": 0
                },
                {
                    "sent": "What we do here is we basically randomly sample 100 ontologies at a time.",
                    "label": 0
                },
                {
                    "sent": "Are researchers doing that?",
                    "label": 0
                },
                {
                    "sent": "He's looking at it and then he clusters this sample according to file size, file naming and URL patterns.",
                    "label": 0
                },
                {
                    "sent": "And then he's just sees OK there.",
                    "label": 0
                },
                {
                    "sent": "Let's say a big cluster of files that come from Semantic Mediawiki and we just throw all of this out so that we basically reach to a more set of something that we consider more like distinct ontologies.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And for our particular purpose we also because we created this corpus in the 1st place to fuel studies on description.",
                    "label": 0
                },
                {
                    "sent": "So on the DL on our DL and for a reason or benchmarking and things like that.",
                    "label": 0
                },
                {
                    "sent": "So we also then removed everything that was just our DFS and our full after that point and we ended up with 4547 unique in some way and non.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Via our DL files.",
                    "label": 0
                },
                {
                    "sent": "So yeah, how do we evaluate that kind of thing?",
                    "label": 0
                },
                {
                    "sent": "That is not very straightforward.",
                    "label": 0
                },
                {
                    "sent": "This is just some sort of indication random sample of the.",
                    "label": 0
                },
                {
                    "sent": "Of the ontologies before the curation, the same amount of ontologies in here than in the in the corpus.",
                    "label": 0
                },
                {
                    "sent": "Afterwards this is just a graph where the dots represent all of the edges resent represent some similarity relation which is basically based on signature overlap and you can see that there are still like really really big clusters before the curation and after decorations looks much better.",
                    "label": 0
                },
                {
                    "sent": "There's still clusters in there, but generally at least the fragmentation is.",
                    "label": 0
                },
                {
                    "sent": "Much higher so.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That's OK, just to say again, this filtering part was a bit time consuming and we know it's it's not really easy to evaluate whether that's fine, but it's also still not 100% complete, so if anyone has already seen this corpus, then they will find that there are still some copies of the Koala ontologies in various forms in there.",
                    "label": 1
                },
                {
                    "sent": "And of course, in this way we cannot really get rid of them.",
                    "label": 0
                },
                {
                    "sent": "So the problem of automation is here.",
                    "label": 0
                },
                {
                    "sent": "Still a bit unsolved.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in terms of corpus comparison, we wanted to then see how does this corpus look like in relation to other existing corpora.",
                    "label": 0
                },
                {
                    "sent": "So we compared it to bioportal a dump from November 2012 and two.",
                    "label": 0
                },
                {
                    "sent": "Oxford Ontology Library that we downloaded in April 2013 told that owns repository that has more than 205 items, but 205 items will table at that point and smooth as swoogle sample from a kind of a bit biased dump of swoogle towards owl and scores ontologies.",
                    "label": 1
                },
                {
                    "sent": "I think yeah.",
                    "label": 0
                },
                {
                    "sent": "So with 2002 thousand items in there and OK.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And due to the time detail, a lot about what we find out what we found out about.",
                    "label": 0
                },
                {
                    "sent": "This is a lot about all the different things that you can compare like data type, profile violations were kind of logical entities they used, but just to get a flavor, how this looks like so we can see here that for example, in terms of class.",
                    "label": 0
                },
                {
                    "sent": "A class based axioms.",
                    "label": 0
                },
                {
                    "sent": "We have subclass of axioms in the crawl in Oxford are roughly around 80% in Bio Portland tones.",
                    "label": 0
                },
                {
                    "sent": "There are more towards 100% and in swoogle there's almost none of that, so very few that actually have star plus of axiom and the same thing, just with 40%.",
                    "label": 0
                },
                {
                    "sent": "Here you can see for equivalent classes and in terms of profiles just to point out maybe the most interesting things is the crawl has a very high amount of pure DL in there that so.",
                    "label": 0
                },
                {
                    "sent": "This bar represents the L that is not in another profile.",
                    "label": 0
                },
                {
                    "sent": "These here represent the profiles, but they don't add up because they have intersection as well.",
                    "label": 0
                },
                {
                    "sent": "So yeah, and also what is a bit.",
                    "label": 0
                },
                {
                    "sent": "It may be interesting to see if that both the crawl and Oxford, which are really big.",
                    "label": 0
                },
                {
                    "sent": "The bigger repository's here have only very little El in there, but there's just one thing that we noticed.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, some rivers have complained a bit about that.",
                    "label": 0
                },
                {
                    "sent": "We don't actually look at how these corpora intersect, and since we don't have enough metadata to really compare that perfectly, we did some.",
                    "label": 0
                },
                {
                    "sent": "Study where we basically pairwise compared all the ontologies and the one corpus with the other corpus.",
                    "label": 0
                },
                {
                    "sent": "It again with the similarity metrics that the that that I said before where we compare the signatures and if the signature intersection is more than 90% and we say OK these are similar or with a containment relation where we say OK if the one signature contains the other or vice versa, then they are also similar and according to these two metrics we can see for example that.",
                    "label": 0
                },
                {
                    "sent": "The crawl and swoogle have still a lot of similarity.",
                    "label": 0
                },
                {
                    "sent": "This is probably due to the fact that we've used heavily the seeds from Swoogle.",
                    "label": 0
                },
                {
                    "sent": "When we were crawling in, there might still be a lot.",
                    "label": 0
                },
                {
                    "sent": "There might still be some ontologies that were just found by this crawl, and they're not included in all the other repositories, and there's this interesting similarity between tones and Oxford on both.",
                    "label": 0
                },
                {
                    "sent": "Both of these metrics basically also probably due to the fact that they were can't crafted for the purpose of experimentation, and they might actually have a lot of overlap because of that.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "How are we using this at the moment?",
                    "label": 0
                },
                {
                    "sent": "So for example, this year we have conducted the reasner evaluation.",
                    "label": 0
                },
                {
                    "sent": "The Reason Evaluation Workshop or the reason the contest and the Reason Evaluation Workshop that was Co located with the DL.",
                    "label": 0
                },
                {
                    "sent": "It's with this data set, so the this crawl was the main contributor to the data set that was used in this competition and it was really, really great.",
                    "label": 0
                },
                {
                    "sent": "I think experience for most people that were there and we got a lot of good feedback on that.",
                    "label": 0
                },
                {
                    "sent": "We use this for our study on regional robustness, which is which we also presented at DL, but will that will also be presented later on in the poster session today.",
                    "label": 0
                },
                {
                    "sent": "And some other works of colleagues benefits of refinements.",
                    "label": 1
                },
                {
                    "sent": "Performance prediction of reasoners and other web services service that are currently being.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, So what what do we want to achieve with this?",
                    "label": 0
                },
                {
                    "sent": "We want to in the end create a well indexed repository of ontologies in the same way that that Watson was repository that you could basically use an API to retrieve ontologies from.",
                    "label": 1
                },
                {
                    "sent": "We want to use a lot of variety of metrics so that queries such as give me ontologies that have more than 100 axioms and RNA else.",
                    "label": 0
                },
                {
                    "sent": "Are possible and you can then, so this is the idea we want to allow to download these kind of datasets and then enable sharing datasets by creating an identifier for that data set that can just be put in the paper.",
                    "label": 0
                },
                {
                    "sent": "For example.",
                    "label": 0
                },
                {
                    "sent": "And yeah, the crawl is now an ongoing crawl.",
                    "label": 1
                },
                {
                    "sent": "Took away to set this up properly, but now it's an ongoing crawl as well and we are currently playing around with ideas on how we could automate the manual cleaning.",
                    "label": 0
                },
                {
                    "sent": "Maybe, or maybe if that is not really possible to enable some more cluster based sampling to get to interesting sets of ontologies.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, with that I want to close if anyone is interested you can go to the.",
                    "label": 0
                },
                {
                    "sent": "URL there yeah.",
                    "label": 0
                },
                {
                    "sent": "Or write an email and thank you very much for that.",
                    "label": 0
                }
            ]
        }
    }
}