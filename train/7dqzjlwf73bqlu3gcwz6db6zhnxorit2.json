{
    "id": "7dqzjlwf73bqlu3gcwz6db6zhnxorit2",
    "title": "GeoMF: Joint Geographical Modeling and Matrix Factorization for Point-of-Interest Recommendation",
    "info": {
        "author": [
            "Xing Xie, Microsoft Research Asia, Microsoft Research"
        ],
        "published": "Oct. 7, 2014",
        "recorded": "August 2014",
        "category": [
            "Top->Computer Science->Data Mining",
            "Top->Computer Science->Knowledge Extraction"
        ]
    },
    "url": "http://videolectures.net/kdd2014_xie_geomf/",
    "segmentation": [
        [
            "So I'm seeing here from Microsoft Research Asia and the leases joint work between Mac, so research and the University of Science and Technology of China.",
            "So in this work I will recent work on joint geographical modeling and metric factorization for point of interest recommendation.",
            "So we called GMF."
        ],
        [
            "So basically we are working on location recommendation so it is an important application, so I think we have already seen two talks about recommendation in this session so.",
            "For local recommendation, basically we first need to understand the use of potential interest and then we need to be familiar with the surroundings.",
            "And with these two type of knowledge we can use design model to discover interesting values for the users.",
            "So the difference between location recommendation and the other contests as seen here is we have spatial information or we call it geographical knowledge, which should be an important factor for the recommendation performance.",
            "So the figures are here, let's see.",
            "Yeah, the figures here actually shows the human mobility, which actually was shown to be highly clustered.",
            "For example, you usually.",
            "Go to some place near your home near your work location and there's some important locations.",
            "And also the figure in the middle shows the distance, the distribution of distance between two consecutive checkings.",
            "So we can see that most of the constructed checkings actually quite close to each other.",
            "For them here.",
            "Actually we can see it's most of the checking out within 1 kilometer.",
            "So this is log scale."
        ],
        [
            "So usually we represent the user data or look for recommendation.",
            "Actually as a metrics so we can use metric factoring here.",
            "So basically this we have a dimension of user and we have a dimension of item.",
            "Here the item is location of equality point of interest.",
            "For location flow character recommendation, actually one difference is here.",
            "Usually we can.",
            "It's difficult to get the preference of users to each location.",
            "Actually that is very huge labeling effort.",
            "So usually we can only get the location history data of users.",
            "For example using any location sensing device using smartphone or or etc.",
            "So this metric shows we could have for example how frequent this user has been to this location like.",
            "If you can see the mouse, you can see this user a may have been here for five times so we can have a 5 here.",
            "In general, we can view this as an implicit feedback.",
            "That means the user actually didn't give any label for the location.",
            "Basically, we only know how frequently this user has been there, so this just implicitly indicate the user is has some preference on this location.",
            "So with the location basically implies some individual preference, but the frequency here doesn't really mean.",
            "The user is more preferred or not depending on the frequency.",
            "Then the value of the frequency.",
            "It usually implies the confidence of the purpose.",
            "I mean how confidence?",
            "We can say this user is preferred.",
            "This user prefer this location.",
            "And for those missing values, so for this like zeros.",
            "Is this actually on those unvisited locations so it's difficult to distinguish whether these unvisited locations, whether they are negative or positive?",
            "Here positive means the user preferred this location.",
            "So so so if we look at this, we can see this is a typical in implicit feedback data.",
            "But if we look at an example, we can have some ideas of how we can further distinguish this unvisited locations or missing values.",
            "If we look at this, this is a map of Beijing.",
            "In this map, actually we show the mobility data for user.",
            "We can see this user is active in this area.",
            "This could be like junction area and the user is not active in another area.",
            "So for a location for unvisited location in this region.",
            "We can probably.",
            "We can say this more probably to be negative, but for location in the other region which user is not that active.",
            "This could be a mixed mixture of negative and positive location, so this is basically the motivation of this work.",
            "So we try to use some ways to distinguish this on visit locations according to the distance between these locations and use active areas.",
            "So the idea is an visit location near the active use active area could potentially be negative.",
            "So the problem is here how we can define the user activity, activity area and also how to define the influence region of the location.",
            "Because for different type of locations they may have different type of influence regions for result.",
            "If it is very popular maybe people can come far away to this restaurant, but for the local restaurant maybe only only user nearby will visit them."
        ],
        [
            "Now already actually quite a few related work in this space.",
            "For example, we have two lines of related work.",
            "One is on geographic modeling.",
            "People try to model the geography geographical clustering phenomenon of this user mobility and use that to help locate recommendation, which is quite similar to our work.",
            "But basically they don't really view the problem as an implicit feedback, and they have used different.",
            "Recommendation framework.",
            "So in our approach we use nonparametric modeling for the geographic modeling and for the on.",
            "The airline is the recommended framework for the location recommendation.",
            "In general, we have seen like non negative matrix factorization.",
            "We have seen user based CF and we have seen random work and in our work we try to leverage the weighted recognize regularised metric factorization because it has been shown to work well.",
            "For those implicit feedback data.",
            "So basically this."
        ],
        [
            "In this work, first we have three.",
            "I think we have three tasks.",
            "Firstly, how to model the geographical clustering phenomenon.",
            "Here we use a 2D kernel density estimation and 2nd is how we were kind of recommendation framework we are using.",
            "Here we use a weighted recognized metric factorization and then we combine these two into a joint model we call GMF."
        ],
        [
            "So in.",
            "So in summary, actually this still MF.",
            "Basically we try to extend the traditional met refrigeration framework.",
            "Usually we have a user pure metrics here.",
            "The value here is could be a 01 rating metric, which shows the preference of the users.",
            "And traditionally, basically we can.",
            "Divide this into two latent factor vectors.",
            "Why is like we call it user latent factors?",
            "The other card location, latent factors, and in our framework we argument leads to latent factors for user latent factors, we will add a user activity area vectors to the users.",
            "To this to this vector and further location latent factors we will add the influence the location inference areas.",
            "So as I've said that the activity areas means how active users was in this in these areas.",
            "So we divide the whole map into a set of grids.",
            "Here the number of grids is L here, so we have the air.",
            "Vectors for all the users.",
            "And also for a location with defined the influence areas.",
            "How influential this location disappeared?",
            "Why this could be a restaurant has for any individual area among these errors.",
            "So this is the basic framework for our for our GMF."
        ],
        [
            "So let's come to the objective function.",
            "So basically because we have add here, we call it X&YX stands for activity area and Y stand for inference cherry.",
            "And then we have added this XY to the original P&Q.",
            "Here P just is the user latent factor and Q is the location latent effect factors.",
            "So we added this XY 2P and Q.",
            "So the objective function become.",
            "We will calculate P&P butter by Q and then add by X * Y and use this to approximate RR is the original rating metrics.",
            "And because of we use weighted measure of activation.",
            "So we will have a wait here.",
            "So this wait actually stands for how confident we have for each of the approximation.",
            "So this weight is defined using this function.",
            "Basically here Cus I means the visit frequency of user you too to allocation I.",
            "Another is a hereafter is a monotone increasing function.",
            "That means if the visiting frequency of this user to the location I is large, then we will have a large weight.",
            "For in this objective function, that means we have more confidence for this approximation, and this large weight.",
            "Basically we use that to help to get more accurate approximation for this value and we have some regularization items for PQ&X here.",
            "So in general here we will fix Y and we try to learn PQ&X from the data.",
            "And for White here we use a 2D kernel density estimation.",
            "Here why means the location inference regions influence areas?"
        ],
        [
            "So the inference for each grade.",
            "This grass I've said we have divided the whole map into UU grids.",
            "If these are red, point is the location is a restaurant.",
            "For example, put pie and it depends on the distance from the grid to this location.",
            "We have different densities here.",
            "For example this FJ&K.",
            "This grades the weather could be 0.6 and for a actually it could be 0.1.",
            "So it's like Gaussian distribution.",
            "And then if we have this location influence areas.",
            "And we also, if we have already learned the user activity areas, then we can multiply them together to calculate the geographical preference of this user to the point of interest.",
            "I.",
            "So that means if the user is active at some region and also this region is influenced highly influenced by a restaurant or buy some pie and then the user could have a higher geographical preference over the supply."
        ],
        [
            "So for optimization we have already introduced our object function.",
            "So for optimization basically use iterative approach.",
            "So basically two step.",
            "First we fix X and then we update P&Q and in the paper we have calculated time complexity."
        ],
        [
            "And then the next step is fixed P&Q and then we update the X.",
            "So we do this iteratively.",
            "I will not go into the detail, but we have a nurse for the time complexity for both steps."
        ],
        [
            "And in this way, actually, we can distinguish the unvisited locations.",
            "I assume will be fixed X and then we are actually if we revisit the object function so we actually approximate knew our this this I storage rating metrics and you are mean is actually the I will be minus by the X * Y X&Y.",
            "Here at the activity area and influence areas.",
            "So for use given user if he has some activity area and for a location I around this active area is very probably.",
            "These are could be negative because user because if the user to visit frequency is a positive value and this if the influence is also a positive value then this could be very probably negative value.",
            "That means on visit locations around those frequent visits areas are highly likely to be negative.",
            "So that means we add more negative labels to the original data set.",
            "So this means how we can distinguish those unvisited."
        ],
        [
            "Asians?",
            "So we go to let's go to the experiments.",
            "So basically we have a data set from China which is location based social networks, which is similar to Foursquare.",
            "We have crowded there set for three years and we have data from quite a few cities.",
            "For example in Shanghai, which is a big city in China, we have 4400 about 400,000 users and they have 225 million checkings.",
            "And for paging we have also we have about 160,000 users.",
            "We extract about 30% of the locations for testing and we use the remaining data for training and we round the expenses for five independent trials and elation metric.",
            "Here is because we can calculate the preference of user to any location.",
            "So we output the top K result in the testing locations and we calculate the required precision for these top K. Output so we average result as the final output."
        ],
        [
            "So we compare our algorithm with a set of baselines including user based collaborative filtering, which is widely used in the industry and also will compare with previous work is based in non negative matrix factorization and we also based compare algorithm with a simple approach will be quite regularize SVD which is based on the 01 metrics and also we extend this 01 metric to a frequency metrics.",
            "That means we use frequency.",
            "To stand, stand for the represent the preference.",
            "That means we don't use the frequency to represent confidence by the by the preference here, so we do another metric factorization based on these visiting frequency metrics.",
            "We want to compare this to approach and also we tried.",
            "We improve our algorithm by considering bio.",
            "So we called WMF bias.",
            "So if we look at this figure we can see that this actually the bottom this.",
            "Co is from the MF frequency.",
            "That means if we can see the frequency as the preference, the performance is very low.",
            "So that means we should not do that.",
            "And we found that a simple approach MF 01.",
            "Here is the red line here, which actually the performance is quite good.",
            "It is even better than UC F and the basin nonnegative matrix factorization.",
            "And our approach is WMF.",
            "The top 2 lines WMF and WFB.",
            "Considering bias, but we found that considering bias, the improvement is very very small, so it may not be necessary to do this.",
            "One reason is maybe this metric Federation for locations because we work use a 01 matrix rating metrics.",
            "So maybe the bias here is not that significant."
        ],
        [
            "So to summary for the for the first set of experiments, we found that our approach we called WF here is we outperformance UC F and the negative base in MF.",
            "And also it outperformance outperforms the simple approach which called MF01 matrix.",
            "And and also we found I'd embarrass, which is not.",
            "There's not big effect."
        ],
        [
            "And Secondly, we try to study OK. Yeah, we could go through study the spatial clustering phenomenon.",
            "So basically remove P&QP&Q means the user latent location, latent factors and we study.",
            "We compare this with two DKD and non weighted version."
        ],
        [
            "Yeah, I think I will skip."
        ],
        [
            "And in summary, we outperformance the outperformed too simple, apologize the traditional weight weighted macrophyte Reggie and the other is the week and we only you consider the Geo clustering phenomenon here.",
            "So we need to combine these two to get better performance."
        ],
        [
            "OK, to conclude this talk.",
            "Basically we propose a 2D kernel density estimation for the gram modeling and then we combine that with weighted metric factorization and get better performance compared with baselines.",
            "And we propose a learning algorithm and we analyze the time complexity.",
            "OK so thank you and questions."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I'm seeing here from Microsoft Research Asia and the leases joint work between Mac, so research and the University of Science and Technology of China.",
                    "label": 1
                },
                {
                    "sent": "So in this work I will recent work on joint geographical modeling and metric factorization for point of interest recommendation.",
                    "label": 0
                },
                {
                    "sent": "So we called GMF.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So basically we are working on location recommendation so it is an important application, so I think we have already seen two talks about recommendation in this session so.",
                    "label": 1
                },
                {
                    "sent": "For local recommendation, basically we first need to understand the use of potential interest and then we need to be familiar with the surroundings.",
                    "label": 0
                },
                {
                    "sent": "And with these two type of knowledge we can use design model to discover interesting values for the users.",
                    "label": 0
                },
                {
                    "sent": "So the difference between location recommendation and the other contests as seen here is we have spatial information or we call it geographical knowledge, which should be an important factor for the recommendation performance.",
                    "label": 0
                },
                {
                    "sent": "So the figures are here, let's see.",
                    "label": 0
                },
                {
                    "sent": "Yeah, the figures here actually shows the human mobility, which actually was shown to be highly clustered.",
                    "label": 0
                },
                {
                    "sent": "For example, you usually.",
                    "label": 0
                },
                {
                    "sent": "Go to some place near your home near your work location and there's some important locations.",
                    "label": 0
                },
                {
                    "sent": "And also the figure in the middle shows the distance, the distribution of distance between two consecutive checkings.",
                    "label": 0
                },
                {
                    "sent": "So we can see that most of the constructed checkings actually quite close to each other.",
                    "label": 0
                },
                {
                    "sent": "For them here.",
                    "label": 0
                },
                {
                    "sent": "Actually we can see it's most of the checking out within 1 kilometer.",
                    "label": 0
                },
                {
                    "sent": "So this is log scale.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So usually we represent the user data or look for recommendation.",
                    "label": 0
                },
                {
                    "sent": "Actually as a metrics so we can use metric factoring here.",
                    "label": 0
                },
                {
                    "sent": "So basically this we have a dimension of user and we have a dimension of item.",
                    "label": 0
                },
                {
                    "sent": "Here the item is location of equality point of interest.",
                    "label": 0
                },
                {
                    "sent": "For location flow character recommendation, actually one difference is here.",
                    "label": 0
                },
                {
                    "sent": "Usually we can.",
                    "label": 0
                },
                {
                    "sent": "It's difficult to get the preference of users to each location.",
                    "label": 0
                },
                {
                    "sent": "Actually that is very huge labeling effort.",
                    "label": 0
                },
                {
                    "sent": "So usually we can only get the location history data of users.",
                    "label": 0
                },
                {
                    "sent": "For example using any location sensing device using smartphone or or etc.",
                    "label": 0
                },
                {
                    "sent": "So this metric shows we could have for example how frequent this user has been to this location like.",
                    "label": 0
                },
                {
                    "sent": "If you can see the mouse, you can see this user a may have been here for five times so we can have a 5 here.",
                    "label": 0
                },
                {
                    "sent": "In general, we can view this as an implicit feedback.",
                    "label": 1
                },
                {
                    "sent": "That means the user actually didn't give any label for the location.",
                    "label": 0
                },
                {
                    "sent": "Basically, we only know how frequently this user has been there, so this just implicitly indicate the user is has some preference on this location.",
                    "label": 0
                },
                {
                    "sent": "So with the location basically implies some individual preference, but the frequency here doesn't really mean.",
                    "label": 0
                },
                {
                    "sent": "The user is more preferred or not depending on the frequency.",
                    "label": 0
                },
                {
                    "sent": "Then the value of the frequency.",
                    "label": 0
                },
                {
                    "sent": "It usually implies the confidence of the purpose.",
                    "label": 1
                },
                {
                    "sent": "I mean how confidence?",
                    "label": 0
                },
                {
                    "sent": "We can say this user is preferred.",
                    "label": 0
                },
                {
                    "sent": "This user prefer this location.",
                    "label": 0
                },
                {
                    "sent": "And for those missing values, so for this like zeros.",
                    "label": 0
                },
                {
                    "sent": "Is this actually on those unvisited locations so it's difficult to distinguish whether these unvisited locations, whether they are negative or positive?",
                    "label": 1
                },
                {
                    "sent": "Here positive means the user preferred this location.",
                    "label": 0
                },
                {
                    "sent": "So so so if we look at this, we can see this is a typical in implicit feedback data.",
                    "label": 0
                },
                {
                    "sent": "But if we look at an example, we can have some ideas of how we can further distinguish this unvisited locations or missing values.",
                    "label": 0
                },
                {
                    "sent": "If we look at this, this is a map of Beijing.",
                    "label": 0
                },
                {
                    "sent": "In this map, actually we show the mobility data for user.",
                    "label": 0
                },
                {
                    "sent": "We can see this user is active in this area.",
                    "label": 0
                },
                {
                    "sent": "This could be like junction area and the user is not active in another area.",
                    "label": 0
                },
                {
                    "sent": "So for a location for unvisited location in this region.",
                    "label": 0
                },
                {
                    "sent": "We can probably.",
                    "label": 0
                },
                {
                    "sent": "We can say this more probably to be negative, but for location in the other region which user is not that active.",
                    "label": 1
                },
                {
                    "sent": "This could be a mixed mixture of negative and positive location, so this is basically the motivation of this work.",
                    "label": 0
                },
                {
                    "sent": "So we try to use some ways to distinguish this on visit locations according to the distance between these locations and use active areas.",
                    "label": 0
                },
                {
                    "sent": "So the idea is an visit location near the active use active area could potentially be negative.",
                    "label": 0
                },
                {
                    "sent": "So the problem is here how we can define the user activity, activity area and also how to define the influence region of the location.",
                    "label": 0
                },
                {
                    "sent": "Because for different type of locations they may have different type of influence regions for result.",
                    "label": 0
                },
                {
                    "sent": "If it is very popular maybe people can come far away to this restaurant, but for the local restaurant maybe only only user nearby will visit them.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now already actually quite a few related work in this space.",
                    "label": 0
                },
                {
                    "sent": "For example, we have two lines of related work.",
                    "label": 1
                },
                {
                    "sent": "One is on geographic modeling.",
                    "label": 0
                },
                {
                    "sent": "People try to model the geography geographical clustering phenomenon of this user mobility and use that to help locate recommendation, which is quite similar to our work.",
                    "label": 0
                },
                {
                    "sent": "But basically they don't really view the problem as an implicit feedback, and they have used different.",
                    "label": 0
                },
                {
                    "sent": "Recommendation framework.",
                    "label": 1
                },
                {
                    "sent": "So in our approach we use nonparametric modeling for the geographic modeling and for the on.",
                    "label": 0
                },
                {
                    "sent": "The airline is the recommended framework for the location recommendation.",
                    "label": 1
                },
                {
                    "sent": "In general, we have seen like non negative matrix factorization.",
                    "label": 0
                },
                {
                    "sent": "We have seen user based CF and we have seen random work and in our work we try to leverage the weighted recognize regularised metric factorization because it has been shown to work well.",
                    "label": 0
                },
                {
                    "sent": "For those implicit feedback data.",
                    "label": 1
                },
                {
                    "sent": "So basically this.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In this work, first we have three.",
                    "label": 0
                },
                {
                    "sent": "I think we have three tasks.",
                    "label": 0
                },
                {
                    "sent": "Firstly, how to model the geographical clustering phenomenon.",
                    "label": 0
                },
                {
                    "sent": "Here we use a 2D kernel density estimation and 2nd is how we were kind of recommendation framework we are using.",
                    "label": 1
                },
                {
                    "sent": "Here we use a weighted recognized metric factorization and then we combine these two into a joint model we call GMF.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in.",
                    "label": 0
                },
                {
                    "sent": "So in summary, actually this still MF.",
                    "label": 0
                },
                {
                    "sent": "Basically we try to extend the traditional met refrigeration framework.",
                    "label": 0
                },
                {
                    "sent": "Usually we have a user pure metrics here.",
                    "label": 0
                },
                {
                    "sent": "The value here is could be a 01 rating metric, which shows the preference of the users.",
                    "label": 0
                },
                {
                    "sent": "And traditionally, basically we can.",
                    "label": 0
                },
                {
                    "sent": "Divide this into two latent factor vectors.",
                    "label": 0
                },
                {
                    "sent": "Why is like we call it user latent factors?",
                    "label": 0
                },
                {
                    "sent": "The other card location, latent factors, and in our framework we argument leads to latent factors for user latent factors, we will add a user activity area vectors to the users.",
                    "label": 1
                },
                {
                    "sent": "To this to this vector and further location latent factors we will add the influence the location inference areas.",
                    "label": 0
                },
                {
                    "sent": "So as I've said that the activity areas means how active users was in this in these areas.",
                    "label": 0
                },
                {
                    "sent": "So we divide the whole map into a set of grids.",
                    "label": 0
                },
                {
                    "sent": "Here the number of grids is L here, so we have the air.",
                    "label": 0
                },
                {
                    "sent": "Vectors for all the users.",
                    "label": 1
                },
                {
                    "sent": "And also for a location with defined the influence areas.",
                    "label": 0
                },
                {
                    "sent": "How influential this location disappeared?",
                    "label": 0
                },
                {
                    "sent": "Why this could be a restaurant has for any individual area among these errors.",
                    "label": 0
                },
                {
                    "sent": "So this is the basic framework for our for our GMF.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's come to the objective function.",
                    "label": 0
                },
                {
                    "sent": "So basically because we have add here, we call it X&YX stands for activity area and Y stand for inference cherry.",
                    "label": 0
                },
                {
                    "sent": "And then we have added this XY to the original P&Q.",
                    "label": 0
                },
                {
                    "sent": "Here P just is the user latent factor and Q is the location latent effect factors.",
                    "label": 0
                },
                {
                    "sent": "So we added this XY 2P and Q.",
                    "label": 0
                },
                {
                    "sent": "So the objective function become.",
                    "label": 0
                },
                {
                    "sent": "We will calculate P&P butter by Q and then add by X * Y and use this to approximate RR is the original rating metrics.",
                    "label": 1
                },
                {
                    "sent": "And because of we use weighted measure of activation.",
                    "label": 0
                },
                {
                    "sent": "So we will have a wait here.",
                    "label": 0
                },
                {
                    "sent": "So this wait actually stands for how confident we have for each of the approximation.",
                    "label": 0
                },
                {
                    "sent": "So this weight is defined using this function.",
                    "label": 0
                },
                {
                    "sent": "Basically here Cus I means the visit frequency of user you too to allocation I.",
                    "label": 1
                },
                {
                    "sent": "Another is a hereafter is a monotone increasing function.",
                    "label": 1
                },
                {
                    "sent": "That means if the visiting frequency of this user to the location I is large, then we will have a large weight.",
                    "label": 0
                },
                {
                    "sent": "For in this objective function, that means we have more confidence for this approximation, and this large weight.",
                    "label": 0
                },
                {
                    "sent": "Basically we use that to help to get more accurate approximation for this value and we have some regularization items for PQ&X here.",
                    "label": 0
                },
                {
                    "sent": "So in general here we will fix Y and we try to learn PQ&X from the data.",
                    "label": 0
                },
                {
                    "sent": "And for White here we use a 2D kernel density estimation.",
                    "label": 0
                },
                {
                    "sent": "Here why means the location inference regions influence areas?",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the inference for each grade.",
                    "label": 0
                },
                {
                    "sent": "This grass I've said we have divided the whole map into UU grids.",
                    "label": 0
                },
                {
                    "sent": "If these are red, point is the location is a restaurant.",
                    "label": 0
                },
                {
                    "sent": "For example, put pie and it depends on the distance from the grid to this location.",
                    "label": 0
                },
                {
                    "sent": "We have different densities here.",
                    "label": 0
                },
                {
                    "sent": "For example this FJ&K.",
                    "label": 0
                },
                {
                    "sent": "This grades the weather could be 0.6 and for a actually it could be 0.1.",
                    "label": 0
                },
                {
                    "sent": "So it's like Gaussian distribution.",
                    "label": 1
                },
                {
                    "sent": "And then if we have this location influence areas.",
                    "label": 0
                },
                {
                    "sent": "And we also, if we have already learned the user activity areas, then we can multiply them together to calculate the geographical preference of this user to the point of interest.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                },
                {
                    "sent": "So that means if the user is active at some region and also this region is influenced highly influenced by a restaurant or buy some pie and then the user could have a higher geographical preference over the supply.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for optimization we have already introduced our object function.",
                    "label": 0
                },
                {
                    "sent": "So for optimization basically use iterative approach.",
                    "label": 0
                },
                {
                    "sent": "So basically two step.",
                    "label": 0
                },
                {
                    "sent": "First we fix X and then we update P&Q and in the paper we have calculated time complexity.",
                    "label": 1
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then the next step is fixed P&Q and then we update the X.",
                    "label": 0
                },
                {
                    "sent": "So we do this iteratively.",
                    "label": 0
                },
                {
                    "sent": "I will not go into the detail, but we have a nurse for the time complexity for both steps.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And in this way, actually, we can distinguish the unvisited locations.",
                    "label": 0
                },
                {
                    "sent": "I assume will be fixed X and then we are actually if we revisit the object function so we actually approximate knew our this this I storage rating metrics and you are mean is actually the I will be minus by the X * Y X&Y.",
                    "label": 0
                },
                {
                    "sent": "Here at the activity area and influence areas.",
                    "label": 0
                },
                {
                    "sent": "So for use given user if he has some activity area and for a location I around this active area is very probably.",
                    "label": 1
                },
                {
                    "sent": "These are could be negative because user because if the user to visit frequency is a positive value and this if the influence is also a positive value then this could be very probably negative value.",
                    "label": 0
                },
                {
                    "sent": "That means on visit locations around those frequent visits areas are highly likely to be negative.",
                    "label": 1
                },
                {
                    "sent": "So that means we add more negative labels to the original data set.",
                    "label": 0
                },
                {
                    "sent": "So this means how we can distinguish those unvisited.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Asians?",
                    "label": 0
                },
                {
                    "sent": "So we go to let's go to the experiments.",
                    "label": 0
                },
                {
                    "sent": "So basically we have a data set from China which is location based social networks, which is similar to Foursquare.",
                    "label": 1
                },
                {
                    "sent": "We have crowded there set for three years and we have data from quite a few cities.",
                    "label": 0
                },
                {
                    "sent": "For example in Shanghai, which is a big city in China, we have 4400 about 400,000 users and they have 225 million checkings.",
                    "label": 0
                },
                {
                    "sent": "And for paging we have also we have about 160,000 users.",
                    "label": 0
                },
                {
                    "sent": "We extract about 30% of the locations for testing and we use the remaining data for training and we round the expenses for five independent trials and elation metric.",
                    "label": 0
                },
                {
                    "sent": "Here is because we can calculate the preference of user to any location.",
                    "label": 0
                },
                {
                    "sent": "So we output the top K result in the testing locations and we calculate the required precision for these top K. Output so we average result as the final output.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we compare our algorithm with a set of baselines including user based collaborative filtering, which is widely used in the industry and also will compare with previous work is based in non negative matrix factorization and we also based compare algorithm with a simple approach will be quite regularize SVD which is based on the 01 metrics and also we extend this 01 metric to a frequency metrics.",
                    "label": 0
                },
                {
                    "sent": "That means we use frequency.",
                    "label": 0
                },
                {
                    "sent": "To stand, stand for the represent the preference.",
                    "label": 0
                },
                {
                    "sent": "That means we don't use the frequency to represent confidence by the by the preference here, so we do another metric factorization based on these visiting frequency metrics.",
                    "label": 0
                },
                {
                    "sent": "We want to compare this to approach and also we tried.",
                    "label": 0
                },
                {
                    "sent": "We improve our algorithm by considering bio.",
                    "label": 0
                },
                {
                    "sent": "So we called WMF bias.",
                    "label": 0
                },
                {
                    "sent": "So if we look at this figure we can see that this actually the bottom this.",
                    "label": 0
                },
                {
                    "sent": "Co is from the MF frequency.",
                    "label": 0
                },
                {
                    "sent": "That means if we can see the frequency as the preference, the performance is very low.",
                    "label": 0
                },
                {
                    "sent": "So that means we should not do that.",
                    "label": 0
                },
                {
                    "sent": "And we found that a simple approach MF 01.",
                    "label": 0
                },
                {
                    "sent": "Here is the red line here, which actually the performance is quite good.",
                    "label": 0
                },
                {
                    "sent": "It is even better than UC F and the basin nonnegative matrix factorization.",
                    "label": 1
                },
                {
                    "sent": "And our approach is WMF.",
                    "label": 0
                },
                {
                    "sent": "The top 2 lines WMF and WFB.",
                    "label": 0
                },
                {
                    "sent": "Considering bias, but we found that considering bias, the improvement is very very small, so it may not be necessary to do this.",
                    "label": 0
                },
                {
                    "sent": "One reason is maybe this metric Federation for locations because we work use a 01 matrix rating metrics.",
                    "label": 0
                },
                {
                    "sent": "So maybe the bias here is not that significant.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So to summary for the for the first set of experiments, we found that our approach we called WF here is we outperformance UC F and the negative base in MF.",
                    "label": 0
                },
                {
                    "sent": "And also it outperformance outperforms the simple approach which called MF01 matrix.",
                    "label": 0
                },
                {
                    "sent": "And and also we found I'd embarrass, which is not.",
                    "label": 0
                },
                {
                    "sent": "There's not big effect.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And Secondly, we try to study OK. Yeah, we could go through study the spatial clustering phenomenon.",
                    "label": 1
                },
                {
                    "sent": "So basically remove P&QP&Q means the user latent location, latent factors and we study.",
                    "label": 1
                },
                {
                    "sent": "We compare this with two DKD and non weighted version.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, I think I will skip.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in summary, we outperformance the outperformed too simple, apologize the traditional weight weighted macrophyte Reggie and the other is the week and we only you consider the Geo clustering phenomenon here.",
                    "label": 0
                },
                {
                    "sent": "So we need to combine these two to get better performance.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, to conclude this talk.",
                    "label": 0
                },
                {
                    "sent": "Basically we propose a 2D kernel density estimation for the gram modeling and then we combine that with weighted metric factorization and get better performance compared with baselines.",
                    "label": 1
                },
                {
                    "sent": "And we propose a learning algorithm and we analyze the time complexity.",
                    "label": 1
                },
                {
                    "sent": "OK so thank you and questions.",
                    "label": 0
                }
            ]
        }
    }
}