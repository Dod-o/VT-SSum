{
    "id": "xyre3hz4nhqbv7tzletdtus66wybwtuq",
    "title": "\"Tuning\": Error Optimisation in Ad-Hoc Retrieval",
    "info": {
        "author": [
            "Hugo Zaragoza, Yahoo! Research"
        ],
        "published": "Feb. 25, 2007",
        "recorded": "May 2006",
        "category": [
            "Top->Computer Science->Information Retrieval"
        ]
    },
    "url": "http://videolectures.net/fws06_zaragoza_eohr/",
    "segmentation": [
        [
            "So this is done.",
            "I've done this work over the last two years with a number of people and I'm not going to be referencing individual people.",
            "Sort of our historical ordering.",
            "This remembered about perfect Steven Roberson, Microtel Nick Craswell, increase verges.",
            "Nick Russell is still very active in this area.",
            "I've moved on to other things, but Nick is still working on this and in fact you see he's gonna talk tomorrow on a different topic which is image search and most of what I'm going to say applies to his sisters retrieval.",
            "So it's quite a general topic.",
            "I think there's been a fundamental problem in information retrieval for the last few years, and to me this is very interesting, very important, and I'm going to try to at least convey the problem.",
            "The importance of the problem and see if you agree with it, and then I'll give you one solution.",
            "But the problem is the following.",
            "Imagine that you have this search engine that is working to a certain degree.",
            "And it has a number of features, and now you think of a new feature.",
            "So you have this system A and you think of a new feature.",
            "It could be a new way of disambiguating words so it could be a new way of anti spam page run or it could be an idea about how people read and then you say I'm going to add this idea to my search engine so you have system A and you add a thing called B and it's a new thing and you evaluate it and it doesn't work much better than before and I think we've all been there.",
            "If we've done any IR in the past.",
            "So then what is the conclusion of this experiment?",
            "You had a USB, nothing improves.",
            "And the conclusion, unfortunately.",
            "Is well, nothing.",
            "I cannot conclude the bees, but I can.",
            "I can probably conclude the Beast B is not awesome because maybe it would have worked by chance.",
            "The main conclusion there is in this particular combination that I've used B doesn't work with a OK. Now if you want a strong conclusion, you have to try all possible combinations of DNA and then you can say B is rubbish 'cause I've done everything I could and it didn't improve a OK.",
            "So in a way we need to automate the process of saying I've tried everything and it didn't work.",
            "And that's in a way, what way machine learning or parameterized learning does?",
            "It tells you how you should combine things so you can worry about what are the things that you want to combine, and then the combination is something some more or less consistent that you can trust.",
            "So the result at the end is a conclusion that is strong.",
            "OK, so to me this is very fundamental and I think we're getting to the point now where we can start doing this kind of things.",
            "We can start saying, well, I've seriously tried everything I could with B within a parametric model, and it doesn't seem to work.",
            "OK."
        ],
        [
            "So let me give you the machine learning speech and that doesn't mean I subscribe to all of this.",
            "I have some critics later, but this is the standard way of explaining machine learning.",
            "You have some object which could be anything.",
            "It could be a part of a speech.",
            "It could be some text digit and then human perception interprets this in some way.",
            "So there's some features that are extracted and that's the object representation.",
            "So all we know about the object is this representation here and the human also provides a label for it, and that's the big problem.",
            "What is the label?",
            "Just if I knew the object representation?",
            "So if I know the label, I already know it, but if I don't know what do we do about it and so machine learning says, well, I need a model that takes as an input and object representation and outputs a label.",
            "And this is interesting because if the difference between what I predict what I really want is small enough then in the future.",
            "Sorry this is out of sync, but we're getting there in the future if I have a new object that I don't know, I really don't know the label.",
            "I can use this model and guess the label and this guessing is the important part, right?",
            "So information retrieval this may be the instance of a user typing a query and what I did really don't know is the label.",
            "The quality of a particular document, or this may be a sound and I'm trying to get the phone name of this sound etc and the way you do this is you basically parameterized your model, so you fix the model, but you let a bunch of parameters that are free parameters and then you basically learn.",
            "Those parameters that the error is minimized in some way, and that's the standard machine learning framework.",
            "If you want and for a long time machine learning, people have been trying to convince us that this is it.",
            "This is the world, so just just use this and then everything is solved, meaning that almost every learning problem can be cast into this framework.",
            "And now that we know how to do this framework well, and we know how to run SVM, something like that, we're realizing that the world is a little bit more complex and there are many things we want to do that do not fit this framework and information retrieval is one of them for several reasons, but one of the main ones is what I'm looking at.",
            "What I'm going to concentrate on today.",
            "Is because in information retrieval this idea of a label corresponding to a single object doesn't make much sense.",
            "So if I show you one query and one document and ask what is the rank of this document, should I put it first, second, and third, you're going to ask me well what are the other documents, right?",
            "So if there's another document is really good, then this should go underneath.",
            "If not, this should go first, so I'll be a bit more formal about this, but will get there in a minute.",
            "So within this framework we just have object representations or labels.",
            "And very very large number of."
        ],
        [
            "Problems can be cast into this and it's quite amazing that there's so many things you can cast into this framework.",
            "So for example, as you know, if the labels I binary binary, so either something is in a class or not in a class, then you have a classification problem and you have very.",
            "Fundamental theorems that tell you how to do classification in a very efficient way in very high dimensions with reasonable speed or strong guarantees of performance, etc.",
            "He fits discrete in some sense.",
            "We have several classes.",
            "Then you can use multiclass classification theorems.",
            "To do this you can do clustering if you don't know the classes.",
            "Again, we know a lot of things we can do with this.",
            "If we have preferences as in, well, I don't know the class, but I know that AIDS.",
            "Sorry, I have discrete classes like a B&C, but not only that I have an order so I know that a is better than B is B is between A&C, then these are discrete classes.",
            "But this thing should be important and this is known in statistical learning as ordinal regression problem.",
            "And finally if you have a continuous space of labels then you basically in the regression space and all of this has been studied and we have reasonable ways to attack this problems OK."
        ],
        [
            "So the problem is then is well, you give you some features.",
            "Give me some labels.",
            "You had a little bit of machine learning and you end up with a good model.",
            "OK, and that's great because you can concentrate on the features.",
            "Concentrate on that asks what do you want to do, and then once you've decided what you want to do, which is kind of the labels and how you're going to do it.",
            "The features, then the combination.",
            "Happens by magic and then if it doesn't happen.",
            "If it doesn't work, then you can conclude that the features were bad in the 1st place.",
            "OK, now we all know that this is a dream that has not completely been realized, so we know that to make this work we need really good features to start with.",
            "OK, that's the first hurdle that we have.",
            "We need good features now.",
            "Someone on speaker today said that informed the fundamental problem in information retrieval was finding the closest document to a query in a sort of cosine space right to me.",
            "The fundamental question information retrieval.",
            "Is defining that metric?",
            "What is the space that we want to work if I already told you that cause casinos is the solution?",
            "If I only tell you the relevance is they've created distance between query and document then the problem is pretty much solved.",
            "We can do it faster or slower.",
            "The problem is solved.",
            "What I'm worried about is what is the metric?",
            "What do we measure and how much does each direction matter OK?",
            "So that's kind of what the features are is the first step towards finding a metric.",
            "What are the access that we're going to play this point on OK?",
            "Now, once you find those features, you need lots of labels because most of these machine learning techniques they require a lot of information.",
            "I'm a labels have to be good, so there has to be lots of Vampyr feature.",
            "They cannot be very sparse and will see in a specific in a minute that not only that labels have to be with respect to documents, so every document has to have a label and that's the problem with cinnamon.",
            "Finally, the billables better not be too noisy and if there are noises they better be nicely noises after we got through the distributed.",
            "So for example the noises to be uncorrelated between labels and all those things really hit you when you're in reality.",
            "These things don't necessarily work for you.",
            "OK, and the most important one.",
            "That was really hurting us over the last two years.",
            "Were trying to learn information retrieval with this elementwise condition, so I'll show you what this means.",
            "But basically every element that you train, you better have a label for it, or else you have it.",
            "You're not going to be able to train, so I'll explain this in a minute.",
            "The idea is that we're almost at the point where data, sorry, we're almost at the point where we have models that can solve these problems.",
            "We're almost there, and in many cases were already there.",
            "OK, so there's a number of algorithms that are having developed the last few years that get out of this standard framework and into more realistic frameworks.",
            "And this is an example of one of them.",
            "But not this.",
            "This is a. OK, this is all this version of other version of PowerPoint so I had to put the animations on the next slide so these are some examples of what I just said.",
            "Example, I said we need good features now if you want to make information retrieval work with machine learning, you only you can't just say through the machine learning algorithm.",
            "Here are some words you have to say here some thiefs or by the way here's some ideas, or by the way TF times log of idea, that's actually very useful and if you go all the way there then you start getting good features that you can put into machine learning, but if you just have a string of text then you're very far so development of features of course is a very important issue.",
            "OK?",
            "Well there's some other examples of the lack of data, so today a lot of the things we want to do, for example in Linux.",
            "We have all these dreams of structured document retrieval, but most of the hypothesis that we have we cannot test because there's not enough data to learn these systems, OK?",
            "And I was talking about the noise.",
            "If you have labels like bias judges, if you have a judge that is consistently negative, consistently positive.",
            "This is very this is correlated noise, so it's not uncorrelated with respect to labels.",
            "And that's going to hurt you again.",
            "OK, but these are all things that are being treated in the machine learning community right now.",
            "The one I was talking about is this one document wise error.",
            "What does it mean?",
            "Most metrics most problems in machine learning they use pairwise error pointwise error.",
            "Meaning for example compute the distance between what you've obtained for this pattern and what you wanted to obtain.",
            "For example L2 error.",
            "So the squared distance of what you wanted is the measure of quality of your model.",
            "OK, but this is very different information retrieval so."
        ],
        [
            "Give you an example.",
            "This is a typical information retrieval setting, so I have a query of some sort and I end up with a bunch of documents with scores, so this is what I have a score 17.917 point, six 2012.5.",
            "These are different documents with different scores and they are ordered by the rank that have obtained, and then I have a human that says this is bad.",
            "This is good.",
            "This is bad bad.",
            "This is good.",
            "So these are the labels.",
            "OK, now in machine learning the way most error functions work.",
            "Is this following wait for this document?",
            "You've obtained a 12.5.",
            "Given that it's now negative, how bad did you do?",
            "What is the error independent of anything else right now?",
            "That's very hard to do an information retrieval and information retrieval.",
            "All you really know is that this first guy was not relevant and this one was relevant.",
            "So you would want the order to be reverse, but the actual value is of no importance to you.",
            "OK, so an example of this, for example, is computed precision at 5.",
            "This is something we all do in our first information retrieval session.",
            "OK, what is precision?",
            "How many correct documents are if I go down five ranks in this case there's two, so it's two out of five.",
            "This is a standard information retrieval performance measure, because that's sort of correlates to what a human expects.",
            "If there's a lot of good things in the first 5 results, this is a good engine, and there's a lot of bad things in the first 5 results is about engine OK, but this measure?",
            "Is actually computed scoring the entire collection.",
            "So if I tell you this document has this score, you cannot judge just from that information.",
            "If the final precision at 5 is going to be good or bad.",
            "So the error function that we're going to use depends on every single score, because first you need to sort.",
            "Then you need to take the first 5.",
            "OK, so as I'll show in the next slide, we need error functions that take this into account.",
            "Now, one way to do it is to say, well, everything that is good.",
            "I'm going to hope that it gets a very high score, let's say 100.",
            "Everything that is bad.",
            "I'm going to hold it gets a very bad score, let's say zero, and then I compute the difference between zero and the obtained score 100 obtain score.",
            "The standard L2 kind of behavior and that was will see is not going to work.",
            "OK, so let me show you exact."
        ],
        [
            "Really, how this is going to happen?",
            "I'm going to show you a couple of solutions, but the problem is quite generic so well is going to center on a specific problem.",
            "Imagine that we want to rank documents on the web.",
            "OK, so a document on the web may be defined by a number of features.",
            "Here, for example, I just used a bunch of features like them 25.",
            "For a particular query, the page trying the length of the URL, the link in degree, the click distance, etc.",
            "OK and the machine learning problem is combined them properly so that you get a good result at the end.",
            "Now for a particular document, I have a particular value of each one of those boxes.",
            "I obtain an output a score, let's say 12.7.",
            "What was the desired output that I wanted to obtain full?",
            "That's unknown.",
            "That depends on the rank of the entire collection, so I don't have a signal here to learn this model.",
            "OK.",
            "So how are we going to do this then?"
        ],
        [
            "We're going to define an error that is not doesn't depend on individual elements anymore, and that's what the new problem called ranking is being defined and a lot of people called this the ranking problem.",
            "Now, at least in this sort of mathematical machine learning community and ranking is different from binary classification, multiclass classification, ordinal regression, all the problems I talked about at the beginning are not a subset of ranking.",
            "OK, so in ranking we're going to say we're going to be interested only in the top ranked objects.",
            "That's the first thing.",
            "Labels are only going to be relative to each other.",
            "That's the second thing.",
            "So there's two components.",
            "The first one says I don't care about the errors on the entire collection.",
            "I only care about the top ten errors.",
            "She's a radical departure of, say, L2 or things like that.",
            "The second one is I'm going to measure errors based on relative quality, not absolute quality.",
            "OK, so this is an example.",
            "Imagine that you're learning a simple linear regression problem like you do in high school, so you have .6 and why you have a cloud of points and you're trying to find the line that fits.",
            "Best those points, but now you're going to say, actually I'm only going to minimize that line on the points that obtained the 10 highest scores, for example.",
            "So only compute this course that are high as the rest ignore.",
            "Now those high sports is course depend on the line, so as a line changes, some points become important, some points disappear and that's why this is a non trivial problem, OK?",
            "In our case, we're going to say we want high precision at 5, so I don't care about the score of any document except they want the guys that get at the top five.",
            "So as we change the parameters, some guys that they took five disappear.",
            "Some guys enter and then they matter or they don't matter depending where they are on this line.",
            "Precision 5 is interesting because precision at K is just.",
            "If you can do this, then you can do average precision.",
            "You can do anything you can do reciprocal mean and a whole bunch of family functions that they are all used in information retrieval.",
            "So the big problem is this idea of precision at K. If you can solve that, then everything else is solved.",
            "This is difficult, but and there's been some theoretical resource before that had algorithms, but they were extremely expensive to compute and I think we're getting to the point where there's a couple of competing algorithms that can do this kind of thing.",
            "If you have enough data, you know you can learn this copy.",
            "OK.",
            "So let me just go back here.",
            "OK. Is this?"
        ],
        [
            "OK, so imagine that I could do that.",
            "I have this error function that I can define.",
            "OK, so that for a particular setting of parameters on a particular collection, I can compute the error.",
            "So an example of that is average precision, average precision cares about the top more than the bottom, so it really similar to what humans care about.",
            "How good are we at the top of the rank?",
            "So here I've plotted this thing for a particular ranking function that has only two parameters.",
            "I can plot all possible results of average precision for those two parameters, so this is what this graphical representation means.",
            "If I take a point here like this, I take a ranking function that has two parameters.",
            "I said the first parameter to this value.",
            "I said the second parameter to this value and I compute the final average precision over a particular collection.",
            "And now I do that for all possible values of the two parameters I attend this surface here and it tells me basically that if I set the parameters to this value, the first one and this value the second one, I get the maximum possible average precision.",
            "So learning is finding that point, finding the parameter setting that optimizes your error function.",
            "That's what learning is about, and there's several ways to do this.",
            "One way that we tried to do this is using gradient descent.",
            "So if I am here and I can compute this surface analytically, then I can follow the gradient until I hit the maximum.",
            "And if there's one local minima in a whole bunch of other conditions, then I get the right the right result at the end.",
            "So if I could just compute the gradient here, I would be happy will be solved.",
            "The main problem is that when you have this kind of error function that I talked about where you have rank dependent error functions, nobody knows how to compute a gradient there.",
            "We just don't know how to compute a gradient.",
            "So let me show you why."
        ],
        [
            "This is an example of precision at K precision at 5.",
            "How do I compute this?",
            "One way of writing this is the following.",
            "Imagine that that's an example.",
            "There I have 4 results.",
            "So I'm going to look at all the pairs of documents.",
            "I have a number of documents and I'm only considering there for documents.",
            "OK, so I can be 1234 and J can be.",
            "Sorry that this is great, so there's a number of documents and I'm going to take two at random I&J and I'm going to look whether I is above or below J and if it's above whether it's relevant or more relevant than the other one.",
            "So what I want is that if one document is more relevant than the other one, it should be above, and if not, it should be the other way around.",
            "So these are the possibilities.",
            "Imagine that, for example, I is not relevant and J is relevant.",
            "So as long as J is above I, then my error is good.",
            "OK, if they're both irrelevant or both relevant and there's nothing.",
            "I know they could be anywhere.",
            "All I know is that there are less likely to be one above the other.",
            "Finally, if they reverse, then I want the other one to be on top, so this is just one minus because this is normalized to 01 and this is just some function of the difference of scores.",
            "OK, the error.",
            "So in this case, if I take a function like this, it just says if I am above.",
            "If the difference is positive, then the error is 1 difference, negative there is zero.",
            "So this is just a function that as long as the relevant guys over an irrelevant one, then you're OK. And then at some point you go under it and then you ever go from zero to 1 for that pair.",
            "OK, so it's just a flip, it counts how many whether you are flipping and relevant with any relevant or not.",
            "And so you can say the number of mistakes for a particular document in a particular rank.",
            "It's just the number of flips as he goes from the top ranked to that position.",
            "OK so I have a document position five.",
            "I just look are there.",
            "How many documents above me are negative?",
            "That's the number of flips.",
            "And then you can write precision at K as the maximum possible number of flips for a particular document at a particular rank.",
            "OK, and you just have to believe me at this point that precision RK can be exactly written as this.",
            "OK, so this is the function that I want as an error function.",
            "If I could take the derivative of these then I could just go up the Hill and then we would be done.",
            "We don't know how to do this so one solution and there's been a couple proposed, but this is the one that for us seems to make more sense.",
            "Is the following.",
            "We do a bunch of tricks.",
            "The first thing is this Max.",
            "We don't know how to take a derivative off, so I'm going to replace it by the sum and this is standard trick and now we're sort of in approximation land will no longer optimizing precision at K, But some kind of approximation.",
            "And instead of taking this step function here, we can take.",
            "Some kind of smooth version of that so it could be a hinge laws or exponential growing function.",
            "OK, and suddenly what happens is that this sum now because it's a sum over some server smooth functions.",
            "I know how to take the relative derivative and I can do gradient descent over it.",
            "OK, what does that mean?",
            "It means that I."
        ],
        [
            "I'm here.",
            "I have the surface.",
            "I've now changed the surface into some kind of approximation, which takes a salmon's mood version, so I don't know the surface anymore.",
            "But I have some kind of approximation in which I can move now towards the maximum, so if the approximation is good enough then I will hit the right point.",
            "If the approximation is not good enough, then it will be somewhere else.",
            "OK.",
            "So let me show you how that works."
        ],
        [
            "This is what we had at the beginning.",
            "We were somewhere over here, but we didn't know how to compute the gradient, and we approximated this with something that we know how to compute the grade and then we look at it and say does it look like originally?",
            "And this is what we get.",
            "This is mirth surface that we know how to navigate.",
            "In some sense we have a local gradient here and it looks remarkably like.",
            "Map OK, so that's a nice result, at least in 2D.",
            "Kind of indicates that you have the right surface.",
            "OK, so we started doing all kinds of studies of can we prove theoretically that these two are closed?",
            "Can we prove empirically at these two are close and there's a number of work is going to the papers, but that's not true.",
            "Number of rejected papers that cigar that you can try to read OK?",
            "So one result that is interest."
        ],
        [
            "It is theoretically, can you prove that those two services have to be closed, at least at some point?",
            "Because if you can't, then it's all guessing.",
            "And we have one result that is quite quite simple and quite powerful by by Robertson that says the following.",
            "If you are at a local Maxima of the new function that we've invented, then you have to be at a local Maxima of N DCG average precision on any rank depending measure that you have.",
            "This is quite nice 'cause it means if you actually find this Maxima then you know that at least it's a local maximum for the other measures.",
            "That's quite powerful.",
            "Unfortunately, there's only been proven for 2D.",
            "When you go to Heidi then there's a bunch of weird cases in which this is not necessarily true, so it's more a lemma or.",
            "Or a hope than a theorem, but hopefully people that are more mathematically oriented and can read these and prove it for all possible cases and then will be done OK.",
            "So that's the only theoretical result that we have.",
            "We have a bunch of empirical results like this, like this one where we can actually prove that we get the right results.",
            "The most interesting one was done at a very large."
        ],
        [
            "Cal recently at Microsoft where they actually took thousands and thousands of training patterns and they compute real precision or N DCG, which is a soft version of average precision over thousands of queries for real user evaluations.",
            "So this is what happened.",
            "The first option that you have is you have all these parameters and you don't know anything about.",
            "Just explain so you can try to do some kind of line search, and if you're lucky enough you will find the right parameter setting OK.",
            "In fact with very few parameters you can do a fairly exhaustive line line search and then you find the right possible.",
            "The highest possible maximum, but this may overfit of course, so this is what you get as you increase the number of training.",
            "This means query document pairs.",
            "OK, so for example this means I have 1000 query document pairs, which could mean I have 100 queries with 10 evaluations each, or maybe 50 queries with 20 evaluations etc.",
            "OK.",
            "So let's search over fits a lot of the beginning and then it settles and it doesn't take too many features at the end because the number of features is kind of in saturated here.",
            "Now, in theory, if you are lots of more features, you could bring this up but it overfits even more so it takes you forever to actually settle and by then you have spent all your money on evaluations and the game is over.",
            "OK so one thing you can do is you can train this gradient descent.",
            "I just talked about with the function approximation function that I just talked about and then you get this kind of behavior.",
            "We use few features you can see that right away you're in the right region.",
            "Probably because you're a bit more robust with respect to overfitting and then as you add features in very increases a little bit, but it settles because basically you're not going to get any better than what line search does with lots of features, but the advantage that this is automatic.",
            "Sorry, this is automatic, this is a gradient descent, so this is the time it takes is not at all exponential in the sense of line search.",
            "OK, kind of proves that you have here are very hard to explain because it depends on so many things, but in practice it great in the sentence to finally quickly.",
            "Find quickly local Optima.",
            "Now what you can do with this kind of bread in the sense that I just described, you can now explore the number of features you don't care how many features you have because you can compute these credits now over any number of features, so you can greatly increase the number of features so we go from order of magnitude of 10 to 52 order of magnitude of 100 to 500.",
            "And what you see is that well, initially, as you can imagine, this thing is wildly all over the place because there's not enough data, but it keeps going.",
            "And we don't know how far it keeps going because we could continue to add queries and training data and this could go so this kind of energy increase is sort of unheard of.",
            "This is not statistically significant, is statistically amazing for us, like a .1 increase in energy is like as much as you could guess.",
            "So for us this is very critical and the fact that it's so simple to learn now because we have this gradient descent.",
            "For us it was very important.",
            "OK, I'm going to stop there and Nick and I are.",
            "Nick is in the conference, so if you're interested in this kind of work, he's actively in the area so you could talk to him.",
            "This is what happens in CRC missions.",
            "Did you ever is this offer different runs?",
            "I mean he's playing games.",
            "Different connections of training sets because this ringing seems very well.",
            "This is why you get so.",
            "So here you're in an area that is underspecified, so it's very random.",
            "So if you average, you will get a very large error bar, which gets smaller and smaller as you going home.",
            "Yeah, I feel the same for competitive gaming instead of this complicated real social construction meeting.",
            "Necessary and asking difficult questions game as opposed to this country.",
            "Cumulative gain.",
            "NDC G as you get further down the list, yet much less of the center.",
            "So we thought that discounting yeah yeah, so actually OK so here this pairwise thing does not take into account the discount.",
            "It does not.",
            "So you actually trust CG a lot better than decision.",
            "We're just getting lucky enough that this is good enough for this.",
            "In theory, you want to force that behavior, and that's really hard is something we've worked quite hard and we failed so far to actually be able to discount as you go down.",
            "So this is actually almost DCG tracking.",
            "Instead of N DCG, but with enough data it seems it doesn't matter.",
            "Right?",
            "So that's a very good question.",
            "That's going up.",
            "This guy here.",
            "Yeah, I was very tempted to remove it, but I don't know.",
            "I think.",
            "I mean you were kind of here and maybe maybe that's go up slowly.",
            "The thing is like search is very expensive and actually you know it gets more and more expensive as it goes to the right.",
            "This this takes literally several like overnight right?",
            "And this is orders of magnitude faster, so at some point you have to stop the line search."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is done.",
                    "label": 0
                },
                {
                    "sent": "I've done this work over the last two years with a number of people and I'm not going to be referencing individual people.",
                    "label": 0
                },
                {
                    "sent": "Sort of our historical ordering.",
                    "label": 0
                },
                {
                    "sent": "This remembered about perfect Steven Roberson, Microtel Nick Craswell, increase verges.",
                    "label": 0
                },
                {
                    "sent": "Nick Russell is still very active in this area.",
                    "label": 0
                },
                {
                    "sent": "I've moved on to other things, but Nick is still working on this and in fact you see he's gonna talk tomorrow on a different topic which is image search and most of what I'm going to say applies to his sisters retrieval.",
                    "label": 0
                },
                {
                    "sent": "So it's quite a general topic.",
                    "label": 0
                },
                {
                    "sent": "I think there's been a fundamental problem in information retrieval for the last few years, and to me this is very interesting, very important, and I'm going to try to at least convey the problem.",
                    "label": 0
                },
                {
                    "sent": "The importance of the problem and see if you agree with it, and then I'll give you one solution.",
                    "label": 0
                },
                {
                    "sent": "But the problem is the following.",
                    "label": 0
                },
                {
                    "sent": "Imagine that you have this search engine that is working to a certain degree.",
                    "label": 0
                },
                {
                    "sent": "And it has a number of features, and now you think of a new feature.",
                    "label": 0
                },
                {
                    "sent": "So you have this system A and you think of a new feature.",
                    "label": 0
                },
                {
                    "sent": "It could be a new way of disambiguating words so it could be a new way of anti spam page run or it could be an idea about how people read and then you say I'm going to add this idea to my search engine so you have system A and you add a thing called B and it's a new thing and you evaluate it and it doesn't work much better than before and I think we've all been there.",
                    "label": 0
                },
                {
                    "sent": "If we've done any IR in the past.",
                    "label": 0
                },
                {
                    "sent": "So then what is the conclusion of this experiment?",
                    "label": 0
                },
                {
                    "sent": "You had a USB, nothing improves.",
                    "label": 0
                },
                {
                    "sent": "And the conclusion, unfortunately.",
                    "label": 0
                },
                {
                    "sent": "Is well, nothing.",
                    "label": 0
                },
                {
                    "sent": "I cannot conclude the bees, but I can.",
                    "label": 0
                },
                {
                    "sent": "I can probably conclude the Beast B is not awesome because maybe it would have worked by chance.",
                    "label": 0
                },
                {
                    "sent": "The main conclusion there is in this particular combination that I've used B doesn't work with a OK. Now if you want a strong conclusion, you have to try all possible combinations of DNA and then you can say B is rubbish 'cause I've done everything I could and it didn't improve a OK.",
                    "label": 0
                },
                {
                    "sent": "So in a way we need to automate the process of saying I've tried everything and it didn't work.",
                    "label": 0
                },
                {
                    "sent": "And that's in a way, what way machine learning or parameterized learning does?",
                    "label": 0
                },
                {
                    "sent": "It tells you how you should combine things so you can worry about what are the things that you want to combine, and then the combination is something some more or less consistent that you can trust.",
                    "label": 0
                },
                {
                    "sent": "So the result at the end is a conclusion that is strong.",
                    "label": 0
                },
                {
                    "sent": "OK, so to me this is very fundamental and I think we're getting to the point now where we can start doing this kind of things.",
                    "label": 0
                },
                {
                    "sent": "We can start saying, well, I've seriously tried everything I could with B within a parametric model, and it doesn't seem to work.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let me give you the machine learning speech and that doesn't mean I subscribe to all of this.",
                    "label": 0
                },
                {
                    "sent": "I have some critics later, but this is the standard way of explaining machine learning.",
                    "label": 0
                },
                {
                    "sent": "You have some object which could be anything.",
                    "label": 0
                },
                {
                    "sent": "It could be a part of a speech.",
                    "label": 0
                },
                {
                    "sent": "It could be some text digit and then human perception interprets this in some way.",
                    "label": 0
                },
                {
                    "sent": "So there's some features that are extracted and that's the object representation.",
                    "label": 0
                },
                {
                    "sent": "So all we know about the object is this representation here and the human also provides a label for it, and that's the big problem.",
                    "label": 0
                },
                {
                    "sent": "What is the label?",
                    "label": 0
                },
                {
                    "sent": "Just if I knew the object representation?",
                    "label": 0
                },
                {
                    "sent": "So if I know the label, I already know it, but if I don't know what do we do about it and so machine learning says, well, I need a model that takes as an input and object representation and outputs a label.",
                    "label": 0
                },
                {
                    "sent": "And this is interesting because if the difference between what I predict what I really want is small enough then in the future.",
                    "label": 0
                },
                {
                    "sent": "Sorry this is out of sync, but we're getting there in the future if I have a new object that I don't know, I really don't know the label.",
                    "label": 0
                },
                {
                    "sent": "I can use this model and guess the label and this guessing is the important part, right?",
                    "label": 0
                },
                {
                    "sent": "So information retrieval this may be the instance of a user typing a query and what I did really don't know is the label.",
                    "label": 0
                },
                {
                    "sent": "The quality of a particular document, or this may be a sound and I'm trying to get the phone name of this sound etc and the way you do this is you basically parameterized your model, so you fix the model, but you let a bunch of parameters that are free parameters and then you basically learn.",
                    "label": 0
                },
                {
                    "sent": "Those parameters that the error is minimized in some way, and that's the standard machine learning framework.",
                    "label": 0
                },
                {
                    "sent": "If you want and for a long time machine learning, people have been trying to convince us that this is it.",
                    "label": 0
                },
                {
                    "sent": "This is the world, so just just use this and then everything is solved, meaning that almost every learning problem can be cast into this framework.",
                    "label": 0
                },
                {
                    "sent": "And now that we know how to do this framework well, and we know how to run SVM, something like that, we're realizing that the world is a little bit more complex and there are many things we want to do that do not fit this framework and information retrieval is one of them for several reasons, but one of the main ones is what I'm looking at.",
                    "label": 0
                },
                {
                    "sent": "What I'm going to concentrate on today.",
                    "label": 0
                },
                {
                    "sent": "Is because in information retrieval this idea of a label corresponding to a single object doesn't make much sense.",
                    "label": 0
                },
                {
                    "sent": "So if I show you one query and one document and ask what is the rank of this document, should I put it first, second, and third, you're going to ask me well what are the other documents, right?",
                    "label": 0
                },
                {
                    "sent": "So if there's another document is really good, then this should go underneath.",
                    "label": 0
                },
                {
                    "sent": "If not, this should go first, so I'll be a bit more formal about this, but will get there in a minute.",
                    "label": 0
                },
                {
                    "sent": "So within this framework we just have object representations or labels.",
                    "label": 0
                },
                {
                    "sent": "And very very large number of.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Problems can be cast into this and it's quite amazing that there's so many things you can cast into this framework.",
                    "label": 0
                },
                {
                    "sent": "So for example, as you know, if the labels I binary binary, so either something is in a class or not in a class, then you have a classification problem and you have very.",
                    "label": 0
                },
                {
                    "sent": "Fundamental theorems that tell you how to do classification in a very efficient way in very high dimensions with reasonable speed or strong guarantees of performance, etc.",
                    "label": 0
                },
                {
                    "sent": "He fits discrete in some sense.",
                    "label": 0
                },
                {
                    "sent": "We have several classes.",
                    "label": 0
                },
                {
                    "sent": "Then you can use multiclass classification theorems.",
                    "label": 0
                },
                {
                    "sent": "To do this you can do clustering if you don't know the classes.",
                    "label": 0
                },
                {
                    "sent": "Again, we know a lot of things we can do with this.",
                    "label": 0
                },
                {
                    "sent": "If we have preferences as in, well, I don't know the class, but I know that AIDS.",
                    "label": 0
                },
                {
                    "sent": "Sorry, I have discrete classes like a B&C, but not only that I have an order so I know that a is better than B is B is between A&C, then these are discrete classes.",
                    "label": 0
                },
                {
                    "sent": "But this thing should be important and this is known in statistical learning as ordinal regression problem.",
                    "label": 0
                },
                {
                    "sent": "And finally if you have a continuous space of labels then you basically in the regression space and all of this has been studied and we have reasonable ways to attack this problems OK.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the problem is then is well, you give you some features.",
                    "label": 0
                },
                {
                    "sent": "Give me some labels.",
                    "label": 0
                },
                {
                    "sent": "You had a little bit of machine learning and you end up with a good model.",
                    "label": 0
                },
                {
                    "sent": "OK, and that's great because you can concentrate on the features.",
                    "label": 0
                },
                {
                    "sent": "Concentrate on that asks what do you want to do, and then once you've decided what you want to do, which is kind of the labels and how you're going to do it.",
                    "label": 0
                },
                {
                    "sent": "The features, then the combination.",
                    "label": 0
                },
                {
                    "sent": "Happens by magic and then if it doesn't happen.",
                    "label": 0
                },
                {
                    "sent": "If it doesn't work, then you can conclude that the features were bad in the 1st place.",
                    "label": 0
                },
                {
                    "sent": "OK, now we all know that this is a dream that has not completely been realized, so we know that to make this work we need really good features to start with.",
                    "label": 0
                },
                {
                    "sent": "OK, that's the first hurdle that we have.",
                    "label": 0
                },
                {
                    "sent": "We need good features now.",
                    "label": 0
                },
                {
                    "sent": "Someone on speaker today said that informed the fundamental problem in information retrieval was finding the closest document to a query in a sort of cosine space right to me.",
                    "label": 0
                },
                {
                    "sent": "The fundamental question information retrieval.",
                    "label": 0
                },
                {
                    "sent": "Is defining that metric?",
                    "label": 0
                },
                {
                    "sent": "What is the space that we want to work if I already told you that cause casinos is the solution?",
                    "label": 0
                },
                {
                    "sent": "If I only tell you the relevance is they've created distance between query and document then the problem is pretty much solved.",
                    "label": 0
                },
                {
                    "sent": "We can do it faster or slower.",
                    "label": 0
                },
                {
                    "sent": "The problem is solved.",
                    "label": 0
                },
                {
                    "sent": "What I'm worried about is what is the metric?",
                    "label": 0
                },
                {
                    "sent": "What do we measure and how much does each direction matter OK?",
                    "label": 0
                },
                {
                    "sent": "So that's kind of what the features are is the first step towards finding a metric.",
                    "label": 0
                },
                {
                    "sent": "What are the access that we're going to play this point on OK?",
                    "label": 0
                },
                {
                    "sent": "Now, once you find those features, you need lots of labels because most of these machine learning techniques they require a lot of information.",
                    "label": 0
                },
                {
                    "sent": "I'm a labels have to be good, so there has to be lots of Vampyr feature.",
                    "label": 0
                },
                {
                    "sent": "They cannot be very sparse and will see in a specific in a minute that not only that labels have to be with respect to documents, so every document has to have a label and that's the problem with cinnamon.",
                    "label": 0
                },
                {
                    "sent": "Finally, the billables better not be too noisy and if there are noises they better be nicely noises after we got through the distributed.",
                    "label": 0
                },
                {
                    "sent": "So for example the noises to be uncorrelated between labels and all those things really hit you when you're in reality.",
                    "label": 0
                },
                {
                    "sent": "These things don't necessarily work for you.",
                    "label": 0
                },
                {
                    "sent": "OK, and the most important one.",
                    "label": 0
                },
                {
                    "sent": "That was really hurting us over the last two years.",
                    "label": 0
                },
                {
                    "sent": "Were trying to learn information retrieval with this elementwise condition, so I'll show you what this means.",
                    "label": 0
                },
                {
                    "sent": "But basically every element that you train, you better have a label for it, or else you have it.",
                    "label": 0
                },
                {
                    "sent": "You're not going to be able to train, so I'll explain this in a minute.",
                    "label": 0
                },
                {
                    "sent": "The idea is that we're almost at the point where data, sorry, we're almost at the point where we have models that can solve these problems.",
                    "label": 0
                },
                {
                    "sent": "We're almost there, and in many cases were already there.",
                    "label": 0
                },
                {
                    "sent": "OK, so there's a number of algorithms that are having developed the last few years that get out of this standard framework and into more realistic frameworks.",
                    "label": 0
                },
                {
                    "sent": "And this is an example of one of them.",
                    "label": 0
                },
                {
                    "sent": "But not this.",
                    "label": 0
                },
                {
                    "sent": "This is a. OK, this is all this version of other version of PowerPoint so I had to put the animations on the next slide so these are some examples of what I just said.",
                    "label": 0
                },
                {
                    "sent": "Example, I said we need good features now if you want to make information retrieval work with machine learning, you only you can't just say through the machine learning algorithm.",
                    "label": 0
                },
                {
                    "sent": "Here are some words you have to say here some thiefs or by the way here's some ideas, or by the way TF times log of idea, that's actually very useful and if you go all the way there then you start getting good features that you can put into machine learning, but if you just have a string of text then you're very far so development of features of course is a very important issue.",
                    "label": 0
                },
                {
                    "sent": "OK?",
                    "label": 0
                },
                {
                    "sent": "Well there's some other examples of the lack of data, so today a lot of the things we want to do, for example in Linux.",
                    "label": 0
                },
                {
                    "sent": "We have all these dreams of structured document retrieval, but most of the hypothesis that we have we cannot test because there's not enough data to learn these systems, OK?",
                    "label": 0
                },
                {
                    "sent": "And I was talking about the noise.",
                    "label": 0
                },
                {
                    "sent": "If you have labels like bias judges, if you have a judge that is consistently negative, consistently positive.",
                    "label": 0
                },
                {
                    "sent": "This is very this is correlated noise, so it's not uncorrelated with respect to labels.",
                    "label": 0
                },
                {
                    "sent": "And that's going to hurt you again.",
                    "label": 0
                },
                {
                    "sent": "OK, but these are all things that are being treated in the machine learning community right now.",
                    "label": 0
                },
                {
                    "sent": "The one I was talking about is this one document wise error.",
                    "label": 0
                },
                {
                    "sent": "What does it mean?",
                    "label": 0
                },
                {
                    "sent": "Most metrics most problems in machine learning they use pairwise error pointwise error.",
                    "label": 0
                },
                {
                    "sent": "Meaning for example compute the distance between what you've obtained for this pattern and what you wanted to obtain.",
                    "label": 0
                },
                {
                    "sent": "For example L2 error.",
                    "label": 0
                },
                {
                    "sent": "So the squared distance of what you wanted is the measure of quality of your model.",
                    "label": 0
                },
                {
                    "sent": "OK, but this is very different information retrieval so.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Give you an example.",
                    "label": 0
                },
                {
                    "sent": "This is a typical information retrieval setting, so I have a query of some sort and I end up with a bunch of documents with scores, so this is what I have a score 17.917 point, six 2012.5.",
                    "label": 0
                },
                {
                    "sent": "These are different documents with different scores and they are ordered by the rank that have obtained, and then I have a human that says this is bad.",
                    "label": 0
                },
                {
                    "sent": "This is good.",
                    "label": 0
                },
                {
                    "sent": "This is bad bad.",
                    "label": 0
                },
                {
                    "sent": "This is good.",
                    "label": 0
                },
                {
                    "sent": "So these are the labels.",
                    "label": 0
                },
                {
                    "sent": "OK, now in machine learning the way most error functions work.",
                    "label": 0
                },
                {
                    "sent": "Is this following wait for this document?",
                    "label": 0
                },
                {
                    "sent": "You've obtained a 12.5.",
                    "label": 0
                },
                {
                    "sent": "Given that it's now negative, how bad did you do?",
                    "label": 0
                },
                {
                    "sent": "What is the error independent of anything else right now?",
                    "label": 0
                },
                {
                    "sent": "That's very hard to do an information retrieval and information retrieval.",
                    "label": 0
                },
                {
                    "sent": "All you really know is that this first guy was not relevant and this one was relevant.",
                    "label": 0
                },
                {
                    "sent": "So you would want the order to be reverse, but the actual value is of no importance to you.",
                    "label": 0
                },
                {
                    "sent": "OK, so an example of this, for example, is computed precision at 5.",
                    "label": 0
                },
                {
                    "sent": "This is something we all do in our first information retrieval session.",
                    "label": 0
                },
                {
                    "sent": "OK, what is precision?",
                    "label": 0
                },
                {
                    "sent": "How many correct documents are if I go down five ranks in this case there's two, so it's two out of five.",
                    "label": 0
                },
                {
                    "sent": "This is a standard information retrieval performance measure, because that's sort of correlates to what a human expects.",
                    "label": 0
                },
                {
                    "sent": "If there's a lot of good things in the first 5 results, this is a good engine, and there's a lot of bad things in the first 5 results is about engine OK, but this measure?",
                    "label": 0
                },
                {
                    "sent": "Is actually computed scoring the entire collection.",
                    "label": 0
                },
                {
                    "sent": "So if I tell you this document has this score, you cannot judge just from that information.",
                    "label": 0
                },
                {
                    "sent": "If the final precision at 5 is going to be good or bad.",
                    "label": 0
                },
                {
                    "sent": "So the error function that we're going to use depends on every single score, because first you need to sort.",
                    "label": 0
                },
                {
                    "sent": "Then you need to take the first 5.",
                    "label": 0
                },
                {
                    "sent": "OK, so as I'll show in the next slide, we need error functions that take this into account.",
                    "label": 0
                },
                {
                    "sent": "Now, one way to do it is to say, well, everything that is good.",
                    "label": 0
                },
                {
                    "sent": "I'm going to hope that it gets a very high score, let's say 100.",
                    "label": 0
                },
                {
                    "sent": "Everything that is bad.",
                    "label": 0
                },
                {
                    "sent": "I'm going to hold it gets a very bad score, let's say zero, and then I compute the difference between zero and the obtained score 100 obtain score.",
                    "label": 0
                },
                {
                    "sent": "The standard L2 kind of behavior and that was will see is not going to work.",
                    "label": 0
                },
                {
                    "sent": "OK, so let me show you exact.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Really, how this is going to happen?",
                    "label": 0
                },
                {
                    "sent": "I'm going to show you a couple of solutions, but the problem is quite generic so well is going to center on a specific problem.",
                    "label": 0
                },
                {
                    "sent": "Imagine that we want to rank documents on the web.",
                    "label": 0
                },
                {
                    "sent": "OK, so a document on the web may be defined by a number of features.",
                    "label": 0
                },
                {
                    "sent": "Here, for example, I just used a bunch of features like them 25.",
                    "label": 0
                },
                {
                    "sent": "For a particular query, the page trying the length of the URL, the link in degree, the click distance, etc.",
                    "label": 0
                },
                {
                    "sent": "OK and the machine learning problem is combined them properly so that you get a good result at the end.",
                    "label": 0
                },
                {
                    "sent": "Now for a particular document, I have a particular value of each one of those boxes.",
                    "label": 0
                },
                {
                    "sent": "I obtain an output a score, let's say 12.7.",
                    "label": 0
                },
                {
                    "sent": "What was the desired output that I wanted to obtain full?",
                    "label": 0
                },
                {
                    "sent": "That's unknown.",
                    "label": 0
                },
                {
                    "sent": "That depends on the rank of the entire collection, so I don't have a signal here to learn this model.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So how are we going to do this then?",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We're going to define an error that is not doesn't depend on individual elements anymore, and that's what the new problem called ranking is being defined and a lot of people called this the ranking problem.",
                    "label": 0
                },
                {
                    "sent": "Now, at least in this sort of mathematical machine learning community and ranking is different from binary classification, multiclass classification, ordinal regression, all the problems I talked about at the beginning are not a subset of ranking.",
                    "label": 0
                },
                {
                    "sent": "OK, so in ranking we're going to say we're going to be interested only in the top ranked objects.",
                    "label": 0
                },
                {
                    "sent": "That's the first thing.",
                    "label": 0
                },
                {
                    "sent": "Labels are only going to be relative to each other.",
                    "label": 0
                },
                {
                    "sent": "That's the second thing.",
                    "label": 0
                },
                {
                    "sent": "So there's two components.",
                    "label": 0
                },
                {
                    "sent": "The first one says I don't care about the errors on the entire collection.",
                    "label": 0
                },
                {
                    "sent": "I only care about the top ten errors.",
                    "label": 0
                },
                {
                    "sent": "She's a radical departure of, say, L2 or things like that.",
                    "label": 0
                },
                {
                    "sent": "The second one is I'm going to measure errors based on relative quality, not absolute quality.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is an example.",
                    "label": 0
                },
                {
                    "sent": "Imagine that you're learning a simple linear regression problem like you do in high school, so you have .6 and why you have a cloud of points and you're trying to find the line that fits.",
                    "label": 0
                },
                {
                    "sent": "Best those points, but now you're going to say, actually I'm only going to minimize that line on the points that obtained the 10 highest scores, for example.",
                    "label": 0
                },
                {
                    "sent": "So only compute this course that are high as the rest ignore.",
                    "label": 0
                },
                {
                    "sent": "Now those high sports is course depend on the line, so as a line changes, some points become important, some points disappear and that's why this is a non trivial problem, OK?",
                    "label": 0
                },
                {
                    "sent": "In our case, we're going to say we want high precision at 5, so I don't care about the score of any document except they want the guys that get at the top five.",
                    "label": 0
                },
                {
                    "sent": "So as we change the parameters, some guys that they took five disappear.",
                    "label": 0
                },
                {
                    "sent": "Some guys enter and then they matter or they don't matter depending where they are on this line.",
                    "label": 0
                },
                {
                    "sent": "Precision 5 is interesting because precision at K is just.",
                    "label": 0
                },
                {
                    "sent": "If you can do this, then you can do average precision.",
                    "label": 0
                },
                {
                    "sent": "You can do anything you can do reciprocal mean and a whole bunch of family functions that they are all used in information retrieval.",
                    "label": 0
                },
                {
                    "sent": "So the big problem is this idea of precision at K. If you can solve that, then everything else is solved.",
                    "label": 0
                },
                {
                    "sent": "This is difficult, but and there's been some theoretical resource before that had algorithms, but they were extremely expensive to compute and I think we're getting to the point where there's a couple of competing algorithms that can do this kind of thing.",
                    "label": 0
                },
                {
                    "sent": "If you have enough data, you know you can learn this copy.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So let me just go back here.",
                    "label": 0
                },
                {
                    "sent": "OK. Is this?",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so imagine that I could do that.",
                    "label": 0
                },
                {
                    "sent": "I have this error function that I can define.",
                    "label": 0
                },
                {
                    "sent": "OK, so that for a particular setting of parameters on a particular collection, I can compute the error.",
                    "label": 0
                },
                {
                    "sent": "So an example of that is average precision, average precision cares about the top more than the bottom, so it really similar to what humans care about.",
                    "label": 0
                },
                {
                    "sent": "How good are we at the top of the rank?",
                    "label": 0
                },
                {
                    "sent": "So here I've plotted this thing for a particular ranking function that has only two parameters.",
                    "label": 0
                },
                {
                    "sent": "I can plot all possible results of average precision for those two parameters, so this is what this graphical representation means.",
                    "label": 0
                },
                {
                    "sent": "If I take a point here like this, I take a ranking function that has two parameters.",
                    "label": 0
                },
                {
                    "sent": "I said the first parameter to this value.",
                    "label": 0
                },
                {
                    "sent": "I said the second parameter to this value and I compute the final average precision over a particular collection.",
                    "label": 0
                },
                {
                    "sent": "And now I do that for all possible values of the two parameters I attend this surface here and it tells me basically that if I set the parameters to this value, the first one and this value the second one, I get the maximum possible average precision.",
                    "label": 1
                },
                {
                    "sent": "So learning is finding that point, finding the parameter setting that optimizes your error function.",
                    "label": 0
                },
                {
                    "sent": "That's what learning is about, and there's several ways to do this.",
                    "label": 0
                },
                {
                    "sent": "One way that we tried to do this is using gradient descent.",
                    "label": 0
                },
                {
                    "sent": "So if I am here and I can compute this surface analytically, then I can follow the gradient until I hit the maximum.",
                    "label": 0
                },
                {
                    "sent": "And if there's one local minima in a whole bunch of other conditions, then I get the right the right result at the end.",
                    "label": 0
                },
                {
                    "sent": "So if I could just compute the gradient here, I would be happy will be solved.",
                    "label": 0
                },
                {
                    "sent": "The main problem is that when you have this kind of error function that I talked about where you have rank dependent error functions, nobody knows how to compute a gradient there.",
                    "label": 0
                },
                {
                    "sent": "We just don't know how to compute a gradient.",
                    "label": 0
                },
                {
                    "sent": "So let me show you why.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is an example of precision at K precision at 5.",
                    "label": 0
                },
                {
                    "sent": "How do I compute this?",
                    "label": 0
                },
                {
                    "sent": "One way of writing this is the following.",
                    "label": 0
                },
                {
                    "sent": "Imagine that that's an example.",
                    "label": 0
                },
                {
                    "sent": "There I have 4 results.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to look at all the pairs of documents.",
                    "label": 0
                },
                {
                    "sent": "I have a number of documents and I'm only considering there for documents.",
                    "label": 0
                },
                {
                    "sent": "OK, so I can be 1234 and J can be.",
                    "label": 0
                },
                {
                    "sent": "Sorry that this is great, so there's a number of documents and I'm going to take two at random I&J and I'm going to look whether I is above or below J and if it's above whether it's relevant or more relevant than the other one.",
                    "label": 0
                },
                {
                    "sent": "So what I want is that if one document is more relevant than the other one, it should be above, and if not, it should be the other way around.",
                    "label": 0
                },
                {
                    "sent": "So these are the possibilities.",
                    "label": 0
                },
                {
                    "sent": "Imagine that, for example, I is not relevant and J is relevant.",
                    "label": 0
                },
                {
                    "sent": "So as long as J is above I, then my error is good.",
                    "label": 0
                },
                {
                    "sent": "OK, if they're both irrelevant or both relevant and there's nothing.",
                    "label": 0
                },
                {
                    "sent": "I know they could be anywhere.",
                    "label": 0
                },
                {
                    "sent": "All I know is that there are less likely to be one above the other.",
                    "label": 0
                },
                {
                    "sent": "Finally, if they reverse, then I want the other one to be on top, so this is just one minus because this is normalized to 01 and this is just some function of the difference of scores.",
                    "label": 0
                },
                {
                    "sent": "OK, the error.",
                    "label": 0
                },
                {
                    "sent": "So in this case, if I take a function like this, it just says if I am above.",
                    "label": 0
                },
                {
                    "sent": "If the difference is positive, then the error is 1 difference, negative there is zero.",
                    "label": 0
                },
                {
                    "sent": "So this is just a function that as long as the relevant guys over an irrelevant one, then you're OK. And then at some point you go under it and then you ever go from zero to 1 for that pair.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's just a flip, it counts how many whether you are flipping and relevant with any relevant or not.",
                    "label": 0
                },
                {
                    "sent": "And so you can say the number of mistakes for a particular document in a particular rank.",
                    "label": 0
                },
                {
                    "sent": "It's just the number of flips as he goes from the top ranked to that position.",
                    "label": 0
                },
                {
                    "sent": "OK so I have a document position five.",
                    "label": 0
                },
                {
                    "sent": "I just look are there.",
                    "label": 0
                },
                {
                    "sent": "How many documents above me are negative?",
                    "label": 0
                },
                {
                    "sent": "That's the number of flips.",
                    "label": 0
                },
                {
                    "sent": "And then you can write precision at K as the maximum possible number of flips for a particular document at a particular rank.",
                    "label": 0
                },
                {
                    "sent": "OK, and you just have to believe me at this point that precision RK can be exactly written as this.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is the function that I want as an error function.",
                    "label": 0
                },
                {
                    "sent": "If I could take the derivative of these then I could just go up the Hill and then we would be done.",
                    "label": 0
                },
                {
                    "sent": "We don't know how to do this so one solution and there's been a couple proposed, but this is the one that for us seems to make more sense.",
                    "label": 0
                },
                {
                    "sent": "Is the following.",
                    "label": 0
                },
                {
                    "sent": "We do a bunch of tricks.",
                    "label": 0
                },
                {
                    "sent": "The first thing is this Max.",
                    "label": 0
                },
                {
                    "sent": "We don't know how to take a derivative off, so I'm going to replace it by the sum and this is standard trick and now we're sort of in approximation land will no longer optimizing precision at K, But some kind of approximation.",
                    "label": 0
                },
                {
                    "sent": "And instead of taking this step function here, we can take.",
                    "label": 0
                },
                {
                    "sent": "Some kind of smooth version of that so it could be a hinge laws or exponential growing function.",
                    "label": 0
                },
                {
                    "sent": "OK, and suddenly what happens is that this sum now because it's a sum over some server smooth functions.",
                    "label": 0
                },
                {
                    "sent": "I know how to take the relative derivative and I can do gradient descent over it.",
                    "label": 0
                },
                {
                    "sent": "OK, what does that mean?",
                    "label": 0
                },
                {
                    "sent": "It means that I.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm here.",
                    "label": 0
                },
                {
                    "sent": "I have the surface.",
                    "label": 0
                },
                {
                    "sent": "I've now changed the surface into some kind of approximation, which takes a salmon's mood version, so I don't know the surface anymore.",
                    "label": 0
                },
                {
                    "sent": "But I have some kind of approximation in which I can move now towards the maximum, so if the approximation is good enough then I will hit the right point.",
                    "label": 0
                },
                {
                    "sent": "If the approximation is not good enough, then it will be somewhere else.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So let me show you how that works.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is what we had at the beginning.",
                    "label": 0
                },
                {
                    "sent": "We were somewhere over here, but we didn't know how to compute the gradient, and we approximated this with something that we know how to compute the grade and then we look at it and say does it look like originally?",
                    "label": 0
                },
                {
                    "sent": "And this is what we get.",
                    "label": 0
                },
                {
                    "sent": "This is mirth surface that we know how to navigate.",
                    "label": 0
                },
                {
                    "sent": "In some sense we have a local gradient here and it looks remarkably like.",
                    "label": 0
                },
                {
                    "sent": "Map OK, so that's a nice result, at least in 2D.",
                    "label": 0
                },
                {
                    "sent": "Kind of indicates that you have the right surface.",
                    "label": 0
                },
                {
                    "sent": "OK, so we started doing all kinds of studies of can we prove theoretically that these two are closed?",
                    "label": 0
                },
                {
                    "sent": "Can we prove empirically at these two are close and there's a number of work is going to the papers, but that's not true.",
                    "label": 0
                },
                {
                    "sent": "Number of rejected papers that cigar that you can try to read OK?",
                    "label": 0
                },
                {
                    "sent": "So one result that is interest.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It is theoretically, can you prove that those two services have to be closed, at least at some point?",
                    "label": 0
                },
                {
                    "sent": "Because if you can't, then it's all guessing.",
                    "label": 0
                },
                {
                    "sent": "And we have one result that is quite quite simple and quite powerful by by Robertson that says the following.",
                    "label": 0
                },
                {
                    "sent": "If you are at a local Maxima of the new function that we've invented, then you have to be at a local Maxima of N DCG average precision on any rank depending measure that you have.",
                    "label": 0
                },
                {
                    "sent": "This is quite nice 'cause it means if you actually find this Maxima then you know that at least it's a local maximum for the other measures.",
                    "label": 0
                },
                {
                    "sent": "That's quite powerful.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately, there's only been proven for 2D.",
                    "label": 0
                },
                {
                    "sent": "When you go to Heidi then there's a bunch of weird cases in which this is not necessarily true, so it's more a lemma or.",
                    "label": 0
                },
                {
                    "sent": "Or a hope than a theorem, but hopefully people that are more mathematically oriented and can read these and prove it for all possible cases and then will be done OK.",
                    "label": 0
                },
                {
                    "sent": "So that's the only theoretical result that we have.",
                    "label": 0
                },
                {
                    "sent": "We have a bunch of empirical results like this, like this one where we can actually prove that we get the right results.",
                    "label": 0
                },
                {
                    "sent": "The most interesting one was done at a very large.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Cal recently at Microsoft where they actually took thousands and thousands of training patterns and they compute real precision or N DCG, which is a soft version of average precision over thousands of queries for real user evaluations.",
                    "label": 0
                },
                {
                    "sent": "So this is what happened.",
                    "label": 0
                },
                {
                    "sent": "The first option that you have is you have all these parameters and you don't know anything about.",
                    "label": 0
                },
                {
                    "sent": "Just explain so you can try to do some kind of line search, and if you're lucky enough you will find the right parameter setting OK.",
                    "label": 0
                },
                {
                    "sent": "In fact with very few parameters you can do a fairly exhaustive line line search and then you find the right possible.",
                    "label": 0
                },
                {
                    "sent": "The highest possible maximum, but this may overfit of course, so this is what you get as you increase the number of training.",
                    "label": 0
                },
                {
                    "sent": "This means query document pairs.",
                    "label": 0
                },
                {
                    "sent": "OK, so for example this means I have 1000 query document pairs, which could mean I have 100 queries with 10 evaluations each, or maybe 50 queries with 20 evaluations etc.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So let's search over fits a lot of the beginning and then it settles and it doesn't take too many features at the end because the number of features is kind of in saturated here.",
                    "label": 0
                },
                {
                    "sent": "Now, in theory, if you are lots of more features, you could bring this up but it overfits even more so it takes you forever to actually settle and by then you have spent all your money on evaluations and the game is over.",
                    "label": 0
                },
                {
                    "sent": "OK so one thing you can do is you can train this gradient descent.",
                    "label": 0
                },
                {
                    "sent": "I just talked about with the function approximation function that I just talked about and then you get this kind of behavior.",
                    "label": 0
                },
                {
                    "sent": "We use few features you can see that right away you're in the right region.",
                    "label": 0
                },
                {
                    "sent": "Probably because you're a bit more robust with respect to overfitting and then as you add features in very increases a little bit, but it settles because basically you're not going to get any better than what line search does with lots of features, but the advantage that this is automatic.",
                    "label": 0
                },
                {
                    "sent": "Sorry, this is automatic, this is a gradient descent, so this is the time it takes is not at all exponential in the sense of line search.",
                    "label": 0
                },
                {
                    "sent": "OK, kind of proves that you have here are very hard to explain because it depends on so many things, but in practice it great in the sentence to finally quickly.",
                    "label": 0
                },
                {
                    "sent": "Find quickly local Optima.",
                    "label": 0
                },
                {
                    "sent": "Now what you can do with this kind of bread in the sense that I just described, you can now explore the number of features you don't care how many features you have because you can compute these credits now over any number of features, so you can greatly increase the number of features so we go from order of magnitude of 10 to 52 order of magnitude of 100 to 500.",
                    "label": 0
                },
                {
                    "sent": "And what you see is that well, initially, as you can imagine, this thing is wildly all over the place because there's not enough data, but it keeps going.",
                    "label": 0
                },
                {
                    "sent": "And we don't know how far it keeps going because we could continue to add queries and training data and this could go so this kind of energy increase is sort of unheard of.",
                    "label": 0
                },
                {
                    "sent": "This is not statistically significant, is statistically amazing for us, like a .1 increase in energy is like as much as you could guess.",
                    "label": 0
                },
                {
                    "sent": "So for us this is very critical and the fact that it's so simple to learn now because we have this gradient descent.",
                    "label": 0
                },
                {
                    "sent": "For us it was very important.",
                    "label": 0
                },
                {
                    "sent": "OK, I'm going to stop there and Nick and I are.",
                    "label": 0
                },
                {
                    "sent": "Nick is in the conference, so if you're interested in this kind of work, he's actively in the area so you could talk to him.",
                    "label": 0
                },
                {
                    "sent": "This is what happens in CRC missions.",
                    "label": 0
                },
                {
                    "sent": "Did you ever is this offer different runs?",
                    "label": 0
                },
                {
                    "sent": "I mean he's playing games.",
                    "label": 0
                },
                {
                    "sent": "Different connections of training sets because this ringing seems very well.",
                    "label": 0
                },
                {
                    "sent": "This is why you get so.",
                    "label": 0
                },
                {
                    "sent": "So here you're in an area that is underspecified, so it's very random.",
                    "label": 0
                },
                {
                    "sent": "So if you average, you will get a very large error bar, which gets smaller and smaller as you going home.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I feel the same for competitive gaming instead of this complicated real social construction meeting.",
                    "label": 0
                },
                {
                    "sent": "Necessary and asking difficult questions game as opposed to this country.",
                    "label": 0
                },
                {
                    "sent": "Cumulative gain.",
                    "label": 0
                },
                {
                    "sent": "NDC G as you get further down the list, yet much less of the center.",
                    "label": 0
                },
                {
                    "sent": "So we thought that discounting yeah yeah, so actually OK so here this pairwise thing does not take into account the discount.",
                    "label": 0
                },
                {
                    "sent": "It does not.",
                    "label": 0
                },
                {
                    "sent": "So you actually trust CG a lot better than decision.",
                    "label": 0
                },
                {
                    "sent": "We're just getting lucky enough that this is good enough for this.",
                    "label": 0
                },
                {
                    "sent": "In theory, you want to force that behavior, and that's really hard is something we've worked quite hard and we failed so far to actually be able to discount as you go down.",
                    "label": 0
                },
                {
                    "sent": "So this is actually almost DCG tracking.",
                    "label": 0
                },
                {
                    "sent": "Instead of N DCG, but with enough data it seems it doesn't matter.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "So that's a very good question.",
                    "label": 0
                },
                {
                    "sent": "That's going up.",
                    "label": 0
                },
                {
                    "sent": "This guy here.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I was very tempted to remove it, but I don't know.",
                    "label": 0
                },
                {
                    "sent": "I think.",
                    "label": 0
                },
                {
                    "sent": "I mean you were kind of here and maybe maybe that's go up slowly.",
                    "label": 0
                },
                {
                    "sent": "The thing is like search is very expensive and actually you know it gets more and more expensive as it goes to the right.",
                    "label": 0
                },
                {
                    "sent": "This this takes literally several like overnight right?",
                    "label": 0
                },
                {
                    "sent": "And this is orders of magnitude faster, so at some point you have to stop the line search.",
                    "label": 0
                }
            ]
        }
    }
}