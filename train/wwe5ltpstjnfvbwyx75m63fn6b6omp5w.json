{
    "id": "wwe5ltpstjnfvbwyx75m63fn6b6omp5w",
    "title": "Learning Theory",
    "info": {
        "author": [
            "Mark Reid, Research School of Information Sciences and Engineering, Australian National University"
        ],
        "published": "April 1, 2009",
        "recorded": "January 2009",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/ssll09_reid_leth/",
    "segmentation": [
        [
            "So, um, who for who is this the first summer school I've been to?",
            "Machine Learning summer school.",
            "That's good for this mine too.",
            "So my name is Mark Reed.",
            "I'm a research fellow.",
            "At the eye, and you hear the research School of Information Sciences and Engineering.",
            "OK, this is this song.",
            "This is make it clear.",
            "Just rearrange my setup.",
            "How's that better?",
            "OK, great, so today I'm going to talk about some work I've been doing with Bob Williamson.",
            "Son, as the title says, information divergents and risk for binary classification problems.",
            "It's quite a theoretical talk, so anyone looking for algorithms and applications you might want to give this one.",
            "I miss, so that very formal title is kind of my second choice.",
            "My first choice for a title would be."
        ],
        [
            "Taylor and Jensen's most excellent adventure through statistical learning theory.",
            "The reason for this title is a lot of the results that I'll be presenting today over the course of the next few hours in one way or another, related to Taylor representations for functions or Jensen's inequality.",
            "There are sort of two main theorems that will be driving a lot of this work, so.",
            "That's my preferred title for this talk."
        ],
        [
            "So before I get into the technical material, I'll just give a bit of a philosophical overview of what Bob and I have been working on for the last 18 months, which has been my pay."
        ],
        [
            "Stock here.",
            "I don't know how many of you are familiar with the old folk story of the blind men and the elephant.",
            "The story goes that these six blind men are standing around a large elephant, and because I can't see the elephant, they can only describe what they can feel.",
            "And so the guy on the.",
            "On the left there is saying, well, I must be standing in front of the branch because that's what I can feel.",
            "The second guy says I'm standing in front of some kind of pipe 'cause he's touching the Tusk.",
            "The next time I'm in front of a curtain or a fan 'cause he's holding elephants here.",
            "The next guy saying must be in front of a tree.",
            "This because the elephants foot feels like a tree trunk and so on.",
            "The guys in front of a big wall and the last cases that must be holding piece of rope must be in front of a piece of rope.",
            "Of course, all of them give different reports about what it is that they're experiencing, because they can't see the full picture Ann."
        ],
        [
            "I'm going to suggest with this talk that machine learning is the elephant in the room and a lot of work that's done in machine learning, or at least in binary classification in machine learning.",
            "Is only looking at small parts of the whole elephant at the one time, so."
        ],
        [
            "This is great quote by.",
            "Laplace punk punk Ari says mathematics is the art of giving the same name to different things so.",
            "What I'm going to try to do in this talk is show you that a lot of the names that are given to different things are actually the same concept."
        ],
        [
            "Right, so as I mentioned earlier.",
            "Here's what you can expect from this talk.",
            "I'll be giving a whole heap of definitions, mainly in the first hour, and then in the second hour.",
            "I'll talk about some relationships between these definitions and some representations of some of the main concepts, and there will be a few proofs thrown in for good."
        ],
        [
            "Measure.",
            "What not to expect?",
            "Any algorithms, models, data or technicalities?",
            "So it's."
        ],
        [
            "Very much a theory rather than a.",
            "Practical talk.",
            "So just letting you know what you're in for.",
            "Because we're going to be covering a large number of definitions."
        ],
        [
            "I always find Maps useful, so I'm going to give you a lay of the land of what I see is terror statistika So to begin with, I'm going to talk through a bit of background.",
            "I'm going to introduce a couple of key concepts from convex analysis.",
            "I'm going to introduce Taylor's theorem."
        ],
        [
            "Jensen's inequality.",
            "Then we're going to talk a little bit about binary experiments, an distributions statistical tests the Neyman Pearson lemma, and eventually F divergences are one of the key concepts in."
        ],
        [
            "My experiments.",
            "Then I'm going to move onto.",
            "Um?",
            "Class probability estimation or classification where will?",
            "Bump into ideas like lostris regret.",
            "And notions of information.",
            "So that will be in the first hour."
        ],
        [
            "Second hour, I'm going to talk about some relationships between all of those previous concepts and some different representations of those concepts that help us see things in a different light."
        ],
        [
            "And then at the end I'll talk about how we can apply a lot of these ideas to existing results and come up with a few new results.",
            "So that's later than any questions so far."
        ],
        [
            "Alright, let's get started."
        ],
        [
            "This first part is going to introduce some background, so how?"
        ],
        [
            "If you are familiar with ideas of convex sets and convex functions, hoping a lot of you yeah.",
            "OK, good, so I'll I'll rush through this fairly quickly then.",
            "So a convex set is pretty key concept.",
            "It's a convex set is some collection of points that's closed under convex combination.",
            "Anna Convex combination is.",
            "I like to think of it as an average, so as the definition says there.",
            "There's a number of white slanders, Lambda, one Lambda N they all have to be non negative and they have to sum to one.",
            "If you take those weights and you take some set of endpoints within your set S. And you take the average in some sense, what convexity says is that that average also has to be in the set.",
            "That's sort of what that complicated definition says, but I find the picture a lot more intuitive.",
            "Basically saying every point in that triangle between those three points."
        ],
        [
            "In the set as well, there's a sufficient condition for convexity, which breaks it down to just.",
            "Saying that.",
            "All of the points that can be.",
            "Found between any two points in the set have to also be in the set, so a convex set satisfies that condition for every two points and a non convex set means that sometimes if you linearly interpolate two points you'll fall outside the set.",
            "I'm.",
            "No, mostly it'll just be.",
            "1 dimensional functions.",
            "Functions of real argument to the real line, yes.",
            "But of course, you can frame a lot of this stuff more generally."
        ],
        [
            "Not now.",
            "So like I said before, I like to think of convexity, meaning closed under expectations or averages and that.",
            "View of convexity is going to be fairly important in the remainder of this material."
        ],
        [
            "So a convex function is just a function whose epigraph is a convex set.",
            "An epigraph is just all of the points that lie above the function, so we can hear.",
            "See here.",
            "The curve line is F. The epigraph is all the points that sit above it, and we say a function is convex if its epigraph is convex, so that's pretty straightforward.",
            "One nice property of convex functions isn't necessarily continuous.",
            "If you want a nice little exercise, you can try."
        ],
        [
            "Prove that.",
            "Right, so now we get to the first main theorem that drives a lot of what's going to go on here, and it's Taylor's theorem, something you probably would have counted in.",
            "Your first year undergraduate calculus course, probably, or maybe even high school.",
            "This is a slightly different form to the one you used to the usual Taylor expansion is says that you can express a function as.",
            "A constant plus a linear term plus a quadratic term plus a cubic term etc etc.",
            "This integral form of Taylor's expansion says that you can express some function on an interval as.",
            "Evaluation at point.",
            "The linear term, which is multiplied by the derivative of that point and then all of the quadratic cubic.",
            "Um?",
            "Quartic and etc terms are wrapped up in that integral there so.",
            "Essentially, what this form of the Taylor expansion does is pull the pulls out the the linear part of the function and then wraps up the.",
            "Nonlinear part of the function in the integral term there, which is expressed as a linear part times the second derivative of the function integrated over this interval.",
            "So how many of you have seen this form of tell US expansion before?",
            "Yeah, as we say it's going to be quite."
        ],
        [
            "We're just going to put it in a slightly more convenient form.",
            "So in this form, all we've done is where previously the limits of integration were from the point that we're expanding about to the point we're interested in at evaluating.",
            "At here, we're just going to take the integral over the whole.",
            "Interval with the functions defined on.",
            "And change that T -- S term in there.",
            "Two piecewise linear terms, so this.",
            "This corollary is not hard to show.",
            "You just have to substitute in this this term and you'll get the original form of the Taylor expansion back.",
            "How?",
            "And.",
            "I'm pretty much going to ignore this twice differentiable condition.",
            "In a lot of this talk, because if you interpret these well, first of all, we're going to only look at convex functions and their continuous, so the left and right hand derivatives of all these functions are going to exist, and so we just pick one of them, and for the second derivatives we can kind of interpret them distributionally in some sense because the second derivatives mainly going to appear.",
            "As a as a inside the integral and so we can sort of, think of it as a measure.",
            "So.",
            "I'm pretty much going to ignore differentiability from now on.",
            "Any questions about that?",
            "So there's two cases, right?",
            "If T0 is less than T then GT S T -- S, But if it's the other way around, it says minus T, otherwise it's 0.",
            "So that that flipping of the sign just make sure that the interval goes the right way.",
            "OK."
        ],
        [
            "So I'm going to use these breakout slides to to emphasize.",
            "Key points during the talk, so this is our first key point.",
            "The integral form of Taylor expansion is.",
            "Is this guy so if you are deciding to take notes, this is 1 to drop down.",
            "Yep, they're arbitrary.",
            "So most of the time they will be zero and one some of the other time they'll be 0 Infinity.",
            "But we're going to.",
            "We're going to avoid the technicalities of when things converge a little bit just to get the flavor of the results more than anything.",
            "I should point out I've made a few modifications to the notes that are probably in your lectures, so the.",
            "Um, if I remember, I'll try and flag where the changes are, but for your own edification, I suggest that when I pop up one of these slides, you maybe jot down a few notes.",
            "I've tried to structure it a bit better.",
            "OK, so.",
            "One other point about this is because we're going to do with convex functions.",
            "One property of convex functions that second derivative is non negative, so that if double dashed function is always going to be.",
            "Are bigger than equal to 0."
        ],
        [
            "So another another thing you can derive from convex functions is a sort of general notion of distance, which is called a Bregman divergent.",
            "Bregman Bregman Divergent is formulas up there.",
            "It's essentially.",
            "The difference between.",
            "The curved part of the function and a linear part of this gap.",
            "There that's shown on the right hand side of the slides.",
            "And the formula is expressed in it in a fairly general way here.",
            "But for the functions, we're going to be considering.",
            "You can think of that as F of T -- 15 or minus the product of T -- T, not an the derivative of F at T. Um?"
        ],
        [
            "A nice connection between Bregman divergences and F divergences is that the.",
            "The Bregman divergences kind of the tail of the Taylor expansion of F. So if you rearrange if you took the Taylor expansion of F as I showed you before, and you rearranged it, you'd find that be of F is the integral part of that function.",
            "To see some more connections would go on.",
            "So like I said, it's going to be a lot of definitions up front, but I'll try and pull it all together as I go."
        ],
        [
            "So the other the other really important thing in this talk is Jensen's inequality, who's seen Jensen's inequality before?",
            "Yeah, so this is this.",
            "Is this inequality.",
            "Inequality basically says the relationship between expectation and convex functions is and what we're looking at is material.",
            "I found out that.",
            "Convexity is quite central too.",
            "Probability theory, so this inequality kind of captures a lot of what's going on.",
            "So I'm going to talk about thing called, which I've called the Jensen Gap.",
            "Maybe others have called it the same thing, but essentially.",
            "If you have a convex function that's just Maps reels to reels, the Jensen Gap is the difference between.",
            "The expected value of the function as you vary its argument minus the function of valued at the evaluated at the mean of all of your arguments."
        ],
        [
            "Jensen's inequality says that this Jensen Gap quantity is non negative if and only if F is convex.",
            "So it's quite a strong characterization of what's going on between expectation."
        ],
        [
            "Convexity and I like to think of it in terms of this diagram here, so.",
            "If we've got four points along the bottom, there X one X4, you can imagine them being mapped up to F of X1 through the F of X4.",
            "Any average you take is going to lie somewhere in that quadrilateral in the function and Jensen's inequality just says that that points gotta lie above the corresponding point on the function.",
            "For that's all that Jennifer Quality says."
        ],
        [
            "As I said at the beginning, it's quite central to what we're looking at.",
            "So when I put it on one of these slides, so this gap here is non negative if and only if F is convex."
        ],
        [
            "The final.",
            "The final property of convex functions we're going to make use of a little bit is something that's called the Lasiandra Fenchel transform.",
            "Sure, many of you are familiar with this as well.",
            "Yeah, show of hands who's seen this before?",
            "He would have no OK.",
            "So this is another.",
            "This is a transformation that you can do to convex functions which.",
            "It's kind of like a generalized derivative in some sense for functions that may not be differentiable at some points.",
            "So the diagram sort of shows how you would calculate F star of T style, which is the.",
            "LF transform of the function F. So what it's saying is that if you give me some slope T star, I'm going to do this look through an origin and I want to maximize the difference between that line with slope T star and the convex function F. And in the diagram here you can see that.",
            "That value is maximized at the point shown at T. The details of."
        ],
        [
            "Where this is used is not so important.",
            "That's what's really important for our purposes is for convex functions.",
            "If you take this transformation again and your original function is convex, you end up with the same function.",
            "That is, we say that the LF transform is an involution on the set of convex functions.",
            "So that means if I take F doublestar I get F back as we'll see a bit later.",
            "This gives us another way to look at some key concepts in.",
            "Binary classification."
        ],
        [
            "So summarize this background section.",
            "What we've ended up with is Fire Taylor's theorem in via the Fenchel dual.",
            "We've now got two ways we can sort of pull apart convex functions.",
            "With Taylor's theorem, we can pull a convex function into a linear part and this.",
            "Integral of piecewise linear terms with respect to some.",
            "Wait function.",
            "If you like F double dash an with the variational representation.",
            "We can use this.",
            "Involuted property of the LF jewel to pull apart a convex function into.",
            "This supremum operator so there any questions so far?",
            "Well, that's just a product.",
            "But because we are dealing with the reels of replaced the inner product angle brackets with just the modification.",
            "What's that?",
            "Sorry yeah.",
            "Yeah, that's true.",
            "So that's some most of the background out of the way.",
            "I'll come back to come back to some of these definitions when they're required later in the talk."
        ],
        [
            "So back to our map.",
            "We've we've covered the background material now.",
            "We've talked about convexity, Tails theorem in Jensen's inequality, so."
        ],
        [
            "Move on to talking about binary experiments."
        ],
        [
            "So.",
            "A binary experiment is.",
            "The term comes from sort of old statistics literature, but essentially it's a pair of distributions P and Q / a common space which we'll call X.",
            "When we're dealing with the discrete space, you can kind of picture in your minds the discrete.",
            "Distributions P&Q is shown in that figure there, so we've got P assigns probability.",
            ".3 Point 5.2 to a B&C&Q assigns a different set of probabilities when we're dealing with continuous spaces.",
            "We just picture the two distributions as their density functions, that's.",
            "The mess intuitive way to get a handle on what's going on here and will often talk of P being the positive distribution and cubing the negative distribution.",
            "So."
        ],
        [
            "So.",
            "In binary experiments, usually what happens is you get a bunch of samples from one or the other of these distributions, and you want to say which one it came from.",
            "Sorry, what was that?",
            "What is a negative distribution?",
            "It's just a label.",
            "We're giving to queue, so we're saying that.",
            "To to make a link between binary experiments and binary classifications.",
            "It's it's good to think about P as being the distribution over positive instances and Q being the distribution over negative instances.",
            "OK, so in hypothesis testing you get some samples you don't know which distribution that's from, but you want to pick whether it was P or Q."
        ],
        [
            "This is called hypothesis testing and in some sense the further apart these two distributions are in your space, the easier this decision will be.",
            "So if I see a whole bunch of points coming from the left here, and I know my distributions over here or here, I can be pretty certain that came from the one on the left.",
            "But if the distributions overlap a lot is going to be a lot harder to make that decision.",
            "So what we require is some notion of distance between distributions and.",
            "BF divergent switch.",
            "I'll introduce in a bit is a big family of.",
            "Distances for distributions that will examine in some detail."
        ],
        [
            "But to get there I have to talk first about test statistics.",
            "'cause I'm going to do all of this non pair."
        ],
        [
            "Metrically, I'm not going to use models or I'm not going to assume.",
            "Um, whole bunch of parameter vectors and things like that.",
            "So we're going to deal with things non parametrically and so in general.",
            "We're going to need to formulate our tests in terms of a mapping from the original SpaceX to the real line, so we map all our points of the real line and then we calculate something with the mapped values.",
            "So this is called a test statistic.",
            "Its function from the space that we're interested in to the real line.",
            "I mean, it's usually some function is usually depends on the distributions you're interesting interested in as."
        ],
        [
            "Healthy.",
            "A statistical test is we take a test statistic an you just threshold it somewhere.",
            "So here I've introduced a threshold T not on the real line and all the points to the left of T not going to get.",
            "Assigned to the positive class and all of the other way around.",
            "All of the points bigger than order in the positive class.",
            "All the points less than a negative class.",
            "So each threshold partitions the entire space into 2.",
            "So that's you got a statistical test which is an arbitrary mapping.",
            "Whenever your threshold it, you get.",
            "Sorry, test statistic is an arbitrary mapping down to the reels and then when you threshold it you get a test statistic statistic.",
            "Any questions?"
        ],
        [
            "You might have seen these before.",
            "He's seen contingency tables, true positives, false positives, those sort of things, right?",
            "So this will be pretty familiar.",
            "So whenever you have a statistical.",
            "Test.",
            "I town a town North you can.",
            "Put in this contingency table how well it does.",
            "Essentially this contingency tables a summary of.",
            "The.",
            "The quality of the test statistic so.",
            "If we look at all the points again.",
            "That are bigger than the threshold.",
            "When the map down by Tao, if we measure them against P, that's sort of the true positive rate.",
            "It's also known as the power in the statistical literature literature.",
            "The false positive rate is when all of those mappings, all those points that got mapped above the threshold.",
            "When they actually negative instances, we get a false positive rate and similarly true negative and false negative rates are as described up there.",
            "So this is a round about way to getting to the main point, which is this quite classical result from the statistical literature called the name in."
        ],
        [
            "Pearson lemma, who's heard of this?",
            "Alright, finally got something new.",
            "OK so the the Neyman Pearson lemma.",
            "Is fairly strong statement about what makes for a good statistical test.",
            "And.",
            "It is expressed in terms of this likelihood ratio, so the likelihood ratio.",
            "Is just the ratio of the probabilities.",
            "Single point, so if I've got my two distributions P&Q then DP and DQ or the densities the two densities of P&Q and the likelihood ratio Telstar is just the ratio of the densities at each point, so it's a function, and for each X it gives me the ratio of the two densities, right?",
            "So for a discrete distribution it will just be P of X / Q of X, but in the continuous case it's the radon nikodym derivative want robot, the technicalities?"
        ],
        [
            "So the name in Pearson lemma says that this likelihood ratio is in some sense the best.",
            "Test statistic you can use for binary experiment.",
            "It says that it's uniformly most powerful.",
            "That is, for any false positive rate you wish to choose.",
            "The likelihood ratio will give you the best true positive rate.",
            "So the way to think about this is I have my likelihood ratio that Maps me from my SpaceX to the real line.",
            "And.",
            "As I move my threshold, I'm going to change the false positive rate of this.",
            "Test statistic each time I thresholding to false positive rate what this lemma says is that the.",
            "For any other tests that you can think of with the same false positive rate, this will have the likelihood ratio.",
            "That is, will have the best true positive rate.",
            "So I'll come back to this diagram a bit later in the talk.",
            "This is an RC curve.",
            "People have seen these before, so you can kind of think of each test statistic as giving you a curve on an RC diagram and what the name in Pearson lemma says is the likelihood ratio is going to dominate every other.",
            "Curve that you care to put on this some diagram.",
            "Any questions about that?",
            "Well, like I said, how do you compute it with the question?",
            "In when you have a discrete distribution, it's quite simple.",
            "If I discrete distribution.",
            "I can compute the probability of P at each individual X, and I can compute the probability of Q at each individual point X, and then this likelihood ratio is just going to be.",
            "P of X divided by cube X.",
            "He computer quite directly.",
            "In the case of continuous variables.",
            "Um?",
            "You probably have to model the distributions stuff, but I'm not going to go into that.",
            "Conceptually.",
            "It's the same idea though.",
            "Right, so why have I gone this roundabout route through statistical tests well?",
            "Um?"
        ],
        [
            "We wanted some way of measuring.",
            "The distance between two distributions we have our distributions P&Q and we wanted some notion of distance or divergences between them and.",
            "This class of divergences about to describe called the F Divergences.",
            "Are built upon the likelihood ratio in some sense and.",
            "Took me a long while to realize this, but.",
            "When I started looking at these F divergences, I was just given the formula.",
            "You can see there in terms of the integral.",
            "It's the integral over all X of F. Or evaluated the likelihood ratio with an average taken with respect to Q.",
            "Look quite.",
            "And obvious to me.",
            "So after thinking about it for awhile, I realized that the reason it's formulated this way is the likelihood ratio in the middle there.",
            "Is the best mapping in some sense from our space to the real line for the pair of distributions P&Q in that it separates the points the most?",
            "Ann, this F function kind of acts as a penalty, so further away that D PDQ is from one.",
            "The F function gives you a penalty away from one, and so this F divergent here is kind of the average penalty you'll incur.",
            "4.",
            "Differing densities P&Q.",
            "Does that make sense?",
            "So every time that DP is not equal to DQ, we're going to incur some penalty.",
            "Um?",
            "So we can state this F divergent fairly generally, but to be a divergent we want it to be non negative and we want it to be.",
            "We want it to assign zero divergent if I'm.",
            "Comparing a distribution to itself.",
            "So on the right here, the condition we need is that.",
            "Um?",
            "The Q average of F of the likelihood ratio has to be.",
            "Big."
        ],
        [
            "Then well, from Jensen's inequality, we know that the following is the case if we start with the general definition of F. Vergence then.",
            "We can say that it's bigger than equal to F, evaluated the mean, but of course the queue mean of the PDQ is just one, so.",
            "For all F. That is."
        ],
        [
            "Convex we can get.",
            "BF divergences?",
            "PQ is bigger than F of 1.",
            "So if we want I have to be a divergent that is non negative and.",
            "Has some value zero when we're matching the same thing against itself.",
            "Then we need F to be convex and F1 to be 0.",
            "So.",
            "This."
        ],
        [
            "Is the.",
            "One another takehome slide.",
            "Here the class of divergences for two distributions.",
            "F divergences are the kind of think of it as a Jensen gap.",
            "For the function F. Applied to the likelihood ratio.",
            "And you've got this extra constraint, which is kind of a technicality, and that F of one is zero and all that saying is that you're not assigning any penalty.",
            "To the likelihood ratio, when the likelihood ratio is 1.",
            "That makes sense.",
            "Who's seen if divergences before?",
            "No.",
            "OK."
        ],
        [
            "So some examples will probably help.",
            "Maybe you've seen some of these before.",
            "So different choices of the function F will give us.",
            "Different types of divergent measures.",
            "So if we choose F of T to be the absolute value of T -- 1 at the top there.",
            "Plot of the function on the right hand side so you can sort of see what this is doing.",
            "You get what's called the variational divergent, which is a fairly.",
            "Central divergents in hypothesis testing.",
            "You notice that on all of these examples, it's a bit hard to see 'cause the scales too small, but on all of these examples, the functions are zero at F of 1, which is required by the definition, and maybe it's a bit clearer here.",
            "Went up when I was talking about penalties being assigned to deviations away from one.",
            "You can kind of see that all of these functions are minimized at F of 1 and then apply larger and larger penalties as you move away from 1.",
            "So for different choices of this penalty function F you get different measures of divergent when you take.",
            "The average of these?",
            "Against.",
            "Yep, that's right.",
            "Doesn't it tend towards 0?",
            "No, I don't.",
            "I don't think so because T will.",
            "Um?",
            "T goes to 0.",
            "I guess to go to 0 faster than log T1.",
            "That's surprising because it's clear that F of one in that case is 0.",
            "But the derivative is going to be.",
            "1.",
            "Derivative is going to be 1 plus LNT, right?",
            "So.",
            "As T goes to zero, it should go to negative Infinity, shouldn't.",
            "The derivative which is.",
            "Which is correct?",
            "So the derivative if you think that will prove is doing it going upwards or at the end.",
            "I don't think so, but we can check that during the break.",
            "OK. Maybe there's a mistake in my slide.",
            "So maybe if you come across some of you, probably would have come across the KL divergent in the past.",
            "Some of the other ones are a bit more obscure, but the point of this slide is that.",
            "There is a very large number of existing divergences for hypothesis testing that are subsumed by the class of F Divergent."
        ],
        [
            "So we'll just work through a quick example, so here's our discrete distribution again, over the points AB&C.",
            "Distributions P and blue and Q in red.",
            "And to compute this is the question I think demo had before.",
            "How do you compute the likelihood ratio?",
            "Well, you just plug the numbers into the formula.",
            "So the variational vergence is just the sum over the points AB&C of the ratio of the two probabilities.",
            "And then you apply the function to it.",
            "So in this case for variational versions, F of T was the absolute value of T -- 1.",
            "We plug it in and we find that.",
            "These two distributions, P&Q separated by one according to variational."
        ],
        [
            "Free.",
            "OK, so for discrete distributions you don't really talk about densities that much the densities.",
            "Yeah, so I used to PDQ 'cause it's kind of more general.",
            "Yeah.",
            "For sure.",
            "The ratio of the densities.",
            "The PDQ yeah.",
            "Yeah, with respect to some reference measure on the.",
            "On the space that you're interested in, turns out it doesn't really matter what reference measure you take, but you can just drive.",
            "You can just take the.",
            "Question of the two derivatives of the functions.",
            "Right, so if we choose a different, FF is equal to 20, we can plug it in.",
            "We can plug in P&Q for these two distributions as well.",
            "And KL Divergent gives a different.",
            "Measure of the distance between these two functions."
        ],
        [
            "So in some sense, there's.",
            "You can imagine the space of all possible distributions.",
            "Come over a B&C.",
            "You can visualize it as points in this convex combination of AB&C and.",
            "What each of the F divisions is doing is kind of measuring that distance between P&Q in this space of distributions."
        ],
        [
            "Alright, so that's binary experience, you know."
        ],
        [
            "Hopefully.",
            "We will be moving on to something.",
            "A bit more familiar to some of you have studied a bit.",
            "Have studied machine learning in the past.",
            "I found I was quite surprised actually.",
            "How much of the statistics literature is kind of unknown even by me when I first?",
            "Started looking into this stuff.",
            "What I hope to show in this talk is that.",
            "A lot of the there's a lot of commonality between concepts you see in.",
            "Binary classification and concepts you see in hypothesis testing, so we've just been overall hypothesis testing stuff and now will look at."
        ],
        [
            "Binary classification, which hopefully you'll be a bit more familiar with."
        ],
        [
            "So to recap.",
            "So in hypothesis testing we get a bunch of instances from one of two classes, and our aim is to try and decide where the instances came from.",
            "An as I said before.",
            "If we can get some measure of distance between the two distributions, the larger that distance, the easier it is to decide whether the samples came from P or Q.",
            "So.",
            "The point here is that.",
            "We want to make one decision.",
            "For a set of points, did they come from POQ an we use a measure of divergents to try and make that?"
        ],
        [
            "Decision.",
            "So in classification and probability estimation, we still have two distributions, but now we assume that we have a mixture of the two distributions.",
            "So.",
            "This mixture.",
            "Um?",
            "Means that.",
            "You can sample a point and there's a chance that came from P and there's a chance that came from Q an that chances alright using \u03c0.",
            "So Pi is the probability that a single point was grown from P as opposed to Q.",
            "And in classification, you're more interested in making this decision as to whether a point came from P or Q for each point, rather than for the entire set of points.",
            "And we measure how well or how badly we're doing with respect to some loss function or penalty.",
            "So."
        ],
        [
            "There's sort of two views going on here in.",
            "Um, I like to talk about them as being generative and discriminative of borrow these terms from some other researchers in the field.",
            "So.",
            "In the generative view on the right here.",
            "We had, we just had two distributions in the densities DP&Q.",
            "And now we kind of scaling them.",
            "We pick a single value Pi an we scale PBY pie and Q by 1 -- \u03c0 and we get these two distributions.",
            "Which we mix and get this mixture.",
            "Measure M so on the on the left.",
            "Here the green.",
            "Um, grain distribution is the mixture of P&Q.",
            "And instead of deciding.",
            "Whether a whole sample is from Peel from Q, we want to do is we want to kind of estimate this function Eater, which is the conditional class probability.",
            "So for each point X which runs along the bottom axis, we want to estimate.",
            "The probability that it came from.",
            "From the class P. So you can see for these examples on the right here P&Q.",
            "As we move from left to right, the probability came from P starts off very close to one and then it drops off in the middle through a half and then goes to zero as we.",
            "Head to the right so these are sort of two views of the same setup.",
            "If you like.",
            "How do you work?"
        ],
        [
            "How do you compute it?",
            "Oh, it turns out, it's the.",
            "It's the density of P with respect to M times pilots.",
            "There the formula just under empire so.",
            "If you started with just the joint distribution, it's the probability of wire conditioned on X.",
            "If you like.",
            "That makes more sense.",
            "So I'm going to refer to that as the conditional class probability or the pointwise class probability.",
            "So you can.",
            "Given pipian Q, you can compute ether and M using the formulas on the left there and vice versa given either and MI can compute \u03c0."
        ],
        [
            "P&Q using those formulas and essentially you can move between the two using Bayes rule.",
            "There's nothing really to it at all, it's just.",
            "You decompose the joint probability conditionally on X or conditionally on why, and you get the two different views, the generative and discriminative, Yep.",
            "This.",
            "So Pi is the.",
            "Probability.",
            "That your point was drawn from the distribution P. So if you want to interpret it in terms of a joint distribution, it's the marginal distribution over your class labels.",
            "It's the in fact it's the probability that your class label is positive.",
            "Everyone follow that so far.",
            "OK.",
            "So usually the way I think about it is that nature has kind of already picked pipian Q for you.",
            "You may or may not know it.",
            "Usually you try to estimate it from your data.",
            "Really going to talk about estimation.",
            "Data, if I can avoid it.",
            "Um?",
            "Right?"
        ],
        [
            "So for now, but now we switched so.",
            "From here on in I'll talk either about either and M as being.",
            "Sort of all the information about a problem or pipian cubing all the information about a problem.",
            "So now we can introduce something that helps fairly familiar people would have.",
            "But with different measures of loss before.",
            "So when you have a machine learning problem.",
            "Very simple way of.",
            "Determining how you're going is you just count how many mistakes you make when you create a classifier.",
            "So I get a bunch of training instances with positive and negative examples.",
            "I train it up and then when I test it on some test data, if I get a label wrong, I incur a penalty of 1.",
            "If I get right, I get a penalty of zero.",
            "That's a loss function, so in general a loss function.",
            "Is just a penalty for guessing some value.",
            "Eat a hat when the true classes Y where Y is the positive or negative 01 however you like.",
            "So when.",
            "So when Eater is discrete I when we just predicting 01 positive or negative, then we're essentially doing a classification problem, But when Eater is.",
            "Ranging between zero and one, we can think of the loss as being for probability estimation problem so.",
            "We're mainly going to focus on the latter probability estimation because the classification is like a special case.",
            "It's when you're making extreme probability predictions, if you like.",
            "So.",
            "Either here is your estimate of the probability that a point is in the positive class.",
            "OK."
        ],
        [
            "Once we have a loss function, we can talk about the pointwise risk for a loss.",
            "This is a function that.",
            "Takes in a true value for.",
            "The class probability takes in your estimate and then return sum score which is.",
            "The expected loss.",
            "So here capital L of Ada Ada hat is just the expectation.",
            "Overdrawing your class labels from a binomial distribution with probability eater and the expectation is over your loss function.",
            "And so you can actually just write that out explicitly.",
            "It's the 1 -- E to times the.",
            "The loss at zero of eight at plus eight times the loss at one of eat at.",
            "That sort of makes sense."
        ],
        [
            "Yep, and then of course you can take the average over all.",
            "Your ex is now.",
            "So once I have capital, Li can for each point I can workout the conditional risk.",
            "An I can average it all up over that distribution M, which is over all of my points and I can get the full risk or the average pointwise risk.",
            "Yep."
        ],
        [
            "And then another important quantity that we have is the Bayes risk.",
            "Which is the best you can possibly do.",
            "For a given loss function at a given problem, so the Bayes risk here is this is the pointwise Bayes risk.",
            "I guess the first line capital L under buyer.",
            "Is the.",
            "Smallest pointwise risk you can get as you.",
            "Over all possible guesses, you can make, so that's the infima over all possible guesses eater.",
            "For the pointwise risk and the full Bayes risk is just expectations taken over me."
        ],
        [
            "And regret which is the last of these main quantities.",
            "I'm going to introduce is the difference between.",
            "The loss that you're.",
            "Estimate obtains, and the best you can possibly do so down the bottom.",
            "Here regret is just the difference between.",
            "The first case, that's the difference between the pointwise risk and the best pointwise risk in the second case, that's the difference between the best.",
            "Your risk, and the best possible risk.",
            "Alright, so that's a lot of definitions.",
            "Any questions about those who've seen one or more of these before?",
            "Yeah.",
            "OK, so maybe some examples again will."
        ],
        [
            "Clear things up.",
            "Time.",
            "OK, so you've probably all seen 01 misclassification loss, just not written in this way before.",
            "This is a function as I said, if you're.",
            "If you estimate one, either either hat is bigger than .5, but the true class is 0.",
            "Then you're going to incur a penalty for one.",
            "This double bracket notation is a bit of a shorthand.",
            "I use so double brackets of some predicate P is 1 if P is true and zero FP is false.",
            "So that's a shorthand way of writing that loss function.",
            "The dotted line is the.",
            "Loss when the true value is 1 and the solid line is the.",
            "Function When the true value is 0.",
            "So.",
            "Log loss is another.",
            "Loss function.",
            "When the loss is when the true value is 1, you get the dotted line, and when the true value is 0, you get the.",
            "The solid line never lets the log loss function square loss functions down the bottom left.",
            "An hinge loss is used a lot in SVM's as the function loss function you wish to minimize so.",
            "Any questions about those examples?",
            "These are all binary, so the whole talk is about binary classification and binary experiments, yet so they're all binary losses.",
            "Right now I'm."
        ],
        [
            "To talk about.",
            "Kind of subset, so I've introduced losses very generally here.",
            "And there are essentially any function I care to mention that takes in a true value and estimate and return some.",
            "Notion of cost.",
            "So what we're going to do is narrow our view a bit and consider what.",
            "I called proper losses or in the statistics literature known as proper scoring rules, so this introduces a very mild condition called Fisher consistency, which I think you'll agree makes intuitive sense anyway, so.",
            "We say that our losses fish are consistent.",
            "If it's minimized by the true value of the probability of the class labels, so.",
            "What this statement says here is that the pointwise risk L. Um?",
            "When the true probability of the positive classes eater, if you estimate either, then you've minimized the risk.",
            "Right, so that's Fisher consistently says.",
            "Basically, if you.",
            "If you guess the true probability, then you should incur the least possible penalty.",
            "That's Fisher consistency, and we say that Fisher consistency.",
            "We say it's strictly Fisher consistent.",
            "If it's uniquely minimizes the loss function.",
            "Right?"
        ],
        [
            "So a proper loss is just one that's Fisher consistent.",
            "Um?",
            "So as I said before, in economics are known as proper scoring rules and have been studied by lots of people for a long time, but only very recently.",
            "The last couple of references there, Boo ET al few years ago.",
            "And very recently, a guy called Lambert started looking at.",
            "Kind of machine learning.",
            "Take on these proper scoring rules and I find them very interesting and I think I'm hoping.",
            "In this talk, to convince you that there's something that we need to study as machine learners as well, they have a very long history and they have a lot of interesting structure.",
            "So one."
        ],
        [
            "Again, I'll see if I can help your intuition a bit with some examples so.",
            "Of these four losses we saw before, three of them are proper, and one of them is not proper.",
            "So, um.",
            "The.",
            "The way you would test that these functions proper, which I'm not going to do now is you would take their derivative an you'd make sure that that derivative is 0.",
            "You take the derivative with respect to either hat, which is your estimate and when you plug in heater you want to get zero and that way you know you've got a minimizer.",
            "So if you do this procedure with each of zero misclassification log loss square loss, you'll see that they are indeed proper.",
            "So that means the pointwise risk is minimized by the true value of the class label true value of the probability of the class label.",
            "But hinge loss is one of one of the few that isn't.",
            "Which is unfortunate because it's used a lot in support vector machines.",
            "And the interpretation of hinge loss being not proper is that.",
            "Hum.",
            "It's.",
            "We'll get onto this idea of surrogate losses later, but.",
            "Um?",
            "01 misclassification loss is very hard to use in practice because you're not given any hints of whether you're doing better or worse at a given point, so.",
            "With all these other losses, the derivatives give you some hint as to which way you should change your estimate in order to get better zero.",
            "I'm in class classification doesn't do that.",
            "It's basically says you're wrong, you're wrong, wrong, wrong wrong, and then suddenly you're right.",
            "So you've got no hints as to how to minimize it, so.",
            "It's called a sorry.",
            "A lot of the time people use hinge loss 'cause it's very simple.",
            "But it being not proper means that unlike the other losses.",
            "Where you're effectively doing probability estimation, hinge loss is directly doing classification instead of probability estimation.",
            "I'll talk a bit more about surrogate losses at the end of this this session, but just thought I'd highlight that now."
        ],
        [
            "So there's some really, really cool properties of of proper losses.",
            "One is that their pointwise Bayes risk is always concave.",
            "Now we're seeing some, maybe some links back into the background part of the talk, right?",
            "So we talked about convexity and everything, here's why.",
            "If.",
            "If we just expand the definition of capital L on the right there we get 1 -- 8 * L Zero 8 at plus 8AL1 Aida hat.",
            "That's the definition of Le to eat a hat on the right.",
            "You can see that they're just lines.",
            "With respect to Aida.",
            "So.",
            "The infamous, then, when we're taking the pointwise Bayes risk.",
            "This function is just an infamous whole lot of lines, and there's a theorem from convex analysis that says that if your function is described as the in form of a whole lot of lines, it's gotta be concave.",
            "So the Bayes risk.",
            "For proper scoring rule is.",
            "Is a concave just."
        ],
        [
            "Um?",
            "There's a theorem by a guy called Leo Savage back in 1971 from statistics and economics.",
            "He went a bit further, he said that.",
            "Your loss function is proper if and only if its base risk is concave, so that's quite a strong statement.",
            "It says if you give me any concave function that concave function.",
            "Must be the pointwise Bayes risk for some proper loss.",
            "And if you give me a lot proper loss then its pointwise Bayes risk must be concave, so it's kind of a complete characterization of the proper losses.",
            "Um, he also provides this formula of how you translate between the two.",
            "So if you give me a concave function L bar.",
            "Then I can derive a proper loss.",
            "With this formula here I I take L bar at my estimate and then I add this linear term times the derivative at my estimate."
        ],
        [
            "So this is another one of these.",
            "Really cool things that you should drop down if you haven't already, this is.",
            "This is like a complete characterization of proper losses and proper losses are what you want to do.",
            "The right thing to use for probability estimation.",
            "So one.",
            "We'll see this quite a bit as we go through some of the relationships between these things.",
            "Any questions about that?",
            "I'm.",
            "Because it is directly doing classification so.",
            "One thing I'll get to when I talk about surrogate bosses a bit later is.",
            "That essentially when you use a surrogate loss, you're doing probability estimation and then you kind of thresholding to get a classification.",
            "If that surrogate loss is a proper scoring rule, then that's what you're doing.",
            "You're going through.",
            "Probability estimation to get to classification.",
            "The hinge loss is interesting because it's not a proper loss, so you're not doing probability estimation.",
            "You're going straight for classification so.",
            "Yep, but there's this.",
            "There's this principle.",
            "By that Nick says, you know.",
            "Invented a lot of the theory behind support vector machines and he sort of said you should do classification if your aim is to do classification you should do classification directly.",
            "Don't go via some Securitas route.",
            "So that's why the hinge loss is not proper because it's not doing probability estimation.",
            "It is what sorry inconsistent.",
            "Yeah, so the pencil.",
            "Right?",
            "It could, it could be.",
            "I mean, it's what it does.",
            "Basically if you try to minimize hinge loss.",
            "The your estimates will either zoom off to negative Infinity or zoom off to positive Infinity, representing a negative prediction or positive prediction because the law says that if you're depending on which side of the margin, you shouldn't make that function as bigger as small as possible.",
            "So it doesn't do probability estimation, 'cause that requires your function to.",
            "This requires your predicted to sort of tune its value to a precise probability test."
        ],
        [
            "Alright, so I'll just run through some examples really quickly so.",
            "This is some examples of savages theorem, so if we take zero on misclassify."
        ],
        [
            "And also we can write the pointwise risk like this which is just.",
            "Negative 8 or if prediction is bigger than .5 and either prediction is less than .5.",
            "That's the penalty penalty.",
            "The average point.",
            "Where is this?",
            "You'll get for prediction either."
        ],
        [
            "We can compute the minimizer of this by just plugging in.",
            "Um eater, instead of eat a hat and we get very very slight variation that you notice the hats are missing from.",
            "The conditions in the second line."
        ],
        [
            "And then of course we can take the derivative, which will just be negative one if you're if either is bigger than .5 and one for less than .5.",
            "So I haven't done this on the screen, but if we go back to.",
            "We go back to.",
            "Savages theorem."
        ],
        [
            "What I was trying to show with this example is how you can compute L bar and El Bar Dash quite easily and.",
            "If you drop down this example and compute these values, you can convince yourself."
        ],
        [
            "That the LL of Ada Ada hat is actually equal to.",
            "The formula seven.",
            "These values for LL Bar and Elbow Dash satisfy that Savage formula.",
            "You"
        ],
        [
            "Do the same thing for log loss as well.",
            "So you can take the definition of log loss."
        ],
        [
            "It's quite easy to compute L of ITA ITA hat.",
            "You just plug in either and eat a hat into the formula.",
            "You can, we know, because it's proper that we can just plug in heater wherever we see, eat a hat to get the minimizer.",
            "And then we can just take its derivative an once again, if you felt like it, you could plug these back it into the Savage format and you'll see that because it's a proper loss that for."
        ],
        [
            "So satisfied, so the point of the examples are that.",
            "Normally you might think of Bayes risk is something very unwieldy and hard to get to.",
            "After all, that's what it is you're trying to get to when you're minimizing when you're doing any kind of optimization problem in classification, you're trying to minimize loss, so normally you would think that the Bayes risk would be a very difficult thing to work with, but the pointwise Bayes risk or conditional Bayes risk is actually just closed formula and it's very easy to work with if you give me a loss, I can compute the pointwise loss and I just plug in heater in both arguments and I get the.",
            "Um, I get the.",
            "Pointwise Bayes risk?",
            "Given that if it's proper, This is why proper proper losses are important.",
            "OK, any question?",
            "Any anymore questions?",
            "Alright, so I've got a few minutes left to go through the last lot of definitions and then after this session I've covered all of the all of the important points and will start connecting him up in the next part.",
            "So the last thing I'd like to talk about is information motions of in."
        ],
        [
            "Nation for binary experiments.",
            "Whenever I think of information, there's this great quote by TS Eliot, who asked in his courses from the Rock."
        ],
        [
            "Where is the wisdom we have lost in knowledge and where is the knowledge we have lost in information?",
            "I think it's some.",
            "I think it's something we should.",
            "We should ask as machine learners because our job I think is too.",
            "Recover knowledge from information or maybe even were a step lower.",
            "We need to recover information from data.",
            "So eventually would like to move up that hierarchy and get to.",
            "Artificial wisdom, I suppose."
        ],
        [
            "Right so back in 1962 guy called.",
            "The group introduced a very general notion of what he called statistical information.",
            "Anne.",
            "The way he set it up, as he said, well, let's suppose we have some distribution which is called desire there.",
            "And suppose we've got you, which is some measure of how uncertain the distribution is.",
            "So for really really peaked distribution like the one on the left there we would say it has low uncertainty.",
            "All of the distributions very tightly.",
            "Tom.",
            "Peaked around a single value, so there's not much uncertainty in that.",
            "Then for other distributions where the more spread out, you would say that has high uncertainty.",
            "So he like to think of this uncertainty function you which assigned measures of uncertainty."
        ],
        [
            "Distributions.",
            "I'm now we assume that we have some prior distribution over our values and then we have some posterior distribution.",
            "Then we can talk about a reduction in uncertainty.",
            "We can say how much uncertainty was there when I only had the prior and how much uncertainty was there when I had the posterior.",
            "And this reduction of uncertainty is what he called information.",
            "So if I started a prior and observe X one, I would get some posterior.",
            "Zyvex one when I observe X2 I might get a different posterior.",
            "X3 might give me a different posterior."
        ],
        [
            "And if I take the average.",
            "Over all of my observations and I look at the average reduction of uncertainty.",
            "Then um.",
            "This is what he called statistical information.",
            "It's the average reduction of uncertainty from a prior to.",
            "Posterior distributions.",
            "It's just some function.",
            "So.",
            "I.",
            "It could be the variance, it could be.",
            "Um?",
            "Could be yeah, it's.",
            "Quite general, I'll show you how we get a whole lot of uncertainty measures for free in a bit.",
            "Yep, and this is a really cool part so."
        ],
        [
            "Right?",
            "So.",
            "Intuition says that if I start with the prior and I observe something.",
            "That observation should contain some information.",
            "It's not going to take away information.",
            "At the very least right.",
            "So if I have some measure of information with respect to some uncertainty function, then we'd hope that it would be bigger than the information that we derive from that uncertainty.",
            "Certainty function is going to be non negative.",
            "We want the reduction to increase.",
            "We want to.",
            "So we start off being very uncertain.",
            "We just have a prior and then as we get observations we want to pull that uncertainty down.",
            "So the gap we get from.",
            "What we had when we started and what we had after the observations.",
            "We want to be as big as possible.",
            "So we want this to be non.",
            "And this is where Jensen's inequality comes in again.",
            "So if if I use the definition of information had before that Delta you an I expand it out.",
            "In a few lines you can see that this is actually.",
            "The uncertainty of the average value of the distribution minus the average value of the uncertainty.",
            "So this is just the Jensen gap that was introduced awhile ago."
        ],
        [
            "And we know that Jensen's inequality says that we only get this Jensen Gap being non negative when we have a convex function.",
            "Well, in this case the negative of a convex function, so we only get.",
            "A sensible definition of information using this construction.",
            "If the uncertainty function we had is concave.",
            "Right?"
        ],
        [
            "So this is I've introduces in a very general fashion, but it does subsume pretty much any measure.",
            "Any definition of information you care to mention.",
            "So Shannon information is when your uncertainty function is the entropy of the distribution, for example.",
            "I'm not sure what you would get if you use variance, but that would be interesting."
        ],
        [
            "So here's another takeaway.",
            "Statistical information is the reduction between the prior uncertainty in posterior certainty uncertainty and this is non negative and only if you is concave.",
            "Um, so in the next part of this talk after the break.",
            "Will see how to get ahold of you functions."
        ],
        [
            "Before we finish up just recently in 2005 in Erie, Banegi and a few others introduced this notion of Bregman information they started with.",
            "A Bregman divergent.",
            "So someone gives you a Bregman divergent service base of points and then asks.",
            "What single point in my space minimizes the average distance to every other point in that space, and so Bregman?",
            "Pregnant information is.",
            "A measure of the average distance to every other point from a given point in a space where the distance is measured by the Bregman divergences that you were first given.",
            "So someone gives you a Bregman divergent.",
            "The pregnant information is average spread if you like.",
            "With respect to that Bregman divergent.",
            "So quite a technical definition and they show that the.",
            "The single point that that that that achieves this minimum is actually the mean of the distribution that you're interested in.",
            "And the reason I'm not going to spend much time on this is because in the next part of the talk, we'll see that this is exactly the same as statistical information, although it looks very different to begin with, turns out."
        ],
        [
            "The same thing, and.",
            "So the next part of the talk we're going to use mathematics to give the same name to whole bunch of different things, but I think for now we'll just have a bit of a break."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, um, who for who is this the first summer school I've been to?",
                    "label": 0
                },
                {
                    "sent": "Machine Learning summer school.",
                    "label": 0
                },
                {
                    "sent": "That's good for this mine too.",
                    "label": 0
                },
                {
                    "sent": "So my name is Mark Reed.",
                    "label": 0
                },
                {
                    "sent": "I'm a research fellow.",
                    "label": 0
                },
                {
                    "sent": "At the eye, and you hear the research School of Information Sciences and Engineering.",
                    "label": 1
                },
                {
                    "sent": "OK, this is this song.",
                    "label": 0
                },
                {
                    "sent": "This is make it clear.",
                    "label": 0
                },
                {
                    "sent": "Just rearrange my setup.",
                    "label": 0
                },
                {
                    "sent": "How's that better?",
                    "label": 0
                },
                {
                    "sent": "OK, great, so today I'm going to talk about some work I've been doing with Bob Williamson.",
                    "label": 0
                },
                {
                    "sent": "Son, as the title says, information divergents and risk for binary classification problems.",
                    "label": 1
                },
                {
                    "sent": "It's quite a theoretical talk, so anyone looking for algorithms and applications you might want to give this one.",
                    "label": 0
                },
                {
                    "sent": "I miss, so that very formal title is kind of my second choice.",
                    "label": 0
                },
                {
                    "sent": "My first choice for a title would be.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Taylor and Jensen's most excellent adventure through statistical learning theory.",
                    "label": 1
                },
                {
                    "sent": "The reason for this title is a lot of the results that I'll be presenting today over the course of the next few hours in one way or another, related to Taylor representations for functions or Jensen's inequality.",
                    "label": 0
                },
                {
                    "sent": "There are sort of two main theorems that will be driving a lot of this work, so.",
                    "label": 0
                },
                {
                    "sent": "That's my preferred title for this talk.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So before I get into the technical material, I'll just give a bit of a philosophical overview of what Bob and I have been working on for the last 18 months, which has been my pay.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Stock here.",
                    "label": 0
                },
                {
                    "sent": "I don't know how many of you are familiar with the old folk story of the blind men and the elephant.",
                    "label": 1
                },
                {
                    "sent": "The story goes that these six blind men are standing around a large elephant, and because I can't see the elephant, they can only describe what they can feel.",
                    "label": 0
                },
                {
                    "sent": "And so the guy on the.",
                    "label": 0
                },
                {
                    "sent": "On the left there is saying, well, I must be standing in front of the branch because that's what I can feel.",
                    "label": 0
                },
                {
                    "sent": "The second guy says I'm standing in front of some kind of pipe 'cause he's touching the Tusk.",
                    "label": 0
                },
                {
                    "sent": "The next time I'm in front of a curtain or a fan 'cause he's holding elephants here.",
                    "label": 0
                },
                {
                    "sent": "The next guy saying must be in front of a tree.",
                    "label": 0
                },
                {
                    "sent": "This because the elephants foot feels like a tree trunk and so on.",
                    "label": 0
                },
                {
                    "sent": "The guys in front of a big wall and the last cases that must be holding piece of rope must be in front of a piece of rope.",
                    "label": 0
                },
                {
                    "sent": "Of course, all of them give different reports about what it is that they're experiencing, because they can't see the full picture Ann.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm going to suggest with this talk that machine learning is the elephant in the room and a lot of work that's done in machine learning, or at least in binary classification in machine learning.",
                    "label": 0
                },
                {
                    "sent": "Is only looking at small parts of the whole elephant at the one time, so.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is great quote by.",
                    "label": 0
                },
                {
                    "sent": "Laplace punk punk Ari says mathematics is the art of giving the same name to different things so.",
                    "label": 0
                },
                {
                    "sent": "What I'm going to try to do in this talk is show you that a lot of the names that are given to different things are actually the same concept.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right, so as I mentioned earlier.",
                    "label": 0
                },
                {
                    "sent": "Here's what you can expect from this talk.",
                    "label": 0
                },
                {
                    "sent": "I'll be giving a whole heap of definitions, mainly in the first hour, and then in the second hour.",
                    "label": 0
                },
                {
                    "sent": "I'll talk about some relationships between these definitions and some representations of some of the main concepts, and there will be a few proofs thrown in for good.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Measure.",
                    "label": 0
                },
                {
                    "sent": "What not to expect?",
                    "label": 0
                },
                {
                    "sent": "Any algorithms, models, data or technicalities?",
                    "label": 0
                },
                {
                    "sent": "So it's.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Very much a theory rather than a.",
                    "label": 0
                },
                {
                    "sent": "Practical talk.",
                    "label": 0
                },
                {
                    "sent": "So just letting you know what you're in for.",
                    "label": 0
                },
                {
                    "sent": "Because we're going to be covering a large number of definitions.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I always find Maps useful, so I'm going to give you a lay of the land of what I see is terror statistika So to begin with, I'm going to talk through a bit of background.",
                    "label": 0
                },
                {
                    "sent": "I'm going to introduce a couple of key concepts from convex analysis.",
                    "label": 0
                },
                {
                    "sent": "I'm going to introduce Taylor's theorem.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Jensen's inequality.",
                    "label": 0
                },
                {
                    "sent": "Then we're going to talk a little bit about binary experiments, an distributions statistical tests the Neyman Pearson lemma, and eventually F divergences are one of the key concepts in.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "My experiments.",
                    "label": 0
                },
                {
                    "sent": "Then I'm going to move onto.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Class probability estimation or classification where will?",
                    "label": 1
                },
                {
                    "sent": "Bump into ideas like lostris regret.",
                    "label": 0
                },
                {
                    "sent": "And notions of information.",
                    "label": 0
                },
                {
                    "sent": "So that will be in the first hour.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Second hour, I'm going to talk about some relationships between all of those previous concepts and some different representations of those concepts that help us see things in a different light.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then at the end I'll talk about how we can apply a lot of these ideas to existing results and come up with a few new results.",
                    "label": 0
                },
                {
                    "sent": "So that's later than any questions so far.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, let's get started.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This first part is going to introduce some background, so how?",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If you are familiar with ideas of convex sets and convex functions, hoping a lot of you yeah.",
                    "label": 0
                },
                {
                    "sent": "OK, good, so I'll I'll rush through this fairly quickly then.",
                    "label": 0
                },
                {
                    "sent": "So a convex set is pretty key concept.",
                    "label": 0
                },
                {
                    "sent": "It's a convex set is some collection of points that's closed under convex combination.",
                    "label": 1
                },
                {
                    "sent": "Anna Convex combination is.",
                    "label": 0
                },
                {
                    "sent": "I like to think of it as an average, so as the definition says there.",
                    "label": 0
                },
                {
                    "sent": "There's a number of white slanders, Lambda, one Lambda N they all have to be non negative and they have to sum to one.",
                    "label": 0
                },
                {
                    "sent": "If you take those weights and you take some set of endpoints within your set S. And you take the average in some sense, what convexity says is that that average also has to be in the set.",
                    "label": 0
                },
                {
                    "sent": "That's sort of what that complicated definition says, but I find the picture a lot more intuitive.",
                    "label": 0
                },
                {
                    "sent": "Basically saying every point in that triangle between those three points.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the set as well, there's a sufficient condition for convexity, which breaks it down to just.",
                    "label": 0
                },
                {
                    "sent": "Saying that.",
                    "label": 0
                },
                {
                    "sent": "All of the points that can be.",
                    "label": 0
                },
                {
                    "sent": "Found between any two points in the set have to also be in the set, so a convex set satisfies that condition for every two points and a non convex set means that sometimes if you linearly interpolate two points you'll fall outside the set.",
                    "label": 0
                },
                {
                    "sent": "I'm.",
                    "label": 0
                },
                {
                    "sent": "No, mostly it'll just be.",
                    "label": 0
                },
                {
                    "sent": "1 dimensional functions.",
                    "label": 0
                },
                {
                    "sent": "Functions of real argument to the real line, yes.",
                    "label": 0
                },
                {
                    "sent": "But of course, you can frame a lot of this stuff more generally.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Not now.",
                    "label": 0
                },
                {
                    "sent": "So like I said before, I like to think of convexity, meaning closed under expectations or averages and that.",
                    "label": 0
                },
                {
                    "sent": "View of convexity is going to be fairly important in the remainder of this material.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So a convex function is just a function whose epigraph is a convex set.",
                    "label": 1
                },
                {
                    "sent": "An epigraph is just all of the points that lie above the function, so we can hear.",
                    "label": 0
                },
                {
                    "sent": "See here.",
                    "label": 1
                },
                {
                    "sent": "The curve line is F. The epigraph is all the points that sit above it, and we say a function is convex if its epigraph is convex, so that's pretty straightforward.",
                    "label": 0
                },
                {
                    "sent": "One nice property of convex functions isn't necessarily continuous.",
                    "label": 0
                },
                {
                    "sent": "If you want a nice little exercise, you can try.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Prove that.",
                    "label": 0
                },
                {
                    "sent": "Right, so now we get to the first main theorem that drives a lot of what's going to go on here, and it's Taylor's theorem, something you probably would have counted in.",
                    "label": 0
                },
                {
                    "sent": "Your first year undergraduate calculus course, probably, or maybe even high school.",
                    "label": 0
                },
                {
                    "sent": "This is a slightly different form to the one you used to the usual Taylor expansion is says that you can express a function as.",
                    "label": 0
                },
                {
                    "sent": "A constant plus a linear term plus a quadratic term plus a cubic term etc etc.",
                    "label": 0
                },
                {
                    "sent": "This integral form of Taylor's expansion says that you can express some function on an interval as.",
                    "label": 1
                },
                {
                    "sent": "Evaluation at point.",
                    "label": 0
                },
                {
                    "sent": "The linear term, which is multiplied by the derivative of that point and then all of the quadratic cubic.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Quartic and etc terms are wrapped up in that integral there so.",
                    "label": 0
                },
                {
                    "sent": "Essentially, what this form of the Taylor expansion does is pull the pulls out the the linear part of the function and then wraps up the.",
                    "label": 0
                },
                {
                    "sent": "Nonlinear part of the function in the integral term there, which is expressed as a linear part times the second derivative of the function integrated over this interval.",
                    "label": 0
                },
                {
                    "sent": "So how many of you have seen this form of tell US expansion before?",
                    "label": 0
                },
                {
                    "sent": "Yeah, as we say it's going to be quite.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We're just going to put it in a slightly more convenient form.",
                    "label": 0
                },
                {
                    "sent": "So in this form, all we've done is where previously the limits of integration were from the point that we're expanding about to the point we're interested in at evaluating.",
                    "label": 0
                },
                {
                    "sent": "At here, we're just going to take the integral over the whole.",
                    "label": 0
                },
                {
                    "sent": "Interval with the functions defined on.",
                    "label": 0
                },
                {
                    "sent": "And change that T -- S term in there.",
                    "label": 0
                },
                {
                    "sent": "Two piecewise linear terms, so this.",
                    "label": 0
                },
                {
                    "sent": "This corollary is not hard to show.",
                    "label": 0
                },
                {
                    "sent": "You just have to substitute in this this term and you'll get the original form of the Taylor expansion back.",
                    "label": 0
                },
                {
                    "sent": "How?",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "I'm pretty much going to ignore this twice differentiable condition.",
                    "label": 0
                },
                {
                    "sent": "In a lot of this talk, because if you interpret these well, first of all, we're going to only look at convex functions and their continuous, so the left and right hand derivatives of all these functions are going to exist, and so we just pick one of them, and for the second derivatives we can kind of interpret them distributionally in some sense because the second derivatives mainly going to appear.",
                    "label": 0
                },
                {
                    "sent": "As a as a inside the integral and so we can sort of, think of it as a measure.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "I'm pretty much going to ignore differentiability from now on.",
                    "label": 0
                },
                {
                    "sent": "Any questions about that?",
                    "label": 0
                },
                {
                    "sent": "So there's two cases, right?",
                    "label": 0
                },
                {
                    "sent": "If T0 is less than T then GT S T -- S, But if it's the other way around, it says minus T, otherwise it's 0.",
                    "label": 1
                },
                {
                    "sent": "So that that flipping of the sign just make sure that the interval goes the right way.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I'm going to use these breakout slides to to emphasize.",
                    "label": 0
                },
                {
                    "sent": "Key points during the talk, so this is our first key point.",
                    "label": 0
                },
                {
                    "sent": "The integral form of Taylor expansion is.",
                    "label": 1
                },
                {
                    "sent": "Is this guy so if you are deciding to take notes, this is 1 to drop down.",
                    "label": 0
                },
                {
                    "sent": "Yep, they're arbitrary.",
                    "label": 0
                },
                {
                    "sent": "So most of the time they will be zero and one some of the other time they'll be 0 Infinity.",
                    "label": 0
                },
                {
                    "sent": "But we're going to.",
                    "label": 0
                },
                {
                    "sent": "We're going to avoid the technicalities of when things converge a little bit just to get the flavor of the results more than anything.",
                    "label": 0
                },
                {
                    "sent": "I should point out I've made a few modifications to the notes that are probably in your lectures, so the.",
                    "label": 0
                },
                {
                    "sent": "Um, if I remember, I'll try and flag where the changes are, but for your own edification, I suggest that when I pop up one of these slides, you maybe jot down a few notes.",
                    "label": 0
                },
                {
                    "sent": "I've tried to structure it a bit better.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "One other point about this is because we're going to do with convex functions.",
                    "label": 0
                },
                {
                    "sent": "One property of convex functions that second derivative is non negative, so that if double dashed function is always going to be.",
                    "label": 0
                },
                {
                    "sent": "Are bigger than equal to 0.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So another another thing you can derive from convex functions is a sort of general notion of distance, which is called a Bregman divergent.",
                    "label": 1
                },
                {
                    "sent": "Bregman Bregman Divergent is formulas up there.",
                    "label": 0
                },
                {
                    "sent": "It's essentially.",
                    "label": 0
                },
                {
                    "sent": "The difference between.",
                    "label": 0
                },
                {
                    "sent": "The curved part of the function and a linear part of this gap.",
                    "label": 0
                },
                {
                    "sent": "There that's shown on the right hand side of the slides.",
                    "label": 0
                },
                {
                    "sent": "And the formula is expressed in it in a fairly general way here.",
                    "label": 0
                },
                {
                    "sent": "But for the functions, we're going to be considering.",
                    "label": 0
                },
                {
                    "sent": "You can think of that as F of T -- 15 or minus the product of T -- T, not an the derivative of F at T. Um?",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A nice connection between Bregman divergences and F divergences is that the.",
                    "label": 0
                },
                {
                    "sent": "The Bregman divergences kind of the tail of the Taylor expansion of F. So if you rearrange if you took the Taylor expansion of F as I showed you before, and you rearranged it, you'd find that be of F is the integral part of that function.",
                    "label": 0
                },
                {
                    "sent": "To see some more connections would go on.",
                    "label": 0
                },
                {
                    "sent": "So like I said, it's going to be a lot of definitions up front, but I'll try and pull it all together as I go.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the other the other really important thing in this talk is Jensen's inequality, who's seen Jensen's inequality before?",
                    "label": 0
                },
                {
                    "sent": "Yeah, so this is this.",
                    "label": 0
                },
                {
                    "sent": "Is this inequality.",
                    "label": 0
                },
                {
                    "sent": "Inequality basically says the relationship between expectation and convex functions is and what we're looking at is material.",
                    "label": 0
                },
                {
                    "sent": "I found out that.",
                    "label": 0
                },
                {
                    "sent": "Convexity is quite central too.",
                    "label": 0
                },
                {
                    "sent": "Probability theory, so this inequality kind of captures a lot of what's going on.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to talk about thing called, which I've called the Jensen Gap.",
                    "label": 1
                },
                {
                    "sent": "Maybe others have called it the same thing, but essentially.",
                    "label": 0
                },
                {
                    "sent": "If you have a convex function that's just Maps reels to reels, the Jensen Gap is the difference between.",
                    "label": 0
                },
                {
                    "sent": "The expected value of the function as you vary its argument minus the function of valued at the evaluated at the mean of all of your arguments.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Jensen's inequality says that this Jensen Gap quantity is non negative if and only if F is convex.",
                    "label": 0
                },
                {
                    "sent": "So it's quite a strong characterization of what's going on between expectation.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Convexity and I like to think of it in terms of this diagram here, so.",
                    "label": 0
                },
                {
                    "sent": "If we've got four points along the bottom, there X one X4, you can imagine them being mapped up to F of X1 through the F of X4.",
                    "label": 0
                },
                {
                    "sent": "Any average you take is going to lie somewhere in that quadrilateral in the function and Jensen's inequality just says that that points gotta lie above the corresponding point on the function.",
                    "label": 0
                },
                {
                    "sent": "For that's all that Jennifer Quality says.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As I said at the beginning, it's quite central to what we're looking at.",
                    "label": 0
                },
                {
                    "sent": "So when I put it on one of these slides, so this gap here is non negative if and only if F is convex.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The final.",
                    "label": 0
                },
                {
                    "sent": "The final property of convex functions we're going to make use of a little bit is something that's called the Lasiandra Fenchel transform.",
                    "label": 0
                },
                {
                    "sent": "Sure, many of you are familiar with this as well.",
                    "label": 0
                },
                {
                    "sent": "Yeah, show of hands who's seen this before?",
                    "label": 0
                },
                {
                    "sent": "He would have no OK.",
                    "label": 0
                },
                {
                    "sent": "So this is another.",
                    "label": 0
                },
                {
                    "sent": "This is a transformation that you can do to convex functions which.",
                    "label": 0
                },
                {
                    "sent": "It's kind of like a generalized derivative in some sense for functions that may not be differentiable at some points.",
                    "label": 0
                },
                {
                    "sent": "So the diagram sort of shows how you would calculate F star of T style, which is the.",
                    "label": 0
                },
                {
                    "sent": "LF transform of the function F. So what it's saying is that if you give me some slope T star, I'm going to do this look through an origin and I want to maximize the difference between that line with slope T star and the convex function F. And in the diagram here you can see that.",
                    "label": 0
                },
                {
                    "sent": "That value is maximized at the point shown at T. The details of.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Where this is used is not so important.",
                    "label": 0
                },
                {
                    "sent": "That's what's really important for our purposes is for convex functions.",
                    "label": 0
                },
                {
                    "sent": "If you take this transformation again and your original function is convex, you end up with the same function.",
                    "label": 0
                },
                {
                    "sent": "That is, we say that the LF transform is an involution on the set of convex functions.",
                    "label": 1
                },
                {
                    "sent": "So that means if I take F doublestar I get F back as we'll see a bit later.",
                    "label": 0
                },
                {
                    "sent": "This gives us another way to look at some key concepts in.",
                    "label": 0
                },
                {
                    "sent": "Binary classification.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So summarize this background section.",
                    "label": 0
                },
                {
                    "sent": "What we've ended up with is Fire Taylor's theorem in via the Fenchel dual.",
                    "label": 1
                },
                {
                    "sent": "We've now got two ways we can sort of pull apart convex functions.",
                    "label": 0
                },
                {
                    "sent": "With Taylor's theorem, we can pull a convex function into a linear part and this.",
                    "label": 0
                },
                {
                    "sent": "Integral of piecewise linear terms with respect to some.",
                    "label": 0
                },
                {
                    "sent": "Wait function.",
                    "label": 0
                },
                {
                    "sent": "If you like F double dash an with the variational representation.",
                    "label": 0
                },
                {
                    "sent": "We can use this.",
                    "label": 0
                },
                {
                    "sent": "Involuted property of the LF jewel to pull apart a convex function into.",
                    "label": 0
                },
                {
                    "sent": "This supremum operator so there any questions so far?",
                    "label": 0
                },
                {
                    "sent": "Well, that's just a product.",
                    "label": 0
                },
                {
                    "sent": "But because we are dealing with the reels of replaced the inner product angle brackets with just the modification.",
                    "label": 0
                },
                {
                    "sent": "What's that?",
                    "label": 0
                },
                {
                    "sent": "Sorry yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that's true.",
                    "label": 0
                },
                {
                    "sent": "So that's some most of the background out of the way.",
                    "label": 0
                },
                {
                    "sent": "I'll come back to come back to some of these definitions when they're required later in the talk.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So back to our map.",
                    "label": 0
                },
                {
                    "sent": "We've we've covered the background material now.",
                    "label": 0
                },
                {
                    "sent": "We've talked about convexity, Tails theorem in Jensen's inequality, so.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Move on to talking about binary experiments.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "A binary experiment is.",
                    "label": 0
                },
                {
                    "sent": "The term comes from sort of old statistics literature, but essentially it's a pair of distributions P and Q / a common space which we'll call X.",
                    "label": 1
                },
                {
                    "sent": "When we're dealing with the discrete space, you can kind of picture in your minds the discrete.",
                    "label": 0
                },
                {
                    "sent": "Distributions P&Q is shown in that figure there, so we've got P assigns probability.",
                    "label": 0
                },
                {
                    "sent": ".3 Point 5.2 to a B&C&Q assigns a different set of probabilities when we're dealing with continuous spaces.",
                    "label": 0
                },
                {
                    "sent": "We just picture the two distributions as their density functions, that's.",
                    "label": 1
                },
                {
                    "sent": "The mess intuitive way to get a handle on what's going on here and will often talk of P being the positive distribution and cubing the negative distribution.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "In binary experiments, usually what happens is you get a bunch of samples from one or the other of these distributions, and you want to say which one it came from.",
                    "label": 1
                },
                {
                    "sent": "Sorry, what was that?",
                    "label": 1
                },
                {
                    "sent": "What is a negative distribution?",
                    "label": 0
                },
                {
                    "sent": "It's just a label.",
                    "label": 0
                },
                {
                    "sent": "We're giving to queue, so we're saying that.",
                    "label": 1
                },
                {
                    "sent": "To to make a link between binary experiments and binary classifications.",
                    "label": 0
                },
                {
                    "sent": "It's it's good to think about P as being the distribution over positive instances and Q being the distribution over negative instances.",
                    "label": 0
                },
                {
                    "sent": "OK, so in hypothesis testing you get some samples you don't know which distribution that's from, but you want to pick whether it was P or Q.",
                    "label": 1
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is called hypothesis testing and in some sense the further apart these two distributions are in your space, the easier this decision will be.",
                    "label": 1
                },
                {
                    "sent": "So if I see a whole bunch of points coming from the left here, and I know my distributions over here or here, I can be pretty certain that came from the one on the left.",
                    "label": 0
                },
                {
                    "sent": "But if the distributions overlap a lot is going to be a lot harder to make that decision.",
                    "label": 0
                },
                {
                    "sent": "So what we require is some notion of distance between distributions and.",
                    "label": 0
                },
                {
                    "sent": "BF divergent switch.",
                    "label": 1
                },
                {
                    "sent": "I'll introduce in a bit is a big family of.",
                    "label": 1
                },
                {
                    "sent": "Distances for distributions that will examine in some detail.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But to get there I have to talk first about test statistics.",
                    "label": 0
                },
                {
                    "sent": "'cause I'm going to do all of this non pair.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Metrically, I'm not going to use models or I'm not going to assume.",
                    "label": 0
                },
                {
                    "sent": "Um, whole bunch of parameter vectors and things like that.",
                    "label": 0
                },
                {
                    "sent": "So we're going to deal with things non parametrically and so in general.",
                    "label": 0
                },
                {
                    "sent": "We're going to need to formulate our tests in terms of a mapping from the original SpaceX to the real line, so we map all our points of the real line and then we calculate something with the mapped values.",
                    "label": 0
                },
                {
                    "sent": "So this is called a test statistic.",
                    "label": 0
                },
                {
                    "sent": "Its function from the space that we're interested in to the real line.",
                    "label": 0
                },
                {
                    "sent": "I mean, it's usually some function is usually depends on the distributions you're interesting interested in as.",
                    "label": 1
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Healthy.",
                    "label": 0
                },
                {
                    "sent": "A statistical test is we take a test statistic an you just threshold it somewhere.",
                    "label": 1
                },
                {
                    "sent": "So here I've introduced a threshold T not on the real line and all the points to the left of T not going to get.",
                    "label": 1
                },
                {
                    "sent": "Assigned to the positive class and all of the other way around.",
                    "label": 0
                },
                {
                    "sent": "All of the points bigger than order in the positive class.",
                    "label": 0
                },
                {
                    "sent": "All the points less than a negative class.",
                    "label": 1
                },
                {
                    "sent": "So each threshold partitions the entire space into 2.",
                    "label": 1
                },
                {
                    "sent": "So that's you got a statistical test which is an arbitrary mapping.",
                    "label": 0
                },
                {
                    "sent": "Whenever your threshold it, you get.",
                    "label": 0
                },
                {
                    "sent": "Sorry, test statistic is an arbitrary mapping down to the reels and then when you threshold it you get a test statistic statistic.",
                    "label": 0
                },
                {
                    "sent": "Any questions?",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You might have seen these before.",
                    "label": 0
                },
                {
                    "sent": "He's seen contingency tables, true positives, false positives, those sort of things, right?",
                    "label": 1
                },
                {
                    "sent": "So this will be pretty familiar.",
                    "label": 0
                },
                {
                    "sent": "So whenever you have a statistical.",
                    "label": 0
                },
                {
                    "sent": "Test.",
                    "label": 0
                },
                {
                    "sent": "I town a town North you can.",
                    "label": 1
                },
                {
                    "sent": "Put in this contingency table how well it does.",
                    "label": 0
                },
                {
                    "sent": "Essentially this contingency tables a summary of.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "The quality of the test statistic so.",
                    "label": 0
                },
                {
                    "sent": "If we look at all the points again.",
                    "label": 0
                },
                {
                    "sent": "That are bigger than the threshold.",
                    "label": 1
                },
                {
                    "sent": "When the map down by Tao, if we measure them against P, that's sort of the true positive rate.",
                    "label": 0
                },
                {
                    "sent": "It's also known as the power in the statistical literature literature.",
                    "label": 0
                },
                {
                    "sent": "The false positive rate is when all of those mappings, all those points that got mapped above the threshold.",
                    "label": 0
                },
                {
                    "sent": "When they actually negative instances, we get a false positive rate and similarly true negative and false negative rates are as described up there.",
                    "label": 1
                },
                {
                    "sent": "So this is a round about way to getting to the main point, which is this quite classical result from the statistical literature called the name in.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Pearson lemma, who's heard of this?",
                    "label": 0
                },
                {
                    "sent": "Alright, finally got something new.",
                    "label": 0
                },
                {
                    "sent": "OK so the the Neyman Pearson lemma.",
                    "label": 0
                },
                {
                    "sent": "Is fairly strong statement about what makes for a good statistical test.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "It is expressed in terms of this likelihood ratio, so the likelihood ratio.",
                    "label": 1
                },
                {
                    "sent": "Is just the ratio of the probabilities.",
                    "label": 0
                },
                {
                    "sent": "Single point, so if I've got my two distributions P&Q then DP and DQ or the densities the two densities of P&Q and the likelihood ratio Telstar is just the ratio of the densities at each point, so it's a function, and for each X it gives me the ratio of the two densities, right?",
                    "label": 0
                },
                {
                    "sent": "So for a discrete distribution it will just be P of X / Q of X, but in the continuous case it's the radon nikodym derivative want robot, the technicalities?",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the name in Pearson lemma says that this likelihood ratio is in some sense the best.",
                    "label": 0
                },
                {
                    "sent": "Test statistic you can use for binary experiment.",
                    "label": 0
                },
                {
                    "sent": "It says that it's uniformly most powerful.",
                    "label": 1
                },
                {
                    "sent": "That is, for any false positive rate you wish to choose.",
                    "label": 0
                },
                {
                    "sent": "The likelihood ratio will give you the best true positive rate.",
                    "label": 1
                },
                {
                    "sent": "So the way to think about this is I have my likelihood ratio that Maps me from my SpaceX to the real line.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "As I move my threshold, I'm going to change the false positive rate of this.",
                    "label": 0
                },
                {
                    "sent": "Test statistic each time I thresholding to false positive rate what this lemma says is that the.",
                    "label": 0
                },
                {
                    "sent": "For any other tests that you can think of with the same false positive rate, this will have the likelihood ratio.",
                    "label": 1
                },
                {
                    "sent": "That is, will have the best true positive rate.",
                    "label": 0
                },
                {
                    "sent": "So I'll come back to this diagram a bit later in the talk.",
                    "label": 0
                },
                {
                    "sent": "This is an RC curve.",
                    "label": 0
                },
                {
                    "sent": "People have seen these before, so you can kind of think of each test statistic as giving you a curve on an RC diagram and what the name in Pearson lemma says is the likelihood ratio is going to dominate every other.",
                    "label": 0
                },
                {
                    "sent": "Curve that you care to put on this some diagram.",
                    "label": 0
                },
                {
                    "sent": "Any questions about that?",
                    "label": 0
                },
                {
                    "sent": "Well, like I said, how do you compute it with the question?",
                    "label": 0
                },
                {
                    "sent": "In when you have a discrete distribution, it's quite simple.",
                    "label": 0
                },
                {
                    "sent": "If I discrete distribution.",
                    "label": 0
                },
                {
                    "sent": "I can compute the probability of P at each individual X, and I can compute the probability of Q at each individual point X, and then this likelihood ratio is just going to be.",
                    "label": 0
                },
                {
                    "sent": "P of X divided by cube X.",
                    "label": 0
                },
                {
                    "sent": "He computer quite directly.",
                    "label": 0
                },
                {
                    "sent": "In the case of continuous variables.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "You probably have to model the distributions stuff, but I'm not going to go into that.",
                    "label": 0
                },
                {
                    "sent": "Conceptually.",
                    "label": 0
                },
                {
                    "sent": "It's the same idea though.",
                    "label": 0
                },
                {
                    "sent": "Right, so why have I gone this roundabout route through statistical tests well?",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We wanted some way of measuring.",
                    "label": 0
                },
                {
                    "sent": "The distance between two distributions we have our distributions P&Q and we wanted some notion of distance or divergences between them and.",
                    "label": 0
                },
                {
                    "sent": "This class of divergences about to describe called the F Divergences.",
                    "label": 0
                },
                {
                    "sent": "Are built upon the likelihood ratio in some sense and.",
                    "label": 0
                },
                {
                    "sent": "Took me a long while to realize this, but.",
                    "label": 0
                },
                {
                    "sent": "When I started looking at these F divergences, I was just given the formula.",
                    "label": 0
                },
                {
                    "sent": "You can see there in terms of the integral.",
                    "label": 0
                },
                {
                    "sent": "It's the integral over all X of F. Or evaluated the likelihood ratio with an average taken with respect to Q.",
                    "label": 0
                },
                {
                    "sent": "Look quite.",
                    "label": 0
                },
                {
                    "sent": "And obvious to me.",
                    "label": 0
                },
                {
                    "sent": "So after thinking about it for awhile, I realized that the reason it's formulated this way is the likelihood ratio in the middle there.",
                    "label": 0
                },
                {
                    "sent": "Is the best mapping in some sense from our space to the real line for the pair of distributions P&Q in that it separates the points the most?",
                    "label": 0
                },
                {
                    "sent": "Ann, this F function kind of acts as a penalty, so further away that D PDQ is from one.",
                    "label": 0
                },
                {
                    "sent": "The F function gives you a penalty away from one, and so this F divergent here is kind of the average penalty you'll incur.",
                    "label": 0
                },
                {
                    "sent": "4.",
                    "label": 0
                },
                {
                    "sent": "Differing densities P&Q.",
                    "label": 0
                },
                {
                    "sent": "Does that make sense?",
                    "label": 0
                },
                {
                    "sent": "So every time that DP is not equal to DQ, we're going to incur some penalty.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So we can state this F divergent fairly generally, but to be a divergent we want it to be non negative and we want it to be.",
                    "label": 0
                },
                {
                    "sent": "We want it to assign zero divergent if I'm.",
                    "label": 0
                },
                {
                    "sent": "Comparing a distribution to itself.",
                    "label": 0
                },
                {
                    "sent": "So on the right here, the condition we need is that.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "The Q average of F of the likelihood ratio has to be.",
                    "label": 0
                },
                {
                    "sent": "Big.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then well, from Jensen's inequality, we know that the following is the case if we start with the general definition of F. Vergence then.",
                    "label": 0
                },
                {
                    "sent": "We can say that it's bigger than equal to F, evaluated the mean, but of course the queue mean of the PDQ is just one, so.",
                    "label": 0
                },
                {
                    "sent": "For all F. That is.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Convex we can get.",
                    "label": 0
                },
                {
                    "sent": "BF divergences?",
                    "label": 0
                },
                {
                    "sent": "PQ is bigger than F of 1.",
                    "label": 0
                },
                {
                    "sent": "So if we want I have to be a divergent that is non negative and.",
                    "label": 0
                },
                {
                    "sent": "Has some value zero when we're matching the same thing against itself.",
                    "label": 0
                },
                {
                    "sent": "Then we need F to be convex and F1 to be 0.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "This.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is the.",
                    "label": 0
                },
                {
                    "sent": "One another takehome slide.",
                    "label": 0
                },
                {
                    "sent": "Here the class of divergences for two distributions.",
                    "label": 0
                },
                {
                    "sent": "F divergences are the kind of think of it as a Jensen gap.",
                    "label": 0
                },
                {
                    "sent": "For the function F. Applied to the likelihood ratio.",
                    "label": 0
                },
                {
                    "sent": "And you've got this extra constraint, which is kind of a technicality, and that F of one is zero and all that saying is that you're not assigning any penalty.",
                    "label": 0
                },
                {
                    "sent": "To the likelihood ratio, when the likelihood ratio is 1.",
                    "label": 0
                },
                {
                    "sent": "That makes sense.",
                    "label": 0
                },
                {
                    "sent": "Who's seen if divergences before?",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So some examples will probably help.",
                    "label": 0
                },
                {
                    "sent": "Maybe you've seen some of these before.",
                    "label": 0
                },
                {
                    "sent": "So different choices of the function F will give us.",
                    "label": 0
                },
                {
                    "sent": "Different types of divergent measures.",
                    "label": 0
                },
                {
                    "sent": "So if we choose F of T to be the absolute value of T -- 1 at the top there.",
                    "label": 0
                },
                {
                    "sent": "Plot of the function on the right hand side so you can sort of see what this is doing.",
                    "label": 0
                },
                {
                    "sent": "You get what's called the variational divergent, which is a fairly.",
                    "label": 0
                },
                {
                    "sent": "Central divergents in hypothesis testing.",
                    "label": 0
                },
                {
                    "sent": "You notice that on all of these examples, it's a bit hard to see 'cause the scales too small, but on all of these examples, the functions are zero at F of 1, which is required by the definition, and maybe it's a bit clearer here.",
                    "label": 0
                },
                {
                    "sent": "Went up when I was talking about penalties being assigned to deviations away from one.",
                    "label": 0
                },
                {
                    "sent": "You can kind of see that all of these functions are minimized at F of 1 and then apply larger and larger penalties as you move away from 1.",
                    "label": 0
                },
                {
                    "sent": "So for different choices of this penalty function F you get different measures of divergent when you take.",
                    "label": 0
                },
                {
                    "sent": "The average of these?",
                    "label": 0
                },
                {
                    "sent": "Against.",
                    "label": 0
                },
                {
                    "sent": "Yep, that's right.",
                    "label": 0
                },
                {
                    "sent": "Doesn't it tend towards 0?",
                    "label": 0
                },
                {
                    "sent": "No, I don't.",
                    "label": 0
                },
                {
                    "sent": "I don't think so because T will.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "T goes to 0.",
                    "label": 0
                },
                {
                    "sent": "I guess to go to 0 faster than log T1.",
                    "label": 0
                },
                {
                    "sent": "That's surprising because it's clear that F of one in that case is 0.",
                    "label": 0
                },
                {
                    "sent": "But the derivative is going to be.",
                    "label": 0
                },
                {
                    "sent": "1.",
                    "label": 0
                },
                {
                    "sent": "Derivative is going to be 1 plus LNT, right?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "As T goes to zero, it should go to negative Infinity, shouldn't.",
                    "label": 0
                },
                {
                    "sent": "The derivative which is.",
                    "label": 0
                },
                {
                    "sent": "Which is correct?",
                    "label": 0
                },
                {
                    "sent": "So the derivative if you think that will prove is doing it going upwards or at the end.",
                    "label": 0
                },
                {
                    "sent": "I don't think so, but we can check that during the break.",
                    "label": 0
                },
                {
                    "sent": "OK. Maybe there's a mistake in my slide.",
                    "label": 0
                },
                {
                    "sent": "So maybe if you come across some of you, probably would have come across the KL divergent in the past.",
                    "label": 0
                },
                {
                    "sent": "Some of the other ones are a bit more obscure, but the point of this slide is that.",
                    "label": 0
                },
                {
                    "sent": "There is a very large number of existing divergences for hypothesis testing that are subsumed by the class of F Divergent.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we'll just work through a quick example, so here's our discrete distribution again, over the points AB&C.",
                    "label": 0
                },
                {
                    "sent": "Distributions P and blue and Q in red.",
                    "label": 0
                },
                {
                    "sent": "And to compute this is the question I think demo had before.",
                    "label": 0
                },
                {
                    "sent": "How do you compute the likelihood ratio?",
                    "label": 0
                },
                {
                    "sent": "Well, you just plug the numbers into the formula.",
                    "label": 0
                },
                {
                    "sent": "So the variational vergence is just the sum over the points AB&C of the ratio of the two probabilities.",
                    "label": 0
                },
                {
                    "sent": "And then you apply the function to it.",
                    "label": 0
                },
                {
                    "sent": "So in this case for variational versions, F of T was the absolute value of T -- 1.",
                    "label": 0
                },
                {
                    "sent": "We plug it in and we find that.",
                    "label": 0
                },
                {
                    "sent": "These two distributions, P&Q separated by one according to variational.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Free.",
                    "label": 0
                },
                {
                    "sent": "OK, so for discrete distributions you don't really talk about densities that much the densities.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so I used to PDQ 'cause it's kind of more general.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "For sure.",
                    "label": 0
                },
                {
                    "sent": "The ratio of the densities.",
                    "label": 0
                },
                {
                    "sent": "The PDQ yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah, with respect to some reference measure on the.",
                    "label": 0
                },
                {
                    "sent": "On the space that you're interested in, turns out it doesn't really matter what reference measure you take, but you can just drive.",
                    "label": 0
                },
                {
                    "sent": "You can just take the.",
                    "label": 0
                },
                {
                    "sent": "Question of the two derivatives of the functions.",
                    "label": 0
                },
                {
                    "sent": "Right, so if we choose a different, FF is equal to 20, we can plug it in.",
                    "label": 0
                },
                {
                    "sent": "We can plug in P&Q for these two distributions as well.",
                    "label": 0
                },
                {
                    "sent": "And KL Divergent gives a different.",
                    "label": 0
                },
                {
                    "sent": "Measure of the distance between these two functions.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in some sense, there's.",
                    "label": 0
                },
                {
                    "sent": "You can imagine the space of all possible distributions.",
                    "label": 0
                },
                {
                    "sent": "Come over a B&C.",
                    "label": 0
                },
                {
                    "sent": "You can visualize it as points in this convex combination of AB&C and.",
                    "label": 0
                },
                {
                    "sent": "What each of the F divisions is doing is kind of measuring that distance between P&Q in this space of distributions.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so that's binary experience, you know.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hopefully.",
                    "label": 0
                },
                {
                    "sent": "We will be moving on to something.",
                    "label": 0
                },
                {
                    "sent": "A bit more familiar to some of you have studied a bit.",
                    "label": 0
                },
                {
                    "sent": "Have studied machine learning in the past.",
                    "label": 0
                },
                {
                    "sent": "I found I was quite surprised actually.",
                    "label": 0
                },
                {
                    "sent": "How much of the statistics literature is kind of unknown even by me when I first?",
                    "label": 0
                },
                {
                    "sent": "Started looking into this stuff.",
                    "label": 0
                },
                {
                    "sent": "What I hope to show in this talk is that.",
                    "label": 0
                },
                {
                    "sent": "A lot of the there's a lot of commonality between concepts you see in.",
                    "label": 0
                },
                {
                    "sent": "Binary classification and concepts you see in hypothesis testing, so we've just been overall hypothesis testing stuff and now will look at.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Binary classification, which hopefully you'll be a bit more familiar with.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to recap.",
                    "label": 0
                },
                {
                    "sent": "So in hypothesis testing we get a bunch of instances from one of two classes, and our aim is to try and decide where the instances came from.",
                    "label": 0
                },
                {
                    "sent": "An as I said before.",
                    "label": 0
                },
                {
                    "sent": "If we can get some measure of distance between the two distributions, the larger that distance, the easier it is to decide whether the samples came from P or Q.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The point here is that.",
                    "label": 0
                },
                {
                    "sent": "We want to make one decision.",
                    "label": 0
                },
                {
                    "sent": "For a set of points, did they come from POQ an we use a measure of divergents to try and make that?",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Decision.",
                    "label": 0
                },
                {
                    "sent": "So in classification and probability estimation, we still have two distributions, but now we assume that we have a mixture of the two distributions.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "This mixture.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Means that.",
                    "label": 0
                },
                {
                    "sent": "You can sample a point and there's a chance that came from P and there's a chance that came from Q an that chances alright using \u03c0.",
                    "label": 0
                },
                {
                    "sent": "So Pi is the probability that a single point was grown from P as opposed to Q.",
                    "label": 0
                },
                {
                    "sent": "And in classification, you're more interested in making this decision as to whether a point came from P or Q for each point, rather than for the entire set of points.",
                    "label": 1
                },
                {
                    "sent": "And we measure how well or how badly we're doing with respect to some loss function or penalty.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There's sort of two views going on here in.",
                    "label": 0
                },
                {
                    "sent": "Um, I like to talk about them as being generative and discriminative of borrow these terms from some other researchers in the field.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "In the generative view on the right here.",
                    "label": 0
                },
                {
                    "sent": "We had, we just had two distributions in the densities DP&Q.",
                    "label": 0
                },
                {
                    "sent": "And now we kind of scaling them.",
                    "label": 0
                },
                {
                    "sent": "We pick a single value Pi an we scale PBY pie and Q by 1 -- \u03c0 and we get these two distributions.",
                    "label": 0
                },
                {
                    "sent": "Which we mix and get this mixture.",
                    "label": 0
                },
                {
                    "sent": "Measure M so on the on the left.",
                    "label": 0
                },
                {
                    "sent": "Here the green.",
                    "label": 0
                },
                {
                    "sent": "Um, grain distribution is the mixture of P&Q.",
                    "label": 0
                },
                {
                    "sent": "And instead of deciding.",
                    "label": 0
                },
                {
                    "sent": "Whether a whole sample is from Peel from Q, we want to do is we want to kind of estimate this function Eater, which is the conditional class probability.",
                    "label": 0
                },
                {
                    "sent": "So for each point X which runs along the bottom axis, we want to estimate.",
                    "label": 0
                },
                {
                    "sent": "The probability that it came from.",
                    "label": 0
                },
                {
                    "sent": "From the class P. So you can see for these examples on the right here P&Q.",
                    "label": 0
                },
                {
                    "sent": "As we move from left to right, the probability came from P starts off very close to one and then it drops off in the middle through a half and then goes to zero as we.",
                    "label": 0
                },
                {
                    "sent": "Head to the right so these are sort of two views of the same setup.",
                    "label": 0
                },
                {
                    "sent": "If you like.",
                    "label": 0
                },
                {
                    "sent": "How do you work?",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How do you compute it?",
                    "label": 0
                },
                {
                    "sent": "Oh, it turns out, it's the.",
                    "label": 0
                },
                {
                    "sent": "It's the density of P with respect to M times pilots.",
                    "label": 0
                },
                {
                    "sent": "There the formula just under empire so.",
                    "label": 0
                },
                {
                    "sent": "If you started with just the joint distribution, it's the probability of wire conditioned on X.",
                    "label": 0
                },
                {
                    "sent": "If you like.",
                    "label": 0
                },
                {
                    "sent": "That makes more sense.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to refer to that as the conditional class probability or the pointwise class probability.",
                    "label": 0
                },
                {
                    "sent": "So you can.",
                    "label": 0
                },
                {
                    "sent": "Given pipian Q, you can compute ether and M using the formulas on the left there and vice versa given either and MI can compute \u03c0.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "P&Q using those formulas and essentially you can move between the two using Bayes rule.",
                    "label": 0
                },
                {
                    "sent": "There's nothing really to it at all, it's just.",
                    "label": 0
                },
                {
                    "sent": "You decompose the joint probability conditionally on X or conditionally on why, and you get the two different views, the generative and discriminative, Yep.",
                    "label": 1
                },
                {
                    "sent": "This.",
                    "label": 0
                },
                {
                    "sent": "So Pi is the.",
                    "label": 0
                },
                {
                    "sent": "Probability.",
                    "label": 1
                },
                {
                    "sent": "That your point was drawn from the distribution P. So if you want to interpret it in terms of a joint distribution, it's the marginal distribution over your class labels.",
                    "label": 0
                },
                {
                    "sent": "It's the in fact it's the probability that your class label is positive.",
                    "label": 0
                },
                {
                    "sent": "Everyone follow that so far.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So usually the way I think about it is that nature has kind of already picked pipian Q for you.",
                    "label": 0
                },
                {
                    "sent": "You may or may not know it.",
                    "label": 0
                },
                {
                    "sent": "Usually you try to estimate it from your data.",
                    "label": 0
                },
                {
                    "sent": "Really going to talk about estimation.",
                    "label": 0
                },
                {
                    "sent": "Data, if I can avoid it.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for now, but now we switched so.",
                    "label": 0
                },
                {
                    "sent": "From here on in I'll talk either about either and M as being.",
                    "label": 0
                },
                {
                    "sent": "Sort of all the information about a problem or pipian cubing all the information about a problem.",
                    "label": 0
                },
                {
                    "sent": "So now we can introduce something that helps fairly familiar people would have.",
                    "label": 0
                },
                {
                    "sent": "But with different measures of loss before.",
                    "label": 0
                },
                {
                    "sent": "So when you have a machine learning problem.",
                    "label": 0
                },
                {
                    "sent": "Very simple way of.",
                    "label": 0
                },
                {
                    "sent": "Determining how you're going is you just count how many mistakes you make when you create a classifier.",
                    "label": 0
                },
                {
                    "sent": "So I get a bunch of training instances with positive and negative examples.",
                    "label": 0
                },
                {
                    "sent": "I train it up and then when I test it on some test data, if I get a label wrong, I incur a penalty of 1.",
                    "label": 0
                },
                {
                    "sent": "If I get right, I get a penalty of zero.",
                    "label": 0
                },
                {
                    "sent": "That's a loss function, so in general a loss function.",
                    "label": 0
                },
                {
                    "sent": "Is just a penalty for guessing some value.",
                    "label": 1
                },
                {
                    "sent": "Eat a hat when the true classes Y where Y is the positive or negative 01 however you like.",
                    "label": 0
                },
                {
                    "sent": "So when.",
                    "label": 0
                },
                {
                    "sent": "So when Eater is discrete I when we just predicting 01 positive or negative, then we're essentially doing a classification problem, But when Eater is.",
                    "label": 0
                },
                {
                    "sent": "Ranging between zero and one, we can think of the loss as being for probability estimation problem so.",
                    "label": 0
                },
                {
                    "sent": "We're mainly going to focus on the latter probability estimation because the classification is like a special case.",
                    "label": 0
                },
                {
                    "sent": "It's when you're making extreme probability predictions, if you like.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Either here is your estimate of the probability that a point is in the positive class.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Once we have a loss function, we can talk about the pointwise risk for a loss.",
                    "label": 0
                },
                {
                    "sent": "This is a function that.",
                    "label": 0
                },
                {
                    "sent": "Takes in a true value for.",
                    "label": 0
                },
                {
                    "sent": "The class probability takes in your estimate and then return sum score which is.",
                    "label": 0
                },
                {
                    "sent": "The expected loss.",
                    "label": 0
                },
                {
                    "sent": "So here capital L of Ada Ada hat is just the expectation.",
                    "label": 0
                },
                {
                    "sent": "Overdrawing your class labels from a binomial distribution with probability eater and the expectation is over your loss function.",
                    "label": 0
                },
                {
                    "sent": "And so you can actually just write that out explicitly.",
                    "label": 0
                },
                {
                    "sent": "It's the 1 -- E to times the.",
                    "label": 0
                },
                {
                    "sent": "The loss at zero of eight at plus eight times the loss at one of eat at.",
                    "label": 0
                },
                {
                    "sent": "That sort of makes sense.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yep, and then of course you can take the average over all.",
                    "label": 0
                },
                {
                    "sent": "Your ex is now.",
                    "label": 0
                },
                {
                    "sent": "So once I have capital, Li can for each point I can workout the conditional risk.",
                    "label": 0
                },
                {
                    "sent": "An I can average it all up over that distribution M, which is over all of my points and I can get the full risk or the average pointwise risk.",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then another important quantity that we have is the Bayes risk.",
                    "label": 0
                },
                {
                    "sent": "Which is the best you can possibly do.",
                    "label": 0
                },
                {
                    "sent": "For a given loss function at a given problem, so the Bayes risk here is this is the pointwise Bayes risk.",
                    "label": 0
                },
                {
                    "sent": "I guess the first line capital L under buyer.",
                    "label": 0
                },
                {
                    "sent": "Is the.",
                    "label": 0
                },
                {
                    "sent": "Smallest pointwise risk you can get as you.",
                    "label": 0
                },
                {
                    "sent": "Over all possible guesses, you can make, so that's the infima over all possible guesses eater.",
                    "label": 0
                },
                {
                    "sent": "For the pointwise risk and the full Bayes risk is just expectations taken over me.",
                    "label": 1
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And regret which is the last of these main quantities.",
                    "label": 1
                },
                {
                    "sent": "I'm going to introduce is the difference between.",
                    "label": 0
                },
                {
                    "sent": "The loss that you're.",
                    "label": 0
                },
                {
                    "sent": "Estimate obtains, and the best you can possibly do so down the bottom.",
                    "label": 0
                },
                {
                    "sent": "Here regret is just the difference between.",
                    "label": 0
                },
                {
                    "sent": "The first case, that's the difference between the pointwise risk and the best pointwise risk in the second case, that's the difference between the best.",
                    "label": 1
                },
                {
                    "sent": "Your risk, and the best possible risk.",
                    "label": 0
                },
                {
                    "sent": "Alright, so that's a lot of definitions.",
                    "label": 0
                },
                {
                    "sent": "Any questions about those who've seen one or more of these before?",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "OK, so maybe some examples again will.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Clear things up.",
                    "label": 0
                },
                {
                    "sent": "Time.",
                    "label": 0
                },
                {
                    "sent": "OK, so you've probably all seen 01 misclassification loss, just not written in this way before.",
                    "label": 1
                },
                {
                    "sent": "This is a function as I said, if you're.",
                    "label": 0
                },
                {
                    "sent": "If you estimate one, either either hat is bigger than .5, but the true class is 0.",
                    "label": 0
                },
                {
                    "sent": "Then you're going to incur a penalty for one.",
                    "label": 0
                },
                {
                    "sent": "This double bracket notation is a bit of a shorthand.",
                    "label": 0
                },
                {
                    "sent": "I use so double brackets of some predicate P is 1 if P is true and zero FP is false.",
                    "label": 0
                },
                {
                    "sent": "So that's a shorthand way of writing that loss function.",
                    "label": 0
                },
                {
                    "sent": "The dotted line is the.",
                    "label": 0
                },
                {
                    "sent": "Loss when the true value is 1 and the solid line is the.",
                    "label": 0
                },
                {
                    "sent": "Function When the true value is 0.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Log loss is another.",
                    "label": 0
                },
                {
                    "sent": "Loss function.",
                    "label": 0
                },
                {
                    "sent": "When the loss is when the true value is 1, you get the dotted line, and when the true value is 0, you get the.",
                    "label": 1
                },
                {
                    "sent": "The solid line never lets the log loss function square loss functions down the bottom left.",
                    "label": 0
                },
                {
                    "sent": "An hinge loss is used a lot in SVM's as the function loss function you wish to minimize so.",
                    "label": 0
                },
                {
                    "sent": "Any questions about those examples?",
                    "label": 0
                },
                {
                    "sent": "These are all binary, so the whole talk is about binary classification and binary experiments, yet so they're all binary losses.",
                    "label": 0
                },
                {
                    "sent": "Right now I'm.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To talk about.",
                    "label": 0
                },
                {
                    "sent": "Kind of subset, so I've introduced losses very generally here.",
                    "label": 0
                },
                {
                    "sent": "And there are essentially any function I care to mention that takes in a true value and estimate and return some.",
                    "label": 0
                },
                {
                    "sent": "Notion of cost.",
                    "label": 0
                },
                {
                    "sent": "So what we're going to do is narrow our view a bit and consider what.",
                    "label": 0
                },
                {
                    "sent": "I called proper losses or in the statistics literature known as proper scoring rules, so this introduces a very mild condition called Fisher consistency, which I think you'll agree makes intuitive sense anyway, so.",
                    "label": 0
                },
                {
                    "sent": "We say that our losses fish are consistent.",
                    "label": 0
                },
                {
                    "sent": "If it's minimized by the true value of the probability of the class labels, so.",
                    "label": 0
                },
                {
                    "sent": "What this statement says here is that the pointwise risk L. Um?",
                    "label": 0
                },
                {
                    "sent": "When the true probability of the positive classes eater, if you estimate either, then you've minimized the risk.",
                    "label": 0
                },
                {
                    "sent": "Right, so that's Fisher consistently says.",
                    "label": 0
                },
                {
                    "sent": "Basically, if you.",
                    "label": 0
                },
                {
                    "sent": "If you guess the true probability, then you should incur the least possible penalty.",
                    "label": 0
                },
                {
                    "sent": "That's Fisher consistency, and we say that Fisher consistency.",
                    "label": 1
                },
                {
                    "sent": "We say it's strictly Fisher consistent.",
                    "label": 0
                },
                {
                    "sent": "If it's uniquely minimizes the loss function.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So a proper loss is just one that's Fisher consistent.",
                    "label": 1
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So as I said before, in economics are known as proper scoring rules and have been studied by lots of people for a long time, but only very recently.",
                    "label": 1
                },
                {
                    "sent": "The last couple of references there, Boo ET al few years ago.",
                    "label": 0
                },
                {
                    "sent": "And very recently, a guy called Lambert started looking at.",
                    "label": 0
                },
                {
                    "sent": "Kind of machine learning.",
                    "label": 0
                },
                {
                    "sent": "Take on these proper scoring rules and I find them very interesting and I think I'm hoping.",
                    "label": 0
                },
                {
                    "sent": "In this talk, to convince you that there's something that we need to study as machine learners as well, they have a very long history and they have a lot of interesting structure.",
                    "label": 0
                },
                {
                    "sent": "So one.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Again, I'll see if I can help your intuition a bit with some examples so.",
                    "label": 0
                },
                {
                    "sent": "Of these four losses we saw before, three of them are proper, and one of them is not proper.",
                    "label": 0
                },
                {
                    "sent": "So, um.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "The way you would test that these functions proper, which I'm not going to do now is you would take their derivative an you'd make sure that that derivative is 0.",
                    "label": 0
                },
                {
                    "sent": "You take the derivative with respect to either hat, which is your estimate and when you plug in heater you want to get zero and that way you know you've got a minimizer.",
                    "label": 0
                },
                {
                    "sent": "So if you do this procedure with each of zero misclassification log loss square loss, you'll see that they are indeed proper.",
                    "label": 1
                },
                {
                    "sent": "So that means the pointwise risk is minimized by the true value of the class label true value of the probability of the class label.",
                    "label": 0
                },
                {
                    "sent": "But hinge loss is one of one of the few that isn't.",
                    "label": 0
                },
                {
                    "sent": "Which is unfortunate because it's used a lot in support vector machines.",
                    "label": 1
                },
                {
                    "sent": "And the interpretation of hinge loss being not proper is that.",
                    "label": 0
                },
                {
                    "sent": "Hum.",
                    "label": 0
                },
                {
                    "sent": "It's.",
                    "label": 0
                },
                {
                    "sent": "We'll get onto this idea of surrogate losses later, but.",
                    "label": 1
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "01 misclassification loss is very hard to use in practice because you're not given any hints of whether you're doing better or worse at a given point, so.",
                    "label": 0
                },
                {
                    "sent": "With all these other losses, the derivatives give you some hint as to which way you should change your estimate in order to get better zero.",
                    "label": 0
                },
                {
                    "sent": "I'm in class classification doesn't do that.",
                    "label": 0
                },
                {
                    "sent": "It's basically says you're wrong, you're wrong, wrong, wrong wrong, and then suddenly you're right.",
                    "label": 0
                },
                {
                    "sent": "So you've got no hints as to how to minimize it, so.",
                    "label": 0
                },
                {
                    "sent": "It's called a sorry.",
                    "label": 0
                },
                {
                    "sent": "A lot of the time people use hinge loss 'cause it's very simple.",
                    "label": 0
                },
                {
                    "sent": "But it being not proper means that unlike the other losses.",
                    "label": 0
                },
                {
                    "sent": "Where you're effectively doing probability estimation, hinge loss is directly doing classification instead of probability estimation.",
                    "label": 0
                },
                {
                    "sent": "I'll talk a bit more about surrogate losses at the end of this this session, but just thought I'd highlight that now.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So there's some really, really cool properties of of proper losses.",
                    "label": 1
                },
                {
                    "sent": "One is that their pointwise Bayes risk is always concave.",
                    "label": 0
                },
                {
                    "sent": "Now we're seeing some, maybe some links back into the background part of the talk, right?",
                    "label": 0
                },
                {
                    "sent": "So we talked about convexity and everything, here's why.",
                    "label": 0
                },
                {
                    "sent": "If.",
                    "label": 0
                },
                {
                    "sent": "If we just expand the definition of capital L on the right there we get 1 -- 8 * L Zero 8 at plus 8AL1 Aida hat.",
                    "label": 0
                },
                {
                    "sent": "That's the definition of Le to eat a hat on the right.",
                    "label": 0
                },
                {
                    "sent": "You can see that they're just lines.",
                    "label": 0
                },
                {
                    "sent": "With respect to Aida.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The infamous, then, when we're taking the pointwise Bayes risk.",
                    "label": 0
                },
                {
                    "sent": "This function is just an infamous whole lot of lines, and there's a theorem from convex analysis that says that if your function is described as the in form of a whole lot of lines, it's gotta be concave.",
                    "label": 0
                },
                {
                    "sent": "So the Bayes risk.",
                    "label": 0
                },
                {
                    "sent": "For proper scoring rule is.",
                    "label": 0
                },
                {
                    "sent": "Is a concave just.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "There's a theorem by a guy called Leo Savage back in 1971 from statistics and economics.",
                    "label": 0
                },
                {
                    "sent": "He went a bit further, he said that.",
                    "label": 0
                },
                {
                    "sent": "Your loss function is proper if and only if its base risk is concave, so that's quite a strong statement.",
                    "label": 1
                },
                {
                    "sent": "It says if you give me any concave function that concave function.",
                    "label": 0
                },
                {
                    "sent": "Must be the pointwise Bayes risk for some proper loss.",
                    "label": 1
                },
                {
                    "sent": "And if you give me a lot proper loss then its pointwise Bayes risk must be concave, so it's kind of a complete characterization of the proper losses.",
                    "label": 0
                },
                {
                    "sent": "Um, he also provides this formula of how you translate between the two.",
                    "label": 0
                },
                {
                    "sent": "So if you give me a concave function L bar.",
                    "label": 0
                },
                {
                    "sent": "Then I can derive a proper loss.",
                    "label": 0
                },
                {
                    "sent": "With this formula here I I take L bar at my estimate and then I add this linear term times the derivative at my estimate.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is another one of these.",
                    "label": 0
                },
                {
                    "sent": "Really cool things that you should drop down if you haven't already, this is.",
                    "label": 0
                },
                {
                    "sent": "This is like a complete characterization of proper losses and proper losses are what you want to do.",
                    "label": 0
                },
                {
                    "sent": "The right thing to use for probability estimation.",
                    "label": 0
                },
                {
                    "sent": "So one.",
                    "label": 0
                },
                {
                    "sent": "We'll see this quite a bit as we go through some of the relationships between these things.",
                    "label": 0
                },
                {
                    "sent": "Any questions about that?",
                    "label": 0
                },
                {
                    "sent": "I'm.",
                    "label": 0
                },
                {
                    "sent": "Because it is directly doing classification so.",
                    "label": 0
                },
                {
                    "sent": "One thing I'll get to when I talk about surrogate bosses a bit later is.",
                    "label": 0
                },
                {
                    "sent": "That essentially when you use a surrogate loss, you're doing probability estimation and then you kind of thresholding to get a classification.",
                    "label": 0
                },
                {
                    "sent": "If that surrogate loss is a proper scoring rule, then that's what you're doing.",
                    "label": 1
                },
                {
                    "sent": "You're going through.",
                    "label": 0
                },
                {
                    "sent": "Probability estimation to get to classification.",
                    "label": 0
                },
                {
                    "sent": "The hinge loss is interesting because it's not a proper loss, so you're not doing probability estimation.",
                    "label": 0
                },
                {
                    "sent": "You're going straight for classification so.",
                    "label": 0
                },
                {
                    "sent": "Yep, but there's this.",
                    "label": 0
                },
                {
                    "sent": "There's this principle.",
                    "label": 0
                },
                {
                    "sent": "By that Nick says, you know.",
                    "label": 0
                },
                {
                    "sent": "Invented a lot of the theory behind support vector machines and he sort of said you should do classification if your aim is to do classification you should do classification directly.",
                    "label": 0
                },
                {
                    "sent": "Don't go via some Securitas route.",
                    "label": 0
                },
                {
                    "sent": "So that's why the hinge loss is not proper because it's not doing probability estimation.",
                    "label": 0
                },
                {
                    "sent": "It is what sorry inconsistent.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so the pencil.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "It could, it could be.",
                    "label": 0
                },
                {
                    "sent": "I mean, it's what it does.",
                    "label": 0
                },
                {
                    "sent": "Basically if you try to minimize hinge loss.",
                    "label": 0
                },
                {
                    "sent": "The your estimates will either zoom off to negative Infinity or zoom off to positive Infinity, representing a negative prediction or positive prediction because the law says that if you're depending on which side of the margin, you shouldn't make that function as bigger as small as possible.",
                    "label": 0
                },
                {
                    "sent": "So it doesn't do probability estimation, 'cause that requires your function to.",
                    "label": 0
                },
                {
                    "sent": "This requires your predicted to sort of tune its value to a precise probability test.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so I'll just run through some examples really quickly so.",
                    "label": 0
                },
                {
                    "sent": "This is some examples of savages theorem, so if we take zero on misclassify.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And also we can write the pointwise risk like this which is just.",
                    "label": 0
                },
                {
                    "sent": "Negative 8 or if prediction is bigger than .5 and either prediction is less than .5.",
                    "label": 0
                },
                {
                    "sent": "That's the penalty penalty.",
                    "label": 0
                },
                {
                    "sent": "The average point.",
                    "label": 0
                },
                {
                    "sent": "Where is this?",
                    "label": 0
                },
                {
                    "sent": "You'll get for prediction either.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We can compute the minimizer of this by just plugging in.",
                    "label": 0
                },
                {
                    "sent": "Um eater, instead of eat a hat and we get very very slight variation that you notice the hats are missing from.",
                    "label": 0
                },
                {
                    "sent": "The conditions in the second line.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then of course we can take the derivative, which will just be negative one if you're if either is bigger than .5 and one for less than .5.",
                    "label": 0
                },
                {
                    "sent": "So I haven't done this on the screen, but if we go back to.",
                    "label": 0
                },
                {
                    "sent": "We go back to.",
                    "label": 0
                },
                {
                    "sent": "Savages theorem.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What I was trying to show with this example is how you can compute L bar and El Bar Dash quite easily and.",
                    "label": 0
                },
                {
                    "sent": "If you drop down this example and compute these values, you can convince yourself.",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That the LL of Ada Ada hat is actually equal to.",
                    "label": 0
                },
                {
                    "sent": "The formula seven.",
                    "label": 0
                },
                {
                    "sent": "These values for LL Bar and Elbow Dash satisfy that Savage formula.",
                    "label": 0
                },
                {
                    "sent": "You",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Do the same thing for log loss as well.",
                    "label": 0
                },
                {
                    "sent": "So you can take the definition of log loss.",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's quite easy to compute L of ITA ITA hat.",
                    "label": 0
                },
                {
                    "sent": "You just plug in either and eat a hat into the formula.",
                    "label": 0
                },
                {
                    "sent": "You can, we know, because it's proper that we can just plug in heater wherever we see, eat a hat to get the minimizer.",
                    "label": 0
                },
                {
                    "sent": "And then we can just take its derivative an once again, if you felt like it, you could plug these back it into the Savage format and you'll see that because it's a proper loss that for.",
                    "label": 0
                }
            ]
        },
        "clip_80": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So satisfied, so the point of the examples are that.",
                    "label": 0
                },
                {
                    "sent": "Normally you might think of Bayes risk is something very unwieldy and hard to get to.",
                    "label": 1
                },
                {
                    "sent": "After all, that's what it is you're trying to get to when you're minimizing when you're doing any kind of optimization problem in classification, you're trying to minimize loss, so normally you would think that the Bayes risk would be a very difficult thing to work with, but the pointwise Bayes risk or conditional Bayes risk is actually just closed formula and it's very easy to work with if you give me a loss, I can compute the pointwise loss and I just plug in heater in both arguments and I get the.",
                    "label": 0
                },
                {
                    "sent": "Um, I get the.",
                    "label": 0
                },
                {
                    "sent": "Pointwise Bayes risk?",
                    "label": 0
                },
                {
                    "sent": "Given that if it's proper, This is why proper proper losses are important.",
                    "label": 0
                },
                {
                    "sent": "OK, any question?",
                    "label": 0
                },
                {
                    "sent": "Any anymore questions?",
                    "label": 0
                },
                {
                    "sent": "Alright, so I've got a few minutes left to go through the last lot of definitions and then after this session I've covered all of the all of the important points and will start connecting him up in the next part.",
                    "label": 0
                },
                {
                    "sent": "So the last thing I'd like to talk about is information motions of in.",
                    "label": 0
                }
            ]
        },
        "clip_81": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Nation for binary experiments.",
                    "label": 0
                },
                {
                    "sent": "Whenever I think of information, there's this great quote by TS Eliot, who asked in his courses from the Rock.",
                    "label": 0
                }
            ]
        },
        "clip_82": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Where is the wisdom we have lost in knowledge and where is the knowledge we have lost in information?",
                    "label": 1
                },
                {
                    "sent": "I think it's some.",
                    "label": 0
                },
                {
                    "sent": "I think it's something we should.",
                    "label": 0
                },
                {
                    "sent": "We should ask as machine learners because our job I think is too.",
                    "label": 0
                },
                {
                    "sent": "Recover knowledge from information or maybe even were a step lower.",
                    "label": 0
                },
                {
                    "sent": "We need to recover information from data.",
                    "label": 0
                },
                {
                    "sent": "So eventually would like to move up that hierarchy and get to.",
                    "label": 0
                },
                {
                    "sent": "Artificial wisdom, I suppose.",
                    "label": 0
                }
            ]
        },
        "clip_83": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right so back in 1962 guy called.",
                    "label": 0
                },
                {
                    "sent": "The group introduced a very general notion of what he called statistical information.",
                    "label": 1
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "The way he set it up, as he said, well, let's suppose we have some distribution which is called desire there.",
                    "label": 0
                },
                {
                    "sent": "And suppose we've got you, which is some measure of how uncertain the distribution is.",
                    "label": 1
                },
                {
                    "sent": "So for really really peaked distribution like the one on the left there we would say it has low uncertainty.",
                    "label": 0
                },
                {
                    "sent": "All of the distributions very tightly.",
                    "label": 0
                },
                {
                    "sent": "Tom.",
                    "label": 0
                },
                {
                    "sent": "Peaked around a single value, so there's not much uncertainty in that.",
                    "label": 1
                },
                {
                    "sent": "Then for other distributions where the more spread out, you would say that has high uncertainty.",
                    "label": 0
                },
                {
                    "sent": "So he like to think of this uncertainty function you which assigned measures of uncertainty.",
                    "label": 0
                }
            ]
        },
        "clip_84": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Distributions.",
                    "label": 0
                },
                {
                    "sent": "I'm now we assume that we have some prior distribution over our values and then we have some posterior distribution.",
                    "label": 1
                },
                {
                    "sent": "Then we can talk about a reduction in uncertainty.",
                    "label": 1
                },
                {
                    "sent": "We can say how much uncertainty was there when I only had the prior and how much uncertainty was there when I had the posterior.",
                    "label": 1
                },
                {
                    "sent": "And this reduction of uncertainty is what he called information.",
                    "label": 0
                },
                {
                    "sent": "So if I started a prior and observe X one, I would get some posterior.",
                    "label": 0
                },
                {
                    "sent": "Zyvex one when I observe X2 I might get a different posterior.",
                    "label": 0
                },
                {
                    "sent": "X3 might give me a different posterior.",
                    "label": 0
                }
            ]
        },
        "clip_85": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And if I take the average.",
                    "label": 0
                },
                {
                    "sent": "Over all of my observations and I look at the average reduction of uncertainty.",
                    "label": 0
                },
                {
                    "sent": "Then um.",
                    "label": 0
                },
                {
                    "sent": "This is what he called statistical information.",
                    "label": 1
                },
                {
                    "sent": "It's the average reduction of uncertainty from a prior to.",
                    "label": 0
                },
                {
                    "sent": "Posterior distributions.",
                    "label": 0
                },
                {
                    "sent": "It's just some function.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                },
                {
                    "sent": "It could be the variance, it could be.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Could be yeah, it's.",
                    "label": 0
                },
                {
                    "sent": "Quite general, I'll show you how we get a whole lot of uncertainty measures for free in a bit.",
                    "label": 1
                },
                {
                    "sent": "Yep, and this is a really cool part so.",
                    "label": 0
                }
            ]
        },
        "clip_86": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Intuition says that if I start with the prior and I observe something.",
                    "label": 0
                },
                {
                    "sent": "That observation should contain some information.",
                    "label": 1
                },
                {
                    "sent": "It's not going to take away information.",
                    "label": 0
                },
                {
                    "sent": "At the very least right.",
                    "label": 0
                },
                {
                    "sent": "So if I have some measure of information with respect to some uncertainty function, then we'd hope that it would be bigger than the information that we derive from that uncertainty.",
                    "label": 0
                },
                {
                    "sent": "Certainty function is going to be non negative.",
                    "label": 0
                },
                {
                    "sent": "We want the reduction to increase.",
                    "label": 0
                },
                {
                    "sent": "We want to.",
                    "label": 0
                },
                {
                    "sent": "So we start off being very uncertain.",
                    "label": 0
                },
                {
                    "sent": "We just have a prior and then as we get observations we want to pull that uncertainty down.",
                    "label": 0
                },
                {
                    "sent": "So the gap we get from.",
                    "label": 0
                },
                {
                    "sent": "What we had when we started and what we had after the observations.",
                    "label": 0
                },
                {
                    "sent": "We want to be as big as possible.",
                    "label": 0
                },
                {
                    "sent": "So we want this to be non.",
                    "label": 1
                },
                {
                    "sent": "And this is where Jensen's inequality comes in again.",
                    "label": 0
                },
                {
                    "sent": "So if if I use the definition of information had before that Delta you an I expand it out.",
                    "label": 0
                },
                {
                    "sent": "In a few lines you can see that this is actually.",
                    "label": 0
                },
                {
                    "sent": "The uncertainty of the average value of the distribution minus the average value of the uncertainty.",
                    "label": 0
                },
                {
                    "sent": "So this is just the Jensen gap that was introduced awhile ago.",
                    "label": 0
                }
            ]
        },
        "clip_87": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we know that Jensen's inequality says that we only get this Jensen Gap being non negative when we have a convex function.",
                    "label": 0
                },
                {
                    "sent": "Well, in this case the negative of a convex function, so we only get.",
                    "label": 0
                },
                {
                    "sent": "A sensible definition of information using this construction.",
                    "label": 0
                },
                {
                    "sent": "If the uncertainty function we had is concave.",
                    "label": 1
                },
                {
                    "sent": "Right?",
                    "label": 0
                }
            ]
        },
        "clip_88": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is I've introduces in a very general fashion, but it does subsume pretty much any measure.",
                    "label": 0
                },
                {
                    "sent": "Any definition of information you care to mention.",
                    "label": 0
                },
                {
                    "sent": "So Shannon information is when your uncertainty function is the entropy of the distribution, for example.",
                    "label": 1
                },
                {
                    "sent": "I'm not sure what you would get if you use variance, but that would be interesting.",
                    "label": 0
                }
            ]
        },
        "clip_89": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's another takeaway.",
                    "label": 0
                },
                {
                    "sent": "Statistical information is the reduction between the prior uncertainty in posterior certainty uncertainty and this is non negative and only if you is concave.",
                    "label": 1
                },
                {
                    "sent": "Um, so in the next part of this talk after the break.",
                    "label": 0
                },
                {
                    "sent": "Will see how to get ahold of you functions.",
                    "label": 0
                }
            ]
        },
        "clip_90": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Before we finish up just recently in 2005 in Erie, Banegi and a few others introduced this notion of Bregman information they started with.",
                    "label": 0
                },
                {
                    "sent": "A Bregman divergent.",
                    "label": 0
                },
                {
                    "sent": "So someone gives you a Bregman divergent service base of points and then asks.",
                    "label": 0
                },
                {
                    "sent": "What single point in my space minimizes the average distance to every other point in that space, and so Bregman?",
                    "label": 0
                },
                {
                    "sent": "Pregnant information is.",
                    "label": 0
                },
                {
                    "sent": "A measure of the average distance to every other point from a given point in a space where the distance is measured by the Bregman divergences that you were first given.",
                    "label": 1
                },
                {
                    "sent": "So someone gives you a Bregman divergent.",
                    "label": 0
                },
                {
                    "sent": "The pregnant information is average spread if you like.",
                    "label": 0
                },
                {
                    "sent": "With respect to that Bregman divergent.",
                    "label": 0
                },
                {
                    "sent": "So quite a technical definition and they show that the.",
                    "label": 0
                },
                {
                    "sent": "The single point that that that that achieves this minimum is actually the mean of the distribution that you're interested in.",
                    "label": 1
                },
                {
                    "sent": "And the reason I'm not going to spend much time on this is because in the next part of the talk, we'll see that this is exactly the same as statistical information, although it looks very different to begin with, turns out.",
                    "label": 0
                }
            ]
        },
        "clip_91": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The same thing, and.",
                    "label": 0
                },
                {
                    "sent": "So the next part of the talk we're going to use mathematics to give the same name to whole bunch of different things, but I think for now we'll just have a bit of a break.",
                    "label": 0
                }
            ]
        }
    }
}