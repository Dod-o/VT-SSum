{
    "id": "42kxrpoi7stcwx3pekgj4inucdf2pg7s",
    "title": "Advanced Statistical Learning Theory",
    "info": {
        "author": [
            "Olivier Bousquet, Google, Inc."
        ],
        "published": "Feb. 25, 2007",
        "recorded": "September 2004",
        "category": [
            "Top->Computer Science->Machine Learning->Statistical Learning"
        ]
    },
    "url": "http://videolectures.net/mlss04_bousquet_aslt/",
    "segmentation": [
        [
            "I'm a bit frustrated because it seems that it was and it still is a nice place to be.",
            "I wish I had stayed more and I would.",
            "I wish I had more time to stay here so.",
            "I have not attended Johns lectures, so there might be some overlap.",
            "I went through the slides.",
            "It seems that there is not too many too much overlap, but in case there is, feel free to let me know and feel free to tell me OK, John told everything about this so don't bother or."
        ],
        [
            "Or if there is something that you that you feel would be nice, I don't know if John promised that I would talk about something, let me know as well.",
            "So this is intended to be somehow the extension of John's lectures.",
            "And I will go into more details about some specific aspects of learning theory.",
            "There will be 4 lectures.",
            "The first one will be about the Union bound.",
            "Which is one key ingredients of obtaining bounds in learning theory and the second lecture will be about variance.",
            "An local run maker averages, and this is the second key ingredients of statistical learning bounds.",
            "And then there will be some sort of two other lectures will be about more about supplying the bounds to specific situations.",
            "Lecture #3 will be about loss functions and how to adapt the bounds that we will see in the first 2 lectures that will be restricted to the binary classification case to more general setting still in classification, but where the loss function is a convex loss function.",
            "And the first lecture will be some applications to SVM.",
            "I'm not sure we will be able to go all the way to the first one, so the end of the first lecture.",
            "I will try to adapt the level so if there are something that are too easy or too difficult again, feel free to interrupt me and let me know.",
            "So the plan for today is the following.",
            "I will first recall briefly what is the setting that we are dealing with and."
        ],
        [
            "Again, I will focus on binary classification.",
            "In the statistical learning theory framework.",
            "And I will.",
            "Recall you what is the Union bound basic version of Union bound and then introduce more and more refinements about this Union bound.",
            "Then another topic that we will talk about an that's explains the title pack Bayesian techniques is what is called random."
        ],
        [
            "Classification, and that's where these pack vision bounds occurred first.",
            "And then we'll see some other refinements, so it will be all about the Union bound.",
            "OK, so maybe I'll introduce the setting again and then tell you what is a union one because it may not be obvious for all of you.",
            "So the setting is quite classical.",
            "I don't know if this works.",
            "OK, so we have an input SpaceX and output Space Y.",
            "And here as we are in classification setting our output space."
        ],
        [
            "As only two possible two elements, it's plus one or minus one.",
            "An the assumption that we make or the model or the way we model the problem is that we assume that we have a pair of random variables.",
            "X&Y, that are.",
            "I don't know if this is very convenient.",
            "Maybe I should avoid it?",
            "So we have a pair of random variables.",
            "Maybe the mouse would do it.",
            "Kind of everybody.",
            "See the mouse.",
            "OK.",
            "So we have a pair XY.",
            "An OK X belongs to our input space, which is anything any space.",
            "And why is iser plus one or minus one, and this pair is assumed to be distributed according to some distribution which we call P, which is unknown.",
            "An instead of knowing P, which would be ideal.",
            "We observe a sequence.",
            "Of North N is the sample size, IID pairs XI which are sampled according to this P. So we observe we get knowledge about this unknown probability distribution via the observation of these pairs XII.",
            "This is our training sample.",
            "And the goal is."
        ],
        [
            "As usual.",
            "To construct a function that allows to predict the output Y from the input X.",
            "And this function we call G. It's usually called the classifier in this in this setting.",
            "Ann, it's for any instance X in the input space.",
            "It's Maps it to either plus one or minus one.",
            "And it has to.",
            "I mean, the goal is to build the function such that it is able to predict the random variable Y from the random variable X, which means an we have to define what what means predicting in this setting and predicting means making as few mistakes as possible.",
            "And the way we measure the number of mistakes is via this formulation here.",
            "We call that the risk and the risk is the probability that when we take a pair XY of random variables from this unknown P. And we try to predict Y from X using this function G. We make a mistake which means the predicted outcome is different from the one we observe.",
            "An these probability of making mistakes can be written as the expected value of the indicate."
        ],
        [
            "Or function so this one here with an.",
            "With a subscript, here is the indicator function that this is true.",
            "It's it takes value one when this is true and zero when it's not true and the expected value of such a function is nothing but the probability that the event is true.",
            "OK, so this is a bit of notation.",
            "But it doesn't say anything complicated.",
            "It just says that we want to find the function that makes few mistakes.",
            "Now of course there are some issues and which explain why it's not an easy problem.",
            "So first of all, as I told before, P is unknown, so we can't.",
            "We can't even define this quantity or can't even compute it.",
            "So this is already a big problem.",
            "And the only thing we can do instead is to use our training data to measure at least the agreements of our classifier with this training data, which is called usually the empirical risk or empirical error, and this is nothing but the empirical average or empirical expectation of the error function.",
            "This indicator function computed on our sample, so we just count how many mistakes we make on our sample.",
            "We divide this by the sample size.",
            "And this gives us a number, and this is called the empirical error.",
            "And of course, it's a good idea to have a small empirical error, or to find a function G which has a small empirical error.",
            "And usually we hope that when this empirical error is small, then the true risk.",
            "Or expected risk?",
            "Will be also small.",
            "And the whole goal of this statistical learning theory is to quantify how much we.",
            "How wrong we are in assuming that when this empirical risk will be small, the true risk will also be small.",
            "And for that we the theory aims at producing bounds, which are statements that tell you how far you are.",
            "When you think that your true error is is small because your empirical error is small.",
            "So.",
            "Again, some notation that I introduce here.",
            "So we have this training data X IX1Y12X NYN and we produce a function GN.",
            "So whenever I put a small."
        ],
        [
            "Subscript N here it means a quantity that depends on the data that we have determined after seeing the data.",
            "So GN means the classifier that we constructed after we have seen the data.",
            "So we produce this classifier GN.",
            "And the question is, how can we estimate the risk of this classifier?",
            "And of course.",
            "And that's why this N here.",
            "I mean why I put this in here in order not to forget that this is a random quantity, because it depends on the data and our basic assumption is that this data is a random sample from a distribution.",
            "So we need what are called probabilistic bounds.",
            "We cannot make any.",
            "Absolute statements we can only say that because of this model that we have.",
            "Because we assume that the data is sampled IID from a certain distribution which never changes.",
            "Then there is some chance, some probability.",
            "That's what we observe on the data will be close to what we would observe if we had infinite infinite amount of data.",
            "And that's what is called probabilistic bounds.",
            "And of course you're already have seen some probabilistic bounds in John's lecture and maybe.",
            "All this is clear to you, but I want to reset the.",
            "The setting.",
            "OK, so there are two types.",
            "Two big two main types of.",
            "Probabilistic bounds that we can derive the first type is of the of the following form we upper bound.",
            "So all this is with a certain probability, so with high probability on the random sampling of the sample, we provide an upper bound on the true risk R of GN of our classifier that we constructed from the data.",
            "Here."
        ],
        [
            "From the empirical error of this same classifier plus some quantity, some quantity which is actually the bound which is this B here.",
            "And these tales that.",
            "The true error can be.",
            "As big as the empirical error plus some penalty.",
            "And this this type of bound allows us to estimate from above the true risk from an empirical version of this risk.",
            "The other type of bond also gives an estimate from above of the true risk, but from other quantities.",
            "Usually non empirical quantities.",
            "So there are two, two big again.",
            "Two types, the first type is.",
            "You compare the true risk to the risk of the best classifier in a given class.",
            "And the second type is that you compare the true risk of your constructed classifier to the best of all classifiers, which is called the Bayes classifier usually, and these are star means the best risk you could obtain from function from X to Y.",
            "So you just construct the best function and the best function usually is.",
            "The function that predicts plus one when the probability of being off.",
            "Why OK, maybe I should write it.",
            "But I don't know if it will be seen in singable from everywhere.",
            "So.",
            "Again, we have this probability distribution XY.",
            "If we look at the probability.",
            "Of why being equals to one.",
            "Given X, so at a specific location in our input space, we look at what is the probability that at this location Y is equal to 1.",
            "So what is the probability that the label of these points is equal to 1?",
            "And then we look at whether this probability is larger or not done 1/2 then this gives us what is called the base classifier, which means whenever this is true whenever this property is larger than 1/2, we predict with one and whenever it's less than 1/2, we predict with minus one.",
            "And this is the optimal thing that we could do with a deterministic function.",
            "And the risk of this classifier is this R star here.",
            "And of course, it's interesting to know if you can provide such a bound.",
            "Then it tells you, OK, you have built a classifier from the data and your that's far from doing the best thing."
        ],
        [
            "Could do.",
            "So this provides us theoretical guarantees.",
            "On the algorithm that we construct.",
            "OK, so.",
            "Again, notation was.",
            "It's a bit confusing maybe.",
            "But OK, the goal is to simplify things.",
            "So we have these two variables X&Y and we just call these pairs Y. OK. Now there are two concepts that I will go back and forth from.",
            "The first one is called hypothesis, hypothesis class or function class.",
            "Or classifier class whatever and it's the set of all possible classifiers that we consider at when we construct."
        ],
        [
            "An algorithm.",
            "And it contains function that map the input space to.",
            "OK, usually plus one or minus one, but it could be more general.",
            "It could map to any real number.",
            "OK, so whenever I write G, it means a classifier function that predicts.",
            "Some value for all inputs.",
            "And when I write F then it's not the function that predicts but the function that computes the error of a given classifier.",
            "So the way you construct these functions, F is that you so F is defined on the pair XY and it computes the error of the classifier G on the pair XY.",
            "It compares G of X&Y and it puts that into this L, which is a loss function which in our case so far is.",
            "The indicator of that that G of X is different from Y, and this gives us a number and this is the value that we assign to F of Z. OK, so we have two ways of looking at the same thing.",
            "Either we look at the classifier and."
        ],
        [
            "Look at the predictions made by made by this classifier.",
            "That's G&G of X.",
            "Or we look at the error made by this classifier, which means we look at the pair XY.",
            "We predict with G of X and we compare the FX with Y and that's F of Z or F of XY.",
            "And OK, there is another way, which is we can even look not directly at the error of the classifier, but at the error of the classifier compared to the error of the best classifier.",
            "And that's the relative loss which is written.",
            "Here is the difference between the lots, sorry.",
            "Of our classifier minus the loss of the best classifier, what happens, sorry.",
            "OK, Ann, why do I do all this?",
            "The main reason is that it allows me to treat everything as expectations.",
            "Recall that I told you that the error of the classifier is just the expectation of the loss function or the indicator function that it makes some mistakes.",
            "So now now that I have introduced this notation, FI can rewrite the risk of a given classifier G as the expected value of the corresponding F. Right and same thing for the empirical risk RN of G. It's the empirical average of F of Z.",
            "And to denote sexpectations I use P of F. So PF means expectation with respect to P of the function F&PNF means expectation computed on the sample so empirical average.",
            "OK, so that allows me to have somehow simpler notation in the rest.",
            "OK, so now that I've introduced all this notation and I hope it's more less clear.",
            "Let's get to the topic.",
            "So.",
            "If there is anything that you should recall from this lecture is what is written on these slides.",
            "Um?",
            "I will detail this in the remaining of the lecture, but I want to give you a first overview of that."
        ],
        [
            "So there are two main ingredients.",
            "When you build a bounds, the first one is deviation inequality, which tells you how far can be a random quantity from its expectation, and you have probably seen many of those in Johns lectures, which are called usually concentration inequalities.",
            "And the other ingredients is what is called a union bound, and it allows you to treat not just one random variable at a time, but a collection of random variables.",
            "So.",
            "So you have these two things you first have to say.",
            "Well, for each of my random variables there is such and such a probability that it deviates from its expectation.",
            "But then when you look at many random variables at the same time, for example, when you look at all the functions that you have in your function class.",
            "Then you need to be able to say something about collectively all these random variables.",
            "And that's what is a union bound.",
            "Anne Anne.",
            "The optimal way of.",
            "Performing such a union bound, so performing union bound means telling something about a collection of random variables.",
            "From a statement on each of the random variables.",
            "So the optimal way of doing this is by using the metric structure of your space of random variables, and then I will explain what this means in more detail later.",
            "But that's the idea.",
            "So when you have several random variables, the main thing that you have to look at is how they are structured and how they relate to each other.",
            "And once you know how they relate to each other, then you can say something about their global behavior.",
            "Another thing which is quite interesting an that you have to recall is that it is possible."
        ],
        [
            "To introduce what is called prior, but it's quite different from what visions would call prior.",
            "It's mostly a technical tool, but you can introduce a prior into union bounds, and you can actually tweak the Union bound in certain ways according to what you think is more likely to happen.",
            "When you have data.",
            "And the last thing is that the last thing that you have you have to record from this lecture is that there is this so called pack vision technique that will present.",
            "And the main aspect of this pack vision technique is that it allows you to improve the Union bound when you average over several classifiers.",
            "OK, and this will be clear in a minute.",
            "OK, so let's start again with deviation inequalities.",
            "So this is the most straightforward inequality I would say.",
            "OK, the notation may not be familiar to you, especially that it's quite different from John's notation, but I will try to explain.",
            "So what it tells you is that.",
            "The expectation of a function.",
            "Minus the empirical expectation of a function is upper bounded by such a quantity here.",
            "And OK. You you should recall that P of F is nothing but the risk of a certain classifier and PFF is the empirical risk.",
            "So this bound tells you what is the difference between the true empirical risk of a given classifier.",
            "And what it tells you is that with a high probability.",
            "Delta is usually a small quantity.",
            "This difference is bounded by a certain constant Times Square root.",
            "Of this log, one over Delta divided by N. So essentially 1 / sqrt N. So that's one thing that you should always have in mind when you look at an empirical average and you want to compare it with the true average.",
            "For a fixed function.",
            "F. This is fixed.",
            "This quantity, when the function is bounded at least.",
            "These quantities of order 1 / sqrt N OK that's easy, straightforward and always true.",
            "So with high probability the difference between those two quantities of order 1 / sqrt N. So that's called object inequality and OK, I should have written somewhere that it requires boundedness of the function.",
            "So now this is fine for one function, but usually you have many functions to choose from.",
            "Your algorithm is not restricted to always use the same classifier at each time every time it sees new data, it is allowed to pick a different function.",
            "So you usually have a set of possible functions and your classifier look at the data, tries to find the best one in these sets with respect to the empirical error.",
            "So the first thing we can assume is let's see what happens when the set of functions we have is finite.",
            "So assume you have a classifier that just as a finite set of function and picks one from them from this set.",
            "Then you need a statement that somehow.",
            "Is the uniform equivalent of holding in quality because you know that for each individual function you know how to bound the difference between true and empirical risk, but these bound is probabilistic, which means that for certain samples.",
            "This will be true."
        ],
        [
            "But for other samples, it won't be true because only for a fraction 1 minus Delta of them is true.",
            "So now if you look at at other functions, maybe if you look at so this is F. Let's say we look at F prime, maybe 4F prime.",
            "The difference is less than 1 / sqrt N for some samples and bigger for other samples.",
            "But the samples on which it is small may not be the same done for F. So for each different function.",
            "In your class, you may have different samples for which this bound is valid, and different samples for which it is not valid.",
            "And so you don't know how many in the end.",
            "Are such that all the functions?",
            "Are within that range.",
            "OK, so that's why you need to perform this Union bound and.",
            "I've not detailed a way to do it because I thought John did, but maybe not.",
            "Maybe I can write it quickly.",
            "I think there was something about this, but maybe not written in this form in his slides.",
            "OK, but anyway.",
            "So.",
            "We start with Heddings inequality that tells us that.",
            "For a given function, the probability under the sampling that.",
            "The difference between PF&PNF.",
            "OK, so it's a bit misleading because this is a probability, so maybe I should write with two bars here and this is expectation of F. So the probability that the true expectation minus the empirical expectation.",
            "Being larger than.",
            "Square root log one over Delta over N with some constants.",
            "This is less than Delta.",
            "OK, so that's one way of writing has inequality.",
            "The probability that the deviation is large is small.",
            "So now you can write this for several different functions.",
            "So you write it for.",
            "So this is F1C and then you write it for F2.",
            "Based on Delta and so on, and then you want to say something about.",
            "The probability that OK, so the bond we want is something that tells us that gives us a guarantee for all functions simultaneously.",
            "So we want to say that for all functions the difference will be small, so we have to bound the probability that this difference will be large.",
            "So which means that the probability that there exists one function for which the difference will be large, right?",
            "It's the opposite thing that we want to quantify.",
            "An now we have we know how to bound each individual probability and we just have to say what is the probability that one of these events will be realized.",
            "So one of these function will deviate more than a certain quantity.",
            "Which means we have to bound the probability of the disjunctions of the events A or B.",
            "An probability that of A or B.",
            "Is upper bounded by the probability of a plus probability of B?",
            "Right, that's basic knowledge of probability.",
            "So if we apply this to this case, then the probability that eiser function one as a large deviation or function 2 as a large deviation is less than the sum of the two probabilities, which is 2D, right?",
            "So that's how it works.",
            "So if you have any functions, then you just have to replace Delta by end times Delta.",
            "And if you do that and you write the bounds in this way, then it tells you that with probability 1 minus Delta.",
            "For all functions simultaneously in your class F, the deviation between true and empirical error is bounded by this quantity, so.",
            "Actually, I increased Delta by factor F and that gives me this.",
            "Or sorry I should say.",
            "OK, if you look at here, the probability will be less than two Delta, but then you just rename 2D into Delta and that's that.",
            "Corresponds to devising Delta by by two.",
            "OK well just have to write it.",
            "Sorry for not being clear here.",
            "But in the end, OK, the important thing is that the bound has increased a little bit because you have lost some.",
            "Some confidence in a way, because you're looking at many different functions at the same time, and any of them could deviate.",
            "So the bound is a bit worse and how much worse is it?",
            "It's worse by this log of size of this class of function term.",
            "And you can think of this term as a variance in a way.",
            "The more functions you have, the more variability you have, because not only can the empirical average deviate from the true average, but also you can choose different functions.",
            "So this adds some variability to your random quantity.",
            "And another way to think of this log of size of function class.",
            "Is as a measure of the function Class A measure with respect to random fluctuation of a quantity.",
            "And you have seen in John's lectures many other measures of size of a function class, the VC dimension or probably using covering numbers.",
            "The fat shattering dimension.",
            "Anne Radmacher averages.",
            "So all these quantities are quantities that measure the size of a function class, and the log of number of functions is the most basic one."
        ],
        [
            "OK, so this is for the University, I don't know.",
            "Is it clear for everybody?",
            "Are there any difficulties here?",
            "No, no see means are constants here.",
            "Yeah OK you could, yeah, but this is true for each.",
            "N. Big OL would be somehow in the limit so.",
            "This is true for each possible value of N. An yeah and the constant here does not depend on anything.",
            "It doesn't depend on the size of the class of function.",
            "It doesn't depend on Delta, and independent doesn't depend on.",
            "OK, and usually OK in this specific case it's something like 2.",
            "But it depends on the bound that you have on your class or function, but usually the loss is between zero and one and then sees something like 2.",
            "OK, so the next thing you can do, and that's I'm pretty sure that was mentioned, at least in John's lecture.",
            "Is that you can somehow wait all your function in a different way when you perform the Union bound.",
            "So here I had written the same bound for each function, but I can slightly modify the bound that I write for each function and especially I can have.",
            "A different Delta for each such bound, so I can write here D1 and here D2.",
            "And then.",
            "I can just do the same thing, the same union bound and what I get is that now my Delta depends on the function.",
            "And it depends in in in the following way.",
            "Essentially, we have to make sure that all these Del stars that we've right here when we sum them up we have something which is which is still small, which is still a Delta.",
            "So we just have to make sure that D1 plus D2.",
            "Equals Delta for example, right?",
            "So you just pick 2, two numbers D1 and D2 such that their sum is equal to Delta and then.",
            "We can do the same thing and gets the bound that tells you that with probability 1 minus Delta we have this.",
            "At most this deviation.",
            "And OK here that would be a log one over D1 or one log one over D2 depending on the function.",
            "And I just written this, I just separated the term Pi of F from the Delta, so and that's not clear again because I skipped a lot of details.",
            "Essentially, the easiest way to have a sum of deltas that is equal to Delta is to take a probability distribution over.",
            "Over your class of functions.",
            "So for each function."
        ],
        [
            "You have a number \u03c0 of F. Such that the sum of this pie of F, this number is non negative and the sum of this part of F is equal to 1.",
            "So that's a probability distribution on your class of function.",
            "And once you have this, you just write the hovding bound for each function with Delta times \u03c0 of F. And when you will sum all these things, then you will get Delta, that's that."
        ],
        [
            "And that's why you get log of 1 / \u03c0 of F here.",
            "And in the simple case where you put equal weight to all functions, Pi of F is one over the number of functions, so log 1 / \u03c0 of F is just log of the number of functions.",
            "And you recover the previous bound, but but you could imagine to put a different weight on different functions.",
            "And then you would get a different bound, and that's a bit surprising, because you can say well.",
            "What if I put all the weight on one specific function, then I get to a bound which is as good as the acting bound.",
            "But the problem is, and that's where there is a trick.",
            "This specific probability distribution by of F has to be chosen before you see the data, so it cannot be a random distribution here.",
            "So."
        ],
        [
            "Even if you knew in advance, well, even if you guess in advance what will be the classifier picked by your algorithm.",
            "And you know, I mean, OK, sorry.",
            "You can either you can guess before seeing the data what will be the classifier picked by your algorithm, and in that case you could put all the probability mass on this classifier and then you get a super good bound.",
            "But in general, you don't know before hand before seeing the data, you don't know whether the hyperplane will be like this or like this.",
            "Alright, so that's why you cannot really hope to improve your bound by picking the right distribution.",
            "But still.",
            "Still, you can hope to do something because.",
            "You can have an idea about how your algorithm, sorry.",
            "About how your algorithm will behave.",
            "For example, you know that.",
            "In general, your algorithm tries to minimize the empirical error, so it will try to find functions that have low empirical error.",
            "Or you know that it maximizes the margin, so you know that you can put more weight on the functions that have a large margin because those are more likely to be chosen by your algorithm.",
            "And if you do that, you put more weight on these functions, then you decrease the log 1 / \u03c0."
        ],
        [
            "Term so you get a better bounds for those functions.",
            "So you can imagine to put here something that would be proportional to the margin, and then you get a bound that tells you well whenever the margin is large, then the bound is small.",
            "And why?",
            "Because I assume that the algorithm will pick functions with large margin.",
            "But of course if it happens that when I train my classifier on my data, I get a small margin, then the bounding is bad.",
            "So.",
            "It's just the best that you make before before running your classifier.",
            "Your algorithm.",
            "You just bet that the classifier will have such a margin, and if you bet, I mean if you are successful then you have a good bound.",
            "And if you're not then the bound is worse.",
            "So.",
            "You cannot hope to have always a good bond.",
            "Yeah yeah, I mean there is no restriction.",
            "OK here, The thing is.",
            "If you have, I mean this only works for example, if you have a countable class of functions, because otherwise you're.",
            "Let's say the probability of a single function is zero always when you have a continuous distribution, so this log 1, /, \u03c0 blows up and you have a bound that is useless.",
            "But but at least if you have accountable class of function, you can take any any probability distribution.",
            "But most often it's hard to define such a probability distribution.",
            "OK, so so this.",
            "Again, summarizes these considerations.",
            "So pie here is is not.",
            "I mean, it's different from a Bayesian prior in the sense that it's not that we hope that our function is chosen from a probability distribution Pi by some device.",
            "But we just make a bet.",
            "We just say, OK, let's pick some distribution an if we have.",
            "If we are lucky then our bond will be good and if not then it will be bad.",
            "But it has nothing to do with the process of generating the data or generating the function itself.",
            "Anne.",
            "OK, so if you want to have a good bound, So what would be the ideal probability distribution or ideal waiting?",
            "The ideal waiting is such that.",
            "Each function is assigned a weight that correspond to how likely it is to be chosen by your algorithm on the specific data that you have.",
            "So if you were able to sample repeatedly the data."
        ],
        [
            "Train your classifier.",
            "Look at the function that is chosen and if you were able to do this many times then you would obtain the ideal or optimal probability distribution by.",
            "But of course, again, it's not possible to do this.",
            "That's why you somehow have to guess this pie before hand.",
            "OK.",
            "So as expected, it's a bit slower than I thought.",
            "So maybe I'll.",
            "Skip that.",
            "I think maybe I'll come back in the next lecture on this topic.",
            "So.",
            "So here are other ways in which we can improve the Union bound.",
            "So the first I recall the first step was finite union bound.",
            "Just log of the number of functions.",
            "The second step is to introduce these weights and we get log one over the weight.",
            "Then another thing you can do is to use the symmetrization trick and that was explained by John.",
            "I'm pretty sure.",
            "OK, so when you do that, the idea is that you introduce another set of data, so this is the ghost sample and you look at your functions class on this double sample on the initial sample and on the go sample and you just have to count how many functions you have when you look at them through projecting on the on this sample.",
            "And actually you can just perform a union bound on this restricted sets that you obtain, and that's why you obtain here instead of the number of function in your function class F, you obtain this N, which is the size or sorry, the you obtain the Cardinal of this set SN, which is the functions."
        ],
        [
            "Ejected on your ghost sample.",
            "OK, so that's also one way to improve the Union bound.",
            "But the problem is now that your set is.",
            "This set of functions here, this set of vectors I should say.",
            "Is something that has to be computed from the ghost sample and this goes sample does not exist right?",
            "That's why it's called ghosts, it's just.",
            "Is just something a mathematical device if you want.",
            "So.",
            "It's it's not.",
            "I mean you could do something like I take my training data.",
            "I split it into two and I just train on the first half and then compute the number of functions with using the second half.",
            "But then you don't use all the data for training, and that's not not so optimal.",
            "So usually what what people do is that the upper bound this using data independent quantities like the VC dimension.",
            "And this somehow in the similar.",
            "It's the similar the same ID.",
            "That again, you can look at it's enough somehow to look at the function class projected on this God sample.",
            "So you could say well instead of just doing the simple union bound of counting how many functions I have, I can be a bit more clever and introduce these weights again so you can introduce a weight."
        ],
        [
            "Function this big pie here.",
            "That's weights each function, and I put the ones in and so on to indicate that Now this this weight is allowed to depend on this double sample.",
            "Because again, because of symmetrization.",
            "So you can just do the symmetrization proof and when you do the Union bound introduced the weights and you will see that the weights can be introduced in such a way that they depend on the data and the ghost data.",
            "So again if you have a training sample you split it into two parts, you train on the 1st part and then you can say.",
            "And define your weights based on this data so.",
            "So you have a bit more flexibility here.",
            "You don't have to guess everything.",
            "You can say well given these data.",
            "Well, I think that given these data, my classifier will do.",
            "We will choose such and such a function and."
        ],
        [
            "This allows you to fine tune your weights according to your data so you have a data dependent weight.",
            "But OK, there is a catch of course.",
            "Again, it depends on this double sample, but also it has to depend in exchangeable way on this double sample so.",
            "You could say, well, let's let's just make it depend on the first half of the ghost sample.",
            "So then it does not depend on on the story of the first half of the double sample, so that it doesn't depend on the gas sample, but you're not allowed to do this because for the proof to go through, your weight has to depend on all the samples from Z12Z and prime.",
            "Otherwise, you're not able to symmetrize things.",
            "So it's it's a bit better, but not fully satisfactory, and Ann usually most approaches that are based on that many difficulties to relates what happened on the last sample to what happens on the initial sample.",
            "So then comes in the other trick to run macro average approach.",
            "So this is.",
            "Also, something that you have seen before.",
            "An using essentially mcdiarmid's inequality.",
            "You can show that for all functions, the difference between true and empirical error is bounded by this quantity here, which is called the Rainmaker average for the class F. Plus some term of order 1 / sqrt N. And this is.",
            "Actually, not a union bound.",
            "I mean there is no union bound here.",
            "It's purely deviation inequality, concentration, inequality.",
            "So where is the union bound?",
            "The union bound comes in when you want to actually compute the Rainmaker average or upper bound.",
            "The Rainmaker average, and again you can do the same thing you can, for example, of the finite case simpleminded union bound that would.",
            "Upper bound this run macro term by square root of log of number of functions divided by North, so you would recover the same type of bounds that we had before.",
            "But using.",
            "A different, slightly different approach.",
            "So but but the idea is that when you are at this stage, when you introduce this quantity, it seems that you are done because you have a bound.",
            "But most of the work remains to be done in bounding this run macro average.",
            "Of course there are situations where it's possible to do it more or less directly.",
            "But in most cases you have to.",
            "To actually do a union bound.",
            "And.",
            "So.",
            "One way to do this union bound so is to count the number of functions.",
            "But again, if you have infinitely many functions you cannot count, you have first to project.",
            "So you can say I project on the double sample and now the good thing is.",
            "Once you are the red marker level, so once you have done this.",
            "You already have done Symmetrization, and you have gotten rid of the ghost sample, so if you remember the proof of how to get here.",
            "You first have to introduce a ghost sample and then use the fact that goes sample.",
            "An initial sample can be exchanged and then you introduce the Rainmaker random variable.",
            "Sigma I data is or plus one or minus one depending on whether you leave the samples in the same position or whether you extend them.",
            "And.",
            "And then in the end you use the fact that the initial sample and the ghost sample of the same distribution to say that you can cut your run macro average into two pieces and the two pieces of the same distribution.",
            "So they are the same.",
            "OK you you can just look at the slides.",
            "But the idea is that.",
            "The good thing about this approach is that you can get rid of the ghost sample.",
            "So then you can do all these tricks again.",
            "But without the need for using those samples.",
            "So you can just count the number of functions that you obtain when you project your function class on the sample.",
            "And then just use this as a bound.",
            "Or you can use what are called covering numbers.",
            "What does it mean?",
            "It means instead of counting how many functions you have, you first create an approximation of your class with finitely many functions.",
            "And then you count how many functions you have in discover.",
            "But of course, since you approximate your class, you lose a little bit because you can say something about functions in that cover.",
            "But not all functions in your class.",
            "And the difference is the size of the approximation.",
            "So you pay a little bit for the error of approximation.",
            "But then you can say, well, why don't I just approximate again?",
            "So you first start with the big cover, so you just pick say one function and you say approximate my whole set of function by one function.",
            "And then I can have a very good bond because I just have one function.",
            "But I pay a term which correspond to more or less the radius of my function class and then at the second level you say.",
            "Well now I will approximate a bit more.",
            "I will put three functions, say and then again I pay a little bit and you can repeat this procedure of adding more and more functions to approximate your function class and what you obtain in the end is something that takes into account.",
            "The number of functions that are needed to approximate your function class up to a certain radius, and that's called covering number.",
            "So NF epsilon DN is the number of functions that you need to approximate your class F at the radius epsilon in the metric DN, which is the metric of vectors.",
            "Obtain when you project your function class on the data.",
            "So before doing all that, you because you are in the rainmaker setting, you just project through class or function on your data.",
            "You obtain a bunch of vectors which are 01 vectors because it's just the loss that you make on each data.",
            "And all these vectors you look at how they are spread.",
            "In terms of the metric, which correspond to just the Euclidean metric between vectors?",
            "Using.",
            "No, it's not.",
            "It's not necessary, just I mean it's basically a metric space problem.",
            "So you have a space of functions.",
            "You project that you obtain a set of vectors and now this set of vectors is a metric space endowed with the standard Euclidean distance and you try to find to compute the size of approximation to this metric space that you can construct with finite vectors.",
            "Finite number of vectors, and this is this term here and you just have to integrate it which corresponds to the idea that you look at all possible levels of approximation.",
            "Yes.",
            "Yes, but.",
            "Right?",
            "You can.",
            "Yes, yes, exactly, but but that's an interesting question because of course.",
            "You cannot always approximate an infinite set of function by finitely many functions, especially when you want to approximate very small, but this quantity here the integral of this log.",
            "May still converge.",
            "Because the problem is when epsilon gets small then this number may blow up, but as soon I mean as long as it doesn't increase too fast then you can still compute this integral.",
            "And for example, if you have a finite dimensional space.",
            "The number of balls that you need to cover a space of dimension D at radius epsilon is proportional to one over epsilon power D, right?",
            "So this goes to Infinity to Infinity very fast.",
            "When epsilon goes to 0.",
            "But still you can if you compute this integral, then it's finite and you can have much bigger spaces than this.",
            "You can have infinite in finite dimensional spaces and still have convergence of this integral.",
            "So as long as the covering numbers do not grow more than exponentially, then it's fine.",
            "Oh sorry, the log of the curving number do not grow more than exponential.",
            "Um?",
            "OK, and.",
            "And this is this is called somehow the global metric structure that you're capturing via discovering numbers an I'm a bit overtime so I will finish soon.",
            "Free.",
            "And there is a way to do something a bit more clever by instead of looking at covers of your space of functions that are global, which means globally in the sense that everywhere you want to approximate at a certain accuracy, you can do things a bit more local.",
            "And there is actually a quantity which is called.",
            "Um?",
            "Majorizing measure bound majorizing measure bound, which is written here.",
            "It's not very easy to explain, but let me just say that the idea is to instead of covering your space, you construct a partition of your space.",
            "Into finer and finer partitions.",
            "And you ensure that your partitions are certain.",
            "A certain diameter, so again, is the idea of bowls.",
            "You can think of bowls as a partition if you want.",
            "But in addition, you put weights on this partition, so again, this idea of waiting comes in, and that's why there is this pie here.",
            "So you put a probability distribution on your space of function and that gives a weights to each element of the partition.",
            "An by computing this quantity you have something that estimates the radmacher average, and that's actually if you choose these weights properly is equal up to a constant to the rainmaker average, which was not the case of this quantity here, which is covering numbers.",
            "So using covering numbers you can upper bound the Rainmaker average, but you lose something.",
            "Whereas if you introduce weights in addition to your doing discovering you can match the value of the ramaker average.",
            "So this is somehow the optimal way of performing this Union bound.",
            "And now I conclude with this take com messages again.",
            "So as I said in the beginning, we have these two ingredients in the bound, the deviation and the Union bound.",
            "This lecture was about the union bound.",
            "Next lecture will be about the deviations.",
            "The optimal way of performing the Union bound is to take into account the metric structure of your space of functions.",
            "After projecting on the data.",
            "That's called generic chaining.",
            "I did not mention it, but that was the title of the slide.",
            "You can introduce a prior into the bound and that's this weighting \u03c0.",
            "And that allows us to improve the Union bound and the best prior.",
            "As I said before, depends on the algorithm.",
            "And ideally you would like to estimate before hand.",
            "What's the function, which function will be chosen by the algorithm.",
            "And I do not talk about the park vision techniques, so I will not come back to this.",
            "So maybe in the next lecture.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm a bit frustrated because it seems that it was and it still is a nice place to be.",
                    "label": 0
                },
                {
                    "sent": "I wish I had stayed more and I would.",
                    "label": 0
                },
                {
                    "sent": "I wish I had more time to stay here so.",
                    "label": 0
                },
                {
                    "sent": "I have not attended Johns lectures, so there might be some overlap.",
                    "label": 0
                },
                {
                    "sent": "I went through the slides.",
                    "label": 0
                },
                {
                    "sent": "It seems that there is not too many too much overlap, but in case there is, feel free to let me know and feel free to tell me OK, John told everything about this so don't bother or.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Or if there is something that you that you feel would be nice, I don't know if John promised that I would talk about something, let me know as well.",
                    "label": 0
                },
                {
                    "sent": "So this is intended to be somehow the extension of John's lectures.",
                    "label": 0
                },
                {
                    "sent": "And I will go into more details about some specific aspects of learning theory.",
                    "label": 1
                },
                {
                    "sent": "There will be 4 lectures.",
                    "label": 0
                },
                {
                    "sent": "The first one will be about the Union bound.",
                    "label": 0
                },
                {
                    "sent": "Which is one key ingredients of obtaining bounds in learning theory and the second lecture will be about variance.",
                    "label": 1
                },
                {
                    "sent": "An local run maker averages, and this is the second key ingredients of statistical learning bounds.",
                    "label": 0
                },
                {
                    "sent": "And then there will be some sort of two other lectures will be about more about supplying the bounds to specific situations.",
                    "label": 0
                },
                {
                    "sent": "Lecture #3 will be about loss functions and how to adapt the bounds that we will see in the first 2 lectures that will be restricted to the binary classification case to more general setting still in classification, but where the loss function is a convex loss function.",
                    "label": 1
                },
                {
                    "sent": "And the first lecture will be some applications to SVM.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure we will be able to go all the way to the first one, so the end of the first lecture.",
                    "label": 0
                },
                {
                    "sent": "I will try to adapt the level so if there are something that are too easy or too difficult again, feel free to interrupt me and let me know.",
                    "label": 0
                },
                {
                    "sent": "So the plan for today is the following.",
                    "label": 0
                },
                {
                    "sent": "I will first recall briefly what is the setting that we are dealing with and.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Again, I will focus on binary classification.",
                    "label": 0
                },
                {
                    "sent": "In the statistical learning theory framework.",
                    "label": 1
                },
                {
                    "sent": "And I will.",
                    "label": 0
                },
                {
                    "sent": "Recall you what is the Union bound basic version of Union bound and then introduce more and more refinements about this Union bound.",
                    "label": 0
                },
                {
                    "sent": "Then another topic that we will talk about an that's explains the title pack Bayesian techniques is what is called random.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Classification, and that's where these pack vision bounds occurred first.",
                    "label": 0
                },
                {
                    "sent": "And then we'll see some other refinements, so it will be all about the Union bound.",
                    "label": 0
                },
                {
                    "sent": "OK, so maybe I'll introduce the setting again and then tell you what is a union one because it may not be obvious for all of you.",
                    "label": 0
                },
                {
                    "sent": "So the setting is quite classical.",
                    "label": 0
                },
                {
                    "sent": "I don't know if this works.",
                    "label": 0
                },
                {
                    "sent": "OK, so we have an input SpaceX and output Space Y.",
                    "label": 0
                },
                {
                    "sent": "And here as we are in classification setting our output space.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As only two possible two elements, it's plus one or minus one.",
                    "label": 0
                },
                {
                    "sent": "An the assumption that we make or the model or the way we model the problem is that we assume that we have a pair of random variables.",
                    "label": 0
                },
                {
                    "sent": "X&Y, that are.",
                    "label": 0
                },
                {
                    "sent": "I don't know if this is very convenient.",
                    "label": 0
                },
                {
                    "sent": "Maybe I should avoid it?",
                    "label": 0
                },
                {
                    "sent": "So we have a pair of random variables.",
                    "label": 0
                },
                {
                    "sent": "Maybe the mouse would do it.",
                    "label": 0
                },
                {
                    "sent": "Kind of everybody.",
                    "label": 0
                },
                {
                    "sent": "See the mouse.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So we have a pair XY.",
                    "label": 0
                },
                {
                    "sent": "An OK X belongs to our input space, which is anything any space.",
                    "label": 0
                },
                {
                    "sent": "And why is iser plus one or minus one, and this pair is assumed to be distributed according to some distribution which we call P, which is unknown.",
                    "label": 0
                },
                {
                    "sent": "An instead of knowing P, which would be ideal.",
                    "label": 0
                },
                {
                    "sent": "We observe a sequence.",
                    "label": 0
                },
                {
                    "sent": "Of North N is the sample size, IID pairs XI which are sampled according to this P. So we observe we get knowledge about this unknown probability distribution via the observation of these pairs XII.",
                    "label": 0
                },
                {
                    "sent": "This is our training sample.",
                    "label": 0
                },
                {
                    "sent": "And the goal is.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As usual.",
                    "label": 0
                },
                {
                    "sent": "To construct a function that allows to predict the output Y from the input X.",
                    "label": 0
                },
                {
                    "sent": "And this function we call G. It's usually called the classifier in this in this setting.",
                    "label": 0
                },
                {
                    "sent": "Ann, it's for any instance X in the input space.",
                    "label": 0
                },
                {
                    "sent": "It's Maps it to either plus one or minus one.",
                    "label": 0
                },
                {
                    "sent": "And it has to.",
                    "label": 0
                },
                {
                    "sent": "I mean, the goal is to build the function such that it is able to predict the random variable Y from the random variable X, which means an we have to define what what means predicting in this setting and predicting means making as few mistakes as possible.",
                    "label": 0
                },
                {
                    "sent": "And the way we measure the number of mistakes is via this formulation here.",
                    "label": 0
                },
                {
                    "sent": "We call that the risk and the risk is the probability that when we take a pair XY of random variables from this unknown P. And we try to predict Y from X using this function G. We make a mistake which means the predicted outcome is different from the one we observe.",
                    "label": 0
                },
                {
                    "sent": "An these probability of making mistakes can be written as the expected value of the indicate.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Or function so this one here with an.",
                    "label": 0
                },
                {
                    "sent": "With a subscript, here is the indicator function that this is true.",
                    "label": 0
                },
                {
                    "sent": "It's it takes value one when this is true and zero when it's not true and the expected value of such a function is nothing but the probability that the event is true.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is a bit of notation.",
                    "label": 0
                },
                {
                    "sent": "But it doesn't say anything complicated.",
                    "label": 0
                },
                {
                    "sent": "It just says that we want to find the function that makes few mistakes.",
                    "label": 0
                },
                {
                    "sent": "Now of course there are some issues and which explain why it's not an easy problem.",
                    "label": 0
                },
                {
                    "sent": "So first of all, as I told before, P is unknown, so we can't.",
                    "label": 0
                },
                {
                    "sent": "We can't even define this quantity or can't even compute it.",
                    "label": 0
                },
                {
                    "sent": "So this is already a big problem.",
                    "label": 0
                },
                {
                    "sent": "And the only thing we can do instead is to use our training data to measure at least the agreements of our classifier with this training data, which is called usually the empirical risk or empirical error, and this is nothing but the empirical average or empirical expectation of the error function.",
                    "label": 0
                },
                {
                    "sent": "This indicator function computed on our sample, so we just count how many mistakes we make on our sample.",
                    "label": 0
                },
                {
                    "sent": "We divide this by the sample size.",
                    "label": 0
                },
                {
                    "sent": "And this gives us a number, and this is called the empirical error.",
                    "label": 0
                },
                {
                    "sent": "And of course, it's a good idea to have a small empirical error, or to find a function G which has a small empirical error.",
                    "label": 0
                },
                {
                    "sent": "And usually we hope that when this empirical error is small, then the true risk.",
                    "label": 1
                },
                {
                    "sent": "Or expected risk?",
                    "label": 0
                },
                {
                    "sent": "Will be also small.",
                    "label": 0
                },
                {
                    "sent": "And the whole goal of this statistical learning theory is to quantify how much we.",
                    "label": 1
                },
                {
                    "sent": "How wrong we are in assuming that when this empirical risk will be small, the true risk will also be small.",
                    "label": 0
                },
                {
                    "sent": "And for that we the theory aims at producing bounds, which are statements that tell you how far you are.",
                    "label": 0
                },
                {
                    "sent": "When you think that your true error is is small because your empirical error is small.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Again, some notation that I introduce here.",
                    "label": 0
                },
                {
                    "sent": "So we have this training data X IX1Y12X NYN and we produce a function GN.",
                    "label": 0
                },
                {
                    "sent": "So whenever I put a small.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Subscript N here it means a quantity that depends on the data that we have determined after seeing the data.",
                    "label": 0
                },
                {
                    "sent": "So GN means the classifier that we constructed after we have seen the data.",
                    "label": 0
                },
                {
                    "sent": "So we produce this classifier GN.",
                    "label": 0
                },
                {
                    "sent": "And the question is, how can we estimate the risk of this classifier?",
                    "label": 0
                },
                {
                    "sent": "And of course.",
                    "label": 0
                },
                {
                    "sent": "And that's why this N here.",
                    "label": 0
                },
                {
                    "sent": "I mean why I put this in here in order not to forget that this is a random quantity, because it depends on the data and our basic assumption is that this data is a random sample from a distribution.",
                    "label": 0
                },
                {
                    "sent": "So we need what are called probabilistic bounds.",
                    "label": 0
                },
                {
                    "sent": "We cannot make any.",
                    "label": 0
                },
                {
                    "sent": "Absolute statements we can only say that because of this model that we have.",
                    "label": 0
                },
                {
                    "sent": "Because we assume that the data is sampled IID from a certain distribution which never changes.",
                    "label": 0
                },
                {
                    "sent": "Then there is some chance, some probability.",
                    "label": 0
                },
                {
                    "sent": "That's what we observe on the data will be close to what we would observe if we had infinite infinite amount of data.",
                    "label": 0
                },
                {
                    "sent": "And that's what is called probabilistic bounds.",
                    "label": 0
                },
                {
                    "sent": "And of course you're already have seen some probabilistic bounds in John's lecture and maybe.",
                    "label": 0
                },
                {
                    "sent": "All this is clear to you, but I want to reset the.",
                    "label": 0
                },
                {
                    "sent": "The setting.",
                    "label": 0
                },
                {
                    "sent": "OK, so there are two types.",
                    "label": 0
                },
                {
                    "sent": "Two big two main types of.",
                    "label": 0
                },
                {
                    "sent": "Probabilistic bounds that we can derive the first type is of the of the following form we upper bound.",
                    "label": 0
                },
                {
                    "sent": "So all this is with a certain probability, so with high probability on the random sampling of the sample, we provide an upper bound on the true risk R of GN of our classifier that we constructed from the data.",
                    "label": 0
                },
                {
                    "sent": "Here.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "From the empirical error of this same classifier plus some quantity, some quantity which is actually the bound which is this B here.",
                    "label": 0
                },
                {
                    "sent": "And these tales that.",
                    "label": 0
                },
                {
                    "sent": "The true error can be.",
                    "label": 0
                },
                {
                    "sent": "As big as the empirical error plus some penalty.",
                    "label": 0
                },
                {
                    "sent": "And this this type of bound allows us to estimate from above the true risk from an empirical version of this risk.",
                    "label": 0
                },
                {
                    "sent": "The other type of bond also gives an estimate from above of the true risk, but from other quantities.",
                    "label": 0
                },
                {
                    "sent": "Usually non empirical quantities.",
                    "label": 0
                },
                {
                    "sent": "So there are two, two big again.",
                    "label": 0
                },
                {
                    "sent": "Two types, the first type is.",
                    "label": 0
                },
                {
                    "sent": "You compare the true risk to the risk of the best classifier in a given class.",
                    "label": 0
                },
                {
                    "sent": "And the second type is that you compare the true risk of your constructed classifier to the best of all classifiers, which is called the Bayes classifier usually, and these are star means the best risk you could obtain from function from X to Y.",
                    "label": 0
                },
                {
                    "sent": "So you just construct the best function and the best function usually is.",
                    "label": 0
                },
                {
                    "sent": "The function that predicts plus one when the probability of being off.",
                    "label": 0
                },
                {
                    "sent": "Why OK, maybe I should write it.",
                    "label": 0
                },
                {
                    "sent": "But I don't know if it will be seen in singable from everywhere.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Again, we have this probability distribution XY.",
                    "label": 0
                },
                {
                    "sent": "If we look at the probability.",
                    "label": 0
                },
                {
                    "sent": "Of why being equals to one.",
                    "label": 0
                },
                {
                    "sent": "Given X, so at a specific location in our input space, we look at what is the probability that at this location Y is equal to 1.",
                    "label": 0
                },
                {
                    "sent": "So what is the probability that the label of these points is equal to 1?",
                    "label": 0
                },
                {
                    "sent": "And then we look at whether this probability is larger or not done 1/2 then this gives us what is called the base classifier, which means whenever this is true whenever this property is larger than 1/2, we predict with one and whenever it's less than 1/2, we predict with minus one.",
                    "label": 0
                },
                {
                    "sent": "And this is the optimal thing that we could do with a deterministic function.",
                    "label": 0
                },
                {
                    "sent": "And the risk of this classifier is this R star here.",
                    "label": 0
                },
                {
                    "sent": "And of course, it's interesting to know if you can provide such a bound.",
                    "label": 0
                },
                {
                    "sent": "Then it tells you, OK, you have built a classifier from the data and your that's far from doing the best thing.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Could do.",
                    "label": 0
                },
                {
                    "sent": "So this provides us theoretical guarantees.",
                    "label": 0
                },
                {
                    "sent": "On the algorithm that we construct.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Again, notation was.",
                    "label": 0
                },
                {
                    "sent": "It's a bit confusing maybe.",
                    "label": 0
                },
                {
                    "sent": "But OK, the goal is to simplify things.",
                    "label": 0
                },
                {
                    "sent": "So we have these two variables X&Y and we just call these pairs Y. OK. Now there are two concepts that I will go back and forth from.",
                    "label": 0
                },
                {
                    "sent": "The first one is called hypothesis, hypothesis class or function class.",
                    "label": 0
                },
                {
                    "sent": "Or classifier class whatever and it's the set of all possible classifiers that we consider at when we construct.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "An algorithm.",
                    "label": 0
                },
                {
                    "sent": "And it contains function that map the input space to.",
                    "label": 0
                },
                {
                    "sent": "OK, usually plus one or minus one, but it could be more general.",
                    "label": 0
                },
                {
                    "sent": "It could map to any real number.",
                    "label": 0
                },
                {
                    "sent": "OK, so whenever I write G, it means a classifier function that predicts.",
                    "label": 0
                },
                {
                    "sent": "Some value for all inputs.",
                    "label": 0
                },
                {
                    "sent": "And when I write F then it's not the function that predicts but the function that computes the error of a given classifier.",
                    "label": 0
                },
                {
                    "sent": "So the way you construct these functions, F is that you so F is defined on the pair XY and it computes the error of the classifier G on the pair XY.",
                    "label": 0
                },
                {
                    "sent": "It compares G of X&Y and it puts that into this L, which is a loss function which in our case so far is.",
                    "label": 0
                },
                {
                    "sent": "The indicator of that that G of X is different from Y, and this gives us a number and this is the value that we assign to F of Z. OK, so we have two ways of looking at the same thing.",
                    "label": 0
                },
                {
                    "sent": "Either we look at the classifier and.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Look at the predictions made by made by this classifier.",
                    "label": 0
                },
                {
                    "sent": "That's G&G of X.",
                    "label": 0
                },
                {
                    "sent": "Or we look at the error made by this classifier, which means we look at the pair XY.",
                    "label": 0
                },
                {
                    "sent": "We predict with G of X and we compare the FX with Y and that's F of Z or F of XY.",
                    "label": 0
                },
                {
                    "sent": "And OK, there is another way, which is we can even look not directly at the error of the classifier, but at the error of the classifier compared to the error of the best classifier.",
                    "label": 0
                },
                {
                    "sent": "And that's the relative loss which is written.",
                    "label": 0
                },
                {
                    "sent": "Here is the difference between the lots, sorry.",
                    "label": 0
                },
                {
                    "sent": "Of our classifier minus the loss of the best classifier, what happens, sorry.",
                    "label": 0
                },
                {
                    "sent": "OK, Ann, why do I do all this?",
                    "label": 0
                },
                {
                    "sent": "The main reason is that it allows me to treat everything as expectations.",
                    "label": 0
                },
                {
                    "sent": "Recall that I told you that the error of the classifier is just the expectation of the loss function or the indicator function that it makes some mistakes.",
                    "label": 0
                },
                {
                    "sent": "So now now that I have introduced this notation, FI can rewrite the risk of a given classifier G as the expected value of the corresponding F. Right and same thing for the empirical risk RN of G. It's the empirical average of F of Z.",
                    "label": 1
                },
                {
                    "sent": "And to denote sexpectations I use P of F. So PF means expectation with respect to P of the function F&PNF means expectation computed on the sample so empirical average.",
                    "label": 1
                },
                {
                    "sent": "OK, so that allows me to have somehow simpler notation in the rest.",
                    "label": 0
                },
                {
                    "sent": "OK, so now that I've introduced all this notation and I hope it's more less clear.",
                    "label": 0
                },
                {
                    "sent": "Let's get to the topic.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "If there is anything that you should recall from this lecture is what is written on these slides.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "I will detail this in the remaining of the lecture, but I want to give you a first overview of that.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So there are two main ingredients.",
                    "label": 0
                },
                {
                    "sent": "When you build a bounds, the first one is deviation inequality, which tells you how far can be a random quantity from its expectation, and you have probably seen many of those in Johns lectures, which are called usually concentration inequalities.",
                    "label": 0
                },
                {
                    "sent": "And the other ingredients is what is called a union bound, and it allows you to treat not just one random variable at a time, but a collection of random variables.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So you have these two things you first have to say.",
                    "label": 0
                },
                {
                    "sent": "Well, for each of my random variables there is such and such a probability that it deviates from its expectation.",
                    "label": 0
                },
                {
                    "sent": "But then when you look at many random variables at the same time, for example, when you look at all the functions that you have in your function class.",
                    "label": 0
                },
                {
                    "sent": "Then you need to be able to say something about collectively all these random variables.",
                    "label": 0
                },
                {
                    "sent": "And that's what is a union bound.",
                    "label": 0
                },
                {
                    "sent": "Anne Anne.",
                    "label": 0
                },
                {
                    "sent": "The optimal way of.",
                    "label": 0
                },
                {
                    "sent": "Performing such a union bound, so performing union bound means telling something about a collection of random variables.",
                    "label": 0
                },
                {
                    "sent": "From a statement on each of the random variables.",
                    "label": 0
                },
                {
                    "sent": "So the optimal way of doing this is by using the metric structure of your space of random variables, and then I will explain what this means in more detail later.",
                    "label": 0
                },
                {
                    "sent": "But that's the idea.",
                    "label": 0
                },
                {
                    "sent": "So when you have several random variables, the main thing that you have to look at is how they are structured and how they relate to each other.",
                    "label": 0
                },
                {
                    "sent": "And once you know how they relate to each other, then you can say something about their global behavior.",
                    "label": 0
                },
                {
                    "sent": "Another thing which is quite interesting an that you have to recall is that it is possible.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To introduce what is called prior, but it's quite different from what visions would call prior.",
                    "label": 0
                },
                {
                    "sent": "It's mostly a technical tool, but you can introduce a prior into union bounds, and you can actually tweak the Union bound in certain ways according to what you think is more likely to happen.",
                    "label": 0
                },
                {
                    "sent": "When you have data.",
                    "label": 0
                },
                {
                    "sent": "And the last thing is that the last thing that you have you have to record from this lecture is that there is this so called pack vision technique that will present.",
                    "label": 0
                },
                {
                    "sent": "And the main aspect of this pack vision technique is that it allows you to improve the Union bound when you average over several classifiers.",
                    "label": 0
                },
                {
                    "sent": "OK, and this will be clear in a minute.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's start again with deviation inequalities.",
                    "label": 0
                },
                {
                    "sent": "So this is the most straightforward inequality I would say.",
                    "label": 0
                },
                {
                    "sent": "OK, the notation may not be familiar to you, especially that it's quite different from John's notation, but I will try to explain.",
                    "label": 0
                },
                {
                    "sent": "So what it tells you is that.",
                    "label": 0
                },
                {
                    "sent": "The expectation of a function.",
                    "label": 0
                },
                {
                    "sent": "Minus the empirical expectation of a function is upper bounded by such a quantity here.",
                    "label": 0
                },
                {
                    "sent": "And OK. You you should recall that P of F is nothing but the risk of a certain classifier and PFF is the empirical risk.",
                    "label": 1
                },
                {
                    "sent": "So this bound tells you what is the difference between the true empirical risk of a given classifier.",
                    "label": 0
                },
                {
                    "sent": "And what it tells you is that with a high probability.",
                    "label": 0
                },
                {
                    "sent": "Delta is usually a small quantity.",
                    "label": 0
                },
                {
                    "sent": "This difference is bounded by a certain constant Times Square root.",
                    "label": 0
                },
                {
                    "sent": "Of this log, one over Delta divided by N. So essentially 1 / sqrt N. So that's one thing that you should always have in mind when you look at an empirical average and you want to compare it with the true average.",
                    "label": 0
                },
                {
                    "sent": "For a fixed function.",
                    "label": 0
                },
                {
                    "sent": "F. This is fixed.",
                    "label": 0
                },
                {
                    "sent": "This quantity, when the function is bounded at least.",
                    "label": 0
                },
                {
                    "sent": "These quantities of order 1 / sqrt N OK that's easy, straightforward and always true.",
                    "label": 0
                },
                {
                    "sent": "So with high probability the difference between those two quantities of order 1 / sqrt N. So that's called object inequality and OK, I should have written somewhere that it requires boundedness of the function.",
                    "label": 0
                },
                {
                    "sent": "So now this is fine for one function, but usually you have many functions to choose from.",
                    "label": 0
                },
                {
                    "sent": "Your algorithm is not restricted to always use the same classifier at each time every time it sees new data, it is allowed to pick a different function.",
                    "label": 1
                },
                {
                    "sent": "So you usually have a set of possible functions and your classifier look at the data, tries to find the best one in these sets with respect to the empirical error.",
                    "label": 0
                },
                {
                    "sent": "So the first thing we can assume is let's see what happens when the set of functions we have is finite.",
                    "label": 0
                },
                {
                    "sent": "So assume you have a classifier that just as a finite set of function and picks one from them from this set.",
                    "label": 0
                },
                {
                    "sent": "Then you need a statement that somehow.",
                    "label": 0
                },
                {
                    "sent": "Is the uniform equivalent of holding in quality because you know that for each individual function you know how to bound the difference between true and empirical risk, but these bound is probabilistic, which means that for certain samples.",
                    "label": 0
                },
                {
                    "sent": "This will be true.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But for other samples, it won't be true because only for a fraction 1 minus Delta of them is true.",
                    "label": 0
                },
                {
                    "sent": "So now if you look at at other functions, maybe if you look at so this is F. Let's say we look at F prime, maybe 4F prime.",
                    "label": 0
                },
                {
                    "sent": "The difference is less than 1 / sqrt N for some samples and bigger for other samples.",
                    "label": 0
                },
                {
                    "sent": "But the samples on which it is small may not be the same done for F. So for each different function.",
                    "label": 0
                },
                {
                    "sent": "In your class, you may have different samples for which this bound is valid, and different samples for which it is not valid.",
                    "label": 0
                },
                {
                    "sent": "And so you don't know how many in the end.",
                    "label": 0
                },
                {
                    "sent": "Are such that all the functions?",
                    "label": 0
                },
                {
                    "sent": "Are within that range.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's why you need to perform this Union bound and.",
                    "label": 0
                },
                {
                    "sent": "I've not detailed a way to do it because I thought John did, but maybe not.",
                    "label": 0
                },
                {
                    "sent": "Maybe I can write it quickly.",
                    "label": 0
                },
                {
                    "sent": "I think there was something about this, but maybe not written in this form in his slides.",
                    "label": 0
                },
                {
                    "sent": "OK, but anyway.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We start with Heddings inequality that tells us that.",
                    "label": 0
                },
                {
                    "sent": "For a given function, the probability under the sampling that.",
                    "label": 0
                },
                {
                    "sent": "The difference between PF&PNF.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's a bit misleading because this is a probability, so maybe I should write with two bars here and this is expectation of F. So the probability that the true expectation minus the empirical expectation.",
                    "label": 0
                },
                {
                    "sent": "Being larger than.",
                    "label": 0
                },
                {
                    "sent": "Square root log one over Delta over N with some constants.",
                    "label": 0
                },
                {
                    "sent": "This is less than Delta.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's one way of writing has inequality.",
                    "label": 0
                },
                {
                    "sent": "The probability that the deviation is large is small.",
                    "label": 0
                },
                {
                    "sent": "So now you can write this for several different functions.",
                    "label": 0
                },
                {
                    "sent": "So you write it for.",
                    "label": 0
                },
                {
                    "sent": "So this is F1C and then you write it for F2.",
                    "label": 0
                },
                {
                    "sent": "Based on Delta and so on, and then you want to say something about.",
                    "label": 0
                },
                {
                    "sent": "The probability that OK, so the bond we want is something that tells us that gives us a guarantee for all functions simultaneously.",
                    "label": 0
                },
                {
                    "sent": "So we want to say that for all functions the difference will be small, so we have to bound the probability that this difference will be large.",
                    "label": 0
                },
                {
                    "sent": "So which means that the probability that there exists one function for which the difference will be large, right?",
                    "label": 0
                },
                {
                    "sent": "It's the opposite thing that we want to quantify.",
                    "label": 0
                },
                {
                    "sent": "An now we have we know how to bound each individual probability and we just have to say what is the probability that one of these events will be realized.",
                    "label": 0
                },
                {
                    "sent": "So one of these function will deviate more than a certain quantity.",
                    "label": 0
                },
                {
                    "sent": "Which means we have to bound the probability of the disjunctions of the events A or B.",
                    "label": 0
                },
                {
                    "sent": "An probability that of A or B.",
                    "label": 0
                },
                {
                    "sent": "Is upper bounded by the probability of a plus probability of B?",
                    "label": 0
                },
                {
                    "sent": "Right, that's basic knowledge of probability.",
                    "label": 0
                },
                {
                    "sent": "So if we apply this to this case, then the probability that eiser function one as a large deviation or function 2 as a large deviation is less than the sum of the two probabilities, which is 2D, right?",
                    "label": 0
                },
                {
                    "sent": "So that's how it works.",
                    "label": 0
                },
                {
                    "sent": "So if you have any functions, then you just have to replace Delta by end times Delta.",
                    "label": 0
                },
                {
                    "sent": "And if you do that and you write the bounds in this way, then it tells you that with probability 1 minus Delta.",
                    "label": 0
                },
                {
                    "sent": "For all functions simultaneously in your class F, the deviation between true and empirical error is bounded by this quantity, so.",
                    "label": 0
                },
                {
                    "sent": "Actually, I increased Delta by factor F and that gives me this.",
                    "label": 0
                },
                {
                    "sent": "Or sorry I should say.",
                    "label": 0
                },
                {
                    "sent": "OK, if you look at here, the probability will be less than two Delta, but then you just rename 2D into Delta and that's that.",
                    "label": 0
                },
                {
                    "sent": "Corresponds to devising Delta by by two.",
                    "label": 0
                },
                {
                    "sent": "OK well just have to write it.",
                    "label": 0
                },
                {
                    "sent": "Sorry for not being clear here.",
                    "label": 0
                },
                {
                    "sent": "But in the end, OK, the important thing is that the bound has increased a little bit because you have lost some.",
                    "label": 0
                },
                {
                    "sent": "Some confidence in a way, because you're looking at many different functions at the same time, and any of them could deviate.",
                    "label": 0
                },
                {
                    "sent": "So the bound is a bit worse and how much worse is it?",
                    "label": 0
                },
                {
                    "sent": "It's worse by this log of size of this class of function term.",
                    "label": 0
                },
                {
                    "sent": "And you can think of this term as a variance in a way.",
                    "label": 0
                },
                {
                    "sent": "The more functions you have, the more variability you have, because not only can the empirical average deviate from the true average, but also you can choose different functions.",
                    "label": 0
                },
                {
                    "sent": "So this adds some variability to your random quantity.",
                    "label": 0
                },
                {
                    "sent": "And another way to think of this log of size of function class.",
                    "label": 0
                },
                {
                    "sent": "Is as a measure of the function Class A measure with respect to random fluctuation of a quantity.",
                    "label": 0
                },
                {
                    "sent": "And you have seen in John's lectures many other measures of size of a function class, the VC dimension or probably using covering numbers.",
                    "label": 0
                },
                {
                    "sent": "The fat shattering dimension.",
                    "label": 0
                },
                {
                    "sent": "Anne Radmacher averages.",
                    "label": 0
                },
                {
                    "sent": "So all these quantities are quantities that measure the size of a function class, and the log of number of functions is the most basic one.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so this is for the University, I don't know.",
                    "label": 0
                },
                {
                    "sent": "Is it clear for everybody?",
                    "label": 0
                },
                {
                    "sent": "Are there any difficulties here?",
                    "label": 0
                },
                {
                    "sent": "No, no see means are constants here.",
                    "label": 0
                },
                {
                    "sent": "Yeah OK you could, yeah, but this is true for each.",
                    "label": 0
                },
                {
                    "sent": "N. Big OL would be somehow in the limit so.",
                    "label": 0
                },
                {
                    "sent": "This is true for each possible value of N. An yeah and the constant here does not depend on anything.",
                    "label": 0
                },
                {
                    "sent": "It doesn't depend on the size of the class of function.",
                    "label": 1
                },
                {
                    "sent": "It doesn't depend on Delta, and independent doesn't depend on.",
                    "label": 0
                },
                {
                    "sent": "OK, and usually OK in this specific case it's something like 2.",
                    "label": 0
                },
                {
                    "sent": "But it depends on the bound that you have on your class or function, but usually the loss is between zero and one and then sees something like 2.",
                    "label": 1
                },
                {
                    "sent": "OK, so the next thing you can do, and that's I'm pretty sure that was mentioned, at least in John's lecture.",
                    "label": 0
                },
                {
                    "sent": "Is that you can somehow wait all your function in a different way when you perform the Union bound.",
                    "label": 0
                },
                {
                    "sent": "So here I had written the same bound for each function, but I can slightly modify the bound that I write for each function and especially I can have.",
                    "label": 0
                },
                {
                    "sent": "A different Delta for each such bound, so I can write here D1 and here D2.",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 0
                },
                {
                    "sent": "I can just do the same thing, the same union bound and what I get is that now my Delta depends on the function.",
                    "label": 0
                },
                {
                    "sent": "And it depends in in in the following way.",
                    "label": 0
                },
                {
                    "sent": "Essentially, we have to make sure that all these Del stars that we've right here when we sum them up we have something which is which is still small, which is still a Delta.",
                    "label": 0
                },
                {
                    "sent": "So we just have to make sure that D1 plus D2.",
                    "label": 0
                },
                {
                    "sent": "Equals Delta for example, right?",
                    "label": 1
                },
                {
                    "sent": "So you just pick 2, two numbers D1 and D2 such that their sum is equal to Delta and then.",
                    "label": 0
                },
                {
                    "sent": "We can do the same thing and gets the bound that tells you that with probability 1 minus Delta we have this.",
                    "label": 0
                },
                {
                    "sent": "At most this deviation.",
                    "label": 0
                },
                {
                    "sent": "And OK here that would be a log one over D1 or one log one over D2 depending on the function.",
                    "label": 0
                },
                {
                    "sent": "And I just written this, I just separated the term Pi of F from the Delta, so and that's not clear again because I skipped a lot of details.",
                    "label": 0
                },
                {
                    "sent": "Essentially, the easiest way to have a sum of deltas that is equal to Delta is to take a probability distribution over.",
                    "label": 0
                },
                {
                    "sent": "Over your class of functions.",
                    "label": 0
                },
                {
                    "sent": "So for each function.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You have a number \u03c0 of F. Such that the sum of this pie of F, this number is non negative and the sum of this part of F is equal to 1.",
                    "label": 0
                },
                {
                    "sent": "So that's a probability distribution on your class of function.",
                    "label": 0
                },
                {
                    "sent": "And once you have this, you just write the hovding bound for each function with Delta times \u03c0 of F. And when you will sum all these things, then you will get Delta, that's that.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And that's why you get log of 1 / \u03c0 of F here.",
                    "label": 0
                },
                {
                    "sent": "And in the simple case where you put equal weight to all functions, Pi of F is one over the number of functions, so log 1 / \u03c0 of F is just log of the number of functions.",
                    "label": 0
                },
                {
                    "sent": "And you recover the previous bound, but but you could imagine to put a different weight on different functions.",
                    "label": 0
                },
                {
                    "sent": "And then you would get a different bound, and that's a bit surprising, because you can say well.",
                    "label": 0
                },
                {
                    "sent": "What if I put all the weight on one specific function, then I get to a bound which is as good as the acting bound.",
                    "label": 0
                },
                {
                    "sent": "But the problem is, and that's where there is a trick.",
                    "label": 0
                },
                {
                    "sent": "This specific probability distribution by of F has to be chosen before you see the data, so it cannot be a random distribution here.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Even if you knew in advance, well, even if you guess in advance what will be the classifier picked by your algorithm.",
                    "label": 0
                },
                {
                    "sent": "And you know, I mean, OK, sorry.",
                    "label": 0
                },
                {
                    "sent": "You can either you can guess before seeing the data what will be the classifier picked by your algorithm, and in that case you could put all the probability mass on this classifier and then you get a super good bound.",
                    "label": 0
                },
                {
                    "sent": "But in general, you don't know before hand before seeing the data, you don't know whether the hyperplane will be like this or like this.",
                    "label": 0
                },
                {
                    "sent": "Alright, so that's why you cannot really hope to improve your bound by picking the right distribution.",
                    "label": 0
                },
                {
                    "sent": "But still.",
                    "label": 0
                },
                {
                    "sent": "Still, you can hope to do something because.",
                    "label": 0
                },
                {
                    "sent": "You can have an idea about how your algorithm, sorry.",
                    "label": 0
                },
                {
                    "sent": "About how your algorithm will behave.",
                    "label": 0
                },
                {
                    "sent": "For example, you know that.",
                    "label": 0
                },
                {
                    "sent": "In general, your algorithm tries to minimize the empirical error, so it will try to find functions that have low empirical error.",
                    "label": 0
                },
                {
                    "sent": "Or you know that it maximizes the margin, so you know that you can put more weight on the functions that have a large margin because those are more likely to be chosen by your algorithm.",
                    "label": 0
                },
                {
                    "sent": "And if you do that, you put more weight on these functions, then you decrease the log 1 / \u03c0.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Term so you get a better bounds for those functions.",
                    "label": 0
                },
                {
                    "sent": "So you can imagine to put here something that would be proportional to the margin, and then you get a bound that tells you well whenever the margin is large, then the bound is small.",
                    "label": 0
                },
                {
                    "sent": "And why?",
                    "label": 0
                },
                {
                    "sent": "Because I assume that the algorithm will pick functions with large margin.",
                    "label": 0
                },
                {
                    "sent": "But of course if it happens that when I train my classifier on my data, I get a small margin, then the bounding is bad.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "It's just the best that you make before before running your classifier.",
                    "label": 0
                },
                {
                    "sent": "Your algorithm.",
                    "label": 0
                },
                {
                    "sent": "You just bet that the classifier will have such a margin, and if you bet, I mean if you are successful then you have a good bound.",
                    "label": 0
                },
                {
                    "sent": "And if you're not then the bound is worse.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "You cannot hope to have always a good bond.",
                    "label": 0
                },
                {
                    "sent": "Yeah yeah, I mean there is no restriction.",
                    "label": 0
                },
                {
                    "sent": "OK here, The thing is.",
                    "label": 0
                },
                {
                    "sent": "If you have, I mean this only works for example, if you have a countable class of functions, because otherwise you're.",
                    "label": 0
                },
                {
                    "sent": "Let's say the probability of a single function is zero always when you have a continuous distribution, so this log 1, /, \u03c0 blows up and you have a bound that is useless.",
                    "label": 0
                },
                {
                    "sent": "But but at least if you have accountable class of function, you can take any any probability distribution.",
                    "label": 0
                },
                {
                    "sent": "But most often it's hard to define such a probability distribution.",
                    "label": 0
                },
                {
                    "sent": "OK, so so this.",
                    "label": 0
                },
                {
                    "sent": "Again, summarizes these considerations.",
                    "label": 0
                },
                {
                    "sent": "So pie here is is not.",
                    "label": 0
                },
                {
                    "sent": "I mean, it's different from a Bayesian prior in the sense that it's not that we hope that our function is chosen from a probability distribution Pi by some device.",
                    "label": 0
                },
                {
                    "sent": "But we just make a bet.",
                    "label": 0
                },
                {
                    "sent": "We just say, OK, let's pick some distribution an if we have.",
                    "label": 0
                },
                {
                    "sent": "If we are lucky then our bond will be good and if not then it will be bad.",
                    "label": 0
                },
                {
                    "sent": "But it has nothing to do with the process of generating the data or generating the function itself.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "OK, so if you want to have a good bound, So what would be the ideal probability distribution or ideal waiting?",
                    "label": 0
                },
                {
                    "sent": "The ideal waiting is such that.",
                    "label": 0
                },
                {
                    "sent": "Each function is assigned a weight that correspond to how likely it is to be chosen by your algorithm on the specific data that you have.",
                    "label": 0
                },
                {
                    "sent": "So if you were able to sample repeatedly the data.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Train your classifier.",
                    "label": 0
                },
                {
                    "sent": "Look at the function that is chosen and if you were able to do this many times then you would obtain the ideal or optimal probability distribution by.",
                    "label": 0
                },
                {
                    "sent": "But of course, again, it's not possible to do this.",
                    "label": 0
                },
                {
                    "sent": "That's why you somehow have to guess this pie before hand.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So as expected, it's a bit slower than I thought.",
                    "label": 0
                },
                {
                    "sent": "So maybe I'll.",
                    "label": 0
                },
                {
                    "sent": "Skip that.",
                    "label": 0
                },
                {
                    "sent": "I think maybe I'll come back in the next lecture on this topic.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So here are other ways in which we can improve the Union bound.",
                    "label": 0
                },
                {
                    "sent": "So the first I recall the first step was finite union bound.",
                    "label": 0
                },
                {
                    "sent": "Just log of the number of functions.",
                    "label": 0
                },
                {
                    "sent": "The second step is to introduce these weights and we get log one over the weight.",
                    "label": 0
                },
                {
                    "sent": "Then another thing you can do is to use the symmetrization trick and that was explained by John.",
                    "label": 0
                },
                {
                    "sent": "I'm pretty sure.",
                    "label": 0
                },
                {
                    "sent": "OK, so when you do that, the idea is that you introduce another set of data, so this is the ghost sample and you look at your functions class on this double sample on the initial sample and on the go sample and you just have to count how many functions you have when you look at them through projecting on the on this sample.",
                    "label": 0
                },
                {
                    "sent": "And actually you can just perform a union bound on this restricted sets that you obtain, and that's why you obtain here instead of the number of function in your function class F, you obtain this N, which is the size or sorry, the you obtain the Cardinal of this set SN, which is the functions.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Ejected on your ghost sample.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's also one way to improve the Union bound.",
                    "label": 0
                },
                {
                    "sent": "But the problem is now that your set is.",
                    "label": 0
                },
                {
                    "sent": "This set of functions here, this set of vectors I should say.",
                    "label": 0
                },
                {
                    "sent": "Is something that has to be computed from the ghost sample and this goes sample does not exist right?",
                    "label": 0
                },
                {
                    "sent": "That's why it's called ghosts, it's just.",
                    "label": 0
                },
                {
                    "sent": "Is just something a mathematical device if you want.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "It's it's not.",
                    "label": 0
                },
                {
                    "sent": "I mean you could do something like I take my training data.",
                    "label": 0
                },
                {
                    "sent": "I split it into two and I just train on the first half and then compute the number of functions with using the second half.",
                    "label": 0
                },
                {
                    "sent": "But then you don't use all the data for training, and that's not not so optimal.",
                    "label": 0
                },
                {
                    "sent": "So usually what what people do is that the upper bound this using data independent quantities like the VC dimension.",
                    "label": 0
                },
                {
                    "sent": "And this somehow in the similar.",
                    "label": 0
                },
                {
                    "sent": "It's the similar the same ID.",
                    "label": 0
                },
                {
                    "sent": "That again, you can look at it's enough somehow to look at the function class projected on this God sample.",
                    "label": 0
                },
                {
                    "sent": "So you could say well instead of just doing the simple union bound of counting how many functions I have, I can be a bit more clever and introduce these weights again so you can introduce a weight.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Function this big pie here.",
                    "label": 0
                },
                {
                    "sent": "That's weights each function, and I put the ones in and so on to indicate that Now this this weight is allowed to depend on this double sample.",
                    "label": 0
                },
                {
                    "sent": "Because again, because of symmetrization.",
                    "label": 0
                },
                {
                    "sent": "So you can just do the symmetrization proof and when you do the Union bound introduced the weights and you will see that the weights can be introduced in such a way that they depend on the data and the ghost data.",
                    "label": 1
                },
                {
                    "sent": "So again if you have a training sample you split it into two parts, you train on the 1st part and then you can say.",
                    "label": 0
                },
                {
                    "sent": "And define your weights based on this data so.",
                    "label": 0
                },
                {
                    "sent": "So you have a bit more flexibility here.",
                    "label": 0
                },
                {
                    "sent": "You don't have to guess everything.",
                    "label": 0
                },
                {
                    "sent": "You can say well given these data.",
                    "label": 0
                },
                {
                    "sent": "Well, I think that given these data, my classifier will do.",
                    "label": 1
                },
                {
                    "sent": "We will choose such and such a function and.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This allows you to fine tune your weights according to your data so you have a data dependent weight.",
                    "label": 0
                },
                {
                    "sent": "But OK, there is a catch of course.",
                    "label": 0
                },
                {
                    "sent": "Again, it depends on this double sample, but also it has to depend in exchangeable way on this double sample so.",
                    "label": 0
                },
                {
                    "sent": "You could say, well, let's let's just make it depend on the first half of the ghost sample.",
                    "label": 0
                },
                {
                    "sent": "So then it does not depend on on the story of the first half of the double sample, so that it doesn't depend on the gas sample, but you're not allowed to do this because for the proof to go through, your weight has to depend on all the samples from Z12Z and prime.",
                    "label": 0
                },
                {
                    "sent": "Otherwise, you're not able to symmetrize things.",
                    "label": 0
                },
                {
                    "sent": "So it's it's a bit better, but not fully satisfactory, and Ann usually most approaches that are based on that many difficulties to relates what happened on the last sample to what happens on the initial sample.",
                    "label": 0
                },
                {
                    "sent": "So then comes in the other trick to run macro average approach.",
                    "label": 0
                },
                {
                    "sent": "So this is.",
                    "label": 0
                },
                {
                    "sent": "Also, something that you have seen before.",
                    "label": 0
                },
                {
                    "sent": "An using essentially mcdiarmid's inequality.",
                    "label": 0
                },
                {
                    "sent": "You can show that for all functions, the difference between true and empirical error is bounded by this quantity here, which is called the Rainmaker average for the class F. Plus some term of order 1 / sqrt N. And this is.",
                    "label": 0
                },
                {
                    "sent": "Actually, not a union bound.",
                    "label": 0
                },
                {
                    "sent": "I mean there is no union bound here.",
                    "label": 0
                },
                {
                    "sent": "It's purely deviation inequality, concentration, inequality.",
                    "label": 0
                },
                {
                    "sent": "So where is the union bound?",
                    "label": 0
                },
                {
                    "sent": "The union bound comes in when you want to actually compute the Rainmaker average or upper bound.",
                    "label": 0
                },
                {
                    "sent": "The Rainmaker average, and again you can do the same thing you can, for example, of the finite case simpleminded union bound that would.",
                    "label": 0
                },
                {
                    "sent": "Upper bound this run macro term by square root of log of number of functions divided by North, so you would recover the same type of bounds that we had before.",
                    "label": 0
                },
                {
                    "sent": "But using.",
                    "label": 0
                },
                {
                    "sent": "A different, slightly different approach.",
                    "label": 0
                },
                {
                    "sent": "So but but the idea is that when you are at this stage, when you introduce this quantity, it seems that you are done because you have a bound.",
                    "label": 0
                },
                {
                    "sent": "But most of the work remains to be done in bounding this run macro average.",
                    "label": 0
                },
                {
                    "sent": "Of course there are situations where it's possible to do it more or less directly.",
                    "label": 0
                },
                {
                    "sent": "But in most cases you have to.",
                    "label": 0
                },
                {
                    "sent": "To actually do a union bound.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "One way to do this union bound so is to count the number of functions.",
                    "label": 0
                },
                {
                    "sent": "But again, if you have infinitely many functions you cannot count, you have first to project.",
                    "label": 0
                },
                {
                    "sent": "So you can say I project on the double sample and now the good thing is.",
                    "label": 0
                },
                {
                    "sent": "Once you are the red marker level, so once you have done this.",
                    "label": 0
                },
                {
                    "sent": "You already have done Symmetrization, and you have gotten rid of the ghost sample, so if you remember the proof of how to get here.",
                    "label": 0
                },
                {
                    "sent": "You first have to introduce a ghost sample and then use the fact that goes sample.",
                    "label": 0
                },
                {
                    "sent": "An initial sample can be exchanged and then you introduce the Rainmaker random variable.",
                    "label": 0
                },
                {
                    "sent": "Sigma I data is or plus one or minus one depending on whether you leave the samples in the same position or whether you extend them.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "And then in the end you use the fact that the initial sample and the ghost sample of the same distribution to say that you can cut your run macro average into two pieces and the two pieces of the same distribution.",
                    "label": 0
                },
                {
                    "sent": "So they are the same.",
                    "label": 0
                },
                {
                    "sent": "OK you you can just look at the slides.",
                    "label": 0
                },
                {
                    "sent": "But the idea is that.",
                    "label": 0
                },
                {
                    "sent": "The good thing about this approach is that you can get rid of the ghost sample.",
                    "label": 0
                },
                {
                    "sent": "So then you can do all these tricks again.",
                    "label": 0
                },
                {
                    "sent": "But without the need for using those samples.",
                    "label": 0
                },
                {
                    "sent": "So you can just count the number of functions that you obtain when you project your function class on the sample.",
                    "label": 0
                },
                {
                    "sent": "And then just use this as a bound.",
                    "label": 0
                },
                {
                    "sent": "Or you can use what are called covering numbers.",
                    "label": 0
                },
                {
                    "sent": "What does it mean?",
                    "label": 0
                },
                {
                    "sent": "It means instead of counting how many functions you have, you first create an approximation of your class with finitely many functions.",
                    "label": 0
                },
                {
                    "sent": "And then you count how many functions you have in discover.",
                    "label": 0
                },
                {
                    "sent": "But of course, since you approximate your class, you lose a little bit because you can say something about functions in that cover.",
                    "label": 0
                },
                {
                    "sent": "But not all functions in your class.",
                    "label": 0
                },
                {
                    "sent": "And the difference is the size of the approximation.",
                    "label": 0
                },
                {
                    "sent": "So you pay a little bit for the error of approximation.",
                    "label": 0
                },
                {
                    "sent": "But then you can say, well, why don't I just approximate again?",
                    "label": 0
                },
                {
                    "sent": "So you first start with the big cover, so you just pick say one function and you say approximate my whole set of function by one function.",
                    "label": 0
                },
                {
                    "sent": "And then I can have a very good bond because I just have one function.",
                    "label": 0
                },
                {
                    "sent": "But I pay a term which correspond to more or less the radius of my function class and then at the second level you say.",
                    "label": 0
                },
                {
                    "sent": "Well now I will approximate a bit more.",
                    "label": 0
                },
                {
                    "sent": "I will put three functions, say and then again I pay a little bit and you can repeat this procedure of adding more and more functions to approximate your function class and what you obtain in the end is something that takes into account.",
                    "label": 0
                },
                {
                    "sent": "The number of functions that are needed to approximate your function class up to a certain radius, and that's called covering number.",
                    "label": 0
                },
                {
                    "sent": "So NF epsilon DN is the number of functions that you need to approximate your class F at the radius epsilon in the metric DN, which is the metric of vectors.",
                    "label": 0
                },
                {
                    "sent": "Obtain when you project your function class on the data.",
                    "label": 0
                },
                {
                    "sent": "So before doing all that, you because you are in the rainmaker setting, you just project through class or function on your data.",
                    "label": 0
                },
                {
                    "sent": "You obtain a bunch of vectors which are 01 vectors because it's just the loss that you make on each data.",
                    "label": 0
                },
                {
                    "sent": "And all these vectors you look at how they are spread.",
                    "label": 0
                },
                {
                    "sent": "In terms of the metric, which correspond to just the Euclidean metric between vectors?",
                    "label": 0
                },
                {
                    "sent": "Using.",
                    "label": 0
                },
                {
                    "sent": "No, it's not.",
                    "label": 0
                },
                {
                    "sent": "It's not necessary, just I mean it's basically a metric space problem.",
                    "label": 0
                },
                {
                    "sent": "So you have a space of functions.",
                    "label": 0
                },
                {
                    "sent": "You project that you obtain a set of vectors and now this set of vectors is a metric space endowed with the standard Euclidean distance and you try to find to compute the size of approximation to this metric space that you can construct with finite vectors.",
                    "label": 0
                },
                {
                    "sent": "Finite number of vectors, and this is this term here and you just have to integrate it which corresponds to the idea that you look at all possible levels of approximation.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Yes, but.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "You can.",
                    "label": 0
                },
                {
                    "sent": "Yes, yes, exactly, but but that's an interesting question because of course.",
                    "label": 0
                },
                {
                    "sent": "You cannot always approximate an infinite set of function by finitely many functions, especially when you want to approximate very small, but this quantity here the integral of this log.",
                    "label": 0
                },
                {
                    "sent": "May still converge.",
                    "label": 0
                },
                {
                    "sent": "Because the problem is when epsilon gets small then this number may blow up, but as soon I mean as long as it doesn't increase too fast then you can still compute this integral.",
                    "label": 0
                },
                {
                    "sent": "And for example, if you have a finite dimensional space.",
                    "label": 0
                },
                {
                    "sent": "The number of balls that you need to cover a space of dimension D at radius epsilon is proportional to one over epsilon power D, right?",
                    "label": 0
                },
                {
                    "sent": "So this goes to Infinity to Infinity very fast.",
                    "label": 0
                },
                {
                    "sent": "When epsilon goes to 0.",
                    "label": 0
                },
                {
                    "sent": "But still you can if you compute this integral, then it's finite and you can have much bigger spaces than this.",
                    "label": 0
                },
                {
                    "sent": "You can have infinite in finite dimensional spaces and still have convergence of this integral.",
                    "label": 0
                },
                {
                    "sent": "So as long as the covering numbers do not grow more than exponentially, then it's fine.",
                    "label": 0
                },
                {
                    "sent": "Oh sorry, the log of the curving number do not grow more than exponential.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "OK, and.",
                    "label": 0
                },
                {
                    "sent": "And this is this is called somehow the global metric structure that you're capturing via discovering numbers an I'm a bit overtime so I will finish soon.",
                    "label": 0
                },
                {
                    "sent": "Free.",
                    "label": 0
                },
                {
                    "sent": "And there is a way to do something a bit more clever by instead of looking at covers of your space of functions that are global, which means globally in the sense that everywhere you want to approximate at a certain accuracy, you can do things a bit more local.",
                    "label": 0
                },
                {
                    "sent": "And there is actually a quantity which is called.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Majorizing measure bound majorizing measure bound, which is written here.",
                    "label": 0
                },
                {
                    "sent": "It's not very easy to explain, but let me just say that the idea is to instead of covering your space, you construct a partition of your space.",
                    "label": 0
                },
                {
                    "sent": "Into finer and finer partitions.",
                    "label": 0
                },
                {
                    "sent": "And you ensure that your partitions are certain.",
                    "label": 0
                },
                {
                    "sent": "A certain diameter, so again, is the idea of bowls.",
                    "label": 0
                },
                {
                    "sent": "You can think of bowls as a partition if you want.",
                    "label": 0
                },
                {
                    "sent": "But in addition, you put weights on this partition, so again, this idea of waiting comes in, and that's why there is this pie here.",
                    "label": 0
                },
                {
                    "sent": "So you put a probability distribution on your space of function and that gives a weights to each element of the partition.",
                    "label": 0
                },
                {
                    "sent": "An by computing this quantity you have something that estimates the radmacher average, and that's actually if you choose these weights properly is equal up to a constant to the rainmaker average, which was not the case of this quantity here, which is covering numbers.",
                    "label": 0
                },
                {
                    "sent": "So using covering numbers you can upper bound the Rainmaker average, but you lose something.",
                    "label": 0
                },
                {
                    "sent": "Whereas if you introduce weights in addition to your doing discovering you can match the value of the ramaker average.",
                    "label": 0
                },
                {
                    "sent": "So this is somehow the optimal way of performing this Union bound.",
                    "label": 0
                },
                {
                    "sent": "And now I conclude with this take com messages again.",
                    "label": 0
                },
                {
                    "sent": "So as I said in the beginning, we have these two ingredients in the bound, the deviation and the Union bound.",
                    "label": 0
                },
                {
                    "sent": "This lecture was about the union bound.",
                    "label": 0
                },
                {
                    "sent": "Next lecture will be about the deviations.",
                    "label": 0
                },
                {
                    "sent": "The optimal way of performing the Union bound is to take into account the metric structure of your space of functions.",
                    "label": 0
                },
                {
                    "sent": "After projecting on the data.",
                    "label": 0
                },
                {
                    "sent": "That's called generic chaining.",
                    "label": 0
                },
                {
                    "sent": "I did not mention it, but that was the title of the slide.",
                    "label": 0
                },
                {
                    "sent": "You can introduce a prior into the bound and that's this weighting \u03c0.",
                    "label": 0
                },
                {
                    "sent": "And that allows us to improve the Union bound and the best prior.",
                    "label": 0
                },
                {
                    "sent": "As I said before, depends on the algorithm.",
                    "label": 0
                },
                {
                    "sent": "And ideally you would like to estimate before hand.",
                    "label": 0
                },
                {
                    "sent": "What's the function, which function will be chosen by the algorithm.",
                    "label": 0
                },
                {
                    "sent": "And I do not talk about the park vision techniques, so I will not come back to this.",
                    "label": 0
                },
                {
                    "sent": "So maybe in the next lecture.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}