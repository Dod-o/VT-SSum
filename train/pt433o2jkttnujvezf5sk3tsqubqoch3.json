{
    "id": "pt433o2jkttnujvezf5sk3tsqubqoch3",
    "title": "Multimodal Machine Learning: Modeling Human Communication Dynamics",
    "info": {
        "author": [
            "Louis-Philippe Morency, Language Technologies Institute, Carnegie Mellon University"
        ],
        "published": "July 2, 2015",
        "recorded": "May 2015",
        "category": [
            "Top->Computer Science->Computer Vision",
            "Top->Computer Science->Computer Vision->Face & Gesture Analysis"
        ]
    },
    "url": "http://videolectures.net/fgconference2015_morency_human_communication/",
    "segmentation": [
        [
            "Thank you very much.",
            "Good morning everyone.",
            "Can everybody can hear me OK?",
            "And I probably don't need a microphone, so great pleasure to be here this today I will try to wake you up and also it's a challenging talk because it's about multimodal machine learning.",
            "I did my best to reduce the number of equation but I want you to understand the challenges in multimodal machine learning and because I think this is the right time and this is the right crowd.",
            "To work on this topic, there's a lot of interesting achievements that happened in the past few years, and I think face and gesture by default is multimodal in the sense of multiple queues, face and gestures, and body, and so we really, I think into this really interesting you feel as just as a usual disclaimer."
        ],
        [
            "A lot of the work you will see today are always in fact the one of the students.",
            "They're the one behind a lot of this work, and what interests me and why I'm always being interested with face and gesture is for me, face and gesture is about visual communicate.",
            "If behaviors, it's about understanding human communication than social aspect of human communication.",
            "Both primary visual but also on the verbal side.",
            "So to give you an example, why are we so?",
            "Important, and it's a."
        ],
        [
            "Self reinforcement on the white face and gestures are important.",
            "Let's just start with the typical interaction human communication and let's go one modality at the time.",
            "So let's start with the verbal modality, and I want you to interact and try to start thinking.",
            "What is the state of mind of the speaker?",
            "So it's an interview here.",
            "Guy Kewney is data of the Technology review website.",
            "Good morning?",
            "Were you surprised by the verdict today?",
            "I'm very surprised to see the verdict to come on me because I was not expecting that I came something.",
            "I'm I'm coming didn't tell me So what state or emotion?",
            "Let's call it an emotion in this case.",
            "Here's math here.",
            "So let's call it an emotion.",
            "Westate this field.",
            "Probably surprised that you probably got why that's interesting part.",
            "Why is this surprise?",
            "I'm not going to do the hands, but let's add an extra mortality.",
            "And in this case look at it, listen and listen.",
            "Which words were emphasized."
        ],
        [
            "Music online well Guy Kewney is the editor of the technology website news wireless Hello, Good morning to you.",
            "Good morning.",
            "Were you surprised by this verdict?",
            "Today I'm very surprised to see this verdict to come on me because I wasn't expecting that when I came.",
            "They told me something else and I'm coming.",
            "You gotta.",
            "Obviously the big surprise.",
            "Anyway, big surprise.",
            "Yeah, yeah.",
            "So which word was emphasize here?",
            "Any specific words me me was emphasized, which is interesting if you just parse it the first time, it was not closed.",
            "It was probably about the verdict originally that he was surprised by.",
            "It seems there's something about him that makes it surprising, and so let's add or modality, face and gesture.",
            "And now let's look at his facial expression and look at the timing of the facial expression, because that's really the key part here.",
            "No, that was a short clip.",
            "Is it music online?",
            "Well, Guy Kewney is the editor of the technology website news wireless Hello, Good morning to you.",
            "Good morning.",
            "Were you surprised by this verdict?",
            "Today I'm very surprised to see this ability to to come on me because I wasn't expecting that when I came.",
            "They told me something else and I'm coming.",
            "You gotta obviously very big surprise anyway.",
            "Surprise yes yeah."
        ],
        [
            "It's a really interesting clip by the way.",
            "She ended up continuing the interview until the commercial really professional.",
            "She is.",
            "So when did so.",
            "We surprised again, but what was the timing of the surprise?",
            "It was much earlier, much earlier than we heard.",
            "We could see.",
            "So who is from the UK?",
            "Because probably most of the people in the UK have heard about this, so we from the multimodal signals we probably know that his name is Guy Kewney.",
            "But there's something wrong about the second part, and in fact his name is Dick Uni, but he's a taxi driver and he went to the he went there.",
            "For an interview job interview and they say oh get uni OK Great they brought him they put him in the makeup room.",
            "They brought him on stage and then he started the interview and at that moment that's when he realized that this is not his job interview.",
            "This is a life TV show in his own life TV.",
            "So it came and it was really well publicized.",
            "I think in UK at that point, but I think it's a what it shows is the timing.",
            "Between modalities and we know really well between face and gesture.",
            "The timing of these can be really important.",
            "So when we think about multimodal, we have to think about how to model this."
        ],
        [
            "This different synchrony an eye synchrony between modalities.",
            "So here I think we all understand the importance of gestures.",
            "I'm gesturing and be gesture.",
            "I'm emphasizing iconic gestures.",
            "This is important also between the Proximex body language.",
            "I think I'm everybody agree with that.",
            "The eye contact here is important, and even more with face to face interaction.",
            "When you want to hold the floor.",
            "These are really important, and I think we've seen a lot of great work in the past days.",
            "On facial expression and looking at the automatic and what I love also of the field is we're going a little bit outside the basic facial expression.",
            "Really expanding that, and I think that's interesting for.",
            "But there are other people working on other things.",
            "The other half of human communication.",
            "And let's say the other half since we believe in face and gesture.",
            "But there are people also studying verbal and that's really important.",
            "We saw their message, the transcript.",
            "There's a lot of information of how people decide which word exactly they decide to speak.",
            "Also how they phrase their sentences is a really important and is always the semantic aspect of it.",
            "But there's also the acoustic.",
            "I'm emphasizing certain word me that also gives me more information.",
            "So the goal of modeling human communication dynamics is visual, but I think it's also multimodal with verbal, and so there was a question earlier about should language be part of face and gesture.",
            "I personally believe it is because it allows us.",
            "To go a level higher and try to include some of the context.",
            "In some sense, the dialogue context in the interaction so this."
        ],
        [
            "It's a big challenge.",
            "This is a long term, but it has real impact and now is the time to do it.",
            "We know that connected in solve everything, although the media target world, but it did enable a lot of technology.",
            "A lot of possibilities, and now we're at the point where we do have technologies.",
            "I think we had wonderful demos in the past few days where we have at least the low level sensing and some of the recognition there and we want to go higher to better understand human communication.",
            "And these have real impact."
        ],
        [
            "We have a lot of application where this is possible.",
            "There is a lot of great work there was on pain and there's an depression being able to look at visual behavior related to depression.",
            "Suicidal.",
            "Do you know that there are more than 40 teenagers are weak going to Cincinnati Hospital with suicidal ideations?",
            "And then you have the Doctor Who has to make this really hard decision.",
            "Am I keeping that patient him by sending them back?",
            "They need those tools to be able to objectively be.",
            "Quantify the behavior and that can really help when we think our nonverbal autistic, both children and young adult helping the young adult to go back into the work.",
            "But we also have a lot in education.",
            "Students these days are learning more and more online, but we know that face to face interaction is often a lot more powerful.",
            "How do we bring face to face interaction online such that students can really work together in a lot more?",
            "A concrete way and and public speaking.",
            "I think we had or will have a talk on that, but how can you train people to give good talk?",
            "And so we had a project on the virtual audience which was really interesting and I believe there is this wonderful source of information now about human communication.",
            "It's been shown over the years now in many conferences where you can look at people love talking online, sharing their opinion and we have also.",
            "This great technology of teleconference, Skype and these teleconference system have been the same for more than 10 to 12 years.",
            "How do we get Skype plus Plus or Google Plus plus if you want?",
            "But yeah, how do we go beyond just teleconference and enhance this?",
            "So there's a lot of application of being able to understand visual behavior at a higher level, but it's a hard challenge and so."
        ],
        [
            "So, but if you think about it, multimodal started along time ago and we had some great talk.",
            "I think on Tuesday.",
            "In fact, some of the earlier work on multimodal started a lot of it in audiovisual speech recognition.",
            "I think it peaked at some point in 2000, and now it's back even more powerful.",
            "Multimodal also is really strong, and the reason I'm talking about these is that we have to understand that face and gesture is.",
            "Part of a larger ecosystem, and by collaborating with outside world or outside world.",
            "I mean then that's so alien, but about your target.",
            "By collaborating with these other communities, I think this is how we're going to be able to solve these much challenging problem.",
            "So in multimedia there's a lot of work on cross Media boat for queries, an four categories of videos.",
            "Event detection is really a lot of interesting work.",
            "Recently.",
            "Affective computing.",
            "Came up at least the term came up more recently compared with some of the other communities, but the idea of modeling facial expression.",
            "We had some great challenges on other visual emotion.",
            "I would say what is wonderful now is that two communities who used to be extremely unimodal are now becoming also multimodal, and that's really that's telling that, yes, this is one of the direction.",
            "So now these days there's a lot of work on language and vision.",
            "Really beautiful work on image and captioning video and captioning.",
            "So I think we see that and you probably were expecting this word.",
            "So it is coming.",
            "Yes, deep learning is does help a lot.",
            "I see a lot of interesting emotion every time this term is spoken.",
            "I think we should see it as a great enabler.",
            "It's not going to solve things, but it really brings a lot of possibilities.",
            "And specifically, I personally love the way deep learning can be applied for language.",
            "I think this is one of the best enabler.",
            "I'm going to talk more about it, but all of these community I think are."
        ],
        [
            "All working together evidentially.",
            "I went to what I'm hoping to be able to solve the bigger picture of human communication, and personally I think there's at least four challenges when you address human communication once you need to be able to understand each behavior and the dynamic of it.",
            "And so we as an example, anybody who is from Dublin, Dublin.",
            "Is there some OK in speech?",
            "There is the great data set we got from Dublin where we look at.",
            "All the word yet in the meeting corpus and just listen the different intent behind each of these word.",
            "It's sorry it's the same word, but they really spoken differently and at the same time trying to find which well known speech researcher is speaking, all of them.",
            "Yeah yeah, yeah.",
            "Yeah yeah, yeah.",
            "Yeah yeah yeah yeah OK.",
            "Anyone found who it is?",
            "Nick Campbell, but he every intonation is really different.",
            "I could have done the same for smiles at the 50 Shades of smile there I could have done it.",
            "For most expression, there's always a subtlety in it and we need to be able to model this the second one."
        ],
        [
            "Which is obvious by now is we need to learn the dynamic between gesture and different modalities.",
            "So that's really important interpersonal.",
            "We had a lot of great work yesterday about social contexts.",
            "The interpersonal and cultural aspect is really important when you study multimodal communication today, I'm really going to emphasize these two aspects behavior and multimodal together, but I believe they are part of a larger picture so."
        ],
        [
            "Here's the challenge in a really small, really simplistic nutshell, but we want to be able to integrate what people say their face and gesture and how they say it all together to be able to infer something about the intent of be able to embed or interpret.",
            "But this is multimodal, but I also believe that this is multimodal.",
            "Face and gesture is multimodal implicitly, and so everything I will be explaining today about multimodal.",
            "I will often use verbal, visual and acoustic.",
            "But I think a lot of it also generalizes to different modalities, because depth and intensity are also two different modalities.",
            "So how we're approaching this?",
            "I really hard problem.",
            "I think we have to look at it at least in four major challenges.",
            "There are probably a lot more than that, but I think if you are to start and multimodal and you've not work on this topic yet, I think you have to think about at least 4.",
            "Four of the main challenges."
        ],
        [
            "One is the hidden temporal structure isto."
        ],
        [
            "Are you about the yeah or I could have done the same with smile.",
            "Every smile has this dynamic and you need to model this.",
            "The simplest models of smiles were these early onset peak and upset.",
            "I think we can go a lot more complex than that to be able to model it and so you need to have technology that learn that hidden structure that learn this dynamic and be able to identify how this change and the most interesting these days.",
            "How is this dynamic?",
            "Affecting on long range dependencies, I think there's really interesting work there.",
            "The second one is about multimodal representation.",
            "Can we an?",
            "I think that's one of my dream.",
            "Can we build a representation where speech and gesture will be together?",
            "We know it's possible the human brain is able to have such representation.",
            "At least some people believe that there's a lot of interesting working kinds of science trying to understand the cognitive aspect of speech and gesture.",
            "But how can we create a representation?",
            "That jointly learn there both speech and gesture.",
            "This the third one, is how the synchronization of it and the last one, I think is the key of what makes human communication so challenging.",
            "Is this inherent uncertainty in the in the interpretation?",
            "And what when you see object recognition, it's often a really discrete label, emotion or expression, or, implicitly I implicitly uncertain or.",
            "I use the word fuzziness.",
            "Really scientific word, but it's really looking at the uncertainty of interpretation and the change of it between people.",
            "So how do we address this?",
            "How do we build algorithm to create an model this?",
            "This is what we're going to do today and I'm going to go through this four points.",
            "If at any point you have questions, feel free to ask questions.",
            "Otherwise I will answer this at the end so."
        ],
        [
            "How do we model the hidden structure?",
            "What do I mean by hidden structure?",
            "I mean being able to model inside a certain gesture, so ahead shake has a ignorant, really simple structure to it left right repeatative cyclic gesture.",
            "But a lot of other emotion or expression have a lot more complex.",
            "So how do you model this?",
            "And I will use today just because I'm getting you out outside your comfort zone.",
            "But maybe of you I'm going to use a lot of examples from language.",
            "Just because so that you can understand that what we know about face and gesture is also really important for language.",
            "So we're going to give you a lot of examples for language just to get you a little bit outside that maybe comfort zone.",
            "So there's been over the years.",
            "A lot of interesting approaches to model these.",
            "We have the earlier work on generative model looking at simple Naive Bayes, and I think by now everybody who's done some face and gesture or speech recognition knows about hidden Markov model.",
            "These are great models that model the dynamic latent structure of the signal in a generative way, and they were really powerful for early work.",
            "Now these days we still see some generative model, but a lot of work recently, even more discriminative model support vector machines were in there only 2000 in the mid 2000 conditional random field were able to expand this to a more structure.",
            "There is a struct.",
            "SVM that also will model the structure.",
            "This model has the advantage of if you have a task.",
            "If you have a task in mind discriminating between different expression, if you have a task in my often modeling it discriminatively improve performance.",
            "It's not true for every data set by it's often improving, so let me give you an example.",
            "As I said, for language so that you understand so Anon phrase non first segmentation is one of the early step.",
            "It's the same way you're going to do a gesture.",
            "Segmentation is the early stage before doing something more high level like sentiment analysis.",
            "So how do people do so?",
            "I have a sentence.",
            "OK Oh my gosh, I didn't expect to see words.",
            "Where are my images so I have a simple sentence and I want to segment it to know where is the beginning of a noun phrase.",
            "These are the key moments beginning of a noun phrase so I can segment it and so this is the continuity of a noun phrase and this is other meaning that in this case it's the verb.",
            "So you want to be able to automatically that.",
            "But I could have easily put here the beginning of a head, nods and then a head shakes.",
            "This is the same general idea.",
            "The reason I'm doing this is that I want to model this.",
            "Sequence of information and I want to model it to be able to recognize it discriminatively and so I have my input and there is an interesting thing.",
            "The usual way to represent word will be all really long vector that simply as a bag of features.",
            "So let's suppose for our simple bag of feature that you can recognize that.",
            "So the typical conditional random field will be looking OK.",
            "This is 1 equation.",
            "If you have.",
            "I know all the all the next equation will all come from.",
            "This one, so just take a second to understand that probably a lot of you understand the basic of this, But this if you have to focus on one equation, understand this one all the rest after that are much easier, ever neural networks these days will be often represented as potential function, so a lot of the representation that you see it is the same for a lot of models.",
            "So the simple model in this state that will try to predict.",
            "And when you think of discriminative, think of conditional probability, that's usually.",
            "The way of optimizing a discriminative model, so I want to optimize the probability of seeing these label given that I observe these words.",
            "So it's a simple conditional probability and two main aspect to it is I will have what we've seen in the hidden Markov model as an observation model.",
            "So I will model the potential or let's say it the relationship or the closeness between my observation and the labels.",
            "And I will also model the dynamic between my labels, so there's only two terms here and I have parameters to try to see how each word in the simplest case you could imagine how each word of my dictionary is correlated to a specific label.",
            "That's the easiest way of thinking of potential function, so this is a really powerful this kind of energy model or representation is really powerful, and what I love about it.",
            "The reason I like this kind of model is that they are a lot easier to interpret because if I want to know what did the model learn, I can go and look at these parameters and look at which word was important for which label, and I think that's when you start doing analysis that's more high level.",
            "You want to be able to interpret the model, so I think this is important, But this doesn't solve everything that we wanted to.",
            "It doesn't solve the hidden structure, it doesn't learn the hidden structure, so."
        ],
        [
            "Well, how do you model the hidden structure?",
            "And here's again, that's on purpose language example, because in NLP often when you do this kind of problem, you will look at what's called part of speech tagging.",
            "So you will look at these.",
            "Then viable to better predict your label and what we want is we are lazy, OK and we don't want to label this by hand.",
            "So what we will do is in fact learn some later."
        ],
        [
            "Variable latent be behavior that will later viable that will model this for us.",
            "And so when you think of latent variable, always think of these grouping of behaviors or grouping of features and so we will learn this automatically and I'm going to skip some of them at.",
            "But what I want you to learn here is that I'm going to learn the grouping and let me give you the example here for gesture recognition.",
            "So I have a lot of frames that go one way.",
            "I want to group them together.",
            "And I am going to do the same, so that's how you learn this latent structure is that the model will learn it for you, so."
        ],
        [
            "By doing that, what you learn is two things.",
            "And that's the main take.",
            "Home message here.",
            "Forget the match for a second.",
            "The two things.",
            "There's two type of dynamics you're gonna learn.",
            "OK, there's one dynamic which is inside in the label, so the dynamic is what is my dynamic inside my gestures.",
            "But you also want to learn what is the dynamic between gestures and these are the two type of dynamic you're going to learn automatically with this kind of model.",
            "And I think this is."
        ],
        [
            "Is really powerful and that can in fact learn automatically how to group all of these latent variable automatically.",
            "And so you learn automatically that the beginning of a sentence often start with determinant.",
            "A beginning of a sentence always start with the determinant, but the same thing could be also a happy smile.",
            "Often start with unset, so that's a lot of the same intuition.",
            "And what is?"
        ],
        [
            "Red is the same model, can work really well for face and gestures.",
            "There's been a lot of great work presented yesterday using LD CRF, an extension of ldif.",
            "It works really well for gesture and works really well for language.",
            "OK, this was really painful talking about language.",
            "The rest of it is an example will be about vision, but I wanted you to get at least some intuition that a lot of the same model we're using for facial expression recognition works really well with language.",
            "Ah."
        ],
        [
            "And these models can be able to not just predict instantaneously the state, but you can also summarize it.",
            "And I think this is a powerful aspect of it too, is to integrate all this overtime.",
            "So if I have a full video and I want to know the general expression or emotion in this video, you can also use these same models extension that are to be able to generalize it and the only take all my one here is that you start being able to share.",
            "Hidden State between labels?",
            "What does it mean?",
            "So let's say I'm trying to recognize happy, sad.",
            "Let's let's put content just to be a little bit more interesting.",
            "So happy and content are probably sharing a lot of the dynamic.",
            "A lot of the same features, so you don't want to just learn one for happy and one for content.",
            "So you want to be able to learn some shared representation, and these models can learn that as well.",
            "So I think that's one of the powerful aspect of."
        ],
        [
            "So this was a lot more mathematical, and now I'm going to get into how we take all this prior work on modeling latent dynamic to be able to be able to do multimodal.",
            "OK, so we have first aspect is representation and I think that's one of the great challenge with a lot of this work is how do you represent together verbal, acoustic and visual together?",
            "How do we represent not just the how do you represent the three of them together?",
            "And this is, I think there's been some interesting work also presenting how you do face and body.",
            "And that's the same idea."
        ],
        [
            "Here, so you want to be able to learn the same kind of models, but now we're going to add this neural layer, and here's what I want you to understand.",
            "Conditional random field were invented originally for language.",
            "They work extremely well when your features are this bag of features, because each feature is a discrete one, and what you learn is how important each of them is.",
            "But if you have continuous features were like we have here in face and gesture, you should be aware that.",
            "This model may not be optimal.",
            "It's much better to have a first layer like a neuron that is going to learn this.",
            "We have continuous feature in face and gesture.",
            "We have these continuous features.",
            "So how do you model these continuous features?",
            "They being able to learn it with the neural layer will allow you to group or represent them in a much easier way such that you learn the representation and then you learn after that how these features are important for your task.",
            "So the couple in your mind, these two step feature representation and then modeling of the dynamic it's better to today couple that and it's much easier for a lot of the system.",
            "Once you de couple it you have one layer that is learning what is the right way to look.",
            "I have this motion I'm moving right now.",
            "This is a highly dimensional vector or representation.",
            "This first layer is going to be there.",
            "To learn to represent this such that you can then learn the dynamic of it.",
            "So decoupling this and two different layer improve a lot the performance in Oliver at task we've tried and it's really easy mathematically.",
            "You just adding these weights.",
            "So what is this weight learning?",
            "It's a representation.",
            "What is this weight learning is?",
            "Which features is important?",
            "What is this weight learning?",
            "Is the dynamic and so you're decoupling that and then you can analyze it afterwards.",
            "It makes it much."
        ],
        [
            "Powerful and the key aspect.",
            "Of what?"
        ],
        [
            "Why deep learning is now possible?",
            "An why?",
            "All of this is the challenge is when you do these OK, multiple layer is each layer end up learning the same thing.",
            "That's a challenge when you do hidden or latent on deep learning or multiple layer is the challenge that you don't want one layer to learn the same as the next layer.",
            "And This is why you will add some regularization that makes it such that one layer learn something different than the other and there are many different trick for that.",
            "The most simplest one these days is the dropout, where you randomly turn off some of your neurons and it turns out that this is the trick to make deep learning."
        ],
        [
            "Working not the only one, but one of the main one.",
            "So when you."
        ],
        [
            "To do this, you can improve a lot on what was the LDIF for a lot of the work."
        ],
        [
            "So here's the audio Visual Emotion Challenge and so in these challenges you have visual and acoustic feature.",
            "You look up.",
            "Sorry I put the word emotion.",
            "You have the."
        ],
        [
            "Pression of arousal and then in this case you improve dramatically, and I think the main reason for that, is that not only are you able to learn a better representation, but that representation is multimodal in this case, so audio and visual were able to merge at that layer, and you're like, oh, but you didn't say the word deep yet."
        ],
        [
            "Why I got everything should be deep.",
            "These models why I took the time to explain to you the CIF.",
            "The conditional random field is that neural networks are the exact same, almost the same, a lot of.",
            "The neural network have the same structure, so here it's the same exact representation.",
            "So here you have multiple layer, so you these are imagine neural layers and then you can model this the exact same thing.",
            "But as you know the deep learning or neural network often are not dynamic, although there's some conditional version of that.",
            "So here is the same idea and I'm going to show this.",
            "Improved here, you probably saw this representation more often, but what we see here."
        ],
        [
            "Is the same idea.",
            "So imagine that this is the same."
        ],
        [
            "As this will."
        ],
        [
            "Presentation, So what it is is all the great work you hear about deep learning can be included or inserted in all of these conditional random field or energy models.",
            "So now these days they we hear a lot about image and caption which are forgetting about this temporal aspect.",
            "But we know the importance in this community of temporal for the gesture for the facial expression we know that we are expert in that aspect.",
            "And I think This is why this community is one of the community ready to look at the next stage.",
            "Let's go outside of just the static Image caption and let's look at temporal information.",
            "But there's been great work, so if you have two papers to look at when you come back these two papers, but primarily the second one, the first one is just because I told you, uh, do visual speech recognition had a really big peak in 2000, and now these days, a lot of this work and I just put the first one.",
            "But there's a long line of now work on audiovisual speech recognition.",
            "That really learns this George representation and what I love about it by learning it jointly.",
            "Then you a lot more robust to occlusion or missing data.",
            "And what does it mean?",
            "I think in audiovisual speech term it means if one of your channel is really noisy, the other one will compensate automatically.",
            "And so in this case of audiovisual, if my audio channel is is noisy then the visual will compensate.",
            "And so this is 1 but the one where I really want you to read and take time to read that paper.",
            "This is this was a insightful paper, and there's a lot follow up with data from Stanford, but this paper what it did is is video and text.",
            "Image and caption of picture of a dog and the word dog.",
            "Really simple thing.",
            "But by learning this representation together, what were they able to do?",
            "You put an image in the network and you get the words that is the most likely.",
            "This was wonderful with joint representation.",
            "If you put a word then you see the kind of images you see for that word.",
            "That is really interesting.",
            "And I told you let the best application of deep learning in my in my mind is language.",
            "It does really well for vision convolutional network.",
            "But let's talk about deep learning for language.",
            "What happened before?",
            "If you want to merge language and vision, you had to look at symbols like words and merge it with signals, which is what we're mostly used to in the face and gesture and speed.",
            "But now these days.",
            "You have a representation that is based on what's called distributional hypothesis, so they look at all of Wikipedia under word in Wikipedia and look at where are the words each word usually happened.",
            "Where is its neighborhood and what it did is it's an approximation to what's called semantic and we in computer and computer vision the user work semantic like it's like peanut butter or like, but what really semantic in this case is an approximation.",
            "Is that if the word, let's say the word men and women, they will often be used in similar sentence is just with a different with the same neighborhood.",
            "So they are able to learn a vectorial representation of how a word should be represented mathematically, and I think that's a beautiful thing of it is now with the deep learning.",
            "I take a word and you can transform it to vectors and are many of them.",
            "In fact, the obvious one is the Google one that's called word two vectors.",
            "But what it is that vector intuitively?",
            "What I what I see is that each dimension you could see it as one dimension could be arousal, one dimension.",
            "Who could be some aspect of gender.",
            "So these vector representation are beautiful wave.",
            "So if you want to do multimodal then now we have a nice way of representing thing vectorially numerically so that we can do Fusion with the audio and visual OK it's alone explanation but at the end of the day I will say look at this kind of work.",
            "Because I think it can be really inspiring for your future work and there is an audio visual emotion challenge.",
            "Recognition already from 2013.",
            "This one was done on the emo cap again.",
            "OK, so yes this was great work and then the.",
            "Is a lot of follow up since then and I think he has at least 10 papers on deep learning and emotion.",
            "So OK, so this was my deep learning slide.",
            "I don't want to overemphasize it but you have questions.",
            "We are in fact preparing and multimodal surveys.",
            "That's going to come out in a few months so that."
        ],
        [
            "Going to come out to help that so.",
            "Nonlinearity is important and representation is important.",
            "The second aspect is we are used to 30 frames per second.",
            "We love it.",
            "High frame rate but words other than me.",
            "Most people speak maybe 3 or 4 words per second.",
            "I'ma probably much higher than that, but how do you take words and allowing them with a really high frame rate?",
            "I personally believe that we need to do what's called modality summarization.",
            "Take a high frame rate video.",
            "And be able to summarize it, and there's some interesting work on summarization.",
            "But my goal here is not to summarize so I can show a shorter clip too.",
            "The subject, but mostly because I want to the keyframes of a sequence and so."
        ],
        [
            "Here I have a sequence and I would like to learn this representation that will summarize the whole sequence.",
            "N. I don't want to just summarize it, but I have a task in mind.",
            "I want to summarize it such that I can better recognize the gesture.",
            "If you have a task in mind, think discriminative model.",
            "So task in mind discriminative model.",
            "So I want to be able to take this input sequence and do summarization.",
            "What are the two obvious way of taking this observation and summarizing in them?",
            "There are two obvious way the first one will be to take a same fixed sampling rate.",
            "I'm going to take one out of every 4 frames and I think there were some good work on that and I had a lot of time.",
            "This kind of pyramid approach works really well the other."
        ],
        [
            "One would be let's look at the frame and let's look at 2 frames look alike and we're going to merge them together if they look alike.",
            "But I have a task in mind, so there's a third way to do it, which is I have a task of recognizing gesture, so I'm going to use the same HCI F that we've learned earlier, and I'm going to learn what are the remember every time you hear latent variable or hidden Bible.",
            "Think of grouping, grouping with a task in mind, so I'm gonna end up group.",
            "My observation with a task in mind and do the grouping at that level because these are kind of taking my observation and putting in a low dimensional space.",
            "And there I'm going to do the grouping and doing that.",
            "I'm going to skip some of the details."
        ],
        [
            "But doing that you can not only be able to summarize, but we end up improving on gesture recognition by being able to create this pyramid of representation.",
            "Some gesture may be better recognized at a high frame rate, some gesture at a lower frame rate.",
            "So by doing that we can better Rica."
        ],
        [
            "Nice and both on the task."
        ],
        [
            "Of recognizing our man, gesture, arm and hand gestures, and also for the really."
        ],
        [
            "Old videos that we had for the under this don't use this data set please 99.59 let's stop using this data set, but it's a gesture data set that was done along time ago, but we really improve by having this multiple layer and not only."
        ],
        [
            "Were you able to create that?",
            "But we can know where they're from, and that's really interesting, because now you can see these summarize a really specific aspect of the gesture so."
        ],
        [
            "This is 1 aspect that was really important is representation.",
            "The second one is synchrony or asynchrony, and we said in our data we had the facial expression happening of surprise when he was when we heard his title and that's really important.",
            "So you want to be able to learn the synchrony and the complementary."
        ],
        [
            "Pretty, the complementarity is some early work on Coadaptation Norco core learning that has been done, but I will.",
            "I will emphasize primarily the synchrony in this case, so they just do."
        ],
        [
            "So people are aware of this work.",
            "I'm not emphasizing it, but there's some early work trying to code app so I have more and modality and I like audio.",
            "I want to be able to learn and find the strong cases or positive strong cases and use that to improve the visual and vis versa together."
        ],
        [
            "Some early work."
        ],
        [
            "Yeah, but there one way I really want take home message when you think of multimodal.",
            "There are two type of dynamic.",
            "Again there is the dynamic that's private to that modality.",
            "And then there's the the one that shared between modalities.",
            "And why do we go through this whole process of doing both?",
            "OK, let's think of audio and visual.",
            "Audio has its own noise model.",
            "The noise model there is really different from what you will see in images and so that you want to be able to model each of them independently.",
            "But then after that find out when they should be seen."
        ],
        [
            "Cronise, and so we will look at a model like the HCI F, But we're going to in fact not just do the typical early and late Fusion early Fusion will be.",
            "I in fact end up stacking together all my features and just learn the same model.",
            "And that's one of the things.",
            "Please, if you submit any papers through ICM, I or any of this conference try to go a little bit further than just Lillian late Fusion.",
            "I think there's a lot of interesting word that's been there, but let's try to go a step further.",
            "I think this is the next stage now of that, and so can we model where we have one sequence for audio and the second sequence."
        ],
        [
            "The video and each of them have their private dynamic, so you learn audio and visual how each of them, they're noise and all this.",
            "So you learn that, and then you're going to learn when they synchronize together.",
            "And I just heard there's some interesting work extension of that work that thing that's going to be presented soon, so there's a lot of interesting model of that these the same model as before.",
            "It's a conditional probability is just that.",
            "Instead of having just X, you have the observation for the audio.",
            "And observation from the visual.",
            "And when you do that."
        ],
        [
            "Then you prove on a lot of cases this was for agreement disagreement data set that it was improving."
        ],
        [
            "The the final part of this whole multimodal is the interpretation, and the problem is so big and this is just a small baby step, but I want you to at least think about it, and I think the talk yesterday and I think the workshop on context was first step towards that.",
            "But really, when we interpret a state of the user like let's say an emotion or expression, there's a lot of variability on how people are interpreting this.",
            "So people, all these people looking at the same videos may have really slightly different interpretation.",
            "And how are we going to model this difference between observers?",
            "I think this is a wonderful research problem and has been understudied in machine learning.",
            "I will give you a really small approximation of that which is instead of doing the discrete the discrete between looking at an emotion, an expression as active or not, which is all what I talk.",
            "We're going to look at it as a regression problem, so we're going to look at the same kind of behavior."
        ],
        [
            "Kind of model as before, but now it's regression, so I have here one of the output, maybe from avek that tells me on how much violence are, or recently with Farrah it was wonderful with all of these different intensity X action units, so this is what I'm trying to predict and my input could be unimodal or bimodal.",
            "Tree MoD try model and I'm going to try to learn OK so this is my observation.",
            "What is this?",
            "This is a neural network.",
            "Why did I put it there?",
            "Why didn't I just connect them?",
            "Because my input, let's say I'm looking at facial expression is really is is not just a discrete input like text.",
            "It's a lot more complex, so I need these neurons to learn my representation.",
            "Yes.",
            "What?",
            "Oh sorry, the color scheme.",
            "No, they're not observed there.",
            "Great, sorry they're not observe and so you're going to learn that their latent, sorry, the color scheme.",
            "Not perfect here.",
            "And So what is the biggest challenge when you do regression?",
            "Is this integral?",
            "This integral is what makes this a hard problem is because before we had discrete label, because you had discrete label, you could go through all possible label or do an approximation, would believe propagation, but because now you're going from minus Infinity, you'll able could go from minus Infinity plus Infinity.",
            "You are a much harder case, so nicely is that there's an approximation to that someone else has seen that if you can take this.",
            "Equation here if you can take this equation here and put it in this format."
        ],
        [
            "What is this?",
            "It looks really fancy, but this is just a Gaussian.",
            "This is a Gaussian distribution, so if you can put it in this format, this equation in this format, then there's a solution to it.",
            "There's a nice solution to it, and not just.",
            "There's a solution to that, but."
        ],
        [
            "On top of that, the most when you have a Gaussian, what is the optimal point of a Gaussian?",
            "The mean?",
            "So if you're optimizing this, you get automatically the up the maximum of that distribution is going to be in the mean, which can be computed really easily.",
            "So this was some great work that was done."
        ],
        [
            "And collaboration with Harris and Peter and so what's also really nice with it is not only because you are not doing anymore approximation for belief propagation.",
            "You can now start have long range dependencies.",
            "So now you can model long range dependencies an you can start modeling a 2D cases so you can start modeling today and this is how the facial landmark detector was, because now your input will be an image and that's working the same way here, so the same."
        ],
        [
            "Model can be extended as large as we want, so.",
            "And that is."
        ],
        [
            "Improve on many datasets."
        ],
        [
            "Also, for emotion, and this was work.",
            "Great work done by Ta da sound that so."
        ],
        [
            "So this is a summary.",
            "Hopefully you're still with me and sleeping already because of all the math.",
            "But what I wanted to emphasize today is when you think about multimodal, think first about unimodal.",
            "It's still really important, but when you think of your new model, think of this temporal structure.",
            "How do you model the different?",
            "Yeah, the different smile.",
            "How do you model that dynamic second?",
            "How do I represent linear this?",
            "Relationship disincentive this relationship and for that you should really think about it as now I really really fashion area and so I don't think I've seen the word multimodal at NIPS or ICML until 2012, or really few cases.",
            "And now if you look at these machine learning conferences, use it regularly so this is a wonderful time to do that kind of research, and because our communities.",
            "Are recognizing the importance of it.",
            "Multimedia always knew it, but now the speech, language, vision and machine learning also recognizing the important think about synchrony and prediction.",
            "I didn't talk about multitask, but you can also try to predict more than one expression or action unit at the same time.",
            "There's some great work done on that.",
            "I've put, uh, we do our best to take all of those algorithms we created and try to put it in one place.",
            "If the algorithm is not there yet, email us.",
            "When do our best to share it.",
            "I think we eventually if you do extensions to these algorithm, if you share it with us, that's all."
        ],
        [
            "Really nice so that the community does so am I doing on time?",
            "OK, great so I'm just going to show these five minutes this last five which is which was in fact the introduction of it is that it has a real impact.",
            "This work and this work can really help.",
            "In our case we want to help doctors and clinicians to be able to recognize distress, depression and so I'm going to show this how this technology can be used in a real application.",
            "In this case recognizing distress.",
            "So let's listen at this videos and look at two things.",
            "One is the distress person and second look at the clinician.",
            "How is she interacting?",
            "She's a wonderful tension who ended up being really trying to show a lot of.",
            "Engaging behavior in this case, so let's look at it.",
            "How?",
            "Yeah, I mean I I didn't suffocate, but I was very uncomfortable like it never happens.",
            "Pressure.",
            "Sarah.",
            "So I mean, I notice that.",
            "Yeah, I'm.",
            "I didn't even manage to come rescue me or anything, but but what's interesting is to see this behavior.",
            "How can we quantify this behavior of distress, like the tone of voice and all all these behavior, so I think."
        ],
        [
            "This is 1 area that I'm really excited and I think there's a lot of momentum there.",
            "We call it health behavior informatics, but the idea of taking these interaction, either human to human or human, to virtual human and be able to quantify how is this person behaving today?",
            "How were they?",
            "A week ago, two weeks ago?",
            "How can I compare with?",
            "Database, maybe they have other people who were in distress and be able to learn from that.",
            "Is this person getting better or worse and this person seems to be getting better.",
            "That's a good news.",
            "And so when you put everything together, what's interesting here, I'm going to show a video.",
            "This is the final video I'm going to show.",
            "You are going to see all the sensing and you're going to see the virtual human who is reacting all the work I presented today can be used for recognition of distress behavior.",
            "But it can also be used for prediction, and in this case for animation of the virtual human.",
            "And so here's the."
        ],
        [
            "Video thanks for coming in today.",
            "I was created to talk to people in a safe and secure environment.",
            "I'm not a therapist, but I'm here to learn about people and would love to learn about you.",
            "I'll ask a few questions to get us started.",
            "Everything is live free to tell me anything.",
            "Your answers are totally confidential.",
            "Are you OK with this?",
            "Yes.",
            "So how are you doing today?",
            "I'm doing well.",
            "That's good.",
            "Where are you from originally?",
            "I'm from Los Angeles.",
            "Oh, I'm from LA myself.",
            "When was the last time you felt really happy?",
            "Um?",
            "But I try to stay happy.",
            "I rather be happy.",
            "My kids keep me going.",
            "What advice would you have given yourself 10 or 20 years ago?",
            "Um?",
            "2.",
            "I do not believe.",
            "Do not be so gullible to not be so gullible.",
            "So you see their lives tracking in real time, facial landmark detection, acoustic analysis, speech recognition, dialogue modeling, virtual nonverbal behavior generation.",
            "Everything is happening in real time.",
            "If you stop by Los Angeles, you can run an interact with Ellie.",
            "That's her name."
        ],
        [
            "So I gave an example.",
            "There are a lot of examples where this technology can be used.",
            "In fact, there is a lot of application already seen here, but I think this is the exciting part is how can you model this human communication to help with suicide prevention with distress, with pain to be able to improve public speaking, may be for autistic young adults.",
            "These are some of the application."
        ],
        [
            "Last slide is my thoughts of where this is going.",
            "I mean this is my talks.",
            "I don't have a magic ball, but I think they at least and for interesting future direction.",
            "One is.",
            "There's been a lot of interesting work on audiovisual, on tax and vision, but I don't think we yet have trimodal representations.",
            "It's a question of time and maybe someone has already done it, but it's not there yet.",
            "And so how do you model these?",
            "Language, speech and vision.",
            "Together, I think this is still a really interesting and an open.",
            "And what is the challenge here is the temporal aspect, which is in fact the second one, and that's why I think the face and gesture community is key in this equation is we understand temporal and right now there is some interesting work with recurrent neural network added.",
            "Emphasize it today.",
            "It's really funny to see the machine learning community and vision community suddenly discovering LST M long.",
            "Short term memory.",
            "If we had Bjorn Schuler here, will have it would I said, oh God, I told you 15 years ago that this was a good algorithm.",
            "But yeah, so it is really interesting.",
            "Nice way of modeling the temporal aspect.",
            "Whyel STM is so popular compared to some of the model is shown is the model I've shown.",
            "I'm modeling the short term but you want to not just model the short term but you model also the long term and that's why you need to find a way to do the best of two words.",
            "The world, and I think that's one of the future.",
            "Enter, I didn't emphasize it today because part of it is I gave a full talk about it on Monday, but interpersonal dynamic I right now.",
            "I've talked about one person, but their whole aspect.",
            "If you have a dynamic and you could see it as another modality, the other person is another reality.",
            "Another view on the problem and finally social context.",
            "I had to put it because I strongly believe in it and there's some interesting work to be done there and there.",
            "How do you include?",
            "1st about how do you represent this social context?",
            "Computationally is a big problem and the Secondly is how you integrate that.",
            "It's even a bigger product, so there's a lot of interesting work.",
            "I think dialogue Community has approached it a little bit, but that's how we thought.",
            "So thank you."
        ],
        [
            "Very much for your attention and I'm ready for questions.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Thank you very much.",
                    "label": 0
                },
                {
                    "sent": "Good morning everyone.",
                    "label": 0
                },
                {
                    "sent": "Can everybody can hear me OK?",
                    "label": 0
                },
                {
                    "sent": "And I probably don't need a microphone, so great pleasure to be here this today I will try to wake you up and also it's a challenging talk because it's about multimodal machine learning.",
                    "label": 1
                },
                {
                    "sent": "I did my best to reduce the number of equation but I want you to understand the challenges in multimodal machine learning and because I think this is the right time and this is the right crowd.",
                    "label": 0
                },
                {
                    "sent": "To work on this topic, there's a lot of interesting achievements that happened in the past few years, and I think face and gesture by default is multimodal in the sense of multiple queues, face and gestures, and body, and so we really, I think into this really interesting you feel as just as a usual disclaimer.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A lot of the work you will see today are always in fact the one of the students.",
                    "label": 0
                },
                {
                    "sent": "They're the one behind a lot of this work, and what interests me and why I'm always being interested with face and gesture is for me, face and gesture is about visual communicate.",
                    "label": 0
                },
                {
                    "sent": "If behaviors, it's about understanding human communication than social aspect of human communication.",
                    "label": 0
                },
                {
                    "sent": "Both primary visual but also on the verbal side.",
                    "label": 0
                },
                {
                    "sent": "So to give you an example, why are we so?",
                    "label": 0
                },
                {
                    "sent": "Important, and it's a.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Self reinforcement on the white face and gestures are important.",
                    "label": 0
                },
                {
                    "sent": "Let's just start with the typical interaction human communication and let's go one modality at the time.",
                    "label": 0
                },
                {
                    "sent": "So let's start with the verbal modality, and I want you to interact and try to start thinking.",
                    "label": 0
                },
                {
                    "sent": "What is the state of mind of the speaker?",
                    "label": 0
                },
                {
                    "sent": "So it's an interview here.",
                    "label": 0
                },
                {
                    "sent": "Guy Kewney is data of the Technology review website.",
                    "label": 0
                },
                {
                    "sent": "Good morning?",
                    "label": 0
                },
                {
                    "sent": "Were you surprised by the verdict today?",
                    "label": 0
                },
                {
                    "sent": "I'm very surprised to see the verdict to come on me because I was not expecting that I came something.",
                    "label": 1
                },
                {
                    "sent": "I'm I'm coming didn't tell me So what state or emotion?",
                    "label": 0
                },
                {
                    "sent": "Let's call it an emotion in this case.",
                    "label": 0
                },
                {
                    "sent": "Here's math here.",
                    "label": 0
                },
                {
                    "sent": "So let's call it an emotion.",
                    "label": 0
                },
                {
                    "sent": "Westate this field.",
                    "label": 0
                },
                {
                    "sent": "Probably surprised that you probably got why that's interesting part.",
                    "label": 0
                },
                {
                    "sent": "Why is this surprise?",
                    "label": 0
                },
                {
                    "sent": "I'm not going to do the hands, but let's add an extra mortality.",
                    "label": 0
                },
                {
                    "sent": "And in this case look at it, listen and listen.",
                    "label": 0
                },
                {
                    "sent": "Which words were emphasized.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Music online well Guy Kewney is the editor of the technology website news wireless Hello, Good morning to you.",
                    "label": 0
                },
                {
                    "sent": "Good morning.",
                    "label": 0
                },
                {
                    "sent": "Were you surprised by this verdict?",
                    "label": 0
                },
                {
                    "sent": "Today I'm very surprised to see this verdict to come on me because I wasn't expecting that when I came.",
                    "label": 0
                },
                {
                    "sent": "They told me something else and I'm coming.",
                    "label": 0
                },
                {
                    "sent": "You gotta.",
                    "label": 0
                },
                {
                    "sent": "Obviously the big surprise.",
                    "label": 0
                },
                {
                    "sent": "Anyway, big surprise.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah.",
                    "label": 0
                },
                {
                    "sent": "So which word was emphasize here?",
                    "label": 0
                },
                {
                    "sent": "Any specific words me me was emphasized, which is interesting if you just parse it the first time, it was not closed.",
                    "label": 0
                },
                {
                    "sent": "It was probably about the verdict originally that he was surprised by.",
                    "label": 0
                },
                {
                    "sent": "It seems there's something about him that makes it surprising, and so let's add or modality, face and gesture.",
                    "label": 0
                },
                {
                    "sent": "And now let's look at his facial expression and look at the timing of the facial expression, because that's really the key part here.",
                    "label": 0
                },
                {
                    "sent": "No, that was a short clip.",
                    "label": 0
                },
                {
                    "sent": "Is it music online?",
                    "label": 0
                },
                {
                    "sent": "Well, Guy Kewney is the editor of the technology website news wireless Hello, Good morning to you.",
                    "label": 0
                },
                {
                    "sent": "Good morning.",
                    "label": 0
                },
                {
                    "sent": "Were you surprised by this verdict?",
                    "label": 0
                },
                {
                    "sent": "Today I'm very surprised to see this ability to to come on me because I wasn't expecting that when I came.",
                    "label": 0
                },
                {
                    "sent": "They told me something else and I'm coming.",
                    "label": 0
                },
                {
                    "sent": "You gotta obviously very big surprise anyway.",
                    "label": 0
                },
                {
                    "sent": "Surprise yes yeah.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's a really interesting clip by the way.",
                    "label": 0
                },
                {
                    "sent": "She ended up continuing the interview until the commercial really professional.",
                    "label": 0
                },
                {
                    "sent": "She is.",
                    "label": 0
                },
                {
                    "sent": "So when did so.",
                    "label": 0
                },
                {
                    "sent": "We surprised again, but what was the timing of the surprise?",
                    "label": 0
                },
                {
                    "sent": "It was much earlier, much earlier than we heard.",
                    "label": 0
                },
                {
                    "sent": "We could see.",
                    "label": 0
                },
                {
                    "sent": "So who is from the UK?",
                    "label": 0
                },
                {
                    "sent": "Because probably most of the people in the UK have heard about this, so we from the multimodal signals we probably know that his name is Guy Kewney.",
                    "label": 0
                },
                {
                    "sent": "But there's something wrong about the second part, and in fact his name is Dick Uni, but he's a taxi driver and he went to the he went there.",
                    "label": 0
                },
                {
                    "sent": "For an interview job interview and they say oh get uni OK Great they brought him they put him in the makeup room.",
                    "label": 0
                },
                {
                    "sent": "They brought him on stage and then he started the interview and at that moment that's when he realized that this is not his job interview.",
                    "label": 0
                },
                {
                    "sent": "This is a life TV show in his own life TV.",
                    "label": 0
                },
                {
                    "sent": "So it came and it was really well publicized.",
                    "label": 0
                },
                {
                    "sent": "I think in UK at that point, but I think it's a what it shows is the timing.",
                    "label": 0
                },
                {
                    "sent": "Between modalities and we know really well between face and gesture.",
                    "label": 0
                },
                {
                    "sent": "The timing of these can be really important.",
                    "label": 0
                },
                {
                    "sent": "So when we think about multimodal, we have to think about how to model this.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This different synchrony an eye synchrony between modalities.",
                    "label": 0
                },
                {
                    "sent": "So here I think we all understand the importance of gestures.",
                    "label": 0
                },
                {
                    "sent": "I'm gesturing and be gesture.",
                    "label": 0
                },
                {
                    "sent": "I'm emphasizing iconic gestures.",
                    "label": 0
                },
                {
                    "sent": "This is important also between the Proximex body language.",
                    "label": 1
                },
                {
                    "sent": "I think I'm everybody agree with that.",
                    "label": 1
                },
                {
                    "sent": "The eye contact here is important, and even more with face to face interaction.",
                    "label": 0
                },
                {
                    "sent": "When you want to hold the floor.",
                    "label": 0
                },
                {
                    "sent": "These are really important, and I think we've seen a lot of great work in the past days.",
                    "label": 0
                },
                {
                    "sent": "On facial expression and looking at the automatic and what I love also of the field is we're going a little bit outside the basic facial expression.",
                    "label": 0
                },
                {
                    "sent": "Really expanding that, and I think that's interesting for.",
                    "label": 0
                },
                {
                    "sent": "But there are other people working on other things.",
                    "label": 0
                },
                {
                    "sent": "The other half of human communication.",
                    "label": 0
                },
                {
                    "sent": "And let's say the other half since we believe in face and gesture.",
                    "label": 0
                },
                {
                    "sent": "But there are people also studying verbal and that's really important.",
                    "label": 0
                },
                {
                    "sent": "We saw their message, the transcript.",
                    "label": 0
                },
                {
                    "sent": "There's a lot of information of how people decide which word exactly they decide to speak.",
                    "label": 0
                },
                {
                    "sent": "Also how they phrase their sentences is a really important and is always the semantic aspect of it.",
                    "label": 0
                },
                {
                    "sent": "But there's also the acoustic.",
                    "label": 0
                },
                {
                    "sent": "I'm emphasizing certain word me that also gives me more information.",
                    "label": 0
                },
                {
                    "sent": "So the goal of modeling human communication dynamics is visual, but I think it's also multimodal with verbal, and so there was a question earlier about should language be part of face and gesture.",
                    "label": 0
                },
                {
                    "sent": "I personally believe it is because it allows us.",
                    "label": 0
                },
                {
                    "sent": "To go a level higher and try to include some of the context.",
                    "label": 0
                },
                {
                    "sent": "In some sense, the dialogue context in the interaction so this.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's a big challenge.",
                    "label": 0
                },
                {
                    "sent": "This is a long term, but it has real impact and now is the time to do it.",
                    "label": 0
                },
                {
                    "sent": "We know that connected in solve everything, although the media target world, but it did enable a lot of technology.",
                    "label": 0
                },
                {
                    "sent": "A lot of possibilities, and now we're at the point where we do have technologies.",
                    "label": 0
                },
                {
                    "sent": "I think we had wonderful demos in the past few days where we have at least the low level sensing and some of the recognition there and we want to go higher to better understand human communication.",
                    "label": 0
                },
                {
                    "sent": "And these have real impact.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We have a lot of application where this is possible.",
                    "label": 0
                },
                {
                    "sent": "There is a lot of great work there was on pain and there's an depression being able to look at visual behavior related to depression.",
                    "label": 0
                },
                {
                    "sent": "Suicidal.",
                    "label": 0
                },
                {
                    "sent": "Do you know that there are more than 40 teenagers are weak going to Cincinnati Hospital with suicidal ideations?",
                    "label": 0
                },
                {
                    "sent": "And then you have the Doctor Who has to make this really hard decision.",
                    "label": 0
                },
                {
                    "sent": "Am I keeping that patient him by sending them back?",
                    "label": 0
                },
                {
                    "sent": "They need those tools to be able to objectively be.",
                    "label": 0
                },
                {
                    "sent": "Quantify the behavior and that can really help when we think our nonverbal autistic, both children and young adult helping the young adult to go back into the work.",
                    "label": 0
                },
                {
                    "sent": "But we also have a lot in education.",
                    "label": 0
                },
                {
                    "sent": "Students these days are learning more and more online, but we know that face to face interaction is often a lot more powerful.",
                    "label": 0
                },
                {
                    "sent": "How do we bring face to face interaction online such that students can really work together in a lot more?",
                    "label": 0
                },
                {
                    "sent": "A concrete way and and public speaking.",
                    "label": 0
                },
                {
                    "sent": "I think we had or will have a talk on that, but how can you train people to give good talk?",
                    "label": 0
                },
                {
                    "sent": "And so we had a project on the virtual audience which was really interesting and I believe there is this wonderful source of information now about human communication.",
                    "label": 0
                },
                {
                    "sent": "It's been shown over the years now in many conferences where you can look at people love talking online, sharing their opinion and we have also.",
                    "label": 0
                },
                {
                    "sent": "This great technology of teleconference, Skype and these teleconference system have been the same for more than 10 to 12 years.",
                    "label": 0
                },
                {
                    "sent": "How do we get Skype plus Plus or Google Plus plus if you want?",
                    "label": 0
                },
                {
                    "sent": "But yeah, how do we go beyond just teleconference and enhance this?",
                    "label": 0
                },
                {
                    "sent": "So there's a lot of application of being able to understand visual behavior at a higher level, but it's a hard challenge and so.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, but if you think about it, multimodal started along time ago and we had some great talk.",
                    "label": 0
                },
                {
                    "sent": "I think on Tuesday.",
                    "label": 0
                },
                {
                    "sent": "In fact, some of the earlier work on multimodal started a lot of it in audiovisual speech recognition.",
                    "label": 1
                },
                {
                    "sent": "I think it peaked at some point in 2000, and now it's back even more powerful.",
                    "label": 0
                },
                {
                    "sent": "Multimodal also is really strong, and the reason I'm talking about these is that we have to understand that face and gesture is.",
                    "label": 0
                },
                {
                    "sent": "Part of a larger ecosystem, and by collaborating with outside world or outside world.",
                    "label": 0
                },
                {
                    "sent": "I mean then that's so alien, but about your target.",
                    "label": 0
                },
                {
                    "sent": "By collaborating with these other communities, I think this is how we're going to be able to solve these much challenging problem.",
                    "label": 0
                },
                {
                    "sent": "So in multimedia there's a lot of work on cross Media boat for queries, an four categories of videos.",
                    "label": 0
                },
                {
                    "sent": "Event detection is really a lot of interesting work.",
                    "label": 0
                },
                {
                    "sent": "Recently.",
                    "label": 0
                },
                {
                    "sent": "Affective computing.",
                    "label": 0
                },
                {
                    "sent": "Came up at least the term came up more recently compared with some of the other communities, but the idea of modeling facial expression.",
                    "label": 0
                },
                {
                    "sent": "We had some great challenges on other visual emotion.",
                    "label": 0
                },
                {
                    "sent": "I would say what is wonderful now is that two communities who used to be extremely unimodal are now becoming also multimodal, and that's really that's telling that, yes, this is one of the direction.",
                    "label": 0
                },
                {
                    "sent": "So now these days there's a lot of work on language and vision.",
                    "label": 1
                },
                {
                    "sent": "Really beautiful work on image and captioning video and captioning.",
                    "label": 0
                },
                {
                    "sent": "So I think we see that and you probably were expecting this word.",
                    "label": 0
                },
                {
                    "sent": "So it is coming.",
                    "label": 1
                },
                {
                    "sent": "Yes, deep learning is does help a lot.",
                    "label": 0
                },
                {
                    "sent": "I see a lot of interesting emotion every time this term is spoken.",
                    "label": 0
                },
                {
                    "sent": "I think we should see it as a great enabler.",
                    "label": 0
                },
                {
                    "sent": "It's not going to solve things, but it really brings a lot of possibilities.",
                    "label": 0
                },
                {
                    "sent": "And specifically, I personally love the way deep learning can be applied for language.",
                    "label": 0
                },
                {
                    "sent": "I think this is one of the best enabler.",
                    "label": 0
                },
                {
                    "sent": "I'm going to talk more about it, but all of these community I think are.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "All working together evidentially.",
                    "label": 0
                },
                {
                    "sent": "I went to what I'm hoping to be able to solve the bigger picture of human communication, and personally I think there's at least four challenges when you address human communication once you need to be able to understand each behavior and the dynamic of it.",
                    "label": 0
                },
                {
                    "sent": "And so we as an example, anybody who is from Dublin, Dublin.",
                    "label": 0
                },
                {
                    "sent": "Is there some OK in speech?",
                    "label": 0
                },
                {
                    "sent": "There is the great data set we got from Dublin where we look at.",
                    "label": 0
                },
                {
                    "sent": "All the word yet in the meeting corpus and just listen the different intent behind each of these word.",
                    "label": 0
                },
                {
                    "sent": "It's sorry it's the same word, but they really spoken differently and at the same time trying to find which well known speech researcher is speaking, all of them.",
                    "label": 0
                },
                {
                    "sent": "Yeah yeah, yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah yeah, yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah yeah yeah yeah OK.",
                    "label": 0
                },
                {
                    "sent": "Anyone found who it is?",
                    "label": 0
                },
                {
                    "sent": "Nick Campbell, but he every intonation is really different.",
                    "label": 0
                },
                {
                    "sent": "I could have done the same for smiles at the 50 Shades of smile there I could have done it.",
                    "label": 1
                },
                {
                    "sent": "For most expression, there's always a subtlety in it and we need to be able to model this the second one.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which is obvious by now is we need to learn the dynamic between gesture and different modalities.",
                    "label": 0
                },
                {
                    "sent": "So that's really important interpersonal.",
                    "label": 0
                },
                {
                    "sent": "We had a lot of great work yesterday about social contexts.",
                    "label": 0
                },
                {
                    "sent": "The interpersonal and cultural aspect is really important when you study multimodal communication today, I'm really going to emphasize these two aspects behavior and multimodal together, but I believe they are part of a larger picture so.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here's the challenge in a really small, really simplistic nutshell, but we want to be able to integrate what people say their face and gesture and how they say it all together to be able to infer something about the intent of be able to embed or interpret.",
                    "label": 0
                },
                {
                    "sent": "But this is multimodal, but I also believe that this is multimodal.",
                    "label": 0
                },
                {
                    "sent": "Face and gesture is multimodal implicitly, and so everything I will be explaining today about multimodal.",
                    "label": 0
                },
                {
                    "sent": "I will often use verbal, visual and acoustic.",
                    "label": 0
                },
                {
                    "sent": "But I think a lot of it also generalizes to different modalities, because depth and intensity are also two different modalities.",
                    "label": 0
                },
                {
                    "sent": "So how we're approaching this?",
                    "label": 0
                },
                {
                    "sent": "I really hard problem.",
                    "label": 0
                },
                {
                    "sent": "I think we have to look at it at least in four major challenges.",
                    "label": 0
                },
                {
                    "sent": "There are probably a lot more than that, but I think if you are to start and multimodal and you've not work on this topic yet, I think you have to think about at least 4.",
                    "label": 0
                },
                {
                    "sent": "Four of the main challenges.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One is the hidden temporal structure isto.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Are you about the yeah or I could have done the same with smile.",
                    "label": 0
                },
                {
                    "sent": "Every smile has this dynamic and you need to model this.",
                    "label": 0
                },
                {
                    "sent": "The simplest models of smiles were these early onset peak and upset.",
                    "label": 0
                },
                {
                    "sent": "I think we can go a lot more complex than that to be able to model it and so you need to have technology that learn that hidden structure that learn this dynamic and be able to identify how this change and the most interesting these days.",
                    "label": 1
                },
                {
                    "sent": "How is this dynamic?",
                    "label": 0
                },
                {
                    "sent": "Affecting on long range dependencies, I think there's really interesting work there.",
                    "label": 1
                },
                {
                    "sent": "The second one is about multimodal representation.",
                    "label": 0
                },
                {
                    "sent": "Can we an?",
                    "label": 0
                },
                {
                    "sent": "I think that's one of my dream.",
                    "label": 0
                },
                {
                    "sent": "Can we build a representation where speech and gesture will be together?",
                    "label": 0
                },
                {
                    "sent": "We know it's possible the human brain is able to have such representation.",
                    "label": 1
                },
                {
                    "sent": "At least some people believe that there's a lot of interesting working kinds of science trying to understand the cognitive aspect of speech and gesture.",
                    "label": 1
                },
                {
                    "sent": "But how can we create a representation?",
                    "label": 1
                },
                {
                    "sent": "That jointly learn there both speech and gesture.",
                    "label": 0
                },
                {
                    "sent": "This the third one, is how the synchronization of it and the last one, I think is the key of what makes human communication so challenging.",
                    "label": 0
                },
                {
                    "sent": "Is this inherent uncertainty in the in the interpretation?",
                    "label": 1
                },
                {
                    "sent": "And what when you see object recognition, it's often a really discrete label, emotion or expression, or, implicitly I implicitly uncertain or.",
                    "label": 0
                },
                {
                    "sent": "I use the word fuzziness.",
                    "label": 0
                },
                {
                    "sent": "Really scientific word, but it's really looking at the uncertainty of interpretation and the change of it between people.",
                    "label": 0
                },
                {
                    "sent": "So how do we address this?",
                    "label": 0
                },
                {
                    "sent": "How do we build algorithm to create an model this?",
                    "label": 0
                },
                {
                    "sent": "This is what we're going to do today and I'm going to go through this four points.",
                    "label": 0
                },
                {
                    "sent": "If at any point you have questions, feel free to ask questions.",
                    "label": 0
                },
                {
                    "sent": "Otherwise I will answer this at the end so.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "How do we model the hidden structure?",
                    "label": 0
                },
                {
                    "sent": "What do I mean by hidden structure?",
                    "label": 0
                },
                {
                    "sent": "I mean being able to model inside a certain gesture, so ahead shake has a ignorant, really simple structure to it left right repeatative cyclic gesture.",
                    "label": 0
                },
                {
                    "sent": "But a lot of other emotion or expression have a lot more complex.",
                    "label": 0
                },
                {
                    "sent": "So how do you model this?",
                    "label": 0
                },
                {
                    "sent": "And I will use today just because I'm getting you out outside your comfort zone.",
                    "label": 0
                },
                {
                    "sent": "But maybe of you I'm going to use a lot of examples from language.",
                    "label": 0
                },
                {
                    "sent": "Just because so that you can understand that what we know about face and gesture is also really important for language.",
                    "label": 0
                },
                {
                    "sent": "So we're going to give you a lot of examples for language just to get you a little bit outside that maybe comfort zone.",
                    "label": 0
                },
                {
                    "sent": "So there's been over the years.",
                    "label": 0
                },
                {
                    "sent": "A lot of interesting approaches to model these.",
                    "label": 0
                },
                {
                    "sent": "We have the earlier work on generative model looking at simple Naive Bayes, and I think by now everybody who's done some face and gesture or speech recognition knows about hidden Markov model.",
                    "label": 1
                },
                {
                    "sent": "These are great models that model the dynamic latent structure of the signal in a generative way, and they were really powerful for early work.",
                    "label": 0
                },
                {
                    "sent": "Now these days we still see some generative model, but a lot of work recently, even more discriminative model support vector machines were in there only 2000 in the mid 2000 conditional random field were able to expand this to a more structure.",
                    "label": 1
                },
                {
                    "sent": "There is a struct.",
                    "label": 0
                },
                {
                    "sent": "SVM that also will model the structure.",
                    "label": 0
                },
                {
                    "sent": "This model has the advantage of if you have a task.",
                    "label": 0
                },
                {
                    "sent": "If you have a task in mind discriminating between different expression, if you have a task in my often modeling it discriminatively improve performance.",
                    "label": 0
                },
                {
                    "sent": "It's not true for every data set by it's often improving, so let me give you an example.",
                    "label": 0
                },
                {
                    "sent": "As I said, for language so that you understand so Anon phrase non first segmentation is one of the early step.",
                    "label": 0
                },
                {
                    "sent": "It's the same way you're going to do a gesture.",
                    "label": 0
                },
                {
                    "sent": "Segmentation is the early stage before doing something more high level like sentiment analysis.",
                    "label": 0
                },
                {
                    "sent": "So how do people do so?",
                    "label": 0
                },
                {
                    "sent": "I have a sentence.",
                    "label": 0
                },
                {
                    "sent": "OK Oh my gosh, I didn't expect to see words.",
                    "label": 0
                },
                {
                    "sent": "Where are my images so I have a simple sentence and I want to segment it to know where is the beginning of a noun phrase.",
                    "label": 0
                },
                {
                    "sent": "These are the key moments beginning of a noun phrase so I can segment it and so this is the continuity of a noun phrase and this is other meaning that in this case it's the verb.",
                    "label": 0
                },
                {
                    "sent": "So you want to be able to automatically that.",
                    "label": 0
                },
                {
                    "sent": "But I could have easily put here the beginning of a head, nods and then a head shakes.",
                    "label": 0
                },
                {
                    "sent": "This is the same general idea.",
                    "label": 0
                },
                {
                    "sent": "The reason I'm doing this is that I want to model this.",
                    "label": 0
                },
                {
                    "sent": "Sequence of information and I want to model it to be able to recognize it discriminatively and so I have my input and there is an interesting thing.",
                    "label": 0
                },
                {
                    "sent": "The usual way to represent word will be all really long vector that simply as a bag of features.",
                    "label": 0
                },
                {
                    "sent": "So let's suppose for our simple bag of feature that you can recognize that.",
                    "label": 0
                },
                {
                    "sent": "So the typical conditional random field will be looking OK.",
                    "label": 0
                },
                {
                    "sent": "This is 1 equation.",
                    "label": 0
                },
                {
                    "sent": "If you have.",
                    "label": 0
                },
                {
                    "sent": "I know all the all the next equation will all come from.",
                    "label": 0
                },
                {
                    "sent": "This one, so just take a second to understand that probably a lot of you understand the basic of this, But this if you have to focus on one equation, understand this one all the rest after that are much easier, ever neural networks these days will be often represented as potential function, so a lot of the representation that you see it is the same for a lot of models.",
                    "label": 0
                },
                {
                    "sent": "So the simple model in this state that will try to predict.",
                    "label": 0
                },
                {
                    "sent": "And when you think of discriminative, think of conditional probability, that's usually.",
                    "label": 0
                },
                {
                    "sent": "The way of optimizing a discriminative model, so I want to optimize the probability of seeing these label given that I observe these words.",
                    "label": 0
                },
                {
                    "sent": "So it's a simple conditional probability and two main aspect to it is I will have what we've seen in the hidden Markov model as an observation model.",
                    "label": 0
                },
                {
                    "sent": "So I will model the potential or let's say it the relationship or the closeness between my observation and the labels.",
                    "label": 0
                },
                {
                    "sent": "And I will also model the dynamic between my labels, so there's only two terms here and I have parameters to try to see how each word in the simplest case you could imagine how each word of my dictionary is correlated to a specific label.",
                    "label": 0
                },
                {
                    "sent": "That's the easiest way of thinking of potential function, so this is a really powerful this kind of energy model or representation is really powerful, and what I love about it.",
                    "label": 0
                },
                {
                    "sent": "The reason I like this kind of model is that they are a lot easier to interpret because if I want to know what did the model learn, I can go and look at these parameters and look at which word was important for which label, and I think that's when you start doing analysis that's more high level.",
                    "label": 0
                },
                {
                    "sent": "You want to be able to interpret the model, so I think this is important, But this doesn't solve everything that we wanted to.",
                    "label": 0
                },
                {
                    "sent": "It doesn't solve the hidden structure, it doesn't learn the hidden structure, so.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, how do you model the hidden structure?",
                    "label": 0
                },
                {
                    "sent": "And here's again, that's on purpose language example, because in NLP often when you do this kind of problem, you will look at what's called part of speech tagging.",
                    "label": 0
                },
                {
                    "sent": "So you will look at these.",
                    "label": 0
                },
                {
                    "sent": "Then viable to better predict your label and what we want is we are lazy, OK and we don't want to label this by hand.",
                    "label": 0
                },
                {
                    "sent": "So what we will do is in fact learn some later.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Variable latent be behavior that will later viable that will model this for us.",
                    "label": 0
                },
                {
                    "sent": "And so when you think of latent variable, always think of these grouping of behaviors or grouping of features and so we will learn this automatically and I'm going to skip some of them at.",
                    "label": 0
                },
                {
                    "sent": "But what I want you to learn here is that I'm going to learn the grouping and let me give you the example here for gesture recognition.",
                    "label": 0
                },
                {
                    "sent": "So I have a lot of frames that go one way.",
                    "label": 0
                },
                {
                    "sent": "I want to group them together.",
                    "label": 0
                },
                {
                    "sent": "And I am going to do the same, so that's how you learn this latent structure is that the model will learn it for you, so.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "By doing that, what you learn is two things.",
                    "label": 0
                },
                {
                    "sent": "And that's the main take.",
                    "label": 0
                },
                {
                    "sent": "Home message here.",
                    "label": 0
                },
                {
                    "sent": "Forget the match for a second.",
                    "label": 0
                },
                {
                    "sent": "The two things.",
                    "label": 0
                },
                {
                    "sent": "There's two type of dynamics you're gonna learn.",
                    "label": 0
                },
                {
                    "sent": "OK, there's one dynamic which is inside in the label, so the dynamic is what is my dynamic inside my gestures.",
                    "label": 0
                },
                {
                    "sent": "But you also want to learn what is the dynamic between gestures and these are the two type of dynamic you're going to learn automatically with this kind of model.",
                    "label": 0
                },
                {
                    "sent": "And I think this is.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is really powerful and that can in fact learn automatically how to group all of these latent variable automatically.",
                    "label": 0
                },
                {
                    "sent": "And so you learn automatically that the beginning of a sentence often start with determinant.",
                    "label": 0
                },
                {
                    "sent": "A beginning of a sentence always start with the determinant, but the same thing could be also a happy smile.",
                    "label": 0
                },
                {
                    "sent": "Often start with unset, so that's a lot of the same intuition.",
                    "label": 0
                },
                {
                    "sent": "And what is?",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Red is the same model, can work really well for face and gestures.",
                    "label": 0
                },
                {
                    "sent": "There's been a lot of great work presented yesterday using LD CRF, an extension of ldif.",
                    "label": 0
                },
                {
                    "sent": "It works really well for gesture and works really well for language.",
                    "label": 0
                },
                {
                    "sent": "OK, this was really painful talking about language.",
                    "label": 0
                },
                {
                    "sent": "The rest of it is an example will be about vision, but I wanted you to get at least some intuition that a lot of the same model we're using for facial expression recognition works really well with language.",
                    "label": 0
                },
                {
                    "sent": "Ah.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And these models can be able to not just predict instantaneously the state, but you can also summarize it.",
                    "label": 0
                },
                {
                    "sent": "And I think this is a powerful aspect of it too, is to integrate all this overtime.",
                    "label": 0
                },
                {
                    "sent": "So if I have a full video and I want to know the general expression or emotion in this video, you can also use these same models extension that are to be able to generalize it and the only take all my one here is that you start being able to share.",
                    "label": 0
                },
                {
                    "sent": "Hidden State between labels?",
                    "label": 0
                },
                {
                    "sent": "What does it mean?",
                    "label": 0
                },
                {
                    "sent": "So let's say I'm trying to recognize happy, sad.",
                    "label": 0
                },
                {
                    "sent": "Let's let's put content just to be a little bit more interesting.",
                    "label": 0
                },
                {
                    "sent": "So happy and content are probably sharing a lot of the dynamic.",
                    "label": 0
                },
                {
                    "sent": "A lot of the same features, so you don't want to just learn one for happy and one for content.",
                    "label": 0
                },
                {
                    "sent": "So you want to be able to learn some shared representation, and these models can learn that as well.",
                    "label": 0
                },
                {
                    "sent": "So I think that's one of the powerful aspect of.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this was a lot more mathematical, and now I'm going to get into how we take all this prior work on modeling latent dynamic to be able to be able to do multimodal.",
                    "label": 0
                },
                {
                    "sent": "OK, so we have first aspect is representation and I think that's one of the great challenge with a lot of this work is how do you represent together verbal, acoustic and visual together?",
                    "label": 0
                },
                {
                    "sent": "How do we represent not just the how do you represent the three of them together?",
                    "label": 0
                },
                {
                    "sent": "And this is, I think there's been some interesting work also presenting how you do face and body.",
                    "label": 0
                },
                {
                    "sent": "And that's the same idea.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here, so you want to be able to learn the same kind of models, but now we're going to add this neural layer, and here's what I want you to understand.",
                    "label": 0
                },
                {
                    "sent": "Conditional random field were invented originally for language.",
                    "label": 0
                },
                {
                    "sent": "They work extremely well when your features are this bag of features, because each feature is a discrete one, and what you learn is how important each of them is.",
                    "label": 0
                },
                {
                    "sent": "But if you have continuous features were like we have here in face and gesture, you should be aware that.",
                    "label": 0
                },
                {
                    "sent": "This model may not be optimal.",
                    "label": 0
                },
                {
                    "sent": "It's much better to have a first layer like a neuron that is going to learn this.",
                    "label": 0
                },
                {
                    "sent": "We have continuous feature in face and gesture.",
                    "label": 0
                },
                {
                    "sent": "We have these continuous features.",
                    "label": 0
                },
                {
                    "sent": "So how do you model these continuous features?",
                    "label": 0
                },
                {
                    "sent": "They being able to learn it with the neural layer will allow you to group or represent them in a much easier way such that you learn the representation and then you learn after that how these features are important for your task.",
                    "label": 0
                },
                {
                    "sent": "So the couple in your mind, these two step feature representation and then modeling of the dynamic it's better to today couple that and it's much easier for a lot of the system.",
                    "label": 0
                },
                {
                    "sent": "Once you de couple it you have one layer that is learning what is the right way to look.",
                    "label": 0
                },
                {
                    "sent": "I have this motion I'm moving right now.",
                    "label": 0
                },
                {
                    "sent": "This is a highly dimensional vector or representation.",
                    "label": 0
                },
                {
                    "sent": "This first layer is going to be there.",
                    "label": 0
                },
                {
                    "sent": "To learn to represent this such that you can then learn the dynamic of it.",
                    "label": 0
                },
                {
                    "sent": "So decoupling this and two different layer improve a lot the performance in Oliver at task we've tried and it's really easy mathematically.",
                    "label": 0
                },
                {
                    "sent": "You just adding these weights.",
                    "label": 0
                },
                {
                    "sent": "So what is this weight learning?",
                    "label": 0
                },
                {
                    "sent": "It's a representation.",
                    "label": 0
                },
                {
                    "sent": "What is this weight learning is?",
                    "label": 0
                },
                {
                    "sent": "Which features is important?",
                    "label": 0
                },
                {
                    "sent": "What is this weight learning?",
                    "label": 0
                },
                {
                    "sent": "Is the dynamic and so you're decoupling that and then you can analyze it afterwards.",
                    "label": 0
                },
                {
                    "sent": "It makes it much.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Powerful and the key aspect.",
                    "label": 0
                },
                {
                    "sent": "Of what?",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Why deep learning is now possible?",
                    "label": 0
                },
                {
                    "sent": "An why?",
                    "label": 0
                },
                {
                    "sent": "All of this is the challenge is when you do these OK, multiple layer is each layer end up learning the same thing.",
                    "label": 0
                },
                {
                    "sent": "That's a challenge when you do hidden or latent on deep learning or multiple layer is the challenge that you don't want one layer to learn the same as the next layer.",
                    "label": 0
                },
                {
                    "sent": "And This is why you will add some regularization that makes it such that one layer learn something different than the other and there are many different trick for that.",
                    "label": 0
                },
                {
                    "sent": "The most simplest one these days is the dropout, where you randomly turn off some of your neurons and it turns out that this is the trick to make deep learning.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Working not the only one, but one of the main one.",
                    "label": 0
                },
                {
                    "sent": "So when you.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To do this, you can improve a lot on what was the LDIF for a lot of the work.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's the audio Visual Emotion Challenge and so in these challenges you have visual and acoustic feature.",
                    "label": 0
                },
                {
                    "sent": "You look up.",
                    "label": 0
                },
                {
                    "sent": "Sorry I put the word emotion.",
                    "label": 0
                },
                {
                    "sent": "You have the.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Pression of arousal and then in this case you improve dramatically, and I think the main reason for that, is that not only are you able to learn a better representation, but that representation is multimodal in this case, so audio and visual were able to merge at that layer, and you're like, oh, but you didn't say the word deep yet.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Why I got everything should be deep.",
                    "label": 0
                },
                {
                    "sent": "These models why I took the time to explain to you the CIF.",
                    "label": 0
                },
                {
                    "sent": "The conditional random field is that neural networks are the exact same, almost the same, a lot of.",
                    "label": 0
                },
                {
                    "sent": "The neural network have the same structure, so here it's the same exact representation.",
                    "label": 0
                },
                {
                    "sent": "So here you have multiple layer, so you these are imagine neural layers and then you can model this the exact same thing.",
                    "label": 0
                },
                {
                    "sent": "But as you know the deep learning or neural network often are not dynamic, although there's some conditional version of that.",
                    "label": 0
                },
                {
                    "sent": "So here is the same idea and I'm going to show this.",
                    "label": 0
                },
                {
                    "sent": "Improved here, you probably saw this representation more often, but what we see here.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is the same idea.",
                    "label": 0
                },
                {
                    "sent": "So imagine that this is the same.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As this will.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Presentation, So what it is is all the great work you hear about deep learning can be included or inserted in all of these conditional random field or energy models.",
                    "label": 0
                },
                {
                    "sent": "So now these days they we hear a lot about image and caption which are forgetting about this temporal aspect.",
                    "label": 0
                },
                {
                    "sent": "But we know the importance in this community of temporal for the gesture for the facial expression we know that we are expert in that aspect.",
                    "label": 0
                },
                {
                    "sent": "And I think This is why this community is one of the community ready to look at the next stage.",
                    "label": 0
                },
                {
                    "sent": "Let's go outside of just the static Image caption and let's look at temporal information.",
                    "label": 0
                },
                {
                    "sent": "But there's been great work, so if you have two papers to look at when you come back these two papers, but primarily the second one, the first one is just because I told you, uh, do visual speech recognition had a really big peak in 2000, and now these days, a lot of this work and I just put the first one.",
                    "label": 0
                },
                {
                    "sent": "But there's a long line of now work on audiovisual speech recognition.",
                    "label": 1
                },
                {
                    "sent": "That really learns this George representation and what I love about it by learning it jointly.",
                    "label": 0
                },
                {
                    "sent": "Then you a lot more robust to occlusion or missing data.",
                    "label": 0
                },
                {
                    "sent": "And what does it mean?",
                    "label": 0
                },
                {
                    "sent": "I think in audiovisual speech term it means if one of your channel is really noisy, the other one will compensate automatically.",
                    "label": 0
                },
                {
                    "sent": "And so in this case of audiovisual, if my audio channel is is noisy then the visual will compensate.",
                    "label": 0
                },
                {
                    "sent": "And so this is 1 but the one where I really want you to read and take time to read that paper.",
                    "label": 0
                },
                {
                    "sent": "This is this was a insightful paper, and there's a lot follow up with data from Stanford, but this paper what it did is is video and text.",
                    "label": 0
                },
                {
                    "sent": "Image and caption of picture of a dog and the word dog.",
                    "label": 0
                },
                {
                    "sent": "Really simple thing.",
                    "label": 0
                },
                {
                    "sent": "But by learning this representation together, what were they able to do?",
                    "label": 0
                },
                {
                    "sent": "You put an image in the network and you get the words that is the most likely.",
                    "label": 0
                },
                {
                    "sent": "This was wonderful with joint representation.",
                    "label": 0
                },
                {
                    "sent": "If you put a word then you see the kind of images you see for that word.",
                    "label": 0
                },
                {
                    "sent": "That is really interesting.",
                    "label": 1
                },
                {
                    "sent": "And I told you let the best application of deep learning in my in my mind is language.",
                    "label": 0
                },
                {
                    "sent": "It does really well for vision convolutional network.",
                    "label": 0
                },
                {
                    "sent": "But let's talk about deep learning for language.",
                    "label": 0
                },
                {
                    "sent": "What happened before?",
                    "label": 0
                },
                {
                    "sent": "If you want to merge language and vision, you had to look at symbols like words and merge it with signals, which is what we're mostly used to in the face and gesture and speed.",
                    "label": 0
                },
                {
                    "sent": "But now these days.",
                    "label": 0
                },
                {
                    "sent": "You have a representation that is based on what's called distributional hypothesis, so they look at all of Wikipedia under word in Wikipedia and look at where are the words each word usually happened.",
                    "label": 0
                },
                {
                    "sent": "Where is its neighborhood and what it did is it's an approximation to what's called semantic and we in computer and computer vision the user work semantic like it's like peanut butter or like, but what really semantic in this case is an approximation.",
                    "label": 0
                },
                {
                    "sent": "Is that if the word, let's say the word men and women, they will often be used in similar sentence is just with a different with the same neighborhood.",
                    "label": 0
                },
                {
                    "sent": "So they are able to learn a vectorial representation of how a word should be represented mathematically, and I think that's a beautiful thing of it is now with the deep learning.",
                    "label": 0
                },
                {
                    "sent": "I take a word and you can transform it to vectors and are many of them.",
                    "label": 0
                },
                {
                    "sent": "In fact, the obvious one is the Google one that's called word two vectors.",
                    "label": 0
                },
                {
                    "sent": "But what it is that vector intuitively?",
                    "label": 0
                },
                {
                    "sent": "What I what I see is that each dimension you could see it as one dimension could be arousal, one dimension.",
                    "label": 0
                },
                {
                    "sent": "Who could be some aspect of gender.",
                    "label": 0
                },
                {
                    "sent": "So these vector representation are beautiful wave.",
                    "label": 0
                },
                {
                    "sent": "So if you want to do multimodal then now we have a nice way of representing thing vectorially numerically so that we can do Fusion with the audio and visual OK it's alone explanation but at the end of the day I will say look at this kind of work.",
                    "label": 0
                },
                {
                    "sent": "Because I think it can be really inspiring for your future work and there is an audio visual emotion challenge.",
                    "label": 0
                },
                {
                    "sent": "Recognition already from 2013.",
                    "label": 0
                },
                {
                    "sent": "This one was done on the emo cap again.",
                    "label": 0
                },
                {
                    "sent": "OK, so yes this was great work and then the.",
                    "label": 0
                },
                {
                    "sent": "Is a lot of follow up since then and I think he has at least 10 papers on deep learning and emotion.",
                    "label": 0
                },
                {
                    "sent": "So OK, so this was my deep learning slide.",
                    "label": 0
                },
                {
                    "sent": "I don't want to overemphasize it but you have questions.",
                    "label": 0
                },
                {
                    "sent": "We are in fact preparing and multimodal surveys.",
                    "label": 0
                },
                {
                    "sent": "That's going to come out in a few months so that.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Going to come out to help that so.",
                    "label": 0
                },
                {
                    "sent": "Nonlinearity is important and representation is important.",
                    "label": 0
                },
                {
                    "sent": "The second aspect is we are used to 30 frames per second.",
                    "label": 0
                },
                {
                    "sent": "We love it.",
                    "label": 0
                },
                {
                    "sent": "High frame rate but words other than me.",
                    "label": 0
                },
                {
                    "sent": "Most people speak maybe 3 or 4 words per second.",
                    "label": 0
                },
                {
                    "sent": "I'ma probably much higher than that, but how do you take words and allowing them with a really high frame rate?",
                    "label": 0
                },
                {
                    "sent": "I personally believe that we need to do what's called modality summarization.",
                    "label": 0
                },
                {
                    "sent": "Take a high frame rate video.",
                    "label": 0
                },
                {
                    "sent": "And be able to summarize it, and there's some interesting work on summarization.",
                    "label": 0
                },
                {
                    "sent": "But my goal here is not to summarize so I can show a shorter clip too.",
                    "label": 0
                },
                {
                    "sent": "The subject, but mostly because I want to the keyframes of a sequence and so.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here I have a sequence and I would like to learn this representation that will summarize the whole sequence.",
                    "label": 0
                },
                {
                    "sent": "N. I don't want to just summarize it, but I have a task in mind.",
                    "label": 0
                },
                {
                    "sent": "I want to summarize it such that I can better recognize the gesture.",
                    "label": 0
                },
                {
                    "sent": "If you have a task in mind, think discriminative model.",
                    "label": 0
                },
                {
                    "sent": "So task in mind discriminative model.",
                    "label": 0
                },
                {
                    "sent": "So I want to be able to take this input sequence and do summarization.",
                    "label": 0
                },
                {
                    "sent": "What are the two obvious way of taking this observation and summarizing in them?",
                    "label": 0
                },
                {
                    "sent": "There are two obvious way the first one will be to take a same fixed sampling rate.",
                    "label": 0
                },
                {
                    "sent": "I'm going to take one out of every 4 frames and I think there were some good work on that and I had a lot of time.",
                    "label": 0
                },
                {
                    "sent": "This kind of pyramid approach works really well the other.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One would be let's look at the frame and let's look at 2 frames look alike and we're going to merge them together if they look alike.",
                    "label": 0
                },
                {
                    "sent": "But I have a task in mind, so there's a third way to do it, which is I have a task of recognizing gesture, so I'm going to use the same HCI F that we've learned earlier, and I'm going to learn what are the remember every time you hear latent variable or hidden Bible.",
                    "label": 0
                },
                {
                    "sent": "Think of grouping, grouping with a task in mind, so I'm gonna end up group.",
                    "label": 0
                },
                {
                    "sent": "My observation with a task in mind and do the grouping at that level because these are kind of taking my observation and putting in a low dimensional space.",
                    "label": 0
                },
                {
                    "sent": "And there I'm going to do the grouping and doing that.",
                    "label": 0
                },
                {
                    "sent": "I'm going to skip some of the details.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But doing that you can not only be able to summarize, but we end up improving on gesture recognition by being able to create this pyramid of representation.",
                    "label": 0
                },
                {
                    "sent": "Some gesture may be better recognized at a high frame rate, some gesture at a lower frame rate.",
                    "label": 0
                },
                {
                    "sent": "So by doing that we can better Rica.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Nice and both on the task.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of recognizing our man, gesture, arm and hand gestures, and also for the really.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Old videos that we had for the under this don't use this data set please 99.59 let's stop using this data set, but it's a gesture data set that was done along time ago, but we really improve by having this multiple layer and not only.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Were you able to create that?",
                    "label": 0
                },
                {
                    "sent": "But we can know where they're from, and that's really interesting, because now you can see these summarize a really specific aspect of the gesture so.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is 1 aspect that was really important is representation.",
                    "label": 0
                },
                {
                    "sent": "The second one is synchrony or asynchrony, and we said in our data we had the facial expression happening of surprise when he was when we heard his title and that's really important.",
                    "label": 0
                },
                {
                    "sent": "So you want to be able to learn the synchrony and the complementary.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Pretty, the complementarity is some early work on Coadaptation Norco core learning that has been done, but I will.",
                    "label": 0
                },
                {
                    "sent": "I will emphasize primarily the synchrony in this case, so they just do.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So people are aware of this work.",
                    "label": 0
                },
                {
                    "sent": "I'm not emphasizing it, but there's some early work trying to code app so I have more and modality and I like audio.",
                    "label": 0
                },
                {
                    "sent": "I want to be able to learn and find the strong cases or positive strong cases and use that to improve the visual and vis versa together.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some early work.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, but there one way I really want take home message when you think of multimodal.",
                    "label": 0
                },
                {
                    "sent": "There are two type of dynamic.",
                    "label": 0
                },
                {
                    "sent": "Again there is the dynamic that's private to that modality.",
                    "label": 0
                },
                {
                    "sent": "And then there's the the one that shared between modalities.",
                    "label": 0
                },
                {
                    "sent": "And why do we go through this whole process of doing both?",
                    "label": 0
                },
                {
                    "sent": "OK, let's think of audio and visual.",
                    "label": 0
                },
                {
                    "sent": "Audio has its own noise model.",
                    "label": 0
                },
                {
                    "sent": "The noise model there is really different from what you will see in images and so that you want to be able to model each of them independently.",
                    "label": 0
                },
                {
                    "sent": "But then after that find out when they should be seen.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Cronise, and so we will look at a model like the HCI F, But we're going to in fact not just do the typical early and late Fusion early Fusion will be.",
                    "label": 0
                },
                {
                    "sent": "I in fact end up stacking together all my features and just learn the same model.",
                    "label": 0
                },
                {
                    "sent": "And that's one of the things.",
                    "label": 0
                },
                {
                    "sent": "Please, if you submit any papers through ICM, I or any of this conference try to go a little bit further than just Lillian late Fusion.",
                    "label": 0
                },
                {
                    "sent": "I think there's a lot of interesting word that's been there, but let's try to go a step further.",
                    "label": 0
                },
                {
                    "sent": "I think this is the next stage now of that, and so can we model where we have one sequence for audio and the second sequence.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The video and each of them have their private dynamic, so you learn audio and visual how each of them, they're noise and all this.",
                    "label": 0
                },
                {
                    "sent": "So you learn that, and then you're going to learn when they synchronize together.",
                    "label": 0
                },
                {
                    "sent": "And I just heard there's some interesting work extension of that work that thing that's going to be presented soon, so there's a lot of interesting model of that these the same model as before.",
                    "label": 0
                },
                {
                    "sent": "It's a conditional probability is just that.",
                    "label": 0
                },
                {
                    "sent": "Instead of having just X, you have the observation for the audio.",
                    "label": 0
                },
                {
                    "sent": "And observation from the visual.",
                    "label": 0
                },
                {
                    "sent": "And when you do that.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then you prove on a lot of cases this was for agreement disagreement data set that it was improving.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The the final part of this whole multimodal is the interpretation, and the problem is so big and this is just a small baby step, but I want you to at least think about it, and I think the talk yesterday and I think the workshop on context was first step towards that.",
                    "label": 0
                },
                {
                    "sent": "But really, when we interpret a state of the user like let's say an emotion or expression, there's a lot of variability on how people are interpreting this.",
                    "label": 0
                },
                {
                    "sent": "So people, all these people looking at the same videos may have really slightly different interpretation.",
                    "label": 0
                },
                {
                    "sent": "And how are we going to model this difference between observers?",
                    "label": 0
                },
                {
                    "sent": "I think this is a wonderful research problem and has been understudied in machine learning.",
                    "label": 0
                },
                {
                    "sent": "I will give you a really small approximation of that which is instead of doing the discrete the discrete between looking at an emotion, an expression as active or not, which is all what I talk.",
                    "label": 0
                },
                {
                    "sent": "We're going to look at it as a regression problem, so we're going to look at the same kind of behavior.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Kind of model as before, but now it's regression, so I have here one of the output, maybe from avek that tells me on how much violence are, or recently with Farrah it was wonderful with all of these different intensity X action units, so this is what I'm trying to predict and my input could be unimodal or bimodal.",
                    "label": 0
                },
                {
                    "sent": "Tree MoD try model and I'm going to try to learn OK so this is my observation.",
                    "label": 0
                },
                {
                    "sent": "What is this?",
                    "label": 0
                },
                {
                    "sent": "This is a neural network.",
                    "label": 0
                },
                {
                    "sent": "Why did I put it there?",
                    "label": 0
                },
                {
                    "sent": "Why didn't I just connect them?",
                    "label": 0
                },
                {
                    "sent": "Because my input, let's say I'm looking at facial expression is really is is not just a discrete input like text.",
                    "label": 0
                },
                {
                    "sent": "It's a lot more complex, so I need these neurons to learn my representation.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "What?",
                    "label": 0
                },
                {
                    "sent": "Oh sorry, the color scheme.",
                    "label": 0
                },
                {
                    "sent": "No, they're not observed there.",
                    "label": 0
                },
                {
                    "sent": "Great, sorry they're not observe and so you're going to learn that their latent, sorry, the color scheme.",
                    "label": 0
                },
                {
                    "sent": "Not perfect here.",
                    "label": 0
                },
                {
                    "sent": "And So what is the biggest challenge when you do regression?",
                    "label": 0
                },
                {
                    "sent": "Is this integral?",
                    "label": 0
                },
                {
                    "sent": "This integral is what makes this a hard problem is because before we had discrete label, because you had discrete label, you could go through all possible label or do an approximation, would believe propagation, but because now you're going from minus Infinity, you'll able could go from minus Infinity plus Infinity.",
                    "label": 0
                },
                {
                    "sent": "You are a much harder case, so nicely is that there's an approximation to that someone else has seen that if you can take this.",
                    "label": 0
                },
                {
                    "sent": "Equation here if you can take this equation here and put it in this format.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What is this?",
                    "label": 0
                },
                {
                    "sent": "It looks really fancy, but this is just a Gaussian.",
                    "label": 0
                },
                {
                    "sent": "This is a Gaussian distribution, so if you can put it in this format, this equation in this format, then there's a solution to it.",
                    "label": 0
                },
                {
                    "sent": "There's a nice solution to it, and not just.",
                    "label": 0
                },
                {
                    "sent": "There's a solution to that, but.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On top of that, the most when you have a Gaussian, what is the optimal point of a Gaussian?",
                    "label": 0
                },
                {
                    "sent": "The mean?",
                    "label": 0
                },
                {
                    "sent": "So if you're optimizing this, you get automatically the up the maximum of that distribution is going to be in the mean, which can be computed really easily.",
                    "label": 0
                },
                {
                    "sent": "So this was some great work that was done.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And collaboration with Harris and Peter and so what's also really nice with it is not only because you are not doing anymore approximation for belief propagation.",
                    "label": 0
                },
                {
                    "sent": "You can now start have long range dependencies.",
                    "label": 0
                },
                {
                    "sent": "So now you can model long range dependencies an you can start modeling a 2D cases so you can start modeling today and this is how the facial landmark detector was, because now your input will be an image and that's working the same way here, so the same.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Model can be extended as large as we want, so.",
                    "label": 0
                },
                {
                    "sent": "And that is.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Improve on many datasets.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Also, for emotion, and this was work.",
                    "label": 0
                },
                {
                    "sent": "Great work done by Ta da sound that so.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is a summary.",
                    "label": 0
                },
                {
                    "sent": "Hopefully you're still with me and sleeping already because of all the math.",
                    "label": 0
                },
                {
                    "sent": "But what I wanted to emphasize today is when you think about multimodal, think first about unimodal.",
                    "label": 0
                },
                {
                    "sent": "It's still really important, but when you think of your new model, think of this temporal structure.",
                    "label": 0
                },
                {
                    "sent": "How do you model the different?",
                    "label": 0
                },
                {
                    "sent": "Yeah, the different smile.",
                    "label": 0
                },
                {
                    "sent": "How do you model that dynamic second?",
                    "label": 0
                },
                {
                    "sent": "How do I represent linear this?",
                    "label": 0
                },
                {
                    "sent": "Relationship disincentive this relationship and for that you should really think about it as now I really really fashion area and so I don't think I've seen the word multimodal at NIPS or ICML until 2012, or really few cases.",
                    "label": 0
                },
                {
                    "sent": "And now if you look at these machine learning conferences, use it regularly so this is a wonderful time to do that kind of research, and because our communities.",
                    "label": 0
                },
                {
                    "sent": "Are recognizing the importance of it.",
                    "label": 0
                },
                {
                    "sent": "Multimedia always knew it, but now the speech, language, vision and machine learning also recognizing the important think about synchrony and prediction.",
                    "label": 0
                },
                {
                    "sent": "I didn't talk about multitask, but you can also try to predict more than one expression or action unit at the same time.",
                    "label": 0
                },
                {
                    "sent": "There's some great work done on that.",
                    "label": 0
                },
                {
                    "sent": "I've put, uh, we do our best to take all of those algorithms we created and try to put it in one place.",
                    "label": 0
                },
                {
                    "sent": "If the algorithm is not there yet, email us.",
                    "label": 0
                },
                {
                    "sent": "When do our best to share it.",
                    "label": 0
                },
                {
                    "sent": "I think we eventually if you do extensions to these algorithm, if you share it with us, that's all.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Really nice so that the community does so am I doing on time?",
                    "label": 0
                },
                {
                    "sent": "OK, great so I'm just going to show these five minutes this last five which is which was in fact the introduction of it is that it has a real impact.",
                    "label": 0
                },
                {
                    "sent": "This work and this work can really help.",
                    "label": 0
                },
                {
                    "sent": "In our case we want to help doctors and clinicians to be able to recognize distress, depression and so I'm going to show this how this technology can be used in a real application.",
                    "label": 0
                },
                {
                    "sent": "In this case recognizing distress.",
                    "label": 0
                },
                {
                    "sent": "So let's listen at this videos and look at two things.",
                    "label": 0
                },
                {
                    "sent": "One is the distress person and second look at the clinician.",
                    "label": 0
                },
                {
                    "sent": "How is she interacting?",
                    "label": 0
                },
                {
                    "sent": "She's a wonderful tension who ended up being really trying to show a lot of.",
                    "label": 0
                },
                {
                    "sent": "Engaging behavior in this case, so let's look at it.",
                    "label": 0
                },
                {
                    "sent": "How?",
                    "label": 0
                },
                {
                    "sent": "Yeah, I mean I I didn't suffocate, but I was very uncomfortable like it never happens.",
                    "label": 0
                },
                {
                    "sent": "Pressure.",
                    "label": 0
                },
                {
                    "sent": "Sarah.",
                    "label": 0
                },
                {
                    "sent": "So I mean, I notice that.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I'm.",
                    "label": 0
                },
                {
                    "sent": "I didn't even manage to come rescue me or anything, but but what's interesting is to see this behavior.",
                    "label": 0
                },
                {
                    "sent": "How can we quantify this behavior of distress, like the tone of voice and all all these behavior, so I think.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is 1 area that I'm really excited and I think there's a lot of momentum there.",
                    "label": 0
                },
                {
                    "sent": "We call it health behavior informatics, but the idea of taking these interaction, either human to human or human, to virtual human and be able to quantify how is this person behaving today?",
                    "label": 0
                },
                {
                    "sent": "How were they?",
                    "label": 0
                },
                {
                    "sent": "A week ago, two weeks ago?",
                    "label": 0
                },
                {
                    "sent": "How can I compare with?",
                    "label": 0
                },
                {
                    "sent": "Database, maybe they have other people who were in distress and be able to learn from that.",
                    "label": 0
                },
                {
                    "sent": "Is this person getting better or worse and this person seems to be getting better.",
                    "label": 0
                },
                {
                    "sent": "That's a good news.",
                    "label": 0
                },
                {
                    "sent": "And so when you put everything together, what's interesting here, I'm going to show a video.",
                    "label": 0
                },
                {
                    "sent": "This is the final video I'm going to show.",
                    "label": 0
                },
                {
                    "sent": "You are going to see all the sensing and you're going to see the virtual human who is reacting all the work I presented today can be used for recognition of distress behavior.",
                    "label": 0
                },
                {
                    "sent": "But it can also be used for prediction, and in this case for animation of the virtual human.",
                    "label": 0
                },
                {
                    "sent": "And so here's the.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Video thanks for coming in today.",
                    "label": 0
                },
                {
                    "sent": "I was created to talk to people in a safe and secure environment.",
                    "label": 0
                },
                {
                    "sent": "I'm not a therapist, but I'm here to learn about people and would love to learn about you.",
                    "label": 0
                },
                {
                    "sent": "I'll ask a few questions to get us started.",
                    "label": 0
                },
                {
                    "sent": "Everything is live free to tell me anything.",
                    "label": 0
                },
                {
                    "sent": "Your answers are totally confidential.",
                    "label": 0
                },
                {
                    "sent": "Are you OK with this?",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "So how are you doing today?",
                    "label": 0
                },
                {
                    "sent": "I'm doing well.",
                    "label": 0
                },
                {
                    "sent": "That's good.",
                    "label": 0
                },
                {
                    "sent": "Where are you from originally?",
                    "label": 0
                },
                {
                    "sent": "I'm from Los Angeles.",
                    "label": 0
                },
                {
                    "sent": "Oh, I'm from LA myself.",
                    "label": 0
                },
                {
                    "sent": "When was the last time you felt really happy?",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "But I try to stay happy.",
                    "label": 0
                },
                {
                    "sent": "I rather be happy.",
                    "label": 0
                },
                {
                    "sent": "My kids keep me going.",
                    "label": 0
                },
                {
                    "sent": "What advice would you have given yourself 10 or 20 years ago?",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "2.",
                    "label": 0
                },
                {
                    "sent": "I do not believe.",
                    "label": 0
                },
                {
                    "sent": "Do not be so gullible to not be so gullible.",
                    "label": 0
                },
                {
                    "sent": "So you see their lives tracking in real time, facial landmark detection, acoustic analysis, speech recognition, dialogue modeling, virtual nonverbal behavior generation.",
                    "label": 0
                },
                {
                    "sent": "Everything is happening in real time.",
                    "label": 0
                },
                {
                    "sent": "If you stop by Los Angeles, you can run an interact with Ellie.",
                    "label": 0
                },
                {
                    "sent": "That's her name.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I gave an example.",
                    "label": 0
                },
                {
                    "sent": "There are a lot of examples where this technology can be used.",
                    "label": 0
                },
                {
                    "sent": "In fact, there is a lot of application already seen here, but I think this is the exciting part is how can you model this human communication to help with suicide prevention with distress, with pain to be able to improve public speaking, may be for autistic young adults.",
                    "label": 1
                },
                {
                    "sent": "These are some of the application.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Last slide is my thoughts of where this is going.",
                    "label": 0
                },
                {
                    "sent": "I mean this is my talks.",
                    "label": 0
                },
                {
                    "sent": "I don't have a magic ball, but I think they at least and for interesting future direction.",
                    "label": 0
                },
                {
                    "sent": "One is.",
                    "label": 0
                },
                {
                    "sent": "There's been a lot of interesting work on audiovisual, on tax and vision, but I don't think we yet have trimodal representations.",
                    "label": 0
                },
                {
                    "sent": "It's a question of time and maybe someone has already done it, but it's not there yet.",
                    "label": 0
                },
                {
                    "sent": "And so how do you model these?",
                    "label": 0
                },
                {
                    "sent": "Language, speech and vision.",
                    "label": 0
                },
                {
                    "sent": "Together, I think this is still a really interesting and an open.",
                    "label": 0
                },
                {
                    "sent": "And what is the challenge here is the temporal aspect, which is in fact the second one, and that's why I think the face and gesture community is key in this equation is we understand temporal and right now there is some interesting work with recurrent neural network added.",
                    "label": 0
                },
                {
                    "sent": "Emphasize it today.",
                    "label": 0
                },
                {
                    "sent": "It's really funny to see the machine learning community and vision community suddenly discovering LST M long.",
                    "label": 1
                },
                {
                    "sent": "Short term memory.",
                    "label": 0
                },
                {
                    "sent": "If we had Bjorn Schuler here, will have it would I said, oh God, I told you 15 years ago that this was a good algorithm.",
                    "label": 0
                },
                {
                    "sent": "But yeah, so it is really interesting.",
                    "label": 0
                },
                {
                    "sent": "Nice way of modeling the temporal aspect.",
                    "label": 0
                },
                {
                    "sent": "Whyel STM is so popular compared to some of the model is shown is the model I've shown.",
                    "label": 0
                },
                {
                    "sent": "I'm modeling the short term but you want to not just model the short term but you model also the long term and that's why you need to find a way to do the best of two words.",
                    "label": 0
                },
                {
                    "sent": "The world, and I think that's one of the future.",
                    "label": 0
                },
                {
                    "sent": "Enter, I didn't emphasize it today because part of it is I gave a full talk about it on Monday, but interpersonal dynamic I right now.",
                    "label": 0
                },
                {
                    "sent": "I've talked about one person, but their whole aspect.",
                    "label": 0
                },
                {
                    "sent": "If you have a dynamic and you could see it as another modality, the other person is another reality.",
                    "label": 1
                },
                {
                    "sent": "Another view on the problem and finally social context.",
                    "label": 0
                },
                {
                    "sent": "I had to put it because I strongly believe in it and there's some interesting work to be done there and there.",
                    "label": 0
                },
                {
                    "sent": "How do you include?",
                    "label": 0
                },
                {
                    "sent": "1st about how do you represent this social context?",
                    "label": 0
                },
                {
                    "sent": "Computationally is a big problem and the Secondly is how you integrate that.",
                    "label": 0
                },
                {
                    "sent": "It's even a bigger product, so there's a lot of interesting work.",
                    "label": 0
                },
                {
                    "sent": "I think dialogue Community has approached it a little bit, but that's how we thought.",
                    "label": 0
                },
                {
                    "sent": "So thank you.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Very much for your attention and I'm ready for questions.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}