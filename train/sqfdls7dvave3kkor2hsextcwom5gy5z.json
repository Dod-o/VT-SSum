{
    "id": "sqfdls7dvave3kkor2hsextcwom5gy5z",
    "title": "MC4: A Tempering Algorithm for Large-sample Network Inference",
    "info": {
        "author": [
            "Daniel James Barker, University of Warwick"
        ],
        "published": "Oct. 14, 2010",
        "recorded": "September 2010",
        "category": [
            "Top->Computer Science->Network Analysis"
        ]
    },
    "url": "http://videolectures.net/prib2010_barker_mtal/",
    "segmentation": [
        [
            "Thank you sounds strangely introduced by that only my mom calls me that when she is angry at me, my full name, but I'll try and keep it brief.",
            "'cause we are limited by time, so I'm going to start with a sort of a very, very brief introduction of the background.",
            "I'm sure I don't need to go into too much detail with sort of the crowd we've got here.",
            "I'm sure you'll know mostly what I'll say about that.",
            "Then I'll proceed to sort of introduce what people do.",
            "Currently, the problems associated with that how we sort of propose.",
            "One way of getting around this and then present some results and that we've got from that and then the conclusions."
        ],
        [
            "So we can draw from that.",
            "So as I said, very brief but background.",
            "So as I'm sure you've gathered all the talks in this section have been about inferring networks and protein interactions.",
            "Stuff like this networks are very, very sort of fundamental sort of approach in biology at the moment, mainly due to sort of recent advances in biochemical technology, experimental procedures that allow us access to much bigger datasets.",
            "So rather than examining the structure of a particular protein or something like those, people are now interested in how they interact.",
            "One key approach, which is sort of fallen out of all of this, is what's called probabilistic graphical models.",
            "So an example of a sort of a network or a graph describing a biological system is the picture there, which is unfortunately a bit small.",
            "But this is the signaling network called Artique."
        ],
        [
            "But So what are graphical models will show?",
            "Everybody has a sort of idea what they are.",
            "Generally you see a link between say protein AMB or ANC.",
            "Rather and you think OK somehow a effects B, there's loads of ways you can encode this in various models, But what it actually So what the graph actually specifies.",
            "His statements about the conditional independence.",
            "OK, so associated to each node in a graph would be a random variable.",
            "So how much of the protein there is?",
            "Or something like this in the cell?",
            "And then these graphs specify the conditional independence is.",
            "Certain most situations the graph has to be acyclic, otherwise you would end up with a protein affecting itself later on down the line because you need the a cyclist here to be able to factorize out the probabilities in terms of the parents in the graph.",
            "So some examples of this are hidden Markov models, Bayesian networks, and dynamic Bayesian networks, just to name a few."
        ],
        [
            "Right, so we're working in a Bayesian framework here, so we have a model associated with each of these probabilistic graphical models associated with the graph.",
            "So we can write down a model and then in some cases it's possible to integrate out the model parameters and get a closed form like for the likelihood, which then we can associate with the prior PG.",
            "This means that it's actually possible to get sort of a closed form, so you can.",
            "Give it some data and you can get value out for how likely the posterior probability so the posterior probability is.",
            "The probability of seeing a graph given the data.",
            "OK, so when we write down the model, we say if this is the graph.",
            "This is how likely it is we see the data which is Bayes theorem to flip that around and then obviously we're kind of interested given some data which is the most likely graph or something like this.",
            "So what people allowed people do is simply try and maximize the posterior probability so you say.",
            "We want the most likely graph, but there's problems with this.",
            "If you imagine you have.",
            "Some data and you have a model.",
            "Then the posterior probability could give you back two graphs which are very different but have both highly scoring.",
            "According to this both are highly scoring according to this posterior probability.",
            "Then how do you choose between the two?",
            "There's nothing really to tell you which one is anymore valid than the other.",
            "So to get around this, people use what's called."
        ],
        [
            "Model averaging, which is very simple.",
            "All we do is we look at all of the graphs.",
            "Look at their posterior probability and then look at the probability that certain edges appear in the graphs so.",
            "The graphs.",
            "Obviously there are highly scoring, and if there's an edge that appears in those graphs regularly, then that edge in particular would be highly scoring, so this is much more robust to sort of changes in the data and also maximization procedures tend to give you different answers, so this is sort of robust with respect to that.",
            "However, it requires that we know the constant of proportionality for the posterior probability.",
            "This is a big problem because the state space of graphs is actually huge, grows super exponentially.",
            "With the number of nodes P, so enumerating it becomes rapidly rapidly Invisible Man.",
            "Nice fact that I like, which is that fair even 11 nodes.",
            "There's actually more possible graphs than there are stars in the known universe, so that gives you an idea just how infeasible this sort of stuff is.",
            "To get around this, people use Markov chain Monte Carlo to estimate the posterior probabilities so we no longer assume can get the exact posterior probabilities, but often an estimate will be good enough to make."
        ],
        [
            "Inferences so how do people do this?",
            "Monte Carlo at the moment.",
            "Basically, you construct a Markov chain for which the stationary distribution is the posterior distribution that we're interested in.",
            "So this is the posterior distribution over graphs given the data.",
            "To do this, we have to move around our state space of graphs.",
            "Now this is done by choosing an initial graph.",
            "There's many ways of doing that, but once you have that, you just move around the state space by a combination of these fundamental sort of graph operations.",
            "Here you can either add an edge to the graph or you can flip the direction of a graph of an edge as long as it keeps the graph acyclic and you can delete graphs.",
            "So obviously these two you have to check for a cycliste but for deletion.",
            "You're never going to make a cyclic by deleting an edge.",
            "So once we've picked a new graph, then we either accept that to be the new graph or not.",
            "Based on this acceptance probability here, which is the Metropolis Hastings acceptance probability, which is just the ratio of the posterior probability for the new graph and the old graph.",
            "Normalized by the Hastings Factor, which is just the probability that we choose a particular graph.",
            "OK, so we define the neighborhood of any graph G to be all of the graphs that you can reach from that.",
            "So obviously if you have a graph, there's many different graphs you can reach by performing these operations on each edge, and so that's called the neighborhood, and we have to take into account the size of that.",
            "This acceptance probability is actually for uniform priors, so we've heard some talks about how it's possible to incorporate sort of biological knowledge into these problems.",
            "Again, you can do that in this situation, but here we just consider.",
            "The uniform case.",
            "So this method is called MC3, stands for model composition by Markov chain.",
            "Monte Carlo is first introduced by Madigan in York in 95.",
            "So once we've got this Markov chain up and running, we let it run for some time and then our estimate of the posterior probability is just going to be.",
            "For a particular graph, is going to be basically just count how many times you encounter that graph in the run of this Markov chain.",
            "So that's given by this formula."
        ],
        [
            "Her.",
            "Say another thing we've had a lot of last couple days, how there's not a lot of high throughput experiments coming on, so fax things like this.",
            "Give us access to loads and loads of data, but we have to be careful with this because in certain situations, especially when you're trying to graph inference and things like this, this can actually be a problem.",
            "So we see this plot here is actually the information entropy, or the very very simple 24 nodes, which is very small trivial problem.",
            "But the reason for that is we can actually calculate the exact posterior probability for this, 'cause it's small enough, but we can see as you increase the number of sample data points you have for a particular experiment, we see the information entropy rapidly very quickly drops off.",
            "What does this mean?"
        ],
        [
            "Well, if we look at the distribution over graphs, we can see that the posterior probability actually as we increase N, becomes very very peaked on a few graphs.",
            "So in the low sample size situation it's very dispersed.",
            "So if you get a few bumps, but most of the graphs have some posterior probability associated with them as we move into the higher sample size, then you pick out sort of several graphs, maybe maybe a few, and then as you increase N. Towards Infinity, obviously you pick out all of the graphs which belong to the correct data generating class.",
            "So why is this problem so?",
            "Basically what happens when we run this Markov chain?",
            "We're moving between the graphs, right?",
            "But if you imagine in this situation where the posterior mass is quite dispersed, we can move around relatively freely in our state space of graphs.",
            "In this situation.",
            "However, if these two graphs are like far apart in graphs based somehow, it's hard to visualize, but you imagine it.",
            "Maybe it takes a lot of these basic operations to get between them and they are separated by region of very low scoring graphs.",
            "Then it's going to be very, very tough to get between them.",
            "So if we by chance happen to start on this graph, then the sort of in any typical run of the Markov chain is going to be very unlikely.",
            "That will also sample the second graph, so this is a big problem for actually inferring these probabilities correctly.",
            "Skype."
        ],
        [
            "Save introduced now the the MC Four scheme to explain what the name means in a second.",
            "But basically we're taking the physics.",
            "The physics idea of parallel tempering and applying that to this problem.",
            "So you set up multiple Markov chains to explore this state space, but each Markov chain is actually at a different temperature.",
            "Now, what this means is when you have the acceptance probability, if you're at a higher temperature, you're more likely to accept and move to a lower scoring graph.",
            "OK, so if you're at a low temperature.",
            "You only really likely to accept highly scoring graphs, so we have all these chains shown in this diagram here, and you can imagine that as we increase the temperature then the probability mass becomes more dispersed and it's more like the lower sample size situation that I just showed.",
            "So the Markov chains at the higher temperature could explore the state space much more freely.",
            "What do we mean by temperature in this case?",
            "Closely in a physical system, it's kind of obvious.",
            "We mean the actual physical temperature.",
            "In this case we can just introduce an analogy to that by raising the posterior to the power of beta, where beta is just the inverse temperature 1 / T. So."
        ],
        [
            "What we do there is we have these chains running at different temperatures, so we set up to be a bit more concrete.",
            "If we set up M Markov chains and let them run and those are simulated using the normal Metropolis Hastings scheme, so they're working around that.",
            "But then every now and again, what we do with every iteration with a certain probability called P swap, you propose to pick two of the neighboring chains, and then you swap the swap the graphs with those ones and what this allows is if you imagine you've got a higher temperature, one that can explore very freely the state space.",
            "So it can be moving between the peaks that maybe the lower temperature 1 can't get between.",
            "So by swapping these graphs periodically, then you allow the lower chain the lower temperature chain that we're interested in to explore the state space more effective."
        ],
        [
            "So I'm going to look at some results quickly here so.",
            "The first thing first system we looked at is data that was simulated from a known network.",
            "So the way we did that is all the parent nodes were just Gaussian distributed with certain variants, child nodes that had one parent which I haven't written him afraid, but they were the mean of those was again normally distributed, but the mean, say the mean was just the parent value an for children with two nodes, then they were distributed according to this.",
            "Normal distribution where the mean was just sort of the some of the parents plus some non linear combination of those values.",
            "So this non linear combination actually makes it quite hard to infer 'cause you end up with highly scoring graphs that are separated quite a lot in this."
        ],
        [
            "Office space so 'cause we know the graph, we can plot the Roc curves right?",
            "So this shows the number of false positives against the number of true positives that we get back.",
            "Using this both the MC three scheme, the MC Four and a related method that is due to Xion Gang which was recently published so we can see that actually this is in the case where we've got 5000.",
            "Sample simulated from this network, which is actually quite a lot, but it's not really unreasonable when you consider the advances in sort of biotechnology and things like this, we can see very nicely that by the time we've got to five false positives, actually the MC four parallel tempering scheme has achieved actually almost twice as many true positives as the other as the constraint based scheme and also the Metropolis Hastings MC three scheme."
        ],
        [
            "So this is very nice.",
            "So if we look at a few other what curves now this is the same one that was on the last slide.",
            "So this is for the N = 5000.",
            "This is zoom out of that, so it's the same thing, but zoomed completely out and we can see that.",
            "Actually for the MC3 to achieve all of the true positives we have to have a ridiculous number of false positives which is picking out which we don't.",
            "We don't see this problem with the MC 4 so this is very nice, sort of validation of this.",
            "If we look in a lower sample size regime so N = 500.",
            "We actually don't see much difference between the schemes of door, so this is showing that the low sample size.",
            "We can still explore the state space effectively with the low temperature Markov chain, so it's not a problem generally for low sample size, but for higher sample size it becomes very, very in."
        ],
        [
            "So these are these sort of methods ready.",
            "Set times up.",
            "I've only got a couple of slides.",
            "Can I finish very quickly?",
            "OK cool, so we also looked at some real programmatic data proteomic data, sorry, but in this case we're trying to have a dynamic Bayesian network now with dynamic Bayesian networks there exists a certain factorization which you can use to get the exact edge probabilities, so this gives us a fantastic sort of comparison.",
            "We can actually compare to the exact edge probabilities, so we don't know the underlying graph in this case, 'cause this is real experimental data, so we can't plot Roc curves, But what we can look at is.",
            "A sort of a comparison between our estimated probabilities and the exact ones we count."
        ],
        [
            "Wait, what do we see?",
            "If we look at the correlation between the two, we see that the MC Four scheme does a much better job than the MC three scheme here.",
            "As time goes on.",
            "So this is time on the bottom against the correlation between our estimated edges and the exact ones on this side.",
            "We just similar sort of thing.",
            "It's just the sum differences between the two.",
            "Zero obviously would be a perfect inference for this graph, and we can see it much lower for the MC."
        ],
        [
            "Low.",
            "If we look what the edges edge probabilities look like at the end of the run, so this is after half a million iterations, so quite a lot of computation time.",
            "Here we can see that MC Four has actually remedied the worst sort of failings of the MC three, so this is the exact sort of the truth.",
            "If you like on the bottom plotted against the estimations on the vertical axis here.",
            "So these in the upper left at the bottom right corner represent the sort of gravest's failings of the empty 3.",
            "And we can see MC Four has remedied that I'm being way."
        ],
        [
            "That so to conclude, MC 4 is good, you need to if you want to make robust biological data, you have to take care of."
        ],
        [
            "Monte Carlo I liked it knowledge.",
            "My coauthors, EPS or see for funding and some colleagues thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you sounds strangely introduced by that only my mom calls me that when she is angry at me, my full name, but I'll try and keep it brief.",
                    "label": 0
                },
                {
                    "sent": "'cause we are limited by time, so I'm going to start with a sort of a very, very brief introduction of the background.",
                    "label": 0
                },
                {
                    "sent": "I'm sure I don't need to go into too much detail with sort of the crowd we've got here.",
                    "label": 0
                },
                {
                    "sent": "I'm sure you'll know mostly what I'll say about that.",
                    "label": 0
                },
                {
                    "sent": "Then I'll proceed to sort of introduce what people do.",
                    "label": 0
                },
                {
                    "sent": "Currently, the problems associated with that how we sort of propose.",
                    "label": 0
                },
                {
                    "sent": "One way of getting around this and then present some results and that we've got from that and then the conclusions.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we can draw from that.",
                    "label": 0
                },
                {
                    "sent": "So as I said, very brief but background.",
                    "label": 0
                },
                {
                    "sent": "So as I'm sure you've gathered all the talks in this section have been about inferring networks and protein interactions.",
                    "label": 0
                },
                {
                    "sent": "Stuff like this networks are very, very sort of fundamental sort of approach in biology at the moment, mainly due to sort of recent advances in biochemical technology, experimental procedures that allow us access to much bigger datasets.",
                    "label": 0
                },
                {
                    "sent": "So rather than examining the structure of a particular protein or something like those, people are now interested in how they interact.",
                    "label": 0
                },
                {
                    "sent": "One key approach, which is sort of fallen out of all of this, is what's called probabilistic graphical models.",
                    "label": 1
                },
                {
                    "sent": "So an example of a sort of a network or a graph describing a biological system is the picture there, which is unfortunately a bit small.",
                    "label": 0
                },
                {
                    "sent": "But this is the signaling network called Artique.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But So what are graphical models will show?",
                    "label": 1
                },
                {
                    "sent": "Everybody has a sort of idea what they are.",
                    "label": 0
                },
                {
                    "sent": "Generally you see a link between say protein AMB or ANC.",
                    "label": 0
                },
                {
                    "sent": "Rather and you think OK somehow a effects B, there's loads of ways you can encode this in various models, But what it actually So what the graph actually specifies.",
                    "label": 1
                },
                {
                    "sent": "His statements about the conditional independence.",
                    "label": 1
                },
                {
                    "sent": "OK, so associated to each node in a graph would be a random variable.",
                    "label": 0
                },
                {
                    "sent": "So how much of the protein there is?",
                    "label": 0
                },
                {
                    "sent": "Or something like this in the cell?",
                    "label": 1
                },
                {
                    "sent": "And then these graphs specify the conditional independence is.",
                    "label": 0
                },
                {
                    "sent": "Certain most situations the graph has to be acyclic, otherwise you would end up with a protein affecting itself later on down the line because you need the a cyclist here to be able to factorize out the probabilities in terms of the parents in the graph.",
                    "label": 0
                },
                {
                    "sent": "So some examples of this are hidden Markov models, Bayesian networks, and dynamic Bayesian networks, just to name a few.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right, so we're working in a Bayesian framework here, so we have a model associated with each of these probabilistic graphical models associated with the graph.",
                    "label": 0
                },
                {
                    "sent": "So we can write down a model and then in some cases it's possible to integrate out the model parameters and get a closed form like for the likelihood, which then we can associate with the prior PG.",
                    "label": 0
                },
                {
                    "sent": "This means that it's actually possible to get sort of a closed form, so you can.",
                    "label": 1
                },
                {
                    "sent": "Give it some data and you can get value out for how likely the posterior probability so the posterior probability is.",
                    "label": 1
                },
                {
                    "sent": "The probability of seeing a graph given the data.",
                    "label": 0
                },
                {
                    "sent": "OK, so when we write down the model, we say if this is the graph.",
                    "label": 0
                },
                {
                    "sent": "This is how likely it is we see the data which is Bayes theorem to flip that around and then obviously we're kind of interested given some data which is the most likely graph or something like this.",
                    "label": 0
                },
                {
                    "sent": "So what people allowed people do is simply try and maximize the posterior probability so you say.",
                    "label": 0
                },
                {
                    "sent": "We want the most likely graph, but there's problems with this.",
                    "label": 0
                },
                {
                    "sent": "If you imagine you have.",
                    "label": 0
                },
                {
                    "sent": "Some data and you have a model.",
                    "label": 1
                },
                {
                    "sent": "Then the posterior probability could give you back two graphs which are very different but have both highly scoring.",
                    "label": 0
                },
                {
                    "sent": "According to this both are highly scoring according to this posterior probability.",
                    "label": 1
                },
                {
                    "sent": "Then how do you choose between the two?",
                    "label": 0
                },
                {
                    "sent": "There's nothing really to tell you which one is anymore valid than the other.",
                    "label": 0
                },
                {
                    "sent": "So to get around this, people use what's called.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Model averaging, which is very simple.",
                    "label": 1
                },
                {
                    "sent": "All we do is we look at all of the graphs.",
                    "label": 0
                },
                {
                    "sent": "Look at their posterior probability and then look at the probability that certain edges appear in the graphs so.",
                    "label": 0
                },
                {
                    "sent": "The graphs.",
                    "label": 0
                },
                {
                    "sent": "Obviously there are highly scoring, and if there's an edge that appears in those graphs regularly, then that edge in particular would be highly scoring, so this is much more robust to sort of changes in the data and also maximization procedures tend to give you different answers, so this is sort of robust with respect to that.",
                    "label": 0
                },
                {
                    "sent": "However, it requires that we know the constant of proportionality for the posterior probability.",
                    "label": 0
                },
                {
                    "sent": "This is a big problem because the state space of graphs is actually huge, grows super exponentially.",
                    "label": 0
                },
                {
                    "sent": "With the number of nodes P, so enumerating it becomes rapidly rapidly Invisible Man.",
                    "label": 0
                },
                {
                    "sent": "Nice fact that I like, which is that fair even 11 nodes.",
                    "label": 0
                },
                {
                    "sent": "There's actually more possible graphs than there are stars in the known universe, so that gives you an idea just how infeasible this sort of stuff is.",
                    "label": 0
                },
                {
                    "sent": "To get around this, people use Markov chain Monte Carlo to estimate the posterior probabilities so we no longer assume can get the exact posterior probabilities, but often an estimate will be good enough to make.",
                    "label": 1
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Inferences so how do people do this?",
                    "label": 0
                },
                {
                    "sent": "Monte Carlo at the moment.",
                    "label": 1
                },
                {
                    "sent": "Basically, you construct a Markov chain for which the stationary distribution is the posterior distribution that we're interested in.",
                    "label": 0
                },
                {
                    "sent": "So this is the posterior distribution over graphs given the data.",
                    "label": 0
                },
                {
                    "sent": "To do this, we have to move around our state space of graphs.",
                    "label": 0
                },
                {
                    "sent": "Now this is done by choosing an initial graph.",
                    "label": 0
                },
                {
                    "sent": "There's many ways of doing that, but once you have that, you just move around the state space by a combination of these fundamental sort of graph operations.",
                    "label": 0
                },
                {
                    "sent": "Here you can either add an edge to the graph or you can flip the direction of a graph of an edge as long as it keeps the graph acyclic and you can delete graphs.",
                    "label": 0
                },
                {
                    "sent": "So obviously these two you have to check for a cycliste but for deletion.",
                    "label": 0
                },
                {
                    "sent": "You're never going to make a cyclic by deleting an edge.",
                    "label": 0
                },
                {
                    "sent": "So once we've picked a new graph, then we either accept that to be the new graph or not.",
                    "label": 0
                },
                {
                    "sent": "Based on this acceptance probability here, which is the Metropolis Hastings acceptance probability, which is just the ratio of the posterior probability for the new graph and the old graph.",
                    "label": 0
                },
                {
                    "sent": "Normalized by the Hastings Factor, which is just the probability that we choose a particular graph.",
                    "label": 0
                },
                {
                    "sent": "OK, so we define the neighborhood of any graph G to be all of the graphs that you can reach from that.",
                    "label": 0
                },
                {
                    "sent": "So obviously if you have a graph, there's many different graphs you can reach by performing these operations on each edge, and so that's called the neighborhood, and we have to take into account the size of that.",
                    "label": 0
                },
                {
                    "sent": "This acceptance probability is actually for uniform priors, so we've heard some talks about how it's possible to incorporate sort of biological knowledge into these problems.",
                    "label": 1
                },
                {
                    "sent": "Again, you can do that in this situation, but here we just consider.",
                    "label": 0
                },
                {
                    "sent": "The uniform case.",
                    "label": 0
                },
                {
                    "sent": "So this method is called MC3, stands for model composition by Markov chain.",
                    "label": 0
                },
                {
                    "sent": "Monte Carlo is first introduced by Madigan in York in 95.",
                    "label": 0
                },
                {
                    "sent": "So once we've got this Markov chain up and running, we let it run for some time and then our estimate of the posterior probability is just going to be.",
                    "label": 0
                },
                {
                    "sent": "For a particular graph, is going to be basically just count how many times you encounter that graph in the run of this Markov chain.",
                    "label": 0
                },
                {
                    "sent": "So that's given by this formula.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Her.",
                    "label": 0
                },
                {
                    "sent": "Say another thing we've had a lot of last couple days, how there's not a lot of high throughput experiments coming on, so fax things like this.",
                    "label": 1
                },
                {
                    "sent": "Give us access to loads and loads of data, but we have to be careful with this because in certain situations, especially when you're trying to graph inference and things like this, this can actually be a problem.",
                    "label": 1
                },
                {
                    "sent": "So we see this plot here is actually the information entropy, or the very very simple 24 nodes, which is very small trivial problem.",
                    "label": 0
                },
                {
                    "sent": "But the reason for that is we can actually calculate the exact posterior probability for this, 'cause it's small enough, but we can see as you increase the number of sample data points you have for a particular experiment, we see the information entropy rapidly very quickly drops off.",
                    "label": 0
                },
                {
                    "sent": "What does this mean?",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well, if we look at the distribution over graphs, we can see that the posterior probability actually as we increase N, becomes very very peaked on a few graphs.",
                    "label": 0
                },
                {
                    "sent": "So in the low sample size situation it's very dispersed.",
                    "label": 0
                },
                {
                    "sent": "So if you get a few bumps, but most of the graphs have some posterior probability associated with them as we move into the higher sample size, then you pick out sort of several graphs, maybe maybe a few, and then as you increase N. Towards Infinity, obviously you pick out all of the graphs which belong to the correct data generating class.",
                    "label": 1
                },
                {
                    "sent": "So why is this problem so?",
                    "label": 1
                },
                {
                    "sent": "Basically what happens when we run this Markov chain?",
                    "label": 0
                },
                {
                    "sent": "We're moving between the graphs, right?",
                    "label": 0
                },
                {
                    "sent": "But if you imagine in this situation where the posterior mass is quite dispersed, we can move around relatively freely in our state space of graphs.",
                    "label": 0
                },
                {
                    "sent": "In this situation.",
                    "label": 1
                },
                {
                    "sent": "However, if these two graphs are like far apart in graphs based somehow, it's hard to visualize, but you imagine it.",
                    "label": 0
                },
                {
                    "sent": "Maybe it takes a lot of these basic operations to get between them and they are separated by region of very low scoring graphs.",
                    "label": 1
                },
                {
                    "sent": "Then it's going to be very, very tough to get between them.",
                    "label": 0
                },
                {
                    "sent": "So if we by chance happen to start on this graph, then the sort of in any typical run of the Markov chain is going to be very unlikely.",
                    "label": 0
                },
                {
                    "sent": "That will also sample the second graph, so this is a big problem for actually inferring these probabilities correctly.",
                    "label": 0
                },
                {
                    "sent": "Skype.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Save introduced now the the MC Four scheme to explain what the name means in a second.",
                    "label": 0
                },
                {
                    "sent": "But basically we're taking the physics.",
                    "label": 0
                },
                {
                    "sent": "The physics idea of parallel tempering and applying that to this problem.",
                    "label": 1
                },
                {
                    "sent": "So you set up multiple Markov chains to explore this state space, but each Markov chain is actually at a different temperature.",
                    "label": 0
                },
                {
                    "sent": "Now, what this means is when you have the acceptance probability, if you're at a higher temperature, you're more likely to accept and move to a lower scoring graph.",
                    "label": 0
                },
                {
                    "sent": "OK, so if you're at a low temperature.",
                    "label": 0
                },
                {
                    "sent": "You only really likely to accept highly scoring graphs, so we have all these chains shown in this diagram here, and you can imagine that as we increase the temperature then the probability mass becomes more dispersed and it's more like the lower sample size situation that I just showed.",
                    "label": 0
                },
                {
                    "sent": "So the Markov chains at the higher temperature could explore the state space much more freely.",
                    "label": 0
                },
                {
                    "sent": "What do we mean by temperature in this case?",
                    "label": 0
                },
                {
                    "sent": "Closely in a physical system, it's kind of obvious.",
                    "label": 0
                },
                {
                    "sent": "We mean the actual physical temperature.",
                    "label": 1
                },
                {
                    "sent": "In this case we can just introduce an analogy to that by raising the posterior to the power of beta, where beta is just the inverse temperature 1 / T. So.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What we do there is we have these chains running at different temperatures, so we set up to be a bit more concrete.",
                    "label": 0
                },
                {
                    "sent": "If we set up M Markov chains and let them run and those are simulated using the normal Metropolis Hastings scheme, so they're working around that.",
                    "label": 1
                },
                {
                    "sent": "But then every now and again, what we do with every iteration with a certain probability called P swap, you propose to pick two of the neighboring chains, and then you swap the swap the graphs with those ones and what this allows is if you imagine you've got a higher temperature, one that can explore very freely the state space.",
                    "label": 1
                },
                {
                    "sent": "So it can be moving between the peaks that maybe the lower temperature 1 can't get between.",
                    "label": 0
                },
                {
                    "sent": "So by swapping these graphs periodically, then you allow the lower chain the lower temperature chain that we're interested in to explore the state space more effective.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I'm going to look at some results quickly here so.",
                    "label": 0
                },
                {
                    "sent": "The first thing first system we looked at is data that was simulated from a known network.",
                    "label": 0
                },
                {
                    "sent": "So the way we did that is all the parent nodes were just Gaussian distributed with certain variants, child nodes that had one parent which I haven't written him afraid, but they were the mean of those was again normally distributed, but the mean, say the mean was just the parent value an for children with two nodes, then they were distributed according to this.",
                    "label": 0
                },
                {
                    "sent": "Normal distribution where the mean was just sort of the some of the parents plus some non linear combination of those values.",
                    "label": 0
                },
                {
                    "sent": "So this non linear combination actually makes it quite hard to infer 'cause you end up with highly scoring graphs that are separated quite a lot in this.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Office space so 'cause we know the graph, we can plot the Roc curves right?",
                    "label": 0
                },
                {
                    "sent": "So this shows the number of false positives against the number of true positives that we get back.",
                    "label": 1
                },
                {
                    "sent": "Using this both the MC three scheme, the MC Four and a related method that is due to Xion Gang which was recently published so we can see that actually this is in the case where we've got 5000.",
                    "label": 0
                },
                {
                    "sent": "Sample simulated from this network, which is actually quite a lot, but it's not really unreasonable when you consider the advances in sort of biotechnology and things like this, we can see very nicely that by the time we've got to five false positives, actually the MC four parallel tempering scheme has achieved actually almost twice as many true positives as the other as the constraint based scheme and also the Metropolis Hastings MC three scheme.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is very nice.",
                    "label": 0
                },
                {
                    "sent": "So if we look at a few other what curves now this is the same one that was on the last slide.",
                    "label": 0
                },
                {
                    "sent": "So this is for the N = 5000.",
                    "label": 0
                },
                {
                    "sent": "This is zoom out of that, so it's the same thing, but zoomed completely out and we can see that.",
                    "label": 0
                },
                {
                    "sent": "Actually for the MC3 to achieve all of the true positives we have to have a ridiculous number of false positives which is picking out which we don't.",
                    "label": 1
                },
                {
                    "sent": "We don't see this problem with the MC 4 so this is very nice, sort of validation of this.",
                    "label": 0
                },
                {
                    "sent": "If we look in a lower sample size regime so N = 500.",
                    "label": 0
                },
                {
                    "sent": "We actually don't see much difference between the schemes of door, so this is showing that the low sample size.",
                    "label": 0
                },
                {
                    "sent": "We can still explore the state space effectively with the low temperature Markov chain, so it's not a problem generally for low sample size, but for higher sample size it becomes very, very in.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So these are these sort of methods ready.",
                    "label": 0
                },
                {
                    "sent": "Set times up.",
                    "label": 0
                },
                {
                    "sent": "I've only got a couple of slides.",
                    "label": 0
                },
                {
                    "sent": "Can I finish very quickly?",
                    "label": 0
                },
                {
                    "sent": "OK cool, so we also looked at some real programmatic data proteomic data, sorry, but in this case we're trying to have a dynamic Bayesian network now with dynamic Bayesian networks there exists a certain factorization which you can use to get the exact edge probabilities, so this gives us a fantastic sort of comparison.",
                    "label": 1
                },
                {
                    "sent": "We can actually compare to the exact edge probabilities, so we don't know the underlying graph in this case, 'cause this is real experimental data, so we can't plot Roc curves, But what we can look at is.",
                    "label": 1
                },
                {
                    "sent": "A sort of a comparison between our estimated probabilities and the exact ones we count.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Wait, what do we see?",
                    "label": 0
                },
                {
                    "sent": "If we look at the correlation between the two, we see that the MC Four scheme does a much better job than the MC three scheme here.",
                    "label": 0
                },
                {
                    "sent": "As time goes on.",
                    "label": 0
                },
                {
                    "sent": "So this is time on the bottom against the correlation between our estimated edges and the exact ones on this side.",
                    "label": 0
                },
                {
                    "sent": "We just similar sort of thing.",
                    "label": 0
                },
                {
                    "sent": "It's just the sum differences between the two.",
                    "label": 0
                },
                {
                    "sent": "Zero obviously would be a perfect inference for this graph, and we can see it much lower for the MC.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Low.",
                    "label": 0
                },
                {
                    "sent": "If we look what the edges edge probabilities look like at the end of the run, so this is after half a million iterations, so quite a lot of computation time.",
                    "label": 1
                },
                {
                    "sent": "Here we can see that MC Four has actually remedied the worst sort of failings of the MC three, so this is the exact sort of the truth.",
                    "label": 0
                },
                {
                    "sent": "If you like on the bottom plotted against the estimations on the vertical axis here.",
                    "label": 0
                },
                {
                    "sent": "So these in the upper left at the bottom right corner represent the sort of gravest's failings of the empty 3.",
                    "label": 0
                },
                {
                    "sent": "And we can see MC Four has remedied that I'm being way.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That so to conclude, MC 4 is good, you need to if you want to make robust biological data, you have to take care of.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Monte Carlo I liked it knowledge.",
                    "label": 0
                },
                {
                    "sent": "My coauthors, EPS or see for funding and some colleagues thank you.",
                    "label": 0
                }
            ]
        }
    }
}