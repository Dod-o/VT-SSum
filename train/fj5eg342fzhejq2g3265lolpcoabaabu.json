{
    "id": "fj5eg342fzhejq2g3265lolpcoabaabu",
    "title": "Effective and Efficient Entity Search in RDF data",
    "info": {
        "author": [
            "Peter Mika, Yahoo! Research"
        ],
        "published": "Nov. 25, 2011",
        "recorded": "October 2011",
        "category": [
            "Top->Computer Science->Semantic Web->RDF - Resource Description Framework"
        ]
    },
    "url": "http://videolectures.net/iswc2011_mika_entity/",
    "segmentation": [
        [
            "Thank you, thank you, Paul for enthusiastic introduction.",
            "Welcome everyone.",
            "My name is Peter Mika.",
            "This is the paper titled Effective and Efficient Entity Search in RDF data Ann.",
            "I guess it's alternative in the same sense that the previous to talks were alternative in that we're talking about information retrieval inspired approaches to RDF querying.",
            "This is joint work with my colleague Roy Blanco, also from Yahoo Research in Barcelona and with Sebastian Vigna from Milano."
        ],
        [
            "So why are we talking about semantic search?",
            "Just to recap, some of the motivation or some of these pieces were mentioned earlier.",
            "We are mainly intending to support end users who may not be able to express their their needs in sparkle because they don't even know what sparkle is on the 1st place.",
            "We are targeting situations where there are large datasets.",
            "You probably know that in the past two or three years to semantic Web has sort of boomed in data both as a result of.",
            "The linked data, efforts and sort of an interest in in web markup in marking up pages with with our DFI another format and this has given us sort of a large scale and larger scale data corpus to work with very small.",
            "The earlier approaches might not scale.",
            "Also we are looking at very heterogeneous datasets, so in particular datasets collected from the web.",
            "The problem in this case is that the users.",
            "May not be aware of the scheme of the data or simply the data set is so heterogeneous that there's no way that the user can keep in mind all the classes and properties that are in the data.",
            "So just to give you an example.",
            "In the billion triples, 2009 days said that we work with.",
            "There are two point 6 million classes and 33,000 properties.",
            "So obviously we cannot expect the user to exactly name the class and the properties that that he or she is interested in.",
            "So simply in this case it's not possible for the user to formulate their structured query that would precisely match his or her information need.",
            "We are also talking about the entity search and these are queries.",
            "These are the most basic types of queries.",
            "A schema for mentioned where the user is looking for exactly 1 entity.",
            "So the user has does have something in mind right?",
            "These are not.",
            "This is not kind of the least searches, but the user does have a particular entity in mind and in the query contains the description.",
            "Of this entity, either contains are the names the entity or or provide some description of it.",
            "I put some examples there.",
            "These queries might seem basic in that in that these are.",
            "This is actually what the user wants, and it seems that you just have to match it to the description of the resources that are in the data set.",
            "But still this becomes a very hard problem simply because there might be a linguistic mismatch.",
            "So maybe the words are not exactly the same in the query as in the resources to be rank.",
            "There might be relevant issues right?",
            "So maybe?",
            "You don't exactly have one of these entities in your data set, but you have something related, in which case the problem is to rank the resources by degree of relatedness."
        ],
        [
            "So that's that's the problem we are dealing with.",
            "I just wanted to mention very briefly that this has practical applications in web search in particular.",
            "So these days when you when you go to a search engine and you search for such an entity query like in this case Born Germany, you already get quite a bit of structured data, right?",
            "So in this case the search engine tries to identify the particular entity, in this case of city, the discovery starting and give you some information about.",
            "About that city.",
            "Also, we show related entities in this case.",
            "This is a screenshot from Yahoo search, and obviously that again requires to find the focused entity of the query.",
            "And Lastly, we use more and more structured data that we extract from HTML.",
            "To you to increased markup."
        ],
        [
            "Um?",
            "Again, to summarize, you know how this?",
            "How this compares to I guess than an alternative approaches to do RDF carrying and that is the more database style indexing of RDF data, which is typically implemented in triple stores.",
            "Triple stores are built to execute structural queries and typically they do not provide keyword query facilities or if they do, then it's some kind of side index that is operated.",
            "On the side.",
            "And even in that case the the site index is used only for for matching.",
            "For restricting search results.",
            "But typically triple stores do not provide ranking of results.",
            "And since there's no ranking evaluation or the competition between triple stores, if you will is mostly on their on their efficiency, how fast they are?",
            "Comparing that to the more I are inspired approaches, these are search engines.",
            "We call them search engines.",
            "They execute keyword queries and the focus is on ranking so much of the competition in this field is on the effectiveness, right?",
            "So how good you are in ranking things in terms of the relevancy to the user query?",
            "Of course there are there approaches in the related work that tries to combine these two very different ways of thinking.",
            "By combining keyword matching with some limited joint processing, for example."
        ],
        [
            "I will not go into into great detail in related work.",
            "Please, please see the paper.",
            "This is a relatively new field that I wanted to mention, so I guess I SW. 2007 was probably first conference or we've seen a paper that that looked at our approaches to to semantic web search.",
            "There have been a number of papers since then, in fact, we've been organizing a semantic search workshop since 2008, so a lot of the related work appeared there.",
            "One particular paper by by Perez Agara is very close to our ranking method in the sense that we're both space or experiments on on the BM25F ranking model.",
            "I'll explain how we how we extend that.",
            "And of course there are many, many others.",
            "The literature you might want to look at also evaluation campaigns.",
            "The one we use in this paper is evaluation campaign that has been organized in conjunction with the previously mentioned semantic search.",
            "Workshop is called the same search challenge.",
            "Their systems participate and compete on RDF ranking task.",
            "There are similar competitions with slightly different focus question answering or link data.",
            "That was an event organized this year and as the name says, its focus is it focuses on question answering so that our full questions to be answered.",
            "And the track entity track?",
            "That's that's more on the information retrieval side in the sense that you are still ranking documents, but each document is somehow relevant to a particular entity.",
            "Um and then of course.",
            "As previously mentioned, there are related applications of IR to other data models, databases, XML and some.",
            "Some of these fields, for example keyword searching databases, did not produce kind of evaluation frameworks that you're lucky to have in some of the Trinity."
        ],
        [
            "OK, so a very brief overview of how how the big picture looks like.",
            "Essentially we are building a full full search engine, very take an RDF collection from the web, which is typically quads, so so triples with some provenance information in the document to which they belonged on the web.",
            "And then simply the index.",
            "These collections using MapReduce and I'll explain a bit more how that works.",
            "So that's going to be the first part of the talk.",
            "And then once you build this indices as a result of the process, you get a set of indices which you have to merge and then distribute that you're you're serving environment, and that's where ranking take place and I'll focus on the ranking in the second part."
        ],
        [
            "Very briefly, RDF indexing using MapReduce MapReduce if if you know its origin comes out.",
            "The current implementation of it, at least or distributed systems comes out from Google, so there's no wonder that it's very good for building search indices, and in fact, the basic operation of MapReduce is exactly what you need to build an inverted index, so you parse the document into into key value pairs where the key is a term and values document.",
            "And the framework what it does is simply to collect the values for the same key so it collects all the documents that contain a particular term, and that's exactly what you need to build an inverted index.",
            "So nothing new there.",
            "The application of this to RDF indexing is slightly different in that RDF structure.",
            "Then you want to preserve some of this structure.",
            "This is described in a previous paper, but basic idea is that there are more less variations of this in a little bit more less.",
            "The basic idea is you take as a document all the triples about a given subject.",
            "You are I and you index that in some way you can expand that.",
            "So you might take RDF.",
            "Molecules are also related.",
            "Related resources when you're creating your documents.",
            "And then you you create some comfort index that is capable of of capturing from which property a certain value belong to, right?",
            "So which in which property of certain keyword epigram?",
            "And I will show you all the basic variations that that you're working with in this work.",
            "Typically, in addition to this, people also index terms in the subject you are I because people choose your eyes on the web to be meaningful.",
            "So often that so this is very valuable signal for Frank."
        ],
        [
            "There are two basic index structures that we previously proposed, and there's a third one in this paper.",
            "The first one that we proposed two years ago, I guess, was this.",
            "This horizontal index structure actually very natural way to organize your data when you simply have one field in your index for essentially every position.",
            "So one field would contain the keywords from the value from the literals.",
            "One field would contain the words from the properties and if you want another field which contain words from from the context in first position of the quad.",
            "Now this type of index allows you to do searches where you're looking for a particular variant of particular field, and in order to do that you need what they called the alignment operator, which is supported by some search engines.",
            "Do not.",
            "All these M G4, JM, G4, J supports this and the alignment operator basically does what it sounds like.",
            "If you say I'm looking for the word Peter, but only in asset value of 4th name.",
            "It looks for matches of Peter and it looks for measure full name and only counted as a match if it appears on the same position, right?",
            "So here the alignment is that.",
            "The particular on the particular position in the token field.",
            "The property field provides for which property was it the value.",
            "I'm."
        ],
        [
            "The other natural way to organize your data is is sort of sort of iteration of this.",
            "They actually have one field, their property, so you take you take all your properties or as much as you can, and you create a separate index for each of them, right?",
            "And in this case it's very natural to just execute the previous dimensions vary where you're looking for a particular term in a particular property, because you just go to the particular index that represents that property.",
            "This sounds very good in practice.",
            "One of the problems that you're running into this is that if you have many, many properties.",
            "And you're using the approach that we used value generating disease using MapReduce.",
            "You might end up with with very many small indices, which is then a problem for for performance.",
            "And also you know practical problems like you have to keep these indices in memory on the reducers while you're building your index and so on.",
            "However, the the way to deal with that is that we actually limit the number of properties in the experiments.",
            "We just take the top end most common properties in a particular evaluation.",
            "It's 300, so top 300 properties in the data set."
        ],
        [
            "In this paper, we propose efficiency improvements to this for this basic scheme.",
            "And one is what we call the reduced vertical index.",
            "The idea here, or the observation is that you don't really need if just one for ranking for a keyword queries you don't really need to distinguish fields that you will eventually attribute the same weight too.",
            "So if you if you if you use their ranking scheme like we do, they assign weights to particular properties.",
            "You will probably assign similar weight levels, at least some properties and you can.",
            "Group basically the text from these properties into into into the same field so that in our case we use 3 weight levels.",
            "So in this case you have three, so 300 fields.",
            "You would have three fields, which which makes things more efficient.",
            "Other very basic practical steps you can take is to precompute these alignments that I mentioned previously.",
            "So basically what you what you build an index that tells you which terms appear in any of the resources, which terms up here in a particular field, right?",
            "Again, this is helpful because.",
            "Yeah, the fields might have very particular vocabulary, so for example, you know the H field will hopefully always contain numbers, so if there's a word that is not a number, that will probably never appear in the age field and you can know that in advance and you can put in your query.",
            "Accordingly."
        ],
        [
            "Right?",
            "We previously reported numbers on indexing efficiency, so I just I just put them here for for completeness.",
            "The data set the experiment within.",
            "Actually all of these experiments is the billion triples 2098 set.",
            "I already mentioned.",
            "It's a fairly heterogeneous data set, it's about 250 gigabytes of uncompressed data.",
            "For the vertical next thing I mentioned, we selected the 300 most frequent data type properties.",
            "We actually only next decide properties, so we end up indexing about 270 million triples from the one 1.1 billion triples in total.",
            "We do the indexing using using Hadoop Hadoop implementation of MapReduce.",
            "Very essentially I didn't mention but essentially this is a fully parallelizable problem, so the scale is really limited only by the number of machines that you have.",
            "The number of mappers, if you know how do you Members is basically determined by the size of your input data.",
            "The number of users is something that you choose.",
            "In this case, it's a tradeoff between how fast indexing is going to go and how small the indexes will be at the end, right?",
            "So if you said the number for users very high, we get very very small indices, which you'll have to spend some time to merge.",
            "But essentially, you know the the numbers are are in the paper.",
            "Essentially, you know this is paralyzed a problem, so it's it just depends on how much how much you spend on hardware."
        ],
        [
            "More interesting probably is, is the runtime efficiency of these index structures and in compression.",
            "So here we measured the average execution time using a large stuff queries.",
            "So we took 150,000 queries.",
            "We of course did not manually check that they aren't queries, but we simply took various that little Wikipedia clicks, assuming that that on average they will be antiquaries.",
            "The length of this is about 2.2 tokens on average.",
            "And as a baseline, you know, besides all these structured indices, we took a plain text index.",
            "Very don't separate the description of resource into separate fields, but just take all the text that is in the description of the resource.",
            "You can see that that you know information that people engines are fairly fast, so here we are always talking about subsequent times here.",
            "Plain text indexing.",
            "This is MG4J.",
            "I did not mention by the size of this index is about 5 gigabytes, so this is a billion triples.",
            "Data after indexing is $250, you get 5 gigabytes index which which is something you can keep in memory these days.",
            "So things are super super fast because of that as well.",
            "The base you know the baseline is under 100 milliseconds.",
            "Horizontal indexes is more expensive because of the alignment operator, and we also tested the differences between and and or execution modes and is always faster and it's obviously you can terminate early right?",
            "If you don't.",
            "If you don't find one of the keywords.",
            "Harvard or is typically used in the cases on smaller datasets, and even billion triples is a small data set in this case, and and is typically used by by web search engines.",
            "In larger datasets, the vertical index does significantly improve the execution time for these.",
            "For the OR operation mode that we are interested in, and it gets it down to about 150 milliseconds, which we consider good."
        ],
        [
            "Now moving onto ranking and the second part we use a modification of the young 25 F. We have 25 and the Empire F are valuable metals in the literature.",
            "We did not invent them.",
            "Essentially the basic idea of of these all these ranking models is that supposed to you know standard TF IDF you take into account the fact that additional terms in the documents.",
            "Additional appearances of the term in the document may may contribute decreasing amounts of relevance.",
            "So what you do is you take the term frequency, but you normalize it by this by this document length normalization factor, which takes into account the average length of the field compared to how many times the term appeared.",
            "There's also debating here, right?",
            "So so this is scheme that allows you to put different weights in different fields.",
            "And in the horizontal case, units, token, and property and all that in the vertical case.",
            "That's that's the different properties that you're indexing."
        ],
        [
            "The ranking score is then a combination of of this.",
            "This modified TF measure and an IDF and inverse document frequency measure which is dirty tendered IDF measure.",
            "Um?",
            "The the key parameter here is is a tunable parameter which basically puts the weight on the on the modified version of the tfor.",
            "The unmodified version of the TF.",
            "The final score is.",
            "Then is, then simply the scores of the individual terms.",
            "So if you take the query terms you do the do the matching and scoring of them individually and then at the end you sum up those scores to get a complete score for that.",
            "Very in that particular resource or document that you're."
        ],
        [
            "So this is the basic function they've evaluated it and.",
            "In practice, is that we took this semantic search Challenge 2010 task.",
            "There is a public evaluation, so the data are the queries and assessments.",
            "Everything is available online, so the results are reproducible.",
            "This evaluation uses this billion triples 2009 days set, and the queries are manually selected entity queries.",
            "They've been selected from a sample, and these samples are taken from real web search query logs, so they are real real queries entered by users.",
            "This is public evaluation that I mentioned the.",
            "The Co organized two years ago at this at this workshop.",
            "So I think 6 systems participated that year in this competition.",
            "And we did not participate.",
            "We assess the results using Amazon's Mechanical Turk, or rather, this competition assess the results using Amazon Mechanical Turk and you can.",
            "You can read about that can be."
        ],
        [
            "Related work.",
            "As you might expect, you know these these Turkers these spades assessors verse simply asked to rate particular resources, particular results that people submitted against the queries that that we proposed, so I can see an example of such an evaluation form here we used multigrade scaling so that you can compute measures that that take take, take scaling into account."
        ],
        [
            "In in implementation, this simplified somewhat the theoretical model or a formal model that I that I described earlier in that we actually don't use a different weight for all the different properties.",
            "We actually do what I mentioned in the indexing section, we just use 3 levels, so we assign.",
            "Find ascential properties into three different buckets.",
            "Important neutral.",
            "An unimportant ones.",
            "But in this case, but of course this can be extended to to any number of levels that you might want to try.",
            "Also, instead of assigning weights to individual documents, which is which is allowed by the model, we assigned weights to domains.",
            "And essentially all the documents from the same domain, then then get the same fate.",
            "For the parameters, so the there's a single parameter B for all BS is even though you could have a separate BS parameter or for all the fields.",
            "And similarly there's a.",
            "There's a single parameter for the length of the field instead of instead of a different parameter for the for the length of different fields, and we also bonded this by a maximum.",
            "Anne.",
            "You might ask how we are we actually assigned the properties into these different weight classes.",
            "Well, they will simply manual in this work.",
            "So the point of this work was simply to prove that you know even a simple manual classification of properties and thus exploiting some of the semantics and some of the things we know about the importance of these properties can help you to improve your retrieval.",
            "Now obviously, you might want to try and learn this classification.",
            "What we do so the classification we do manually what we do in this work is to stick to innovate so the actual values that we assign to these classes."
        ],
        [
            "So here are the results in terms of the in terms of the effectiveness of the method compared to the baseline, which is again the M 25.",
            "So the plane unstructured index.",
            "Where are you simply assign all text in the resource description to a document?",
            "We performed two series of experiments.",
            "One is there and as you can see in the individual features column, one is where we took the baseline and we added each feature individually, right?",
            "And the second is, which is shown in the combination column is where we add these features sequentially.",
            "So we add feature.",
            "Then we had the next feature keeping the previous one, and so on and so on.",
            "So you can sort of see the marginal improvement in the second column.",
            "What is personal thing here is that all of these results are actually positive and this thing is different improvements compared to the baseline.",
            "And even this this manual classification of properties and domains seem to help and seem to help in a quite big way, resulting in 2025% improvement over the baseline even when you just consider that those features.",
            "Hello.",
            "Overall, and that and that you can see if you would actually add up the numbers in the in the combination column, the overall improvement is about 53% over the baseline.",
            "What you also see is that we get different.",
            "These different features actually do combine.",
            "You represent different signals of relevance so that so that when you add them in combination, each of them contributes to the results.",
            "Obviously, you know you might wonder why the B parameter is contributing so much that's actually available, resulting in literature that if you just, you know, tune that particular parameter of the model, you will get that improvement.",
            "So in fact, you know we would not necessarily even quote results very not tuning to be perative, because it's an expected feature."
        ],
        [
            "In comparison to the other systems that have been that have been submitted to the evaluation at at this, some search 2010 challenge, we compare the results to the results that have been reported there.",
            "We used for the tuning of our parameters.",
            "We use the two fold cross validation approach and we in this case we actually tuned all the parameters at the same time using these promising directions algorithm by Robertson and Zaragoza.",
            "What we see here is is a 42% improvement or the best method that has been that has been submitted in terms of MMPI score.",
            "And then maybe we'll be able to primary evaluation metric there.",
            "If you look in the results in a bit more detail, what we see is maybe somewhat not surprisingly, we perform well on short and specific queries with with many results.",
            "Negative example, would something like this query The Morning Call Lehigh Valley, PA.",
            "This is the case where the user entered many many words, hoping to get better results.",
            "But everyone actually the results get diverse because.",
            "That are very relevant.",
            "Results were not all of these words would be mentioned."
        ],
        [
            "OK, so so I'm getting to the end here, and in conclusion we provided knew indexing schemes and the ranking method for RDF data, the ranking method being based on BM25F.",
            "There are a couple of ways we would like to extend this in the future.",
            "One One Direction is looking at ranking documents with metadata, so this is the case where where you have an annotated document, for example microdata, RDF data and so on.",
            "Another direction is to exploit more of the semantics.",
            "So for example, try to take either explicit same as statements into account or try to do coreference resolution on the result set online and see if that that improves.",
            "That improves things from out from every whole perspective.",
            "Um?",
            "Then of course, when you're when you're displaying search results, you might you might have the task of also ranking the triples for display, and that's that's an area of research as well as well as ask question answering over RDF data.",
            "Right so it's actually going into into trying to answer full full questions formulated in natural language."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Thank you, thank you, Paul for enthusiastic introduction.",
                    "label": 0
                },
                {
                    "sent": "Welcome everyone.",
                    "label": 0
                },
                {
                    "sent": "My name is Peter Mika.",
                    "label": 0
                },
                {
                    "sent": "This is the paper titled Effective and Efficient Entity Search in RDF data Ann.",
                    "label": 1
                },
                {
                    "sent": "I guess it's alternative in the same sense that the previous to talks were alternative in that we're talking about information retrieval inspired approaches to RDF querying.",
                    "label": 0
                },
                {
                    "sent": "This is joint work with my colleague Roy Blanco, also from Yahoo Research in Barcelona and with Sebastian Vigna from Milano.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So why are we talking about semantic search?",
                    "label": 1
                },
                {
                    "sent": "Just to recap, some of the motivation or some of these pieces were mentioned earlier.",
                    "label": 0
                },
                {
                    "sent": "We are mainly intending to support end users who may not be able to express their their needs in sparkle because they don't even know what sparkle is on the 1st place.",
                    "label": 0
                },
                {
                    "sent": "We are targeting situations where there are large datasets.",
                    "label": 0
                },
                {
                    "sent": "You probably know that in the past two or three years to semantic Web has sort of boomed in data both as a result of.",
                    "label": 0
                },
                {
                    "sent": "The linked data, efforts and sort of an interest in in web markup in marking up pages with with our DFI another format and this has given us sort of a large scale and larger scale data corpus to work with very small.",
                    "label": 0
                },
                {
                    "sent": "The earlier approaches might not scale.",
                    "label": 0
                },
                {
                    "sent": "Also we are looking at very heterogeneous datasets, so in particular datasets collected from the web.",
                    "label": 0
                },
                {
                    "sent": "The problem in this case is that the users.",
                    "label": 0
                },
                {
                    "sent": "May not be aware of the scheme of the data or simply the data set is so heterogeneous that there's no way that the user can keep in mind all the classes and properties that are in the data.",
                    "label": 1
                },
                {
                    "sent": "So just to give you an example.",
                    "label": 1
                },
                {
                    "sent": "In the billion triples, 2009 days said that we work with.",
                    "label": 0
                },
                {
                    "sent": "There are two point 6 million classes and 33,000 properties.",
                    "label": 0
                },
                {
                    "sent": "So obviously we cannot expect the user to exactly name the class and the properties that that he or she is interested in.",
                    "label": 0
                },
                {
                    "sent": "So simply in this case it's not possible for the user to formulate their structured query that would precisely match his or her information need.",
                    "label": 0
                },
                {
                    "sent": "We are also talking about the entity search and these are queries.",
                    "label": 0
                },
                {
                    "sent": "These are the most basic types of queries.",
                    "label": 1
                },
                {
                    "sent": "A schema for mentioned where the user is looking for exactly 1 entity.",
                    "label": 0
                },
                {
                    "sent": "So the user has does have something in mind right?",
                    "label": 0
                },
                {
                    "sent": "These are not.",
                    "label": 0
                },
                {
                    "sent": "This is not kind of the least searches, but the user does have a particular entity in mind and in the query contains the description.",
                    "label": 0
                },
                {
                    "sent": "Of this entity, either contains are the names the entity or or provide some description of it.",
                    "label": 0
                },
                {
                    "sent": "I put some examples there.",
                    "label": 0
                },
                {
                    "sent": "These queries might seem basic in that in that these are.",
                    "label": 0
                },
                {
                    "sent": "This is actually what the user wants, and it seems that you just have to match it to the description of the resources that are in the data set.",
                    "label": 0
                },
                {
                    "sent": "But still this becomes a very hard problem simply because there might be a linguistic mismatch.",
                    "label": 0
                },
                {
                    "sent": "So maybe the words are not exactly the same in the query as in the resources to be rank.",
                    "label": 0
                },
                {
                    "sent": "There might be relevant issues right?",
                    "label": 0
                },
                {
                    "sent": "So maybe?",
                    "label": 0
                },
                {
                    "sent": "You don't exactly have one of these entities in your data set, but you have something related, in which case the problem is to rank the resources by degree of relatedness.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So that's that's the problem we are dealing with.",
                    "label": 0
                },
                {
                    "sent": "I just wanted to mention very briefly that this has practical applications in web search in particular.",
                    "label": 0
                },
                {
                    "sent": "So these days when you when you go to a search engine and you search for such an entity query like in this case Born Germany, you already get quite a bit of structured data, right?",
                    "label": 0
                },
                {
                    "sent": "So in this case the search engine tries to identify the particular entity, in this case of city, the discovery starting and give you some information about.",
                    "label": 0
                },
                {
                    "sent": "About that city.",
                    "label": 0
                },
                {
                    "sent": "Also, we show related entities in this case.",
                    "label": 0
                },
                {
                    "sent": "This is a screenshot from Yahoo search, and obviously that again requires to find the focused entity of the query.",
                    "label": 0
                },
                {
                    "sent": "And Lastly, we use more and more structured data that we extract from HTML.",
                    "label": 1
                },
                {
                    "sent": "To you to increased markup.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Again, to summarize, you know how this?",
                    "label": 0
                },
                {
                    "sent": "How this compares to I guess than an alternative approaches to do RDF carrying and that is the more database style indexing of RDF data, which is typically implemented in triple stores.",
                    "label": 1
                },
                {
                    "sent": "Triple stores are built to execute structural queries and typically they do not provide keyword query facilities or if they do, then it's some kind of side index that is operated.",
                    "label": 0
                },
                {
                    "sent": "On the side.",
                    "label": 0
                },
                {
                    "sent": "And even in that case the the site index is used only for for matching.",
                    "label": 0
                },
                {
                    "sent": "For restricting search results.",
                    "label": 0
                },
                {
                    "sent": "But typically triple stores do not provide ranking of results.",
                    "label": 0
                },
                {
                    "sent": "And since there's no ranking evaluation or the competition between triple stores, if you will is mostly on their on their efficiency, how fast they are?",
                    "label": 0
                },
                {
                    "sent": "Comparing that to the more I are inspired approaches, these are search engines.",
                    "label": 0
                },
                {
                    "sent": "We call them search engines.",
                    "label": 0
                },
                {
                    "sent": "They execute keyword queries and the focus is on ranking so much of the competition in this field is on the effectiveness, right?",
                    "label": 0
                },
                {
                    "sent": "So how good you are in ranking things in terms of the relevancy to the user query?",
                    "label": 0
                },
                {
                    "sent": "Of course there are there approaches in the related work that tries to combine these two very different ways of thinking.",
                    "label": 0
                },
                {
                    "sent": "By combining keyword matching with some limited joint processing, for example.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I will not go into into great detail in related work.",
                    "label": 0
                },
                {
                    "sent": "Please, please see the paper.",
                    "label": 0
                },
                {
                    "sent": "This is a relatively new field that I wanted to mention, so I guess I SW. 2007 was probably first conference or we've seen a paper that that looked at our approaches to to semantic web search.",
                    "label": 0
                },
                {
                    "sent": "There have been a number of papers since then, in fact, we've been organizing a semantic search workshop since 2008, so a lot of the related work appeared there.",
                    "label": 0
                },
                {
                    "sent": "One particular paper by by Perez Agara is very close to our ranking method in the sense that we're both space or experiments on on the BM25F ranking model.",
                    "label": 0
                },
                {
                    "sent": "I'll explain how we how we extend that.",
                    "label": 0
                },
                {
                    "sent": "And of course there are many, many others.",
                    "label": 1
                },
                {
                    "sent": "The literature you might want to look at also evaluation campaigns.",
                    "label": 0
                },
                {
                    "sent": "The one we use in this paper is evaluation campaign that has been organized in conjunction with the previously mentioned semantic search.",
                    "label": 0
                },
                {
                    "sent": "Workshop is called the same search challenge.",
                    "label": 1
                },
                {
                    "sent": "Their systems participate and compete on RDF ranking task.",
                    "label": 0
                },
                {
                    "sent": "There are similar competitions with slightly different focus question answering or link data.",
                    "label": 0
                },
                {
                    "sent": "That was an event organized this year and as the name says, its focus is it focuses on question answering so that our full questions to be answered.",
                    "label": 0
                },
                {
                    "sent": "And the track entity track?",
                    "label": 1
                },
                {
                    "sent": "That's that's more on the information retrieval side in the sense that you are still ranking documents, but each document is somehow relevant to a particular entity.",
                    "label": 0
                },
                {
                    "sent": "Um and then of course.",
                    "label": 0
                },
                {
                    "sent": "As previously mentioned, there are related applications of IR to other data models, databases, XML and some.",
                    "label": 0
                },
                {
                    "sent": "Some of these fields, for example keyword searching databases, did not produce kind of evaluation frameworks that you're lucky to have in some of the Trinity.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so a very brief overview of how how the big picture looks like.",
                    "label": 0
                },
                {
                    "sent": "Essentially we are building a full full search engine, very take an RDF collection from the web, which is typically quads, so so triples with some provenance information in the document to which they belonged on the web.",
                    "label": 0
                },
                {
                    "sent": "And then simply the index.",
                    "label": 0
                },
                {
                    "sent": "These collections using MapReduce and I'll explain a bit more how that works.",
                    "label": 0
                },
                {
                    "sent": "So that's going to be the first part of the talk.",
                    "label": 1
                },
                {
                    "sent": "And then once you build this indices as a result of the process, you get a set of indices which you have to merge and then distribute that you're you're serving environment, and that's where ranking take place and I'll focus on the ranking in the second part.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Very briefly, RDF indexing using MapReduce MapReduce if if you know its origin comes out.",
                    "label": 1
                },
                {
                    "sent": "The current implementation of it, at least or distributed systems comes out from Google, so there's no wonder that it's very good for building search indices, and in fact, the basic operation of MapReduce is exactly what you need to build an inverted index, so you parse the document into into key value pairs where the key is a term and values document.",
                    "label": 1
                },
                {
                    "sent": "And the framework what it does is simply to collect the values for the same key so it collects all the documents that contain a particular term, and that's exactly what you need to build an inverted index.",
                    "label": 1
                },
                {
                    "sent": "So nothing new there.",
                    "label": 0
                },
                {
                    "sent": "The application of this to RDF indexing is slightly different in that RDF structure.",
                    "label": 0
                },
                {
                    "sent": "Then you want to preserve some of this structure.",
                    "label": 1
                },
                {
                    "sent": "This is described in a previous paper, but basic idea is that there are more less variations of this in a little bit more less.",
                    "label": 0
                },
                {
                    "sent": "The basic idea is you take as a document all the triples about a given subject.",
                    "label": 0
                },
                {
                    "sent": "You are I and you index that in some way you can expand that.",
                    "label": 0
                },
                {
                    "sent": "So you might take RDF.",
                    "label": 0
                },
                {
                    "sent": "Molecules are also related.",
                    "label": 0
                },
                {
                    "sent": "Related resources when you're creating your documents.",
                    "label": 0
                },
                {
                    "sent": "And then you you create some comfort index that is capable of of capturing from which property a certain value belong to, right?",
                    "label": 0
                },
                {
                    "sent": "So which in which property of certain keyword epigram?",
                    "label": 0
                },
                {
                    "sent": "And I will show you all the basic variations that that you're working with in this work.",
                    "label": 0
                },
                {
                    "sent": "Typically, in addition to this, people also index terms in the subject you are I because people choose your eyes on the web to be meaningful.",
                    "label": 1
                },
                {
                    "sent": "So often that so this is very valuable signal for Frank.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There are two basic index structures that we previously proposed, and there's a third one in this paper.",
                    "label": 0
                },
                {
                    "sent": "The first one that we proposed two years ago, I guess, was this.",
                    "label": 0
                },
                {
                    "sent": "This horizontal index structure actually very natural way to organize your data when you simply have one field in your index for essentially every position.",
                    "label": 1
                },
                {
                    "sent": "So one field would contain the keywords from the value from the literals.",
                    "label": 0
                },
                {
                    "sent": "One field would contain the words from the properties and if you want another field which contain words from from the context in first position of the quad.",
                    "label": 0
                },
                {
                    "sent": "Now this type of index allows you to do searches where you're looking for a particular variant of particular field, and in order to do that you need what they called the alignment operator, which is supported by some search engines.",
                    "label": 0
                },
                {
                    "sent": "Do not.",
                    "label": 0
                },
                {
                    "sent": "All these M G4, JM, G4, J supports this and the alignment operator basically does what it sounds like.",
                    "label": 1
                },
                {
                    "sent": "If you say I'm looking for the word Peter, but only in asset value of 4th name.",
                    "label": 0
                },
                {
                    "sent": "It looks for matches of Peter and it looks for measure full name and only counted as a match if it appears on the same position, right?",
                    "label": 1
                },
                {
                    "sent": "So here the alignment is that.",
                    "label": 0
                },
                {
                    "sent": "The particular on the particular position in the token field.",
                    "label": 1
                },
                {
                    "sent": "The property field provides for which property was it the value.",
                    "label": 0
                },
                {
                    "sent": "I'm.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The other natural way to organize your data is is sort of sort of iteration of this.",
                    "label": 0
                },
                {
                    "sent": "They actually have one field, their property, so you take you take all your properties or as much as you can, and you create a separate index for each of them, right?",
                    "label": 0
                },
                {
                    "sent": "And in this case it's very natural to just execute the previous dimensions vary where you're looking for a particular term in a particular property, because you just go to the particular index that represents that property.",
                    "label": 0
                },
                {
                    "sent": "This sounds very good in practice.",
                    "label": 0
                },
                {
                    "sent": "One of the problems that you're running into this is that if you have many, many properties.",
                    "label": 0
                },
                {
                    "sent": "And you're using the approach that we used value generating disease using MapReduce.",
                    "label": 0
                },
                {
                    "sent": "You might end up with with very many small indices, which is then a problem for for performance.",
                    "label": 1
                },
                {
                    "sent": "And also you know practical problems like you have to keep these indices in memory on the reducers while you're building your index and so on.",
                    "label": 0
                },
                {
                    "sent": "However, the the way to deal with that is that we actually limit the number of properties in the experiments.",
                    "label": 0
                },
                {
                    "sent": "We just take the top end most common properties in a particular evaluation.",
                    "label": 1
                },
                {
                    "sent": "It's 300, so top 300 properties in the data set.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In this paper, we propose efficiency improvements to this for this basic scheme.",
                    "label": 1
                },
                {
                    "sent": "And one is what we call the reduced vertical index.",
                    "label": 0
                },
                {
                    "sent": "The idea here, or the observation is that you don't really need if just one for ranking for a keyword queries you don't really need to distinguish fields that you will eventually attribute the same weight too.",
                    "label": 0
                },
                {
                    "sent": "So if you if you if you use their ranking scheme like we do, they assign weights to particular properties.",
                    "label": 1
                },
                {
                    "sent": "You will probably assign similar weight levels, at least some properties and you can.",
                    "label": 0
                },
                {
                    "sent": "Group basically the text from these properties into into into the same field so that in our case we use 3 weight levels.",
                    "label": 0
                },
                {
                    "sent": "So in this case you have three, so 300 fields.",
                    "label": 0
                },
                {
                    "sent": "You would have three fields, which which makes things more efficient.",
                    "label": 1
                },
                {
                    "sent": "Other very basic practical steps you can take is to precompute these alignments that I mentioned previously.",
                    "label": 0
                },
                {
                    "sent": "So basically what you what you build an index that tells you which terms appear in any of the resources, which terms up here in a particular field, right?",
                    "label": 0
                },
                {
                    "sent": "Again, this is helpful because.",
                    "label": 0
                },
                {
                    "sent": "Yeah, the fields might have very particular vocabulary, so for example, you know the H field will hopefully always contain numbers, so if there's a word that is not a number, that will probably never appear in the age field and you can know that in advance and you can put in your query.",
                    "label": 0
                },
                {
                    "sent": "Accordingly.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "We previously reported numbers on indexing efficiency, so I just I just put them here for for completeness.",
                    "label": 0
                },
                {
                    "sent": "The data set the experiment within.",
                    "label": 0
                },
                {
                    "sent": "Actually all of these experiments is the billion triples 2098 set.",
                    "label": 0
                },
                {
                    "sent": "I already mentioned.",
                    "label": 0
                },
                {
                    "sent": "It's a fairly heterogeneous data set, it's about 250 gigabytes of uncompressed data.",
                    "label": 0
                },
                {
                    "sent": "For the vertical next thing I mentioned, we selected the 300 most frequent data type properties.",
                    "label": 1
                },
                {
                    "sent": "We actually only next decide properties, so we end up indexing about 270 million triples from the one 1.1 billion triples in total.",
                    "label": 1
                },
                {
                    "sent": "We do the indexing using using Hadoop Hadoop implementation of MapReduce.",
                    "label": 1
                },
                {
                    "sent": "Very essentially I didn't mention but essentially this is a fully parallelizable problem, so the scale is really limited only by the number of machines that you have.",
                    "label": 1
                },
                {
                    "sent": "The number of mappers, if you know how do you Members is basically determined by the size of your input data.",
                    "label": 0
                },
                {
                    "sent": "The number of users is something that you choose.",
                    "label": 0
                },
                {
                    "sent": "In this case, it's a tradeoff between how fast indexing is going to go and how small the indexes will be at the end, right?",
                    "label": 0
                },
                {
                    "sent": "So if you said the number for users very high, we get very very small indices, which you'll have to spend some time to merge.",
                    "label": 0
                },
                {
                    "sent": "But essentially, you know the the numbers are are in the paper.",
                    "label": 0
                },
                {
                    "sent": "Essentially, you know this is paralyzed a problem, so it's it just depends on how much how much you spend on hardware.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "More interesting probably is, is the runtime efficiency of these index structures and in compression.",
                    "label": 1
                },
                {
                    "sent": "So here we measured the average execution time using a large stuff queries.",
                    "label": 1
                },
                {
                    "sent": "So we took 150,000 queries.",
                    "label": 1
                },
                {
                    "sent": "We of course did not manually check that they aren't queries, but we simply took various that little Wikipedia clicks, assuming that that on average they will be antiquaries.",
                    "label": 1
                },
                {
                    "sent": "The length of this is about 2.2 tokens on average.",
                    "label": 0
                },
                {
                    "sent": "And as a baseline, you know, besides all these structured indices, we took a plain text index.",
                    "label": 0
                },
                {
                    "sent": "Very don't separate the description of resource into separate fields, but just take all the text that is in the description of the resource.",
                    "label": 0
                },
                {
                    "sent": "You can see that that you know information that people engines are fairly fast, so here we are always talking about subsequent times here.",
                    "label": 0
                },
                {
                    "sent": "Plain text indexing.",
                    "label": 0
                },
                {
                    "sent": "This is MG4J.",
                    "label": 0
                },
                {
                    "sent": "I did not mention by the size of this index is about 5 gigabytes, so this is a billion triples.",
                    "label": 0
                },
                {
                    "sent": "Data after indexing is $250, you get 5 gigabytes index which which is something you can keep in memory these days.",
                    "label": 1
                },
                {
                    "sent": "So things are super super fast because of that as well.",
                    "label": 0
                },
                {
                    "sent": "The base you know the baseline is under 100 milliseconds.",
                    "label": 0
                },
                {
                    "sent": "Horizontal indexes is more expensive because of the alignment operator, and we also tested the differences between and and or execution modes and is always faster and it's obviously you can terminate early right?",
                    "label": 1
                },
                {
                    "sent": "If you don't.",
                    "label": 0
                },
                {
                    "sent": "If you don't find one of the keywords.",
                    "label": 0
                },
                {
                    "sent": "Harvard or is typically used in the cases on smaller datasets, and even billion triples is a small data set in this case, and and is typically used by by web search engines.",
                    "label": 0
                },
                {
                    "sent": "In larger datasets, the vertical index does significantly improve the execution time for these.",
                    "label": 0
                },
                {
                    "sent": "For the OR operation mode that we are interested in, and it gets it down to about 150 milliseconds, which we consider good.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now moving onto ranking and the second part we use a modification of the young 25 F. We have 25 and the Empire F are valuable metals in the literature.",
                    "label": 0
                },
                {
                    "sent": "We did not invent them.",
                    "label": 0
                },
                {
                    "sent": "Essentially the basic idea of of these all these ranking models is that supposed to you know standard TF IDF you take into account the fact that additional terms in the documents.",
                    "label": 0
                },
                {
                    "sent": "Additional appearances of the term in the document may may contribute decreasing amounts of relevance.",
                    "label": 0
                },
                {
                    "sent": "So what you do is you take the term frequency, but you normalize it by this by this document length normalization factor, which takes into account the average length of the field compared to how many times the term appeared.",
                    "label": 1
                },
                {
                    "sent": "There's also debating here, right?",
                    "label": 0
                },
                {
                    "sent": "So so this is scheme that allows you to put different weights in different fields.",
                    "label": 0
                },
                {
                    "sent": "And in the horizontal case, units, token, and property and all that in the vertical case.",
                    "label": 0
                },
                {
                    "sent": "That's that's the different properties that you're indexing.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The ranking score is then a combination of of this.",
                    "label": 1
                },
                {
                    "sent": "This modified TF measure and an IDF and inverse document frequency measure which is dirty tendered IDF measure.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "The the key parameter here is is a tunable parameter which basically puts the weight on the on the modified version of the tfor.",
                    "label": 1
                },
                {
                    "sent": "The unmodified version of the TF.",
                    "label": 1
                },
                {
                    "sent": "The final score is.",
                    "label": 0
                },
                {
                    "sent": "Then is, then simply the scores of the individual terms.",
                    "label": 0
                },
                {
                    "sent": "So if you take the query terms you do the do the matching and scoring of them individually and then at the end you sum up those scores to get a complete score for that.",
                    "label": 0
                },
                {
                    "sent": "Very in that particular resource or document that you're.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is the basic function they've evaluated it and.",
                    "label": 0
                },
                {
                    "sent": "In practice, is that we took this semantic search Challenge 2010 task.",
                    "label": 1
                },
                {
                    "sent": "There is a public evaluation, so the data are the queries and assessments.",
                    "label": 0
                },
                {
                    "sent": "Everything is available online, so the results are reproducible.",
                    "label": 0
                },
                {
                    "sent": "This evaluation uses this billion triples 2009 days set, and the queries are manually selected entity queries.",
                    "label": 0
                },
                {
                    "sent": "They've been selected from a sample, and these samples are taken from real web search query logs, so they are real real queries entered by users.",
                    "label": 0
                },
                {
                    "sent": "This is public evaluation that I mentioned the.",
                    "label": 0
                },
                {
                    "sent": "The Co organized two years ago at this at this workshop.",
                    "label": 0
                },
                {
                    "sent": "So I think 6 systems participated that year in this competition.",
                    "label": 0
                },
                {
                    "sent": "And we did not participate.",
                    "label": 1
                },
                {
                    "sent": "We assess the results using Amazon's Mechanical Turk, or rather, this competition assess the results using Amazon Mechanical Turk and you can.",
                    "label": 0
                },
                {
                    "sent": "You can read about that can be.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Related work.",
                    "label": 0
                },
                {
                    "sent": "As you might expect, you know these these Turkers these spades assessors verse simply asked to rate particular resources, particular results that people submitted against the queries that that we proposed, so I can see an example of such an evaluation form here we used multigrade scaling so that you can compute measures that that take take, take scaling into account.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In in implementation, this simplified somewhat the theoretical model or a formal model that I that I described earlier in that we actually don't use a different weight for all the different properties.",
                    "label": 0
                },
                {
                    "sent": "We actually do what I mentioned in the indexing section, we just use 3 levels, so we assign.",
                    "label": 0
                },
                {
                    "sent": "Find ascential properties into three different buckets.",
                    "label": 0
                },
                {
                    "sent": "Important neutral.",
                    "label": 0
                },
                {
                    "sent": "An unimportant ones.",
                    "label": 0
                },
                {
                    "sent": "But in this case, but of course this can be extended to to any number of levels that you might want to try.",
                    "label": 0
                },
                {
                    "sent": "Also, instead of assigning weights to individual documents, which is which is allowed by the model, we assigned weights to domains.",
                    "label": 0
                },
                {
                    "sent": "And essentially all the documents from the same domain, then then get the same fate.",
                    "label": 0
                },
                {
                    "sent": "For the parameters, so the there's a single parameter B for all BS is even though you could have a separate BS parameter or for all the fields.",
                    "label": 1
                },
                {
                    "sent": "And similarly there's a.",
                    "label": 0
                },
                {
                    "sent": "There's a single parameter for the length of the field instead of instead of a different parameter for the for the length of different fields, and we also bonded this by a maximum.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "You might ask how we are we actually assigned the properties into these different weight classes.",
                    "label": 0
                },
                {
                    "sent": "Well, they will simply manual in this work.",
                    "label": 0
                },
                {
                    "sent": "So the point of this work was simply to prove that you know even a simple manual classification of properties and thus exploiting some of the semantics and some of the things we know about the importance of these properties can help you to improve your retrieval.",
                    "label": 0
                },
                {
                    "sent": "Now obviously, you might want to try and learn this classification.",
                    "label": 0
                },
                {
                    "sent": "What we do so the classification we do manually what we do in this work is to stick to innovate so the actual values that we assign to these classes.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here are the results in terms of the in terms of the effectiveness of the method compared to the baseline, which is again the M 25.",
                    "label": 0
                },
                {
                    "sent": "So the plane unstructured index.",
                    "label": 0
                },
                {
                    "sent": "Where are you simply assign all text in the resource description to a document?",
                    "label": 0
                },
                {
                    "sent": "We performed two series of experiments.",
                    "label": 0
                },
                {
                    "sent": "One is there and as you can see in the individual features column, one is where we took the baseline and we added each feature individually, right?",
                    "label": 0
                },
                {
                    "sent": "And the second is, which is shown in the combination column is where we add these features sequentially.",
                    "label": 0
                },
                {
                    "sent": "So we add feature.",
                    "label": 0
                },
                {
                    "sent": "Then we had the next feature keeping the previous one, and so on and so on.",
                    "label": 0
                },
                {
                    "sent": "So you can sort of see the marginal improvement in the second column.",
                    "label": 0
                },
                {
                    "sent": "What is personal thing here is that all of these results are actually positive and this thing is different improvements compared to the baseline.",
                    "label": 0
                },
                {
                    "sent": "And even this this manual classification of properties and domains seem to help and seem to help in a quite big way, resulting in 2025% improvement over the baseline even when you just consider that those features.",
                    "label": 1
                },
                {
                    "sent": "Hello.",
                    "label": 0
                },
                {
                    "sent": "Overall, and that and that you can see if you would actually add up the numbers in the in the combination column, the overall improvement is about 53% over the baseline.",
                    "label": 0
                },
                {
                    "sent": "What you also see is that we get different.",
                    "label": 0
                },
                {
                    "sent": "These different features actually do combine.",
                    "label": 1
                },
                {
                    "sent": "You represent different signals of relevance so that so that when you add them in combination, each of them contributes to the results.",
                    "label": 0
                },
                {
                    "sent": "Obviously, you know you might wonder why the B parameter is contributing so much that's actually available, resulting in literature that if you just, you know, tune that particular parameter of the model, you will get that improvement.",
                    "label": 0
                },
                {
                    "sent": "So in fact, you know we would not necessarily even quote results very not tuning to be perative, because it's an expected feature.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In comparison to the other systems that have been that have been submitted to the evaluation at at this, some search 2010 challenge, we compare the results to the results that have been reported there.",
                    "label": 0
                },
                {
                    "sent": "We used for the tuning of our parameters.",
                    "label": 0
                },
                {
                    "sent": "We use the two fold cross validation approach and we in this case we actually tuned all the parameters at the same time using these promising directions algorithm by Robertson and Zaragoza.",
                    "label": 1
                },
                {
                    "sent": "What we see here is is a 42% improvement or the best method that has been that has been submitted in terms of MMPI score.",
                    "label": 0
                },
                {
                    "sent": "And then maybe we'll be able to primary evaluation metric there.",
                    "label": 0
                },
                {
                    "sent": "If you look in the results in a bit more detail, what we see is maybe somewhat not surprisingly, we perform well on short and specific queries with with many results.",
                    "label": 1
                },
                {
                    "sent": "Negative example, would something like this query The Morning Call Lehigh Valley, PA.",
                    "label": 0
                },
                {
                    "sent": "This is the case where the user entered many many words, hoping to get better results.",
                    "label": 0
                },
                {
                    "sent": "But everyone actually the results get diverse because.",
                    "label": 0
                },
                {
                    "sent": "That are very relevant.",
                    "label": 0
                },
                {
                    "sent": "Results were not all of these words would be mentioned.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so so I'm getting to the end here, and in conclusion we provided knew indexing schemes and the ranking method for RDF data, the ranking method being based on BM25F.",
                    "label": 1
                },
                {
                    "sent": "There are a couple of ways we would like to extend this in the future.",
                    "label": 0
                },
                {
                    "sent": "One One Direction is looking at ranking documents with metadata, so this is the case where where you have an annotated document, for example microdata, RDF data and so on.",
                    "label": 1
                },
                {
                    "sent": "Another direction is to exploit more of the semantics.",
                    "label": 0
                },
                {
                    "sent": "So for example, try to take either explicit same as statements into account or try to do coreference resolution on the result set online and see if that that improves.",
                    "label": 0
                },
                {
                    "sent": "That improves things from out from every whole perspective.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Then of course, when you're when you're displaying search results, you might you might have the task of also ranking the triples for display, and that's that's an area of research as well as well as ask question answering over RDF data.",
                    "label": 0
                },
                {
                    "sent": "Right so it's actually going into into trying to answer full full questions formulated in natural language.",
                    "label": 0
                }
            ]
        }
    }
}