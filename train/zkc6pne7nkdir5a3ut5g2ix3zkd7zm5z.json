{
    "id": "zkc6pne7nkdir5a3ut5g2ix3zkd7zm5z",
    "title": "Bayesian Inference of Mechanistic Systems Models Using Population MCMC",
    "info": {
        "author": [
            "Ben Calderhead, Department of Statistical Science, University College London"
        ],
        "published": "Nov. 6, 2007",
        "recorded": "September 2007",
        "category": [
            "Top->Computer Science->Machine Learning->Markov Processes",
            "Top->Computer Science->Machine Learning->Bayesian Learning"
        ]
    },
    "url": "http://videolectures.net/pim07_calderhead_bim/",
    "segmentation": [
        [
            "The challenges associated with sampling from multimodal distributions, the likes of which crop up quite often.",
            "Trying to infer parameters over particularly assilah Terry models an I talked about a population based method of sampling which was able to sample accurately from these multiple distributions, so I'd like to continue today on the same theme introducing another population based method of sampling population Markov chain Monte Carlo.",
            "So start off by showing firstly that can simulate from these complex.",
            "Posterior distributions and then I'll show how it can be used together with thermodynamic integration, calculate marginal likelihoods and base factors which can be used for comparing competing model hypothesis."
        ],
        [
            "OK, first of all, talk by the Celtic biological processes, which will be modeling and then I'll talk about the parameter inference over such models and then finally about model comparison and show some results that we've got comparing two nonlinear facility models."
        ],
        [
            "OK, so many important ilitary systems are poorly understood.",
            "An even very important ones such as the skating Clock."
        ],
        [
            "And so it's important to produce methodology which will allow us to develop and compare models or hypothesis for prescribing these.",
            "So in the case of Arabidopsis, it's been estimated that more than 5% of the genome is directly or indirectly affected by output pathways from these circadian biochemical networks, and this corresponds to in order to 50,000 different genes.",
            "So obviously we want to be able to understand the genome as a whole.",
            "It's vital that we understand this particular starcadian network."
        ],
        [
            "A silvery behavior occurs in other areas as well, so the development of vertebrate embryos as such as S1.",
            "So here we also see a similar kind of symmetry behavior."
        ],
        [
            "And we can reproduce this kind of behavior using time delays on negative feedback loops."
        ],
        [
            "So you're such a model for this one, so it's fairly simple model, just two equations.",
            "So DN BI DT is the rate of change of M RNA and DP by TI by DT is the rate of change of the protein.",
            "So you can see there's a time delay when you seem tired and.",
            "Munamon UPR the degradation rates for the M RNA and protein."
        ],
        [
            "And the period of oscillation T is dependent on this to and these two free parameters, so we can see that.",
            "R. Data with a particular periods we can produce lots of sets of parameters that produce the same facility behavior."
        ],
        [
            "And so it's difficult type uniquely identify one single correct set of parameters.",
            "Of course could use optimization based methods such as simulated annealing to find maybe a global maximum, but there may well be other.",
            "Equally valid solutions, and so if you use just simulated annealing you would ignore.",
            "The whole range of dynamics from particular model.",
            "And so this comes.",
            "This is where the advanced sampling techniques such as population, Markov chain, Monte Carlo comes in.",
            "So we want to be able to sample from the whole distribution of likely parameter sets and not just find a single global Max."
        ],
        [
            "OK, so at this point I'm going to introduce a multi dimensional representation of a complex posterior distribution for which we need some 3D glasses.",
            "I've only got 10 pairs, so you might need to share them about it.",
            "Handsome."
        ],
        [
            "Hopefully this will work.",
            "So.",
            "This is a typical posterior distribution and so you can clearly see the two parameters that are coupled and producing these concentric circles in the in the posterior.",
            "OK, upon re previous model and this is from a Goodman model, which is the model of the basic model to describe circadian rhythms.",
            "Yep, so in a lot of the Sillett remodels you find that there there is coupling between the parameters.",
            "And yeah, this is displayed very clearly in the in these ridges.",
            "So the problem is, well can have.",
            "Is that using a similar type of sampling?",
            "The sampler might only find the maximum a local maximum, which could be here could be on this Ridge could be on that Ridge and what we want to be able to do is sample across the whole of the distribution."
        ],
        [
            "OK, so this should be familiar from the last talk, and this is sort of minimal model to describe circadian networks and it's called the Goodwin model.",
            "So it was introduced by Brian Goodwin in the 1960s.",
            "So this is a very old model and it's a very simple model and so we thought we'd start off with a very simple model to see what kind of difficulties will encounter using population, Markov chain Monte Carlo.",
            "As this has three equations and just six free parameters in time."
        ],
        [
            "OK, so this is the set of equations for an N variable Goodwin model an so we can we can change North."
        ],
        [
            "So X1 corresponds to the levels of MRNE, X2 corresponds to the levels of protein and."
        ],
        [
            "The rest of the axis corresponds to perhaps other proteins which introduce delays into the system.",
            "So we have a feedback loop.",
            "Next feedback loop and the extra equations introduced the delays, so this would be equivalent to the Tao in the Hess one set of equations.",
            "And with this is perhaps easier to see.",
            "The relationship to the actual biology that's going on becausw instead of just having a time parameter which we incorporate somehow, we actually have the different equations corresponding to the different proteins, so it's perhaps easier to map it to the real biology."
        ],
        [
            "OK, so this is the same.",
            "Posterior that we saw from the top.",
            "So the blue corresponds to regions of low density and the red regions of high density.",
            "And again you can see the.",
            "The parents parameters.",
            "And this is just using.",
            "Three variable given model, so very basic Goodman model and we're just looking at two of the parameters and fixing the rest of the parameters.",
            "And so for this I used them just the standard metropolis based sampling.",
            "Running 20 chains independently.",
            "With a sampling their starting positions from prior which we defined.",
            "And so the axes correspond to their starting positions, and then you can follow their paths to the.",
            "2/3 circles, which is their end position.",
            "So we can see if an X starts somewhere near the global maximum refine.",
            "It follows the route to the top of the Hill.",
            "If however, they start somewhere.",
            "Else in the parameter space we tend to follow the.",
            "The ridges and if they start way off then go off and wander about somewhere else in the parameter space.",
            "An yes, we can see that the chains don't converge an they also in different places in your finishing mostly different places.",
            "And this depends a bit on the parameter setting would be in CMC, yes, so so we adopted an adaptive step size in order to try and adapt the local steps to the local topology.",
            "What kind of acceptance rate.",
            "OK, so we looked for an exception shape between 20 and 50% and then if it was more than that then would increase the step size to make it less likely that step was accepted.",
            "So this is very good book Bayesian data analysis that incorporates that includes all the engineering techniques that you can use an to try and get this working, but even including even using some of these techniques, we still run into serious problems."
        ],
        [
            "OK, so that was their motivation.",
            "That's why we need a more advanced sampling technique.",
            "So the one chosen to use this population, Markov chain Monte Carlo.",
            "So as the name suggests, instead of using a single independent Markov chain, we use a population of chains, and these can communicate with each other, the idea being that one chain finds a region of higher density than another.",
            "They can move towards the region of high density, and the second idea is to use temperature schedule.",
            "So instead of all the chains exploring just one posterior distribution.",
            "We have different chains exploring different distributions."
        ],
        [
            "In parallel.",
            "Let's take the temporary things.",
            "Yes, yeah, exactly.",
            "And so we're sampling from a product of distributions which are indexed by this temperature parameter.",
            "Anne.",
            "So normally the temperature parameter is between zero and one with T = 1 being equivalent to the actual target distribution, and T = 0 being equivalent to an easy to sample from."
        ],
        [
            "Distribution, such as a prior.",
            "So I'm so we could also write this as posterior being the prior times likelihood raised to this temperature, so when the temperature is 1, obviously it's just the prior times likelihood when the temperature is 0 is just prior, and then we have a range of intermediate temperatures.",
            "And.",
            "I haven't got a picture of this, but if you visualize the intermediate steps you'll see the shape of it changing from a nice flat goes in, for example, and you'll see ridges appearing gradually, so that's a higher temperatures for T closer to zero.",
            "It's easier for the chains to explore the whole of the space.",
            "And then at higher temperature, if a chain gets stuck in a local maximum, it can jump down, temperatures move across, and perhaps find another maximum later."
        ],
        [
            "Yes, this is the basic algorithm.",
            "First of all, with the final temperature schedule.",
            "And then we assign starting positions for the chains at each temperature, so.",
            "And in our case we just sampled these from the prior and then for each iteration and each chain we first of all move them either according to Metropolis Step or a crossover operator.",
            "So the metropolis step is just like a metropolis algorithm.",
            "It just makes a local set.",
            "The crossover operator chooses two different chains and swaps over parts of the position vectors.",
            "So the idea being two chains in different positions and you swap over.",
            "Mutates their position.",
            "Vectors look potentially finds new areas of the parameter space to search.",
            "And so you can set different probabilities that either one or the other will be selected during each iteration.",
            "So I think this suggested in the Yang one paper that it should be about 70% and 50%.",
            "So you want me more local steps than more global steps, because a lot of the global steps won't be accepted just because the lens up in in areas which aren't useful.",
            "Amend the last point is just to exchange between temperatures, so you'll find at Lord higher temperatures, so that equals to zero.",
            "The chains will move by a lot, and when they hit upon an area that is, which is the high density further up the temperature ladder, you'll see the chains jumping up up the temperature later.",
            "So.",
            "So this improves the mixing of the chains, so as opposed having 20 chains which are all independent and moving slowly about, you get this much more much richer dynamics between between the chips."
        ],
        [
            "So again, here's our posterior from above.",
            "To only collect samples from the culture.",
            "We collect them from all the chains, OK?",
            "If you're wanting to just infer the parameters, then it's T equals one that you're interested in is the top temperature you're interested in.",
            "But for thermodynamic integration, which will come to later, we use samples from every chain from every temperature, so there's no waste in the algorithm.",
            "So the 1st.",
            "Shows an.",
            "T = 0 So you can see that there's a lot of movement of the chain about the parameter space, and as we move up the temperature ladder, T = .5.",
            "Slightly less, you can see it a lot of samples are taken from this black blob in the global optimum, but it still explores a bit of the rest of the parameter space, and at the very top.",
            "Temperature the chain quickly focuses in on the absolute maximum.",
            "So you can see it's a lot more successful than the Metropolis approach which had chains finishing up all over the place."
        ],
        [
            "So here's an example in firing all five parameters an.",
            "So firstly, metropolis sampling.",
            "We have the true parameters at the top which we just picked random Ann and as you can see the results are way off.",
            "So again, this is just from one of the chains, because obviously the chains haven't converged, so you can look at any of the chains and none of them.",
            "Well, maybe I think 220 hit the correct values an with the other 18 ending up in another local maximum.",
            "Using population MSMC.",
            "You can see a couple of problems.",
            "For example, this one is quite spread across between 0 and 1.5, but the peak.",
            "Pretty much it's the.",
            "It's the true parameters."
        ],
        [
            "OK, so now I'm going to show how the following on from your question how we can use the samples at every temperature.",
            "It's calculating marginal likely."
        ],
        [
            "It's using thermodynamic integration.",
            "So a good way to discriminate between competing model hypothesis is to use based factors."
        ],
        [
            "So these two are is.",
            "They take into account all the possible parameter values, so we're marginalizing over all of the parameter values and not just focusing on the maximum and so given two models H1H2, we want to calculate the likelihoods of experimental data given the model.",
            "So this is the marginal likelihoods and.",
            "The base factor, which is the support for model one over Model 2, is just given by this ratio."
        ],
        [
            "Answer this can be calculated by integrating over the parameters."
        ],
        [
            "Ace OK, so the last workshop down in Sheffields and lab Vision Medscape this is talk on different ways of calculating the marginal likelihood and it shows that the variance of the marginal likelihoods and calculated using thermodynamic integration was about one of the best ways of calculating it, and so we're just going to ignore the other ways of calculating it for it to snow and focus on thermodynamic integration.",
            "OK, so we can calculate the log of the marginal likelihoods using this expression.",
            "Where the expectation is taken with respect."
        ],
        [
            "The power posterior which is I said before this geometric path between T = 0 = 1.",
            "So between the prior and posterior.",
            "Where the likelihood is distressed, this part T for particular schedule of T going between zero and one."
        ],
        [
            "OK, so obviously this is.",
            "This is intractable.",
            "We can calculate this directly, so we can."
        ],
        [
            "Approximate it.",
            "By discretizing then scroll.",
            "So we want some kind of discretization between.",
            "T0 equal to the equal to 0 and TN equal to 1 and then taking samples from each of the.",
            "Each of these power posteriors we can calculate this numerically, and of course these power posteriors are just the samples we take using population MCMC.",
            "An so once we've run hope MCMC, we can take the samples from each temperature level and just put them into this equation to calculate the log likelihood.",
            "Curious, is there any tension between the scheduler optimizes this best and the best schedule for the populations there is?"
        ],
        [
            "So dominant main gives an expression for the optimal density.",
            "And in terms of minimizing the variance of the resulting estimates, and that's given by this nice expression here.",
            "Which."
        ],
        [
            "Is actually analytic for a linear model, so we can if we ignore the bottom part.",
            "We can get an analytic expression for a linear regression model.",
            "For the top part.",
            "Anne."
        ],
        [
            "OK, so if we calculate that.",
            "We got against function which has all its density between 0.1.",
            "And if we look at if we plot the power posteriors 40 grand between 0.1, we can see that the shape of it changes drastically between 0.1.",
            "An and so thinking about population MCMC?",
            "We want to have small changes between the different levels to make it more likely that change will be able to exchange between the temperatures, so this fits in nicely with the pop MCMC.",
            "So if we choose our temperature schedule with the points.",
            "Clustered towards this region.",
            "And not only can we get better estimates optimized mix for the marginal likelihood, but also makes the pop MCMC algorithm more efficient because during the temperature exchanges it comes more likely the exchanges occur and improves mixing."
        ],
        [
            "Right, so we did a little experiment using 2 Goodman models an with five and seven dimensions respectively.",
            "So obviously these models aren't state of the art.",
            "The very basic and we're using them just to show that this methodology."
        ],
        [
            "This work?",
            "So we create some simulated data from.",
            "Firstly H1 and Secondly H2 and for each of the chemical species.",
            "So for each of the.",
            "Equations that we have an.",
            "We take one measurements at each of 80 time points, which is about similar to the type of real data we might have, and we had some Gaussian noise to."
        ],
        [
            "And then we used population MSMC and thermodynamic integration.",
            "To try and see if we can detect which model the original data came from.",
            "So firstly using the data from each one.",
            "We calculate marginal likelihoods using the first model and then the marginal likelihood using the second model.",
            "It's calculated based factor.",
            "And then repeated it for using the data there simulated from Model 2.",
            "So to make it may be a bit clearer in school, H1 with five dimensions, this simple model and each two 7 dimensions them."
        ],
        [
            "Complex model.",
            "So using Metropolis based sampling an we can see that OK these are log likelihoods, marginal look like as an.",
            "This simple model has a higher value than.",
            "The complex model.",
            "Which suggests that the data came from the simple model, but if we look at the variance.",
            "It."
        ],
        [
            "Basically makes the the results useless because you can't see with any accuracy at all whether it's correct, so this was repeated.",
            "These are the variances were calculated from repeating it the experiment 10 times an.",
            "So some of the experiments favorites looked at individually.",
            "Some of the experiments, favorites and more complex model.",
            "Some favorite.",
            "The simpler model, on average it favorite.",
            "The simple model, but with.",
            "An absolutely massive amount of variance associated with it, and so looking at the base factors, Ann is in favor of the simple model with the simple data.",
            "It is in favor of the complex model with complex data, but not with any.",
            "Constance so.",
            "So the the error bars are.",
            "If you use different data or just you run and so this is using Metropolis based sampling, so we saw from the overhead plot that they ended up in lots of different areas.",
            "It was the same data.",
            "So yes, the same data, yeah?",
            "See.",
            "And so obviously, you're having your variance of estimates is going to be massive."
        ],
        [
            "Compare this population MSMC.",
            "Again, we get 110 which is.",
            "In favor of the simple model.",
            "Using the simple data.",
            "And using the complex data we get massively in favor of the complex model.",
            "So.",
            "One way to interpret this is that using the simple beta, both models are capable of reproducing this type of dynamic.",
            "Anne, but because you're marginalizing over all the parameter values, the complex model.",
            "Anne.",
            "Will have will effectively be penalized for being more complex, even though it can produce the correct response.",
            "And the reason this is so high is perhaps be cause the complex model has produced response which cannot be accurately reproduced by a simple model, and therefore it's massively in favor of it.",
            "The main thing serious that the variance."
        ],
        [
            "Associated with these estimates, an makes it sensible mix confident prediction."
        ],
        [
            "So it may conclusions are that the population MCMC can sample from complex."
        ],
        [
            "There are distributions.",
            "And then the next thing is that old samples from every temperature level can be involved in calculating the marginal likelihood at the end.",
            "So there's unlike simulated tempering, for example, we're only taking the posterior samples.",
            "Do you can use all the all the samples that you generates?",
            "This there's no way for."
        ],
        [
            "So further work I said these aren't.",
            "Very accurate models in terms of describing what's really happening biologically, but they prove that this kind of approach works.",
            "It's a different question whether we can scale it to the number of variables necessary for describing.",
            "Other types of.",
            "Real biological data.",
            "And so that's one thing we're working on scaling up to 2050 parameters.",
            "So the moment we're running this on just one machine, and so we're obviously going to have to look at paralyzing the codes using the cluster.",
            "Anne.",
            "On a.",
            "Quite sure what kind of machine some cluster, but it's it was just a single machine.",
            "We're using it as a 64 bit machine and it's taking about two days to calculate 1 Marshall lightweight.",
            "So to do one run of population MCMC.",
            "Could you click the same number of samples for each, yes.",
            "Yes, so we can.",
            "We can monitor the convergence in a similar way to the way you can monitor just for a single chain.",
            "So you're monitoring the convergence at each temperature and then the sampling.",
            "The posterior samples were collected once all the chains at all the temperatures had converged.",
            "Ann, and then we're going to try and apply some real data an to describe circadian rhythms."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The challenges associated with sampling from multimodal distributions, the likes of which crop up quite often.",
                    "label": 0
                },
                {
                    "sent": "Trying to infer parameters over particularly assilah Terry models an I talked about a population based method of sampling which was able to sample accurately from these multiple distributions, so I'd like to continue today on the same theme introducing another population based method of sampling population Markov chain Monte Carlo.",
                    "label": 0
                },
                {
                    "sent": "So start off by showing firstly that can simulate from these complex.",
                    "label": 0
                },
                {
                    "sent": "Posterior distributions and then I'll show how it can be used together with thermodynamic integration, calculate marginal likelihoods and base factors which can be used for comparing competing model hypothesis.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, first of all, talk by the Celtic biological processes, which will be modeling and then I'll talk about the parameter inference over such models and then finally about model comparison and show some results that we've got comparing two nonlinear facility models.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so many important ilitary systems are poorly understood.",
                    "label": 0
                },
                {
                    "sent": "An even very important ones such as the skating Clock.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so it's important to produce methodology which will allow us to develop and compare models or hypothesis for prescribing these.",
                    "label": 0
                },
                {
                    "sent": "So in the case of Arabidopsis, it's been estimated that more than 5% of the genome is directly or indirectly affected by output pathways from these circadian biochemical networks, and this corresponds to in order to 50,000 different genes.",
                    "label": 1
                },
                {
                    "sent": "So obviously we want to be able to understand the genome as a whole.",
                    "label": 0
                },
                {
                    "sent": "It's vital that we understand this particular starcadian network.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A silvery behavior occurs in other areas as well, so the development of vertebrate embryos as such as S1.",
                    "label": 0
                },
                {
                    "sent": "So here we also see a similar kind of symmetry behavior.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we can reproduce this kind of behavior using time delays on negative feedback loops.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So you're such a model for this one, so it's fairly simple model, just two equations.",
                    "label": 0
                },
                {
                    "sent": "So DN BI DT is the rate of change of M RNA and DP by TI by DT is the rate of change of the protein.",
                    "label": 0
                },
                {
                    "sent": "So you can see there's a time delay when you seem tired and.",
                    "label": 0
                },
                {
                    "sent": "Munamon UPR the degradation rates for the M RNA and protein.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the period of oscillation T is dependent on this to and these two free parameters, so we can see that.",
                    "label": 0
                },
                {
                    "sent": "R. Data with a particular periods we can produce lots of sets of parameters that produce the same facility behavior.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so it's difficult type uniquely identify one single correct set of parameters.",
                    "label": 1
                },
                {
                    "sent": "Of course could use optimization based methods such as simulated annealing to find maybe a global maximum, but there may well be other.",
                    "label": 0
                },
                {
                    "sent": "Equally valid solutions, and so if you use just simulated annealing you would ignore.",
                    "label": 0
                },
                {
                    "sent": "The whole range of dynamics from particular model.",
                    "label": 0
                },
                {
                    "sent": "And so this comes.",
                    "label": 0
                },
                {
                    "sent": "This is where the advanced sampling techniques such as population, Markov chain, Monte Carlo comes in.",
                    "label": 1
                },
                {
                    "sent": "So we want to be able to sample from the whole distribution of likely parameter sets and not just find a single global Max.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so at this point I'm going to introduce a multi dimensional representation of a complex posterior distribution for which we need some 3D glasses.",
                    "label": 0
                },
                {
                    "sent": "I've only got 10 pairs, so you might need to share them about it.",
                    "label": 0
                },
                {
                    "sent": "Handsome.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hopefully this will work.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "This is a typical posterior distribution and so you can clearly see the two parameters that are coupled and producing these concentric circles in the in the posterior.",
                    "label": 0
                },
                {
                    "sent": "OK, upon re previous model and this is from a Goodman model, which is the model of the basic model to describe circadian rhythms.",
                    "label": 0
                },
                {
                    "sent": "Yep, so in a lot of the Sillett remodels you find that there there is coupling between the parameters.",
                    "label": 0
                },
                {
                    "sent": "And yeah, this is displayed very clearly in the in these ridges.",
                    "label": 0
                },
                {
                    "sent": "So the problem is, well can have.",
                    "label": 0
                },
                {
                    "sent": "Is that using a similar type of sampling?",
                    "label": 0
                },
                {
                    "sent": "The sampler might only find the maximum a local maximum, which could be here could be on this Ridge could be on that Ridge and what we want to be able to do is sample across the whole of the distribution.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so this should be familiar from the last talk, and this is sort of minimal model to describe circadian networks and it's called the Goodwin model.",
                    "label": 1
                },
                {
                    "sent": "So it was introduced by Brian Goodwin in the 1960s.",
                    "label": 0
                },
                {
                    "sent": "So this is a very old model and it's a very simple model and so we thought we'd start off with a very simple model to see what kind of difficulties will encounter using population, Markov chain Monte Carlo.",
                    "label": 0
                },
                {
                    "sent": "As this has three equations and just six free parameters in time.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so this is the set of equations for an N variable Goodwin model an so we can we can change North.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So X1 corresponds to the levels of MRNE, X2 corresponds to the levels of protein and.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The rest of the axis corresponds to perhaps other proteins which introduce delays into the system.",
                    "label": 1
                },
                {
                    "sent": "So we have a feedback loop.",
                    "label": 1
                },
                {
                    "sent": "Next feedback loop and the extra equations introduced the delays, so this would be equivalent to the Tao in the Hess one set of equations.",
                    "label": 0
                },
                {
                    "sent": "And with this is perhaps easier to see.",
                    "label": 0
                },
                {
                    "sent": "The relationship to the actual biology that's going on becausw instead of just having a time parameter which we incorporate somehow, we actually have the different equations corresponding to the different proteins, so it's perhaps easier to map it to the real biology.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so this is the same.",
                    "label": 0
                },
                {
                    "sent": "Posterior that we saw from the top.",
                    "label": 0
                },
                {
                    "sent": "So the blue corresponds to regions of low density and the red regions of high density.",
                    "label": 0
                },
                {
                    "sent": "And again you can see the.",
                    "label": 0
                },
                {
                    "sent": "The parents parameters.",
                    "label": 0
                },
                {
                    "sent": "And this is just using.",
                    "label": 0
                },
                {
                    "sent": "Three variable given model, so very basic Goodman model and we're just looking at two of the parameters and fixing the rest of the parameters.",
                    "label": 0
                },
                {
                    "sent": "And so for this I used them just the standard metropolis based sampling.",
                    "label": 0
                },
                {
                    "sent": "Running 20 chains independently.",
                    "label": 0
                },
                {
                    "sent": "With a sampling their starting positions from prior which we defined.",
                    "label": 0
                },
                {
                    "sent": "And so the axes correspond to their starting positions, and then you can follow their paths to the.",
                    "label": 0
                },
                {
                    "sent": "2/3 circles, which is their end position.",
                    "label": 0
                },
                {
                    "sent": "So we can see if an X starts somewhere near the global maximum refine.",
                    "label": 0
                },
                {
                    "sent": "It follows the route to the top of the Hill.",
                    "label": 0
                },
                {
                    "sent": "If however, they start somewhere.",
                    "label": 0
                },
                {
                    "sent": "Else in the parameter space we tend to follow the.",
                    "label": 0
                },
                {
                    "sent": "The ridges and if they start way off then go off and wander about somewhere else in the parameter space.",
                    "label": 0
                },
                {
                    "sent": "An yes, we can see that the chains don't converge an they also in different places in your finishing mostly different places.",
                    "label": 0
                },
                {
                    "sent": "And this depends a bit on the parameter setting would be in CMC, yes, so so we adopted an adaptive step size in order to try and adapt the local steps to the local topology.",
                    "label": 0
                },
                {
                    "sent": "What kind of acceptance rate.",
                    "label": 0
                },
                {
                    "sent": "OK, so we looked for an exception shape between 20 and 50% and then if it was more than that then would increase the step size to make it less likely that step was accepted.",
                    "label": 0
                },
                {
                    "sent": "So this is very good book Bayesian data analysis that incorporates that includes all the engineering techniques that you can use an to try and get this working, but even including even using some of these techniques, we still run into serious problems.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so that was their motivation.",
                    "label": 0
                },
                {
                    "sent": "That's why we need a more advanced sampling technique.",
                    "label": 0
                },
                {
                    "sent": "So the one chosen to use this population, Markov chain Monte Carlo.",
                    "label": 1
                },
                {
                    "sent": "So as the name suggests, instead of using a single independent Markov chain, we use a population of chains, and these can communicate with each other, the idea being that one chain finds a region of higher density than another.",
                    "label": 0
                },
                {
                    "sent": "They can move towards the region of high density, and the second idea is to use temperature schedule.",
                    "label": 0
                },
                {
                    "sent": "So instead of all the chains exploring just one posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "We have different chains exploring different distributions.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In parallel.",
                    "label": 0
                },
                {
                    "sent": "Let's take the temporary things.",
                    "label": 0
                },
                {
                    "sent": "Yes, yeah, exactly.",
                    "label": 0
                },
                {
                    "sent": "And so we're sampling from a product of distributions which are indexed by this temperature parameter.",
                    "label": 1
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "So normally the temperature parameter is between zero and one with T = 1 being equivalent to the actual target distribution, and T = 0 being equivalent to an easy to sample from.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Distribution, such as a prior.",
                    "label": 0
                },
                {
                    "sent": "So I'm so we could also write this as posterior being the prior times likelihood raised to this temperature, so when the temperature is 1, obviously it's just the prior times likelihood when the temperature is 0 is just prior, and then we have a range of intermediate temperatures.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "I haven't got a picture of this, but if you visualize the intermediate steps you'll see the shape of it changing from a nice flat goes in, for example, and you'll see ridges appearing gradually, so that's a higher temperatures for T closer to zero.",
                    "label": 0
                },
                {
                    "sent": "It's easier for the chains to explore the whole of the space.",
                    "label": 0
                },
                {
                    "sent": "And then at higher temperature, if a chain gets stuck in a local maximum, it can jump down, temperatures move across, and perhaps find another maximum later.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yes, this is the basic algorithm.",
                    "label": 0
                },
                {
                    "sent": "First of all, with the final temperature schedule.",
                    "label": 0
                },
                {
                    "sent": "And then we assign starting positions for the chains at each temperature, so.",
                    "label": 1
                },
                {
                    "sent": "And in our case we just sampled these from the prior and then for each iteration and each chain we first of all move them either according to Metropolis Step or a crossover operator.",
                    "label": 0
                },
                {
                    "sent": "So the metropolis step is just like a metropolis algorithm.",
                    "label": 0
                },
                {
                    "sent": "It just makes a local set.",
                    "label": 0
                },
                {
                    "sent": "The crossover operator chooses two different chains and swaps over parts of the position vectors.",
                    "label": 0
                },
                {
                    "sent": "So the idea being two chains in different positions and you swap over.",
                    "label": 0
                },
                {
                    "sent": "Mutates their position.",
                    "label": 0
                },
                {
                    "sent": "Vectors look potentially finds new areas of the parameter space to search.",
                    "label": 0
                },
                {
                    "sent": "And so you can set different probabilities that either one or the other will be selected during each iteration.",
                    "label": 0
                },
                {
                    "sent": "So I think this suggested in the Yang one paper that it should be about 70% and 50%.",
                    "label": 0
                },
                {
                    "sent": "So you want me more local steps than more global steps, because a lot of the global steps won't be accepted just because the lens up in in areas which aren't useful.",
                    "label": 0
                },
                {
                    "sent": "Amend the last point is just to exchange between temperatures, so you'll find at Lord higher temperatures, so that equals to zero.",
                    "label": 0
                },
                {
                    "sent": "The chains will move by a lot, and when they hit upon an area that is, which is the high density further up the temperature ladder, you'll see the chains jumping up up the temperature later.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So this improves the mixing of the chains, so as opposed having 20 chains which are all independent and moving slowly about, you get this much more much richer dynamics between between the chips.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So again, here's our posterior from above.",
                    "label": 0
                },
                {
                    "sent": "To only collect samples from the culture.",
                    "label": 0
                },
                {
                    "sent": "We collect them from all the chains, OK?",
                    "label": 0
                },
                {
                    "sent": "If you're wanting to just infer the parameters, then it's T equals one that you're interested in is the top temperature you're interested in.",
                    "label": 0
                },
                {
                    "sent": "But for thermodynamic integration, which will come to later, we use samples from every chain from every temperature, so there's no waste in the algorithm.",
                    "label": 0
                },
                {
                    "sent": "So the 1st.",
                    "label": 0
                },
                {
                    "sent": "Shows an.",
                    "label": 0
                },
                {
                    "sent": "T = 0 So you can see that there's a lot of movement of the chain about the parameter space, and as we move up the temperature ladder, T = .5.",
                    "label": 0
                },
                {
                    "sent": "Slightly less, you can see it a lot of samples are taken from this black blob in the global optimum, but it still explores a bit of the rest of the parameter space, and at the very top.",
                    "label": 0
                },
                {
                    "sent": "Temperature the chain quickly focuses in on the absolute maximum.",
                    "label": 0
                },
                {
                    "sent": "So you can see it's a lot more successful than the Metropolis approach which had chains finishing up all over the place.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's an example in firing all five parameters an.",
                    "label": 0
                },
                {
                    "sent": "So firstly, metropolis sampling.",
                    "label": 0
                },
                {
                    "sent": "We have the true parameters at the top which we just picked random Ann and as you can see the results are way off.",
                    "label": 0
                },
                {
                    "sent": "So again, this is just from one of the chains, because obviously the chains haven't converged, so you can look at any of the chains and none of them.",
                    "label": 0
                },
                {
                    "sent": "Well, maybe I think 220 hit the correct values an with the other 18 ending up in another local maximum.",
                    "label": 0
                },
                {
                    "sent": "Using population MSMC.",
                    "label": 0
                },
                {
                    "sent": "You can see a couple of problems.",
                    "label": 0
                },
                {
                    "sent": "For example, this one is quite spread across between 0 and 1.5, but the peak.",
                    "label": 0
                },
                {
                    "sent": "Pretty much it's the.",
                    "label": 0
                },
                {
                    "sent": "It's the true parameters.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so now I'm going to show how the following on from your question how we can use the samples at every temperature.",
                    "label": 0
                },
                {
                    "sent": "It's calculating marginal likely.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's using thermodynamic integration.",
                    "label": 0
                },
                {
                    "sent": "So a good way to discriminate between competing model hypothesis is to use based factors.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So these two are is.",
                    "label": 0
                },
                {
                    "sent": "They take into account all the possible parameter values, so we're marginalizing over all of the parameter values and not just focusing on the maximum and so given two models H1H2, we want to calculate the likelihoods of experimental data given the model.",
                    "label": 1
                },
                {
                    "sent": "So this is the marginal likelihoods and.",
                    "label": 0
                },
                {
                    "sent": "The base factor, which is the support for model one over Model 2, is just given by this ratio.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Answer this can be calculated by integrating over the parameters.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Ace OK, so the last workshop down in Sheffields and lab Vision Medscape this is talk on different ways of calculating the marginal likelihood and it shows that the variance of the marginal likelihoods and calculated using thermodynamic integration was about one of the best ways of calculating it, and so we're just going to ignore the other ways of calculating it for it to snow and focus on thermodynamic integration.",
                    "label": 0
                },
                {
                    "sent": "OK, so we can calculate the log of the marginal likelihoods using this expression.",
                    "label": 1
                },
                {
                    "sent": "Where the expectation is taken with respect.",
                    "label": 1
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The power posterior which is I said before this geometric path between T = 0 = 1.",
                    "label": 1
                },
                {
                    "sent": "So between the prior and posterior.",
                    "label": 0
                },
                {
                    "sent": "Where the likelihood is distressed, this part T for particular schedule of T going between zero and one.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so obviously this is.",
                    "label": 0
                },
                {
                    "sent": "This is intractable.",
                    "label": 0
                },
                {
                    "sent": "We can calculate this directly, so we can.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Approximate it.",
                    "label": 0
                },
                {
                    "sent": "By discretizing then scroll.",
                    "label": 0
                },
                {
                    "sent": "So we want some kind of discretization between.",
                    "label": 0
                },
                {
                    "sent": "T0 equal to the equal to 0 and TN equal to 1 and then taking samples from each of the.",
                    "label": 0
                },
                {
                    "sent": "Each of these power posteriors we can calculate this numerically, and of course these power posteriors are just the samples we take using population MCMC.",
                    "label": 0
                },
                {
                    "sent": "An so once we've run hope MCMC, we can take the samples from each temperature level and just put them into this equation to calculate the log likelihood.",
                    "label": 0
                },
                {
                    "sent": "Curious, is there any tension between the scheduler optimizes this best and the best schedule for the populations there is?",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So dominant main gives an expression for the optimal density.",
                    "label": 1
                },
                {
                    "sent": "And in terms of minimizing the variance of the resulting estimates, and that's given by this nice expression here.",
                    "label": 1
                },
                {
                    "sent": "Which.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is actually analytic for a linear model, so we can if we ignore the bottom part.",
                    "label": 1
                },
                {
                    "sent": "We can get an analytic expression for a linear regression model.",
                    "label": 1
                },
                {
                    "sent": "For the top part.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so if we calculate that.",
                    "label": 0
                },
                {
                    "sent": "We got against function which has all its density between 0.1.",
                    "label": 0
                },
                {
                    "sent": "And if we look at if we plot the power posteriors 40 grand between 0.1, we can see that the shape of it changes drastically between 0.1.",
                    "label": 0
                },
                {
                    "sent": "An and so thinking about population MCMC?",
                    "label": 0
                },
                {
                    "sent": "We want to have small changes between the different levels to make it more likely that change will be able to exchange between the temperatures, so this fits in nicely with the pop MCMC.",
                    "label": 0
                },
                {
                    "sent": "So if we choose our temperature schedule with the points.",
                    "label": 0
                },
                {
                    "sent": "Clustered towards this region.",
                    "label": 0
                },
                {
                    "sent": "And not only can we get better estimates optimized mix for the marginal likelihood, but also makes the pop MCMC algorithm more efficient because during the temperature exchanges it comes more likely the exchanges occur and improves mixing.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right, so we did a little experiment using 2 Goodman models an with five and seven dimensions respectively.",
                    "label": 0
                },
                {
                    "sent": "So obviously these models aren't state of the art.",
                    "label": 0
                },
                {
                    "sent": "The very basic and we're using them just to show that this methodology.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This work?",
                    "label": 0
                },
                {
                    "sent": "So we create some simulated data from.",
                    "label": 1
                },
                {
                    "sent": "Firstly H1 and Secondly H2 and for each of the chemical species.",
                    "label": 1
                },
                {
                    "sent": "So for each of the.",
                    "label": 0
                },
                {
                    "sent": "Equations that we have an.",
                    "label": 1
                },
                {
                    "sent": "We take one measurements at each of 80 time points, which is about similar to the type of real data we might have, and we had some Gaussian noise to.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then we used population MSMC and thermodynamic integration.",
                    "label": 1
                },
                {
                    "sent": "To try and see if we can detect which model the original data came from.",
                    "label": 0
                },
                {
                    "sent": "So firstly using the data from each one.",
                    "label": 1
                },
                {
                    "sent": "We calculate marginal likelihoods using the first model and then the marginal likelihood using the second model.",
                    "label": 0
                },
                {
                    "sent": "It's calculated based factor.",
                    "label": 0
                },
                {
                    "sent": "And then repeated it for using the data there simulated from Model 2.",
                    "label": 0
                },
                {
                    "sent": "So to make it may be a bit clearer in school, H1 with five dimensions, this simple model and each two 7 dimensions them.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Complex model.",
                    "label": 0
                },
                {
                    "sent": "So using Metropolis based sampling an we can see that OK these are log likelihoods, marginal look like as an.",
                    "label": 0
                },
                {
                    "sent": "This simple model has a higher value than.",
                    "label": 0
                },
                {
                    "sent": "The complex model.",
                    "label": 0
                },
                {
                    "sent": "Which suggests that the data came from the simple model, but if we look at the variance.",
                    "label": 0
                },
                {
                    "sent": "It.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Basically makes the the results useless because you can't see with any accuracy at all whether it's correct, so this was repeated.",
                    "label": 0
                },
                {
                    "sent": "These are the variances were calculated from repeating it the experiment 10 times an.",
                    "label": 0
                },
                {
                    "sent": "So some of the experiments favorites looked at individually.",
                    "label": 0
                },
                {
                    "sent": "Some of the experiments, favorites and more complex model.",
                    "label": 0
                },
                {
                    "sent": "Some favorite.",
                    "label": 0
                },
                {
                    "sent": "The simpler model, on average it favorite.",
                    "label": 0
                },
                {
                    "sent": "The simple model, but with.",
                    "label": 0
                },
                {
                    "sent": "An absolutely massive amount of variance associated with it, and so looking at the base factors, Ann is in favor of the simple model with the simple data.",
                    "label": 0
                },
                {
                    "sent": "It is in favor of the complex model with complex data, but not with any.",
                    "label": 0
                },
                {
                    "sent": "Constance so.",
                    "label": 0
                },
                {
                    "sent": "So the the error bars are.",
                    "label": 0
                },
                {
                    "sent": "If you use different data or just you run and so this is using Metropolis based sampling, so we saw from the overhead plot that they ended up in lots of different areas.",
                    "label": 0
                },
                {
                    "sent": "It was the same data.",
                    "label": 0
                },
                {
                    "sent": "So yes, the same data, yeah?",
                    "label": 0
                },
                {
                    "sent": "See.",
                    "label": 0
                },
                {
                    "sent": "And so obviously, you're having your variance of estimates is going to be massive.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Compare this population MSMC.",
                    "label": 0
                },
                {
                    "sent": "Again, we get 110 which is.",
                    "label": 0
                },
                {
                    "sent": "In favor of the simple model.",
                    "label": 1
                },
                {
                    "sent": "Using the simple data.",
                    "label": 0
                },
                {
                    "sent": "And using the complex data we get massively in favor of the complex model.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "One way to interpret this is that using the simple beta, both models are capable of reproducing this type of dynamic.",
                    "label": 0
                },
                {
                    "sent": "Anne, but because you're marginalizing over all the parameter values, the complex model.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "Will have will effectively be penalized for being more complex, even though it can produce the correct response.",
                    "label": 0
                },
                {
                    "sent": "And the reason this is so high is perhaps be cause the complex model has produced response which cannot be accurately reproduced by a simple model, and therefore it's massively in favor of it.",
                    "label": 0
                },
                {
                    "sent": "The main thing serious that the variance.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Associated with these estimates, an makes it sensible mix confident prediction.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So it may conclusions are that the population MCMC can sample from complex.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There are distributions.",
                    "label": 0
                },
                {
                    "sent": "And then the next thing is that old samples from every temperature level can be involved in calculating the marginal likelihood at the end.",
                    "label": 1
                },
                {
                    "sent": "So there's unlike simulated tempering, for example, we're only taking the posterior samples.",
                    "label": 0
                },
                {
                    "sent": "Do you can use all the all the samples that you generates?",
                    "label": 0
                },
                {
                    "sent": "This there's no way for.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So further work I said these aren't.",
                    "label": 1
                },
                {
                    "sent": "Very accurate models in terms of describing what's really happening biologically, but they prove that this kind of approach works.",
                    "label": 0
                },
                {
                    "sent": "It's a different question whether we can scale it to the number of variables necessary for describing.",
                    "label": 0
                },
                {
                    "sent": "Other types of.",
                    "label": 0
                },
                {
                    "sent": "Real biological data.",
                    "label": 1
                },
                {
                    "sent": "And so that's one thing we're working on scaling up to 2050 parameters.",
                    "label": 0
                },
                {
                    "sent": "So the moment we're running this on just one machine, and so we're obviously going to have to look at paralyzing the codes using the cluster.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "On a.",
                    "label": 0
                },
                {
                    "sent": "Quite sure what kind of machine some cluster, but it's it was just a single machine.",
                    "label": 0
                },
                {
                    "sent": "We're using it as a 64 bit machine and it's taking about two days to calculate 1 Marshall lightweight.",
                    "label": 0
                },
                {
                    "sent": "So to do one run of population MCMC.",
                    "label": 0
                },
                {
                    "sent": "Could you click the same number of samples for each, yes.",
                    "label": 0
                },
                {
                    "sent": "Yes, so we can.",
                    "label": 0
                },
                {
                    "sent": "We can monitor the convergence in a similar way to the way you can monitor just for a single chain.",
                    "label": 0
                },
                {
                    "sent": "So you're monitoring the convergence at each temperature and then the sampling.",
                    "label": 0
                },
                {
                    "sent": "The posterior samples were collected once all the chains at all the temperatures had converged.",
                    "label": 0
                },
                {
                    "sent": "Ann, and then we're going to try and apply some real data an to describe circadian rhythms.",
                    "label": 1
                }
            ]
        }
    }
}