{
    "id": "n4ilnlpcvphqj5t7o3qnm5kscuafm2xl",
    "title": "Convexity Shape Prior for Segmentation",
    "info": {
        "author": [
            "Lena Gorelick, Department of Computer Science, University of Western Ontario"
        ],
        "published": "Oct. 29, 2014",
        "recorded": "September 2014",
        "category": [
            "Top->Computer Science->Computer Vision"
        ]
    },
    "url": "http://videolectures.net/eccv2014_gorelick_shape_prior/",
    "segmentation": [
        [
            "Hi good afternoon everyone."
        ],
        [
            "I will begin my talk with the most simple example of binary segmentation energy in binary segmentation.",
            "Rysiek foreground to background segments like this.",
            "Let's denote the corresponding indicator binary variables by X.",
            "The segmentation program is formulated as energy minimization and the energy has two times.",
            "The first term is unary term, where each pixel has a preference of PETA belong either to foreground auto background.",
            "The here negative values are shown in blue color and they correspond to preference to the foreground.",
            "The second term is a smoothness term and the assumption is the segment boundaries are smooth and this term penalizes the number of discontinuity's in labels between neighboring pixels.",
            "This term is also commonly known as length realization or Potts model, and this is how there is a look like.",
            "It puts modeling situation is quite common in computer vision.",
            "Many applications, in part because it is submodular.",
            "That means that global optimum can be efficiently computed with for example, graph."
        ],
        [
            "However, Lexicalization has few shortcomings.",
            "Consider the following input image an user scribbles if we use we cleanse organization, you obtain another site like this one.",
            "But if you use a stronger lexicalization, there is a shrinking bias and one of the main problems with lens organization is that it's very sensitive to the weight of the organization."
        ],
        [
            "Those problems of length organization motivated and active research for optimization of alternative regularization terms, and here are a few examples.",
            "Curvature penalizes convective season four cavities on segments control.",
            "Connectivity prior assumes object has one connected component.",
            "Can Starship Reassumes object has a star shape with respect to a given center and publish a prior models objects collection of parts and enforces orientation constraints between the parts?"
        ],
        [
            "Convexity Shaper is another interesting shape writer that has been largely overlooked in the past.",
            "We propose a convexity shape prior as higher order organization term.",
            "Convexity is important.",
            "The queue in human vision and many natural objects have a context.",
            "Almost convex objects.",
            "Convex objects are also common in medical images, and here are a few examples.",
            "Any join a liver chambers of the heart."
        ],
        [
            "In the most related work to ours is the method by Sokolowski and criminals in the context of continuous optimization, they model convex objects by inside convex polygons.",
            "They use one part for the foreground and parts for the background, and it's a good approximation model for convex shapes if."
        ],
        [
            "Shapes are small like this circle, because this circle can approximate it well by 8 sided convex Polygon."
        ],
        [
            "But to awkwardly segment arbitrary large convex shapes, they need more background parts, which corresponds to finer discretization of orientation and becomes expensive to optimize."
        ],
        [
            "In contrast to them, we can obtain an arbitrary convex object even for the coarsest discretization of presentation.",
            "In addition, our method is descript, so it's sufficient to optimize even without GPU."
        ],
        [
            "Our overall segmentation energy combines the convexity shape prior with any submodular energy term which can account for appearance, user defined hard constraints, color separation terms, or even length."
        ],
        [
            "So let's see how we define the convexity term.",
            "Consider the following synthetic object.",
            "This object is obviously not convex because you can find pairs of points P&R such that on the line between them there is a point Q that doesn't belong to the object.",
            "These correspond to the following configuration of labels.",
            "So 101 we can enforce convexity by using a triple click potential file that will assign this configuration an infinite cost.",
            "But we need to consider all triplets of all points along all lines."
        ],
        [
            "In all orientation."
        ],
        [
            "In practice, we use a finite penalty Omega, and we write the convex determines follows with some overall lines in orientation.",
            "We go over all triples of points along the lines and count the number of triple petitions that have these configuration.",
            "So all term directly follows from definition of convex shapes."
        ],
        [
            "So this is our convex shape prior and there's similar straight triple clicks were used in squared curvature organization proposed by noise at all in Super 14 they use both 101 configurations and 010 configurations to account for concavities and convexities on the segments control.",
            "But to valid curvature they only need to consider local triple clicks and that results in linear number of triple clicks.",
            "In contrast, convexity is not a local property of the shape control, it is a global property of the entire shape.",
            "And we need to consider triple clicks on straight intervals A of all sizes, so that results in a much larger number of republics.",
            "We have order N squared properties where N is the number of pixels."
        ],
        [
            "So what are the properties of our convexity term?",
            "The first question that arises whether it's a modular or not, so we can use the original definition by Edmonds from 1970s, and it says that energy submodular if for any two segments SMT.",
            "The following inequality halts.",
            "So let's consider one particular example of those two circles, eh?",
            "Let's look at this inequality.",
            "It both SMT a convex segments.",
            "Therefore this term is 0 intersection of convex shapes is always convex.",
            "Therefore this term is also zero.",
            "But the Union of Convex shape is not necessarily convex like in this example.",
            "There for this term is infinite.",
            "Therefore the inequality does not hold.",
            "An hour term is not submodular, which means bad news for optimization.",
            "It's difficult to optimize.",
            "The second difficulty is.",
            "In optimizing, this term arises from the large number of triple click potentials.",
            "Even a valuation of the energy is expensive.",
            "It takes order N squared to compute the energy."
        ],
        [
            "How do we optimize our term?",
            "We use trust region framework.",
            "Translation framework is quite common.",
            "A method in continuous optimization field and it's recently has been successfully used in the context of discrete high order energies and binary pairwise energies.",
            "A direct application of translation will be too expensive because we have so many triple clicks we propose to use dynamic programming to speed up the energy variation.",
            "An approximation in each iteration of trust region."
        ],
        [
            "Now let me briefly overview the Trust region framework, so it's iterative optimization framework.",
            "The goal is to optimize the energy, and this is a schematic illustration.",
            "Consider XT is a current solution.",
            "In each iteration the energy is approximated by tractable model ET around the current solution.",
            "In"
        ],
        [
            "Our approximation."
        ],
        [
            "It keeps the submodular part of energy untouched because we can optimize it easily but linearizes the convexity term.",
            "So overall our approximation is a model function.",
            "If we were to optimize globally our approximation, we would make something that is very similar to Newton Step and Newton step might result in a very large step to a point where approximation has nothing to do with the original function.",
            "Instead."
        ],
        [
            "Trust region.",
            "The approximation is only trusted locally within the vicinity of current solution, and this region is called Trust region.",
            "Then the approximation is optimized within a trust region subject to distance constraints from the current solution.",
            "This step is usually called a trust region subproblem.",
            "Once the candidate solution is obtained, the whole process is repeated again and again and the trust region sizes adaptively adjusted from iteration to iteration based on the quality of current approximation.",
            "So although approximation model is submodular, optimizing it's subject to distance constraint is unfortunately NP hard, so we need to look for an alternative to control the trust region size, not the not the constraints.",
            "For that we."
        ],
        [
            "As a following unconstrained Lagrangian formulation, it has the same submodular part.",
            "The regulation of the convexity part.",
            "And it has the grunge multiplier Lambda T which penalizes the distance from the current solution.",
            "Lambda T is fixed in each iteration and it is inversely proportionate to the trust region size and we can adjust Lambda TA from iteration to iteration based on the quality of the approximation following the principles of trust region.",
            "The distance here can be formulated as unary terms, so overall our Lagrangian formulation is a submodular function and now we can optimize it globally and efficiently with one graph cut."
        ],
        [
            "So I explained about trust region.",
            "Now one more difficulty.",
            "Trust region requires evaluation, an approximation of the convex determine each iteration.",
            "Naive computation takes order N squared.",
            "We use dynamic programming to speed up the computation to linear time due to the lack of time.",
            "I will only explain how to value the energy using dynamic programming.",
            "The approximation is done in a very similar way and the details can be found."
        ],
        [
            "Paper.",
            "So recall that to evaluate our convex detail, we need to count the number of triple clicks that violate the convexity.",
            "That is, they have the configuration 101.",
            "So let's see how to do that for one line."
        ],
        [
            "Those are the pixels on the line with their chorus."
        ],
        [
            "Funding labels, ones and zeros.",
            "Note that each violating Republic potential has zero in the middle, so let's look at these zero picture.",
            "How many triple click potential does it participate in?",
            "That Virat convexity?",
            "It has two object pixels to the left of it and five objective pixels to the right of it.",
            "So overall it participates in 10 triple clicks at valid convexity.",
            "We can quickly compute it by counting the number of object pixels to the left of each pixel and to the right of each pixel using running sums.",
            "Now we can look at the zero pixels on the line and take the product of those counts.",
            "So we have 10 for this zero pixel and we have 12 for the zero pixels.",
            "So overall there are 22 zero 22.",
            "Triple click potentials that they violate the convexity and we were able to compute it in linear time scanning the line so."
        ],
        [
            "Similarly, it's possible to show that it takes order MN operations to scan all lies in orientations, where N is the number of pixels in the image and M is the number of orientations."
        ],
        [
            "So now let me show some experiments and results.",
            "We use convexity shape prior within the framework of interactive image segmentation.",
            "Consider the following input image and user scribbles.",
            "If you don't use any organization, this is the kind of result you would get.",
            "You might hope to fix it with length organization, so let's try different way, toppling situation.",
            "This is the X axis and see how close we get to the ground truth.",
            "This is the Y axis."
        ],
        [
            "And this is the plot for length organization.",
            "And let's look at some key points on that plot.",
            "A point A has very low regularizer weight and as expected it will result in a very noisy segmentation.",
            "A point B has a slightly larger regularizer weight and the result is a bit less noisy, but still a under segmented Point C has a slightly higher weight, but there is a shrinking.",
            "So now let's do the same experiment with the convexity shape prior."
        ],
        [
            "And this is a plot for convex regularization.",
            "As you can see, it's very robust with respect to the regularizer parameter.",
            "And those are few key points from that plot an, so they are visually indistinguishable.",
            "That's why we say that our method is virtually parameter free."
        ],
        [
            "So here a few more examples on natural images.",
            "For some images both legs, organization and convex regularization a obtained good results for wide range of values for the regularizer.",
            "Wait, but for many other images with links organization there is a transition between under segmenting and over segmenting, which happens for very close valves of the regularizer wait?",
            "In contrast, with convexity, the results are very robust, so here a few more examples that exhibit the same pattern of behavior with very sensitive and very robust convex regularization."
        ],
        [
            "You know few examples are on medical images.",
            "You can see that applying convex shape for medical images is able to remove the noise filling the holes in force connectivity and convexity without compromising.",
            "In the corners, the running times can be seen on the right."
        ],
        [
            "In in theory, our convex system can be optimized with standard optimization methods such as QBO, anti RWS.",
            "Those methods were specifically designed for optimization of non submodular energies.",
            "In practice however, our term proved to be prohibitively expensive because we need to enumerate all the quadratic number of triple clicks to fit into those those methods.",
            "Nonetheless, we were able to come up with a more compact model which has less clicks.",
            "Order of N sqrt N clicks.",
            "A surprisingly, this compact model model is slower to optimize than the full model because dynamic programming no longer applies.",
            "Nonetheless, we can use the slower version of our method without dynamic programming and compare it to the capable interest.",
            "TRW SA for very tiny synthetic image."
        ],
        [
            "So here are the results.",
            "For very low value of collectivization, wait all three methods obtain globally optimal but otherwise useless solution.",
            "Because this value of weight does not enforce any convexity for high value of the convex realization rate a both could be beyond until WS failed to obtain satisfactory solutions.",
            "Great color denotes unlabeled pixels with capable and here are the results obtained for values in between.",
            "In all the cases, our method was able to obtain satisfactory solutions.",
            "In there.",
            "A short time."
        ],
        [
            "So some limitations of our method, trust, region, framework is a local iterative optimization that we cannot guarantee global minimum.",
            "Of course, there might be some sensitivity to initialization.",
            "Consider the following synthetic examples.",
            "If we initialize a optimization retrieval solutions where all pixels belong to the foreground depicted here with red, the contour will get to this inferior solution, but.",
            "If, in contrast we initialize with maximum likelihood label purposes, which basically all the black pieces in the foreground, then we get to the global minimum.",
            "So here's some sensitivity to initialization."
        ],
        [
            "And let me summarize a. I've introduced the novel convex shape drivers in the framework of discrete optimization.",
            "Our prior has no shrinking bias.",
            "It is able to remove noise and filling the holes.",
            "It ensures connectivity and convexity while preserving sharp corners.",
            "Our model is get invited you to Infinity constraints an.",
            "But in practice, when we use finite penalty, it is virtually parameter free.",
            "I propose efficient optimization based on trust region and dynamic programming."
        ],
        [
            "In the code is available online.",
            "Please feel free to download and use it and please come by our poster tomorrow to ask questions if you have any.",
            "Facebook.",
            "Questions in your trust region method you seem to compute gradients as well and you have integer variables.",
            "So how do you compute these gradients?",
            "Well, it's not exactly gradient, it's an approximation, so we can compute the linear approximation that agrees with current increases with the current solution with original energy, and it also agrees with original energy.",
            "An N plus one variables AN plus one configurations.",
            "So it's a linear approximation.",
            "It's very close to the original function, but it's not a gradient.",
            "And in the paper we we motivate better while we use our linear approximation.",
            "I think there was one question.",
            "Can you can you tell?",
            "If a convex shape prior really was a good prior for the for the shape based on the energies or the robustness or something.",
            "So if it's really a non convex shape.",
            "If you don't want to get a convex shape as a result, then you shouldn't use this prior.",
            "This prior is for convex shapes.",
            "If it can help, you may be too quickly finding candidate solution and then refine it with other methods, but it's mostly should be useful for convex shape.",
            "In when you were comparing your method to QBO and TWS in your results in the regularization weight, in this case played the played an important role so you get non convex shapes or common shapes.",
            "But in your real world results it was insensitive to.",
            "So can you explain a bit why this difference?",
            "Yes so it is virtually parameter free once you.",
            "You get high enough penalty to enforce convexity before you if you don't enforce convex.",
            "If your regularizer weight is very weak, you will not enforce the context and you cannot enforce the convexity of different levels, But once you hit the point where the conversi has to be enforced because the plant is too high, then there is no no change in the solutions, so synthetic examples are usually more difficult than natural images example because the data terms and natural images are very good.",
            "Does it answer question OK, Thanks.",
            "OK, I think we move on, so thanks again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi good afternoon everyone.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I will begin my talk with the most simple example of binary segmentation energy in binary segmentation.",
                    "label": 0
                },
                {
                    "sent": "Rysiek foreground to background segments like this.",
                    "label": 0
                },
                {
                    "sent": "Let's denote the corresponding indicator binary variables by X.",
                    "label": 0
                },
                {
                    "sent": "The segmentation program is formulated as energy minimization and the energy has two times.",
                    "label": 0
                },
                {
                    "sent": "The first term is unary term, where each pixel has a preference of PETA belong either to foreground auto background.",
                    "label": 0
                },
                {
                    "sent": "The here negative values are shown in blue color and they correspond to preference to the foreground.",
                    "label": 0
                },
                {
                    "sent": "The second term is a smoothness term and the assumption is the segment boundaries are smooth and this term penalizes the number of discontinuity's in labels between neighboring pixels.",
                    "label": 0
                },
                {
                    "sent": "This term is also commonly known as length realization or Potts model, and this is how there is a look like.",
                    "label": 1
                },
                {
                    "sent": "It puts modeling situation is quite common in computer vision.",
                    "label": 0
                },
                {
                    "sent": "Many applications, in part because it is submodular.",
                    "label": 0
                },
                {
                    "sent": "That means that global optimum can be efficiently computed with for example, graph.",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "However, Lexicalization has few shortcomings.",
                    "label": 0
                },
                {
                    "sent": "Consider the following input image an user scribbles if we use we cleanse organization, you obtain another site like this one.",
                    "label": 1
                },
                {
                    "sent": "But if you use a stronger lexicalization, there is a shrinking bias and one of the main problems with lens organization is that it's very sensitive to the weight of the organization.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Those problems of length organization motivated and active research for optimization of alternative regularization terms, and here are a few examples.",
                    "label": 0
                },
                {
                    "sent": "Curvature penalizes convective season four cavities on segments control.",
                    "label": 0
                },
                {
                    "sent": "Connectivity prior assumes object has one connected component.",
                    "label": 0
                },
                {
                    "sent": "Can Starship Reassumes object has a star shape with respect to a given center and publish a prior models objects collection of parts and enforces orientation constraints between the parts?",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Convexity Shaper is another interesting shape writer that has been largely overlooked in the past.",
                    "label": 0
                },
                {
                    "sent": "We propose a convexity shape prior as higher order organization term.",
                    "label": 0
                },
                {
                    "sent": "Convexity is important.",
                    "label": 0
                },
                {
                    "sent": "The queue in human vision and many natural objects have a context.",
                    "label": 0
                },
                {
                    "sent": "Almost convex objects.",
                    "label": 0
                },
                {
                    "sent": "Convex objects are also common in medical images, and here are a few examples.",
                    "label": 0
                },
                {
                    "sent": "Any join a liver chambers of the heart.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the most related work to ours is the method by Sokolowski and criminals in the context of continuous optimization, they model convex objects by inside convex polygons.",
                    "label": 0
                },
                {
                    "sent": "They use one part for the foreground and parts for the background, and it's a good approximation model for convex shapes if.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Shapes are small like this circle, because this circle can approximate it well by 8 sided convex Polygon.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But to awkwardly segment arbitrary large convex shapes, they need more background parts, which corresponds to finer discretization of orientation and becomes expensive to optimize.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In contrast to them, we can obtain an arbitrary convex object even for the coarsest discretization of presentation.",
                    "label": 0
                },
                {
                    "sent": "In addition, our method is descript, so it's sufficient to optimize even without GPU.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Our overall segmentation energy combines the convexity shape prior with any submodular energy term which can account for appearance, user defined hard constraints, color separation terms, or even length.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's see how we define the convexity term.",
                    "label": 0
                },
                {
                    "sent": "Consider the following synthetic object.",
                    "label": 0
                },
                {
                    "sent": "This object is obviously not convex because you can find pairs of points P&R such that on the line between them there is a point Q that doesn't belong to the object.",
                    "label": 0
                },
                {
                    "sent": "These correspond to the following configuration of labels.",
                    "label": 0
                },
                {
                    "sent": "So 101 we can enforce convexity by using a triple click potential file that will assign this configuration an infinite cost.",
                    "label": 0
                },
                {
                    "sent": "But we need to consider all triplets of all points along all lines.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In all orientation.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In practice, we use a finite penalty Omega, and we write the convex determines follows with some overall lines in orientation.",
                    "label": 0
                },
                {
                    "sent": "We go over all triples of points along the lines and count the number of triple petitions that have these configuration.",
                    "label": 0
                },
                {
                    "sent": "So all term directly follows from definition of convex shapes.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is our convex shape prior and there's similar straight triple clicks were used in squared curvature organization proposed by noise at all in Super 14 they use both 101 configurations and 010 configurations to account for concavities and convexities on the segments control.",
                    "label": 0
                },
                {
                    "sent": "But to valid curvature they only need to consider local triple clicks and that results in linear number of triple clicks.",
                    "label": 0
                },
                {
                    "sent": "In contrast, convexity is not a local property of the shape control, it is a global property of the entire shape.",
                    "label": 0
                },
                {
                    "sent": "And we need to consider triple clicks on straight intervals A of all sizes, so that results in a much larger number of republics.",
                    "label": 0
                },
                {
                    "sent": "We have order N squared properties where N is the number of pixels.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what are the properties of our convexity term?",
                    "label": 0
                },
                {
                    "sent": "The first question that arises whether it's a modular or not, so we can use the original definition by Edmonds from 1970s, and it says that energy submodular if for any two segments SMT.",
                    "label": 0
                },
                {
                    "sent": "The following inequality halts.",
                    "label": 0
                },
                {
                    "sent": "So let's consider one particular example of those two circles, eh?",
                    "label": 0
                },
                {
                    "sent": "Let's look at this inequality.",
                    "label": 0
                },
                {
                    "sent": "It both SMT a convex segments.",
                    "label": 0
                },
                {
                    "sent": "Therefore this term is 0 intersection of convex shapes is always convex.",
                    "label": 0
                },
                {
                    "sent": "Therefore this term is also zero.",
                    "label": 0
                },
                {
                    "sent": "But the Union of Convex shape is not necessarily convex like in this example.",
                    "label": 0
                },
                {
                    "sent": "There for this term is infinite.",
                    "label": 0
                },
                {
                    "sent": "Therefore the inequality does not hold.",
                    "label": 0
                },
                {
                    "sent": "An hour term is not submodular, which means bad news for optimization.",
                    "label": 0
                },
                {
                    "sent": "It's difficult to optimize.",
                    "label": 0
                },
                {
                    "sent": "The second difficulty is.",
                    "label": 0
                },
                {
                    "sent": "In optimizing, this term arises from the large number of triple click potentials.",
                    "label": 0
                },
                {
                    "sent": "Even a valuation of the energy is expensive.",
                    "label": 0
                },
                {
                    "sent": "It takes order N squared to compute the energy.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How do we optimize our term?",
                    "label": 0
                },
                {
                    "sent": "We use trust region framework.",
                    "label": 0
                },
                {
                    "sent": "Translation framework is quite common.",
                    "label": 0
                },
                {
                    "sent": "A method in continuous optimization field and it's recently has been successfully used in the context of discrete high order energies and binary pairwise energies.",
                    "label": 0
                },
                {
                    "sent": "A direct application of translation will be too expensive because we have so many triple clicks we propose to use dynamic programming to speed up the energy variation.",
                    "label": 0
                },
                {
                    "sent": "An approximation in each iteration of trust region.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now let me briefly overview the Trust region framework, so it's iterative optimization framework.",
                    "label": 0
                },
                {
                    "sent": "The goal is to optimize the energy, and this is a schematic illustration.",
                    "label": 0
                },
                {
                    "sent": "Consider XT is a current solution.",
                    "label": 0
                },
                {
                    "sent": "In each iteration the energy is approximated by tractable model ET around the current solution.",
                    "label": 0
                },
                {
                    "sent": "In",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Our approximation.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It keeps the submodular part of energy untouched because we can optimize it easily but linearizes the convexity term.",
                    "label": 0
                },
                {
                    "sent": "So overall our approximation is a model function.",
                    "label": 0
                },
                {
                    "sent": "If we were to optimize globally our approximation, we would make something that is very similar to Newton Step and Newton step might result in a very large step to a point where approximation has nothing to do with the original function.",
                    "label": 0
                },
                {
                    "sent": "Instead.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Trust region.",
                    "label": 0
                },
                {
                    "sent": "The approximation is only trusted locally within the vicinity of current solution, and this region is called Trust region.",
                    "label": 0
                },
                {
                    "sent": "Then the approximation is optimized within a trust region subject to distance constraints from the current solution.",
                    "label": 0
                },
                {
                    "sent": "This step is usually called a trust region subproblem.",
                    "label": 0
                },
                {
                    "sent": "Once the candidate solution is obtained, the whole process is repeated again and again and the trust region sizes adaptively adjusted from iteration to iteration based on the quality of current approximation.",
                    "label": 0
                },
                {
                    "sent": "So although approximation model is submodular, optimizing it's subject to distance constraint is unfortunately NP hard, so we need to look for an alternative to control the trust region size, not the not the constraints.",
                    "label": 0
                },
                {
                    "sent": "For that we.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As a following unconstrained Lagrangian formulation, it has the same submodular part.",
                    "label": 0
                },
                {
                    "sent": "The regulation of the convexity part.",
                    "label": 0
                },
                {
                    "sent": "And it has the grunge multiplier Lambda T which penalizes the distance from the current solution.",
                    "label": 0
                },
                {
                    "sent": "Lambda T is fixed in each iteration and it is inversely proportionate to the trust region size and we can adjust Lambda TA from iteration to iteration based on the quality of the approximation following the principles of trust region.",
                    "label": 0
                },
                {
                    "sent": "The distance here can be formulated as unary terms, so overall our Lagrangian formulation is a submodular function and now we can optimize it globally and efficiently with one graph cut.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I explained about trust region.",
                    "label": 0
                },
                {
                    "sent": "Now one more difficulty.",
                    "label": 0
                },
                {
                    "sent": "Trust region requires evaluation, an approximation of the convex determine each iteration.",
                    "label": 0
                },
                {
                    "sent": "Naive computation takes order N squared.",
                    "label": 0
                },
                {
                    "sent": "We use dynamic programming to speed up the computation to linear time due to the lack of time.",
                    "label": 0
                },
                {
                    "sent": "I will only explain how to value the energy using dynamic programming.",
                    "label": 0
                },
                {
                    "sent": "The approximation is done in a very similar way and the details can be found.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Paper.",
                    "label": 0
                },
                {
                    "sent": "So recall that to evaluate our convex detail, we need to count the number of triple clicks that violate the convexity.",
                    "label": 0
                },
                {
                    "sent": "That is, they have the configuration 101.",
                    "label": 0
                },
                {
                    "sent": "So let's see how to do that for one line.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Those are the pixels on the line with their chorus.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Funding labels, ones and zeros.",
                    "label": 0
                },
                {
                    "sent": "Note that each violating Republic potential has zero in the middle, so let's look at these zero picture.",
                    "label": 0
                },
                {
                    "sent": "How many triple click potential does it participate in?",
                    "label": 0
                },
                {
                    "sent": "That Virat convexity?",
                    "label": 0
                },
                {
                    "sent": "It has two object pixels to the left of it and five objective pixels to the right of it.",
                    "label": 0
                },
                {
                    "sent": "So overall it participates in 10 triple clicks at valid convexity.",
                    "label": 0
                },
                {
                    "sent": "We can quickly compute it by counting the number of object pixels to the left of each pixel and to the right of each pixel using running sums.",
                    "label": 0
                },
                {
                    "sent": "Now we can look at the zero pixels on the line and take the product of those counts.",
                    "label": 0
                },
                {
                    "sent": "So we have 10 for this zero pixel and we have 12 for the zero pixels.",
                    "label": 0
                },
                {
                    "sent": "So overall there are 22 zero 22.",
                    "label": 0
                },
                {
                    "sent": "Triple click potentials that they violate the convexity and we were able to compute it in linear time scanning the line so.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Similarly, it's possible to show that it takes order MN operations to scan all lies in orientations, where N is the number of pixels in the image and M is the number of orientations.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now let me show some experiments and results.",
                    "label": 0
                },
                {
                    "sent": "We use convexity shape prior within the framework of interactive image segmentation.",
                    "label": 0
                },
                {
                    "sent": "Consider the following input image and user scribbles.",
                    "label": 0
                },
                {
                    "sent": "If you don't use any organization, this is the kind of result you would get.",
                    "label": 0
                },
                {
                    "sent": "You might hope to fix it with length organization, so let's try different way, toppling situation.",
                    "label": 0
                },
                {
                    "sent": "This is the X axis and see how close we get to the ground truth.",
                    "label": 0
                },
                {
                    "sent": "This is the Y axis.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is the plot for length organization.",
                    "label": 0
                },
                {
                    "sent": "And let's look at some key points on that plot.",
                    "label": 0
                },
                {
                    "sent": "A point A has very low regularizer weight and as expected it will result in a very noisy segmentation.",
                    "label": 0
                },
                {
                    "sent": "A point B has a slightly larger regularizer weight and the result is a bit less noisy, but still a under segmented Point C has a slightly higher weight, but there is a shrinking.",
                    "label": 0
                },
                {
                    "sent": "So now let's do the same experiment with the convexity shape prior.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is a plot for convex regularization.",
                    "label": 0
                },
                {
                    "sent": "As you can see, it's very robust with respect to the regularizer parameter.",
                    "label": 0
                },
                {
                    "sent": "And those are few key points from that plot an, so they are visually indistinguishable.",
                    "label": 0
                },
                {
                    "sent": "That's why we say that our method is virtually parameter free.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here a few more examples on natural images.",
                    "label": 0
                },
                {
                    "sent": "For some images both legs, organization and convex regularization a obtained good results for wide range of values for the regularizer.",
                    "label": 0
                },
                {
                    "sent": "Wait, but for many other images with links organization there is a transition between under segmenting and over segmenting, which happens for very close valves of the regularizer wait?",
                    "label": 0
                },
                {
                    "sent": "In contrast, with convexity, the results are very robust, so here a few more examples that exhibit the same pattern of behavior with very sensitive and very robust convex regularization.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You know few examples are on medical images.",
                    "label": 0
                },
                {
                    "sent": "You can see that applying convex shape for medical images is able to remove the noise filling the holes in force connectivity and convexity without compromising.",
                    "label": 0
                },
                {
                    "sent": "In the corners, the running times can be seen on the right.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In in theory, our convex system can be optimized with standard optimization methods such as QBO, anti RWS.",
                    "label": 0
                },
                {
                    "sent": "Those methods were specifically designed for optimization of non submodular energies.",
                    "label": 0
                },
                {
                    "sent": "In practice however, our term proved to be prohibitively expensive because we need to enumerate all the quadratic number of triple clicks to fit into those those methods.",
                    "label": 0
                },
                {
                    "sent": "Nonetheless, we were able to come up with a more compact model which has less clicks.",
                    "label": 0
                },
                {
                    "sent": "Order of N sqrt N clicks.",
                    "label": 0
                },
                {
                    "sent": "A surprisingly, this compact model model is slower to optimize than the full model because dynamic programming no longer applies.",
                    "label": 0
                },
                {
                    "sent": "Nonetheless, we can use the slower version of our method without dynamic programming and compare it to the capable interest.",
                    "label": 0
                },
                {
                    "sent": "TRW SA for very tiny synthetic image.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here are the results.",
                    "label": 0
                },
                {
                    "sent": "For very low value of collectivization, wait all three methods obtain globally optimal but otherwise useless solution.",
                    "label": 0
                },
                {
                    "sent": "Because this value of weight does not enforce any convexity for high value of the convex realization rate a both could be beyond until WS failed to obtain satisfactory solutions.",
                    "label": 0
                },
                {
                    "sent": "Great color denotes unlabeled pixels with capable and here are the results obtained for values in between.",
                    "label": 0
                },
                {
                    "sent": "In all the cases, our method was able to obtain satisfactory solutions.",
                    "label": 0
                },
                {
                    "sent": "In there.",
                    "label": 0
                },
                {
                    "sent": "A short time.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So some limitations of our method, trust, region, framework is a local iterative optimization that we cannot guarantee global minimum.",
                    "label": 0
                },
                {
                    "sent": "Of course, there might be some sensitivity to initialization.",
                    "label": 0
                },
                {
                    "sent": "Consider the following synthetic examples.",
                    "label": 0
                },
                {
                    "sent": "If we initialize a optimization retrieval solutions where all pixels belong to the foreground depicted here with red, the contour will get to this inferior solution, but.",
                    "label": 0
                },
                {
                    "sent": "If, in contrast we initialize with maximum likelihood label purposes, which basically all the black pieces in the foreground, then we get to the global minimum.",
                    "label": 0
                },
                {
                    "sent": "So here's some sensitivity to initialization.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And let me summarize a. I've introduced the novel convex shape drivers in the framework of discrete optimization.",
                    "label": 0
                },
                {
                    "sent": "Our prior has no shrinking bias.",
                    "label": 0
                },
                {
                    "sent": "It is able to remove noise and filling the holes.",
                    "label": 0
                },
                {
                    "sent": "It ensures connectivity and convexity while preserving sharp corners.",
                    "label": 0
                },
                {
                    "sent": "Our model is get invited you to Infinity constraints an.",
                    "label": 0
                },
                {
                    "sent": "But in practice, when we use finite penalty, it is virtually parameter free.",
                    "label": 1
                },
                {
                    "sent": "I propose efficient optimization based on trust region and dynamic programming.",
                    "label": 1
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the code is available online.",
                    "label": 0
                },
                {
                    "sent": "Please feel free to download and use it and please come by our poster tomorrow to ask questions if you have any.",
                    "label": 0
                },
                {
                    "sent": "Facebook.",
                    "label": 0
                },
                {
                    "sent": "Questions in your trust region method you seem to compute gradients as well and you have integer variables.",
                    "label": 0
                },
                {
                    "sent": "So how do you compute these gradients?",
                    "label": 0
                },
                {
                    "sent": "Well, it's not exactly gradient, it's an approximation, so we can compute the linear approximation that agrees with current increases with the current solution with original energy, and it also agrees with original energy.",
                    "label": 0
                },
                {
                    "sent": "An N plus one variables AN plus one configurations.",
                    "label": 0
                },
                {
                    "sent": "So it's a linear approximation.",
                    "label": 0
                },
                {
                    "sent": "It's very close to the original function, but it's not a gradient.",
                    "label": 0
                },
                {
                    "sent": "And in the paper we we motivate better while we use our linear approximation.",
                    "label": 0
                },
                {
                    "sent": "I think there was one question.",
                    "label": 0
                },
                {
                    "sent": "Can you can you tell?",
                    "label": 0
                },
                {
                    "sent": "If a convex shape prior really was a good prior for the for the shape based on the energies or the robustness or something.",
                    "label": 0
                },
                {
                    "sent": "So if it's really a non convex shape.",
                    "label": 0
                },
                {
                    "sent": "If you don't want to get a convex shape as a result, then you shouldn't use this prior.",
                    "label": 0
                },
                {
                    "sent": "This prior is for convex shapes.",
                    "label": 0
                },
                {
                    "sent": "If it can help, you may be too quickly finding candidate solution and then refine it with other methods, but it's mostly should be useful for convex shape.",
                    "label": 0
                },
                {
                    "sent": "In when you were comparing your method to QBO and TWS in your results in the regularization weight, in this case played the played an important role so you get non convex shapes or common shapes.",
                    "label": 0
                },
                {
                    "sent": "But in your real world results it was insensitive to.",
                    "label": 0
                },
                {
                    "sent": "So can you explain a bit why this difference?",
                    "label": 0
                },
                {
                    "sent": "Yes so it is virtually parameter free once you.",
                    "label": 0
                },
                {
                    "sent": "You get high enough penalty to enforce convexity before you if you don't enforce convex.",
                    "label": 0
                },
                {
                    "sent": "If your regularizer weight is very weak, you will not enforce the context and you cannot enforce the convexity of different levels, But once you hit the point where the conversi has to be enforced because the plant is too high, then there is no no change in the solutions, so synthetic examples are usually more difficult than natural images example because the data terms and natural images are very good.",
                    "label": 0
                },
                {
                    "sent": "Does it answer question OK, Thanks.",
                    "label": 0
                },
                {
                    "sent": "OK, I think we move on, so thanks again.",
                    "label": 0
                }
            ]
        }
    }
}