{
    "id": "6bfcpkubz7x5rkkjz32jtl6kfiag7mwo",
    "title": "Approximate Inference Control",
    "info": {
        "author": [
            "Marc Toussaint, Machine Learning and Intelligent Data Analysis Group, TU Berlin"
        ],
        "published": "Jan. 19, 2010",
        "recorded": "December 2009",
        "category": [
            "Top->Computer Science->Optimization Methods",
            "Top->Computer Science->Machine Learning",
            "Top->Computer Science->Robotics"
        ]
    },
    "url": "http://videolectures.net/nipsworkshops09_toussaint_aic/",
    "segmentation": [
        [
            "OK. Yeah, the last talk today.",
            "Maybe I stand on that side and yet again, another talk on using inference for control and I feel sort of bad.",
            "You must be fed up with that.",
            "But overall, another approach here.",
            "This is basically a talk where which is about the work that I've been presenting at ICL, this here or also two years ago."
        ],
        [
            "At Iris and.",
            "Oh, that's really tricky.",
            "I tried to start with high level discussion of.",
            "Ideas to go about translating stochastic optimal control to influence, and I'm not sure if it's a really good diagram, but maybe it's worth to start as a basis for discussion so stochastic optimal control.",
            "There's been lots of ideas how you could try to translate stochastic optimal control into a problem of inference, and in particular, like bird, it off and the other people that we've heard today.",
            "They had ideas and thinking about how could you sort of exactly translate stochastic optimal.",
            "Control into a problem of infants and that works for certain kind of assumption or constraints on the dynamics.",
            "I think the point I want to make is that.",
            "Stochastic optimal control is a really hard problem, so the really what is very relevant is to find the right approximations to actually solve it right?",
            "So the typical approximations that are being used for instance RDP or LPG and the same also helps holds here like for reasonable problems.",
            "I mean it's nice to formulate it exactly somehow, But anyway you have to do approximations and I think the point that I want."
        ],
        [
            "To make is you know the good approximations.",
            "These are actually the real things that we're interested in, and I think the whole idea of translating the problem into a problem of inference is that we might be able to draw on all these probabilistic inference methods, which sort of suggests knew new approximations.",
            "So what I'm going to talk about today is what I call approximate inference control, and it's just an approximate method which uses Gaussian belief representations, and it will turn out that it's not.",
            "It doesn't directly correspond to."
        ],
        [
            "Being equivalent like on this higher level, but it turns out that if you do these approximations on that level, it turns out that it produces the same results as GDP in iog.",
            "OK, in some sense I think that this is also like a simplest version of using inference for control in the sense that it uses like simple extend common."
        ],
        [
            "A techniques to do inference in these.",
            "So the outline is straightforward.",
            "I'm first going to introduce the model, then I'm going to talk about how to do inference, and then I'm going to spend some time."
        ],
        [
            "Show the experiments that we did within robotics.",
            "Stochastic optimal control.",
            "I guess you've seen it a couple of times today is concerned with the discrete times traffic control process where we have some kind of update equation for the state.",
            "So X denotes the state of the system.",
            "There is some arbitrary nonlinear transition of the state and some kind of calls noise.",
            "You can draw this process also as a graphic model if you like."
        ],
        [
            "Classicly the classical notion of statements to has the optimal control is steady associate cost with the state and the controlling.",
            "Every time slice you just sum this up and the problem now is to find a controller that is a control policy mapping from the state to control that minimizes the expectation of the cost function, and so we're taking the expectation over States and controls.",
            "Given that control policy and sort of want to minimize the expectation of that cost.",
            "And obviously there is this kind of standard approaches how to how to solve the problem.",
            "Thinking backwards from the goal in some sense by defining an optimal value function and and thinking about Bellman's optimality principle and derive moments equation for these."
        ],
        [
            "Now, a different formulation is this one here it's just a simple, so at this point this is just like a different view and how you could view the problem.",
            "So again we have the same kind of process, so we have to state and there is a stochastic update of the state depending on the control.",
            "And this this is just as we had before is just a Gaussian distribution.",
            "Now, in addition to that, what I introduced here is what I call a task variable, and I'm going to explain in a second, why call this task verbal.",
            "It's unusual at first, but it's just a binary random verbal and I just define this binary random available that the likelihood of that random variable to be one depending on the state in control, it's just the export of the negative classical cost, right?",
            "The reason I call this task verbal is because I think this is sort of like a like in robotics.",
            "The task verbal is typically like in end effective verbal or or maybe some kind of end effector orientation or other kinds of things.",
            "In some sense, this binary variable is sort of like a minimalistic representative of other kinds of tasks, and what it will turn out is set in some sense.",
            "We try to control the process such that the task remains in state one all the time.",
            "And later on in robotics case we're going to see examples where we replace the task like like real tasks and affective space and things like that.",
            "Yeah, and Kevin Murphy actually had a really interesting question about to birth, how it relates to influence diagrams.",
            "And it turns out that the general idea of translating costs or utilities or rewards to a binary random variable and then do inference is like really old.",
            "It's like from the 80s and Cooper and chapter, and in particular in a group of factor following that there was a lot of work on really reformulating the problem of maximizing expected utility's as a problem of inference, so in some sense I think.",
            "The conceptual approach here is really not not new at all.",
            "It's just."
        ],
        [
            "Sort of a newer version where we apply modern, more modern techniques for inference.",
            "OK, given that model, before discussing how it relates to stochastic optimal control, what we can do given the model is computed, trajectory posterior spurt pointed out computing such a posterior is the problem of public global minimization, and in some sense, well this is the point where it relates to the carpet clabber approaches that we've seen.",
            "So computing that trajectory posterior is like a core problem within the graphical model."
        ],
        [
            "Another problem you could you could try to compute is compute the MLP control so the the most likely control conditioned on the state at a certain time slice.",
            "Which is an interesting quantity that is really a feedback controller and I'm going to say something."
        ],
        [
            "But that controller, another one is if you assume that the policy in the model has some parametric form, some arbitrary.",
            "Parametric form what you could try to do is maximize the likelihood.",
            "So find the parameter of the controller which maximizes the likelihood of fulfilling the task in all time slices.",
            "And well, I mean this one here.",
            "You would typically do with expectation maximization and, well, this also requires to compute the posterior trajectory.",
            "So both of these PNC requires actually computing the posterior."
        ],
        [
            "So the main point is then to find good approximation methods to compute the posterior.",
            "So finally, how does that relate to the standard stochastic optimal control formulation really trivially by the definition of how I define the model, the likelihood of a specific trajectory and trajectory I mean.",
            "A specific instance of States and control sequences, so the likelihood of for a specific trajectory is just a negative cost, and that also implies that the maximum likelihood trajectory that is the mode of the posterior that we're going to compute is in some sense the optimal trajectory."
        ],
        [
            "But it's also true that if we sort of not conditioned on a specific trajectory, but take expectations over the whole process, well, the likelihood in that model is not equal to negative expected costs.",
            "So this one here is stochastic optimal control.",
            "Maximizing this is stochastic optimal control, and this equation just by Jensen inequality, tells you that.",
            "Well, what I formulated here, it's not really equivalent to stochastic optimal control, and I just wanted to say that too, actually."
        ],
        [
            "Make a point so the two models at this level."
        ],
        [
            "Are different.",
            "They imply different notions of optimality.",
            "So, for instance, in stochastic optimal control, you say I want to minimize the expected costs that arise when I collide with something.",
            "So you have to sort of think about well how, what kind of costs do you invent to penalize collisions or things like that?",
            "In inference?",
            "You could say, well, I want to maximize the likelihood of non collision."
        ],
        [
            "So in that sense, I think it's really worth to think about.",
            "Well who decides which of these are better notions of optimality, and in particular, I think only a practitioner could decide.",
            "Or maybe somebody doing graphics could decide which of these notions of optimality eventually give you better trajectories."
        ],
        [
            "Just a point.",
            "However.",
            "Although that in general both models are different, it turns out that in the LG case, both of these models coincide.",
            "That isn't the case.",
            "Again, what the outcome of the inference.",
            "In particular the AP controller is equal to the optimal control of the LG case, and because the method."
        ],
        [
            "That we are going to use are all based on local approximations.",
            "Well, it turns out that we will sort of reproduce the same kind of solutions that local methods in stochastic optimal control produce.",
            "So how can we do inference in that model in the Akagi case, the whole graphical model that I've introduced is just a Gaussian graphical model, so all the random variables are Gaussian.",
            "The couplings are linear inferences trivial, you just have to do a common smoothing.",
            "It turns out that the backward messages are equivalent to the recut equation, which I think IMO.",
            "Already pointed out.",
            "When discussing the common duality, and it turns out that the MLP controller, that is the posterior control conditioned on the stage in a certain time slice is the optimal stochastic optimal controller for the help."
        ],
        [
            "The case.",
            "Um?",
            "In the non LQT case, well now that's that's the interesting part of course.",
            "How could we do inference?",
            "Well, we could do particles if we wanted to.",
            "Which in high dimensions maybe it's possible not know could do it, but maybe I couldn't, I'm not sure.",
            "Or we could use extended common kind of techniques that that's what I'm doing.",
            "It's kind of crude, but it's fast and it's simple.",
            "We could do unsigned transforms or expectation propagation point that I wanted to make in the kind of applications that I'm using.",
            "Actually evaluating the cost for a certain state is really expensive.",
            "Just evaluating the cost.",
            "So what I'm worried about with unscented, even unscented transform so particles is that you know I have to evaluate lots of particles for those kind of things, and that's that's.",
            "Actually expensive, whereas linearizing the dynamics or computing the messages inverting matrices.",
            "All of this is really cheap compared to evaluating costs and evaluating collisions.",
            "So anyway, what I basically focused on is using extended common techniques and expectation propagation too."
        ],
        [
            "To compute an approximate approximate posterior so the way it works is that we compute Gaussian messages using kind of extended common smoothing.",
            "We linearize always at the mode of the current belief and the algorithm.",
            "What it does now it's looking forward and backward overtime and it every time slice it iterates, updating the messages and the belief until the belief converges.",
            "Now that's an interesting point, because whenever I update the messages then the belief changes.",
            "Then the point of linearisation changes.",
            "Then I have to recompute the messages, and I just iterate it until convergence.",
            "So which means that we actually spend in every time, so I spend quite some effort in order to estimate the belief as best as possible.",
            "And there is lots of computational tricks to actually make this make this more efficient, so.",
            "You could do things like caching and avoid recomputing messages, and when you should be exactly."
        ],
        [
            "OK, some examples.",
            "The first example is.",
            "Like maybe some some tests that I did two years ago, I think where.",
            "I have simple like humanoid model and within that humanoid model I can define certain task variables.",
            "Now these are typical task workers in robotics.",
            "So the first one would be the robots fingertip.",
            "The second one would be a 2 dimensional variable which is the robots balance and the third one would be a variable which is scalar which measures all collisions or proximities of their robot.",
            "What I can do is I can set up a graphical model and condition these task variables to things that I want.",
            "What?"
        ],
        [
            "What this looks like is basically.",
            "It's the same model, but instead of having the binary task wearable you have all these more realistic robotics task wearables.",
            "For instance, Andy Andy, and effect of the robot you only condition in the final time step the collision variable.",
            "You condition all time steps and also the balance condition all time steps.",
            "The point just being you know it's very flexible.",
            "In that sense the setup.",
            "But the algorithm is exactly the same because all of these variables they just induce simple Gaussian messages during that.",
            "Message computation"
        ],
        [
            "OK, here's a. Yeah, there's two little problems that I investigated.",
            "This one here is the start configuration.",
            "This is an end configuration, but the problem is to move the finger towards the goal dot here and at the same time keep balance.",
            "That's why he's sort of like balancing on the left foot here and not colliding and just."
        ],
        [
            "Compare with other kinds of algorithms.",
            "I compare this with really old like technique, spline encoding after trajectory, so this is only if the problem was deterministic.",
            "Is planning coding of the Directory and then just using gradient methods or I'll QG which is this one here or the approximate inference control which is this one here?",
            "The problem by the ways I think 35 dimensional or something and it has a 400 time steps of this trajectory.",
            "The point being, although that it's quite high dimensionalizing informed time steps.",
            "I think you know that's quite fast.",
            "It's on the order of the 2nd to get a really good trajectory, because everything that is below one reaches the goal quite well and it's not colliding.",
            "So yeah, I'm really."
        ],
        [
            "Playing, I'm aiming for having fast, fast algorithms to solve these problems, and this seems promising.",
            "A second example.",
            "Um?",
            "So within our group we've been applied inference on different levels like I've been doing some work to use inference, Markov decision processes and puppies, and also actually a student of mine started to use probabilistic inference methods in order to plan on stochastic relational models.",
            "So this is actually marriage between 1st order logic and stochastic models, where we have a set of stochastic rules, and so with these kinds of methods we can solve things like blocksworld and so we thought.",
            "Well, we can solve blocks world and we can also solve like motion generation with these kind of icon methods we should you integrate that whole thing and now have one big graphical model on all kinds of levels and show that inference could solve that problem.",
            "So let me just show the movie.",
            "If that works, I hope it's on the right screen now.",
            "Yeah, OK. Um?",
            "So if you look in the movie, there is there's cans and accounts of different colors, so there is green cans and red cans with the labels.",
            "The problem for the robot is to stack all the red pants on in one pile and all the green cans in one pile.",
            "So we started planning on a higher level so the 1st order logic kind of inference and the output of that is just a symbolic list of actions that are being too.",
            "You know, the robot should take in order to sort these things and then once we have these symbolic actions we sort of translate them into.",
            "Yeah, there was a bug there.",
            "Very good.",
            "We sort of translate them into what that means.",
            "What that implies for the trajectories.",
            "So the directory is here are generated with this icon and the higher level symbolic plan was generated with the prod algorithm, which uses inference in symbolic logic.",
            "Now, this is what actually the Iko.",
            "So this is what the probabilistic inference for for control uses inside the simulator in order to optimize these trajectories and what we see here all these red markers, these are potential collisions.",
            "These are proximities actually like this trajectory that we've just seen.",
            "I like quite a lot.",
            "Really nice trajectory.",
            "So the location of the counts is inferred from vision, but only the location.",
            "But then we assume to know the size of the cans and then and then we sort of in the CAD model we only have to put all the cans in and right spot.",
            "The location of the cancel is inferred from vision and.",
            "No.",
            "OK, so on the higher level.",
            "Well, I should OK.",
            "But"
        ],
        [
            "On the higher level, actually it is.",
            "In some sense, actually it is on the high level.",
            "It is sampling lots and lots of symbolic actions in a blocks world in a simulated blocks well and sort of testing.",
            "Which actions will actually lead to goal so, but it's sampling, random symbolic actions and then testing their outcome.",
            "From this you can generate with a learning algorithm by coupling generate a list of probabilistic rules and that gives you first order probabilistic description of the blocks world and that can be translated and unambitious.",
            "Network and then then inference.",
            "After that, so when we done that, we have the list of symbolic actions and those then only like trigger.",
            "How to you know the trajectory still in trajectory optimization?",
            "Yeah, so the.",
            "Evaluating the cost in trajectory optimization involves querying the collision detection library, and I'm using Swift plus plus.",
            "If anybody knows, it's really nice because it gives us the normals and the proximities and things, but that is the main cost is really like 70% of the whole algorithm is spent in the collision detection queries and you know all this defense.",
            "He thinks about inverting matrices doesn't really matter, it's all how often we have to query the collision detection library.",
            "An yeah, that's the main cast.",
            "OK."
        ],
        [
            "Like a last example.",
            "In at the poster, actually we also thought about using other kinds of message computations when the tasks are hard constraints.",
            "So in robotics I mean a lot of tasks with the end effector.",
            "You could linearize nicely, but other other tasks like not hitting a joint limit or not having collisions, it's actually more natural to represent as really hard constraints and actually truncations off the beliefs.",
            "So at the poster, or talk to me, well, we show that you can use expectation propagation to compute these kinds of messages, which.",
            "As best as possible representation of beliefs."
        ],
        [
            "To summarize, the bottom line of many talks at this session actually spin that we can reformulate the problem of control.",
            "It's a problem of inference.",
            "My primary focus really is to think about, well, how can you make it fast?",
            "So what kind of tricks can use to have fast approximations and faster inference methods to get this going?",
            "And actually so the goal really is to have ideas for a couple of more tricks.",
            "Computational tricks, in particular paralyzing the inference, think that is.",
            "It's possible which will give like another speedups, and which means that we hope to do the planning for trajectories of like 4 seconds.",
            "Such that it only takes a 10th of a second.",
            "So which means that we would have a fully online planning system at every point the system can plan ahead, like 4 seconds or so.",
            "OK, the code for the for the algorithm is actually at my website.",
            "If you want to test it and that's it, thanks.",
            "Scale with number obstacles.",
            "That's actually it's.",
            "That would all be a matter of the of the collision detection library.",
            "So the question is, how good is the collision detection library in pruning things like pruning potential collisions, which are too far away and like swift plus plus, at least it uses these octrees or whatever to prune away.",
            "You know, computing collisions, which cannot be because they are too far away the objects.",
            "Affect the convergence speed or damper yourself and.",
            "OK. Yeah, maybe there is a point.",
            "So within these grasping seen that you've seen say that there was only one object, but the point being with a finger or with hand, I sort of almost enclosed that object and there were many, many of you know, proximities here, and each of those implied a message on the belief and it really turned out that.",
            "When the that's a very strong conditioning of this situation of the configuration, and it turns out if the conditioning of the situation or configuration is very strong and sort of brittle, then it takes longer for the convergence, yes, but I couldn't really say systematic that you know what the complexity of that is, just by experience here.",
            "The more constrained and hard it is to fulfill all constraints then convergence is slower.",
            "Yep.",
            "Contact the dynamics are no longer control appetite pending on what control signal you choose.",
            "You may or may not make contact, so that's not very.",
            "You know, that doesn't play very well with help with that, yes.",
            "It's in in those examples that I showed here.",
            "It was actually more I should actually say, proximities, not context.",
            "So you know I'm measuring proximities and ensure that they are larger than a margin.",
            "So within these trajectories, I really hope that there will be never really collisions.",
            "I mean, that's the point, right?",
            "Should be collision free.",
            "No, if you look precisely at the video and be critical as you were anyway, then you've seen that it only like the smooth trajectory which you could see.",
            "That's the plan.",
            "One only went to like a centimeter to the objects and then again, heuristic.",
            "If then the next phase is just closing and.",
            "Sorry.",
            "Comment on all the time discretization, 'cause I've also done this kind of problem with hard boundaries in running DP.",
            "After two is actually quite nasty dependence of the type of trajectory that you get.",
            "Yeah, Mon features pointed me to that where is my friend anyway?",
            "To like say, if you double the time scale, then you know exactly what you should do with the cost.",
            "You should sort of half the cost, right?",
            "But if you double the time scale, what do you do with the truncations?",
            "Because I mean there is not only doing a truncation half, so it's really hard to know how could you consistently like double the time scale so such that in principle the same solution rises?",
            "I would only have an idea if on the level of the message the message is a Gaussian Gaussian message, so you could sort of decade DP message when you double the time scale.",
            "If you do the exact replication at every time scale, then it just has double effect in that would work, but did you have a problem with that?",
            "No it at for this kind of experience.",
            "We didn't change the time scale which is fixed it.",
            "Transfer.",
            "Typically it's 10 milliseconds.",
            "Question.",
            "Complexity of the pathfinding problem.",
            "The classes peace based company.",
            "So I'm going to go back to the first question regarding the complexity perspective.",
            "The number of objects.",
            "It's been known to be double exponential, but the best result that I know is simply exponential with the perspective.",
            "Number of obstacles.",
            "So would you comment on the the upper bounds of produce algorithm?",
            "How much ingredients you and are you doing?",
            "Any approximations for that?",
            "So yeah, so I'm.",
            "It's really quite remote.",
            "These kind of arguments that are about pathfinding in really complex scenes where the more objects you have it becomes more complex and their solutions like RTS.",
            "In these kinds of methods, whereas these methods I mean there are totally local right?",
            "I mean just like DDP and I could be there totally local.",
            "So I there is no.",
            "I mean they definitely cannot solve things like the Alpha puzzle or complex configurations like when you have many many objects, obstacles and you need to find a complex path."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK. Yeah, the last talk today.",
                    "label": 0
                },
                {
                    "sent": "Maybe I stand on that side and yet again, another talk on using inference for control and I feel sort of bad.",
                    "label": 1
                },
                {
                    "sent": "You must be fed up with that.",
                    "label": 0
                },
                {
                    "sent": "But overall, another approach here.",
                    "label": 0
                },
                {
                    "sent": "This is basically a talk where which is about the work that I've been presenting at ICL, this here or also two years ago.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At Iris and.",
                    "label": 0
                },
                {
                    "sent": "Oh, that's really tricky.",
                    "label": 0
                },
                {
                    "sent": "I tried to start with high level discussion of.",
                    "label": 0
                },
                {
                    "sent": "Ideas to go about translating stochastic optimal control to influence, and I'm not sure if it's a really good diagram, but maybe it's worth to start as a basis for discussion so stochastic optimal control.",
                    "label": 0
                },
                {
                    "sent": "There's been lots of ideas how you could try to translate stochastic optimal control into a problem of inference, and in particular, like bird, it off and the other people that we've heard today.",
                    "label": 0
                },
                {
                    "sent": "They had ideas and thinking about how could you sort of exactly translate stochastic optimal.",
                    "label": 0
                },
                {
                    "sent": "Control into a problem of infants and that works for certain kind of assumption or constraints on the dynamics.",
                    "label": 0
                },
                {
                    "sent": "I think the point I want to make is that.",
                    "label": 0
                },
                {
                    "sent": "Stochastic optimal control is a really hard problem, so the really what is very relevant is to find the right approximations to actually solve it right?",
                    "label": 0
                },
                {
                    "sent": "So the typical approximations that are being used for instance RDP or LPG and the same also helps holds here like for reasonable problems.",
                    "label": 0
                },
                {
                    "sent": "I mean it's nice to formulate it exactly somehow, But anyway you have to do approximations and I think the point that I want.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To make is you know the good approximations.",
                    "label": 1
                },
                {
                    "sent": "These are actually the real things that we're interested in, and I think the whole idea of translating the problem into a problem of inference is that we might be able to draw on all these probabilistic inference methods, which sort of suggests knew new approximations.",
                    "label": 1
                },
                {
                    "sent": "So what I'm going to talk about today is what I call approximate inference control, and it's just an approximate method which uses Gaussian belief representations, and it will turn out that it's not.",
                    "label": 0
                },
                {
                    "sent": "It doesn't directly correspond to.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Being equivalent like on this higher level, but it turns out that if you do these approximations on that level, it turns out that it produces the same results as GDP in iog.",
                    "label": 0
                },
                {
                    "sent": "OK, in some sense I think that this is also like a simplest version of using inference for control in the sense that it uses like simple extend common.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A techniques to do inference in these.",
                    "label": 0
                },
                {
                    "sent": "So the outline is straightforward.",
                    "label": 0
                },
                {
                    "sent": "I'm first going to introduce the model, then I'm going to talk about how to do inference, and then I'm going to spend some time.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Show the experiments that we did within robotics.",
                    "label": 0
                },
                {
                    "sent": "Stochastic optimal control.",
                    "label": 0
                },
                {
                    "sent": "I guess you've seen it a couple of times today is concerned with the discrete times traffic control process where we have some kind of update equation for the state.",
                    "label": 0
                },
                {
                    "sent": "So X denotes the state of the system.",
                    "label": 0
                },
                {
                    "sent": "There is some arbitrary nonlinear transition of the state and some kind of calls noise.",
                    "label": 0
                },
                {
                    "sent": "You can draw this process also as a graphic model if you like.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Classicly the classical notion of statements to has the optimal control is steady associate cost with the state and the controlling.",
                    "label": 1
                },
                {
                    "sent": "Every time slice you just sum this up and the problem now is to find a controller that is a control policy mapping from the state to control that minimizes the expectation of the cost function, and so we're taking the expectation over States and controls.",
                    "label": 0
                },
                {
                    "sent": "Given that control policy and sort of want to minimize the expectation of that cost.",
                    "label": 1
                },
                {
                    "sent": "And obviously there is this kind of standard approaches how to how to solve the problem.",
                    "label": 0
                },
                {
                    "sent": "Thinking backwards from the goal in some sense by defining an optimal value function and and thinking about Bellman's optimality principle and derive moments equation for these.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now, a different formulation is this one here it's just a simple, so at this point this is just like a different view and how you could view the problem.",
                    "label": 0
                },
                {
                    "sent": "So again we have the same kind of process, so we have to state and there is a stochastic update of the state depending on the control.",
                    "label": 0
                },
                {
                    "sent": "And this this is just as we had before is just a Gaussian distribution.",
                    "label": 0
                },
                {
                    "sent": "Now, in addition to that, what I introduced here is what I call a task variable, and I'm going to explain in a second, why call this task verbal.",
                    "label": 0
                },
                {
                    "sent": "It's unusual at first, but it's just a binary random verbal and I just define this binary random available that the likelihood of that random variable to be one depending on the state in control, it's just the export of the negative classical cost, right?",
                    "label": 0
                },
                {
                    "sent": "The reason I call this task verbal is because I think this is sort of like a like in robotics.",
                    "label": 0
                },
                {
                    "sent": "The task verbal is typically like in end effective verbal or or maybe some kind of end effector orientation or other kinds of things.",
                    "label": 0
                },
                {
                    "sent": "In some sense, this binary variable is sort of like a minimalistic representative of other kinds of tasks, and what it will turn out is set in some sense.",
                    "label": 0
                },
                {
                    "sent": "We try to control the process such that the task remains in state one all the time.",
                    "label": 0
                },
                {
                    "sent": "And later on in robotics case we're going to see examples where we replace the task like like real tasks and affective space and things like that.",
                    "label": 0
                },
                {
                    "sent": "Yeah, and Kevin Murphy actually had a really interesting question about to birth, how it relates to influence diagrams.",
                    "label": 0
                },
                {
                    "sent": "And it turns out that the general idea of translating costs or utilities or rewards to a binary random variable and then do inference is like really old.",
                    "label": 0
                },
                {
                    "sent": "It's like from the 80s and Cooper and chapter, and in particular in a group of factor following that there was a lot of work on really reformulating the problem of maximizing expected utility's as a problem of inference, so in some sense I think.",
                    "label": 0
                },
                {
                    "sent": "The conceptual approach here is really not not new at all.",
                    "label": 0
                },
                {
                    "sent": "It's just.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sort of a newer version where we apply modern, more modern techniques for inference.",
                    "label": 0
                },
                {
                    "sent": "OK, given that model, before discussing how it relates to stochastic optimal control, what we can do given the model is computed, trajectory posterior spurt pointed out computing such a posterior is the problem of public global minimization, and in some sense, well this is the point where it relates to the carpet clabber approaches that we've seen.",
                    "label": 1
                },
                {
                    "sent": "So computing that trajectory posterior is like a core problem within the graphical model.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another problem you could you could try to compute is compute the MLP control so the the most likely control conditioned on the state at a certain time slice.",
                    "label": 0
                },
                {
                    "sent": "Which is an interesting quantity that is really a feedback controller and I'm going to say something.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But that controller, another one is if you assume that the policy in the model has some parametric form, some arbitrary.",
                    "label": 0
                },
                {
                    "sent": "Parametric form what you could try to do is maximize the likelihood.",
                    "label": 0
                },
                {
                    "sent": "So find the parameter of the controller which maximizes the likelihood of fulfilling the task in all time slices.",
                    "label": 0
                },
                {
                    "sent": "And well, I mean this one here.",
                    "label": 0
                },
                {
                    "sent": "You would typically do with expectation maximization and, well, this also requires to compute the posterior trajectory.",
                    "label": 0
                },
                {
                    "sent": "So both of these PNC requires actually computing the posterior.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the main point is then to find good approximation methods to compute the posterior.",
                    "label": 0
                },
                {
                    "sent": "So finally, how does that relate to the standard stochastic optimal control formulation really trivially by the definition of how I define the model, the likelihood of a specific trajectory and trajectory I mean.",
                    "label": 0
                },
                {
                    "sent": "A specific instance of States and control sequences, so the likelihood of for a specific trajectory is just a negative cost, and that also implies that the maximum likelihood trajectory that is the mode of the posterior that we're going to compute is in some sense the optimal trajectory.",
                    "label": 1
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But it's also true that if we sort of not conditioned on a specific trajectory, but take expectations over the whole process, well, the likelihood in that model is not equal to negative expected costs.",
                    "label": 0
                },
                {
                    "sent": "So this one here is stochastic optimal control.",
                    "label": 0
                },
                {
                    "sent": "Maximizing this is stochastic optimal control, and this equation just by Jensen inequality, tells you that.",
                    "label": 0
                },
                {
                    "sent": "Well, what I formulated here, it's not really equivalent to stochastic optimal control, and I just wanted to say that too, actually.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Make a point so the two models at this level.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Are different.",
                    "label": 0
                },
                {
                    "sent": "They imply different notions of optimality.",
                    "label": 1
                },
                {
                    "sent": "So, for instance, in stochastic optimal control, you say I want to minimize the expected costs that arise when I collide with something.",
                    "label": 0
                },
                {
                    "sent": "So you have to sort of think about well how, what kind of costs do you invent to penalize collisions or things like that?",
                    "label": 0
                },
                {
                    "sent": "In inference?",
                    "label": 0
                },
                {
                    "sent": "You could say, well, I want to maximize the likelihood of non collision.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in that sense, I think it's really worth to think about.",
                    "label": 0
                },
                {
                    "sent": "Well who decides which of these are better notions of optimality, and in particular, I think only a practitioner could decide.",
                    "label": 1
                },
                {
                    "sent": "Or maybe somebody doing graphics could decide which of these notions of optimality eventually give you better trajectories.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Just a point.",
                    "label": 0
                },
                {
                    "sent": "However.",
                    "label": 0
                },
                {
                    "sent": "Although that in general both models are different, it turns out that in the LG case, both of these models coincide.",
                    "label": 1
                },
                {
                    "sent": "That isn't the case.",
                    "label": 1
                },
                {
                    "sent": "Again, what the outcome of the inference.",
                    "label": 0
                },
                {
                    "sent": "In particular the AP controller is equal to the optimal control of the LG case, and because the method.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That we are going to use are all based on local approximations.",
                    "label": 0
                },
                {
                    "sent": "Well, it turns out that we will sort of reproduce the same kind of solutions that local methods in stochastic optimal control produce.",
                    "label": 0
                },
                {
                    "sent": "So how can we do inference in that model in the Akagi case, the whole graphical model that I've introduced is just a Gaussian graphical model, so all the random variables are Gaussian.",
                    "label": 1
                },
                {
                    "sent": "The couplings are linear inferences trivial, you just have to do a common smoothing.",
                    "label": 0
                },
                {
                    "sent": "It turns out that the backward messages are equivalent to the recut equation, which I think IMO.",
                    "label": 0
                },
                {
                    "sent": "Already pointed out.",
                    "label": 0
                },
                {
                    "sent": "When discussing the common duality, and it turns out that the MLP controller, that is the posterior control conditioned on the stage in a certain time slice is the optimal stochastic optimal controller for the help.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The case.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "In the non LQT case, well now that's that's the interesting part of course.",
                    "label": 0
                },
                {
                    "sent": "How could we do inference?",
                    "label": 0
                },
                {
                    "sent": "Well, we could do particles if we wanted to.",
                    "label": 0
                },
                {
                    "sent": "Which in high dimensions maybe it's possible not know could do it, but maybe I couldn't, I'm not sure.",
                    "label": 1
                },
                {
                    "sent": "Or we could use extended common kind of techniques that that's what I'm doing.",
                    "label": 0
                },
                {
                    "sent": "It's kind of crude, but it's fast and it's simple.",
                    "label": 1
                },
                {
                    "sent": "We could do unsigned transforms or expectation propagation point that I wanted to make in the kind of applications that I'm using.",
                    "label": 0
                },
                {
                    "sent": "Actually evaluating the cost for a certain state is really expensive.",
                    "label": 0
                },
                {
                    "sent": "Just evaluating the cost.",
                    "label": 0
                },
                {
                    "sent": "So what I'm worried about with unscented, even unscented transform so particles is that you know I have to evaluate lots of particles for those kind of things, and that's that's.",
                    "label": 0
                },
                {
                    "sent": "Actually expensive, whereas linearizing the dynamics or computing the messages inverting matrices.",
                    "label": 1
                },
                {
                    "sent": "All of this is really cheap compared to evaluating costs and evaluating collisions.",
                    "label": 0
                },
                {
                    "sent": "So anyway, what I basically focused on is using extended common techniques and expectation propagation too.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To compute an approximate approximate posterior so the way it works is that we compute Gaussian messages using kind of extended common smoothing.",
                    "label": 0
                },
                {
                    "sent": "We linearize always at the mode of the current belief and the algorithm.",
                    "label": 1
                },
                {
                    "sent": "What it does now it's looking forward and backward overtime and it every time slice it iterates, updating the messages and the belief until the belief converges.",
                    "label": 0
                },
                {
                    "sent": "Now that's an interesting point, because whenever I update the messages then the belief changes.",
                    "label": 0
                },
                {
                    "sent": "Then the point of linearisation changes.",
                    "label": 0
                },
                {
                    "sent": "Then I have to recompute the messages, and I just iterate it until convergence.",
                    "label": 0
                },
                {
                    "sent": "So which means that we actually spend in every time, so I spend quite some effort in order to estimate the belief as best as possible.",
                    "label": 0
                },
                {
                    "sent": "And there is lots of computational tricks to actually make this make this more efficient, so.",
                    "label": 1
                },
                {
                    "sent": "You could do things like caching and avoid recomputing messages, and when you should be exactly.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, some examples.",
                    "label": 0
                },
                {
                    "sent": "The first example is.",
                    "label": 0
                },
                {
                    "sent": "Like maybe some some tests that I did two years ago, I think where.",
                    "label": 0
                },
                {
                    "sent": "I have simple like humanoid model and within that humanoid model I can define certain task variables.",
                    "label": 1
                },
                {
                    "sent": "Now these are typical task workers in robotics.",
                    "label": 0
                },
                {
                    "sent": "So the first one would be the robots fingertip.",
                    "label": 1
                },
                {
                    "sent": "The second one would be a 2 dimensional variable which is the robots balance and the third one would be a variable which is scalar which measures all collisions or proximities of their robot.",
                    "label": 1
                },
                {
                    "sent": "What I can do is I can set up a graphical model and condition these task variables to things that I want.",
                    "label": 0
                },
                {
                    "sent": "What?",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What this looks like is basically.",
                    "label": 0
                },
                {
                    "sent": "It's the same model, but instead of having the binary task wearable you have all these more realistic robotics task wearables.",
                    "label": 0
                },
                {
                    "sent": "For instance, Andy Andy, and effect of the robot you only condition in the final time step the collision variable.",
                    "label": 0
                },
                {
                    "sent": "You condition all time steps and also the balance condition all time steps.",
                    "label": 0
                },
                {
                    "sent": "The point just being you know it's very flexible.",
                    "label": 0
                },
                {
                    "sent": "In that sense the setup.",
                    "label": 0
                },
                {
                    "sent": "But the algorithm is exactly the same because all of these variables they just induce simple Gaussian messages during that.",
                    "label": 0
                },
                {
                    "sent": "Message computation",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, here's a. Yeah, there's two little problems that I investigated.",
                    "label": 0
                },
                {
                    "sent": "This one here is the start configuration.",
                    "label": 0
                },
                {
                    "sent": "This is an end configuration, but the problem is to move the finger towards the goal dot here and at the same time keep balance.",
                    "label": 0
                },
                {
                    "sent": "That's why he's sort of like balancing on the left foot here and not colliding and just.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Compare with other kinds of algorithms.",
                    "label": 0
                },
                {
                    "sent": "I compare this with really old like technique, spline encoding after trajectory, so this is only if the problem was deterministic.",
                    "label": 0
                },
                {
                    "sent": "Is planning coding of the Directory and then just using gradient methods or I'll QG which is this one here or the approximate inference control which is this one here?",
                    "label": 0
                },
                {
                    "sent": "The problem by the ways I think 35 dimensional or something and it has a 400 time steps of this trajectory.",
                    "label": 0
                },
                {
                    "sent": "The point being, although that it's quite high dimensionalizing informed time steps.",
                    "label": 0
                },
                {
                    "sent": "I think you know that's quite fast.",
                    "label": 0
                },
                {
                    "sent": "It's on the order of the 2nd to get a really good trajectory, because everything that is below one reaches the goal quite well and it's not colliding.",
                    "label": 0
                },
                {
                    "sent": "So yeah, I'm really.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Playing, I'm aiming for having fast, fast algorithms to solve these problems, and this seems promising.",
                    "label": 0
                },
                {
                    "sent": "A second example.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So within our group we've been applied inference on different levels like I've been doing some work to use inference, Markov decision processes and puppies, and also actually a student of mine started to use probabilistic inference methods in order to plan on stochastic relational models.",
                    "label": 1
                },
                {
                    "sent": "So this is actually marriage between 1st order logic and stochastic models, where we have a set of stochastic rules, and so with these kinds of methods we can solve things like blocksworld and so we thought.",
                    "label": 0
                },
                {
                    "sent": "Well, we can solve blocks world and we can also solve like motion generation with these kind of icon methods we should you integrate that whole thing and now have one big graphical model on all kinds of levels and show that inference could solve that problem.",
                    "label": 0
                },
                {
                    "sent": "So let me just show the movie.",
                    "label": 0
                },
                {
                    "sent": "If that works, I hope it's on the right screen now.",
                    "label": 0
                },
                {
                    "sent": "Yeah, OK. Um?",
                    "label": 0
                },
                {
                    "sent": "So if you look in the movie, there is there's cans and accounts of different colors, so there is green cans and red cans with the labels.",
                    "label": 0
                },
                {
                    "sent": "The problem for the robot is to stack all the red pants on in one pile and all the green cans in one pile.",
                    "label": 0
                },
                {
                    "sent": "So we started planning on a higher level so the 1st order logic kind of inference and the output of that is just a symbolic list of actions that are being too.",
                    "label": 0
                },
                {
                    "sent": "You know, the robot should take in order to sort these things and then once we have these symbolic actions we sort of translate them into.",
                    "label": 0
                },
                {
                    "sent": "Yeah, there was a bug there.",
                    "label": 0
                },
                {
                    "sent": "Very good.",
                    "label": 0
                },
                {
                    "sent": "We sort of translate them into what that means.",
                    "label": 0
                },
                {
                    "sent": "What that implies for the trajectories.",
                    "label": 0
                },
                {
                    "sent": "So the directory is here are generated with this icon and the higher level symbolic plan was generated with the prod algorithm, which uses inference in symbolic logic.",
                    "label": 0
                },
                {
                    "sent": "Now, this is what actually the Iko.",
                    "label": 0
                },
                {
                    "sent": "So this is what the probabilistic inference for for control uses inside the simulator in order to optimize these trajectories and what we see here all these red markers, these are potential collisions.",
                    "label": 0
                },
                {
                    "sent": "These are proximities actually like this trajectory that we've just seen.",
                    "label": 0
                },
                {
                    "sent": "I like quite a lot.",
                    "label": 0
                },
                {
                    "sent": "Really nice trajectory.",
                    "label": 0
                },
                {
                    "sent": "So the location of the counts is inferred from vision, but only the location.",
                    "label": 0
                },
                {
                    "sent": "But then we assume to know the size of the cans and then and then we sort of in the CAD model we only have to put all the cans in and right spot.",
                    "label": 0
                },
                {
                    "sent": "The location of the cancel is inferred from vision and.",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 1
                },
                {
                    "sent": "OK, so on the higher level.",
                    "label": 0
                },
                {
                    "sent": "Well, I should OK.",
                    "label": 0
                },
                {
                    "sent": "But",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On the higher level, actually it is.",
                    "label": 0
                },
                {
                    "sent": "In some sense, actually it is on the high level.",
                    "label": 0
                },
                {
                    "sent": "It is sampling lots and lots of symbolic actions in a blocks world in a simulated blocks well and sort of testing.",
                    "label": 0
                },
                {
                    "sent": "Which actions will actually lead to goal so, but it's sampling, random symbolic actions and then testing their outcome.",
                    "label": 0
                },
                {
                    "sent": "From this you can generate with a learning algorithm by coupling generate a list of probabilistic rules and that gives you first order probabilistic description of the blocks world and that can be translated and unambitious.",
                    "label": 0
                },
                {
                    "sent": "Network and then then inference.",
                    "label": 0
                },
                {
                    "sent": "After that, so when we done that, we have the list of symbolic actions and those then only like trigger.",
                    "label": 0
                },
                {
                    "sent": "How to you know the trajectory still in trajectory optimization?",
                    "label": 0
                },
                {
                    "sent": "Yeah, so the.",
                    "label": 0
                },
                {
                    "sent": "Evaluating the cost in trajectory optimization involves querying the collision detection library, and I'm using Swift plus plus.",
                    "label": 0
                },
                {
                    "sent": "If anybody knows, it's really nice because it gives us the normals and the proximities and things, but that is the main cost is really like 70% of the whole algorithm is spent in the collision detection queries and you know all this defense.",
                    "label": 0
                },
                {
                    "sent": "He thinks about inverting matrices doesn't really matter, it's all how often we have to query the collision detection library.",
                    "label": 0
                },
                {
                    "sent": "An yeah, that's the main cast.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Like a last example.",
                    "label": 0
                },
                {
                    "sent": "In at the poster, actually we also thought about using other kinds of message computations when the tasks are hard constraints.",
                    "label": 0
                },
                {
                    "sent": "So in robotics I mean a lot of tasks with the end effector.",
                    "label": 0
                },
                {
                    "sent": "You could linearize nicely, but other other tasks like not hitting a joint limit or not having collisions, it's actually more natural to represent as really hard constraints and actually truncations off the beliefs.",
                    "label": 0
                },
                {
                    "sent": "So at the poster, or talk to me, well, we show that you can use expectation propagation to compute these kinds of messages, which.",
                    "label": 0
                },
                {
                    "sent": "As best as possible representation of beliefs.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To summarize, the bottom line of many talks at this session actually spin that we can reformulate the problem of control.",
                    "label": 0
                },
                {
                    "sent": "It's a problem of inference.",
                    "label": 0
                },
                {
                    "sent": "My primary focus really is to think about, well, how can you make it fast?",
                    "label": 1
                },
                {
                    "sent": "So what kind of tricks can use to have fast approximations and faster inference methods to get this going?",
                    "label": 0
                },
                {
                    "sent": "And actually so the goal really is to have ideas for a couple of more tricks.",
                    "label": 0
                },
                {
                    "sent": "Computational tricks, in particular paralyzing the inference, think that is.",
                    "label": 0
                },
                {
                    "sent": "It's possible which will give like another speedups, and which means that we hope to do the planning for trajectories of like 4 seconds.",
                    "label": 0
                },
                {
                    "sent": "Such that it only takes a 10th of a second.",
                    "label": 0
                },
                {
                    "sent": "So which means that we would have a fully online planning system at every point the system can plan ahead, like 4 seconds or so.",
                    "label": 0
                },
                {
                    "sent": "OK, the code for the for the algorithm is actually at my website.",
                    "label": 1
                },
                {
                    "sent": "If you want to test it and that's it, thanks.",
                    "label": 0
                },
                {
                    "sent": "Scale with number obstacles.",
                    "label": 0
                },
                {
                    "sent": "That's actually it's.",
                    "label": 0
                },
                {
                    "sent": "That would all be a matter of the of the collision detection library.",
                    "label": 0
                },
                {
                    "sent": "So the question is, how good is the collision detection library in pruning things like pruning potential collisions, which are too far away and like swift plus plus, at least it uses these octrees or whatever to prune away.",
                    "label": 0
                },
                {
                    "sent": "You know, computing collisions, which cannot be because they are too far away the objects.",
                    "label": 0
                },
                {
                    "sent": "Affect the convergence speed or damper yourself and.",
                    "label": 0
                },
                {
                    "sent": "OK. Yeah, maybe there is a point.",
                    "label": 0
                },
                {
                    "sent": "So within these grasping seen that you've seen say that there was only one object, but the point being with a finger or with hand, I sort of almost enclosed that object and there were many, many of you know, proximities here, and each of those implied a message on the belief and it really turned out that.",
                    "label": 0
                },
                {
                    "sent": "When the that's a very strong conditioning of this situation of the configuration, and it turns out if the conditioning of the situation or configuration is very strong and sort of brittle, then it takes longer for the convergence, yes, but I couldn't really say systematic that you know what the complexity of that is, just by experience here.",
                    "label": 0
                },
                {
                    "sent": "The more constrained and hard it is to fulfill all constraints then convergence is slower.",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "Contact the dynamics are no longer control appetite pending on what control signal you choose.",
                    "label": 0
                },
                {
                    "sent": "You may or may not make contact, so that's not very.",
                    "label": 0
                },
                {
                    "sent": "You know, that doesn't play very well with help with that, yes.",
                    "label": 0
                },
                {
                    "sent": "It's in in those examples that I showed here.",
                    "label": 0
                },
                {
                    "sent": "It was actually more I should actually say, proximities, not context.",
                    "label": 0
                },
                {
                    "sent": "So you know I'm measuring proximities and ensure that they are larger than a margin.",
                    "label": 0
                },
                {
                    "sent": "So within these trajectories, I really hope that there will be never really collisions.",
                    "label": 0
                },
                {
                    "sent": "I mean, that's the point, right?",
                    "label": 0
                },
                {
                    "sent": "Should be collision free.",
                    "label": 0
                },
                {
                    "sent": "No, if you look precisely at the video and be critical as you were anyway, then you've seen that it only like the smooth trajectory which you could see.",
                    "label": 0
                },
                {
                    "sent": "That's the plan.",
                    "label": 0
                },
                {
                    "sent": "One only went to like a centimeter to the objects and then again, heuristic.",
                    "label": 0
                },
                {
                    "sent": "If then the next phase is just closing and.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "Comment on all the time discretization, 'cause I've also done this kind of problem with hard boundaries in running DP.",
                    "label": 0
                },
                {
                    "sent": "After two is actually quite nasty dependence of the type of trajectory that you get.",
                    "label": 0
                },
                {
                    "sent": "Yeah, Mon features pointed me to that where is my friend anyway?",
                    "label": 0
                },
                {
                    "sent": "To like say, if you double the time scale, then you know exactly what you should do with the cost.",
                    "label": 0
                },
                {
                    "sent": "You should sort of half the cost, right?",
                    "label": 0
                },
                {
                    "sent": "But if you double the time scale, what do you do with the truncations?",
                    "label": 0
                },
                {
                    "sent": "Because I mean there is not only doing a truncation half, so it's really hard to know how could you consistently like double the time scale so such that in principle the same solution rises?",
                    "label": 0
                },
                {
                    "sent": "I would only have an idea if on the level of the message the message is a Gaussian Gaussian message, so you could sort of decade DP message when you double the time scale.",
                    "label": 0
                },
                {
                    "sent": "If you do the exact replication at every time scale, then it just has double effect in that would work, but did you have a problem with that?",
                    "label": 0
                },
                {
                    "sent": "No it at for this kind of experience.",
                    "label": 0
                },
                {
                    "sent": "We didn't change the time scale which is fixed it.",
                    "label": 0
                },
                {
                    "sent": "Transfer.",
                    "label": 0
                },
                {
                    "sent": "Typically it's 10 milliseconds.",
                    "label": 0
                },
                {
                    "sent": "Question.",
                    "label": 0
                },
                {
                    "sent": "Complexity of the pathfinding problem.",
                    "label": 0
                },
                {
                    "sent": "The classes peace based company.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to go back to the first question regarding the complexity perspective.",
                    "label": 0
                },
                {
                    "sent": "The number of objects.",
                    "label": 0
                },
                {
                    "sent": "It's been known to be double exponential, but the best result that I know is simply exponential with the perspective.",
                    "label": 0
                },
                {
                    "sent": "Number of obstacles.",
                    "label": 0
                },
                {
                    "sent": "So would you comment on the the upper bounds of produce algorithm?",
                    "label": 0
                },
                {
                    "sent": "How much ingredients you and are you doing?",
                    "label": 0
                },
                {
                    "sent": "Any approximations for that?",
                    "label": 0
                },
                {
                    "sent": "So yeah, so I'm.",
                    "label": 0
                },
                {
                    "sent": "It's really quite remote.",
                    "label": 0
                },
                {
                    "sent": "These kind of arguments that are about pathfinding in really complex scenes where the more objects you have it becomes more complex and their solutions like RTS.",
                    "label": 0
                },
                {
                    "sent": "In these kinds of methods, whereas these methods I mean there are totally local right?",
                    "label": 0
                },
                {
                    "sent": "I mean just like DDP and I could be there totally local.",
                    "label": 0
                },
                {
                    "sent": "So I there is no.",
                    "label": 0
                },
                {
                    "sent": "I mean they definitely cannot solve things like the Alpha puzzle or complex configurations like when you have many many objects, obstacles and you need to find a complex path.",
                    "label": 0
                }
            ]
        }
    }
}