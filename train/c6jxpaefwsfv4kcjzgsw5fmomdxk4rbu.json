{
    "id": "c6jxpaefwsfv4kcjzgsw5fmomdxk4rbu",
    "title": "Manifold Blurring Mean Shift Algorithms for Manifold Denoising",
    "info": {
        "author": [
            "Miguel \u00c1. Carreira-Perpi\u00f1\u00e1n, Department of Electrical Engineering and Computer Science, University of California Merced"
        ],
        "published": "July 19, 2010",
        "recorded": "June 2010",
        "category": [
            "Top->Computer Science->Machine Learning->Manifold Learning",
            "Top->Computer Science->Computer Vision"
        ]
    },
    "url": "http://videolectures.net/cvpr2010_carreira_perpinan_mbms/",
    "segmentation": [
        [
            "The next paper will be many for blowing mean shift algorithms for manifold denoising and we presented by major carrier opinion.",
            "Hello, my name is Miguel Cabrera pinion an from UC Merced and this is work with my student well then one."
        ],
        [
            "The problem of manifold denoising is depicted in this slide we have today to set one is noisy and has low dimensional structure and then we wanted to get from there a different data set which has less noise, noise or no noise at all and preserve them.",
            "Any folder structure.",
            "So the input is one data set, the output is another data set in the same space, the same number of points.",
            "These applications in computer graphics and robotics where you want to smooth the curve for a surface that corresponds to a 3D object that you have sample using laser and then you get a 3D point cloud.",
            "It also has applications in computer vision.",
            "For example, stereo motion segmentation and service based estimation.",
            "But I'm more interested in general in machine learning applications where we use this type of algorithm as a preprocessing step to improve the robustness of algorithms such as dimensionality reduction or classification or other tasks in high dimensional."
        ],
        [
            "Faces one approach to the Indian Ocean is the following.",
            "You just learn the many faults and then you project your points on it.",
            "But the problem is that dimensionality reduction algorithms, many for learning are sensitive to noise and we want to be noise before doing such a thing as a preprocessing step.",
            "In my view, such an algorithm should be as simple as possible and has I make the usage life as simple as possible as well so.",
            "It should be nonparametric making as little model assumption as possible, deterministic.",
            "So there are no local team and the results are repeatable and require a few user user parameters.",
            "So we can indeed derive such an algorithm based on two fundamental very simple ideas.",
            "Local averaging an local dimension."
        ],
        [
            "Litty for the averaging which is responsible for the noise and we're going to use a well known algorithm, which is the Gaussian blur image shift DBMS which has been used mainly for clustering in the past.",
            "The DBMS update shown in the in this life moves each data point to the local average of its neighbors.",
            "So you have here for each given data point you look at all these neighbors, and then they're all averaged using these weights in blue that you see here, which are normalized Gaussian affinity with us Caleb Sigma.",
            "So that points that are within our range of about Sigma.",
            "They have high weight points that are farther than that.",
            "Then they get discounted.",
            "It has two parameters, the scale Sigma and the number of neighbors.",
            "And then this other can be seen as either looking for most in a kernel density estimate defined by the data, or the power iteration using the random walk matrix of normalized affinity.",
            "Here is how it works."
        ],
        [
            "They come in an image for clustering.",
            "The points they're moving all the time towards the average defined by their neighbors, so they locali cluster and after a few iterations they have tightly clusters and you stop the algorithm.",
            "But at the same time, if you look at the recent innovation effect going on with things starting to take someone dimensional shapes there.",
            "So indeed, people have used this for denoising as well, mainly in the computer graphics later."
        ],
        [
            "SHHH.",
            "Here is how DBMS works for denoising.",
            "For the data set that we so we showed earlier, the red points indicate to particular points an where they're going to move under the DBMS update.",
            "Softer."
        ],
        [
            "His original data set after one iteration.",
            "This is where we get indeed.",
            "There is denoising going on very nicely noise and actually, but at the same time you see from the motion of the points that there is a lot of tangential motion.",
            "Look for example at the point here at the boundaries that move."
        ],
        [
            "So here, so that is perturbing the properties of the data.",
            "If you keep going."
        ],
        [
            "The motion doesn't happen only here, but also they're used to seeing gaps and a lot of concentration of points there.",
            "After a few iterations, the data set, the structure is an entirely destroy it.",
            "Will you get essentially a collection of class?"
        ],
        [
            "Why is this happening precisely because the DBMS update ignores entirely the firewalker from any folder.",
            "It is the noisy naturally in all directions.",
            "When you move points tangentially, when you move points within the menu for the problem is that you are changing properties of the data.",
            "For example, in the MNIST data set of handwritten digits, if you move points along the manifold, what happens is that you are changing properties such as the handwriting style or the thickness, or this plan to visit, and you don't want to do that particular classification.",
            "You cannot solve this problem by simply using a smaller scale or using an exotic kernel, and this gets worse in high dimensions with non uniform.",
            "Update them so from this picture it is clear that the way to correct this is to to remove that."
        ],
        [
            "Motion, and that's exactly what we do.",
            "So whatever rhythm has only two fundamental steps up victory steps that does denoising and what it does is local clustering with a DBMS update mean shifter data.",
            "We show before and then we apply a corrector step that removes the tangential motion.",
            "The way to do this very simply that works in high dimensions, is simply by estimating locali the manifold linearly using PCA.",
            "That gives us the.",
            "The best linear dimensional manifold in terms of the construction error, and then, once we have subtracted that motion, we iterate.",
            "So."
        ],
        [
            "So does it look like for the same example, the blue point now indicates where the points are going to move under the new MMIS update and the red ones indicate where they would move with the DBMS update."
        ],
        [
            "So we still get very nicely noising those blue lines there, indicating their local tangent spaces as they are estimated."
        ],
        [
            "Keep iterating."
        ],
        [
            "Dating and we get almost perfect denoising by with very little distortion to the manifold.",
            "Notice how the DBMS point will still keep moving tangentially and our points remain their stack.",
            "On the manifold."
        ],
        [
            "This is the complete algorithm for each point we either use the full graph or the nearest nearest neighbors.",
            "Then we compute the DBMS update here.",
            "Compute the local PCA for that particular point and then subtract the motion along the tangent space.",
            "And then we trade this for points and keep iterating until we stop.",
            "There are three parameters L. The local dimensionality of a manifold.",
            "K The number of neighbors and Sigma the scale of the mean shifter step."
        ],
        [
            "This general algorithm has several interesting particular cases.",
            "We can do nothing, nothing at all as a particular case, we can do PCA.",
            "We can do DBMS as shown before, and there is one special case of particular interest which we call LTP for local tension projection, where we take sigmas Infinity and we use a K nearest neighbor graph."
        ],
        [
            "That algorithm is here and what it does is for each point it computes the K nearest neighbors.",
            "Compute the PCA for that point and simply project it there and then keeps iterating until we stop.",
            "Because only two parameters, so it is easier to use and The thing is that it gives almost as good results as the merge with other values of Sigma."
        ],
        [
            "The cost of the algorithm has two parts for the ambient for the DBMS step at the neighbors.",
            "Naively we have another square cost on the number of points.",
            "If we do not update the neighbors that we just did, then that becomes linear on it and then we have another linear cost on for computing the local PC's.",
            "There are various speed up, so we're going to play here.",
            "The convergence, if you're interested in this, see me at the poster.",
            "It doesn't really matter in practice because we're not going to let their within transport too long anyway.",
            "After one to five iterations.",
            "Generally we have sufficiently noisy.",
            "So we need to also stopping criterion and to stop the algorithm.",
            "A practical indicator is to look at the histogram of variances in the normal direction versus their data generation direction, and I will show you that we."
        ],
        [
            "An example.",
            "It is our first experiment is a toy and spiral into the IT is noisy and it has outliers uniformly distributed on this box here.",
            "So we see two things here in this rose in the middle.",
            "This is the merge with graph on the LP algorithm.",
            "We get very effectively noising an for a large number of iterations and the spiral remains the structure of the spiral remains an altered.",
            "The thing to notice also that the outliers are not getting in the way, so the points that are near the manifold noisy points, they get the noise perfectly as if they were not not liars whatsoever.",
            "They don't have any effect.",
            "To understand that again, come to the post if you're interested because it takes a little to explain demons in the last row, it does the noise, but it also alters significantly than many fallen destroy it in a few iterations."
        ],
        [
            "Here we use the algorithm to preprocess the Swiss roll.",
            "This is a high dimensional series where we have lived three 200 dimensions.",
            "97 dimensions are noise are pure noise and then what we do is we apply ISOMAP or Lt essay for doing dimensionality reduction.",
            "Disrespectful methods that are quite sensitive to noise.",
            "So indeed, as with the noise.",
            "The structure of the schedule changes little, so it is still as usual.",
            "After a few iterations, but without the noise and we can see how I sum up and Lt essay in the original data set, they don't work, but denoising proceeds they start to give better and better results.",
            "The histograms on the right show.",
            "Assessing the normal direction and the variances on the tangential direction.",
            "So these are the normal the normal direction.",
            "Normal to the local PCA.",
            "The local tangent space estimated.",
            "And in the first iteration, the first original data set we are here, we have a large variance there does because there is noise, but after one iteration we move here practically all the noise normally has been removed, and then in one or two iterations more it is almost gone.",
            "However, tangential variances.",
            "They move very little and they stabilize.",
            "This gives us a stopping criterion because we can simply stop when the normal variances are sufficiently small compared to the tangential ones.",
            "And it indicates that there are some is doing denoising properly."
        ],
        [
            "The algorithm performs quite well and there are various wide range of parameters here.",
            "We show for this same switch role will happens over iterations for various values of the number of neighbors and the number of dimensions.",
            "So notice that in all cases this is the original data set and we're comparing here with the ground truth, which we can do for this visual.",
            "So in all cases, no matter how we choose the parameters for the ranges here, we do better than originally, and we can do very well for a range alert number of iterations for a wide range of neighbors, Ann.",
            "It is of course more sensitive to the dimension."
        ],
        [
            "So we feel that things such as holes in the data, varying density, very noise, but in amount of noise depending where you're in the manifold, self intersections and gaps there within that reasonably well seeming at the poster for this."
        ],
        [
            "You're interested now I'm going to show you results where we apply the noise into the image data set of handwritten digits for classification, which is a well known benchmark.",
            "So what we do is that we take the entire training set of 60,000 images, like those you see there, and then we deny them with just one iteration of mess and our algorithms.",
            "And then we feed that to a nearest neighbor classifier.",
            "We don't do any provision of any kind of data.",
            "In particular, we don't with small theater we don't censor it or anything like that.",
            "In fact, everything doesn't know that the data images, they're just high dimensional column vectors.",
            "And if you shopped the pixels in the image, there should be the same.",
            "Then after the noising we have our classifier and we test it on the 10,000 training images which are noisy.",
            "So."
        ],
        [
            "These are the.",
            "The result what we are seeing here are the training set digits after having been denoised, so on the in each pair of images on the left we see the original noisy image.",
            "On the right we see where we get after the noisy.",
            "The thing that is most obvious at first sight is that the region looks smoother.",
            "In fact, it looks easier on the eyes to read and one would imagine that this will help classification, but performed is smooth in this kind of antialiasing effect that we that we get.",
            "If you look closely, you will see a number of very sophisticated corrections, almost done as if they were done by a person correcting these digits by hand.",
            "So we can get rid of speckled noise like here or here.",
            "The algorithm doesn't know that that is speckled noise, it simply is unusual with respect to the neighbors of that those data points.",
            "We can also remove the strokes that are odd, like here, here or here.",
            "For example.",
            "We can reshape this say like that.",
            "That nine will remove also that stroke.",
            "And Conversely we can fill in where gaps exist that look unusual, like for example groups here.",
            "Or gaps here.",
            "Here here, so it fills gaps where they need to be filled and it doesn't fill them or are removing strokes where they don't need to."
        ],
        [
            "Here are the results.",
            "Now classifying within five photos validation on the training set.",
            "And these are the optimum values that we achieved dimensionality of nine.",
            "114 years neighbors and Sigma Scale Sigma 695.",
            "And we decrease the error in this optimal case from 3.06% to 1.997% of 36% improvement.",
            "The baseline is there and not these, importantly, that for practical parameter values we decrease the error.",
            "The best one is here, an LDP then particular case I mentioned before is quite close to it as well.",
            "The we this happens consistently and not just for using the whole training set, but using parts of it.",
            "The robots are over random subsets of the data and we see that these two lines here, this is this is the MSN LTP consistently beat the original and also a DBMS which is here on PC."
        ],
        [
            "The same thing can be seen in the confusion matrix individually.",
            "For points without denoising and with the noise in the improvement is seen in the green squares here.",
            "So practically everywhere we get better."
        ],
        [
            "Chance.",
            "And I'm going to skip this.",
            "So in conclu."
        ],
        [
            "Mercy is a genetic protein algorithm for data with low intrinsic dimensionality.",
            "You can apply this prior to a practical anything that you want to do with data.",
            "Any supervisor, unsupervised learning algorithm and a particular case of it.",
            "LTP is much simpler to use and give close to optimal results.",
            "So you could start with this and then change Sigma to improve.",
            "If it works by doing two things, predict or step that averages and the noise is an corrector.",
            "Steps that corrector steps that make sure that you don't move tangentially on the manifold.",
            "It is nonparametric deterministic and few user has a future parameters and achieves effectively notion of iterations while distorting very little the manifold.",
            "And being an affected by outliers, there are several extensions to it.",
            "A particularly interesting one is to estimate the dimensionality locally for each point.",
            "This is particularly useful if you have a collection of manifolds, each of which has different dimensionality and the MATLAB code will be soon in the in the website, thank you."
        ],
        [
            "A very nice work when you did the nearest neighbor did you do any denoising of the test cases using the manifold?",
            "So we did a number of such such things and they all work well.",
            "They all improved their baseline, but the one that works best.",
            "I'm not sure exactly why it was not the noise in the test set.",
            "Thank you.",
            "I very nice talk, could you comment on some of the cases you think this algorithm would breakdown?",
            "Well, like any other algorithm, if you get through it but parameters so it works well within a certain range.",
            "If the neighbors is very small, then your tiny space will almost be randomly estimated.",
            "Increase the number of neighbors.",
            "It is quite robust Sigma and it is also reasonably robust, robust to the dimension because I already mentioned that is subtract motion from the one that you would do with the VMS alone, and eventually this original original job.",
            "Anne.",
            "Player calculating the local PC S and projects in the data to that local PC your.",
            "Approximating the.",
            "Nonlinear.",
            "Non linearity of the.",
            "Data by a set of linear approximation.",
            "Is that right?",
            "But what is the question?",
            "No, my question is that you are approximating and nonlinear set of data.",
            "Yes, by projecting them into local PCs, yes, and so you're actually calculating like Polygon our partial Polygon that approximates a nonlinear data with linear local linear data.",
            "Is that right, yes.",
            "OK.",
            "Yes, and there is an approximation involved there for sure.",
            "OK, so how do you?",
            "How do you?",
            "Didn't quite understand how do you.",
            "What is the length of this?",
            "Each of these segments, and then then?",
            "Then it doesn't really matter because we just do this for each point and what we want is to move that point somewhere.",
            "So when you move to another point is going to have different segment and a different orientation.",
            "So there is no length of the segments or anything like that, it's just used to let those points fall orthogonally onto the manifold.",
            "Yeah, but but for a look for a for proximity you have a number of points project until 1.",
            "One local eigenvector, is that right?",
            "Yeah, maybe with your thinking is we're ending ending with a piecewise linear?",
            "Yeah no it doesn't happen.",
            "That doesn't happen.",
            "It's not like.",
            "Other things you do have to discuss over lunch, so let's break it now.",
            "Thank you very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The next paper will be many for blowing mean shift algorithms for manifold denoising and we presented by major carrier opinion.",
                    "label": 0
                },
                {
                    "sent": "Hello, my name is Miguel Cabrera pinion an from UC Merced and this is work with my student well then one.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The problem of manifold denoising is depicted in this slide we have today to set one is noisy and has low dimensional structure and then we wanted to get from there a different data set which has less noise, noise or no noise at all and preserve them.",
                    "label": 0
                },
                {
                    "sent": "Any folder structure.",
                    "label": 0
                },
                {
                    "sent": "So the input is one data set, the output is another data set in the same space, the same number of points.",
                    "label": 0
                },
                {
                    "sent": "These applications in computer graphics and robotics where you want to smooth the curve for a surface that corresponds to a 3D object that you have sample using laser and then you get a 3D point cloud.",
                    "label": 1
                },
                {
                    "sent": "It also has applications in computer vision.",
                    "label": 0
                },
                {
                    "sent": "For example, stereo motion segmentation and service based estimation.",
                    "label": 1
                },
                {
                    "sent": "But I'm more interested in general in machine learning applications where we use this type of algorithm as a preprocessing step to improve the robustness of algorithms such as dimensionality reduction or classification or other tasks in high dimensional.",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Faces one approach to the Indian Ocean is the following.",
                    "label": 0
                },
                {
                    "sent": "You just learn the many faults and then you project your points on it.",
                    "label": 1
                },
                {
                    "sent": "But the problem is that dimensionality reduction algorithms, many for learning are sensitive to noise and we want to be noise before doing such a thing as a preprocessing step.",
                    "label": 1
                },
                {
                    "sent": "In my view, such an algorithm should be as simple as possible and has I make the usage life as simple as possible as well so.",
                    "label": 1
                },
                {
                    "sent": "It should be nonparametric making as little model assumption as possible, deterministic.",
                    "label": 0
                },
                {
                    "sent": "So there are no local team and the results are repeatable and require a few user user parameters.",
                    "label": 0
                },
                {
                    "sent": "So we can indeed derive such an algorithm based on two fundamental very simple ideas.",
                    "label": 0
                },
                {
                    "sent": "Local averaging an local dimension.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Litty for the averaging which is responsible for the noise and we're going to use a well known algorithm, which is the Gaussian blur image shift DBMS which has been used mainly for clustering in the past.",
                    "label": 0
                },
                {
                    "sent": "The DBMS update shown in the in this life moves each data point to the local average of its neighbors.",
                    "label": 1
                },
                {
                    "sent": "So you have here for each given data point you look at all these neighbors, and then they're all averaged using these weights in blue that you see here, which are normalized Gaussian affinity with us Caleb Sigma.",
                    "label": 0
                },
                {
                    "sent": "So that points that are within our range of about Sigma.",
                    "label": 0
                },
                {
                    "sent": "They have high weight points that are farther than that.",
                    "label": 0
                },
                {
                    "sent": "Then they get discounted.",
                    "label": 0
                },
                {
                    "sent": "It has two parameters, the scale Sigma and the number of neighbors.",
                    "label": 1
                },
                {
                    "sent": "And then this other can be seen as either looking for most in a kernel density estimate defined by the data, or the power iteration using the random walk matrix of normalized affinity.",
                    "label": 0
                },
                {
                    "sent": "Here is how it works.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "They come in an image for clustering.",
                    "label": 0
                },
                {
                    "sent": "The points they're moving all the time towards the average defined by their neighbors, so they locali cluster and after a few iterations they have tightly clusters and you stop the algorithm.",
                    "label": 0
                },
                {
                    "sent": "But at the same time, if you look at the recent innovation effect going on with things starting to take someone dimensional shapes there.",
                    "label": 0
                },
                {
                    "sent": "So indeed, people have used this for denoising as well, mainly in the computer graphics later.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "SHHH.",
                    "label": 0
                },
                {
                    "sent": "Here is how DBMS works for denoising.",
                    "label": 0
                },
                {
                    "sent": "For the data set that we so we showed earlier, the red points indicate to particular points an where they're going to move under the DBMS update.",
                    "label": 0
                },
                {
                    "sent": "Softer.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "His original data set after one iteration.",
                    "label": 0
                },
                {
                    "sent": "This is where we get indeed.",
                    "label": 0
                },
                {
                    "sent": "There is denoising going on very nicely noise and actually, but at the same time you see from the motion of the points that there is a lot of tangential motion.",
                    "label": 0
                },
                {
                    "sent": "Look for example at the point here at the boundaries that move.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here, so that is perturbing the properties of the data.",
                    "label": 0
                },
                {
                    "sent": "If you keep going.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The motion doesn't happen only here, but also they're used to seeing gaps and a lot of concentration of points there.",
                    "label": 0
                },
                {
                    "sent": "After a few iterations, the data set, the structure is an entirely destroy it.",
                    "label": 0
                },
                {
                    "sent": "Will you get essentially a collection of class?",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Why is this happening precisely because the DBMS update ignores entirely the firewalker from any folder.",
                    "label": 0
                },
                {
                    "sent": "It is the noisy naturally in all directions.",
                    "label": 0
                },
                {
                    "sent": "When you move points tangentially, when you move points within the menu for the problem is that you are changing properties of the data.",
                    "label": 1
                },
                {
                    "sent": "For example, in the MNIST data set of handwritten digits, if you move points along the manifold, what happens is that you are changing properties such as the handwriting style or the thickness, or this plan to visit, and you don't want to do that particular classification.",
                    "label": 1
                },
                {
                    "sent": "You cannot solve this problem by simply using a smaller scale or using an exotic kernel, and this gets worse in high dimensions with non uniform.",
                    "label": 0
                },
                {
                    "sent": "Update them so from this picture it is clear that the way to correct this is to to remove that.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Motion, and that's exactly what we do.",
                    "label": 0
                },
                {
                    "sent": "So whatever rhythm has only two fundamental steps up victory steps that does denoising and what it does is local clustering with a DBMS update mean shifter data.",
                    "label": 1
                },
                {
                    "sent": "We show before and then we apply a corrector step that removes the tangential motion.",
                    "label": 0
                },
                {
                    "sent": "The way to do this very simply that works in high dimensions, is simply by estimating locali the manifold linearly using PCA.",
                    "label": 0
                },
                {
                    "sent": "That gives us the.",
                    "label": 0
                },
                {
                    "sent": "The best linear dimensional manifold in terms of the construction error, and then, once we have subtracted that motion, we iterate.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So does it look like for the same example, the blue point now indicates where the points are going to move under the new MMIS update and the red ones indicate where they would move with the DBMS update.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we still get very nicely noising those blue lines there, indicating their local tangent spaces as they are estimated.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Keep iterating.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Dating and we get almost perfect denoising by with very little distortion to the manifold.",
                    "label": 0
                },
                {
                    "sent": "Notice how the DBMS point will still keep moving tangentially and our points remain their stack.",
                    "label": 0
                },
                {
                    "sent": "On the manifold.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is the complete algorithm for each point we either use the full graph or the nearest nearest neighbors.",
                    "label": 1
                },
                {
                    "sent": "Then we compute the DBMS update here.",
                    "label": 0
                },
                {
                    "sent": "Compute the local PCA for that particular point and then subtract the motion along the tangent space.",
                    "label": 0
                },
                {
                    "sent": "And then we trade this for points and keep iterating until we stop.",
                    "label": 1
                },
                {
                    "sent": "There are three parameters L. The local dimensionality of a manifold.",
                    "label": 0
                },
                {
                    "sent": "K The number of neighbors and Sigma the scale of the mean shifter step.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This general algorithm has several interesting particular cases.",
                    "label": 0
                },
                {
                    "sent": "We can do nothing, nothing at all as a particular case, we can do PCA.",
                    "label": 0
                },
                {
                    "sent": "We can do DBMS as shown before, and there is one special case of particular interest which we call LTP for local tension projection, where we take sigmas Infinity and we use a K nearest neighbor graph.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That algorithm is here and what it does is for each point it computes the K nearest neighbors.",
                    "label": 1
                },
                {
                    "sent": "Compute the PCA for that point and simply project it there and then keeps iterating until we stop.",
                    "label": 1
                },
                {
                    "sent": "Because only two parameters, so it is easier to use and The thing is that it gives almost as good results as the merge with other values of Sigma.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The cost of the algorithm has two parts for the ambient for the DBMS step at the neighbors.",
                    "label": 0
                },
                {
                    "sent": "Naively we have another square cost on the number of points.",
                    "label": 0
                },
                {
                    "sent": "If we do not update the neighbors that we just did, then that becomes linear on it and then we have another linear cost on for computing the local PC's.",
                    "label": 0
                },
                {
                    "sent": "There are various speed up, so we're going to play here.",
                    "label": 0
                },
                {
                    "sent": "The convergence, if you're interested in this, see me at the poster.",
                    "label": 0
                },
                {
                    "sent": "It doesn't really matter in practice because we're not going to let their within transport too long anyway.",
                    "label": 0
                },
                {
                    "sent": "After one to five iterations.",
                    "label": 0
                },
                {
                    "sent": "Generally we have sufficiently noisy.",
                    "label": 0
                },
                {
                    "sent": "So we need to also stopping criterion and to stop the algorithm.",
                    "label": 0
                },
                {
                    "sent": "A practical indicator is to look at the histogram of variances in the normal direction versus their data generation direction, and I will show you that we.",
                    "label": 1
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "An example.",
                    "label": 0
                },
                {
                    "sent": "It is our first experiment is a toy and spiral into the IT is noisy and it has outliers uniformly distributed on this box here.",
                    "label": 0
                },
                {
                    "sent": "So we see two things here in this rose in the middle.",
                    "label": 0
                },
                {
                    "sent": "This is the merge with graph on the LP algorithm.",
                    "label": 0
                },
                {
                    "sent": "We get very effectively noising an for a large number of iterations and the spiral remains the structure of the spiral remains an altered.",
                    "label": 0
                },
                {
                    "sent": "The thing to notice also that the outliers are not getting in the way, so the points that are near the manifold noisy points, they get the noise perfectly as if they were not not liars whatsoever.",
                    "label": 0
                },
                {
                    "sent": "They don't have any effect.",
                    "label": 0
                },
                {
                    "sent": "To understand that again, come to the post if you're interested because it takes a little to explain demons in the last row, it does the noise, but it also alters significantly than many fallen destroy it in a few iterations.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here we use the algorithm to preprocess the Swiss roll.",
                    "label": 0
                },
                {
                    "sent": "This is a high dimensional series where we have lived three 200 dimensions.",
                    "label": 0
                },
                {
                    "sent": "97 dimensions are noise are pure noise and then what we do is we apply ISOMAP or Lt essay for doing dimensionality reduction.",
                    "label": 0
                },
                {
                    "sent": "Disrespectful methods that are quite sensitive to noise.",
                    "label": 0
                },
                {
                    "sent": "So indeed, as with the noise.",
                    "label": 0
                },
                {
                    "sent": "The structure of the schedule changes little, so it is still as usual.",
                    "label": 0
                },
                {
                    "sent": "After a few iterations, but without the noise and we can see how I sum up and Lt essay in the original data set, they don't work, but denoising proceeds they start to give better and better results.",
                    "label": 0
                },
                {
                    "sent": "The histograms on the right show.",
                    "label": 0
                },
                {
                    "sent": "Assessing the normal direction and the variances on the tangential direction.",
                    "label": 0
                },
                {
                    "sent": "So these are the normal the normal direction.",
                    "label": 0
                },
                {
                    "sent": "Normal to the local PCA.",
                    "label": 0
                },
                {
                    "sent": "The local tangent space estimated.",
                    "label": 0
                },
                {
                    "sent": "And in the first iteration, the first original data set we are here, we have a large variance there does because there is noise, but after one iteration we move here practically all the noise normally has been removed, and then in one or two iterations more it is almost gone.",
                    "label": 0
                },
                {
                    "sent": "However, tangential variances.",
                    "label": 0
                },
                {
                    "sent": "They move very little and they stabilize.",
                    "label": 0
                },
                {
                    "sent": "This gives us a stopping criterion because we can simply stop when the normal variances are sufficiently small compared to the tangential ones.",
                    "label": 0
                },
                {
                    "sent": "And it indicates that there are some is doing denoising properly.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The algorithm performs quite well and there are various wide range of parameters here.",
                    "label": 0
                },
                {
                    "sent": "We show for this same switch role will happens over iterations for various values of the number of neighbors and the number of dimensions.",
                    "label": 1
                },
                {
                    "sent": "So notice that in all cases this is the original data set and we're comparing here with the ground truth, which we can do for this visual.",
                    "label": 0
                },
                {
                    "sent": "So in all cases, no matter how we choose the parameters for the ranges here, we do better than originally, and we can do very well for a range alert number of iterations for a wide range of neighbors, Ann.",
                    "label": 1
                },
                {
                    "sent": "It is of course more sensitive to the dimension.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we feel that things such as holes in the data, varying density, very noise, but in amount of noise depending where you're in the manifold, self intersections and gaps there within that reasonably well seeming at the poster for this.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You're interested now I'm going to show you results where we apply the noise into the image data set of handwritten digits for classification, which is a well known benchmark.",
                    "label": 0
                },
                {
                    "sent": "So what we do is that we take the entire training set of 60,000 images, like those you see there, and then we deny them with just one iteration of mess and our algorithms.",
                    "label": 0
                },
                {
                    "sent": "And then we feed that to a nearest neighbor classifier.",
                    "label": 1
                },
                {
                    "sent": "We don't do any provision of any kind of data.",
                    "label": 1
                },
                {
                    "sent": "In particular, we don't with small theater we don't censor it or anything like that.",
                    "label": 0
                },
                {
                    "sent": "In fact, everything doesn't know that the data images, they're just high dimensional column vectors.",
                    "label": 0
                },
                {
                    "sent": "And if you shopped the pixels in the image, there should be the same.",
                    "label": 0
                },
                {
                    "sent": "Then after the noising we have our classifier and we test it on the 10,000 training images which are noisy.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "These are the.",
                    "label": 0
                },
                {
                    "sent": "The result what we are seeing here are the training set digits after having been denoised, so on the in each pair of images on the left we see the original noisy image.",
                    "label": 1
                },
                {
                    "sent": "On the right we see where we get after the noisy.",
                    "label": 0
                },
                {
                    "sent": "The thing that is most obvious at first sight is that the region looks smoother.",
                    "label": 0
                },
                {
                    "sent": "In fact, it looks easier on the eyes to read and one would imagine that this will help classification, but performed is smooth in this kind of antialiasing effect that we that we get.",
                    "label": 0
                },
                {
                    "sent": "If you look closely, you will see a number of very sophisticated corrections, almost done as if they were done by a person correcting these digits by hand.",
                    "label": 0
                },
                {
                    "sent": "So we can get rid of speckled noise like here or here.",
                    "label": 0
                },
                {
                    "sent": "The algorithm doesn't know that that is speckled noise, it simply is unusual with respect to the neighbors of that those data points.",
                    "label": 0
                },
                {
                    "sent": "We can also remove the strokes that are odd, like here, here or here.",
                    "label": 0
                },
                {
                    "sent": "For example.",
                    "label": 0
                },
                {
                    "sent": "We can reshape this say like that.",
                    "label": 0
                },
                {
                    "sent": "That nine will remove also that stroke.",
                    "label": 0
                },
                {
                    "sent": "And Conversely we can fill in where gaps exist that look unusual, like for example groups here.",
                    "label": 0
                },
                {
                    "sent": "Or gaps here.",
                    "label": 0
                },
                {
                    "sent": "Here here, so it fills gaps where they need to be filled and it doesn't fill them or are removing strokes where they don't need to.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here are the results.",
                    "label": 0
                },
                {
                    "sent": "Now classifying within five photos validation on the training set.",
                    "label": 1
                },
                {
                    "sent": "And these are the optimum values that we achieved dimensionality of nine.",
                    "label": 0
                },
                {
                    "sent": "114 years neighbors and Sigma Scale Sigma 695.",
                    "label": 0
                },
                {
                    "sent": "And we decrease the error in this optimal case from 3.06% to 1.997% of 36% improvement.",
                    "label": 1
                },
                {
                    "sent": "The baseline is there and not these, importantly, that for practical parameter values we decrease the error.",
                    "label": 0
                },
                {
                    "sent": "The best one is here, an LDP then particular case I mentioned before is quite close to it as well.",
                    "label": 0
                },
                {
                    "sent": "The we this happens consistently and not just for using the whole training set, but using parts of it.",
                    "label": 0
                },
                {
                    "sent": "The robots are over random subsets of the data and we see that these two lines here, this is this is the MSN LTP consistently beat the original and also a DBMS which is here on PC.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The same thing can be seen in the confusion matrix individually.",
                    "label": 0
                },
                {
                    "sent": "For points without denoising and with the noise in the improvement is seen in the green squares here.",
                    "label": 0
                },
                {
                    "sent": "So practically everywhere we get better.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Chance.",
                    "label": 0
                },
                {
                    "sent": "And I'm going to skip this.",
                    "label": 0
                },
                {
                    "sent": "So in conclu.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Mercy is a genetic protein algorithm for data with low intrinsic dimensionality.",
                    "label": 1
                },
                {
                    "sent": "You can apply this prior to a practical anything that you want to do with data.",
                    "label": 1
                },
                {
                    "sent": "Any supervisor, unsupervised learning algorithm and a particular case of it.",
                    "label": 0
                },
                {
                    "sent": "LTP is much simpler to use and give close to optimal results.",
                    "label": 0
                },
                {
                    "sent": "So you could start with this and then change Sigma to improve.",
                    "label": 0
                },
                {
                    "sent": "If it works by doing two things, predict or step that averages and the noise is an corrector.",
                    "label": 0
                },
                {
                    "sent": "Steps that corrector steps that make sure that you don't move tangentially on the manifold.",
                    "label": 1
                },
                {
                    "sent": "It is nonparametric deterministic and few user has a future parameters and achieves effectively notion of iterations while distorting very little the manifold.",
                    "label": 0
                },
                {
                    "sent": "And being an affected by outliers, there are several extensions to it.",
                    "label": 0
                },
                {
                    "sent": "A particularly interesting one is to estimate the dimensionality locally for each point.",
                    "label": 0
                },
                {
                    "sent": "This is particularly useful if you have a collection of manifolds, each of which has different dimensionality and the MATLAB code will be soon in the in the website, thank you.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A very nice work when you did the nearest neighbor did you do any denoising of the test cases using the manifold?",
                    "label": 0
                },
                {
                    "sent": "So we did a number of such such things and they all work well.",
                    "label": 0
                },
                {
                    "sent": "They all improved their baseline, but the one that works best.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure exactly why it was not the noise in the test set.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "I very nice talk, could you comment on some of the cases you think this algorithm would breakdown?",
                    "label": 0
                },
                {
                    "sent": "Well, like any other algorithm, if you get through it but parameters so it works well within a certain range.",
                    "label": 0
                },
                {
                    "sent": "If the neighbors is very small, then your tiny space will almost be randomly estimated.",
                    "label": 0
                },
                {
                    "sent": "Increase the number of neighbors.",
                    "label": 0
                },
                {
                    "sent": "It is quite robust Sigma and it is also reasonably robust, robust to the dimension because I already mentioned that is subtract motion from the one that you would do with the VMS alone, and eventually this original original job.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "Player calculating the local PC S and projects in the data to that local PC your.",
                    "label": 0
                },
                {
                    "sent": "Approximating the.",
                    "label": 0
                },
                {
                    "sent": "Nonlinear.",
                    "label": 0
                },
                {
                    "sent": "Non linearity of the.",
                    "label": 0
                },
                {
                    "sent": "Data by a set of linear approximation.",
                    "label": 0
                },
                {
                    "sent": "Is that right?",
                    "label": 0
                },
                {
                    "sent": "But what is the question?",
                    "label": 0
                },
                {
                    "sent": "No, my question is that you are approximating and nonlinear set of data.",
                    "label": 0
                },
                {
                    "sent": "Yes, by projecting them into local PCs, yes, and so you're actually calculating like Polygon our partial Polygon that approximates a nonlinear data with linear local linear data.",
                    "label": 0
                },
                {
                    "sent": "Is that right, yes.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Yes, and there is an approximation involved there for sure.",
                    "label": 0
                },
                {
                    "sent": "OK, so how do you?",
                    "label": 0
                },
                {
                    "sent": "How do you?",
                    "label": 0
                },
                {
                    "sent": "Didn't quite understand how do you.",
                    "label": 0
                },
                {
                    "sent": "What is the length of this?",
                    "label": 0
                },
                {
                    "sent": "Each of these segments, and then then?",
                    "label": 0
                },
                {
                    "sent": "Then it doesn't really matter because we just do this for each point and what we want is to move that point somewhere.",
                    "label": 0
                },
                {
                    "sent": "So when you move to another point is going to have different segment and a different orientation.",
                    "label": 0
                },
                {
                    "sent": "So there is no length of the segments or anything like that, it's just used to let those points fall orthogonally onto the manifold.",
                    "label": 0
                },
                {
                    "sent": "Yeah, but but for a look for a for proximity you have a number of points project until 1.",
                    "label": 0
                },
                {
                    "sent": "One local eigenvector, is that right?",
                    "label": 0
                },
                {
                    "sent": "Yeah, maybe with your thinking is we're ending ending with a piecewise linear?",
                    "label": 0
                },
                {
                    "sent": "Yeah no it doesn't happen.",
                    "label": 0
                },
                {
                    "sent": "That doesn't happen.",
                    "label": 0
                },
                {
                    "sent": "It's not like.",
                    "label": 0
                },
                {
                    "sent": "Other things you do have to discuss over lunch, so let's break it now.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                }
            ]
        }
    }
}