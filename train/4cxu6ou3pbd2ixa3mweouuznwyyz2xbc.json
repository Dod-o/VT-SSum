{
    "id": "4cxu6ou3pbd2ixa3mweouuznwyyz2xbc",
    "title": "Multi-way Gaussian Graphical Models with Application to Multivariate Lattice Data",
    "info": {
        "author": [
            "Adrian Dobra, University of Washington"
        ],
        "published": "May 6, 2011",
        "recorded": "April 2011",
        "category": [
            "Top->Computer Science->Machine Learning->Gaussian Processes"
        ]
    },
    "url": "http://videolectures.net/aistats2011_dobra_application/",
    "segmentation": [
        [
            "OK, thank you so much.",
            "Good morning well.",
            "Stay awake for some of us, um, So what I'm going to talk about today are our graphs and these graphs."
        ],
        [
            "Will come in various forms.",
            "You know with this audience you are.",
            "You are familiar with graphical models really well.",
            "So in graphical models you deal with the situation in which you want to model dependencies through a graphical structure and that graphical structure is typically unknown, so that will be one aspect of the of the graphs.",
            "Another aspect of graphs is something like that, right?",
            "So what you're looking at here?",
            "I mean you are looking at the US map, you're looking at the Continental States and the Continental States represent vertices in a graph whose edges represent the neighbors of each state, right?",
            "So this is an example of a graphical structure that is known, and it's an example of a graphical structure.",
            "That needs to be taken into account if you have data that is observed.",
            "In each state.",
            "So say if if you have observations that that belong to each of these states right then then you would somehow want to take this particular graphical structure into account, right?",
            "So when I refer to spatial dependence, that's what I'm going to be referring to.",
            "OK, so."
        ],
        [
            "So the US graph has structure in."
        ],
        [
            "I mean, it's not.",
            "It's not obvious if you if you look at it from this point of view.",
            "But now if you look at graph decompositions.",
            "Then then, then, then you got."
        ],
        [
            "You get these subsets of states.",
            "These these.",
            "These are the 13 maximal prime subgraphs of the US neighborhood graph, and I thought I should show this to you because, well, it is unique.",
            "You know that's never going to change, hopefully, and it plays a really, really big role in the work we represent later on.",
            "Because you see these maximal prime sub graphs represent component that would help.",
            "Uh, the methodology we will develop to be broken into components.",
            "So apply, divide, divide and conquer method that would.",
            "That would help us with our analysis right?",
            "So for example here, see component one is Alabama, Florida and Georgia right?",
            "And then you see down here."
        ],
        [
            "Triangle right?",
            "So this way see you, you break the graph into these compare."
        ],
        [
            "Comments and then you can simplify your problem later on.",
            "You also remark here this huge maximum prime component component too, right?",
            "Fine so so."
        ],
        [
            "Um, let's let's look at the data set right?",
            "So so this data set comes from SCR and it represents.",
            "Sounds mortality counts for 11 times of cancers, so so our datum is a 49 by 11 matrix.",
            "OK, so so on one dimension you have the 49 States and you already know the dependencies you are trying to represent.",
            "That's the graph I've been showing you so far, right?",
            "And then at a different dimension you have your types of cancer types, right?",
            "And what we will do is try to infer the dependencies among the cancers.",
            "So you have 11 variables, right?",
            "Through graphs graphs you don't know in the presence of the spatial dependencies, the dependencies you know, right?",
            "So, so that's what we are going to try to do.",
            "OK.",
            "Uh, so here are the chloroplasts maths for the four types of cancers, right?",
            "And now you see, see the darker color means means higher?"
        ],
        [
            "Mortality rates the lighter color means lower mortality rates, right?",
            "So what you see in these plot is that there is a clear spatial dependence for each type of cancers.",
            "What you see in this plot is that the spatial dependencies change somehow according to cancer type, right?",
            "So what we would like to do is somehow express the dependencies that exist in these well 11 chloro plat Maps through graph.",
            "So just if we just refer to these four types of cancers, what we would like to do is infer edges right?",
            "And it's not necessarily important which edges are in or out, it's the graph looking at multiple graphs multiple.",
            "A possible graph is what we will be interested in.",
            "Right, so that's our problem.",
            "OK, so so let's see how to solve this, how we can solve this problem, right?",
            "So now we will step back and we're going to look at the classical definition of a graphical model and well of Gaussian graphical model, right?",
            "And you I'm sure you are familiar with it, right?",
            "So our parametrization is in terms of a precision matrix.",
            "OK, right so so now I have a graph.",
            "This graph has vertices and edges and edges represent conditional independence, ease of condition, independence of two given variable.",
            "Given the given, the rest right so see."
        ],
        [
            "This matrix K will belong to a cone.",
            "Of symmetric positive definite matrices that is defined by by the graph right?",
            "So these are our model parameter model parameters are represented by this matrix K and this is the classical definition that appears in the literature and that dates back to Dempster.",
            "Alright.",
            "No, that that's the really interesting part.",
            "So there has been, you know that the literature on spatial Epidemiology aerial data has hundreds of papers in it, an essentially most of these papers treat graphs in a very special form.",
            "They don't read graphs."
        ],
        [
            "The way we just looked at it.",
            "Altogether right, they treat graphs and I'll come back to that slide like like."
        ],
        [
            "This right, so the red that see the graph in Red Sea is is the graph we just introduced.",
            "And now see this table.",
            "Gives the neighbors of each state, right?",
            "So we list all the States and then released all all the states that share a border with that particular state, right?",
            "So this means if I take each given state, say Alabama, Alabama, right, then whatever happens, whatever dependencies come in?",
            "Uh, given the other states.",
            "What's going to matter are only the neighbors.",
            "The direct neighbors available, right?",
            "So you'll say, OK, this this representation is equivalent with the vertices and edges representation.",
            "We have been looking at right?",
            "It is.",
            "But then you see if you try to translate this neighborhood representation.",
            "Into a representation of a multivariate normal distribution like this.",
            "So if you look at conditionals right?",
            "Then then you you are running into problems right?",
            "So here you look at the auto regressions right?",
            "And they all assumed to be normal.",
            "Each variable given the rest right?",
            "And now we define this matrix of weights WS right that could be taken to be the agencies in matrix.",
            "The graph which we just.",
            "We just looked at right?",
            "Or we could have ways to quantify distances between centroids and so on.",
            "So those WS don't necessarily.",
            "Need to be one each.",
            "If two states share a connection, OK, but then they must be 0 if if there is no dependency there, right?",
            "So that's that's the parameterization.",
            "Through which we explain we express a graph and now if we look back at the auto regressions you see somehow we need to make them represent a joint distribution.",
            "Right so and I want to make a point here.",
            "It's not see in in this framework in a Bayesian framework you have to stay in the right space at all times and that is very important.",
            "Right, so you have to stay in this code of matrices.",
            "See this this corner here PG right.",
            "That's where your parameters are.",
            "So in order to sustain that cone, you see you need to make this conditionals consistent with each other, right?",
            "You cannot afford to say, well, I will somehow in the limit be getting into the right space, say bye bye by imposing the end or constraints or regression coefficients you see, because that is exactly where the hard problem is staying in the right space or all times.",
            "When you look at multiple graphs.",
            "Right, we cannot off work to, you know, not stay not be correct about about that part, right?",
            "So for this reason there has been many papers published in the spatial literature that deal will precisely this problem, and because they have already defined this adjacency matrix W in some form, and because they had to make these."
        ],
        [
            "Conditional consistent with each other, they had to reduce the parametrization they have been using, right?",
            "So essentially you know their parameterization reduced to say that's a very popular model to a spatial autocorrelation parameter row and to some various parameter top.",
            "OK so I'm trying.",
            "You know, I'm insisting on this point because this is this is a very important point you see, so the motivation of using this representation comes back from the work Julian Besag did in 74, right?",
            "So in an from there on they try to create joint distribution.",
            "Starting from this conditionals and they involved, you know.",
            "And at the end of the day they came up with something like this, you see, and it's clear that these two parameters, Rowan tall don't necessarily cover all the matrices in the cone PG.",
            "Right?",
            "So here see there are two different bodies of literature that never came together somehow, and frankly I never understood why.",
            "So we have all these literature in that relates to Gaussian graphical models and and, you know, we have all these literature that essentially had that work with parametrization of this kind, and they always called this guy Dempster.",
            "Right, because that's the original reference and then then then you have a different body of literature in dash.",
            "The literature that dominated spatial statistics, in which this kind of parameterisation has been using right?",
            "And that is really restrictive.",
            "Because if you look at the critique.",
            "That that appears in the in papers related to some of spatial models they say well over smoothing is is present throughout and over.",
            "Smoothing comes exactly from this kind of, from the necessity to make this conditional consistent with each other, yes.",
            "Change.",
            "But you you yeah?",
            "I mean you can so so this W does that's what you're asking.",
            "If it's just the one or yeah, it can be something else.",
            "It's fine.",
            "You don't.",
            "That's that's precisely the point.",
            "You do not cover the cone you see, because so if you start back from conditionals and try to come up with the joint distribution, you make a very tough problem for yourself.",
            "Right, it's very hard to essentially make make you know, say, 49 conditionals in this particular case.",
            "To be consistent with each other, right?",
            "I mean, if you have.",
            "X If X given Y&Y.",
            "Given X2 normals right there joint either doesn't exist or it doesn't necessarily need to be normal right now have a 49 dimensional problem and then you know if you try to solve this problem.",
            "Essentially that's what you get right.",
            "So see what I'm trying to say.",
            "Is that all the papers?",
            "I mean almost all the papers.",
            "That that tried to deal with spatial data with aerial data did something like this in some form.",
            "Right?",
            "And there's little reason to do it because we have all these other machinery at our disposal.",
            "You see.",
            "And that's precisely what I'm trying to do.",
            "What I will develop now?",
            "OK, so."
        ],
        [
            "So at the core, right will have to construct sampling algorithms, will have to construct here African models, right?",
            "So will need priors for for our parameters, and in particular we want a prior for the precision matrix key that is consistent with the particular graph.",
            "So to this end we will use the Jewish or distribution, right?",
            "So the Jewish.",
            "Distribution is is conjugate to the multinomial right.",
            "It has two parameters Delta and D. You can think about Delta as effective sample size.",
            "You can think about the as effective sample variance covariance matrix right?",
            "So so.",
            "Some some research is dedicated to estimating this, normalizing constant, because if you if you want to move are on graph, you want to do.",
            "Some some sort of reversible jam procedure and then at that point, knowing this, normalizing constant is key, right?",
            "So so computing this guy right here is a problem in itself.",
            "OK, so so now see this key lives in a cone, so it's still not so trivial to handle it right?",
            "So to this end, you know we can handle it better if we use this double Cholesky decomposition, right?",
            "So here, right, you consider Alaska decomposition of the matrix D, right?",
            "And now you have this sign here, right in now the element subside.",
            "I either free or constraint the free elements correspond with other the diagonal elements of the matrix I or with the edges of the graph.",
            "And all these elements in new GRR variation, independent, right?",
            "So the fact that these these elements see the free elements of the matrix IR variation independent makes makes whatever it is that we will do later on work, right?",
            "So you see.",
            "So this is a very convenient parameterisation.",
            "That essentially is less restrictive than than all these other parametrizations that come from conditionals and really gives us what what we want to get.",
            "Right?",
            "OK, so sampling."
        ],
        [
            "And the Jewish Art East Key and has been has been the topic of quite a few papers, right?",
            "So one of them is the blog GIF sampler algorithm.",
            "So if you are familiar with the iterative proportional fitting algorithm or iterative proportional scaling algorithm for for linear models or for fitting Gaussian graphical models.",
            "Then then the blog GIF sampler algorithm essentially works in the same way, right?",
            "So it goes around the clicks of the graphs and then it performs update respect to these clicks, right?",
            "So using this algorithm in the context of Heroical Bayesian framework is is relatively hard, because when you deal with large graphs then.",
            "Then your clicks can also be big, you know, and then you you know you cannot use if you use those maximal prime decompositions you see then then you know for the spatial graphs we're worrying about this maximum maximal prime components could be big, right?",
            "And now see the block Gibbs sampler algorithm requires inversions of large matrices and those large matrices cannot be.",
            "They are broken because they are associated with those clicks of the graphs, right?",
            "So think about that big component I showed you before.",
            "So for this reason, see because you have all these peak matrices, you cannot.",
            "You cannot do too much with it, although you know in theory it works right now for the case of decomposable graphs, there is a very nice direct sampler algorithm.",
            "Right?",
            "Adjust relates to sampling sampling sequentially click by click.",
            "But by taking into account all the conditional is given by the separators, right?",
            "So this sampler works really well for decomposable graphs.",
            "There's been an extension of the sampler by Wang and car volume, right?",
            "And so they have a very nice result essentially.",
            "Say, well, I will use an accept reject algorithm in which I will update all the free elements C. In this side at the time.",
            "Right, so that that again works well in theory.",
            "However, it doesn't scale for large graphs.",
            "Right, and that's what I will.",
            "I'll going to show you next, and then there is another paper.",
            "Car keys Massaman Escobar that describes that appears also in EDS that describes the Metropolis Hastings algorithm and then again they also tried to update all the free elements.",
            "At one time, so we have a very small adjustment to all that in which we simply purchase one free element at the time, right?",
            "So that that's, well, that's a very small.",
            "Detail that we have, however, this detail makes things work right, so we have here."
        ],
        [
            "You're very, uh, small simulation study that involves sampling from a Jewish, our distribution associated with the cycle with P vertices, right?",
            "So this cycle has one maximal prime component, right?",
            "So you cannot use any any graph decompositions for it right now.",
            "See, we compare the acceptance probabilities of this algorithm that we have that perturbs one element at the time.",
            "With the two samplers of Wangan car value and Machakos Kiss and all right, So what you see here is that for these two other samplers, the acceptance probability essentially go to 04.",
            "Even four P = 20.",
            "Now in our case, you know the largest maximal prime component for the US graph had I think 23 vertices right?",
            "So that essentially.",
            "Brings us to 04 for the acceptance rates for these two other algorithms.",
            "You see that for our own algorithm will see the acceptance rates are still fine, so for this reason out of all this work that has been done so far will have to move ahead with this with this sampler that we developed because it scales really well for the large graphs we we have to deal with.",
            "OK, yeah.",
            "Well, I mean see.",
            "So we have this this sign in terms of speed that it's all relatively fast.",
            "If you know 'cause so right.",
            "So see it depends.",
            "So we have this parameter that tells us how far we jump, right?",
            "It's a simple normal kernel, right?",
            "So you know so we can adjust this parameter easily, you know, so see so as dimension as dimension increases, right?",
            "So you know we have.",
            "We can essentially calibrate the acceptance rates.",
            "We have this one parameter and then.",
            "We can control the jump and then.",
            "We the acceptance rates for each element is given element is is relatively constant.",
            "So it doesn't really matter.",
            "You know.",
            "You know we don't need 11 parameter for each prior.",
            "Yeah so so we can.",
            "We can collaborate that easy, but it's a good question.",
            "Yeah, OK, so fine.",
            "So let's move back to."
        ],
        [
            "To our spatial models, right?",
            "So in the classical approach you see we have multivariate normal distribution, right?",
            "And that matrix DW that belongs to the to the right connan that matrix DW has been constructed with weights and parameterized with that with these two parameters rowant all right, there's two parameters for the entire account.",
            "So what we do see?",
            "Our our extension here is to consider this mixture approach.",
            "That is, we say.",
            "We have a multi billion normal here, parameterized with the with the matrix key that belongs to the correct account and now see we push back this DW one level down to be to make to make it in a pro specification for our hierarchical right?",
            "So it's a it's a very simple extension that we did here and you see all we did is say, well, let's just just take what we know from the other body of the literature.",
            "And and combine it with with the spatial models that that already exists, right?",
            "So what does that give us?",
            "Well, what we get see here.",
            "The advantage of using this simple extension can be seen in the conditionals, right?",
            "Because in the conditional see all those regression coefficients, A prayer for the regression coefficients come I prior induced by by the joint G which are prior.",
            "We imposed on the precision matrix.",
            "Right, so now this makes.",
            "This makes the specification of the conditional to be very flexible.",
            "And all these conditions now will be consistent with each other.",
            "Which is exactly what we want.",
            "Right, so we contrast this specification with what the classical approach gave us.",
            "Right and then you see all your regression coefficients.",
            "Here are are are essentially fixed.",
            "You know, given modular on top right.",
            "So so you know it's so that seems to be a nice result that seems to be a very flexible framework."
        ],
        [
            "And now now.",
            "Now let's see what what we can do it.",
            "So what we can do is it relates to.",
            "Specifying.",
            "A matrix valued graphical models, right?",
            "Because if you remember, we had a matrix right?",
            "That's 49 by 11.",
            "And and we want it to infer the graphs for one dimension, the column dimension given the spatial graph we've been looking right, so see.",
            "So now our matrix Varian model is specified.",
            "The parametrization specifies through row and column precision matrix, right?",
            "And now the row and column precision matrix must belong to counts.",
            "That are specified for the through the row and column graphs.",
            "And what that gives us see our condition independence models for the rows and the columns given by by the edges of these two graphs, right?",
            "So, so this is so.",
            "This is the model we will be working on the the added difficulty relates to fact that now the row and column precision matrix is on no longer identify right?",
            "So we need to somehow take care of.",
            "And impose an extra constraint to make the models identifiable.",
            "And now there are many ways to go about that.",
            "We chose to go with the approach proposed by Wang and West that is just just set the one one element of one of the precision matrices to 1, right?",
            "So to that end, we'll have to work with this auxiliary variable Z and take and they make that part of the.",
            "Sampling models.",
            "We will develop later on, right?",
            "So that's what we get.",
            "You see, very simple extension.",
            "It's also in a sense less than what we want, right?",
            "Because we assumed that the dependencies of the column variables of the columns, right?",
            "So the dependencies, the cancer levels, for example, remain the same across the state.",
            "Right, so in a sense, that could be seen a constraint, but but there are.",
            "There are ways to solve that that constraint, right?"
        ],
        [
            "So now if we if we worried about matrix value data, there is no reason why we shouldn't do what we've just done here in in multiple dimensions, right?",
            "So instead of having 2 dimensions, we can now and worry about matrix for your data.",
            "We can worry about a race of any size, right?",
            "So we have we can have any number of dimensions L at each.",
            "A dimension we can have any number of variables, right?",
            "And now the joint distribution for for this matrix variant model will be parameterized to precision matrices corresponding with each dimension.",
            "Right, and that gives us a value joint distribution, right?",
            "And now this precision matrixes will need to belong to counts corresponding with graphs associated with each dimension.",
            "So in each dimension you could have, you could have either non graphs as in our spatial example or or unknown graphs right and so so so in this framework for example, you can account for, say, time dependence, right?",
            "So you can have matrices observed across time.",
            "And in this smaller right, say, say, you can assume your time graphs to be some to be just some autoregressive process of some kind, right?",
            "And then you know you can for example, account for the presence of multiple cancers, right?",
            "And you want to study the dependency, for example, that appear between primary and secondary cancers, which is something you cannot do with matrix various models of this kind, right?",
            "And then the extension to array data is relatively straightforward, be once we put into place this machinery of Jewish shirt.",
            "And and auxiliary variable corresponding with.",
            "With the this identifiability constraint.",
            "Right?",
            "So so see this is a very large and very flexible family of of models that can now be used either directly or as as priors for from random effects in some hierarchical models we can develop.",
            "OK, and then again at each dimension the graphs can be either known and then if they are unknown to reversible jump MCMC, you can average across them, right?",
            "I thought you would complain about something here.",
            "That there is no complaint anywhere.",
            "Matrix Variata River your data.",
            "Yeah.",
            "Having trouble understanding the.",
            "Use the non square matrix.",
            "First line.",
            "Here.",
            "You said chronic care product right?",
            "It's the chronic care program.",
            "Yes yeah yeah yeah yeah yeah.",
            "Well it's a good good complaint, but that's not the complaint I was looking for.",
            "Aquatic so all the printability, they.",
            "Yes, so you can."
        ],
        [
            "You so well I mean, OK, so you can do something fancy and mimic quite what they do there, right?",
            "So so you can now have in the same dimension.",
            "You can have several precision matrices exactly the way they do, right?",
            "So in a sense, so see the beauty of this is that you can mimic.",
            "Everything you know, every contribution that exists in this literature, but with this relatively straightforward extension that relates to using G, we shared and actually living in all the cone of matrices.",
            "Right, so that's a very good comment.",
            "OK, but but still is not the complaint I was looking for.",
            "OK so I thought you you are going to complain about having one matrix.",
            "Right so here see we have one array, so in the sense you'll say, why'd you work with the sample size of 1?",
            "Right here, you know 'cause I, that's why I said, I give you one matrix right?",
            "So so how can I determine a graph given that you know I have one matrix right?",
            "Or two graphs or graphs in several dimensions, right?",
            "For, for for a date?",
            "Well, so it turns out, you see that apparently you have the sample size of 1.",
            "But what really happens is that you see, when you look across rows.",
            "Across columns or across any other dimension you can think as if you would have a sample size equal.",
            "With the product of the other dimension, the dimension not associated with that dimension you're currently focusing on, right?",
            "So for example, in order to determine the row graphs, the actual sample size that you have represent is given by the number of columns.",
            "Right, that's what what what you what you have here you see.",
            "So as you have more and more dimension than than when you sequentially update your graphs, corresponding with each dimension, then then what you really have is a product of the number of dimension corresponding with the number of levels corresponding with all the other dimensions, right?",
            "So special.",
            "You can but.",
            "That's what appears in the sampler.",
            "Right, so the way to get rid of super abilities to look at factor modes.",
            "Right so and you can do it.",
            "Right, but that's that's not this talk.",
            "OK, so so fine, so now.",
            "So now if we move back."
        ],
        [
            "222 our multivariate car models right?",
            "So see the prior we have been working so hard to construct.",
            "This is right here, right?",
            "And that effectively gives us auto regressions at the row level or the column level that are precisely what multivariate car models give.",
            "Right, so so these are consistent with the results.",
            "Mardia present, for example, right?",
            "So now.",
            "So now let's see.",
            "So we."
        ],
        [
            "Will will go back to our cancer example, right?",
            "So will construct a straightforward Poisson log linear model where our interest will be those X, ijs, the random effects.",
            "Right so so see we have we have count data so so we cannot assume that matrix value normal distributions.",
            "You know at the observation level we need to to stick it one level down.",
            "Right now the prayer specification.",
            "see I give it here and you know it's consistent with whatever the spatial literature was doing.",
            "You see, with the exception of this part.",
            "The are of RO that now is is down is 1 level down right?",
            "So let's see.",
            "So these are the four models we will now compare, right?",
            "So see this is this is the joint distribution of the random effect.",
            "OK, now these are the matrix value Gaussian graphical models right with uniform prior for."
        ],
        [
            "For the column graphs, which are, which are the graphs among Kansas?",
            "We try to determine, right?",
            "So in order to see what the effect of the prior on the graph space is, we also look at this size space prior right?",
            "So the size space prior, say, well, I will consider that all the graphs of a certain size are equally likely.",
            "And now all the graph sizes will be equally like, right?",
            "So so so we have two priors here because we want to see the effects of our specification for on the graphs level on on.",
            "On our inferences right?",
            "So now the third model is this model full.",
            "So model fool just says, well, I will keep the column graph to be the complete graph.",
            "That is, I won't impose any any additional constraints for the precision matrix someone associated with the cancer, right?",
            "So that is effectively equivalent to saying, well, this matrix, Casey, you see instead of instead of having a Jewish, are prior to have a wish or prayer.",
            "Right?",
            "So that's one level closer to the classical approach to analyzing aerial date, right?",
            "So now will will move one level down and we look at the classical M car model in the classical N car model is obtained by moving that TR of row one level up.",
            "So that's essentially equivalent to setting the row precision matrix.",
            "To the dro.",
            "Instead of imposing a primer on it.",
            "Right, and now the Jewish.",
            "Our prior for for the column Precision matrix remains the same as in the formal right, and now we can say impose any priors we want from the spatial autocorrelation, right?",
            "So, so those are our four models, and that's you know if you read it the other way represents the transition from where we were at the beginning of talk at the beginning of the talk to where we are now.",
            "Right?",
            "So let's see how well we do.",
            "So we did a 10 fold cross validation exercise, predictive exercise right.",
            "And and we look at the sum of the squared errors.",
            "The variance of the predicted values, and then we also looked at the rank probability score to assess how well we do respect to the entire predictive distribution right?",
            "And now you see that.",
            "Our two models ggmu the model with the uniform prior on graphs and DGM as the model with."
        ],
        [
            "With the size by spring graphs is effectively do much better have better predicted performance.",
            "Then then the other two models.",
            "Right, So what that tells us is that working with fewer parameters are all time by imposing constraints at the for the cancer level graphs."
        ],
        [
            "Makes a lot of sense and now you see I."
        ],
        [
            "I'll come back to that slide, so those.",
            "Types of constraints are are visible, you know, in in, in the kind of graphs we can look at dry.",
            "So you see here for example.",
            "So see this edge inclusion probabilities corresponding with the two models ggmu and DGM.",
            "S right?",
            "See so now you see the posterior probabilities of edges.",
            "You know how they appear and disappear.",
            "The average across that right?",
            "And?",
            "And you see that we are effectively working with a lot fewer parameters at all times.",
            "Right so so see.",
            "So that's a convergence plot.",
            "See of the average graph sizes for the column graph.",
            "So see we have about less than 25 edges on average, right?",
            "So this is really close to what the priors the two prior say, which says.",
            "Well, the graphs are priority, should have about 27.5 edges, but then you see the effect of the two priors, the what the priors.",
            "Do on the graph space is quite different than.",
            "Still we get something consistent right?",
            "Either way, our sample size is not terribly great.",
            "Is either 49 or 11 for the determination of other graph right?",
            "So now let's see so."
        ],
        [
            "I something else I want to point out, you see.",
            "So what we did here is use all the samples computed 95% credible intervals and looked at their coverage and their length.",
            "So what you see here is that the M car model had a coverage rate of .99, which is strange.",
            "Right, so that is indicative of the fact that you know you really work with too many parameters, then then you should in a sense, but too few to get what you should be getting.",
            "Right and then on the other hand, if you look at the mean length.",
            "Of these intervals you see that."
        ],
        [
            "We we get much smaller interval on average, right?",
            "So so, so we impose constraints and those constraints are given by graphs and at the end of the day we can look at the graph like this."
        ],
        [
            "Right so so then you see you have to be careful when interpreting the graph becausw conditional independence for the random effects not translate for condition independence.",
            "For for the actual observed data, because what you have there is something discrete.",
            "So you can only go as far as as the Poisson rates, but not you cannot say anything about the actual cancer.",
            "You need to step one level down.",
            "However you see, this is perhaps indicative of how how diseases interact to each other in the presence of.",
            "Of Of spatial interaction.",
            "Right?",
            "So, uh, so?"
        ],
        [
            "So that's that I have.",
            "I have another example here.",
            "How much time do I have?",
            "OK so but I I I won't go through it, it's a well.",
            "It's actually very simple example because see it only involves C. We had 11 cancers before.",
            "In this example we have.",
            "Scores to forge math and an and verbal tests right so see here that so in this plot here you see a clear dependence between the two scores, so you would expect an edge to be present when you try to infer this graph, which now has only two vertices, right?",
            "So you want to put an edge in between the two, right?",
            "So you see that overall.",
            "See you have you have posterior probability.",
            "Of .8 so the models do what you would hope them to do right, given that that you observe this this kind of dependence right?",
            "So we do something right over all right so now?"
        ],
        [
            "Now see I want you to think at the extension of this work right?",
            "So we had we had counts that are that were observed at each state.",
            "But you can think about those counts as one dimensional marginals of contingency tables, right?",
            "So see in this example I have data from North Carolina, each County in North Carolina.",
            "So so, so gender.",
            "Mother's age at birth and race are possible factors that could influence.",
            "Low birthweight, right?",
            "So see.",
            "So what we have here are 100 the number of counties in North Carolina 2 to the four tables.",
            "Right, so now.",
            "So now what we want to do is analyze that set of 102 to the four tables in the presence of spatial dependence.",
            "Now think about the fact that you."
        ],
        [
            "Might not have complete individual level data for for the individual level data might not be observed throughout.",
            "You might have partial information for some of these samples, So what that means is that you would know some some lower dimensional marginal totals.",
            "So now what you will have to do is perform imputation, given the constraints that you have.",
            "So that's why sampling tables is really key.",
            "And sampling tables is precisely the name of the game in ecological inference.",
            "Right, so in ecological inference they they have deal effectively with two by two tables.",
            "There have been recent extension two I by J tables and that's about it, right?",
            "So this see we talked about this body of literature that refers to graphical models then that that comes from the work of Dempster.",
            "There's this other body of literature.",
            "That relates to spatial epidemic Epidemiology.",
            "And now there is the third body of literature.",
            "That that that is, is that just ways to be joined with the other two."
        ],
        [
            "Right, and that that that really refers to sampling tables and in constructing C dependencies for this kind of data?",
            "Why is this a hard problem?",
            "Well, this is a much harder problem then the problem we talked about before, because now we have higher order interactions, right?",
            "You don't have only first or the interaction, you have higher order interaction, so somehow see you need you need to take that into account.",
            "OK."
        ],
        [
            "So, so I think I will stop here.",
            "You see, there's there's plenty of work to be done.",
            "There are some papers and so."
        ],
        [
            "Plan on my website and you're welcome to look at them."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, thank you so much.",
                    "label": 0
                },
                {
                    "sent": "Good morning well.",
                    "label": 0
                },
                {
                    "sent": "Stay awake for some of us, um, So what I'm going to talk about today are our graphs and these graphs.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Will come in various forms.",
                    "label": 0
                },
                {
                    "sent": "You know with this audience you are.",
                    "label": 0
                },
                {
                    "sent": "You are familiar with graphical models really well.",
                    "label": 0
                },
                {
                    "sent": "So in graphical models you deal with the situation in which you want to model dependencies through a graphical structure and that graphical structure is typically unknown, so that will be one aspect of the of the graphs.",
                    "label": 1
                },
                {
                    "sent": "Another aspect of graphs is something like that, right?",
                    "label": 0
                },
                {
                    "sent": "So what you're looking at here?",
                    "label": 0
                },
                {
                    "sent": "I mean you are looking at the US map, you're looking at the Continental States and the Continental States represent vertices in a graph whose edges represent the neighbors of each state, right?",
                    "label": 0
                },
                {
                    "sent": "So this is an example of a graphical structure that is known, and it's an example of a graphical structure.",
                    "label": 0
                },
                {
                    "sent": "That needs to be taken into account if you have data that is observed.",
                    "label": 0
                },
                {
                    "sent": "In each state.",
                    "label": 0
                },
                {
                    "sent": "So say if if you have observations that that belong to each of these states right then then you would somehow want to take this particular graphical structure into account, right?",
                    "label": 0
                },
                {
                    "sent": "So when I refer to spatial dependence, that's what I'm going to be referring to.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the US graph has structure in.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I mean, it's not.",
                    "label": 0
                },
                {
                    "sent": "It's not obvious if you if you look at it from this point of view.",
                    "label": 0
                },
                {
                    "sent": "But now if you look at graph decompositions.",
                    "label": 0
                },
                {
                    "sent": "Then then, then, then you got.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You get these subsets of states.",
                    "label": 0
                },
                {
                    "sent": "These these.",
                    "label": 0
                },
                {
                    "sent": "These are the 13 maximal prime subgraphs of the US neighborhood graph, and I thought I should show this to you because, well, it is unique.",
                    "label": 1
                },
                {
                    "sent": "You know that's never going to change, hopefully, and it plays a really, really big role in the work we represent later on.",
                    "label": 0
                },
                {
                    "sent": "Because you see these maximal prime sub graphs represent component that would help.",
                    "label": 0
                },
                {
                    "sent": "Uh, the methodology we will develop to be broken into components.",
                    "label": 0
                },
                {
                    "sent": "So apply, divide, divide and conquer method that would.",
                    "label": 0
                },
                {
                    "sent": "That would help us with our analysis right?",
                    "label": 0
                },
                {
                    "sent": "So for example here, see component one is Alabama, Florida and Georgia right?",
                    "label": 0
                },
                {
                    "sent": "And then you see down here.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Triangle right?",
                    "label": 0
                },
                {
                    "sent": "So this way see you, you break the graph into these compare.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Comments and then you can simplify your problem later on.",
                    "label": 0
                },
                {
                    "sent": "You also remark here this huge maximum prime component component too, right?",
                    "label": 0
                },
                {
                    "sent": "Fine so so.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um, let's let's look at the data set right?",
                    "label": 0
                },
                {
                    "sent": "So so this data set comes from SCR and it represents.",
                    "label": 0
                },
                {
                    "sent": "Sounds mortality counts for 11 times of cancers, so so our datum is a 49 by 11 matrix.",
                    "label": 0
                },
                {
                    "sent": "OK, so so on one dimension you have the 49 States and you already know the dependencies you are trying to represent.",
                    "label": 0
                },
                {
                    "sent": "That's the graph I've been showing you so far, right?",
                    "label": 0
                },
                {
                    "sent": "And then at a different dimension you have your types of cancer types, right?",
                    "label": 0
                },
                {
                    "sent": "And what we will do is try to infer the dependencies among the cancers.",
                    "label": 0
                },
                {
                    "sent": "So you have 11 variables, right?",
                    "label": 0
                },
                {
                    "sent": "Through graphs graphs you don't know in the presence of the spatial dependencies, the dependencies you know, right?",
                    "label": 0
                },
                {
                    "sent": "So, so that's what we are going to try to do.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Uh, so here are the chloroplasts maths for the four types of cancers, right?",
                    "label": 0
                },
                {
                    "sent": "And now you see, see the darker color means means higher?",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Mortality rates the lighter color means lower mortality rates, right?",
                    "label": 0
                },
                {
                    "sent": "So what you see in these plot is that there is a clear spatial dependence for each type of cancers.",
                    "label": 0
                },
                {
                    "sent": "What you see in this plot is that the spatial dependencies change somehow according to cancer type, right?",
                    "label": 0
                },
                {
                    "sent": "So what we would like to do is somehow express the dependencies that exist in these well 11 chloro plat Maps through graph.",
                    "label": 0
                },
                {
                    "sent": "So just if we just refer to these four types of cancers, what we would like to do is infer edges right?",
                    "label": 0
                },
                {
                    "sent": "And it's not necessarily important which edges are in or out, it's the graph looking at multiple graphs multiple.",
                    "label": 0
                },
                {
                    "sent": "A possible graph is what we will be interested in.",
                    "label": 0
                },
                {
                    "sent": "Right, so that's our problem.",
                    "label": 0
                },
                {
                    "sent": "OK, so so let's see how to solve this, how we can solve this problem, right?",
                    "label": 0
                },
                {
                    "sent": "So now we will step back and we're going to look at the classical definition of a graphical model and well of Gaussian graphical model, right?",
                    "label": 0
                },
                {
                    "sent": "And you I'm sure you are familiar with it, right?",
                    "label": 0
                },
                {
                    "sent": "So our parametrization is in terms of a precision matrix.",
                    "label": 0
                },
                {
                    "sent": "OK, right so so now I have a graph.",
                    "label": 0
                },
                {
                    "sent": "This graph has vertices and edges and edges represent conditional independence, ease of condition, independence of two given variable.",
                    "label": 0
                },
                {
                    "sent": "Given the given, the rest right so see.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This matrix K will belong to a cone.",
                    "label": 0
                },
                {
                    "sent": "Of symmetric positive definite matrices that is defined by by the graph right?",
                    "label": 1
                },
                {
                    "sent": "So these are our model parameter model parameters are represented by this matrix K and this is the classical definition that appears in the literature and that dates back to Dempster.",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                },
                {
                    "sent": "No, that that's the really interesting part.",
                    "label": 0
                },
                {
                    "sent": "So there has been, you know that the literature on spatial Epidemiology aerial data has hundreds of papers in it, an essentially most of these papers treat graphs in a very special form.",
                    "label": 0
                },
                {
                    "sent": "They don't read graphs.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The way we just looked at it.",
                    "label": 0
                },
                {
                    "sent": "Altogether right, they treat graphs and I'll come back to that slide like like.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This right, so the red that see the graph in Red Sea is is the graph we just introduced.",
                    "label": 0
                },
                {
                    "sent": "And now see this table.",
                    "label": 0
                },
                {
                    "sent": "Gives the neighbors of each state, right?",
                    "label": 0
                },
                {
                    "sent": "So we list all the States and then released all all the states that share a border with that particular state, right?",
                    "label": 0
                },
                {
                    "sent": "So this means if I take each given state, say Alabama, Alabama, right, then whatever happens, whatever dependencies come in?",
                    "label": 0
                },
                {
                    "sent": "Uh, given the other states.",
                    "label": 0
                },
                {
                    "sent": "What's going to matter are only the neighbors.",
                    "label": 0
                },
                {
                    "sent": "The direct neighbors available, right?",
                    "label": 0
                },
                {
                    "sent": "So you'll say, OK, this this representation is equivalent with the vertices and edges representation.",
                    "label": 0
                },
                {
                    "sent": "We have been looking at right?",
                    "label": 0
                },
                {
                    "sent": "It is.",
                    "label": 0
                },
                {
                    "sent": "But then you see if you try to translate this neighborhood representation.",
                    "label": 0
                },
                {
                    "sent": "Into a representation of a multivariate normal distribution like this.",
                    "label": 0
                },
                {
                    "sent": "So if you look at conditionals right?",
                    "label": 0
                },
                {
                    "sent": "Then then you you are running into problems right?",
                    "label": 0
                },
                {
                    "sent": "So here you look at the auto regressions right?",
                    "label": 0
                },
                {
                    "sent": "And they all assumed to be normal.",
                    "label": 0
                },
                {
                    "sent": "Each variable given the rest right?",
                    "label": 0
                },
                {
                    "sent": "And now we define this matrix of weights WS right that could be taken to be the agencies in matrix.",
                    "label": 0
                },
                {
                    "sent": "The graph which we just.",
                    "label": 0
                },
                {
                    "sent": "We just looked at right?",
                    "label": 0
                },
                {
                    "sent": "Or we could have ways to quantify distances between centroids and so on.",
                    "label": 0
                },
                {
                    "sent": "So those WS don't necessarily.",
                    "label": 0
                },
                {
                    "sent": "Need to be one each.",
                    "label": 0
                },
                {
                    "sent": "If two states share a connection, OK, but then they must be 0 if if there is no dependency there, right?",
                    "label": 0
                },
                {
                    "sent": "So that's that's the parameterization.",
                    "label": 0
                },
                {
                    "sent": "Through which we explain we express a graph and now if we look back at the auto regressions you see somehow we need to make them represent a joint distribution.",
                    "label": 0
                },
                {
                    "sent": "Right so and I want to make a point here.",
                    "label": 0
                },
                {
                    "sent": "It's not see in in this framework in a Bayesian framework you have to stay in the right space at all times and that is very important.",
                    "label": 0
                },
                {
                    "sent": "Right, so you have to stay in this code of matrices.",
                    "label": 0
                },
                {
                    "sent": "See this this corner here PG right.",
                    "label": 0
                },
                {
                    "sent": "That's where your parameters are.",
                    "label": 0
                },
                {
                    "sent": "So in order to sustain that cone, you see you need to make this conditionals consistent with each other, right?",
                    "label": 0
                },
                {
                    "sent": "You cannot afford to say, well, I will somehow in the limit be getting into the right space, say bye bye by imposing the end or constraints or regression coefficients you see, because that is exactly where the hard problem is staying in the right space or all times.",
                    "label": 0
                },
                {
                    "sent": "When you look at multiple graphs.",
                    "label": 0
                },
                {
                    "sent": "Right, we cannot off work to, you know, not stay not be correct about about that part, right?",
                    "label": 0
                },
                {
                    "sent": "So for this reason there has been many papers published in the spatial literature that deal will precisely this problem, and because they have already defined this adjacency matrix W in some form, and because they had to make these.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Conditional consistent with each other, they had to reduce the parametrization they have been using, right?",
                    "label": 0
                },
                {
                    "sent": "So essentially you know their parameterization reduced to say that's a very popular model to a spatial autocorrelation parameter row and to some various parameter top.",
                    "label": 0
                },
                {
                    "sent": "OK so I'm trying.",
                    "label": 0
                },
                {
                    "sent": "You know, I'm insisting on this point because this is this is a very important point you see, so the motivation of using this representation comes back from the work Julian Besag did in 74, right?",
                    "label": 0
                },
                {
                    "sent": "So in an from there on they try to create joint distribution.",
                    "label": 0
                },
                {
                    "sent": "Starting from this conditionals and they involved, you know.",
                    "label": 0
                },
                {
                    "sent": "And at the end of the day they came up with something like this, you see, and it's clear that these two parameters, Rowan tall don't necessarily cover all the matrices in the cone PG.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "So here see there are two different bodies of literature that never came together somehow, and frankly I never understood why.",
                    "label": 0
                },
                {
                    "sent": "So we have all these literature in that relates to Gaussian graphical models and and, you know, we have all these literature that essentially had that work with parametrization of this kind, and they always called this guy Dempster.",
                    "label": 0
                },
                {
                    "sent": "Right, because that's the original reference and then then then you have a different body of literature in dash.",
                    "label": 0
                },
                {
                    "sent": "The literature that dominated spatial statistics, in which this kind of parameterisation has been using right?",
                    "label": 0
                },
                {
                    "sent": "And that is really restrictive.",
                    "label": 0
                },
                {
                    "sent": "Because if you look at the critique.",
                    "label": 0
                },
                {
                    "sent": "That that appears in the in papers related to some of spatial models they say well over smoothing is is present throughout and over.",
                    "label": 0
                },
                {
                    "sent": "Smoothing comes exactly from this kind of, from the necessity to make this conditional consistent with each other, yes.",
                    "label": 0
                },
                {
                    "sent": "Change.",
                    "label": 0
                },
                {
                    "sent": "But you you yeah?",
                    "label": 0
                },
                {
                    "sent": "I mean you can so so this W does that's what you're asking.",
                    "label": 0
                },
                {
                    "sent": "If it's just the one or yeah, it can be something else.",
                    "label": 0
                },
                {
                    "sent": "It's fine.",
                    "label": 0
                },
                {
                    "sent": "You don't.",
                    "label": 0
                },
                {
                    "sent": "That's that's precisely the point.",
                    "label": 0
                },
                {
                    "sent": "You do not cover the cone you see, because so if you start back from conditionals and try to come up with the joint distribution, you make a very tough problem for yourself.",
                    "label": 0
                },
                {
                    "sent": "Right, it's very hard to essentially make make you know, say, 49 conditionals in this particular case.",
                    "label": 0
                },
                {
                    "sent": "To be consistent with each other, right?",
                    "label": 0
                },
                {
                    "sent": "I mean, if you have.",
                    "label": 0
                },
                {
                    "sent": "X If X given Y&Y.",
                    "label": 0
                },
                {
                    "sent": "Given X2 normals right there joint either doesn't exist or it doesn't necessarily need to be normal right now have a 49 dimensional problem and then you know if you try to solve this problem.",
                    "label": 0
                },
                {
                    "sent": "Essentially that's what you get right.",
                    "label": 0
                },
                {
                    "sent": "So see what I'm trying to say.",
                    "label": 0
                },
                {
                    "sent": "Is that all the papers?",
                    "label": 0
                },
                {
                    "sent": "I mean almost all the papers.",
                    "label": 0
                },
                {
                    "sent": "That that tried to deal with spatial data with aerial data did something like this in some form.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "And there's little reason to do it because we have all these other machinery at our disposal.",
                    "label": 0
                },
                {
                    "sent": "You see.",
                    "label": 0
                },
                {
                    "sent": "And that's precisely what I'm trying to do.",
                    "label": 0
                },
                {
                    "sent": "What I will develop now?",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So at the core, right will have to construct sampling algorithms, will have to construct here African models, right?",
                    "label": 0
                },
                {
                    "sent": "So will need priors for for our parameters, and in particular we want a prior for the precision matrix key that is consistent with the particular graph.",
                    "label": 0
                },
                {
                    "sent": "So to this end we will use the Jewish or distribution, right?",
                    "label": 0
                },
                {
                    "sent": "So the Jewish.",
                    "label": 0
                },
                {
                    "sent": "Distribution is is conjugate to the multinomial right.",
                    "label": 0
                },
                {
                    "sent": "It has two parameters Delta and D. You can think about Delta as effective sample size.",
                    "label": 0
                },
                {
                    "sent": "You can think about the as effective sample variance covariance matrix right?",
                    "label": 0
                },
                {
                    "sent": "So so.",
                    "label": 0
                },
                {
                    "sent": "Some some research is dedicated to estimating this, normalizing constant, because if you if you want to move are on graph, you want to do.",
                    "label": 0
                },
                {
                    "sent": "Some some sort of reversible jam procedure and then at that point, knowing this, normalizing constant is key, right?",
                    "label": 0
                },
                {
                    "sent": "So so computing this guy right here is a problem in itself.",
                    "label": 0
                },
                {
                    "sent": "OK, so so now see this key lives in a cone, so it's still not so trivial to handle it right?",
                    "label": 0
                },
                {
                    "sent": "So to this end, you know we can handle it better if we use this double Cholesky decomposition, right?",
                    "label": 0
                },
                {
                    "sent": "So here, right, you consider Alaska decomposition of the matrix D, right?",
                    "label": 0
                },
                {
                    "sent": "And now you have this sign here, right in now the element subside.",
                    "label": 0
                },
                {
                    "sent": "I either free or constraint the free elements correspond with other the diagonal elements of the matrix I or with the edges of the graph.",
                    "label": 0
                },
                {
                    "sent": "And all these elements in new GRR variation, independent, right?",
                    "label": 0
                },
                {
                    "sent": "So the fact that these these elements see the free elements of the matrix IR variation independent makes makes whatever it is that we will do later on work, right?",
                    "label": 0
                },
                {
                    "sent": "So you see.",
                    "label": 0
                },
                {
                    "sent": "So this is a very convenient parameterisation.",
                    "label": 0
                },
                {
                    "sent": "That essentially is less restrictive than than all these other parametrizations that come from conditionals and really gives us what what we want to get.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "OK, so sampling.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the Jewish Art East Key and has been has been the topic of quite a few papers, right?",
                    "label": 0
                },
                {
                    "sent": "So one of them is the blog GIF sampler algorithm.",
                    "label": 0
                },
                {
                    "sent": "So if you are familiar with the iterative proportional fitting algorithm or iterative proportional scaling algorithm for for linear models or for fitting Gaussian graphical models.",
                    "label": 0
                },
                {
                    "sent": "Then then the blog GIF sampler algorithm essentially works in the same way, right?",
                    "label": 0
                },
                {
                    "sent": "So it goes around the clicks of the graphs and then it performs update respect to these clicks, right?",
                    "label": 0
                },
                {
                    "sent": "So using this algorithm in the context of Heroical Bayesian framework is is relatively hard, because when you deal with large graphs then.",
                    "label": 0
                },
                {
                    "sent": "Then your clicks can also be big, you know, and then you you know you cannot use if you use those maximal prime decompositions you see then then you know for the spatial graphs we're worrying about this maximum maximal prime components could be big, right?",
                    "label": 0
                },
                {
                    "sent": "And now see the block Gibbs sampler algorithm requires inversions of large matrices and those large matrices cannot be.",
                    "label": 1
                },
                {
                    "sent": "They are broken because they are associated with those clicks of the graphs, right?",
                    "label": 0
                },
                {
                    "sent": "So think about that big component I showed you before.",
                    "label": 0
                },
                {
                    "sent": "So for this reason, see because you have all these peak matrices, you cannot.",
                    "label": 0
                },
                {
                    "sent": "You cannot do too much with it, although you know in theory it works right now for the case of decomposable graphs, there is a very nice direct sampler algorithm.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "Adjust relates to sampling sampling sequentially click by click.",
                    "label": 0
                },
                {
                    "sent": "But by taking into account all the conditional is given by the separators, right?",
                    "label": 0
                },
                {
                    "sent": "So this sampler works really well for decomposable graphs.",
                    "label": 0
                },
                {
                    "sent": "There's been an extension of the sampler by Wang and car volume, right?",
                    "label": 0
                },
                {
                    "sent": "And so they have a very nice result essentially.",
                    "label": 0
                },
                {
                    "sent": "Say, well, I will use an accept reject algorithm in which I will update all the free elements C. In this side at the time.",
                    "label": 0
                },
                {
                    "sent": "Right, so that that again works well in theory.",
                    "label": 0
                },
                {
                    "sent": "However, it doesn't scale for large graphs.",
                    "label": 0
                },
                {
                    "sent": "Right, and that's what I will.",
                    "label": 0
                },
                {
                    "sent": "I'll going to show you next, and then there is another paper.",
                    "label": 0
                },
                {
                    "sent": "Car keys Massaman Escobar that describes that appears also in EDS that describes the Metropolis Hastings algorithm and then again they also tried to update all the free elements.",
                    "label": 0
                },
                {
                    "sent": "At one time, so we have a very small adjustment to all that in which we simply purchase one free element at the time, right?",
                    "label": 0
                },
                {
                    "sent": "So that that's, well, that's a very small.",
                    "label": 0
                },
                {
                    "sent": "Detail that we have, however, this detail makes things work right, so we have here.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You're very, uh, small simulation study that involves sampling from a Jewish, our distribution associated with the cycle with P vertices, right?",
                    "label": 0
                },
                {
                    "sent": "So this cycle has one maximal prime component, right?",
                    "label": 0
                },
                {
                    "sent": "So you cannot use any any graph decompositions for it right now.",
                    "label": 0
                },
                {
                    "sent": "See, we compare the acceptance probabilities of this algorithm that we have that perturbs one element at the time.",
                    "label": 0
                },
                {
                    "sent": "With the two samplers of Wangan car value and Machakos Kiss and all right, So what you see here is that for these two other samplers, the acceptance probability essentially go to 04.",
                    "label": 0
                },
                {
                    "sent": "Even four P = 20.",
                    "label": 0
                },
                {
                    "sent": "Now in our case, you know the largest maximal prime component for the US graph had I think 23 vertices right?",
                    "label": 0
                },
                {
                    "sent": "So that essentially.",
                    "label": 0
                },
                {
                    "sent": "Brings us to 04 for the acceptance rates for these two other algorithms.",
                    "label": 0
                },
                {
                    "sent": "You see that for our own algorithm will see the acceptance rates are still fine, so for this reason out of all this work that has been done so far will have to move ahead with this with this sampler that we developed because it scales really well for the large graphs we we have to deal with.",
                    "label": 0
                },
                {
                    "sent": "OK, yeah.",
                    "label": 0
                },
                {
                    "sent": "Well, I mean see.",
                    "label": 0
                },
                {
                    "sent": "So we have this this sign in terms of speed that it's all relatively fast.",
                    "label": 0
                },
                {
                    "sent": "If you know 'cause so right.",
                    "label": 0
                },
                {
                    "sent": "So see it depends.",
                    "label": 0
                },
                {
                    "sent": "So we have this parameter that tells us how far we jump, right?",
                    "label": 0
                },
                {
                    "sent": "It's a simple normal kernel, right?",
                    "label": 0
                },
                {
                    "sent": "So you know so we can adjust this parameter easily, you know, so see so as dimension as dimension increases, right?",
                    "label": 0
                },
                {
                    "sent": "So you know we have.",
                    "label": 0
                },
                {
                    "sent": "We can essentially calibrate the acceptance rates.",
                    "label": 0
                },
                {
                    "sent": "We have this one parameter and then.",
                    "label": 0
                },
                {
                    "sent": "We can control the jump and then.",
                    "label": 0
                },
                {
                    "sent": "We the acceptance rates for each element is given element is is relatively constant.",
                    "label": 0
                },
                {
                    "sent": "So it doesn't really matter.",
                    "label": 0
                },
                {
                    "sent": "You know.",
                    "label": 0
                },
                {
                    "sent": "You know we don't need 11 parameter for each prior.",
                    "label": 0
                },
                {
                    "sent": "Yeah so so we can.",
                    "label": 0
                },
                {
                    "sent": "We can collaborate that easy, but it's a good question.",
                    "label": 0
                },
                {
                    "sent": "Yeah, OK, so fine.",
                    "label": 0
                },
                {
                    "sent": "So let's move back to.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To our spatial models, right?",
                    "label": 0
                },
                {
                    "sent": "So in the classical approach you see we have multivariate normal distribution, right?",
                    "label": 1
                },
                {
                    "sent": "And that matrix DW that belongs to the to the right connan that matrix DW has been constructed with weights and parameterized with that with these two parameters rowant all right, there's two parameters for the entire account.",
                    "label": 0
                },
                {
                    "sent": "So what we do see?",
                    "label": 1
                },
                {
                    "sent": "Our our extension here is to consider this mixture approach.",
                    "label": 0
                },
                {
                    "sent": "That is, we say.",
                    "label": 0
                },
                {
                    "sent": "We have a multi billion normal here, parameterized with the with the matrix key that belongs to the correct account and now see we push back this DW one level down to be to make to make it in a pro specification for our hierarchical right?",
                    "label": 0
                },
                {
                    "sent": "So it's a it's a very simple extension that we did here and you see all we did is say, well, let's just just take what we know from the other body of the literature.",
                    "label": 0
                },
                {
                    "sent": "And and combine it with with the spatial models that that already exists, right?",
                    "label": 0
                },
                {
                    "sent": "So what does that give us?",
                    "label": 1
                },
                {
                    "sent": "Well, what we get see here.",
                    "label": 0
                },
                {
                    "sent": "The advantage of using this simple extension can be seen in the conditionals, right?",
                    "label": 0
                },
                {
                    "sent": "Because in the conditional see all those regression coefficients, A prayer for the regression coefficients come I prior induced by by the joint G which are prior.",
                    "label": 1
                },
                {
                    "sent": "We imposed on the precision matrix.",
                    "label": 0
                },
                {
                    "sent": "Right, so now this makes.",
                    "label": 0
                },
                {
                    "sent": "This makes the specification of the conditional to be very flexible.",
                    "label": 0
                },
                {
                    "sent": "And all these conditions now will be consistent with each other.",
                    "label": 0
                },
                {
                    "sent": "Which is exactly what we want.",
                    "label": 0
                },
                {
                    "sent": "Right, so we contrast this specification with what the classical approach gave us.",
                    "label": 0
                },
                {
                    "sent": "Right and then you see all your regression coefficients.",
                    "label": 0
                },
                {
                    "sent": "Here are are are essentially fixed.",
                    "label": 0
                },
                {
                    "sent": "You know, given modular on top right.",
                    "label": 0
                },
                {
                    "sent": "So so you know it's so that seems to be a nice result that seems to be a very flexible framework.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And now now.",
                    "label": 0
                },
                {
                    "sent": "Now let's see what what we can do it.",
                    "label": 0
                },
                {
                    "sent": "So what we can do is it relates to.",
                    "label": 0
                },
                {
                    "sent": "Specifying.",
                    "label": 0
                },
                {
                    "sent": "A matrix valued graphical models, right?",
                    "label": 1
                },
                {
                    "sent": "Because if you remember, we had a matrix right?",
                    "label": 0
                },
                {
                    "sent": "That's 49 by 11.",
                    "label": 1
                },
                {
                    "sent": "And and we want it to infer the graphs for one dimension, the column dimension given the spatial graph we've been looking right, so see.",
                    "label": 0
                },
                {
                    "sent": "So now our matrix Varian model is specified.",
                    "label": 1
                },
                {
                    "sent": "The parametrization specifies through row and column precision matrix, right?",
                    "label": 0
                },
                {
                    "sent": "And now the row and column precision matrix must belong to counts.",
                    "label": 0
                },
                {
                    "sent": "That are specified for the through the row and column graphs.",
                    "label": 0
                },
                {
                    "sent": "And what that gives us see our condition independence models for the rows and the columns given by by the edges of these two graphs, right?",
                    "label": 1
                },
                {
                    "sent": "So, so this is so.",
                    "label": 1
                },
                {
                    "sent": "This is the model we will be working on the the added difficulty relates to fact that now the row and column precision matrix is on no longer identify right?",
                    "label": 0
                },
                {
                    "sent": "So we need to somehow take care of.",
                    "label": 0
                },
                {
                    "sent": "And impose an extra constraint to make the models identifiable.",
                    "label": 0
                },
                {
                    "sent": "And now there are many ways to go about that.",
                    "label": 0
                },
                {
                    "sent": "We chose to go with the approach proposed by Wang and West that is just just set the one one element of one of the precision matrices to 1, right?",
                    "label": 0
                },
                {
                    "sent": "So to that end, we'll have to work with this auxiliary variable Z and take and they make that part of the.",
                    "label": 0
                },
                {
                    "sent": "Sampling models.",
                    "label": 0
                },
                {
                    "sent": "We will develop later on, right?",
                    "label": 0
                },
                {
                    "sent": "So that's what we get.",
                    "label": 0
                },
                {
                    "sent": "You see, very simple extension.",
                    "label": 0
                },
                {
                    "sent": "It's also in a sense less than what we want, right?",
                    "label": 0
                },
                {
                    "sent": "Because we assumed that the dependencies of the column variables of the columns, right?",
                    "label": 0
                },
                {
                    "sent": "So the dependencies, the cancer levels, for example, remain the same across the state.",
                    "label": 0
                },
                {
                    "sent": "Right, so in a sense, that could be seen a constraint, but but there are.",
                    "label": 0
                },
                {
                    "sent": "There are ways to solve that that constraint, right?",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now if we if we worried about matrix value data, there is no reason why we shouldn't do what we've just done here in in multiple dimensions, right?",
                    "label": 0
                },
                {
                    "sent": "So instead of having 2 dimensions, we can now and worry about matrix for your data.",
                    "label": 0
                },
                {
                    "sent": "We can worry about a race of any size, right?",
                    "label": 0
                },
                {
                    "sent": "So we have we can have any number of dimensions L at each.",
                    "label": 0
                },
                {
                    "sent": "A dimension we can have any number of variables, right?",
                    "label": 0
                },
                {
                    "sent": "And now the joint distribution for for this matrix variant model will be parameterized to precision matrices corresponding with each dimension.",
                    "label": 0
                },
                {
                    "sent": "Right, and that gives us a value joint distribution, right?",
                    "label": 0
                },
                {
                    "sent": "And now this precision matrixes will need to belong to counts corresponding with graphs associated with each dimension.",
                    "label": 0
                },
                {
                    "sent": "So in each dimension you could have, you could have either non graphs as in our spatial example or or unknown graphs right and so so so in this framework for example, you can account for, say, time dependence, right?",
                    "label": 0
                },
                {
                    "sent": "So you can have matrices observed across time.",
                    "label": 0
                },
                {
                    "sent": "And in this smaller right, say, say, you can assume your time graphs to be some to be just some autoregressive process of some kind, right?",
                    "label": 0
                },
                {
                    "sent": "And then you know you can for example, account for the presence of multiple cancers, right?",
                    "label": 0
                },
                {
                    "sent": "And you want to study the dependency, for example, that appear between primary and secondary cancers, which is something you cannot do with matrix various models of this kind, right?",
                    "label": 0
                },
                {
                    "sent": "And then the extension to array data is relatively straightforward, be once we put into place this machinery of Jewish shirt.",
                    "label": 0
                },
                {
                    "sent": "And and auxiliary variable corresponding with.",
                    "label": 0
                },
                {
                    "sent": "With the this identifiability constraint.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "So so see this is a very large and very flexible family of of models that can now be used either directly or as as priors for from random effects in some hierarchical models we can develop.",
                    "label": 0
                },
                {
                    "sent": "OK, and then again at each dimension the graphs can be either known and then if they are unknown to reversible jump MCMC, you can average across them, right?",
                    "label": 0
                },
                {
                    "sent": "I thought you would complain about something here.",
                    "label": 0
                },
                {
                    "sent": "That there is no complaint anywhere.",
                    "label": 0
                },
                {
                    "sent": "Matrix Variata River your data.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Having trouble understanding the.",
                    "label": 0
                },
                {
                    "sent": "Use the non square matrix.",
                    "label": 0
                },
                {
                    "sent": "First line.",
                    "label": 0
                },
                {
                    "sent": "Here.",
                    "label": 0
                },
                {
                    "sent": "You said chronic care product right?",
                    "label": 0
                },
                {
                    "sent": "It's the chronic care program.",
                    "label": 0
                },
                {
                    "sent": "Yes yeah yeah yeah yeah yeah.",
                    "label": 0
                },
                {
                    "sent": "Well it's a good good complaint, but that's not the complaint I was looking for.",
                    "label": 0
                },
                {
                    "sent": "Aquatic so all the printability, they.",
                    "label": 0
                },
                {
                    "sent": "Yes, so you can.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You so well I mean, OK, so you can do something fancy and mimic quite what they do there, right?",
                    "label": 0
                },
                {
                    "sent": "So so you can now have in the same dimension.",
                    "label": 0
                },
                {
                    "sent": "You can have several precision matrices exactly the way they do, right?",
                    "label": 0
                },
                {
                    "sent": "So in a sense, so see the beauty of this is that you can mimic.",
                    "label": 0
                },
                {
                    "sent": "Everything you know, every contribution that exists in this literature, but with this relatively straightforward extension that relates to using G, we shared and actually living in all the cone of matrices.",
                    "label": 0
                },
                {
                    "sent": "Right, so that's a very good comment.",
                    "label": 0
                },
                {
                    "sent": "OK, but but still is not the complaint I was looking for.",
                    "label": 0
                },
                {
                    "sent": "OK so I thought you you are going to complain about having one matrix.",
                    "label": 0
                },
                {
                    "sent": "Right so here see we have one array, so in the sense you'll say, why'd you work with the sample size of 1?",
                    "label": 0
                },
                {
                    "sent": "Right here, you know 'cause I, that's why I said, I give you one matrix right?",
                    "label": 0
                },
                {
                    "sent": "So so how can I determine a graph given that you know I have one matrix right?",
                    "label": 0
                },
                {
                    "sent": "Or two graphs or graphs in several dimensions, right?",
                    "label": 0
                },
                {
                    "sent": "For, for for a date?",
                    "label": 0
                },
                {
                    "sent": "Well, so it turns out, you see that apparently you have the sample size of 1.",
                    "label": 0
                },
                {
                    "sent": "But what really happens is that you see, when you look across rows.",
                    "label": 0
                },
                {
                    "sent": "Across columns or across any other dimension you can think as if you would have a sample size equal.",
                    "label": 0
                },
                {
                    "sent": "With the product of the other dimension, the dimension not associated with that dimension you're currently focusing on, right?",
                    "label": 0
                },
                {
                    "sent": "So for example, in order to determine the row graphs, the actual sample size that you have represent is given by the number of columns.",
                    "label": 0
                },
                {
                    "sent": "Right, that's what what what you what you have here you see.",
                    "label": 0
                },
                {
                    "sent": "So as you have more and more dimension than than when you sequentially update your graphs, corresponding with each dimension, then then what you really have is a product of the number of dimension corresponding with the number of levels corresponding with all the other dimensions, right?",
                    "label": 0
                },
                {
                    "sent": "So special.",
                    "label": 0
                },
                {
                    "sent": "You can but.",
                    "label": 0
                },
                {
                    "sent": "That's what appears in the sampler.",
                    "label": 0
                },
                {
                    "sent": "Right, so the way to get rid of super abilities to look at factor modes.",
                    "label": 0
                },
                {
                    "sent": "Right so and you can do it.",
                    "label": 0
                },
                {
                    "sent": "Right, but that's that's not this talk.",
                    "label": 0
                },
                {
                    "sent": "OK, so so fine, so now.",
                    "label": 0
                },
                {
                    "sent": "So now if we move back.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "222 our multivariate car models right?",
                    "label": 0
                },
                {
                    "sent": "So see the prior we have been working so hard to construct.",
                    "label": 0
                },
                {
                    "sent": "This is right here, right?",
                    "label": 0
                },
                {
                    "sent": "And that effectively gives us auto regressions at the row level or the column level that are precisely what multivariate car models give.",
                    "label": 0
                },
                {
                    "sent": "Right, so so these are consistent with the results.",
                    "label": 0
                },
                {
                    "sent": "Mardia present, for example, right?",
                    "label": 0
                },
                {
                    "sent": "So now.",
                    "label": 0
                },
                {
                    "sent": "So now let's see.",
                    "label": 0
                },
                {
                    "sent": "So we.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Will will go back to our cancer example, right?",
                    "label": 0
                },
                {
                    "sent": "So will construct a straightforward Poisson log linear model where our interest will be those X, ijs, the random effects.",
                    "label": 0
                },
                {
                    "sent": "Right so so see we have we have count data so so we cannot assume that matrix value normal distributions.",
                    "label": 0
                },
                {
                    "sent": "You know at the observation level we need to to stick it one level down.",
                    "label": 0
                },
                {
                    "sent": "Right now the prayer specification.",
                    "label": 0
                },
                {
                    "sent": "see I give it here and you know it's consistent with whatever the spatial literature was doing.",
                    "label": 0
                },
                {
                    "sent": "You see, with the exception of this part.",
                    "label": 0
                },
                {
                    "sent": "The are of RO that now is is down is 1 level down right?",
                    "label": 0
                },
                {
                    "sent": "So let's see.",
                    "label": 0
                },
                {
                    "sent": "So these are the four models we will now compare, right?",
                    "label": 0
                },
                {
                    "sent": "So see this is this is the joint distribution of the random effect.",
                    "label": 1
                },
                {
                    "sent": "OK, now these are the matrix value Gaussian graphical models right with uniform prior for.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For the column graphs, which are, which are the graphs among Kansas?",
                    "label": 0
                },
                {
                    "sent": "We try to determine, right?",
                    "label": 0
                },
                {
                    "sent": "So in order to see what the effect of the prior on the graph space is, we also look at this size space prior right?",
                    "label": 0
                },
                {
                    "sent": "So the size space prior, say, well, I will consider that all the graphs of a certain size are equally likely.",
                    "label": 0
                },
                {
                    "sent": "And now all the graph sizes will be equally like, right?",
                    "label": 0
                },
                {
                    "sent": "So so so we have two priors here because we want to see the effects of our specification for on the graphs level on on.",
                    "label": 0
                },
                {
                    "sent": "On our inferences right?",
                    "label": 0
                },
                {
                    "sent": "So now the third model is this model full.",
                    "label": 0
                },
                {
                    "sent": "So model fool just says, well, I will keep the column graph to be the complete graph.",
                    "label": 0
                },
                {
                    "sent": "That is, I won't impose any any additional constraints for the precision matrix someone associated with the cancer, right?",
                    "label": 0
                },
                {
                    "sent": "So that is effectively equivalent to saying, well, this matrix, Casey, you see instead of instead of having a Jewish, are prior to have a wish or prayer.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "So that's one level closer to the classical approach to analyzing aerial date, right?",
                    "label": 0
                },
                {
                    "sent": "So now will will move one level down and we look at the classical M car model in the classical N car model is obtained by moving that TR of row one level up.",
                    "label": 0
                },
                {
                    "sent": "So that's essentially equivalent to setting the row precision matrix.",
                    "label": 0
                },
                {
                    "sent": "To the dro.",
                    "label": 0
                },
                {
                    "sent": "Instead of imposing a primer on it.",
                    "label": 0
                },
                {
                    "sent": "Right, and now the Jewish.",
                    "label": 0
                },
                {
                    "sent": "Our prior for for the column Precision matrix remains the same as in the formal right, and now we can say impose any priors we want from the spatial autocorrelation, right?",
                    "label": 0
                },
                {
                    "sent": "So, so those are our four models, and that's you know if you read it the other way represents the transition from where we were at the beginning of talk at the beginning of the talk to where we are now.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "So let's see how well we do.",
                    "label": 0
                },
                {
                    "sent": "So we did a 10 fold cross validation exercise, predictive exercise right.",
                    "label": 0
                },
                {
                    "sent": "And and we look at the sum of the squared errors.",
                    "label": 0
                },
                {
                    "sent": "The variance of the predicted values, and then we also looked at the rank probability score to assess how well we do respect to the entire predictive distribution right?",
                    "label": 0
                },
                {
                    "sent": "And now you see that.",
                    "label": 0
                },
                {
                    "sent": "Our two models ggmu the model with the uniform prior on graphs and DGM as the model with.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With the size by spring graphs is effectively do much better have better predicted performance.",
                    "label": 0
                },
                {
                    "sent": "Then then the other two models.",
                    "label": 0
                },
                {
                    "sent": "Right, So what that tells us is that working with fewer parameters are all time by imposing constraints at the for the cancer level graphs.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Makes a lot of sense and now you see I.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'll come back to that slide, so those.",
                    "label": 0
                },
                {
                    "sent": "Types of constraints are are visible, you know, in in, in the kind of graphs we can look at dry.",
                    "label": 0
                },
                {
                    "sent": "So you see here for example.",
                    "label": 0
                },
                {
                    "sent": "So see this edge inclusion probabilities corresponding with the two models ggmu and DGM.",
                    "label": 0
                },
                {
                    "sent": "S right?",
                    "label": 0
                },
                {
                    "sent": "See so now you see the posterior probabilities of edges.",
                    "label": 0
                },
                {
                    "sent": "You know how they appear and disappear.",
                    "label": 0
                },
                {
                    "sent": "The average across that right?",
                    "label": 1
                },
                {
                    "sent": "And?",
                    "label": 0
                },
                {
                    "sent": "And you see that we are effectively working with a lot fewer parameters at all times.",
                    "label": 0
                },
                {
                    "sent": "Right so so see.",
                    "label": 0
                },
                {
                    "sent": "So that's a convergence plot.",
                    "label": 0
                },
                {
                    "sent": "See of the average graph sizes for the column graph.",
                    "label": 1
                },
                {
                    "sent": "So see we have about less than 25 edges on average, right?",
                    "label": 0
                },
                {
                    "sent": "So this is really close to what the priors the two prior say, which says.",
                    "label": 0
                },
                {
                    "sent": "Well, the graphs are priority, should have about 27.5 edges, but then you see the effect of the two priors, the what the priors.",
                    "label": 0
                },
                {
                    "sent": "Do on the graph space is quite different than.",
                    "label": 0
                },
                {
                    "sent": "Still we get something consistent right?",
                    "label": 0
                },
                {
                    "sent": "Either way, our sample size is not terribly great.",
                    "label": 0
                },
                {
                    "sent": "Is either 49 or 11 for the determination of other graph right?",
                    "label": 0
                },
                {
                    "sent": "So now let's see so.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I something else I want to point out, you see.",
                    "label": 0
                },
                {
                    "sent": "So what we did here is use all the samples computed 95% credible intervals and looked at their coverage and their length.",
                    "label": 1
                },
                {
                    "sent": "So what you see here is that the M car model had a coverage rate of .99, which is strange.",
                    "label": 0
                },
                {
                    "sent": "Right, so that is indicative of the fact that you know you really work with too many parameters, then then you should in a sense, but too few to get what you should be getting.",
                    "label": 0
                },
                {
                    "sent": "Right and then on the other hand, if you look at the mean length.",
                    "label": 1
                },
                {
                    "sent": "Of these intervals you see that.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We we get much smaller interval on average, right?",
                    "label": 0
                },
                {
                    "sent": "So so, so we impose constraints and those constraints are given by graphs and at the end of the day we can look at the graph like this.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right so so then you see you have to be careful when interpreting the graph becausw conditional independence for the random effects not translate for condition independence.",
                    "label": 0
                },
                {
                    "sent": "For for the actual observed data, because what you have there is something discrete.",
                    "label": 0
                },
                {
                    "sent": "So you can only go as far as as the Poisson rates, but not you cannot say anything about the actual cancer.",
                    "label": 0
                },
                {
                    "sent": "You need to step one level down.",
                    "label": 0
                },
                {
                    "sent": "However you see, this is perhaps indicative of how how diseases interact to each other in the presence of.",
                    "label": 0
                },
                {
                    "sent": "Of Of spatial interaction.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "So, uh, so?",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that's that I have.",
                    "label": 0
                },
                {
                    "sent": "I have another example here.",
                    "label": 0
                },
                {
                    "sent": "How much time do I have?",
                    "label": 0
                },
                {
                    "sent": "OK so but I I I won't go through it, it's a well.",
                    "label": 0
                },
                {
                    "sent": "It's actually very simple example because see it only involves C. We had 11 cancers before.",
                    "label": 0
                },
                {
                    "sent": "In this example we have.",
                    "label": 0
                },
                {
                    "sent": "Scores to forge math and an and verbal tests right so see here that so in this plot here you see a clear dependence between the two scores, so you would expect an edge to be present when you try to infer this graph, which now has only two vertices, right?",
                    "label": 0
                },
                {
                    "sent": "So you want to put an edge in between the two, right?",
                    "label": 0
                },
                {
                    "sent": "So you see that overall.",
                    "label": 0
                },
                {
                    "sent": "See you have you have posterior probability.",
                    "label": 0
                },
                {
                    "sent": "Of .8 so the models do what you would hope them to do right, given that that you observe this this kind of dependence right?",
                    "label": 0
                },
                {
                    "sent": "So we do something right over all right so now?",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now see I want you to think at the extension of this work right?",
                    "label": 0
                },
                {
                    "sent": "So we had we had counts that are that were observed at each state.",
                    "label": 0
                },
                {
                    "sent": "But you can think about those counts as one dimensional marginals of contingency tables, right?",
                    "label": 0
                },
                {
                    "sent": "So see in this example I have data from North Carolina, each County in North Carolina.",
                    "label": 1
                },
                {
                    "sent": "So so, so gender.",
                    "label": 0
                },
                {
                    "sent": "Mother's age at birth and race are possible factors that could influence.",
                    "label": 1
                },
                {
                    "sent": "Low birthweight, right?",
                    "label": 0
                },
                {
                    "sent": "So see.",
                    "label": 0
                },
                {
                    "sent": "So what we have here are 100 the number of counties in North Carolina 2 to the four tables.",
                    "label": 0
                },
                {
                    "sent": "Right, so now.",
                    "label": 0
                },
                {
                    "sent": "So now what we want to do is analyze that set of 102 to the four tables in the presence of spatial dependence.",
                    "label": 0
                },
                {
                    "sent": "Now think about the fact that you.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Might not have complete individual level data for for the individual level data might not be observed throughout.",
                    "label": 0
                },
                {
                    "sent": "You might have partial information for some of these samples, So what that means is that you would know some some lower dimensional marginal totals.",
                    "label": 0
                },
                {
                    "sent": "So now what you will have to do is perform imputation, given the constraints that you have.",
                    "label": 0
                },
                {
                    "sent": "So that's why sampling tables is really key.",
                    "label": 0
                },
                {
                    "sent": "And sampling tables is precisely the name of the game in ecological inference.",
                    "label": 0
                },
                {
                    "sent": "Right, so in ecological inference they they have deal effectively with two by two tables.",
                    "label": 0
                },
                {
                    "sent": "There have been recent extension two I by J tables and that's about it, right?",
                    "label": 0
                },
                {
                    "sent": "So this see we talked about this body of literature that refers to graphical models then that that comes from the work of Dempster.",
                    "label": 0
                },
                {
                    "sent": "There's this other body of literature.",
                    "label": 0
                },
                {
                    "sent": "That relates to spatial epidemic Epidemiology.",
                    "label": 0
                },
                {
                    "sent": "And now there is the third body of literature.",
                    "label": 0
                },
                {
                    "sent": "That that that is, is that just ways to be joined with the other two.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right, and that that that really refers to sampling tables and in constructing C dependencies for this kind of data?",
                    "label": 0
                },
                {
                    "sent": "Why is this a hard problem?",
                    "label": 0
                },
                {
                    "sent": "Well, this is a much harder problem then the problem we talked about before, because now we have higher order interactions, right?",
                    "label": 0
                },
                {
                    "sent": "You don't have only first or the interaction, you have higher order interaction, so somehow see you need you need to take that into account.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So, so I think I will stop here.",
                    "label": 0
                },
                {
                    "sent": "You see, there's there's plenty of work to be done.",
                    "label": 0
                },
                {
                    "sent": "There are some papers and so.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Plan on my website and you're welcome to look at them.",
                    "label": 0
                }
            ]
        }
    }
}