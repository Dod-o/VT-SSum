{
    "id": "7dxwcpcb3hf3yyv6homruunsyc2leifk",
    "title": "Graph Similarity, I-Divergences and Entropic Manifold Alignment",
    "info": {
        "author": [
            "Francisco Escolano, Department of Science of the Computation and Artificial Intelligence, University of Alicante"
        ],
        "published": "Sept. 13, 2010",
        "recorded": "August 2010",
        "category": [
            "Top->Computer Science->Pattern Recognition"
        ]
    },
    "url": "http://videolectures.net/ssspr2010_escolano_gsi/",
    "segmentation": [
        [
            "OK, so.",
            "At the end of this talk is to present some.",
            "For machine information theoretic divergences, how can these divergences apply to measure graph similarity in an embedding context?"
        ],
        [
            "So.",
            "Russian book about book.",
            "About information theory.",
            "This sort of presentation of of the book itself so shaded areas are problems in computer vision and pattern recognition.",
            "And the lines.",
            "Connecting them are types that these measures, including similarity, obviously measures proper principles into the MDL.",
            "As Edwin noted before, and theories like mathematical elements.",
            "So you can see that.",
            "But similarity lines or the measure line is central element in old computer vision problems like object recognition or classification and even segmentation.",
            "So the idea is how to apply this."
        ],
        [
            "Philip, this information theoretic elements to graphs, so we have two ways of doing that.",
            "One way is to better definition of of these measures in the domain of graphs, for instance, and help them be opposite poles for trees or graphs.",
            "Other alternative is to always have victimization of the graphs or translation to the graphs into into another domain, like so many fault and try to work there.",
            "So this what we are focusing this part and and we're using spectral graph theory for today."
        ],
        [
            "Terms and.",
            "The basic idea is to work with a couple of graphs.",
            "For instance, if we want to measure the.",
            "We simulated the OR simulated division two graphs or different notes.",
            "So we take the laplacians and.",
            "The volume rolled.",
            "The graph is given by the trace of the degree metrics."
        ],
        [
            "And a degree function of the graph is given by some kind of correlation between the eigenvalues.",
            "So for the new function we can we can compute the commute times.",
            "Good times are given by hitting time.",
            "Hidden time is defined it as expected number of steps before.",
            "From our note, I before visiting Jay and the commute time is.",
            "Some of his time of going to out to J&J twice."
        ],
        [
            "So.",
            "Those are big function.",
            "The commute time is given by by this expression.",
            "So this means that this induces a metric between the nodes in the graph.",
            "So.",
            "Several interesting then when you embed the graph using the computer time embedding, we see consolator.",
            "The greedy and this is within the nodes.",
            "The points in the in the Medina space is exactly the computer time between the nodes in the graph.",
            "So to compute commute times Inspector away, you can use this kind of instead of a correlation.",
            "You have a difference of quadratic kind of distance between the Asian vectors normalized by the eigenvalues stepped in by the second because the first 0.",
            "So it's not useful."
        ],
        [
            "So then every coordinates is R. Of this kind.",
            "So for both graphs that include these these volumes and include the metrics of eigenvectors.",
            "The the conductors and.",
            "The.",
            "They wanna metric so Fagan values for normalizing.",
            "So the time embedding, as I said before, the period distance between pairs of nodes are equal to computer time."
        ],
        [
            "So instead of using because we can use all the nodes, all the dimensions in the new space, we reduce the coordinates and what we're doing there using the dimension is some kind of low pass filtering of the manifold.",
            "The number of dimensions I will talk later about what is the optimal number of dimensions, because one way of doing that is to compute.",
            "What does indecisive dimension of the manifold?",
            "OK, so the resulting etc.",
            "The white given color of your pattern given.",
            "Vector in the new space is something like that starting from the 2nd to the T + 1 dimensions, 'cause you were skipping the First Nation and the same happens with column of the other."
        ],
        [
            "So the idea now is OK. Good time to find some metrics.",
            "We have this.",
            "Approximation because we are comparing two columns without not exactly the complete dimension of the graph, so.",
            "Actually, where we have is.",
            "The reputation is bounded by the real computer time.",
            "That was a quality where this is the number of notes, of course."
        ],
        [
            "So.",
            "What we need now is we have a cloud of points and then with the mission of Space D dimensional space corresponding to one graph and other points corresponding to their graph, and the idea is to make a no rigid alignment in this domain.",
            "This multi dimensional nonrigid alignment in order to minimize the to find the transformation minimizing.",
            "This is normal, which is a typical way of formulating that and."
        ],
        [
            "Up for that.",
            "The for that end, what we need is at.",
            "Another reason for.",
            "Playing that role of multi dimensional alignment and one of the best more recent proposed.",
            "Algorithms which are not constrained by 2D or 3D points is the coherent point drift formulation and incoherent problem.",
            "This confirmation what you are doing is something like minimizing this energy depends on on this.",
            "Kind of difference within the note.",
            "In one graph on the note in our graph plus the rail station 10, which is the usual where you're doing that."
        ],
        [
            "Account of registration.",
            "So the probability.",
            "We have this kind of very deformulation of matching this note of 1 graph and is not on the other graph and the relation function inside.",
            "We use well the trace of general information, certainly that."
        ],
        [
            "OK, so because they couldn't verify, just to summarize is just an EM algorithm where from the probability you estimate this transformation and for the transformation estimate the probability."
        ],
        [
            "OK, do you example of how to how I do different graphs and these are the result after the alignment.",
            "That is both many for the form.",
            "This of course until you mentioned just to show the results, but we're really working in three in five dimensions.",
            "So this is the."
        ],
        [
            "Kind of alignment map from that alignment.",
            "We need to.",
            "One's alignment is.",
            "Then we can use the energy or other information, but as we will see later, using only the energy of this information gives not.",
            "Results in terms of.",
            "The two other code analysis.",
            "So there we are here in this paper.",
            "Just just saying that we are using the normalized Laplacian instead of the original passion for stability and."
        ],
        [
            "The cause of this work is to complement this energy with a principal similarity measure between the manifolds.",
            "Which requires to incorporate a criterion that compares the special distribution.",
            "Because we are doing matching, but some many of the nodes.",
            "When you align the shapes, I'm not much and they are is important that distribution to compute the similarity measure."
        ],
        [
            "So we are following this kind of the recent approach of.",
            "Driving point separation, which are distributional approach where shapes or in this case multi dimensional manifolds are our considered as probability distributions.",
            "OK, so.",
            "So this approach has been used for registration, but not for similarity."
        ],
        [
            "Basics.",
            "So here we define measure, called the normalized entropy score variation, which is something like the entropy of the transformed data.",
            "The graph minus the entropy of the other ref, normalized.",
            "Obviously because graphs are different size, but it turns out that this is except is Department of the mutual information between the transformed data and the.",
            "And the original data browse the joint entropy.",
            "What we are doing is that if you are minimizing that, we are maximizing the mutual information between the two."
        ],
        [
            "Pointclouds so this.",
            "Oops.",
            "Enjoy the similarity and of course we need to submit Symmetrized Ness.",
            "This this this normalized entropy to infer a kernel.",
            "Probably distributions."
        ],
        [
            "So some normalization is clear.",
            "They said that have you the transformation from here to here is not equal to the quantity customers formation.",
            "But we are going to consider both transformation in our similarity matrixes.",
            "So we have this extension."
        ],
        [
            "So we can prove that easily that.",
            "This infers a kernel, and because the entropy is negative definite and this structure to prove that this is also negative definite and.",
            "Make a big different.",
            "This is closed under the same so we have that this is going to be difficult but however the sum of entropy is not negative, but we have does.",
            "This is positive definite for a + 0 greater than 0."
        ],
        [
            "OK, So what we have is this kind of kernel.",
            "And this camera using the proper parameters.",
            "If you have something like a training and training set and test set, we can even find the optimal way weights of the parameters optimal value of the parameters and use them in VM.",
            "So we solve this consistent with other families of kernel based off information theoretic measures like the Jason Shannon, Divergent and.",
            "What we're doing here is OK is applying this kind of approach to compare point distribution representing graphs."
        ],
        [
            "So of course the first element in information theory is entropy estimation, because we are here in a high dimensional space, so interview summation is turns out to be not too complicated.",
            "If you use a bypass estimator and expanding in our electrodes in this in this world."
        ],
        [
            "And one of them is the is the learning custom.",
            "Later you can take this quantity to estimate the entropy.",
            "So then you have the entropies you have.",
            "You can measure you can you can compute the similarity measure.",
            "You can if you want, you can take the kernel and see what happens."
        ],
        [
            "So for this thing we have selected.",
            "Challenging that the base is not well known that the base, but this is very challenging because we have 100 shapes.",
            "From 30 classes, officious, high interclass availability at many overlap between classes.",
            "Then classes with one species with I'm not included in the analysis, and curves 11 gases.",
            "This one to three individuals, five with four to six, and only four classes with more than six species.",
            "6 individuals.",
            "In this case, how many scarves?",
            "Find the measure that produces an average curve above the diagonal and the trace that is the formation energy in this case is close to the diagonal, so we want something setting better.",
            "This is the case of the proposed measure.",
            "We use the dimension is 5.",
            "We have because in this case the intrinsic dimension of the manifold is overestimated.",
            "Between 9:00 and something like 9 and 11, so we apply that to our data.",
            "Every measure is going to fail."
        ],
        [
            "So there's some examples of.",
            "Elements from the same species but quite different shape.",
            "So and this.",
            "Square root and.",
            "About this is this some kind better about this?",
            "Some results about what is the average recall versus retrieval, and we compare or measure with this this one with the Health Center of the vergence.",
            "In both case we compute from.",
            "Assume the translation OK and his special divergences based on his computer with using is comparing the two and three in multidimensions multiple dimensions and finding the edges of the of the MST that connect notes are different.",
            "Clouds of points.",
            "So this is the KD partition is another method for evaluating the entropy.",
            "Just just for playing with that kind of methods.",
            "This is the symmetrized.",
            "Goodbye never diverges Juno this induce also kernel and this is the Jason Chalice.",
            "We just those related to the Jensen Shannon.",
            "Divergent with this seems to be pretty bad in this context.",
            "So this is.",
            "This is important because in high dimensions we find that our measure is is very nice behavior.",
            "Behavior is very nice.",
            "You know dimensions when we apply the same approach, but for shapes, not for graphs.",
            "We found that this.",
            "Herb.",
            "Similar app and sometimes overperforming our measure."
        ],
        [
            "OK, so I'm going to approach can be obtained because instead of using the computer time approach, we can use another kind of manifold or bending like the lapasan bablin.",
            "The errors as you remove the notes are quite similar.",
            "Does a gunfighter more body else in city?",
            "Then you know that it means that the general approach I am proposing here is to take the.",
            "Document of the of the new digital alignment dimensional, not legit alignment and consider motor dimensional.",
            "I divergences for measure SIM."
        ],
        [
            "So for to work we got recast.",
            "The other graph problems establishing with distance."
        ],
        [
            "And so on.",
            "We can also incorporate attributes.",
            "Duralast Abet directed graphs.",
            "Anyway, integration of speculative theory and information there seems to be a promising approach to discovering new techniques, and that's all.",
            "Thank you for your attention.",
            "Thanks Francisco refund for a couple of questions.",
            "Question.",
            "I was wondering whether this framework can be in principle be generalized to hypergraphs.",
            "Also, maybe it depends of if you have many folder you project that then you have a multi dimensional algorithm so the measures.",
            "The key point here is that you have to.",
            "2.",
            "To take similarity measures with can work well in multi dimensional cases because many folks are multi dimensional and the alignment is step is a registration to start to work.",
            "To start to talk.",
            "Just not after that you need something more than counting on the energy.",
            "Add a question.",
            "OK, so let's thank Francisco again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "At the end of this talk is to present some.",
                    "label": 0
                },
                {
                    "sent": "For machine information theoretic divergences, how can these divergences apply to measure graph similarity in an embedding context?",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Russian book about book.",
                    "label": 0
                },
                {
                    "sent": "About information theory.",
                    "label": 0
                },
                {
                    "sent": "This sort of presentation of of the book itself so shaded areas are problems in computer vision and pattern recognition.",
                    "label": 0
                },
                {
                    "sent": "And the lines.",
                    "label": 0
                },
                {
                    "sent": "Connecting them are types that these measures, including similarity, obviously measures proper principles into the MDL.",
                    "label": 0
                },
                {
                    "sent": "As Edwin noted before, and theories like mathematical elements.",
                    "label": 0
                },
                {
                    "sent": "So you can see that.",
                    "label": 0
                },
                {
                    "sent": "But similarity lines or the measure line is central element in old computer vision problems like object recognition or classification and even segmentation.",
                    "label": 0
                },
                {
                    "sent": "So the idea is how to apply this.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Philip, this information theoretic elements to graphs, so we have two ways of doing that.",
                    "label": 0
                },
                {
                    "sent": "One way is to better definition of of these measures in the domain of graphs, for instance, and help them be opposite poles for trees or graphs.",
                    "label": 1
                },
                {
                    "sent": "Other alternative is to always have victimization of the graphs or translation to the graphs into into another domain, like so many fault and try to work there.",
                    "label": 1
                },
                {
                    "sent": "So this what we are focusing this part and and we're using spectral graph theory for today.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Terms and.",
                    "label": 0
                },
                {
                    "sent": "The basic idea is to work with a couple of graphs.",
                    "label": 0
                },
                {
                    "sent": "For instance, if we want to measure the.",
                    "label": 0
                },
                {
                    "sent": "We simulated the OR simulated division two graphs or different notes.",
                    "label": 0
                },
                {
                    "sent": "So we take the laplacians and.",
                    "label": 0
                },
                {
                    "sent": "The volume rolled.",
                    "label": 0
                },
                {
                    "sent": "The graph is given by the trace of the degree metrics.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And a degree function of the graph is given by some kind of correlation between the eigenvalues.",
                    "label": 0
                },
                {
                    "sent": "So for the new function we can we can compute the commute times.",
                    "label": 0
                },
                {
                    "sent": "Good times are given by hitting time.",
                    "label": 1
                },
                {
                    "sent": "Hidden time is defined it as expected number of steps before.",
                    "label": 1
                },
                {
                    "sent": "From our note, I before visiting Jay and the commute time is.",
                    "label": 0
                },
                {
                    "sent": "Some of his time of going to out to J&J twice.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Those are big function.",
                    "label": 0
                },
                {
                    "sent": "The commute time is given by by this expression.",
                    "label": 1
                },
                {
                    "sent": "So this means that this induces a metric between the nodes in the graph.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Several interesting then when you embed the graph using the computer time embedding, we see consolator.",
                    "label": 0
                },
                {
                    "sent": "The greedy and this is within the nodes.",
                    "label": 0
                },
                {
                    "sent": "The points in the in the Medina space is exactly the computer time between the nodes in the graph.",
                    "label": 0
                },
                {
                    "sent": "So to compute commute times Inspector away, you can use this kind of instead of a correlation.",
                    "label": 0
                },
                {
                    "sent": "You have a difference of quadratic kind of distance between the Asian vectors normalized by the eigenvalues stepped in by the second because the first 0.",
                    "label": 0
                },
                {
                    "sent": "So it's not useful.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So then every coordinates is R. Of this kind.",
                    "label": 0
                },
                {
                    "sent": "So for both graphs that include these these volumes and include the metrics of eigenvectors.",
                    "label": 0
                },
                {
                    "sent": "The the conductors and.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "They wanna metric so Fagan values for normalizing.",
                    "label": 0
                },
                {
                    "sent": "So the time embedding, as I said before, the period distance between pairs of nodes are equal to computer time.",
                    "label": 1
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So instead of using because we can use all the nodes, all the dimensions in the new space, we reduce the coordinates and what we're doing there using the dimension is some kind of low pass filtering of the manifold.",
                    "label": 0
                },
                {
                    "sent": "The number of dimensions I will talk later about what is the optimal number of dimensions, because one way of doing that is to compute.",
                    "label": 0
                },
                {
                    "sent": "What does indecisive dimension of the manifold?",
                    "label": 0
                },
                {
                    "sent": "OK, so the resulting etc.",
                    "label": 0
                },
                {
                    "sent": "The white given color of your pattern given.",
                    "label": 0
                },
                {
                    "sent": "Vector in the new space is something like that starting from the 2nd to the T + 1 dimensions, 'cause you were skipping the First Nation and the same happens with column of the other.",
                    "label": 1
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the idea now is OK. Good time to find some metrics.",
                    "label": 0
                },
                {
                    "sent": "We have this.",
                    "label": 0
                },
                {
                    "sent": "Approximation because we are comparing two columns without not exactly the complete dimension of the graph, so.",
                    "label": 0
                },
                {
                    "sent": "Actually, where we have is.",
                    "label": 0
                },
                {
                    "sent": "The reputation is bounded by the real computer time.",
                    "label": 0
                },
                {
                    "sent": "That was a quality where this is the number of notes, of course.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "What we need now is we have a cloud of points and then with the mission of Space D dimensional space corresponding to one graph and other points corresponding to their graph, and the idea is to make a no rigid alignment in this domain.",
                    "label": 0
                },
                {
                    "sent": "This multi dimensional nonrigid alignment in order to minimize the to find the transformation minimizing.",
                    "label": 0
                },
                {
                    "sent": "This is normal, which is a typical way of formulating that and.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Up for that.",
                    "label": 0
                },
                {
                    "sent": "The for that end, what we need is at.",
                    "label": 0
                },
                {
                    "sent": "Another reason for.",
                    "label": 0
                },
                {
                    "sent": "Playing that role of multi dimensional alignment and one of the best more recent proposed.",
                    "label": 0
                },
                {
                    "sent": "Algorithms which are not constrained by 2D or 3D points is the coherent point drift formulation and incoherent problem.",
                    "label": 1
                },
                {
                    "sent": "This confirmation what you are doing is something like minimizing this energy depends on on this.",
                    "label": 0
                },
                {
                    "sent": "Kind of difference within the note.",
                    "label": 0
                },
                {
                    "sent": "In one graph on the note in our graph plus the rail station 10, which is the usual where you're doing that.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Account of registration.",
                    "label": 0
                },
                {
                    "sent": "So the probability.",
                    "label": 0
                },
                {
                    "sent": "We have this kind of very deformulation of matching this note of 1 graph and is not on the other graph and the relation function inside.",
                    "label": 0
                },
                {
                    "sent": "We use well the trace of general information, certainly that.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so because they couldn't verify, just to summarize is just an EM algorithm where from the probability you estimate this transformation and for the transformation estimate the probability.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, do you example of how to how I do different graphs and these are the result after the alignment.",
                    "label": 1
                },
                {
                    "sent": "That is both many for the form.",
                    "label": 0
                },
                {
                    "sent": "This of course until you mentioned just to show the results, but we're really working in three in five dimensions.",
                    "label": 0
                },
                {
                    "sent": "So this is the.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Kind of alignment map from that alignment.",
                    "label": 0
                },
                {
                    "sent": "We need to.",
                    "label": 0
                },
                {
                    "sent": "One's alignment is.",
                    "label": 0
                },
                {
                    "sent": "Then we can use the energy or other information, but as we will see later, using only the energy of this information gives not.",
                    "label": 0
                },
                {
                    "sent": "Results in terms of.",
                    "label": 0
                },
                {
                    "sent": "The two other code analysis.",
                    "label": 0
                },
                {
                    "sent": "So there we are here in this paper.",
                    "label": 0
                },
                {
                    "sent": "Just just saying that we are using the normalized Laplacian instead of the original passion for stability and.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The cause of this work is to complement this energy with a principal similarity measure between the manifolds.",
                    "label": 1
                },
                {
                    "sent": "Which requires to incorporate a criterion that compares the special distribution.",
                    "label": 1
                },
                {
                    "sent": "Because we are doing matching, but some many of the nodes.",
                    "label": 0
                },
                {
                    "sent": "When you align the shapes, I'm not much and they are is important that distribution to compute the similarity measure.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we are following this kind of the recent approach of.",
                    "label": 1
                },
                {
                    "sent": "Driving point separation, which are distributional approach where shapes or in this case multi dimensional manifolds are our considered as probability distributions.",
                    "label": 1
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "So this approach has been used for registration, but not for similarity.",
                    "label": 1
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Basics.",
                    "label": 0
                },
                {
                    "sent": "So here we define measure, called the normalized entropy score variation, which is something like the entropy of the transformed data.",
                    "label": 0
                },
                {
                    "sent": "The graph minus the entropy of the other ref, normalized.",
                    "label": 0
                },
                {
                    "sent": "Obviously because graphs are different size, but it turns out that this is except is Department of the mutual information between the transformed data and the.",
                    "label": 0
                },
                {
                    "sent": "And the original data browse the joint entropy.",
                    "label": 1
                },
                {
                    "sent": "What we are doing is that if you are minimizing that, we are maximizing the mutual information between the two.",
                    "label": 1
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Pointclouds so this.",
                    "label": 0
                },
                {
                    "sent": "Oops.",
                    "label": 0
                },
                {
                    "sent": "Enjoy the similarity and of course we need to submit Symmetrized Ness.",
                    "label": 0
                },
                {
                    "sent": "This this this normalized entropy to infer a kernel.",
                    "label": 0
                },
                {
                    "sent": "Probably distributions.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So some normalization is clear.",
                    "label": 0
                },
                {
                    "sent": "They said that have you the transformation from here to here is not equal to the quantity customers formation.",
                    "label": 0
                },
                {
                    "sent": "But we are going to consider both transformation in our similarity matrixes.",
                    "label": 0
                },
                {
                    "sent": "So we have this extension.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we can prove that easily that.",
                    "label": 0
                },
                {
                    "sent": "This infers a kernel, and because the entropy is negative definite and this structure to prove that this is also negative definite and.",
                    "label": 1
                },
                {
                    "sent": "Make a big different.",
                    "label": 1
                },
                {
                    "sent": "This is closed under the same so we have that this is going to be difficult but however the sum of entropy is not negative, but we have does.",
                    "label": 1
                },
                {
                    "sent": "This is positive definite for a + 0 greater than 0.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, So what we have is this kind of kernel.",
                    "label": 1
                },
                {
                    "sent": "And this camera using the proper parameters.",
                    "label": 0
                },
                {
                    "sent": "If you have something like a training and training set and test set, we can even find the optimal way weights of the parameters optimal value of the parameters and use them in VM.",
                    "label": 0
                },
                {
                    "sent": "So we solve this consistent with other families of kernel based off information theoretic measures like the Jason Shannon, Divergent and.",
                    "label": 1
                },
                {
                    "sent": "What we're doing here is OK is applying this kind of approach to compare point distribution representing graphs.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So of course the first element in information theory is entropy estimation, because we are here in a high dimensional space, so interview summation is turns out to be not too complicated.",
                    "label": 0
                },
                {
                    "sent": "If you use a bypass estimator and expanding in our electrodes in this in this world.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And one of them is the is the learning custom.",
                    "label": 0
                },
                {
                    "sent": "Later you can take this quantity to estimate the entropy.",
                    "label": 0
                },
                {
                    "sent": "So then you have the entropies you have.",
                    "label": 0
                },
                {
                    "sent": "You can measure you can you can compute the similarity measure.",
                    "label": 0
                },
                {
                    "sent": "You can if you want, you can take the kernel and see what happens.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for this thing we have selected.",
                    "label": 0
                },
                {
                    "sent": "Challenging that the base is not well known that the base, but this is very challenging because we have 100 shapes.",
                    "label": 0
                },
                {
                    "sent": "From 30 classes, officious, high interclass availability at many overlap between classes.",
                    "label": 1
                },
                {
                    "sent": "Then classes with one species with I'm not included in the analysis, and curves 11 gases.",
                    "label": 1
                },
                {
                    "sent": "This one to three individuals, five with four to six, and only four classes with more than six species.",
                    "label": 0
                },
                {
                    "sent": "6 individuals.",
                    "label": 0
                },
                {
                    "sent": "In this case, how many scarves?",
                    "label": 1
                },
                {
                    "sent": "Find the measure that produces an average curve above the diagonal and the trace that is the formation energy in this case is close to the diagonal, so we want something setting better.",
                    "label": 0
                },
                {
                    "sent": "This is the case of the proposed measure.",
                    "label": 0
                },
                {
                    "sent": "We use the dimension is 5.",
                    "label": 0
                },
                {
                    "sent": "We have because in this case the intrinsic dimension of the manifold is overestimated.",
                    "label": 0
                },
                {
                    "sent": "Between 9:00 and something like 9 and 11, so we apply that to our data.",
                    "label": 0
                },
                {
                    "sent": "Every measure is going to fail.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So there's some examples of.",
                    "label": 0
                },
                {
                    "sent": "Elements from the same species but quite different shape.",
                    "label": 0
                },
                {
                    "sent": "So and this.",
                    "label": 0
                },
                {
                    "sent": "Square root and.",
                    "label": 0
                },
                {
                    "sent": "About this is this some kind better about this?",
                    "label": 0
                },
                {
                    "sent": "Some results about what is the average recall versus retrieval, and we compare or measure with this this one with the Health Center of the vergence.",
                    "label": 1
                },
                {
                    "sent": "In both case we compute from.",
                    "label": 0
                },
                {
                    "sent": "Assume the translation OK and his special divergences based on his computer with using is comparing the two and three in multidimensions multiple dimensions and finding the edges of the of the MST that connect notes are different.",
                    "label": 0
                },
                {
                    "sent": "Clouds of points.",
                    "label": 0
                },
                {
                    "sent": "So this is the KD partition is another method for evaluating the entropy.",
                    "label": 0
                },
                {
                    "sent": "Just just for playing with that kind of methods.",
                    "label": 0
                },
                {
                    "sent": "This is the symmetrized.",
                    "label": 0
                },
                {
                    "sent": "Goodbye never diverges Juno this induce also kernel and this is the Jason Chalice.",
                    "label": 0
                },
                {
                    "sent": "We just those related to the Jensen Shannon.",
                    "label": 0
                },
                {
                    "sent": "Divergent with this seems to be pretty bad in this context.",
                    "label": 0
                },
                {
                    "sent": "So this is.",
                    "label": 0
                },
                {
                    "sent": "This is important because in high dimensions we find that our measure is is very nice behavior.",
                    "label": 0
                },
                {
                    "sent": "Behavior is very nice.",
                    "label": 0
                },
                {
                    "sent": "You know dimensions when we apply the same approach, but for shapes, not for graphs.",
                    "label": 0
                },
                {
                    "sent": "We found that this.",
                    "label": 0
                },
                {
                    "sent": "Herb.",
                    "label": 0
                },
                {
                    "sent": "Similar app and sometimes overperforming our measure.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so I'm going to approach can be obtained because instead of using the computer time approach, we can use another kind of manifold or bending like the lapasan bablin.",
                    "label": 0
                },
                {
                    "sent": "The errors as you remove the notes are quite similar.",
                    "label": 0
                },
                {
                    "sent": "Does a gunfighter more body else in city?",
                    "label": 0
                },
                {
                    "sent": "Then you know that it means that the general approach I am proposing here is to take the.",
                    "label": 0
                },
                {
                    "sent": "Document of the of the new digital alignment dimensional, not legit alignment and consider motor dimensional.",
                    "label": 0
                },
                {
                    "sent": "I divergences for measure SIM.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for to work we got recast.",
                    "label": 0
                },
                {
                    "sent": "The other graph problems establishing with distance.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so on.",
                    "label": 0
                },
                {
                    "sent": "We can also incorporate attributes.",
                    "label": 0
                },
                {
                    "sent": "Duralast Abet directed graphs.",
                    "label": 0
                },
                {
                    "sent": "Anyway, integration of speculative theory and information there seems to be a promising approach to discovering new techniques, and that's all.",
                    "label": 1
                },
                {
                    "sent": "Thank you for your attention.",
                    "label": 0
                },
                {
                    "sent": "Thanks Francisco refund for a couple of questions.",
                    "label": 0
                },
                {
                    "sent": "Question.",
                    "label": 0
                },
                {
                    "sent": "I was wondering whether this framework can be in principle be generalized to hypergraphs.",
                    "label": 0
                },
                {
                    "sent": "Also, maybe it depends of if you have many folder you project that then you have a multi dimensional algorithm so the measures.",
                    "label": 0
                },
                {
                    "sent": "The key point here is that you have to.",
                    "label": 0
                },
                {
                    "sent": "2.",
                    "label": 0
                },
                {
                    "sent": "To take similarity measures with can work well in multi dimensional cases because many folks are multi dimensional and the alignment is step is a registration to start to work.",
                    "label": 0
                },
                {
                    "sent": "To start to talk.",
                    "label": 0
                },
                {
                    "sent": "Just not after that you need something more than counting on the energy.",
                    "label": 0
                },
                {
                    "sent": "Add a question.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's thank Francisco again.",
                    "label": 0
                }
            ]
        }
    }
}