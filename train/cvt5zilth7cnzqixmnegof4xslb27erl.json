{
    "id": "cvt5zilth7cnzqixmnegof4xslb27erl",
    "title": "Action Recognition with Exemplar Based 2.5D Graph Matching",
    "info": {
        "author": [
            "Bangpeng Yao, Computer Science Department, Stanford University"
        ],
        "chairman": [
            "Michael J. Black, Max Planck Institute for Intelligent Systems, Max Planck Institute",
            "Ivan Laptev, INRIA - The French National Institute for Research in Computer Science and Control"
        ],
        "published": "Nov. 12, 2012",
        "recorded": "October 2012",
        "category": [
            "Top->Computer Science->Computer Vision"
        ]
    },
    "url": "http://videolectures.net/eccv2012_yao_action/",
    "segmentation": [
        [
            "Good afternoon everyone.",
            "My name is a bump on y'all.",
            "This is a joint work with my advisor faithfully."
        ],
        [
            "Our goal is to recognize human actions in still images.",
            "This task is easy for humans, but it's very challenging for computers.",
            "For example, in those two in."
        ],
        [
            "Is the human poses are essentially very similar, but viewpoint changes make the configuration over the body parts very different."
        ],
        [
            "Do we have to perform some very complicated 3D modeling of humans for this problem?"
        ],
        [
            "It is not necessary to do that.",
            "We can take it down, take advantage of existing human pose estimation methods and converting 2D human poses to 3D, and then rotate the 3D skeletons to match one image to the other.",
            "Also inspired by the previous work of using appearance features for action recognition, we also extract image features within within the bounding boxes surrounding each keypoint of the human body parts.",
            "Therefore, all action representation."
        ],
        [
            "Use the 2.5 D graph which consists of view independent 3D posts and reach to the appearance features."
        ],
        [
            "Further, the challenge of Action classification is not limited to viewpoint changes, so we also."
        ],
        [
            "Propose the example based recognition method where we only consider the similarity between a test image and its closest training image.",
            "Instead of considering similarity between the test image and all the training images."
        ],
        [
            "Here's the outline of the rest of the talk.",
            "First are the details of the two point 5D representation an example of basically classification.",
            "Then I will show some experimental results."
        ],
        [
            "OK, let's see what is a 2.5 D action representation."
        ],
        [
            "Given the image, we first estimate the 2D keypoint locations of the human poses of the human body.",
            "Parts like the head, torso, arms and so on."
        ],
        [
            "The two D Keypoint locations are then converted to a 3D skeleton by estimating the depth of each keypoint."
        ],
        [
            "For each keypoint we also extract the image region surrounding this key point and represent this region using a special pyramid."
        ],
        [
            "Combining the 3D locations of the key points and the corresponding appearance feature surround of the location image locations surrounding each keypoint, we form a 2.5 D graph over human action.",
            "The non trivial part of obtaining the 2.5 D graph is to obtain the 3D keypoint locations.",
            "This involves 2 steps.",
            "One is to estimate the 2D keypoint locations there is to convert the 2D keypoint locations to three."
        ],
        [
            "In our approach to obtain the 2D keypoint locations, we directly use the famous pictorial structure model and taking the aspect ratio of the human body parts into consideration.",
            "Of course, there might be some mistakes in this step, but in our experiments we will show that action recognition can still benefit a lot from this automatically obtained human keypoints.",
            "Two convert 2."
        ],
        [
            "Key points to 3D we use.",
            "We use the Taylors approach by estimating the depth of each keypoint using a projection model for a particular body part.",
            "If the locations of its two endpoints in the 2D image plan is U1V1 and U2V2, and if the length of this body part in 3D is L, then the relative depth between these two points can be computed by using this equation.",
            "One issue is this relative depth can be either positive or negative.",
            "We use the two tricks to reduce this ambiguity.",
            "First we add some configuration constraints of the human 3D posts, as in this reaction paper.",
            "Second, we collect some valid and invalid 3D human posts and trend regression model.",
            "If more than one 3D human posts are obtained for a particular human, we only keep the one that corresponds to the largest regression score."
        ],
        [
            "Having introduced the 2.5 D graph, Now let's see how to use them for for action classification."
        ],
        [
            "We use an example based method, so we need a similarity measure.",
            "We match the similarity between two 2.5 D graphs by taking the appearance and post features into consideration.",
            "The appearance similarity is very, very similar to all standard works.",
            "Concatenations of Special pyramids, histogram, intersection and so on.",
            "The exciting part comes from this view independent 3D post matching which."
        ],
        [
            "Is obtained by rotating one 3D skeleton to make his viewpoint similar to the other one.",
            "The rotation matrix is obtained by using a least square approach.",
            "With this similarity measure."
        ],
        [
            "We can match the 2.5 D graph over test image to all training images and I'll put the class label over training image that that has the largest similarity value."
        ],
        [
            "But this is very time consuming because the number of training images is very large is usually very large."
        ],
        [
            "In our approach, we want to match the test image to only a subset of the training images."
        ],
        [
            "This subset of training images needs to need to be diverse enough so that they can correctly recognize all the training images."
        ],
        [
            "Those images are called dominating images.",
            "They are selected in the iterative approach for each action class.",
            "First we learn images, basic feature weights to maximize the coverage for each training image.",
            "The coverage set of image I contains the images that are more closer to this image than any other images of the other classes.",
            "The larger the coverage set, the more representative the images."
        ],
        [
            "Is.",
            "We then find the image that has the largest coverage set.",
            "This image will be one of the dominating image."
        ],
        [
            "Will they remove this image and its coverage set and go back to Step 2 to find the next dominating image?"
        ],
        [
            "By using this iterative approach, we find all the dominating images for all the action classes and in the classification stage we match the test image to only those dominating images."
        ],
        [
            "Now let's do some experiment experiment."
        ],
        [
            "Results.",
            "The first data set contains 24 classes of human interacting with different musical instruments.",
            "For each class there are hundreds training images in 100 testing image."
        ],
        [
            "If we only use the human post for classification, a 3D human pose performs much better than two D human pose.",
            "This is not surprising because there's 3D human human pose representation allows us to rotate the 3D skeleton to match 2 images."
        ],
        [
            "And our appearance features extracted from the keypoint locations performs better than the simple spatial pyramid and is compatible with this arosi method.",
            "The appearance feature performs better than post feature because the post estimation results can have mistakes and the human poses of different classes can be similar.",
            "But if you would combine."
        ],
        [
            "3D human pose and two D appearance features.",
            "The 2.5 D representation further improves the classification performance and our example based method achieves higher performance than simply using an SVM classifier."
        ],
        [
            "Here are two more control experiments.",
            "First, as we have mentioned before, there can be mistakes in human pose estimation.",
            "So how about using the ground truth Keypoint locations for action classification?",
            "We can see that the performance of using the automatically obtained human post drops a little bit, but not too much, so we can see that it is trustable to use the automatically obtained human post for action classification.",
            "In the other control experiment, we compared the performance of matching to all training images and matching to only the dominating images.",
            "The performance are quite similar but matching to all training images is more computationally expensive.",
            "Here we show some dominating images selected from."
        ],
        [
            "Class of people playing bassoon and people holding the person but not playing.",
            "In the class of not playing the post variation is larger so more dominating images are selected.",
            "This is the same for almost all the classes here are."
        ],
        [
            "I'm dominating images for the class of flute and violin.",
            "We also test our method on the Action classification task."
        ],
        [
            "Of Pascal vce 2011 data set."
        ],
        [
            "This data set provides bounding boxes of humans.",
            "This actually makes post estimation easier because we only need to search the locations of the human body parts within the bounding box.",
            "On this data set, some humans only have the upper body parts available, so we train 2 pictorial structure models, one for the full human body and the other for the upper body only."
        ],
        [
            "Comparing with the best, perform the method on the challenge.",
            "Our approach has the best performance on three out of the 10 classes and achieved the best performing average precision."
        ],
        [
            "On the class of jumping, we can see that our example based approach can account for the very large post variations and on the class of reading where the human poses are similar.",
            "Our 3D human 3D representation allows us to rotate the 3D skeleton to have better human post match."
        ],
        [
            "But on the classes where the objects interacting with people is large, such as riding bike and riding horse, the method that explicitly models object has the best performance, so it is actually expected that the performance of our method can also be improved if we also incorporate the objects in the model."
        ],
        [
            "In conclusion, we propose a 2.5 D action representation by considering both view independent 3D posts and reach to the appearance features.",
            "We also propose an example based recognition method where we only consider image and its nearest neighbor."
        ],
        [
            "Thank you.",
            "I have a question regarding the way you actually choose your 3D pose using regression.",
            "So I have a question on that.",
            "Then I have a comment.",
            "So you want me to explain that in more detail?",
            "Well, yeah, I mean how you've got the number of equivalent 3D poses from the point of view of projection.",
            "Join twice projection in terms of the sort of so basically."
        ],
        [
            "In this step we we have some.",
            "So basically on the on the training data set we have some human annotated 3D human posts, then those are the those are the valid 3D human poses and we also manually make some human post is incorrect because this positive and negative can have mistakes.",
            "So based on that we trended regression model to give higher scores to those valid 3D human poses.",
            "That's the regression model and in the in this automatically.",
            "Automatically learning stage if more than one human poses are obtained because of this policy and Anna negative thing, we just give all those 3D human poses to the regression model and just use this.",
            "You use the 3D pose with the highest regression score.",
            "Yeah, but that doesn't look at the image features at all.",
            "So normally if you have these ambiguities at the level of the points, you actually may not have an equal amount of ambiguity at the level of the projections because you have certain limbs that are far away in depth, and certainly the closer in depth.",
            "So the fact of not looking at the image, I think it is not a good idea.",
            "You could have discriminative methods that actually look at take the image features and actually predict repose or you know predict within the space of 3D poses the ones that are more plausible.",
            "So not just look at the joint positions.",
            "Look at the image features as well.",
            "For instance.",
            "Yeah, you're right.",
            "So so I agree the 3D human pose estimation can definitely be improved if we jointly consider the skeleton energy appearance.",
            "But in our approach we treated as two independent steps.",
            "So we trusted the pictorial structure model to give us the correct 2D keypoint locations, and in this step we just convert the 2D key .23 D. So so in our approach there are two separated approach.",
            "But I agree the performance can definitely be improved if we jointly use the appearance and skeleton features and the comment was that the interests of interest of the correct credit.",
            "Actually the message describes the actually special case of Lien Chan.",
            "For parallel projections for so Li and Chen gives give a full perspective solution to the reconstruction problem, whereas the method you describe is just the parallel version of that.",
            "So in principle you could use Lee and Chen up front.",
            "Yeah, yeah yeah, that's true.",
            "Yeah, thank you.",
            "OK, now the questions.",
            "I was unclear to me.",
            "When you rotate the skeleton, the appearance also will change with this 3D transformation and it was unclear to me how you handle that.",
            "So actually in our approach the appearance feature is purely 2D.",
            "We only rotate the 3D skeleton and the two D human pose is the 2D human appearance.",
            "Features are not changing at all."
        ],
        [
            "So for example, given this image, the 2D human poses will be the image locations surrounding the key points in the original image, and we just take the features in all the image regions and that's our 2D feature is not going to be changed.",
            "It's just that the 3D skeleton can be rotated, so that's why it's only 2.5 D because the appearance is purely 2D.",
            "So the question is, what's the computational complexity of the approach so actually the most time consuming part of this approach?",
            "Is the post estimation method so.",
            "And actually the whole and after the whole example best method is also less efficient than simply using the SVM.",
            "But our purpose of this project is not to design the real time system.",
            "Motivation is actually trying to see how human pose can really help us to do action classification.",
            "Yeah.",
            "OK, I think we should move on.",
            "So let's think debunking again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Good afternoon everyone.",
                    "label": 0
                },
                {
                    "sent": "My name is a bump on y'all.",
                    "label": 0
                },
                {
                    "sent": "This is a joint work with my advisor faithfully.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Our goal is to recognize human actions in still images.",
                    "label": 1
                },
                {
                    "sent": "This task is easy for humans, but it's very challenging for computers.",
                    "label": 0
                },
                {
                    "sent": "For example, in those two in.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is the human poses are essentially very similar, but viewpoint changes make the configuration over the body parts very different.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Do we have to perform some very complicated 3D modeling of humans for this problem?",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It is not necessary to do that.",
                    "label": 0
                },
                {
                    "sent": "We can take it down, take advantage of existing human pose estimation methods and converting 2D human poses to 3D, and then rotate the 3D skeletons to match one image to the other.",
                    "label": 0
                },
                {
                    "sent": "Also inspired by the previous work of using appearance features for action recognition, we also extract image features within within the bounding boxes surrounding each keypoint of the human body parts.",
                    "label": 0
                },
                {
                    "sent": "Therefore, all action representation.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Use the 2.5 D graph which consists of view independent 3D posts and reach to the appearance features.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Further, the challenge of Action classification is not limited to viewpoint changes, so we also.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Propose the example based recognition method where we only consider the similarity between a test image and its closest training image.",
                    "label": 0
                },
                {
                    "sent": "Instead of considering similarity between the test image and all the training images.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here's the outline of the rest of the talk.",
                    "label": 0
                },
                {
                    "sent": "First are the details of the two point 5D representation an example of basically classification.",
                    "label": 0
                },
                {
                    "sent": "Then I will show some experimental results.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, let's see what is a 2.5 D action representation.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Given the image, we first estimate the 2D keypoint locations of the human poses of the human body.",
                    "label": 0
                },
                {
                    "sent": "Parts like the head, torso, arms and so on.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The two D Keypoint locations are then converted to a 3D skeleton by estimating the depth of each keypoint.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For each keypoint we also extract the image region surrounding this key point and represent this region using a special pyramid.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Combining the 3D locations of the key points and the corresponding appearance feature surround of the location image locations surrounding each keypoint, we form a 2.5 D graph over human action.",
                    "label": 0
                },
                {
                    "sent": "The non trivial part of obtaining the 2.5 D graph is to obtain the 3D keypoint locations.",
                    "label": 0
                },
                {
                    "sent": "This involves 2 steps.",
                    "label": 0
                },
                {
                    "sent": "One is to estimate the 2D keypoint locations there is to convert the 2D keypoint locations to three.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In our approach to obtain the 2D keypoint locations, we directly use the famous pictorial structure model and taking the aspect ratio of the human body parts into consideration.",
                    "label": 0
                },
                {
                    "sent": "Of course, there might be some mistakes in this step, but in our experiments we will show that action recognition can still benefit a lot from this automatically obtained human keypoints.",
                    "label": 0
                },
                {
                    "sent": "Two convert 2.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Key points to 3D we use.",
                    "label": 1
                },
                {
                    "sent": "We use the Taylors approach by estimating the depth of each keypoint using a projection model for a particular body part.",
                    "label": 0
                },
                {
                    "sent": "If the locations of its two endpoints in the 2D image plan is U1V1 and U2V2, and if the length of this body part in 3D is L, then the relative depth between these two points can be computed by using this equation.",
                    "label": 0
                },
                {
                    "sent": "One issue is this relative depth can be either positive or negative.",
                    "label": 0
                },
                {
                    "sent": "We use the two tricks to reduce this ambiguity.",
                    "label": 0
                },
                {
                    "sent": "First we add some configuration constraints of the human 3D posts, as in this reaction paper.",
                    "label": 0
                },
                {
                    "sent": "Second, we collect some valid and invalid 3D human posts and trend regression model.",
                    "label": 0
                },
                {
                    "sent": "If more than one 3D human posts are obtained for a particular human, we only keep the one that corresponds to the largest regression score.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Having introduced the 2.5 D graph, Now let's see how to use them for for action classification.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We use an example based method, so we need a similarity measure.",
                    "label": 0
                },
                {
                    "sent": "We match the similarity between two 2.5 D graphs by taking the appearance and post features into consideration.",
                    "label": 0
                },
                {
                    "sent": "The appearance similarity is very, very similar to all standard works.",
                    "label": 0
                },
                {
                    "sent": "Concatenations of Special pyramids, histogram, intersection and so on.",
                    "label": 0
                },
                {
                    "sent": "The exciting part comes from this view independent 3D post matching which.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is obtained by rotating one 3D skeleton to make his viewpoint similar to the other one.",
                    "label": 0
                },
                {
                    "sent": "The rotation matrix is obtained by using a least square approach.",
                    "label": 0
                },
                {
                    "sent": "With this similarity measure.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We can match the 2.5 D graph over test image to all training images and I'll put the class label over training image that that has the largest similarity value.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But this is very time consuming because the number of training images is very large is usually very large.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In our approach, we want to match the test image to only a subset of the training images.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This subset of training images needs to need to be diverse enough so that they can correctly recognize all the training images.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Those images are called dominating images.",
                    "label": 1
                },
                {
                    "sent": "They are selected in the iterative approach for each action class.",
                    "label": 0
                },
                {
                    "sent": "First we learn images, basic feature weights to maximize the coverage for each training image.",
                    "label": 1
                },
                {
                    "sent": "The coverage set of image I contains the images that are more closer to this image than any other images of the other classes.",
                    "label": 1
                },
                {
                    "sent": "The larger the coverage set, the more representative the images.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is.",
                    "label": 0
                },
                {
                    "sent": "We then find the image that has the largest coverage set.",
                    "label": 0
                },
                {
                    "sent": "This image will be one of the dominating image.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Will they remove this image and its coverage set and go back to Step 2 to find the next dominating image?",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "By using this iterative approach, we find all the dominating images for all the action classes and in the classification stage we match the test image to only those dominating images.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now let's do some experiment experiment.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Results.",
                    "label": 0
                },
                {
                    "sent": "The first data set contains 24 classes of human interacting with different musical instruments.",
                    "label": 1
                },
                {
                    "sent": "For each class there are hundreds training images in 100 testing image.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If we only use the human post for classification, a 3D human pose performs much better than two D human pose.",
                    "label": 0
                },
                {
                    "sent": "This is not surprising because there's 3D human human pose representation allows us to rotate the 3D skeleton to match 2 images.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And our appearance features extracted from the keypoint locations performs better than the simple spatial pyramid and is compatible with this arosi method.",
                    "label": 0
                },
                {
                    "sent": "The appearance feature performs better than post feature because the post estimation results can have mistakes and the human poses of different classes can be similar.",
                    "label": 0
                },
                {
                    "sent": "But if you would combine.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "3D human pose and two D appearance features.",
                    "label": 0
                },
                {
                    "sent": "The 2.5 D representation further improves the classification performance and our example based method achieves higher performance than simply using an SVM classifier.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here are two more control experiments.",
                    "label": 0
                },
                {
                    "sent": "First, as we have mentioned before, there can be mistakes in human pose estimation.",
                    "label": 0
                },
                {
                    "sent": "So how about using the ground truth Keypoint locations for action classification?",
                    "label": 0
                },
                {
                    "sent": "We can see that the performance of using the automatically obtained human post drops a little bit, but not too much, so we can see that it is trustable to use the automatically obtained human post for action classification.",
                    "label": 0
                },
                {
                    "sent": "In the other control experiment, we compared the performance of matching to all training images and matching to only the dominating images.",
                    "label": 0
                },
                {
                    "sent": "The performance are quite similar but matching to all training images is more computationally expensive.",
                    "label": 0
                },
                {
                    "sent": "Here we show some dominating images selected from.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Class of people playing bassoon and people holding the person but not playing.",
                    "label": 0
                },
                {
                    "sent": "In the class of not playing the post variation is larger so more dominating images are selected.",
                    "label": 0
                },
                {
                    "sent": "This is the same for almost all the classes here are.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm dominating images for the class of flute and violin.",
                    "label": 0
                },
                {
                    "sent": "We also test our method on the Action classification task.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of Pascal vce 2011 data set.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This data set provides bounding boxes of humans.",
                    "label": 0
                },
                {
                    "sent": "This actually makes post estimation easier because we only need to search the locations of the human body parts within the bounding box.",
                    "label": 0
                },
                {
                    "sent": "On this data set, some humans only have the upper body parts available, so we train 2 pictorial structure models, one for the full human body and the other for the upper body only.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Comparing with the best, perform the method on the challenge.",
                    "label": 0
                },
                {
                    "sent": "Our approach has the best performance on three out of the 10 classes and achieved the best performing average precision.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On the class of jumping, we can see that our example based approach can account for the very large post variations and on the class of reading where the human poses are similar.",
                    "label": 0
                },
                {
                    "sent": "Our 3D human 3D representation allows us to rotate the 3D skeleton to have better human post match.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But on the classes where the objects interacting with people is large, such as riding bike and riding horse, the method that explicitly models object has the best performance, so it is actually expected that the performance of our method can also be improved if we also incorporate the objects in the model.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In conclusion, we propose a 2.5 D action representation by considering both view independent 3D posts and reach to the appearance features.",
                    "label": 0
                },
                {
                    "sent": "We also propose an example based recognition method where we only consider image and its nearest neighbor.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "I have a question regarding the way you actually choose your 3D pose using regression.",
                    "label": 1
                },
                {
                    "sent": "So I have a question on that.",
                    "label": 0
                },
                {
                    "sent": "Then I have a comment.",
                    "label": 0
                },
                {
                    "sent": "So you want me to explain that in more detail?",
                    "label": 0
                },
                {
                    "sent": "Well, yeah, I mean how you've got the number of equivalent 3D poses from the point of view of projection.",
                    "label": 0
                },
                {
                    "sent": "Join twice projection in terms of the sort of so basically.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In this step we we have some.",
                    "label": 0
                },
                {
                    "sent": "So basically on the on the training data set we have some human annotated 3D human posts, then those are the those are the valid 3D human poses and we also manually make some human post is incorrect because this positive and negative can have mistakes.",
                    "label": 0
                },
                {
                    "sent": "So based on that we trended regression model to give higher scores to those valid 3D human poses.",
                    "label": 0
                },
                {
                    "sent": "That's the regression model and in the in this automatically.",
                    "label": 0
                },
                {
                    "sent": "Automatically learning stage if more than one human poses are obtained because of this policy and Anna negative thing, we just give all those 3D human poses to the regression model and just use this.",
                    "label": 0
                },
                {
                    "sent": "You use the 3D pose with the highest regression score.",
                    "label": 0
                },
                {
                    "sent": "Yeah, but that doesn't look at the image features at all.",
                    "label": 0
                },
                {
                    "sent": "So normally if you have these ambiguities at the level of the points, you actually may not have an equal amount of ambiguity at the level of the projections because you have certain limbs that are far away in depth, and certainly the closer in depth.",
                    "label": 0
                },
                {
                    "sent": "So the fact of not looking at the image, I think it is not a good idea.",
                    "label": 0
                },
                {
                    "sent": "You could have discriminative methods that actually look at take the image features and actually predict repose or you know predict within the space of 3D poses the ones that are more plausible.",
                    "label": 0
                },
                {
                    "sent": "So not just look at the joint positions.",
                    "label": 0
                },
                {
                    "sent": "Look at the image features as well.",
                    "label": 0
                },
                {
                    "sent": "For instance.",
                    "label": 0
                },
                {
                    "sent": "Yeah, you're right.",
                    "label": 0
                },
                {
                    "sent": "So so I agree the 3D human pose estimation can definitely be improved if we jointly consider the skeleton energy appearance.",
                    "label": 0
                },
                {
                    "sent": "But in our approach we treated as two independent steps.",
                    "label": 0
                },
                {
                    "sent": "So we trusted the pictorial structure model to give us the correct 2D keypoint locations, and in this step we just convert the 2D key .23 D. So so in our approach there are two separated approach.",
                    "label": 0
                },
                {
                    "sent": "But I agree the performance can definitely be improved if we jointly use the appearance and skeleton features and the comment was that the interests of interest of the correct credit.",
                    "label": 0
                },
                {
                    "sent": "Actually the message describes the actually special case of Lien Chan.",
                    "label": 0
                },
                {
                    "sent": "For parallel projections for so Li and Chen gives give a full perspective solution to the reconstruction problem, whereas the method you describe is just the parallel version of that.",
                    "label": 0
                },
                {
                    "sent": "So in principle you could use Lee and Chen up front.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah yeah, that's true.",
                    "label": 0
                },
                {
                    "sent": "Yeah, thank you.",
                    "label": 0
                },
                {
                    "sent": "OK, now the questions.",
                    "label": 0
                },
                {
                    "sent": "I was unclear to me.",
                    "label": 0
                },
                {
                    "sent": "When you rotate the skeleton, the appearance also will change with this 3D transformation and it was unclear to me how you handle that.",
                    "label": 0
                },
                {
                    "sent": "So actually in our approach the appearance feature is purely 2D.",
                    "label": 0
                },
                {
                    "sent": "We only rotate the 3D skeleton and the two D human pose is the 2D human appearance.",
                    "label": 0
                },
                {
                    "sent": "Features are not changing at all.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for example, given this image, the 2D human poses will be the image locations surrounding the key points in the original image, and we just take the features in all the image regions and that's our 2D feature is not going to be changed.",
                    "label": 1
                },
                {
                    "sent": "It's just that the 3D skeleton can be rotated, so that's why it's only 2.5 D because the appearance is purely 2D.",
                    "label": 0
                },
                {
                    "sent": "So the question is, what's the computational complexity of the approach so actually the most time consuming part of this approach?",
                    "label": 0
                },
                {
                    "sent": "Is the post estimation method so.",
                    "label": 0
                },
                {
                    "sent": "And actually the whole and after the whole example best method is also less efficient than simply using the SVM.",
                    "label": 0
                },
                {
                    "sent": "But our purpose of this project is not to design the real time system.",
                    "label": 0
                },
                {
                    "sent": "Motivation is actually trying to see how human pose can really help us to do action classification.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "OK, I think we should move on.",
                    "label": 0
                },
                {
                    "sent": "So let's think debunking again.",
                    "label": 0
                }
            ]
        }
    }
}