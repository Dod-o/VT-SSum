{
    "id": "y3sit77pbjpvmxsd2surnywhdy62iqch",
    "title": "Detection of Unique Temporal Segments by Information Theoretic Meta-clustering",
    "info": {
        "author": [
            "Shin Ando, Gunma University"
        ],
        "published": "Sept. 14, 2009",
        "recorded": "June 2009",
        "category": [
            "Top->Computer Science->Data Mining->Temporal Data"
        ]
    },
    "url": "http://videolectures.net/kdd09_ando_dutsitmc/",
    "segmentation": [
        [
            "Thank you for the introduction and thank you all for your interest.",
            "My name is Shannon Dell and this is joint work with Professor Suzuki.",
            "Over attempt was to detect us."
        ],
        [
            "All set of unusual segments from temporal, sequential data, and so I will get started with an example and try to demonstrate the problem.",
            "These are artificially generated so segments, and since it's hard to see through the connecting lines, remove them.",
            "Now you can see kind of the linear correlation that most of the sequences have despite large amount of noise.",
            "But there is a small portion of this data that has a different trend, and since it's an art."
        ],
        [
            "Special data we know and we can show them in different colors, so the orange points are sequences that has kind of a quadratic shape, and that's different from the majority of the data that that's the blue sequences.",
            "And there's our goal to detect a small set of sequences that has a different trend, or Fitz to different model.",
            "But this is quite a difficult task because of the.",
            "Imbalance of the number of samples and it's unsupervised setting and it's slightly different from out large outliers and anomalies.",
            "We have some examples here."
        ],
        [
            "Ranch sequences are sequences with largest residuals from the estimate of the."
        ],
        [
            "Our data and these green sequences are neighborhood based anomalies.",
            "The sequence is farthest from their neighbors, and there really isn't a trend.",
            "In either case is because it's not part of the outlier detection.",
            "To find the trend so, but that's."
        ],
        [
            "Where our emphasis is to estimate the model of unusual segments so that which may give us an idea about the generative process, their generative process.",
            "So that's the problem and."
        ],
        [
            "Now I'd like to talk about the learning framework based on data compression.",
            "We've been working on this for some time."
        ],
        [
            "So in data compression you have the observed value at the source and you send to the destination an encoded signal, which is a series of code letters.",
            "In this case, the source signal would be the set of sequences and a code letter would indicate whether a sequence is unusual or normal.",
            "So if you look at the encoded signal as hidden class variable, you have your learning framework.",
            "Clustering or classification.",
            "We also use model of generative model of the source data and you send to the destination one parameter instance for each type of code normal or unusual so that we can reconstruct the original data at the destination with some loss of information.",
            "And what we look for here is evaluate here is number of bits that we sent to the destination and how much of the data is reconstructed there.",
            "So that gives us the optimization problem to solve for learning.",
            "And in this process there is one subjective part which is quantifying the loss of information which is kind of like the distance function for selecting distance function for clustering and.",
            "That makes the process."
        ],
        [
            "A little bit arbitrary.",
            "So we wanted to develop a framework that's a little bit more general and I require less work when applying to new data.",
            "And that's the meta clustering and.",
            "We use what we call a baseline hypothesis, which is a compression of the data using prior information, or if there exists one using their information of about the data and then what we want ultimately is a class hypothesis.",
            "We obtained this by clustering the baseline or mapping the baseline hypothesis and.",
            "The reason we go through this complex kind of frame formalization is so that we can express the loss of information and the average number of bits sent using mutual information naturally.",
            "So the loss of information by going from baseline to the class hypothesis is the mutual information between the baseline and the data minus the mutual information shared by the class and the data.",
            "And the average number of bits you can compute by mutual information between the two hypothesis and.",
            "Given the tradeoff between the two, optimizing these are is an analytically tractable problem, so."
        ],
        [
            "So what is the baseline hypothesis, question and?",
            "If you have no prior information about the data class of the data, I guess that's the most frequent case.",
            "You simply assume each data comes from its own class.",
            "So that's really actually very trivial, extremely trivial data compression that practically is never used, but it gives us a good baseline in this case because we know it achieves given the generative model of the data, it achieves the minimal loss of information, and then we compress the encoded signal into the."
        ],
        [
            "Class hypothesis, but I have to skip this."
        ],
        [
            "All this.",
            "About one more point about this, meta clustering is why we use this to detect unusual segment and send more.",
            "Essentially what is what is unusual and we can see this analytically or in a mathematical form if we look at the objective function.",
            "The individual clusters contribution to the objective function.",
            "And I can look at it in the paper, but it approximately equals the callback liebler divergent between the majority of the data and the clusters distribution, and so that's the definition and usual segment cluster collectively diverges from the majority of the data, and when we minimize the objective function for one cluster, we maximize the likelihood and also the divergent."
        ],
        [
            "Majority.",
            "And.",
            "For optimization, we have an iterative algorithm with some nice properties, so I'm going to now talk about the empirical evaluation of that."
        ],
        [
            "So for the first experiment we generated the data sets from 2 polynomial functions.",
            "One it's linear and the other is quadratic, and the number of samples is 1200 to 60.",
            "So the linear function is the majority by 20 to one and below.",
            "This illustration is a sample of."
        ],
        [
            "Data sets we used.",
            "And 1st about the.",
            "A property of the algorithm that.",
            "Contributes to low false positive rate.",
            "We have here logs from 2 typical runs or iterations of the algorithm and we have random's initial starts and.",
            "In one run, initial cluster has good number of unusual segments and in the other it has very few, so the latter is bad and initialization for estimating the cluster of unusual segments.",
            "But because of the imbalance of the samples, that kind of case happens frequently.",
            "So let's run it.",
            "The first initial run in the initial run the precision number of.",
            "Unusual segments in the cluster increases and it converges when it's about 90% of it is true.",
            "Positive unusual, but in the second case the precision stays low, but the size of the cluster keeps decreasing until the cluster is too small to estimate its parameters.",
            "And what happens there is that because we evaluate the number average number of bits sent to the destination?",
            "That kind of works as a regularization term which penalizes large clusters, and when there's no unusual segment in the cluster and there's no divergance, that's the most influential factor.",
            "And because of this property we can set a threshold to reject the cluster that comes from bad initialization based on the cluster size, and that helps reduce the."
        ],
        [
            "Help reduce the false bottom false positives and for comparative evaluation we did a precision recall analysis even though this is not a supervised setting, we can compute the precision recall using the proposed method and outlier detection and clustering because there are only two classes.",
            "The result, in short, was that the proposed method had a high precision and recall, highly balanced precision recall, while the other outlier detection and clustering methods had to pay a steep price for a good precision or recall."
        ],
        [
            "Sorry, the second experiment we took the gene Expression Time series from the.",
            "DNA repair system of E. Coli, which is the pathways for this system, is published in several biological literatures.",
            "Basically, when the DNA is damaged, some pathways are activated to start the repair repairment, and when it's finished it goes back to normal state.",
            "So we model that as a two stage process and also to account for the delay time delay in biological reaction chemical reaction.",
            "We used vector autoregression model.",
            "To model this process and what we did is we divided the time series into short segments using time slicing window and.",
            "Tried to detect segments that came from the activated activated states, which is about 150th of the entire set."
        ],
        [
            "Rents.",
            "And the results was similar to the first post.",
            "As it had a little less.",
            "High precision recall, but recall and.",
            "The other methods were could not achieve that this by changing the."
        ],
        [
            "And finally, in addition.",
            "There's this averaging strategy in the biological literatures where you take the average and the standard deviation of the estimated parameters of the gene regulation model that fits the observed time series and try to predict or reconstruct the original pathways based on the significance of the parameters and.",
            "We tried this strategy and on the segments that was detected from meta clustering.",
            "And was able to reconstruct the pathways in the activated state.",
            "So that was the promising result."
        ],
        [
            "So so in conclusion, we propose a meta clustering framework for temporal data and which is a technique for detecting segments that collectively diverges from the majority, and it has a nice property of low false positive rate.",
            "So that's all my talk and thank you for this."
        ],
        [
            "Logical data.",
            "The number of nose is is.",
            "OK, six in the literature, but we only took four because.",
            "Response to a particular protein.",
            "I'm sorry, correspond twice.",
            "Their SOS jeans and.",
            "Six SOS, yes, it's it's a national.",
            "James, in practice.",
            "Yes there are.",
            "Not our data, but it's publicly available."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you for the introduction and thank you all for your interest.",
                    "label": 0
                },
                {
                    "sent": "My name is Shannon Dell and this is joint work with Professor Suzuki.",
                    "label": 0
                },
                {
                    "sent": "Over attempt was to detect us.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "All set of unusual segments from temporal, sequential data, and so I will get started with an example and try to demonstrate the problem.",
                    "label": 0
                },
                {
                    "sent": "These are artificially generated so segments, and since it's hard to see through the connecting lines, remove them.",
                    "label": 0
                },
                {
                    "sent": "Now you can see kind of the linear correlation that most of the sequences have despite large amount of noise.",
                    "label": 0
                },
                {
                    "sent": "But there is a small portion of this data that has a different trend, and since it's an art.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Special data we know and we can show them in different colors, so the orange points are sequences that has kind of a quadratic shape, and that's different from the majority of the data that that's the blue sequences.",
                    "label": 0
                },
                {
                    "sent": "And there's our goal to detect a small set of sequences that has a different trend, or Fitz to different model.",
                    "label": 0
                },
                {
                    "sent": "But this is quite a difficult task because of the.",
                    "label": 0
                },
                {
                    "sent": "Imbalance of the number of samples and it's unsupervised setting and it's slightly different from out large outliers and anomalies.",
                    "label": 0
                },
                {
                    "sent": "We have some examples here.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Ranch sequences are sequences with largest residuals from the estimate of the.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Our data and these green sequences are neighborhood based anomalies.",
                    "label": 0
                },
                {
                    "sent": "The sequence is farthest from their neighbors, and there really isn't a trend.",
                    "label": 0
                },
                {
                    "sent": "In either case is because it's not part of the outlier detection.",
                    "label": 0
                },
                {
                    "sent": "To find the trend so, but that's.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Where our emphasis is to estimate the model of unusual segments so that which may give us an idea about the generative process, their generative process.",
                    "label": 0
                },
                {
                    "sent": "So that's the problem and.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now I'd like to talk about the learning framework based on data compression.",
                    "label": 0
                },
                {
                    "sent": "We've been working on this for some time.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in data compression you have the observed value at the source and you send to the destination an encoded signal, which is a series of code letters.",
                    "label": 0
                },
                {
                    "sent": "In this case, the source signal would be the set of sequences and a code letter would indicate whether a sequence is unusual or normal.",
                    "label": 1
                },
                {
                    "sent": "So if you look at the encoded signal as hidden class variable, you have your learning framework.",
                    "label": 1
                },
                {
                    "sent": "Clustering or classification.",
                    "label": 0
                },
                {
                    "sent": "We also use model of generative model of the source data and you send to the destination one parameter instance for each type of code normal or unusual so that we can reconstruct the original data at the destination with some loss of information.",
                    "label": 0
                },
                {
                    "sent": "And what we look for here is evaluate here is number of bits that we sent to the destination and how much of the data is reconstructed there.",
                    "label": 0
                },
                {
                    "sent": "So that gives us the optimization problem to solve for learning.",
                    "label": 0
                },
                {
                    "sent": "And in this process there is one subjective part which is quantifying the loss of information which is kind of like the distance function for selecting distance function for clustering and.",
                    "label": 0
                },
                {
                    "sent": "That makes the process.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A little bit arbitrary.",
                    "label": 0
                },
                {
                    "sent": "So we wanted to develop a framework that's a little bit more general and I require less work when applying to new data.",
                    "label": 0
                },
                {
                    "sent": "And that's the meta clustering and.",
                    "label": 0
                },
                {
                    "sent": "We use what we call a baseline hypothesis, which is a compression of the data using prior information, or if there exists one using their information of about the data and then what we want ultimately is a class hypothesis.",
                    "label": 0
                },
                {
                    "sent": "We obtained this by clustering the baseline or mapping the baseline hypothesis and.",
                    "label": 1
                },
                {
                    "sent": "The reason we go through this complex kind of frame formalization is so that we can express the loss of information and the average number of bits sent using mutual information naturally.",
                    "label": 1
                },
                {
                    "sent": "So the loss of information by going from baseline to the class hypothesis is the mutual information between the baseline and the data minus the mutual information shared by the class and the data.",
                    "label": 0
                },
                {
                    "sent": "And the average number of bits you can compute by mutual information between the two hypothesis and.",
                    "label": 0
                },
                {
                    "sent": "Given the tradeoff between the two, optimizing these are is an analytically tractable problem, so.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what is the baseline hypothesis, question and?",
                    "label": 0
                },
                {
                    "sent": "If you have no prior information about the data class of the data, I guess that's the most frequent case.",
                    "label": 0
                },
                {
                    "sent": "You simply assume each data comes from its own class.",
                    "label": 0
                },
                {
                    "sent": "So that's really actually very trivial, extremely trivial data compression that practically is never used, but it gives us a good baseline in this case because we know it achieves given the generative model of the data, it achieves the minimal loss of information, and then we compress the encoded signal into the.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Class hypothesis, but I have to skip this.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "All this.",
                    "label": 0
                },
                {
                    "sent": "About one more point about this, meta clustering is why we use this to detect unusual segment and send more.",
                    "label": 0
                },
                {
                    "sent": "Essentially what is what is unusual and we can see this analytically or in a mathematical form if we look at the objective function.",
                    "label": 0
                },
                {
                    "sent": "The individual clusters contribution to the objective function.",
                    "label": 0
                },
                {
                    "sent": "And I can look at it in the paper, but it approximately equals the callback liebler divergent between the majority of the data and the clusters distribution, and so that's the definition and usual segment cluster collectively diverges from the majority of the data, and when we minimize the objective function for one cluster, we maximize the likelihood and also the divergent.",
                    "label": 1
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Majority.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "For optimization, we have an iterative algorithm with some nice properties, so I'm going to now talk about the empirical evaluation of that.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for the first experiment we generated the data sets from 2 polynomial functions.",
                    "label": 0
                },
                {
                    "sent": "One it's linear and the other is quadratic, and the number of samples is 1200 to 60.",
                    "label": 0
                },
                {
                    "sent": "So the linear function is the majority by 20 to one and below.",
                    "label": 0
                },
                {
                    "sent": "This illustration is a sample of.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Data sets we used.",
                    "label": 0
                },
                {
                    "sent": "And 1st about the.",
                    "label": 0
                },
                {
                    "sent": "A property of the algorithm that.",
                    "label": 0
                },
                {
                    "sent": "Contributes to low false positive rate.",
                    "label": 0
                },
                {
                    "sent": "We have here logs from 2 typical runs or iterations of the algorithm and we have random's initial starts and.",
                    "label": 0
                },
                {
                    "sent": "In one run, initial cluster has good number of unusual segments and in the other it has very few, so the latter is bad and initialization for estimating the cluster of unusual segments.",
                    "label": 0
                },
                {
                    "sent": "But because of the imbalance of the samples, that kind of case happens frequently.",
                    "label": 0
                },
                {
                    "sent": "So let's run it.",
                    "label": 0
                },
                {
                    "sent": "The first initial run in the initial run the precision number of.",
                    "label": 0
                },
                {
                    "sent": "Unusual segments in the cluster increases and it converges when it's about 90% of it is true.",
                    "label": 0
                },
                {
                    "sent": "Positive unusual, but in the second case the precision stays low, but the size of the cluster keeps decreasing until the cluster is too small to estimate its parameters.",
                    "label": 0
                },
                {
                    "sent": "And what happens there is that because we evaluate the number average number of bits sent to the destination?",
                    "label": 0
                },
                {
                    "sent": "That kind of works as a regularization term which penalizes large clusters, and when there's no unusual segment in the cluster and there's no divergance, that's the most influential factor.",
                    "label": 0
                },
                {
                    "sent": "And because of this property we can set a threshold to reject the cluster that comes from bad initialization based on the cluster size, and that helps reduce the.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Help reduce the false bottom false positives and for comparative evaluation we did a precision recall analysis even though this is not a supervised setting, we can compute the precision recall using the proposed method and outlier detection and clustering because there are only two classes.",
                    "label": 0
                },
                {
                    "sent": "The result, in short, was that the proposed method had a high precision and recall, highly balanced precision recall, while the other outlier detection and clustering methods had to pay a steep price for a good precision or recall.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sorry, the second experiment we took the gene Expression Time series from the.",
                    "label": 0
                },
                {
                    "sent": "DNA repair system of E. Coli, which is the pathways for this system, is published in several biological literatures.",
                    "label": 0
                },
                {
                    "sent": "Basically, when the DNA is damaged, some pathways are activated to start the repair repairment, and when it's finished it goes back to normal state.",
                    "label": 0
                },
                {
                    "sent": "So we model that as a two stage process and also to account for the delay time delay in biological reaction chemical reaction.",
                    "label": 0
                },
                {
                    "sent": "We used vector autoregression model.",
                    "label": 1
                },
                {
                    "sent": "To model this process and what we did is we divided the time series into short segments using time slicing window and.",
                    "label": 0
                },
                {
                    "sent": "Tried to detect segments that came from the activated activated states, which is about 150th of the entire set.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Rents.",
                    "label": 0
                },
                {
                    "sent": "And the results was similar to the first post.",
                    "label": 0
                },
                {
                    "sent": "As it had a little less.",
                    "label": 0
                },
                {
                    "sent": "High precision recall, but recall and.",
                    "label": 0
                },
                {
                    "sent": "The other methods were could not achieve that this by changing the.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And finally, in addition.",
                    "label": 0
                },
                {
                    "sent": "There's this averaging strategy in the biological literatures where you take the average and the standard deviation of the estimated parameters of the gene regulation model that fits the observed time series and try to predict or reconstruct the original pathways based on the significance of the parameters and.",
                    "label": 0
                },
                {
                    "sent": "We tried this strategy and on the segments that was detected from meta clustering.",
                    "label": 0
                },
                {
                    "sent": "And was able to reconstruct the pathways in the activated state.",
                    "label": 0
                },
                {
                    "sent": "So that was the promising result.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So so in conclusion, we propose a meta clustering framework for temporal data and which is a technique for detecting segments that collectively diverges from the majority, and it has a nice property of low false positive rate.",
                    "label": 0
                },
                {
                    "sent": "So that's all my talk and thank you for this.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Logical data.",
                    "label": 0
                },
                {
                    "sent": "The number of nose is is.",
                    "label": 0
                },
                {
                    "sent": "OK, six in the literature, but we only took four because.",
                    "label": 0
                },
                {
                    "sent": "Response to a particular protein.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry, correspond twice.",
                    "label": 0
                },
                {
                    "sent": "Their SOS jeans and.",
                    "label": 0
                },
                {
                    "sent": "Six SOS, yes, it's it's a national.",
                    "label": 0
                },
                {
                    "sent": "James, in practice.",
                    "label": 0
                },
                {
                    "sent": "Yes there are.",
                    "label": 0
                },
                {
                    "sent": "Not our data, but it's publicly available.",
                    "label": 0
                }
            ]
        }
    }
}