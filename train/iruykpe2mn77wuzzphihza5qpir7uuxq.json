{
    "id": "iruykpe2mn77wuzzphihza5qpir7uuxq",
    "title": "Complex Inference in Neural Circuits with Probabilistic Population Codes and Topic Models",
    "info": {
        "author": [
            "Jeff Beck, University of Rochester"
        ],
        "published": "Jan. 14, 2013",
        "recorded": "December 2012",
        "category": [
            "Top->Biology->Neuroscience",
            "Top->Computer Science->Machine Learning->Unsupervised Learning",
            "Top->Computer Science->Machine Learning->Semi-supervised Learning"
        ]
    },
    "url": "http://videolectures.net/machine_beck_models/",
    "segmentation": [
        [
            "So probabilistic reasoning provides a coherent and in some ways optimal framework for dealing with uncertainty, and as such it's rather reassuring that behavioral experiments reliably demonstrate that humans and animals behave in a manner consistent with optimal Bayesian reasoning for a wide variety of perceptual, motor, and cognitive tasks.",
            "This requires an error code that represents probability distributions and neural circuits that implement the operations of probabilistic inference afew years ago we began to develop the probabilistic population coding framework, which is just the brain being a mature statistical learning machine.",
            "Is composed of cortical layers that are optimally or nearly optimally decoding their inputs.",
            "When this is the case, noisy patterns about tip activity implicitly represent probability distributions over task relevant stimuli, so for."
        ],
        [
            "Apple, sorry when this is the case, a.",
            "The functional form of the neural code can actually be elucidated by simply determining the functional form of the optimal decoder of neural activity.",
            "For example, a wide variety of studies in awake, behaving monkeys and cats have shown that the optimal probabilistic overall activity has a log linear form to the extent that the brain is statistically efficient.",
            "This means that the neural code that the brain actually uses also has this log linear form.",
            "Much of our previous work is actually going into.",
            "Or has revolved around demonstrating how biologically possible neural circuits might implement some of the basic operations of probabilistic inference using this kind of linear probabilistic population code or PPC, we've even been able to assign specific computational roles.",
            "Just for some of the nonlinear critical operations that we've observed, such as coincidence detection and divisive normalization.",
            "But as I've said, we've largely focused on the simple problems of probabilistic inference like those shown here.",
            "This was sensible both because these simple problems are in a sense the sort of primitives or probabilistic inference.",
            "And also because they correspond to the behavioral tasks for which we actually have normal data.",
            "Regardless, this piece meal approach is left us without a general theory for inference and learning with linear PC's, and no real way to deal with complex and intractable problems of probabilistic inference or paper.",
            "This year was intended to address these issues."
        ],
        [
            "Now for the details of course, come to the poster, but the short answer is that variational Bayesian expectation maximization algorithm naturally alliance with linear PC representations of marginal posterior distributions and can therefore be used to generate fast biologically possible network dynamics that implement approximate probabilistic inference with linear PCs.",
            "This is this is this VBM plus PPC approach yields constraints on normal dynamics needed for approximate inference.",
            "Now I was told by my collaborators that this wasn't enough acronyms for NIPS paper, so as a simple extension to this approach, we generated biologically possible network implementations for some topic for inference with some topic models, in particular LDA, Anna dynamic extension of it.",
            "Now, this wasn't.",
            "And then, uh, idle mathematical exercises, topic models for documents solve the problem, which is very much like the problem faced by.",
            "Every layer of cortex, for example document might be about topics like coffee cake and strawberries.",
            "And associated with these topics are character patterns of words similar, like in a factory system you might have.",
            "You might be interested in smelling to determine whether or not coffee cake or strawberries or present.",
            "And associated with each of those odors is a particular pattern of activity in the olfactory receptor neurons.",
            "Given a factory scene is going to be given, all factory is going to be mixture of these patterns of spikes and the goal naturally term.",
            "How much coffee is actually present regardless, which skews me."
        ],
        [
            "Regardless, we can turn the crank of the MPC machinery applied to LDA to generate networks which infer the underlying causes of complex mixtures of spikes in a biologically possible way.",
            "These networks are interesting features which I don't have time to mention.",
            "But you know, do come by the post and find out.",
            "We also extended this to a dynamic case where we had a odors, varied overtime, cornerback process.",
            "And it's easy to show that actually had very little complexity to the network that does inference, so in any way.",
            "To summarize, VB MPPC, LDA, OUDN and even little LP sparsity all over at TH 92.",
            "Thanks, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So probabilistic reasoning provides a coherent and in some ways optimal framework for dealing with uncertainty, and as such it's rather reassuring that behavioral experiments reliably demonstrate that humans and animals behave in a manner consistent with optimal Bayesian reasoning for a wide variety of perceptual, motor, and cognitive tasks.",
                    "label": 0
                },
                {
                    "sent": "This requires an error code that represents probability distributions and neural circuits that implement the operations of probabilistic inference afew years ago we began to develop the probabilistic population coding framework, which is just the brain being a mature statistical learning machine.",
                    "label": 0
                },
                {
                    "sent": "Is composed of cortical layers that are optimally or nearly optimally decoding their inputs.",
                    "label": 0
                },
                {
                    "sent": "When this is the case, noisy patterns about tip activity implicitly represent probability distributions over task relevant stimuli, so for.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Apple, sorry when this is the case, a.",
                    "label": 0
                },
                {
                    "sent": "The functional form of the neural code can actually be elucidated by simply determining the functional form of the optimal decoder of neural activity.",
                    "label": 0
                },
                {
                    "sent": "For example, a wide variety of studies in awake, behaving monkeys and cats have shown that the optimal probabilistic overall activity has a log linear form to the extent that the brain is statistically efficient.",
                    "label": 0
                },
                {
                    "sent": "This means that the neural code that the brain actually uses also has this log linear form.",
                    "label": 0
                },
                {
                    "sent": "Much of our previous work is actually going into.",
                    "label": 0
                },
                {
                    "sent": "Or has revolved around demonstrating how biologically possible neural circuits might implement some of the basic operations of probabilistic inference using this kind of linear probabilistic population code or PPC, we've even been able to assign specific computational roles.",
                    "label": 0
                },
                {
                    "sent": "Just for some of the nonlinear critical operations that we've observed, such as coincidence detection and divisive normalization.",
                    "label": 1
                },
                {
                    "sent": "But as I've said, we've largely focused on the simple problems of probabilistic inference like those shown here.",
                    "label": 0
                },
                {
                    "sent": "This was sensible both because these simple problems are in a sense the sort of primitives or probabilistic inference.",
                    "label": 0
                },
                {
                    "sent": "And also because they correspond to the behavioral tasks for which we actually have normal data.",
                    "label": 0
                },
                {
                    "sent": "Regardless, this piece meal approach is left us without a general theory for inference and learning with linear PC's, and no real way to deal with complex and intractable problems of probabilistic inference or paper.",
                    "label": 1
                },
                {
                    "sent": "This year was intended to address these issues.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now for the details of course, come to the poster, but the short answer is that variational Bayesian expectation maximization algorithm naturally alliance with linear PC representations of marginal posterior distributions and can therefore be used to generate fast biologically possible network dynamics that implement approximate probabilistic inference with linear PCs.",
                    "label": 1
                },
                {
                    "sent": "This is this is this VBM plus PPC approach yields constraints on normal dynamics needed for approximate inference.",
                    "label": 0
                },
                {
                    "sent": "Now I was told by my collaborators that this wasn't enough acronyms for NIPS paper, so as a simple extension to this approach, we generated biologically possible network implementations for some topic for inference with some topic models, in particular LDA, Anna dynamic extension of it.",
                    "label": 0
                },
                {
                    "sent": "Now, this wasn't.",
                    "label": 0
                },
                {
                    "sent": "And then, uh, idle mathematical exercises, topic models for documents solve the problem, which is very much like the problem faced by.",
                    "label": 0
                },
                {
                    "sent": "Every layer of cortex, for example document might be about topics like coffee cake and strawberries.",
                    "label": 0
                },
                {
                    "sent": "And associated with these topics are character patterns of words similar, like in a factory system you might have.",
                    "label": 0
                },
                {
                    "sent": "You might be interested in smelling to determine whether or not coffee cake or strawberries or present.",
                    "label": 0
                },
                {
                    "sent": "And associated with each of those odors is a particular pattern of activity in the olfactory receptor neurons.",
                    "label": 0
                },
                {
                    "sent": "Given a factory scene is going to be given, all factory is going to be mixture of these patterns of spikes and the goal naturally term.",
                    "label": 0
                },
                {
                    "sent": "How much coffee is actually present regardless, which skews me.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Regardless, we can turn the crank of the MPC machinery applied to LDA to generate networks which infer the underlying causes of complex mixtures of spikes in a biologically possible way.",
                    "label": 0
                },
                {
                    "sent": "These networks are interesting features which I don't have time to mention.",
                    "label": 0
                },
                {
                    "sent": "But you know, do come by the post and find out.",
                    "label": 0
                },
                {
                    "sent": "We also extended this to a dynamic case where we had a odors, varied overtime, cornerback process.",
                    "label": 0
                },
                {
                    "sent": "And it's easy to show that actually had very little complexity to the network that does inference, so in any way.",
                    "label": 0
                },
                {
                    "sent": "To summarize, VB MPPC, LDA, OUDN and even little LP sparsity all over at TH 92.",
                    "label": 0
                },
                {
                    "sent": "Thanks, thank you.",
                    "label": 0
                }
            ]
        }
    }
}