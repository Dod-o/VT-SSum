{
    "id": "nfgxc6mb53yr27emqszsrg3fecbhpd6t",
    "title": "PAC-Bayesian Analysis and Its Applications",
    "info": {
        "author": [
            "Yevgeny Seldin, Department of Computer Science, University of Copenhagen",
            "Fran\u00e7ois Laviolette, Universit\u00e9 Laval",
            "John Shawe-Taylor, Centre for Computational Statistics and Machine Learning, University College London"
        ],
        "published": "Oct. 29, 2012",
        "recorded": "September 2012",
        "category": [
            "Top->Computer Science->Machine Learning->Bayesian Learning",
            "Top->Computer Science->Machine Learning->Reinforcement Learning"
        ]
    },
    "url": "http://videolectures.net/ecmlpkdd2012_seldin_laviolette_shawe_taylor_pac/",
    "segmentation": [
        [
            "This will be a tutorial on Park Basin analysis and its applications, and I'm Yevgeny Selden and the other two presenters are Francois Lavalette and Joshua Taylor.",
            "I."
        ],
        [
            "So at the beginning of the tutorial I will show you the first part based covenant in equality.",
            "And I will show you one application to find the domain of this inequality.",
            "Then John will take the stage and he will talk about applications in continuous domains.",
            "Many support vector machines, the relations between base and learning and pack basing analysis and about learning the prior impact based on analysis.",
            "After this we will have 10 minutes break."
        ],
        [
            "And we will get to the second part of the tutorial which will be started by Francois and he will talk a bit about the history of Park Basin analysis.",
            "Giving a bit while the references about where it is applied.",
            "And talk about localized basin bounds, and then I will get back and I will talk about applications of Park Basin bounds to unsupervised learning density estimation and then about pack based.",
            "Version inequality for martingales and applications of Park Basin analysis in reinforcement learning.",
            "And I'll finish with some summary of the story.",
            "Oak."
        ],
        [
            "OK, so let's start with the first part of the pack base holding an equality and first of all, what is this pack in pack Bayesian bounds?",
            "So pack stays for probably approximately correct learning framework introduced by Valiant.",
            "And it says that we are looking for some.",
            "We are looking to provide guarantees on the approximation error of empirical estimates that hold with high probability with respect to representativeness of the observed sample.",
            "So generally in machine learning we get some sample and we want to infer something from this sample.",
            "I want this to be as accurate as possible.",
            "But there is always some probability that the sample that we observed is not representative for the problem that we are studying.",
            "And in that case we don't do much with that sample.",
            "OK."
        ],
        [
            "So some definitions for supervised learning to start with.",
            "We have some samples SpaceX, we have a label space Y.",
            "We have a loss function for making a wrong prediction.",
            "This L of Y&Y prime will have a hypothesis space.",
            "And each hypothesis, the predictions of the hypothesis on sample X is denoted by this H of X.",
            "And then the loss of hypothesis is the expectation of the respect to the sample which is drawn according to some unknown distribution of the loss of the predictions of this hypothesis on sample.",
            "And the empirical loss.",
            "It's the sum over the sample that we observed of the empirical losses of the points in that sample.",
            "Is that clear, standard, supervised learning setting?"
        ],
        [
            "Now in Park Basin analysis we are going to talk about randomized classifiers and what is a randomized classifier.",
            "So let's say that we have a distribution row over the hypothesis space.",
            "The randomized classifier at each round of the game picks hypostasis from this space according to this distribution of H. Then we observe a sample and we use this hypothesis in order to predict the label on that sample.",
            "And on the next round we repeat it again, so we draw a new hypothesis from H and we use it to predict the label of the sample.",
            "OK.",
            "So in the usual case when you work just with a single hypothesis, you can think about throw as a Delta distribution, but in the more general case we can use several hypostasis.",
            "To make the predictions."
        ],
        [
            "Now the loss of this kind of classifier, so it's expectation with respect to the data there on according to unknown distribution and the hypothesis drone according to of the loss of the hypothesis on the sample that we observe.",
            "Or it's the expectation with respect to the hypothesis drug according to of the expected loss of the hypothesis.",
            "And we use this dot product notation.",
            "So it's just imagine possibly infinite dimensional vector of the losses for each of the prothesis, and this is a distribution over this space, and this is just the dot product between them.",
            "So for discrete hypothesis space it's the sum over reported space, and for continuous Reporter space it's an integral over the Reporter space of the loss according to this distribution role."
        ],
        [
            "And for the empirical loss, it's the average with respect to row of the empirical losses of the hypothesis.",
            "Clearer."
        ],
        [
            "Now, just to remind you, the KL diversions between two distributions on the hypothesis space H. It's the expectation with respect to Ross logarithm of the ratio of the distributions.",
            "Or we use this once again dot product notation which will be useful for the explanations after that and once again this is for the discrete and for the continuous case the definition of the scaled versions.",
            "Now."
        ],
        [
            "Now the bug based on inequality first introduced by David McAllister and 1998 Ninety Nine, says that if we have a loss that is bounded into 01 interval and we fixed reference distribution over the hypothesis space, then for any parameter Delta in the 01 interval with probability greater than one minus Delta over the sample for all posterior distributions throw simultaneously, the expected loss of this randomized classifier.",
            "That takes the hypothesis according to Raw, is bounded by its empirical loss plus the square root of the Cal.",
            "Diversions between the posterior and prior log of one over Delta divided by two times the sample size.",
            "Game now."
        ],
        [
            "Just to give you for comparison, if we would just use the usual Holdings inequality for a single hypothesis, we would get the loss of the single hypothesis is bounded by the empirical loss of the Depot test plus square root of.",
            "Log of one over Delta over two times the sample size.",
            "But if we have multiple hypothesis as you I guess all know we should take some.",
            "For example union bound over all the hypothesis to make sure that this inequality holds for all the hypothesis simultaneously.",
            "So this can be seen as a kind of generalization of the Union bound."
        ],
        [
            "And the difference between the two bounds.",
            "It's this scale diversion storm.",
            "And they know that if row is equal to \u03c0, then actually we don't pay anything in this term.",
            "And if it takes some other procedure distribution, then we pay this scale diversions term.",
            "And there is one other special case that makes it a bit easier to."
        ],
        [
            "Understand the bounds.",
            "So if they protest space is finite and we take the prior as a uniform prior one over the size of the computer space, then the scale divergences it can be written as this."
        ],
        [
            "Average with respect are of logarithm operation between roan pie and we separated into logarithm of 1 / \u03c0 and logarithm of fraud."
        ],
        [
            "Now.",
            "This log of 1 / \u03c0 it's constant for all the prothesis, it's just log out of the size of the Potters space, so we get this log of the size of the reporters space, and this is the entropy of the distribution row.",
            "And since the entropy is always positive, we get that this scale is bounded by the size of the logarithm of the size of the hypothesis space.",
            "Case."
        ],
        [
            "So generally we recover the usual union bound, but as you can see this bound is more general than the Union bound.",
            "OK, in this case it would just have the logarithm of the size of the hypothesis space.",
            "Any questions up to now?",
            "OK."
        ],
        [
            "So a bit of intuition behind the bound, so we get the average loss of the parties with respect to the distribution row is bounded by the average empirical loss plus the square root of the KL diversions over two times the sample size in the Cal diversions we can once again split into this average flow of 1 / \u03c0 minus the entropy.",
            "And this first term it can be seen as the description length.",
            "So if we use PIE in order to build some code for the hypothesis space and we are drawing the hypothesis according to this posterior distribution row.",
            "That's the average number of bits that we need in order to describe the hypothesis that we pick from the hypothesis class."
        ],
        [
            "So we get that here we have a trade off so we have to be cross that minimizes this tradeoff between the empirical error of each of hypothesis, the complexity, or the description length or prior belief in the corresponding capata switches.",
            "The log of 1 / \u03c0.",
            "And at the same time we want draw to have maximum entropy.",
            "OK, so this is the.",
            "Maximum entropy principle combined with the tradeoff between the empirical.",
            "Loss of each individual hypothesis and.",
            "The proud of Billy for the complexity of each of the parties."
        ],
        [
            "Now a bit about relation between this bound and the basin learning.",
            "So this is our bound and the relation is that we have an explicit way to incorporate prior information where the definition of this power of H. So embarrassing learning could start with some distribution on the portal space and we calculate the posterior distribution of vertical process based given the data, which is the evidence.",
            "And despites the same way as in Bayesian learning to encode our prior knowledge.",
            "So what's the difference?",
            "Sophie."
        ],
        [
            "First of all, we have an explicit high probability guarantee on the expected performance of this randomized classifier role, unlike in Basin learning, where we just calculate the most likely posterior distribution.",
            "But we don't know how well this posterior distribution is going to behave on you points.",
            "We just know that it's the best we can do given the sample, but we don't have any guarantee."
        ],
        [
            "Is.",
            "2nd, we don't believe in the correctness of the prior, so this bound holds for any choice of the of the prior distribution \u03c0.",
            "Like once again and based on learning where it is assumed that the prior is actually the kind of correct model of the world."
        ],
        [
            "We have explicit dependence on the loss function here, so if we work with the different loss function, we are going to.",
            "End up with a different posterior distribution.",
            "Whereas in Bayesian learning usually what is used is the log loss.",
            "But here we have the dependence on the explicit law so far.",
            "Really using log loss we will get one classifier for use quadratic loss.",
            "It will be another classifier.",
            "For 01 loss it will be.",
            "Yet another."
        ],
        [
            "Pacifier.",
            "We have a bit different weighting between the prior and evidence and then the."
        ],
        [
            "And learning can.",
            "Finally this bound holds, or any posterior distribution at all, and in particular it is also holds for the Bayesian posterior.",
            "So we can actually calculate the Bayesian posterior and use our bounds to provide guarantees on the expected behavior of the base optimal classifier."
        ],
        [
            "What's the relational difference with this theory about Nick Sherman and Kiss Theory and Rademacher complexities?",
            "So it's almost complementary, so the relation is that we have explicit high probability guarantee on the expected performance of the classifier, and we have explicit dependence on the loss function.",
            "And the difference is."
        ],
        [
            "That so one difference is that the complexity is defined individually for each report is H. We have this definition of five H rather than the complexity of a hypothesis class that we're having.",
            "VC theory, so in this theory we have this dimension of the hypothesis class.",
            "There is no sense to talk about this dimension of individual hypothesis.",
            "Here we can approach each individual hypothesis by setting a different prior.",
            "We have explicit way to incorporate prior knowledge.",
            "We had this definition of the prior.",
            "We can say that some of the hypothesis are more likely.",
            "Some are less likely.",
            "And the third difference is that the bound is defined for this randomized classifier throw and not individual hypothesis as we have.",
            "For example VC theory.",
            "We have the bound which holds for each individual hypothesis.",
            "Here we have the distributions, but there are some work arounds in many cases where we can derive bounds also for individual hypothesis from from this approach."
        ],
        [
            "Ann, some relation to statistical physics.",
            "So if we look at this bound, we can see that there is this tradeoff between the empirical loss and the KL diversions.",
            "So if we write explicitly this thread of parameterized by this better.",
            "This, for those of you who have some statistical physics background that can remind the free energy functional."
        ],
        [
            "And generally, the bound provides the optimal temperature beta to study the system that depends on the size of the sample and the empirical properties of the system which are.",
            "This empirical losses of each of the voters.",
            "Um?"
        ],
        [
            "OK, so this is the bound one more time and now I'm going to show you the idea behind the proof, but.",
            "Any questions up to now?",
            "OK.",
            "So this is the bound that I've shown you before and how we prove this bound.",
            "So the proof starts."
        ],
        [
            "With Don Scarborough Transpirational definition of KL diversions, which says that the kale divergent between oh and Pi can be written as a Supreme over all possible functions.",
            "Between of the difference between the average of the functions respect to raw and logarithm of the average of the exponent of the function with respect to pie.",
            "So this is kind of the dual of the kelda versions and.",
            "This theorem falls follows from duality arguments on the CAD versions and this function."
        ],
        [
            "Now we take this theorem and we just change sites and we get that for any function and any pair of distribution through and by the average of the function with respect to is bounded by the KL divergent plus the average of the logarithm of the average of the function with respect to \u03c0. OK, and this side is what we are going to be interested in."
        ],
        [
            "A bit more background, so just to remind you the Markov's inequality.",
            "So if we have a positive random variable and confidence parameter Delta, then with probability 1 minus Delta, the random variable is bounded by one over Delta times the expectation of the random variable."
        ],
        [
            "And Holdings inequality, which says that if we have a sequence of independent random variables such that each variable belongs to the 01 interval, then for any parameter Lambda the expectation of the exponent of Lambda times the average distance between the variables in their expectations is bounded by the exponent of Lambda Square over 2 * 8 times the number of the variables.",
            "Yeah, so these are standard in equalities."
        ],
        [
            "And now we put all this together.",
            "So we start with this change of measure inequality, which says that the average of the function is bounded by the killed versions plus the average of the exponent of the function."
        ],
        [
            "And we take this F of H as the quantity of interest.",
            "So we take it as Lambda times the difference between the expected and the empirical loss for each of the prothesis.",
            "Now, in order to get the bound, we need to bound this.",
            "Adam, which is known as Laplace transform.",
            "So how we bound this term in the inequality?"
        ],
        [
            "So we look at this average of the exponent of the function as a random variable Y.",
            "Is it random variable because the function has the empirical quantity in its definition, so the value of the function is a random variable and the average of the exponent of the function is also a random variable, and we know that the this random variable by micros inequality is bounded by one over Delta times.",
            "The expectation of this random variable."
        ],
        [
            "Now.",
            "Since we defined by before, we observe the sample, we can exchange the order of the expectation and the DOT product.",
            "So we can take the expectation inside the DOT product.",
            "And this is the important point why we should define the prior before we observe the sample.",
            "If the prior would depend on the sample, we wouldn't be able to change this order.",
            "And now this this quantity it's."
        ],
        [
            "Actually, what's bounded by Harding's inequality?",
            "So we get that the expectation of the exponent of the function is bounded by the exponent of Lambda squared over 8 times the size of the sample, and this bound it actually it's independent of the function, so we get just an average of a number."
        ],
        [
            "And it's just this number.",
            "OK, now.",
            "The important point about this step of the proof.",
            "So the first inequality.",
            "Was valid for any pair of distribution through and \u03c0.",
            "We fixed one of them before we observed the sample.",
            "And now.",
            "We related all possible posterior distributions.",
            "2A single prior distribution \u03c0.",
            "And then we bounded this quantity.",
            "So this quantity depends just on the prior distribution Pi.",
            "There is no posterior distribution in this.",
            "Expression and this randomized argument, based on Markov's inequality would do it only once just for this term.",
            "And therefore we get that this bound holds simultaneously for all posterior distributions with probability 1 minus Delta.",
            "OK, so once again, the probabilistic argument here, which holds with probability one or greater than one minus Delta.",
            "We applied only once to this term.",
            "And this inequality holds for any pair of.",
            "Pie and Roseau pie is fixed, but we can pick any raw.",
            "OK, and we have this inequality for all posterior decisions.",
            "At once.",
            "And one more point, so we could put pick some other functions F and.",
            "This expectation of the exponent of the functions, it's generally a common.",
            "Way to achieve also other.",
            "Concentration inequality is like banished and inequality and many other inequality's and this is going to be the connection point in the continuation of this talk to other inequality.",
            "So we are going to have pack based version quality and park based coding.",
            "Consume inequality for martingales.",
            "So all of them are connecting at this point where we take expectations of exponents of functions.",
            "But here we are in the Holdings inequality."
        ],
        [
            "So we got that this second term is bounded by log of one over Delta plus Lambda squared, over 8 times the sample size."
        ],
        [
            "Then we substitute this bound here and we normalize by Lambda.",
            "So we get this expression and.",
            "The."
        ],
        [
            "Last step is to do optimization over Lambda.",
            "It's just something more technical, so I'm skipping it.",
            "Anne.",
            "And."
        ],
        [
            "After optimization over Lambda, we get this inequality.",
            "OK, so."
        ],
        [
            "The main ingredients once again it's to start with this change of measure inequality to pick the function F to bound.",
            "This term and the inequality, and to do some fine at optimization of the parameters and we have the bound."
        ],
        [
            "Any questions?",
            "OK fine."
        ],
        [
            "So the details that are skipped can be found in this paper.",
            "It says that it's for martingales, but generally you can recover also the details for the individual random variables.",
            "It's almost the same."
        ],
        [
            "OK, now I will show you one application of this bound to start with and application is going to be in final domain and to the."
        ],
        [
            "Problem, so the problem that we are looking at we have a matrix of.",
            "Viewers buy movies and we have the ratings that the viewers give to the movies.",
            "But of course not all viewers.",
            "So all the movies so.",
            "That are all only part of the entries in this matrix that are present and want to complete the missing entries in this matrix.",
            "And the model that we are going to work with.",
            "So we will say that the probability of a certain rating given a pair of viewer and movie it's a sum over.",
            "Possible assignments of viewers to clusters of viewers and movies of two clusters of movies of the probability of assigning the viewer to the cluster of viewers, the movie to the cluster of movies and the probability of observing a certain rating in the cluster product space of movies by viewers.",
            "Or you can also think about it as this graphical model.",
            "So the viewers are mapped to clusters of viewers.",
            "The movies are mapped to clusters of movies.",
            "And the writing is predicted in this cluster product space of clusters of viewers by clusters of movies.",
            "And the idea is that the cluster space is much smaller than the original space, so it's much easier to learn in the cluster space.",
            "We can do it with less samples than doing it on the original space."
        ],
        [
            "So in order to apply the pacbase analysis to this problem, first of all we have to define the hypothesis space that we are working with and the hypothesis space that we are going to take our all hard partitions of the space of years by movies.",
            "And all possible ways to assign labels to this partition space?",
            "So you should also think that we can make permutations of rows and columns in this matrix when we do the partitioning the prior over the space I will define on the next slide and the important point is that this model actually defines a posterior distribution over this space because we can go through all the.",
            "Rose and draw a cluster for each viewer according to the first distribution, we can draw a cluster for each movie according to the second distribution.",
            "We gotta partition and then according to the third distribution we can draw labels to each cluster product cell.",
            "And we got a hypothesis from this importers class.",
            "So we can think that there is this randomized selection of the hypothesis that goes behind the scenes of this.",
            "Classifier.",
            "OK. Now how we build a?"
        ],
        [
            "Prior over the space.",
            "So we just count how many ways there are to partition the viewers and movies into the clusters and to assign labels to the cluster product space.",
            "But we do it in a smart way.",
            "So first of all, if this is the number of viewers.",
            "We can choose between.",
            "One and the number of viewers, clusters of viewers so we can put all the viewers in one cluster.",
            "We can put every viewer in a separate cluster and we can do all the possibilities in between.",
            "So there are the number of viewers possibilities to choose the number of clusters."
        ],
        [
            "Once we've chosen the number of clusters, there are at most number of viewers to the power of the number of clusters, minus one possibilities to choose the sizes of the clusters.",
            "So once again, each cluster maybe between one viewer and all the viewers and the size of the last cluster is determined by the sizes of all other clusters because it just gets what left from the partition.",
            "So we can choose, for example, a partition to two by two clusters, or we can choose the partitions in to three by one clusters in this example."
        ],
        [
            "Once we have chosen the sizes of the clusters, there is this multinomial coefficient possibilities to assign actually the viewers to the clusters of viewers and movies to the clusters of movies.",
            "So if we have a balanced partition, we have 4 / 2 or 6 possibilities to assign viewers to the clusters of viewers.",
            "When the size of each cluster is 2 and we have four unbalanced partitions, four possibilities to assign viewers to the clusters of years when the size of 1 cluster is 3 and the size of the second cluster is 1.",
            "OK, and the important thing to notice here is that the space of balanced partitions is much larger than the space of unbalanced partitions.",
            "OK. And."
        ],
        [
            "Once we have chosen the partition, there are the number of labels to the power of number of the number of the partition cells to assign actual labels to this partition cells."
        ],
        [
            "So if we put everything together, we get that the prior is lower bounded by the exponent of.",
            "Of the quantities that's written on the slide.",
            "K."
        ],
        [
            "So now we have to bound the kelda versions between the posterior and prior.",
            "So this is to remind you that prior to this is the posterior."
        ],
        [
            "And after some calculations we get the KL diversion between the posterior and prior is bounded by the sum over the dimensions of the number of viewers times the mutual information between the viewers and the clusters according to this conditional distribution.",
            "Plus the number of clusters logarithm of the number of years and.",
            "The number of the partition cells located of the number of labels."
        ],
        [
            "So more specifically, we can take this joint distribution which is uniform over the viewers because we went in with Santa cluster for each viewer and conditional distribution from the posterior, and we calculate the mutual information according to this.",
            "Distribution."
        ],
        [
            "And plug it back into the bond and we get that the loss of such prediction strategy is bounded by the empirical loss plus square root of the sum over the dimensions of the number of years times the mutual information between the viewers in the clusters of yours and other terms.",
            "So what does it give us?",
            "So if we look into the solution where we put.",
            "All the viewers and all the movies in one big cluster.",
            "The mutual information between the viewers and the clusters is zero.",
            "We put everybody in one big cluster, so we have no information about each individual.",
            "So in this case.",
            "This bound term is going to be small because the mutual information is small.",
            "But we are going to approximate everything with one global average and.",
            "The empirical loss is going to be large because we are approximately all the entries with one global average.",
            "But this global average is going to be close to the expected loss, which is the expected loss when we predict the version with one global average and generally the bound says that it's very easy to learn.",
            "The average rating for this matrix.",
            "As we go to the other end and we put everybody in a separate cluster, we can achieve 0 empirical loss because we can just predict with the ratings that we have in the corresponding cluster.",
            "But the mutual information is going to be log of the number of years we preserve all the information about the original entries, so this empirical loss that is 0 is going to be far away from the expected loss of that strategy.",
            "Becausw the strategy is very complex, it preserves really a lot of information about the.",
            "Structure of the problem.",
            "And in between the have this intermediate solutions and.",
            "The important point is, once again the unbalanced partitions have lower complexity than balanced partitions.",
            "They're simpler.",
            "You can think about it that you need less bits in order to describe an unbalanced partitions.",
            "Then you need in order to describe a balanced partition.",
            "So generally, if you think about sometimes there is a constraint.",
            "Putting clustering problems to get balanced clusters.",
            "So from the generalization POV, that's kind of incorrect bias for a clustering problem cause.",
            "Once again, unbalanced partitions have better.",
            "They are simpler, so they have better generalization properties."
        ],
        [
            "So.",
            "One more comment.",
            "So there are two types of prior knowledge in this problem, so we used.",
            "We just counted how many ways there are to partition this space.",
            "The class status, so we had no information about the actual distribution of the data.",
            "If there would be some information that would say for example, the two rows are more likely to be together in one cluster.",
            "We could put this information into the prior and this would break the symmetry between the entry so that the prior that we construct it was just based on the symmetries.",
            "In the partitions and partition the whole hypata space into subspaces which were in different under permutation of the symmetric under permutation of names of the variables.",
            "If we have some prior knowledge that breaks the symmetry, we can put it into the prior and then we are going to get a different prior and different CAD versions.",
            "And that's going to be prior knowledge about the distribution over the data, so we have this structural prior knowledge which exploits the symmetries in the path of space and we may have the distributional prior knowledge, which breaks this structural symmetries and introduces the knowledge about the actual distribution over the data into the analysis and bounds."
        ],
        [
            "So, just briefly to give you one example of an application of this bound to a real problem.",
            "So we took movie lens data sets.",
            "There is 100,000 ratings on the five Star scaling.",
            "And we take 80,000 ratings for training and 20,000 ratings for testing that about 1000 viewers and 1500 movies.",
            "And at least at the time that we made the experiment, the state of the art mean absolute error there.",
            "The difference between the predicted number of stars and the actual number of stars was zero point 72, so we're on a 5 star rating scale, so the maximum error is 4 and.",
            "This is like 0.72 out of four maximal error."
        ],
        [
            "So this is the bond that we had on the previous slide and we replace it with the parameterized tradeoff.",
            "This better M times the empirical loss of strategy plus the.",
            "Number of viewers times the mutual information.",
            "The number of movies times the mutual information between the.",
            "Variables in the clusters.",
            "And we do optimization.",
            "We do a linear search over better.",
            "So we solve this problem for several values of beta and we substitute the solution back onto the bound and we calculate what's the bound that we get.",
            "And the point is that the mutual information has nice convex properties, so it's actually very easy to optimize this and the empirical loss is linear, so it's very easy to optimize this thread of and we just once again do a linear search over beta and check with the bound.",
            "What's a good solution?"
        ],
        [
            "So we start with certain by 6 clusters and what you see here.",
            "So the bottom line is the test loss and the blue line is the bound that we get.",
            "So the bound is not very indicative about the.",
            "Test loss, but it's important to point out that the scale, so here it's one 1.4 and the maximal error is 4, so the bound is meaningful.",
            "It's not some voidbound that's somewhere in the skies, but we can actually plot the bound and the test error on the same graph.",
            "Which is quite rare for theoretical analysis.",
            "Now if we zoom in, so this is a zoom in into this line.",
            "And this is how better values.",
            "So we get that for certain values of better we get this optimal zero point 72.",
            "Error rate.",
            "With our model."
        ],
        [
            "Now we go to the next point.",
            "We take 50 by 50 clusters and once again we plot the bound and test error and they both are on the same graph and the bound is still meaningful, still less than 4.",
            "And also here for certain values of better we achieve the optimal performance of zero point 72 even a bit less.",
            "Now."
        ],
        [
            "We go to an extreme point, so we take about 300 by 300 clusters and the important point to mention is that at this point the number of clusters cells is equal to the number of data points that we have.",
            "So generally we can put each data point in a separate cluster cell and try to solve the problem like this.",
            "And the important point once again, so the bound.",
            "Well, it's already close to four, but it's still meaningful and we still get the optimal performance even with this huge number of clusters.",
            "So here the number of clusters provides completely no regularization to the problem, 'cause once again we can put just every point in the separate cluster.",
            "And all the regularization is done by this mutual information term.",
            "And this tradeoff between better times, the empirical loss and the mutual information.",
            "And we see that the mutual information makes a complete control over the.",
            "Problem over the complexity of the model so we can throw in as many clusters as we want.",
            "We don't have to know how many clusters there are in the data and the model will filter out the unnecessary clusters and still get to the best possible solution.",
            "Even with this huge number of clusters."
        ],
        [
            "OK, so the summary of the experiment we achieved this optimal performance even with a huge number of clusters, so this one over better times the mutual information term has a complete control over the model complexity.",
            "And the bond is still remains meaningful even though it's not.",
            "Perfectly tight.",
            "K."
        ],
        [
            "So if you want to read a bit more on this problem, we have it in this general our paper and this result can also be generalized to three type graphical models where we can connect more than two variables and we can also generalize it to matrix three factorization.",
            "So when we very factorize the matrix into left stochastic right so high stick metrics, and what happens in the cluster product space, we can see it as the matrix factorization problem.",
            "Any questions?",
            "Before I'm giving the stage to John."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This will be a tutorial on Park Basin analysis and its applications, and I'm Yevgeny Selden and the other two presenters are Francois Lavalette and Joshua Taylor.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So at the beginning of the tutorial I will show you the first part based covenant in equality.",
                    "label": 1
                },
                {
                    "sent": "And I will show you one application to find the domain of this inequality.",
                    "label": 0
                },
                {
                    "sent": "Then John will take the stage and he will talk about applications in continuous domains.",
                    "label": 1
                },
                {
                    "sent": "Many support vector machines, the relations between base and learning and pack basing analysis and about learning the prior impact based on analysis.",
                    "label": 0
                },
                {
                    "sent": "After this we will have 10 minutes break.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we will get to the second part of the tutorial which will be started by Francois and he will talk a bit about the history of Park Basin analysis.",
                    "label": 1
                },
                {
                    "sent": "Giving a bit while the references about where it is applied.",
                    "label": 0
                },
                {
                    "sent": "And talk about localized basin bounds, and then I will get back and I will talk about applications of Park Basin bounds to unsupervised learning density estimation and then about pack based.",
                    "label": 1
                },
                {
                    "sent": "Version inequality for martingales and applications of Park Basin analysis in reinforcement learning.",
                    "label": 1
                },
                {
                    "sent": "And I'll finish with some summary of the story.",
                    "label": 0
                },
                {
                    "sent": "Oak.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so let's start with the first part of the pack base holding an equality and first of all, what is this pack in pack Bayesian bounds?",
                    "label": 0
                },
                {
                    "sent": "So pack stays for probably approximately correct learning framework introduced by Valiant.",
                    "label": 0
                },
                {
                    "sent": "And it says that we are looking for some.",
                    "label": 0
                },
                {
                    "sent": "We are looking to provide guarantees on the approximation error of empirical estimates that hold with high probability with respect to representativeness of the observed sample.",
                    "label": 1
                },
                {
                    "sent": "So generally in machine learning we get some sample and we want to infer something from this sample.",
                    "label": 0
                },
                {
                    "sent": "I want this to be as accurate as possible.",
                    "label": 0
                },
                {
                    "sent": "But there is always some probability that the sample that we observed is not representative for the problem that we are studying.",
                    "label": 0
                },
                {
                    "sent": "And in that case we don't do much with that sample.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So some definitions for supervised learning to start with.",
                    "label": 0
                },
                {
                    "sent": "We have some samples SpaceX, we have a label space Y.",
                    "label": 0
                },
                {
                    "sent": "We have a loss function for making a wrong prediction.",
                    "label": 0
                },
                {
                    "sent": "This L of Y&Y prime will have a hypothesis space.",
                    "label": 0
                },
                {
                    "sent": "And each hypothesis, the predictions of the hypothesis on sample X is denoted by this H of X.",
                    "label": 0
                },
                {
                    "sent": "And then the loss of hypothesis is the expectation of the respect to the sample which is drawn according to some unknown distribution of the loss of the predictions of this hypothesis on sample.",
                    "label": 0
                },
                {
                    "sent": "And the empirical loss.",
                    "label": 0
                },
                {
                    "sent": "It's the sum over the sample that we observed of the empirical losses of the points in that sample.",
                    "label": 0
                },
                {
                    "sent": "Is that clear, standard, supervised learning setting?",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now in Park Basin analysis we are going to talk about randomized classifiers and what is a randomized classifier.",
                    "label": 1
                },
                {
                    "sent": "So let's say that we have a distribution row over the hypothesis space.",
                    "label": 0
                },
                {
                    "sent": "The randomized classifier at each round of the game picks hypostasis from this space according to this distribution of H. Then we observe a sample and we use this hypothesis in order to predict the label on that sample.",
                    "label": 1
                },
                {
                    "sent": "And on the next round we repeat it again, so we draw a new hypothesis from H and we use it to predict the label of the sample.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So in the usual case when you work just with a single hypothesis, you can think about throw as a Delta distribution, but in the more general case we can use several hypostasis.",
                    "label": 0
                },
                {
                    "sent": "To make the predictions.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now the loss of this kind of classifier, so it's expectation with respect to the data there on according to unknown distribution and the hypothesis drone according to of the loss of the hypothesis on the sample that we observe.",
                    "label": 0
                },
                {
                    "sent": "Or it's the expectation with respect to the hypothesis drug according to of the expected loss of the hypothesis.",
                    "label": 1
                },
                {
                    "sent": "And we use this dot product notation.",
                    "label": 1
                },
                {
                    "sent": "So it's just imagine possibly infinite dimensional vector of the losses for each of the prothesis, and this is a distribution over this space, and this is just the dot product between them.",
                    "label": 0
                },
                {
                    "sent": "So for discrete hypothesis space it's the sum over reported space, and for continuous Reporter space it's an integral over the Reporter space of the loss according to this distribution role.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And for the empirical loss, it's the average with respect to row of the empirical losses of the hypothesis.",
                    "label": 0
                },
                {
                    "sent": "Clearer.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now, just to remind you, the KL diversions between two distributions on the hypothesis space H. It's the expectation with respect to Ross logarithm of the ratio of the distributions.",
                    "label": 0
                },
                {
                    "sent": "Or we use this once again dot product notation which will be useful for the explanations after that and once again this is for the discrete and for the continuous case the definition of the scaled versions.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now the bug based on inequality first introduced by David McAllister and 1998 Ninety Nine, says that if we have a loss that is bounded into 01 interval and we fixed reference distribution over the hypothesis space, then for any parameter Delta in the 01 interval with probability greater than one minus Delta over the sample for all posterior distributions throw simultaneously, the expected loss of this randomized classifier.",
                    "label": 1
                },
                {
                    "sent": "That takes the hypothesis according to Raw, is bounded by its empirical loss plus the square root of the Cal.",
                    "label": 0
                },
                {
                    "sent": "Diversions between the posterior and prior log of one over Delta divided by two times the sample size.",
                    "label": 0
                },
                {
                    "sent": "Game now.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just to give you for comparison, if we would just use the usual Holdings inequality for a single hypothesis, we would get the loss of the single hypothesis is bounded by the empirical loss of the Depot test plus square root of.",
                    "label": 0
                },
                {
                    "sent": "Log of one over Delta over two times the sample size.",
                    "label": 0
                },
                {
                    "sent": "But if we have multiple hypothesis as you I guess all know we should take some.",
                    "label": 0
                },
                {
                    "sent": "For example union bound over all the hypothesis to make sure that this inequality holds for all the hypothesis simultaneously.",
                    "label": 0
                },
                {
                    "sent": "So this can be seen as a kind of generalization of the Union bound.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the difference between the two bounds.",
                    "label": 0
                },
                {
                    "sent": "It's this scale diversion storm.",
                    "label": 0
                },
                {
                    "sent": "And they know that if row is equal to \u03c0, then actually we don't pay anything in this term.",
                    "label": 0
                },
                {
                    "sent": "And if it takes some other procedure distribution, then we pay this scale diversions term.",
                    "label": 0
                },
                {
                    "sent": "And there is one other special case that makes it a bit easier to.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Understand the bounds.",
                    "label": 0
                },
                {
                    "sent": "So if they protest space is finite and we take the prior as a uniform prior one over the size of the computer space, then the scale divergences it can be written as this.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Average with respect are of logarithm operation between roan pie and we separated into logarithm of 1 / \u03c0 and logarithm of fraud.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "This log of 1 / \u03c0 it's constant for all the prothesis, it's just log out of the size of the Potters space, so we get this log of the size of the reporters space, and this is the entropy of the distribution row.",
                    "label": 0
                },
                {
                    "sent": "And since the entropy is always positive, we get that this scale is bounded by the size of the logarithm of the size of the hypothesis space.",
                    "label": 0
                },
                {
                    "sent": "Case.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So generally we recover the usual union bound, but as you can see this bound is more general than the Union bound.",
                    "label": 0
                },
                {
                    "sent": "OK, in this case it would just have the logarithm of the size of the hypothesis space.",
                    "label": 0
                },
                {
                    "sent": "Any questions up to now?",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So a bit of intuition behind the bound, so we get the average loss of the parties with respect to the distribution row is bounded by the average empirical loss plus the square root of the KL diversions over two times the sample size in the Cal diversions we can once again split into this average flow of 1 / \u03c0 minus the entropy.",
                    "label": 1
                },
                {
                    "sent": "And this first term it can be seen as the description length.",
                    "label": 0
                },
                {
                    "sent": "So if we use PIE in order to build some code for the hypothesis space and we are drawing the hypothesis according to this posterior distribution row.",
                    "label": 0
                },
                {
                    "sent": "That's the average number of bits that we need in order to describe the hypothesis that we pick from the hypothesis class.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we get that here we have a trade off so we have to be cross that minimizes this tradeoff between the empirical error of each of hypothesis, the complexity, or the description length or prior belief in the corresponding capata switches.",
                    "label": 1
                },
                {
                    "sent": "The log of 1 / \u03c0.",
                    "label": 0
                },
                {
                    "sent": "And at the same time we want draw to have maximum entropy.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is the.",
                    "label": 1
                },
                {
                    "sent": "Maximum entropy principle combined with the tradeoff between the empirical.",
                    "label": 0
                },
                {
                    "sent": "Loss of each individual hypothesis and.",
                    "label": 0
                },
                {
                    "sent": "The proud of Billy for the complexity of each of the parties.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now a bit about relation between this bound and the basin learning.",
                    "label": 0
                },
                {
                    "sent": "So this is our bound and the relation is that we have an explicit way to incorporate prior information where the definition of this power of H. So embarrassing learning could start with some distribution on the portal space and we calculate the posterior distribution of vertical process based given the data, which is the evidence.",
                    "label": 0
                },
                {
                    "sent": "And despites the same way as in Bayesian learning to encode our prior knowledge.",
                    "label": 0
                },
                {
                    "sent": "So what's the difference?",
                    "label": 0
                },
                {
                    "sent": "Sophie.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "First of all, we have an explicit high probability guarantee on the expected performance of this randomized classifier role, unlike in Basin learning, where we just calculate the most likely posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "But we don't know how well this posterior distribution is going to behave on you points.",
                    "label": 0
                },
                {
                    "sent": "We just know that it's the best we can do given the sample, but we don't have any guarantee.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is.",
                    "label": 0
                },
                {
                    "sent": "2nd, we don't believe in the correctness of the prior, so this bound holds for any choice of the of the prior distribution \u03c0.",
                    "label": 0
                },
                {
                    "sent": "Like once again and based on learning where it is assumed that the prior is actually the kind of correct model of the world.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We have explicit dependence on the loss function here, so if we work with the different loss function, we are going to.",
                    "label": 1
                },
                {
                    "sent": "End up with a different posterior distribution.",
                    "label": 1
                },
                {
                    "sent": "Whereas in Bayesian learning usually what is used is the log loss.",
                    "label": 0
                },
                {
                    "sent": "But here we have the dependence on the explicit law so far.",
                    "label": 0
                },
                {
                    "sent": "Really using log loss we will get one classifier for use quadratic loss.",
                    "label": 0
                },
                {
                    "sent": "It will be another classifier.",
                    "label": 0
                },
                {
                    "sent": "For 01 loss it will be.",
                    "label": 0
                },
                {
                    "sent": "Yet another.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Pacifier.",
                    "label": 0
                },
                {
                    "sent": "We have a bit different weighting between the prior and evidence and then the.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And learning can.",
                    "label": 0
                },
                {
                    "sent": "Finally this bound holds, or any posterior distribution at all, and in particular it is also holds for the Bayesian posterior.",
                    "label": 0
                },
                {
                    "sent": "So we can actually calculate the Bayesian posterior and use our bounds to provide guarantees on the expected behavior of the base optimal classifier.",
                    "label": 1
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What's the relational difference with this theory about Nick Sherman and Kiss Theory and Rademacher complexities?",
                    "label": 1
                },
                {
                    "sent": "So it's almost complementary, so the relation is that we have explicit high probability guarantee on the expected performance of the classifier, and we have explicit dependence on the loss function.",
                    "label": 1
                },
                {
                    "sent": "And the difference is.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That so one difference is that the complexity is defined individually for each report is H. We have this definition of five H rather than the complexity of a hypothesis class that we're having.",
                    "label": 1
                },
                {
                    "sent": "VC theory, so in this theory we have this dimension of the hypothesis class.",
                    "label": 0
                },
                {
                    "sent": "There is no sense to talk about this dimension of individual hypothesis.",
                    "label": 0
                },
                {
                    "sent": "Here we can approach each individual hypothesis by setting a different prior.",
                    "label": 1
                },
                {
                    "sent": "We have explicit way to incorporate prior knowledge.",
                    "label": 0
                },
                {
                    "sent": "We had this definition of the prior.",
                    "label": 0
                },
                {
                    "sent": "We can say that some of the hypothesis are more likely.",
                    "label": 0
                },
                {
                    "sent": "Some are less likely.",
                    "label": 1
                },
                {
                    "sent": "And the third difference is that the bound is defined for this randomized classifier throw and not individual hypothesis as we have.",
                    "label": 0
                },
                {
                    "sent": "For example VC theory.",
                    "label": 0
                },
                {
                    "sent": "We have the bound which holds for each individual hypothesis.",
                    "label": 0
                },
                {
                    "sent": "Here we have the distributions, but there are some work arounds in many cases where we can derive bounds also for individual hypothesis from from this approach.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Ann, some relation to statistical physics.",
                    "label": 1
                },
                {
                    "sent": "So if we look at this bound, we can see that there is this tradeoff between the empirical loss and the KL diversions.",
                    "label": 1
                },
                {
                    "sent": "So if we write explicitly this thread of parameterized by this better.",
                    "label": 0
                },
                {
                    "sent": "This, for those of you who have some statistical physics background that can remind the free energy functional.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And generally, the bound provides the optimal temperature beta to study the system that depends on the size of the sample and the empirical properties of the system which are.",
                    "label": 1
                },
                {
                    "sent": "This empirical losses of each of the voters.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so this is the bound one more time and now I'm going to show you the idea behind the proof, but.",
                    "label": 0
                },
                {
                    "sent": "Any questions up to now?",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So this is the bound that I've shown you before and how we prove this bound.",
                    "label": 0
                },
                {
                    "sent": "So the proof starts.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With Don Scarborough Transpirational definition of KL diversions, which says that the kale divergent between oh and Pi can be written as a Supreme over all possible functions.",
                    "label": 0
                },
                {
                    "sent": "Between of the difference between the average of the functions respect to raw and logarithm of the average of the exponent of the function with respect to pie.",
                    "label": 0
                },
                {
                    "sent": "So this is kind of the dual of the kelda versions and.",
                    "label": 0
                },
                {
                    "sent": "This theorem falls follows from duality arguments on the CAD versions and this function.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now we take this theorem and we just change sites and we get that for any function and any pair of distribution through and by the average of the function with respect to is bounded by the KL divergent plus the average of the logarithm of the average of the function with respect to \u03c0. OK, and this side is what we are going to be interested in.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A bit more background, so just to remind you the Markov's inequality.",
                    "label": 0
                },
                {
                    "sent": "So if we have a positive random variable and confidence parameter Delta, then with probability 1 minus Delta, the random variable is bounded by one over Delta times the expectation of the random variable.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And Holdings inequality, which says that if we have a sequence of independent random variables such that each variable belongs to the 01 interval, then for any parameter Lambda the expectation of the exponent of Lambda times the average distance between the variables in their expectations is bounded by the exponent of Lambda Square over 2 * 8 times the number of the variables.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so these are standard in equalities.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And now we put all this together.",
                    "label": 0
                },
                {
                    "sent": "So we start with this change of measure inequality, which says that the average of the function is bounded by the killed versions plus the average of the exponent of the function.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we take this F of H as the quantity of interest.",
                    "label": 0
                },
                {
                    "sent": "So we take it as Lambda times the difference between the expected and the empirical loss for each of the prothesis.",
                    "label": 0
                },
                {
                    "sent": "Now, in order to get the bound, we need to bound this.",
                    "label": 0
                },
                {
                    "sent": "Adam, which is known as Laplace transform.",
                    "label": 0
                },
                {
                    "sent": "So how we bound this term in the inequality?",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we look at this average of the exponent of the function as a random variable Y.",
                    "label": 0
                },
                {
                    "sent": "Is it random variable because the function has the empirical quantity in its definition, so the value of the function is a random variable and the average of the exponent of the function is also a random variable, and we know that the this random variable by micros inequality is bounded by one over Delta times.",
                    "label": 0
                },
                {
                    "sent": "The expectation of this random variable.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "Since we defined by before, we observe the sample, we can exchange the order of the expectation and the DOT product.",
                    "label": 0
                },
                {
                    "sent": "So we can take the expectation inside the DOT product.",
                    "label": 0
                },
                {
                    "sent": "And this is the important point why we should define the prior before we observe the sample.",
                    "label": 0
                },
                {
                    "sent": "If the prior would depend on the sample, we wouldn't be able to change this order.",
                    "label": 0
                },
                {
                    "sent": "And now this this quantity it's.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Actually, what's bounded by Harding's inequality?",
                    "label": 0
                },
                {
                    "sent": "So we get that the expectation of the exponent of the function is bounded by the exponent of Lambda squared over 8 times the size of the sample, and this bound it actually it's independent of the function, so we get just an average of a number.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And it's just this number.",
                    "label": 0
                },
                {
                    "sent": "OK, now.",
                    "label": 0
                },
                {
                    "sent": "The important point about this step of the proof.",
                    "label": 0
                },
                {
                    "sent": "So the first inequality.",
                    "label": 0
                },
                {
                    "sent": "Was valid for any pair of distribution through and \u03c0.",
                    "label": 0
                },
                {
                    "sent": "We fixed one of them before we observed the sample.",
                    "label": 0
                },
                {
                    "sent": "And now.",
                    "label": 0
                },
                {
                    "sent": "We related all possible posterior distributions.",
                    "label": 0
                },
                {
                    "sent": "2A single prior distribution \u03c0.",
                    "label": 0
                },
                {
                    "sent": "And then we bounded this quantity.",
                    "label": 0
                },
                {
                    "sent": "So this quantity depends just on the prior distribution Pi.",
                    "label": 0
                },
                {
                    "sent": "There is no posterior distribution in this.",
                    "label": 0
                },
                {
                    "sent": "Expression and this randomized argument, based on Markov's inequality would do it only once just for this term.",
                    "label": 0
                },
                {
                    "sent": "And therefore we get that this bound holds simultaneously for all posterior distributions with probability 1 minus Delta.",
                    "label": 0
                },
                {
                    "sent": "OK, so once again, the probabilistic argument here, which holds with probability one or greater than one minus Delta.",
                    "label": 0
                },
                {
                    "sent": "We applied only once to this term.",
                    "label": 0
                },
                {
                    "sent": "And this inequality holds for any pair of.",
                    "label": 0
                },
                {
                    "sent": "Pie and Roseau pie is fixed, but we can pick any raw.",
                    "label": 0
                },
                {
                    "sent": "OK, and we have this inequality for all posterior decisions.",
                    "label": 0
                },
                {
                    "sent": "At once.",
                    "label": 0
                },
                {
                    "sent": "And one more point, so we could put pick some other functions F and.",
                    "label": 0
                },
                {
                    "sent": "This expectation of the exponent of the functions, it's generally a common.",
                    "label": 0
                },
                {
                    "sent": "Way to achieve also other.",
                    "label": 0
                },
                {
                    "sent": "Concentration inequality is like banished and inequality and many other inequality's and this is going to be the connection point in the continuation of this talk to other inequality.",
                    "label": 0
                },
                {
                    "sent": "So we are going to have pack based version quality and park based coding.",
                    "label": 0
                },
                {
                    "sent": "Consume inequality for martingales.",
                    "label": 0
                },
                {
                    "sent": "So all of them are connecting at this point where we take expectations of exponents of functions.",
                    "label": 0
                },
                {
                    "sent": "But here we are in the Holdings inequality.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we got that this second term is bounded by log of one over Delta plus Lambda squared, over 8 times the sample size.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then we substitute this bound here and we normalize by Lambda.",
                    "label": 0
                },
                {
                    "sent": "So we get this expression and.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Last step is to do optimization over Lambda.",
                    "label": 0
                },
                {
                    "sent": "It's just something more technical, so I'm skipping it.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "After optimization over Lambda, we get this inequality.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The main ingredients once again it's to start with this change of measure inequality to pick the function F to bound.",
                    "label": 0
                },
                {
                    "sent": "This term and the inequality, and to do some fine at optimization of the parameters and we have the bound.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Any questions?",
                    "label": 0
                },
                {
                    "sent": "OK fine.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the details that are skipped can be found in this paper.",
                    "label": 0
                },
                {
                    "sent": "It says that it's for martingales, but generally you can recover also the details for the individual random variables.",
                    "label": 0
                },
                {
                    "sent": "It's almost the same.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, now I will show you one application of this bound to start with and application is going to be in final domain and to the.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Problem, so the problem that we are looking at we have a matrix of.",
                    "label": 0
                },
                {
                    "sent": "Viewers buy movies and we have the ratings that the viewers give to the movies.",
                    "label": 0
                },
                {
                    "sent": "But of course not all viewers.",
                    "label": 0
                },
                {
                    "sent": "So all the movies so.",
                    "label": 0
                },
                {
                    "sent": "That are all only part of the entries in this matrix that are present and want to complete the missing entries in this matrix.",
                    "label": 0
                },
                {
                    "sent": "And the model that we are going to work with.",
                    "label": 0
                },
                {
                    "sent": "So we will say that the probability of a certain rating given a pair of viewer and movie it's a sum over.",
                    "label": 0
                },
                {
                    "sent": "Possible assignments of viewers to clusters of viewers and movies of two clusters of movies of the probability of assigning the viewer to the cluster of viewers, the movie to the cluster of movies and the probability of observing a certain rating in the cluster product space of movies by viewers.",
                    "label": 0
                },
                {
                    "sent": "Or you can also think about it as this graphical model.",
                    "label": 0
                },
                {
                    "sent": "So the viewers are mapped to clusters of viewers.",
                    "label": 0
                },
                {
                    "sent": "The movies are mapped to clusters of movies.",
                    "label": 0
                },
                {
                    "sent": "And the writing is predicted in this cluster product space of clusters of viewers by clusters of movies.",
                    "label": 0
                },
                {
                    "sent": "And the idea is that the cluster space is much smaller than the original space, so it's much easier to learn in the cluster space.",
                    "label": 0
                },
                {
                    "sent": "We can do it with less samples than doing it on the original space.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in order to apply the pacbase analysis to this problem, first of all we have to define the hypothesis space that we are working with and the hypothesis space that we are going to take our all hard partitions of the space of years by movies.",
                    "label": 0
                },
                {
                    "sent": "And all possible ways to assign labels to this partition space?",
                    "label": 0
                },
                {
                    "sent": "So you should also think that we can make permutations of rows and columns in this matrix when we do the partitioning the prior over the space I will define on the next slide and the important point is that this model actually defines a posterior distribution over this space because we can go through all the.",
                    "label": 0
                },
                {
                    "sent": "Rose and draw a cluster for each viewer according to the first distribution, we can draw a cluster for each movie according to the second distribution.",
                    "label": 0
                },
                {
                    "sent": "We gotta partition and then according to the third distribution we can draw labels to each cluster product cell.",
                    "label": 0
                },
                {
                    "sent": "And we got a hypothesis from this importers class.",
                    "label": 0
                },
                {
                    "sent": "So we can think that there is this randomized selection of the hypothesis that goes behind the scenes of this.",
                    "label": 0
                },
                {
                    "sent": "Classifier.",
                    "label": 0
                },
                {
                    "sent": "OK. Now how we build a?",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Prior over the space.",
                    "label": 0
                },
                {
                    "sent": "So we just count how many ways there are to partition the viewers and movies into the clusters and to assign labels to the cluster product space.",
                    "label": 0
                },
                {
                    "sent": "But we do it in a smart way.",
                    "label": 0
                },
                {
                    "sent": "So first of all, if this is the number of viewers.",
                    "label": 0
                },
                {
                    "sent": "We can choose between.",
                    "label": 0
                },
                {
                    "sent": "One and the number of viewers, clusters of viewers so we can put all the viewers in one cluster.",
                    "label": 0
                },
                {
                    "sent": "We can put every viewer in a separate cluster and we can do all the possibilities in between.",
                    "label": 0
                },
                {
                    "sent": "So there are the number of viewers possibilities to choose the number of clusters.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Once we've chosen the number of clusters, there are at most number of viewers to the power of the number of clusters, minus one possibilities to choose the sizes of the clusters.",
                    "label": 1
                },
                {
                    "sent": "So once again, each cluster maybe between one viewer and all the viewers and the size of the last cluster is determined by the sizes of all other clusters because it just gets what left from the partition.",
                    "label": 0
                },
                {
                    "sent": "So we can choose, for example, a partition to two by two clusters, or we can choose the partitions in to three by one clusters in this example.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Once we have chosen the sizes of the clusters, there is this multinomial coefficient possibilities to assign actually the viewers to the clusters of viewers and movies to the clusters of movies.",
                    "label": 1
                },
                {
                    "sent": "So if we have a balanced partition, we have 4 / 2 or 6 possibilities to assign viewers to the clusters of viewers.",
                    "label": 0
                },
                {
                    "sent": "When the size of each cluster is 2 and we have four unbalanced partitions, four possibilities to assign viewers to the clusters of years when the size of 1 cluster is 3 and the size of the second cluster is 1.",
                    "label": 1
                },
                {
                    "sent": "OK, and the important thing to notice here is that the space of balanced partitions is much larger than the space of unbalanced partitions.",
                    "label": 0
                },
                {
                    "sent": "OK. And.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Once we have chosen the partition, there are the number of labels to the power of number of the number of the partition cells to assign actual labels to this partition cells.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if we put everything together, we get that the prior is lower bounded by the exponent of.",
                    "label": 0
                },
                {
                    "sent": "Of the quantities that's written on the slide.",
                    "label": 0
                },
                {
                    "sent": "K.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now we have to bound the kelda versions between the posterior and prior.",
                    "label": 0
                },
                {
                    "sent": "So this is to remind you that prior to this is the posterior.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And after some calculations we get the KL diversion between the posterior and prior is bounded by the sum over the dimensions of the number of viewers times the mutual information between the viewers and the clusters according to this conditional distribution.",
                    "label": 0
                },
                {
                    "sent": "Plus the number of clusters logarithm of the number of years and.",
                    "label": 0
                },
                {
                    "sent": "The number of the partition cells located of the number of labels.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So more specifically, we can take this joint distribution which is uniform over the viewers because we went in with Santa cluster for each viewer and conditional distribution from the posterior, and we calculate the mutual information according to this.",
                    "label": 0
                },
                {
                    "sent": "Distribution.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And plug it back into the bond and we get that the loss of such prediction strategy is bounded by the empirical loss plus square root of the sum over the dimensions of the number of years times the mutual information between the viewers in the clusters of yours and other terms.",
                    "label": 0
                },
                {
                    "sent": "So what does it give us?",
                    "label": 0
                },
                {
                    "sent": "So if we look into the solution where we put.",
                    "label": 0
                },
                {
                    "sent": "All the viewers and all the movies in one big cluster.",
                    "label": 0
                },
                {
                    "sent": "The mutual information between the viewers and the clusters is zero.",
                    "label": 0
                },
                {
                    "sent": "We put everybody in one big cluster, so we have no information about each individual.",
                    "label": 0
                },
                {
                    "sent": "So in this case.",
                    "label": 0
                },
                {
                    "sent": "This bound term is going to be small because the mutual information is small.",
                    "label": 0
                },
                {
                    "sent": "But we are going to approximate everything with one global average and.",
                    "label": 0
                },
                {
                    "sent": "The empirical loss is going to be large because we are approximately all the entries with one global average.",
                    "label": 0
                },
                {
                    "sent": "But this global average is going to be close to the expected loss, which is the expected loss when we predict the version with one global average and generally the bound says that it's very easy to learn.",
                    "label": 0
                },
                {
                    "sent": "The average rating for this matrix.",
                    "label": 0
                },
                {
                    "sent": "As we go to the other end and we put everybody in a separate cluster, we can achieve 0 empirical loss because we can just predict with the ratings that we have in the corresponding cluster.",
                    "label": 0
                },
                {
                    "sent": "But the mutual information is going to be log of the number of years we preserve all the information about the original entries, so this empirical loss that is 0 is going to be far away from the expected loss of that strategy.",
                    "label": 0
                },
                {
                    "sent": "Becausw the strategy is very complex, it preserves really a lot of information about the.",
                    "label": 0
                },
                {
                    "sent": "Structure of the problem.",
                    "label": 0
                },
                {
                    "sent": "And in between the have this intermediate solutions and.",
                    "label": 0
                },
                {
                    "sent": "The important point is, once again the unbalanced partitions have lower complexity than balanced partitions.",
                    "label": 0
                },
                {
                    "sent": "They're simpler.",
                    "label": 0
                },
                {
                    "sent": "You can think about it that you need less bits in order to describe an unbalanced partitions.",
                    "label": 0
                },
                {
                    "sent": "Then you need in order to describe a balanced partition.",
                    "label": 0
                },
                {
                    "sent": "So generally, if you think about sometimes there is a constraint.",
                    "label": 0
                },
                {
                    "sent": "Putting clustering problems to get balanced clusters.",
                    "label": 0
                },
                {
                    "sent": "So from the generalization POV, that's kind of incorrect bias for a clustering problem cause.",
                    "label": 0
                },
                {
                    "sent": "Once again, unbalanced partitions have better.",
                    "label": 0
                },
                {
                    "sent": "They are simpler, so they have better generalization properties.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "One more comment.",
                    "label": 0
                },
                {
                    "sent": "So there are two types of prior knowledge in this problem, so we used.",
                    "label": 1
                },
                {
                    "sent": "We just counted how many ways there are to partition this space.",
                    "label": 0
                },
                {
                    "sent": "The class status, so we had no information about the actual distribution of the data.",
                    "label": 0
                },
                {
                    "sent": "If there would be some information that would say for example, the two rows are more likely to be together in one cluster.",
                    "label": 0
                },
                {
                    "sent": "We could put this information into the prior and this would break the symmetry between the entry so that the prior that we construct it was just based on the symmetries.",
                    "label": 0
                },
                {
                    "sent": "In the partitions and partition the whole hypata space into subspaces which were in different under permutation of the symmetric under permutation of names of the variables.",
                    "label": 0
                },
                {
                    "sent": "If we have some prior knowledge that breaks the symmetry, we can put it into the prior and then we are going to get a different prior and different CAD versions.",
                    "label": 0
                },
                {
                    "sent": "And that's going to be prior knowledge about the distribution over the data, so we have this structural prior knowledge which exploits the symmetries in the path of space and we may have the distributional prior knowledge, which breaks this structural symmetries and introduces the knowledge about the actual distribution over the data into the analysis and bounds.",
                    "label": 1
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, just briefly to give you one example of an application of this bound to a real problem.",
                    "label": 0
                },
                {
                    "sent": "So we took movie lens data sets.",
                    "label": 0
                },
                {
                    "sent": "There is 100,000 ratings on the five Star scaling.",
                    "label": 1
                },
                {
                    "sent": "And we take 80,000 ratings for training and 20,000 ratings for testing that about 1000 viewers and 1500 movies.",
                    "label": 1
                },
                {
                    "sent": "And at least at the time that we made the experiment, the state of the art mean absolute error there.",
                    "label": 0
                },
                {
                    "sent": "The difference between the predicted number of stars and the actual number of stars was zero point 72, so we're on a 5 star rating scale, so the maximum error is 4 and.",
                    "label": 0
                },
                {
                    "sent": "This is like 0.72 out of four maximal error.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is the bond that we had on the previous slide and we replace it with the parameterized tradeoff.",
                    "label": 0
                },
                {
                    "sent": "This better M times the empirical loss of strategy plus the.",
                    "label": 0
                },
                {
                    "sent": "Number of viewers times the mutual information.",
                    "label": 0
                },
                {
                    "sent": "The number of movies times the mutual information between the.",
                    "label": 0
                },
                {
                    "sent": "Variables in the clusters.",
                    "label": 0
                },
                {
                    "sent": "And we do optimization.",
                    "label": 0
                },
                {
                    "sent": "We do a linear search over better.",
                    "label": 0
                },
                {
                    "sent": "So we solve this problem for several values of beta and we substitute the solution back onto the bound and we calculate what's the bound that we get.",
                    "label": 0
                },
                {
                    "sent": "And the point is that the mutual information has nice convex properties, so it's actually very easy to optimize this and the empirical loss is linear, so it's very easy to optimize this thread of and we just once again do a linear search over beta and check with the bound.",
                    "label": 0
                },
                {
                    "sent": "What's a good solution?",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we start with certain by 6 clusters and what you see here.",
                    "label": 0
                },
                {
                    "sent": "So the bottom line is the test loss and the blue line is the bound that we get.",
                    "label": 0
                },
                {
                    "sent": "So the bound is not very indicative about the.",
                    "label": 0
                },
                {
                    "sent": "Test loss, but it's important to point out that the scale, so here it's one 1.4 and the maximal error is 4, so the bound is meaningful.",
                    "label": 0
                },
                {
                    "sent": "It's not some voidbound that's somewhere in the skies, but we can actually plot the bound and the test error on the same graph.",
                    "label": 0
                },
                {
                    "sent": "Which is quite rare for theoretical analysis.",
                    "label": 0
                },
                {
                    "sent": "Now if we zoom in, so this is a zoom in into this line.",
                    "label": 0
                },
                {
                    "sent": "And this is how better values.",
                    "label": 0
                },
                {
                    "sent": "So we get that for certain values of better we get this optimal zero point 72.",
                    "label": 0
                },
                {
                    "sent": "Error rate.",
                    "label": 0
                },
                {
                    "sent": "With our model.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now we go to the next point.",
                    "label": 0
                },
                {
                    "sent": "We take 50 by 50 clusters and once again we plot the bound and test error and they both are on the same graph and the bound is still meaningful, still less than 4.",
                    "label": 0
                },
                {
                    "sent": "And also here for certain values of better we achieve the optimal performance of zero point 72 even a bit less.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We go to an extreme point, so we take about 300 by 300 clusters and the important point to mention is that at this point the number of clusters cells is equal to the number of data points that we have.",
                    "label": 0
                },
                {
                    "sent": "So generally we can put each data point in a separate cluster cell and try to solve the problem like this.",
                    "label": 0
                },
                {
                    "sent": "And the important point once again, so the bound.",
                    "label": 0
                },
                {
                    "sent": "Well, it's already close to four, but it's still meaningful and we still get the optimal performance even with this huge number of clusters.",
                    "label": 0
                },
                {
                    "sent": "So here the number of clusters provides completely no regularization to the problem, 'cause once again we can put just every point in the separate cluster.",
                    "label": 0
                },
                {
                    "sent": "And all the regularization is done by this mutual information term.",
                    "label": 0
                },
                {
                    "sent": "And this tradeoff between better times, the empirical loss and the mutual information.",
                    "label": 0
                },
                {
                    "sent": "And we see that the mutual information makes a complete control over the.",
                    "label": 0
                },
                {
                    "sent": "Problem over the complexity of the model so we can throw in as many clusters as we want.",
                    "label": 0
                },
                {
                    "sent": "We don't have to know how many clusters there are in the data and the model will filter out the unnecessary clusters and still get to the best possible solution.",
                    "label": 0
                },
                {
                    "sent": "Even with this huge number of clusters.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so the summary of the experiment we achieved this optimal performance even with a huge number of clusters, so this one over better times the mutual information term has a complete control over the model complexity.",
                    "label": 1
                },
                {
                    "sent": "And the bond is still remains meaningful even though it's not.",
                    "label": 0
                },
                {
                    "sent": "Perfectly tight.",
                    "label": 0
                },
                {
                    "sent": "K.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if you want to read a bit more on this problem, we have it in this general our paper and this result can also be generalized to three type graphical models where we can connect more than two variables and we can also generalize it to matrix three factorization.",
                    "label": 0
                },
                {
                    "sent": "So when we very factorize the matrix into left stochastic right so high stick metrics, and what happens in the cluster product space, we can see it as the matrix factorization problem.",
                    "label": 0
                },
                {
                    "sent": "Any questions?",
                    "label": 0
                },
                {
                    "sent": "Before I'm giving the stage to John.",
                    "label": 0
                }
            ]
        }
    }
}