{
    "id": "zzdg6w55gmcazzvp4pqssf4nvjuzenjm",
    "title": "Active Comparison of Prediction Models",
    "info": {
        "author": [
            "Christoph Sawade, Institute of Computer Science, University of Potsdam"
        ],
        "published": "Jan. 14, 2013",
        "recorded": "December 2012",
        "category": [
            "Top->Computer Science->Machine Learning->Unsupervised Learning"
        ]
    },
    "url": "http://videolectures.net/machine_sawade_prediction_models/",
    "segmentation": [
        [
            "If you have situations in which we are given two candidate predictive models and we would like to identify the model with lower risk.",
            "So and the problem here is, we assume that the model cannot compare on Hola training data or by cross validation.",
            "This is the case for example if the models have been acquired off the shelf from third party and no training that are available or if the training data do not reflect the desired test distribution.",
            "In this case we have to label new test instances.",
            "We address the situation scenario in which we are given a pool of unlabeled instances, and we can label instances at a cost.",
            "The standard approach would be to draw instance uniformly from the pool labels these instances and calculate an empirical estimate of the models risk.",
            "Instead, we actively select instances by drawing from an appropriately engineered distribution that highlights differences of the two competing models.",
            "And if."
        ],
        [
            "Since things are drawn from an instrumental distribution rather than from the test distribution, we need a wedding factors to compensate for the discrepancy between the distributions, and then the weighted average over the instance.",
            "Specific losses consistently estimates risk of a given model.",
            "The estimated difference between the models risks provide some evidence on which model is preferable, so in order to choose apparently better model with higher confidence is high confidence, we can apply a statistical test to reject the null hypothesis that the observed difference is due to chance.",
            "However, statistical test is likelihood that we can reject the null hypothesis if the models incur indeed different risks.",
            "And the power is Furthermore a function of the active sampling distribution.",
            "So our goal is to find the instrumental distribution that maximizes test power and thereby minimizes the likelihood of of choosing the inferior model."
        ],
        [
            "OK, in order to derive the optimal sampling distribution we prove lemma stating that for sufficiently large N, the test power is a monotonically decreasing function of the difference estimator variants.",
            "So we have to find the instrumental distribution that minimizes the asymptotical variants of the difference estimator.",
            "We have another lemma which characterizes the asymptotically variance of the difference estimator an.",
            "From this result we can derive the optimal sampling distribution that maximizes test power, but unfortunately this distribution depends on two unknown quantities, namely is a marginal distribution over the instances, and the conditional distribution P of Y given X.",
            "And in a button approve this setting, we can approximate this marginal distribution simply by uniform distribution over the pool.",
            "And in our approach we approximate the conditional distribution by the given given models."
        ],
        [
            "OK, empirically we observed that the active comparison method identifies the model with lower risk more quickly than uniform sampling, and Furthermore the active comparison method chooses the better model with high confidence.",
            "That means it achieves lower P values.",
            "And finally, we also conduct experiments under the null hypothesis and verified that the active comparison methods does not lead to increased false positive significance results.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If you have situations in which we are given two candidate predictive models and we would like to identify the model with lower risk.",
                    "label": 1
                },
                {
                    "sent": "So and the problem here is, we assume that the model cannot compare on Hola training data or by cross validation.",
                    "label": 0
                },
                {
                    "sent": "This is the case for example if the models have been acquired off the shelf from third party and no training that are available or if the training data do not reflect the desired test distribution.",
                    "label": 1
                },
                {
                    "sent": "In this case we have to label new test instances.",
                    "label": 1
                },
                {
                    "sent": "We address the situation scenario in which we are given a pool of unlabeled instances, and we can label instances at a cost.",
                    "label": 0
                },
                {
                    "sent": "The standard approach would be to draw instance uniformly from the pool labels these instances and calculate an empirical estimate of the models risk.",
                    "label": 0
                },
                {
                    "sent": "Instead, we actively select instances by drawing from an appropriately engineered distribution that highlights differences of the two competing models.",
                    "label": 0
                },
                {
                    "sent": "And if.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Since things are drawn from an instrumental distribution rather than from the test distribution, we need a wedding factors to compensate for the discrepancy between the distributions, and then the weighted average over the instance.",
                    "label": 0
                },
                {
                    "sent": "Specific losses consistently estimates risk of a given model.",
                    "label": 0
                },
                {
                    "sent": "The estimated difference between the models risks provide some evidence on which model is preferable, so in order to choose apparently better model with higher confidence is high confidence, we can apply a statistical test to reject the null hypothesis that the observed difference is due to chance.",
                    "label": 0
                },
                {
                    "sent": "However, statistical test is likelihood that we can reject the null hypothesis if the models incur indeed different risks.",
                    "label": 1
                },
                {
                    "sent": "And the power is Furthermore a function of the active sampling distribution.",
                    "label": 0
                },
                {
                    "sent": "So our goal is to find the instrumental distribution that maximizes test power and thereby minimizes the likelihood of of choosing the inferior model.",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, in order to derive the optimal sampling distribution we prove lemma stating that for sufficiently large N, the test power is a monotonically decreasing function of the difference estimator variants.",
                    "label": 1
                },
                {
                    "sent": "So we have to find the instrumental distribution that minimizes the asymptotical variants of the difference estimator.",
                    "label": 0
                },
                {
                    "sent": "We have another lemma which characterizes the asymptotically variance of the difference estimator an.",
                    "label": 0
                },
                {
                    "sent": "From this result we can derive the optimal sampling distribution that maximizes test power, but unfortunately this distribution depends on two unknown quantities, namely is a marginal distribution over the instances, and the conditional distribution P of Y given X.",
                    "label": 0
                },
                {
                    "sent": "And in a button approve this setting, we can approximate this marginal distribution simply by uniform distribution over the pool.",
                    "label": 0
                },
                {
                    "sent": "And in our approach we approximate the conditional distribution by the given given models.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, empirically we observed that the active comparison method identifies the model with lower risk more quickly than uniform sampling, and Furthermore the active comparison method chooses the better model with high confidence.",
                    "label": 1
                },
                {
                    "sent": "That means it achieves lower P values.",
                    "label": 1
                },
                {
                    "sent": "And finally, we also conduct experiments under the null hypothesis and verified that the active comparison methods does not lead to increased false positive significance results.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}