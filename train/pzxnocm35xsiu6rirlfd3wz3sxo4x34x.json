{
    "id": "pzxnocm35xsiu6rirlfd3wz3sxo4x34x",
    "title": "Question Answering over Linked Data",
    "info": {
        "author": [
            "Daniil Sorokin, Ubiquitous Knowledge Processing Lab, Darmstadt University of Technology"
        ],
        "published": "July 10, 2017",
        "recorded": "May 2017",
        "category": [
            "Top->Computer Science->Big Data",
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/eswc2017_sorokin_linked_data/",
    "segmentation": [
        [
            "Welcome everyone, this is the last system for participation in the QLD share task.",
            "We also work on question answering.",
            "We only work with English data, only work with wiki data for now.",
            "This is a very young project and we're excited to be one very much more mature systems.",
            "So we named our work into end representation.",
            "Learning for question answering and weak supervision because we train machine learning system to select.",
            "Generalized questions and retrieve answers and the work.",
            "This is my work, I'm Daniel and vinegar, which is a professor who supervised me enjoy."
        ],
        [
            "So we have very large group of people working on semantic analysis, an NLP group, and this is also the approach that we take in this system.",
            "We try to perform linguistically motivated semantic analysis of input questions to retrieve the answers, but if you're interested in semantic analysis, general and more specifically mapping natural language to formalize meaning representations, you can look for other work from our group, and this is a group photo.",
            "This is me.",
            "This is Professor Rich.",
            "All the rest people you can look at map.",
            "Yeah, this is almost two most important persons.",
            "Of course, an all you can see from here."
        ],
        [
            "So to just briefly introduce you my system, we do perform analysis of question three steps very simple.",
            "First we identify entities in the question.",
            "This is basically what most of the simple most of the systems.",
            "I'm sorry start with.",
            "We do construct a semantic representation for the question.",
            "This is because we are in an old group and that's what we're interested in.",
            "So we construct a formalized representation of what is being asked, and then we use an arrow model to select the correct representation.",
            "Out of all representations that you can construct for a question to give you."
        ],
        [
            "Examples here's the input question what was the first Beatles album?",
            "And this is an example representation of what is being asked in the question.",
            "We have a question variable Q here that represents the answer that would be retrieved later on and then we have the entities and relations that denote.",
            "What is how the entities are connected to the question variable an we have also these are Camino that basically represents aggregation that was already presented here.",
            "We don't have a limit on relations that can be added to the representations, we have aggregation.",
            "We don't support counting yet, and it only works for English for now.",
            "But the main problem is that of course you don't know which relations are expressed in the questions.",
            "Right away you have to basically construct all possible representations with all questions possible for these entities, and then you have to choose one representation that is the correct one, and for that we train a machine learning model that analyzes the possible representations and select the one that matches the question the best, and in order to train that we would need training players of questions and correct representations at.",
            "Fortunately there is no much data or enough data to train reliably machine learning model.",
            "That contains questions and meaning representations formalized this or similar way.",
            "So what we do?"
        ],
        [
            "We say that OK, we don't have representations.",
            "We're going to take the data that has questions and corresponding answers.",
            "So in this case we have a question.",
            "What was the first Beatles album and the answer would be?",
            "Please please me.",
            "You learn a lot.",
            "If you do question answering me, please give me the first album by The Beatles released in 1963 and we take a web questions data set that basically a 3000 round 3000 questions and corresponding pairs.",
            "Responding answers, I'm sorry and we basically construct representations so that we search what kind of representation would give us the specified answer and that would be the representation that we later use for training."
        ],
        [
            "And this is overview of the system that selects the correct representation for the question.",
            "So we have the question here below and then we have basically some possible representations for it, and we use two models, one for the question and one for the representations to basically encode them into vector representations and then we just take the.",
            "Magic representation that has the vector nearest to the question vector that will be the representation that we then use to retrieve the answer.",
            "The representations are basically is amorphic to sparkle queries, so we directly converted to Sparkle query.",
            "You've seen that there are also variables in relations and you can easily convert it into sparkle triples."
        ],
        [
            "Cinco, the question.",
            "We have a network model very beautiful picture spend first time doing that you can see that and more on the poster on Thursday.",
            "I'm not going to go through it now if you're interested there many more of them we ever."
        ],
        [
            "Waited on the wiki data data set, training data set from task four similar to other systems.",
            "Now that we've seen some other performance numbers, so for task four, it's more less comperable.",
            "Also around Zero point, 3% globally we had to throw out some questions so the data set has 100 questions.",
            "We only process AC.",
            "As I said, we don't support sometime types of questions yet."
        ],
        [
            "To finish on a upbeat nodes, this is how the poster looks like.",
            "The promised lots of beautiful diagrams, even more results and other datasets.",
            "So go check it out.",
            "People with other systems go look at it.",
            "Say that you can do is better than as would be glad to hear it.",
            "As I said, we just started working in it and there are definitely a lot of ideas for improvements.",
            "So on Thursday at 9:00 AM I hope to meet you there.",
            "Thank you for the attention."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Welcome everyone, this is the last system for participation in the QLD share task.",
                    "label": 0
                },
                {
                    "sent": "We also work on question answering.",
                    "label": 0
                },
                {
                    "sent": "We only work with English data, only work with wiki data for now.",
                    "label": 0
                },
                {
                    "sent": "This is a very young project and we're excited to be one very much more mature systems.",
                    "label": 0
                },
                {
                    "sent": "So we named our work into end representation.",
                    "label": 0
                },
                {
                    "sent": "Learning for question answering and weak supervision because we train machine learning system to select.",
                    "label": 1
                },
                {
                    "sent": "Generalized questions and retrieve answers and the work.",
                    "label": 0
                },
                {
                    "sent": "This is my work, I'm Daniel and vinegar, which is a professor who supervised me enjoy.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we have very large group of people working on semantic analysis, an NLP group, and this is also the approach that we take in this system.",
                    "label": 0
                },
                {
                    "sent": "We try to perform linguistically motivated semantic analysis of input questions to retrieve the answers, but if you're interested in semantic analysis, general and more specifically mapping natural language to formalize meaning representations, you can look for other work from our group, and this is a group photo.",
                    "label": 0
                },
                {
                    "sent": "This is me.",
                    "label": 0
                },
                {
                    "sent": "This is Professor Rich.",
                    "label": 0
                },
                {
                    "sent": "All the rest people you can look at map.",
                    "label": 0
                },
                {
                    "sent": "Yeah, this is almost two most important persons.",
                    "label": 0
                },
                {
                    "sent": "Of course, an all you can see from here.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to just briefly introduce you my system, we do perform analysis of question three steps very simple.",
                    "label": 0
                },
                {
                    "sent": "First we identify entities in the question.",
                    "label": 0
                },
                {
                    "sent": "This is basically what most of the simple most of the systems.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry start with.",
                    "label": 0
                },
                {
                    "sent": "We do construct a semantic representation for the question.",
                    "label": 1
                },
                {
                    "sent": "This is because we are in an old group and that's what we're interested in.",
                    "label": 0
                },
                {
                    "sent": "So we construct a formalized representation of what is being asked, and then we use an arrow model to select the correct representation.",
                    "label": 1
                },
                {
                    "sent": "Out of all representations that you can construct for a question to give you.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Examples here's the input question what was the first Beatles album?",
                    "label": 1
                },
                {
                    "sent": "And this is an example representation of what is being asked in the question.",
                    "label": 0
                },
                {
                    "sent": "We have a question variable Q here that represents the answer that would be retrieved later on and then we have the entities and relations that denote.",
                    "label": 0
                },
                {
                    "sent": "What is how the entities are connected to the question variable an we have also these are Camino that basically represents aggregation that was already presented here.",
                    "label": 0
                },
                {
                    "sent": "We don't have a limit on relations that can be added to the representations, we have aggregation.",
                    "label": 0
                },
                {
                    "sent": "We don't support counting yet, and it only works for English for now.",
                    "label": 0
                },
                {
                    "sent": "But the main problem is that of course you don't know which relations are expressed in the questions.",
                    "label": 0
                },
                {
                    "sent": "Right away you have to basically construct all possible representations with all questions possible for these entities, and then you have to choose one representation that is the correct one, and for that we train a machine learning model that analyzes the possible representations and select the one that matches the question the best, and in order to train that we would need training players of questions and correct representations at.",
                    "label": 0
                },
                {
                    "sent": "Fortunately there is no much data or enough data to train reliably machine learning model.",
                    "label": 0
                },
                {
                    "sent": "That contains questions and meaning representations formalized this or similar way.",
                    "label": 0
                },
                {
                    "sent": "So what we do?",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We say that OK, we don't have representations.",
                    "label": 0
                },
                {
                    "sent": "We're going to take the data that has questions and corresponding answers.",
                    "label": 0
                },
                {
                    "sent": "So in this case we have a question.",
                    "label": 0
                },
                {
                    "sent": "What was the first Beatles album and the answer would be?",
                    "label": 1
                },
                {
                    "sent": "Please please me.",
                    "label": 0
                },
                {
                    "sent": "You learn a lot.",
                    "label": 0
                },
                {
                    "sent": "If you do question answering me, please give me the first album by The Beatles released in 1963 and we take a web questions data set that basically a 3000 round 3000 questions and corresponding pairs.",
                    "label": 0
                },
                {
                    "sent": "Responding answers, I'm sorry and we basically construct representations so that we search what kind of representation would give us the specified answer and that would be the representation that we later use for training.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is overview of the system that selects the correct representation for the question.",
                    "label": 0
                },
                {
                    "sent": "So we have the question here below and then we have basically some possible representations for it, and we use two models, one for the question and one for the representations to basically encode them into vector representations and then we just take the.",
                    "label": 0
                },
                {
                    "sent": "Magic representation that has the vector nearest to the question vector that will be the representation that we then use to retrieve the answer.",
                    "label": 0
                },
                {
                    "sent": "The representations are basically is amorphic to sparkle queries, so we directly converted to Sparkle query.",
                    "label": 0
                },
                {
                    "sent": "You've seen that there are also variables in relations and you can easily convert it into sparkle triples.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Cinco, the question.",
                    "label": 0
                },
                {
                    "sent": "We have a network model very beautiful picture spend first time doing that you can see that and more on the poster on Thursday.",
                    "label": 1
                },
                {
                    "sent": "I'm not going to go through it now if you're interested there many more of them we ever.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Waited on the wiki data data set, training data set from task four similar to other systems.",
                    "label": 0
                },
                {
                    "sent": "Now that we've seen some other performance numbers, so for task four, it's more less comperable.",
                    "label": 0
                },
                {
                    "sent": "Also around Zero point, 3% globally we had to throw out some questions so the data set has 100 questions.",
                    "label": 0
                },
                {
                    "sent": "We only process AC.",
                    "label": 0
                },
                {
                    "sent": "As I said, we don't support sometime types of questions yet.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To finish on a upbeat nodes, this is how the poster looks like.",
                    "label": 0
                },
                {
                    "sent": "The promised lots of beautiful diagrams, even more results and other datasets.",
                    "label": 0
                },
                {
                    "sent": "So go check it out.",
                    "label": 0
                },
                {
                    "sent": "People with other systems go look at it.",
                    "label": 0
                },
                {
                    "sent": "Say that you can do is better than as would be glad to hear it.",
                    "label": 0
                },
                {
                    "sent": "As I said, we just started working in it and there are definitely a lot of ideas for improvements.",
                    "label": 0
                },
                {
                    "sent": "So on Thursday at 9:00 AM I hope to meet you there.",
                    "label": 0
                },
                {
                    "sent": "Thank you for the attention.",
                    "label": 0
                }
            ]
        }
    }
}