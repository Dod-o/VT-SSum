{
    "id": "u6tapcg4vrquy322yhxnlpl37c6g4fyc",
    "title": "Pattern Classification and Large Margin Classifiers",
    "info": {
        "author": [
            "Peter L. Bartlett, UC Berkeley"
        ],
        "published": "Feb. 25, 2007",
        "recorded": "August 2006",
        "category": [
            "Top->Computer Science->Machine Learning->Pattern Recognition"
        ]
    },
    "url": "http://videolectures.net/mlss06tw_bartlett_pclmc/",
    "segmentation": [
        [
            "And I turned on.",
            "OK, thank you very much.",
            "Thank you for the for the invitation to speak here and for organizing the summer school.",
            "I'm delighted to be here in Taipei.",
            "Um?",
            "So today and tomorrow I'm going to give some lectures on.",
            "Pattern classification theoretical results in pattern classification.",
            "So."
        ],
        [
            "Let me start.",
            "By giving you the overview of.",
            "Uh, the the two days lectures I want to begin with in this lecture.",
            "With a formalization of the pattern classification problem.",
            "So can everybody hear me is this?",
            "Yep.",
            "Great with the formalization of the pattern classification problem.",
            "And some examples of the types of classes of functions that we're dealing with, which will be reviewing, you know, some of the things that you've seen.",
            "I want to make sure we do fix the notation.",
            "And then I'll look at, uh.",
            "A general way of obtaining risk bounds so so performance guarantees for pattern classification methods.",
            "Using something called Rademacher averages.",
            "So that will be in this lecture in the next lecture will look at.",
            "Some aspects of the VC theory that Nick Sherman anchors theory.",
            "And we'll get onto convergence of we're going to."
        ],
        [
            "Properties of large margin classifiers tomorrow.",
            "OK, so.",
            "Let me start by looking at the patent classify."
        ],
        [
            "Nation problem.",
            "And defining the problem.",
            "So here I'm considering.",
            "We will assume always that we have IID data, so we have an X probability distribution P. And this XY pair is distributed according to P. It's a distribution on the product.",
            "SpaceX here is some domain.",
            "This is the space of possible patterns that we can see.",
            "Why is the space of labels?",
            "And we're assuming that the cardinality of why is finite, right?",
            "We're wanting to classify.",
            "Elements of X into one of this many classes, an for most of what I'll talk about.",
            "Over the next two days, the cardinality of Y is going to be just two, right will be looking at the two class case.",
            "So we assume that we see in XY pairs.",
            "Alright, that have the same distribution.",
            "They're independent, and there's a that's the same distribution as that of XY.",
            "And the aim is the aim here is to use this training data.",
            "These XY pairs.",
            "To choose a decision rule.",
            "That is a function.",
            "That Maps from X to Y.",
            "So that the risk of that function is small.",
            "The risk here is the expectation of the loss, right?",
            "So we define some loss function L which tells us how bad it is to make the prediction F of X.",
            "When the true outcome is why?",
            "Am I?",
            "OK, is this better?",
            "So.",
            "At last function L. Measures how bad it is to make a prediction F of X when the true outcome is.",
            "Why?",
            "Alright, so we're interested in the expectation of loss expectation under this random choice of the XY pair, right?",
            "It's distributed according to P. OK, we'll call this the risk.",
            "And for instance, the case that we're typically concerned with here in the.",
            "Binary classification case, in particular this loss function would be the discrete loss to 01 loss, right?",
            "We incur a loss of one when our prediction, yhat is different from the true outcome one."
        ],
        [
            "OK, so some examples.",
            "The space of patterns X might be a mass spectrogram.",
            "The Class Y represents different disease States and we're wanting to use this mass spec data from somebody's blood serum to decide whether they've got prostate cancer.",
            "OK.",
            "So you know, I'm thinking quite abstractly the the domain here is is not necessarily Euclidean space.",
            "Although many of the examples for many of the examples we define, some set of features on this space and then and then look at Euclidean representation in Euclidean space.",
            "Another example character recognition.",
            "So this domain X might be features of some handwritten character and the space of labels wires how we want to.",
            "Classify these these characters right the set of possible characters or X might be some properties of a 3D structure of a candidate drug model molecule and Y represents properties of some property of interest.",
            "So whether that molecule has some acceptable."
        ],
        [
            "Pharmacological properties like receptor binding affinity or something.",
            "OK, so.",
            "The the key issues in in patent classifications of problems of this kind.",
            "Are issues of approximation estimation computation, so the perspective here is we're thinking of F as being chosen from some fixed class capital F. Write some fixed class of functions.",
            "And then having made that restriction alright, we have an approximation.",
            "Question of how well can functions in the class F. Solve this pattern classification problem.",
            "That is, what's the smallest value over all functions in F?",
            "Of the risk, the expectation of the loss incurred when we predict F of S and the outcome F of X and the outcome is why I might have.",
            "Flip the arguments from my earlier definition here.",
            "Alright, so the approximation.",
            "This is a property of our class of functions and the underlying probability distribution on XX by Y. Estimation is this statistical issue that we only get to choose our F or let's call the estimator F hat right using a finite sample.",
            "OK, and so the the expectation of the loss might be rather far from the best that we can do in that plus right, because the only information we have comes from a finite sample.",
            "And of course the computation issue.",
            "We are concerned that we can use the training data to choose a suitable F efficiently.",
            "So these are the three things that that we're going to be concerned with.",
            "So in these talks I'm not going to focus at all on the approximation question.",
            "I'm going to be looking mainly."
        ],
        [
            "The estimation question and to some extent at the computation question.",
            "Alright, so let me say a little bit about the classes of functions F and the pattern classification algorithms that.",
            "Just to give some examples of these, you know there are things here that you've seen in some detail already and things you will see in some detail in these talks.",
            "But as I say, I'd like to."
        ],
        [
            "You know, make sure we.",
            "All clear on the on the notation that I'm using.",
            "When we when we see these examples later.",
            "OK, so let's think about the class of linear threshold functions.",
            "Right here we're thinking of Euclidean space.",
            "So our domain X is just RDD dimensional.",
            "So there D real inputs right where worrying about classification into.",
            "Just two classes.",
            "OK, so from this point on the.",
            "The set Y is has cardinality too.",
            "It's just we'll call it plus or minus one.",
            "The two labels plus minus one and a class of functions here.",
            "Is the the set of linear threshold functions OK?",
            "Functions that map from X to the sign of W, the inner product between W&X for some?",
            "Weight vector W in Rd.",
            "OK, so in two dimensions.",
            "Alright, this is an example of blue represents the plus one."
        ],
        [
            "Plus one region, the decision region.",
            "Um?",
            "OK, in a classical algorithm for linear threshold functions.",
            "The perceptron algorithm.",
            "Um?",
            "Involves updates to the parameters.",
            "Alright, so we can think of that and again this is something that you've.",
            "You've seen already.",
            "We can think of that in terms of the updates here involve only the the linear combinations of the patterns XT.",
            "OK, so we can represent our parameters either in terms of representing function, either in terms of these linear parameters or in terms of coefficients associated with each of the XTS.",
            "OK, so."
        ],
        [
            "Um?",
            "Another example is a class computed by neural networks.",
            "So let's think about sigmoid networks.",
            "Here, the domain X again is D, the class of functions.",
            "These are functions that map from an element of Rd to the sign of some linear combination of nonlinear functions of the inputs.",
            "Those nonlinear functions involve.",
            "Inner products.",
            "Pass through some scalar non linearity.",
            "This this function Sigma.",
            "Ryan, this is typically squashing function.",
            "So for instance, you know we might consider this this kind of function that Maps to.",
            "The interval 01 or some scale version that Maps to minus one one.",
            "Alright, so we have two types of parameters here.",
            "There are the ones that enter non linearly and the ones that are linearly before we take the threshold.",
            "Alright, so."
        ],
        [
            "This is another class we might consider.",
            "The algorithms there typically work by minimizing, so use heuristics to minimize some sort of a smooth criterion, right?",
            "So, for instance, we might worry about the the sample average of the squared difference between the true label Y and the value F of X. Um?",
            "Or the value F before we take before we threshold, so this notation he had here I'm using to.",
            "OK, I've said that in there, using to represent the expectation of the empirical distribution right the sample average."
        ],
        [
            "Of this quantity.",
            "Another example is decision trees, so here.",
            "We could we could consider decision trees where we have these can be represented using a tree.",
            "The nodes of the tree are decisions based on correspond to decisions based on a single axis projection, so again X is D. Alright, we're considering now we can define these things recursively.",
            "We look at.",
            "Decision trees of depth zero is ones that just map to some constant constant value either plus or minus one.",
            "Right and then decision trees of depth.",
            "I plus one correspond to, you know, take a decision tree of depth of two decision trees of depth I and use those to form our decisions and then add a decision node to the top of that so.",
            "Um?",
            "So.",
            "Typically the the class of decisions computed by these nodes might be the class of threshold functions on one on one dimensional projections, where we.",
            "I'm sorry on single axis projections.",
            "Um?",
            "You know this kind of a thing.",
            "Alright, and the."
        ],
        [
            "Algorithms that are typically used here, again, their heuristics to optimize some sort of an empirical criterion.",
            "And they the the standard approach is to grow the decision tree from the root.",
            "Um?",
            "Choosing a leaf of the tree to expand.",
            "And then adding in a decision node at that leaf.",
            "So as to minimize some sort of an empirical criterion, some sort of an error criterion based on the on the training data.",
            "And there are there are various heuristics.",
            "I mean it's it's common to grow to grow a tree completely until the tree correctly classifieds all of the data and then then prune the tree that prune the tree back according to some criterion some empirical criterion again.",
            "OK, will be considering these as examples of basis classes, for instance for.",
            "Methods that."
        ],
        [
            "Combine classifiers.",
            "OK, so let's think about about those voting methods.",
            "So here.",
            "Our class of functions.",
            "These are functions that again there their threshold are linear combinations, but now not of the the components of the vector X, but are functions defined on X functions from some basis class G. OK, so so here we are taking you can think of this as each FT is a member of our committee, right?",
            "FT is some basis function.",
            "Maybe it's a decision tree.",
            "And we're combining those FT's with some real valued weights, and then we're taking the weighted majority decision, OK?",
            "OK, so an example.",
            "That we consider consider later again is is these.",
            "Geez, are very small decision tree.",
            "So decision trees of depth one.",
            "These are.",
            "These are also called decision stumps.",
            "OK, so the class here is.",
            "These are just functions that MAP 2 to two values depending on some linear threshold function on a single single component of the input vector."
        ],
        [
            "Alright, and one class of algorithms for.",
            "Working with this class of functions.",
            "Other boosting algorithms that maintain some sort of a probability distribution over the data and choose the basis functions in order.",
            "In some sequential order, at each step, minimizing.",
            "Some sort of an empirical criterion, and typically this can be expressed just in terms of this.",
            "This weighting function is weighted empirical error.",
            "And the intuition here is that we're adjusting the the distribution over the data so as to emphasize the mistakes that our our.",
            "Our committee, our previous combination has made on the data."
        ],
        [
            "OK. And I guess I don't need to spell out.",
            "The particular approach taken with."
        ],
        [
            "Without a booster.",
            "Um?",
            "Well, let me let me just say that.",
            "Adaboost is 1 approach here, where the weighting is chosen so so as to.",
            "The choice of the weighting corresponds to choosing a function F from the linear span of our basis class so as to minimize the sample average of some exponential.",
            "Exponentially decreasing function of y * F of X. OK, so just.",
            "Intuitively, you know if F of X is this real valued.",
            "Real valued function here WHI is takes values plus or minus one so it seems reasonable that we would be trying to find a small value of this criterion which corresponds to y * F of X being large and positive.",
            "Right, so that means F has the correct sign."
        ],
        [
            "OK, and.",
            "And that's all I'll say for now about about boosting algorithms, kernel methods.",
            "Again, you've seen you've seen this here, we've.",
            "We've got a rather general domain and input SpaceX on, which we define an inner product and come up with a suitable inner product.",
            "I should say and come up with a Hilbert space that is a reproducing kernel Hilbert space.",
            "And the class of functions that we're considering.",
            "We can view SVM's as working with.",
            "A bounded subset of linear functions, right?",
            "So we look at.",
            "Functions that compute just in a product.",
            "Right, but the the functions are bounded.",
            "The RKS norm of the functions is bounded.",
            "Or equivalently, we can parameterise them by an element of our Hobart space and think of the parameter W is having a bounded norm.",
            "And again, just as in the perceptron case, you know the the neat thing about this kind of approach is that even with the general inner product on a complicated space, we can always represent the function implicitly using this dual representation.",
            "By recording just the weights associated with each, just a weight associated with each.",
            "Each of the exercise in our training."
        ],
        [
            "Right in the approach that's used in the typical SVM is to.",
            "We consider that class of functions and we minimize some empirical criterion.",
            "Alright, this is the sample average of a cost function, again involving Y * F of X + a penalty term, so this is a regularization.",
            "Kind of approach, we have a regularised empirical criterion here.",
            "Right and the cost function that we're concerned with, right?",
            "In this case, is a is a piecewise linear function.",
            "It's the hinge loss.",
            "Alright, so."
        ],
        [
            "You Susan tended to give you an overview of the kinds of approaches that I want to consider.",
            "Function classes and algorithms for pattern classification.",
            "Now let's get onto.",
            "Performance guarantees, so getting risk bounds for."
        ],
        [
            "Of this kind.",
            "So that the general approach that I want to use here is the is Rademacher averages.",
            "I'll start by telling you a bit about you know the very idea of risk bounds.",
            "I guess that we want to understand how we should control the complexity of the functions that we have, so it's the best trade off the the competing issues that we face.",
            "These approximation, in particularly approximation estimation issues.",
            "I'm going to introduce some concentration inequality's that tell us how sample averages converge to.",
            "To expectations and how concentrated these things are, I guess a bit more generally than just sample averages were looking at concentration of other of more general random variables about their expectation, and then we'll be using these ideas.",
            "Improving risk bounds using a measure of complexity called Rademacher averages.",
            "So.",
            "Will."
        ],
        [
            "Will get onto those in a moment.",
            "OK, but just first a bit of.",
            "A bit of intuition.",
            "So if we think of this, the framework, as I've outlined that we have a class of functions capital F. And we'd like to choose some function from that class so as to minimize the expectation of the loss or the minimize the risk.",
            "Um?",
            "But we have these competing issues.",
            "If we were to choose a function from a more complex class, then we're going to do better in terms of the approximation properties, right?",
            "The infima over the class that the minimum over the class of the risk for a bigger class is something that will be smaller, but will suffer on the estimation side right?",
            "And more complex class.",
            "We only have information about the class presented to us in the form of these finite set of labeled examples, OK?",
            "So.",
            "The key issue here is trading off these two properties.",
            "The approximation properties in the estimation properties.",
            "So coming up with estimates of the risk in terms of, for instance, the sample size in some measure of the complexity of F tells us how to control the complexity of F. For instance, using some method of sieves, some approach where we say for a given sample size we can work with a class that's this complex and as the sample size grows, we can choose some function from a bigger and bigger class.",
            "Or an approach that's very very closely related is a regularization approach.",
            "For instance, you know control introducing an extra parameter into an empirical criterion.",
            "Such as the the RKS norm regularization parameter in the SBM."
        ],
        [
            "OK, so.",
            "These are two general approaches of controlling controlling complexity.",
            "So let's think now about.",
            "Suppose we have a case where we've got a very rich class.",
            "Capital F and we split it up into some hierarchy, right?",
            "So we're thinking of choosing functions from this class, but it's way too rich to to.",
            "To estimate some function from that class near optimally using a finite sample.",
            "So we split it up.",
            "We come up with some hierarchy.",
            "We represent functions.",
            "We represent this class as a union of of simpler classes.",
            "F1F2 and so on, where for each K what we're going to do is choose the best F sub K in the class capital FK.",
            "OK, and for instance we might do that by minimizing empirical risk.",
            "And then we'll choose.",
            "And if K right, one of these optimal guys so as to minimize the complexity?",
            "Penalized empirical error.",
            "OK, so this is a generic approach that we might take.",
            "You could think of, you could think of this.",
            "Hierarchical representation, for instance, for things like decision trees, K, might my index K might be the restriction on the number of decision nodes in the tree.",
            "Or 4.",
            "The reproducing kernel Hilbert space.",
            "The index K might allow an increase increasing radius of a ball in an arc HS right F sub K would be a subset of all in the dark ages of radius RK.",
            "Where are Kay is increasing with K?",
            "Right, and then we're thinking of.",
            "So here is 1 general approach.",
            "We're thinking of choosing some function from the from this Union so as to minimize.",
            "A sample based estimate of risk.",
            "Plus a penalty term involving the complexity of the case class OK could have written this just as P sub K. OK, so in the Decision Tree case this would be a penalty that increases with the number of nodes in the decision tree.",
            "In the OK chest case, it's a penalty that increases with the radius of the ball in the disk."
        ],
        [
            "Injury alright, so that's that's a kind of method of sieves which with the complexity.",
            "Penalty there a regularization approach.",
            "We could again consider this rich class.",
            "But instead of doing an explicit partition into a union of.",
            "Classes we could minimize directly over this class are complexity penalized empirical error.",
            "Alright, so here we have.",
            "This is a sample average of.",
            "This is a sample based estimate of risk and here we have a penalty term that depends on the function F itself.",
            "Alright, so this might be for instance in the arcade chess example.",
            "This might be something involving the norm of the HS norm of the function F. Well, that's not so different from the method of sieves on the previous slide, right?",
            "If we think about our the decomposition now into the set of functions that have this complexity penalty smaller than some value.",
            "Right that that defines.",
            "So now we can express F as a union of this kind union of classes of this code.",
            "OK, so so coming up with bounds on risk in terms of.",
            "A sample size and various notions of complexity of functions or function classes tell us what is a suitable complexity penalty to introduce here, right, so?",
            "So how we should restrict F when we represented as a union of?",
            "These F sub K or equivalently."
        ],
        [
            "We should regularize.",
            "F functions.",
            "Alright, so the key tool in obtaining these risk bounds that I'm going to be telling you about over the next.",
            "The next couple of days are Rademacher averages.",
            "So this is a.",
            "This is an important definition and it's going to be central to you know what I what I have to say.",
            "Certainly for the rest of today.",
            "Alright, so.",
            "The Rademacher averages are defined.",
            "In this way.",
            "So we use the notation R sub N of of F. This is our function class and this operator is.",
            "Defined as, so we have the supremum over the class of an average of these Sigma rise times F of XI.",
            "Alright, so this is a random variable.",
            "The Sigma rise here are called Rademacher Random variables, so these are IID uniform.",
            "1 + -- 1.",
            "OK, so we're looking here at an inner product between F the excuse me the function F evaluated at each of the endpoints X one through XN in our in our sample.",
            "Write an inner product between that vector of values and this random plus minus one vector right of the Sigma's.",
            "So our end of F is the supremum.",
            "Overall functions in our class of this of this inner product.",
            "So we're saying take a random vector Sigma right?",
            "So first of all, let's fix the sample X one through XN.",
            "Right then taken a random vector Sigma one through Sigma N of plus minus one values.",
            "Now look at how much each F in our class evaluated at X one through XN.",
            "How much that lines up with this random vector?",
            "OK, what's the biggest inner product we can find as F ranges over the class?",
            "What's the biggest inner product we can find between F of X1 through XN and Sigma one through Sigma N?",
            "OK. And this is the value of that biggest inner product.",
            "OK, so it's a random variable.",
            "I guess there are.",
            "There are two things in here.",
            "There's the sample X one through XN, that's random, and there's the Sigma one through Sigma, and those are also random.",
            "OK, so this thing is a random variable.",
            "And we're going to, in fact will see this is tightly concentrated around its expectation, or any any of the conditional expectations that we want to consider.",
            "I totally concentrated around their expectation.",
            "But let's think now just about removing that randomness is considered the expectation of this thing.",
            "It measures how well our class can correlate with the noise vector Sigma.",
            "Right, so you're picking the Sigma is just some random direction, and then we're saying now try and find an F that lines up with that direction.",
            "OK, it's not a uniformly chosen random direction, it's just on the vertices of the plus or minus one cube.",
            "In fact, we could define this thing not in terms of Rademacher averages, but in terms of Gaussians or elements of.",
            "Uniformly over the sphere and you know all of the results that I tell you will change by.",
            "I guess no more than a log factor anywhere, right?",
            "So so you can think about this.",
            "Sigma is just being a random direction.",
            "Right, and we're asking so now.",
            "How much can we line up with that random direction if we line up?",
            "If we can always line up so?",
            "So for essentially all choices of this direction we can.",
            "We can come up with an F that has some nice big value of this inner product, right then, that tells us that we're unlikely to be able to infer very much from from the training data, right?",
            "Because we can get essentially any labels we want any sign we want from our F of X. OK, so that's a bad thing, right from the statistical point of view.",
            "So one other thing, I guess I should point out this is this is a notion of complexity, so that's one way to think of it, right?",
            "We're measuring how complex our classes.",
            "But we're measuring that complexity with respect to the probability distribution that we see the distribution that generates the X is at least.",
            "So the marginal distribution on the X is, and it's also of course, so it depends on on the combination of the probability distribution and the function class F."
        ],
        [
            "OK, so.",
            "So here's a theorem.",
            "That gives us a bound on on the risk of a.",
            "Of a function in some class.",
            "In terms of.",
            "Um?",
            "Sample averages.",
            "Or empirical risks?",
            "I'm going to express it not in, not in terms of risk, so I'm just saying, look, we've got some class of functions that take value in some bounded interval.",
            "And I want to know about expectations compared to sample averages.",
            "OK, so the case to think of is is these functions are loss loss functions right?",
            "The loss incurred on a sequence of XY pairs.",
            "So the empirical loss.",
            "The sample average of the of the loss versus the expectation of the loss or the OR the risk as we've defined it.",
            "OK, that's the case to think of.",
            "So what's the result?",
            "We've got our class G of.",
            "Functions that take values in some interval.",
            "We can say with probability that gets close to one uniformly across this class.",
            "So for every function in the class, expectations are not much bigger than sample averages.",
            "Right?",
            "And how much bigger will?",
            "There's some small small term that depends on you know how close we want this probability to be to one right into this number X. OK, that's like a one over square root of anything that's small.",
            "And then we've got something that's the expectation of these Rademacher averages.",
            "OK, and so when we think about this, G. As being the the discrete loss that we incur for a particular class of plus minus one valued functions.",
            "Alright, we can write the special case down here.",
            "It turns out these two are related.",
            "We'll see in a moment.",
            "We can write that the risk.",
            "Of so uniformly over the class F, the risk of a function F is no more than the sample average for the empirical risk.",
            "Plus some penalty term.",
            "Involving the complexity of the class, the random maker averages.",
            "OK, so.",
            "So we'll have a look at this at why this theorem is true, but but first.",
            "Let me point out a few things.",
            "Let me just reiterate the Rademacher averages.",
            "Here are a property of both the class and the probability distribution, right?",
            "So we're capturing somehow.",
            "How the probability distribution emphasizes or exercises the complexity of the class?",
            "Um?",
            "Later, we'll see that we can come up with estimates of this sort of a quantity in terms of distribution.",
            "Independent notions of complexity, like VC dimension and covering numbers of various other things.",
            "Um?",
            "OK, so.",
            "Let's say a little bit about the proof of this result.",
            "Yeah, great I can't see.",
            "01 yes, class.",
            "Right?",
            "Right so so here I'm this class G is that you should think of as the class of loss functions, right?",
            "So for every so G is defined as the set of.",
            "Let's call the functions L sub F as F ranges over the class capital F where L sub F is the loss function.",
            "The function that Maps from an XY pair to the loss incured when you predict F of X and the outcome is why?",
            "OK?",
            "So these things are the plus minus one valued functions.",
            "We used to predict.",
            "These things are the losses and the domain.",
            "Here is X.",
            "These things are the losses that we incur.",
            "Right when we use a particular function to predict and the domain is X cross Y.",
            "Zero, the loss is bounded between zero and one that's right and down.",
            "Here we're thinking of the special case where the function is.",
            "So so OK.",
            "I guess I didn't say earlier, you know so.",
            "So this the first part of the theorem, here, you know is more general than just the pattern classification kind of setting, but.",
            "When we apply it, you know will always be worrying about loss classes of this.",
            "Well, actually, that's not true for tomorrow, but for today will always be worrying about loss classes for plus minus one value functions.",
            "Um?",
            "So so yeah, this is the the general result is for loss classes, and we're concerned about loss classes of plus minus one value.",
            "Classes.",
            "Are there any other questions?",
            "The previous slide.",
            "Why are Easter Sigma fixed through a research the voice messed up to three an cases?",
            "No.",
            "The the.",
            "The Sigma IR.",
            "IID uniform and plus minus one.",
            "So they are random variables, so this thing is a random variable, right?",
            "So it's a random variable because it depends on the random X one through XN.",
            "And it depends on the random Sigma one through Sigma in.",
            "OK, so we're not doing any optimization over Sigma, we're doing an optimization over the function F. Essentially, you want the random variable from very small.",
            "You don't want to.",
            "This random variable that's right.",
            "That's right, so so if you think about, you know, throw that Supreme away and think about a fixed F. Right then this thing has mean zero, right?",
            "Each sigmai has mean zero and so the expectation without the soup is zero.",
            "OK, so we're doing a maximization, so will always do at least as well as zero.",
            "So this this this thing.",
            "This random variable takes a value that's at least as big as zero.",
            "And the bigger it is, the more that we can find a function in our class to line up with a random vector.",
            "OK, so the richer classes.",
            "Alright, and now when we look at how that appears in the theorem.",
            "It's the theorem tells us that if we've got a class.",
            "A class of functions that take values in some bounded interval.",
            "Um?",
            "Then expectations are uniformly close to sample averages where provided that this notion of complexity is small.",
            "Right, so if we are in the case where you know we're not doing much better than if we throw this Supreme away and we have just a single function, this thing would be 0 right?",
            "If we have a much richer class than that, and the supremum letters line up really well and this is a large value, then the theorem becomes weaker, right?",
            "We get a much bigger quantity here on the right hand side the we can't guarantee that the.",
            "Expectation is not much bigger than the the sample average, and I've written the inequality in One Direction here.",
            "I mean, I could have put absolute values around the difference between the expectation in the sample average and I could.",
            "So.",
            "You know the interval being 01 is not really crucial.",
            "It could be any bounded interval.",
            "So I could consider negative functions negative.",
            "The set of negative G where G comes from G and get the same thing.",
            "So you know, I mean I can get exactly the same inequality but 2 sided.",
            "I guess I'm saying.",
            "Um?",
            "And I should say in everything that I'm that I'm doing, I'm really relying on the fact that we have bounded random variables.",
            "We'll see later that this is this is crucial for the concentration inequality's that we that we need.",
            "I mean, I guess it could be relaxed if you know something about the tales of of certain distributions that will appear, but I don't go into that at all.",
            "And in our case, for binary valued functions, in fact, for everything that we do, you know these tools are powerful enough, we can.",
            "We can always work with bounded loss functions.",
            "OK, so so let's take a look at.",
            "How this theorem is proved?",
            "What we're looking at here?",
            "I guess one crucial thing that maybe I should emphasize again is that we're talking about a a result that's uniform over the class, right?",
            "So with high probability, right?",
            "Every function in our class has expectation sample, average close.",
            "OK, and that means if we choose some function to minimize the empirical risk right, minimize the sample average of the loss.",
            "Then we know that the loss for that function that minimizer is going to be not too big.",
            "OK, so.",
            "You know it's a.",
            "It's a uniform convergence result.",
            "So it it tells us about the uniform deviations between.",
            "Expectations and sample averages.",
            "OK, So what we're really concerned with here.",
            "He's saying, you know, that the probability of the event that the maximum over this class of the difference between these two is big.",
            "That probability should be."
        ],
        [
            "OK, so.",
            "So we are interested in this quantity.",
            "OK, the maximum over our class G of the difference between expectations and sample averages.",
            "OK, and the concentration result that we use for that particular theorem is is a. Gen one.",
            "That's cold, Mcdiarmid's inequality is also known as hurting Azuma and.",
            "There are, there's another name that this case for the moment, but you know this is this is a result that I guess appeared in a paper of or something equivalent in a paper of hurting, you know, a very long time ago.",
            "So this result is a concentration result for bounded random variables.",
            "That tells us that.",
            "That if.",
            "If in particular we have a random variable such as this one that depends on X1 through XN, alright, so this thing is just the maximum over our class of the expectation of sample averages.",
            "OK, that's random, because it's a, it's a function of the random variables X one through XN.",
            "Through this sample average, now Mcdermott's inequality tells us that if we have a function of IID random variables, as we do here.",
            "Right like then?",
            "Um?",
            "Then we get concentration of the of that random variable about its expectation.",
            "Provided that no one of those independent random variables has a big influence.",
            "OK, so how do we formalize that?",
            "So the random variable we're thinking of is this one in our case, but let's think now about, well, OK, so this thing is a function of X1 through XN, and the crucial condition that lets us apply Mcdermott's inequality is that when one of these independent random variables changes, the function that we have can't change by much.",
            "So how do we measure that?",
            "Well, the sample average of GG is a function.",
            "That takes values in the interval 01, right?",
            "So the sample average.",
            "Can't change by any more than 1 / N OK might go from one extreme like 0 at a particular XI GX I might change from zero to 1 if we change that XI.",
            "OK, so the same thing must be true for the supremum.",
            "If we change one of the excise this thing can't change by more than 1 / N and that means that this random variable is concentrated around its expectation.",
            "So precisely the form of Mcdem's inequality is that this random variable is not much bigger than its expectation plus a little bit.",
            "This little bit depends on the the fluctuations that we see when we change one of those random variables.",
            "OK, so this is a very general and nice and easy to apply inequality right?",
            "We just we're talking about a random variable that can be expressed as a function of a bunch of independent random variables.",
            "If we change any one of those.",
            "Does the function change by not too much?",
            "And if that's the case, then the our random variable is is concentrated around its expectation at this kind of level, it depends on the size of the of the fluctuations."
        ],
        [
            "OK, so that's at the heart of the proof.",
            "Alright, so let me state this concentration inequality precisely.",
            "So we have.",
            "In independent random variables, I'll call them X one through XN.",
            "Now, um.",
            "And we have a function that Maps from from some domain X Maps from the space that these.",
            "That these line into to the reels.",
            "Um?",
            "That's this is not true.",
            "This should be a bounded interval in fact.",
            "Um?",
            "Thanks, but no, no this is true.",
            "OK, so it Maps match the reels and then we have that.",
            "Whenever we take any value of X1 through XN an any and any other X NEI Annie XI prime.",
            "OK, so maximizing over all of the arguments of our function.",
            "If we look at how our function G changes when we change X I2, XI prime.",
            "Right?",
            "The the biggest change that we can get is CI.",
            "OK, if we have this condition satisfied, this is the the bounded differences condition.",
            "There's another name for this inequality, the one I forgot about differences in equality.",
            "Then, with high probability, the deviation between our random variable and its expectation is small on the order of the two norm of this vector of these maximal deviations.",
            "OK, so when we apply that in our case our G takes has fluctuations that are of order 1 / N OK, so we get a sum of of N terms.",
            "Of 1 / N ^2 and we get our sqrt X / N. Turn down here.",
            "OK, alright, so that's taking us a step in the right direction.",
            "We've gone away from you know remember we're trying to.",
            "We're trying to show that that expectations are not much bigger than sample averages.",
            "With uniformly across the cloud across the class, we're trying to show that the the supremum.",
            "For over functions of functions G in our class of differences, here is not too big and and what we first shown is that that random variable is not much bigger than its expectation.",
            "OK G. Quality.",
            "There's no condition saying that she has to be bounded.",
            "There's no condition saying that G has to be bounded, we have.",
            "Um?",
            "Right?",
            "So G is bounded here implicitly, so so the point is, we're always looking at differences.",
            "Right and and for any change of the of these variables were getting a small a small change, so GG is necessarily bounded because we were getting no more than a some of these changes to write.",
            "Jeez, not necessarily bounded.",
            "If we subtract some some value of G at some fixed value of X1 through XN.",
            "Right then then so sent, just centering G around 0.",
            "So for some value of X1 through XN this thing is 0.",
            "Then G is bounded by the sum of the CIS.",
            "Alright, and the way that we use the boundedness of G?",
            "So I guess what's confusing here is that there are two different genes floating around.",
            "G means two different things on this slide and on this slide.",
            "OK, so here we have a class of bounded functions.",
            "The fact that they are bounded.",
            "Right means that the sample average can't change by much when we change one of the arguments.",
            "OK, the random variable we're considering to apply Mick Demons inequality is the supremum over G of the expectation minus sample average.",
            "So on this slide in stating Mcdem's inequality, I shouldn't have used G, right?",
            "I should use some other and some other symbol for the random variable, right?",
            "So the random variable we're talking about here?",
            "Is in our case this thing?",
            "Right, so sorry for that was an unfortunate choice of of notation here."
        ],
        [
            "OK.",
            "So I want to say a little bit about why about Mcdermott's inequality.",
            "Um?",
            "And why it's true?",
            "And some of the ingredients of the proof here will will pop up later when we consider the the VC dimension.",
            "OK, so we're looking here at deviations between the function G of these N random variables and the expectation of G. OK.",
            "So I want to express that.",
            "As a sum over a martingale difference sequence.",
            "So I mean we're not using any properties of martingales here, so you don't have to know what they are.",
            "So so we define the initial sequence X one through XI and worry about how the conditional expectation expectation changes as we see the random variable.",
            "Right, so this is our function G. And we consider the how the expectation has increased.",
            "So VI is the increase in the expectation conditioned on seeing X one through XI over what the conditional expectation was when we'd seen X one through X -- 1.",
            "When we condition on just the first time, I just one of these guys alright, then the random variable G minus its expectation is just the sum of these things, right?",
            "This is a telescoping sum, the first one, the expectation of G. Given nothing.",
            "Well, that's this and the last one the expectation of G given X one through XN.",
            "Well that's this.",
            "Right, so we can write it as a sum of these things and now it's a sum of those guys.",
            "That we want to bound the deviations of this thing.",
            "Let's say with high probability this sum is is small.",
            "OK, so you know I went through the steps, but the expectations of these things given the past are all zero.",
            "OK, so this allows us to apply ideas of of."
        ],
        [
            "Sting going back to hurting.",
            "And I'm going to to go through the argument here because.",
            "It's something that we will see we will see later on.",
            "So OK, so we can write the deviation between our random variable and its expectation as the sum of these differences between conditional expectations.",
            "And now here's a trick that pops up again and again, right?",
            "So the probability that this thing is bigger than that thing?",
            "Well, let's take some monotone transformation of those of the two sides.",
            "OK, in particular the monitoring transformation we going to take is the exponential function.",
            "With some positive constant S. OK, so this is bigger than that, precisely when ITA this is bigger than E to that.",
            "Or either the S times this.",
            "OK, and now this is the.",
            "This is something that we can bound using Markov's inequality.",
            "OK so have you.",
            "Does everybody know about Markov's inequality?",
            "If you do, nobody's admitting.",
            "So this is just saying, you know the that the expectation of some non negative random variable right is at least as big as the probability that it's bigger than something divided by that.",
            "Sometimes that's something.",
            "Right so.",
            "So we can get an upper bound on this probability in terms of expectation of this thing times either minus St. OK, this is called the churn off the turnoff.",
            "Bound right.",
            "This is an idea that's used in shernoff bounds, and this trick appears in a lot of places.",
            "Well this thing this is an expectation of E to the S times some some.",
            "OK, that's a moment generating function, right?",
            "We have a random variable here and we're considering the expectation of E to the S times random variable.",
            "OK, who's who's not met moment generating functions before?",
            "If you OK. Of the I mean, this is this is.",
            "Modular sometimes changes the Laplace transform, so for the other electrical engineers.",
            "Among us, it's essentially the same, the same as the Laplace transform.",
            "So what we're concerned with now?",
            "I mean, we can pull this into the minus St out.",
            "We're concerned just with controlling the moment generating function of this random variable.",
            "OK, and we can express that as an expectation of this product.",
            "Our veizer not independent.",
            "You know the things inequality relies on independence of these things.",
            "We have something close to independence because of our.",
            "Well, we have enough properties to to make things work by by conditioning appropriately.",
            "I won't go into the details of that, but you know the whole game from now on is controlling the moment generating function of these of this random variable."
        ],
        [
            "OK, and it turns out.",
            "Um?",
            "OK, yeah, conditioned on something appropriate.",
            "Alright, so if we have a mean zero random variable that lies in a bounded range, right?",
            "This is Hurting's inequality.",
            "OK, hurting first prove something of this form, maybe with a.",
            "And what I think he got a different constant and that was.",
            "Now actually having gotten improve got the right constant so you can show the moment generating function of abounded random variable is bounded in terms of this E to the X ^2.",
            "Kind of a quantity.",
            "OK, and it's the bounded differences property that lets us that lets us argue that the appropriate random variables here are bounded.",
            "OK, so so now we get a bound on our.",
            "Moment generating function in terms of the this variable S squared and in terms of the some of the differences squared, and we just play with the variable S to come up with to come up with a bound on the probability that we get big deviations.",
            "And that's that's the McDermott inequality, right that the probability of the deviation between G and its expectation being large is bounded by this decreasing exponential in T ^2.",
            "Right, so we get some sort of a something that looks like a Gaussian tail, right?",
            "Provided that the.",
            "The random variable G has this bound of differences property.",
            "OK, so that's.",
            "That's where Mcdavid's inequality comes from.",
            "This idea of controlling.",
            "The moment generating function of a abounded random variable is something that will meet again.",
            "Um?",
            "OK, so where are we?"
        ],
        [
            "Alright, so let's make Damon's inequality.",
            "Just remind you were headed for for this.",
            "This result.",
            "All right, that tells us that.",
            "Expectations are not much bigger than sample averages.",
            "And so far we."
        ],
        [
            "I've got that the supremum.",
            "Over the class of the deviations is close to the expectation of that thing, right?",
            "A little bit extra because of that arises from Mcdem's inequality.",
            "So now we just want to control the expectation of this thing.",
            "OK. Alright, so and this is where the Rademacher averages pop up in a very natural way.",
            "Alright, so these these things."
        ],
        [
            "Um, very close to the Rademacher averages.",
            "Alright, so I'm going to write to a string of inequalities and there's really nothing.",
            "Nothing hard here.",
            "The.",
            "Expected maximal deviation between expectations and sample averages.",
            "OK, I want to rewrite that deviation as an expectation.",
            "What have I done?",
            "Given the XI, what have I done?",
            "So I wanted to rewrite this as an expectation of a conditional expectation.",
            "I've I've dropped one here anyway, so so this should be that we can think of this expectation here as being G of XI.",
            "G of XI prime.",
            "Minus the sample average of G. So I'm defining a new ghost sample, right?",
            "If we think of X1 through XN.",
            "As having a having exactly the same distribution being IID with the same distribution as XX One prime through XN prime having the same distribution as XX One through XN.",
            "Alright, then we can.",
            "Then we can rewrite this difference as an expectation of a sample average of G of XI prime right minus.",
            "And this thing is also a sample average.",
            "OK, so now I'm over here.",
            "I'm conditioning on the X1 through XN.",
            "Right?",
            "OK, so that's this is a note this, given the XI means given X one through XN.",
            "This is why I should have written.",
            "Right, and the expectation there is just worrying about.",
            "The X one prime through XN prime.",
            "So now I can take this expectation outside and I get an inequality, right?",
            "But now I have something that looks just like G of XI prime minus G of XI.",
            "OK, So what have I done to this point?",
            "I've replaced the expectation over G here with another sample average.",
            "Write an average over an independent sample X one prime through XN prime.",
            "OK, so now this thing is quite symmetric, right?",
            "These have exactly the same distribution.",
            "They're independent, they have exactly the same distribution.",
            "OK so I could have as easily put G of XI prime minus G of XI or I could have put G of XI minus G of XI prime.",
            "Right?",
            "Both of those things have exactly the same distribution.",
            "And so I can put a sigmai in here.",
            "Right, for any fixed value of Sigma I I haven't changed things because this is just.",
            "Right, the difference between G at some random, at least.",
            "The distribution of this thing is unchanged.",
            "Right, because it's just the difference between G at some random X ING at some other random and independent XI.",
            "OK, so I can throw these Sigma rise in.",
            "The plus or minus ones without without changing anything here.",
            "But now this is looking a lot like Rademacher averages.",
            "Or I've got a minus in there.",
            "Let's split this up into a sum of that one Sigma IG of XI and this one.",
            "G of XR prime in signal, RG of XI and then I have you know that I can write an inequality.",
            "It's no more than the sum of those two right?",
            "The expected supremum of the difference is no more than taking a Supreme over this one in the supremum over that one.",
            "Which is this?",
            "And that's just the random crap images.",
            "OK, so these things arise in quite a natural way.",
            "As soon as we make the observation that the expectation can be written as a sample average over these these.",
            "Independent choices of X1 through XN.",
            "Then the introduction of the Red America random variables changes.",
            "Nothing, has exactly the same distribution and we get this.",
            "OK, we've introduced a constant factor 2 in here through this sort of an upper bound.",
            "Alright, it turns out that that there is a corresponding lower bound, right that the expectation of the maximal deviations between these two is.",
            "At least as big as some constant times.",
            "The Rademacher averages OK, so all we're giving away in these inequalities is maybe a constant factor.",
            "Right, so in measuring, I mean I don't state this explicitly in here, but in measuring maximal deviations between expectations and sample averages, the Rademacher averages captured that precisely within a constant factor."
        ],
        [
            "OK, so.",
            "I mean, there was one more thing that you know this.",
            "This tells us that that gives us this result right?",
            "The maximum over G of the deviation between expectation and sample averages is no more than this thing.",
            "Right twice the expectation that marriage is plus a little bit that arises from the Mcdem inequality.",
            "To see the second part, or we're doing down here is applying this for the class of loss functions.",
            "OK, so when we consider the expectation of G, we're worrying about the risk right?",
            "The expected loss for some F. The sample average is the sample average of the loss, so all we really need to do to go from here to here.",
            "Is argue that the Rademacher averages for the class of loss functions is no bigger than the Rademacher averages for the original class.",
            "Write the class of plus minus one valued functions.",
            "OK, so so let's think for the discrete loss.",
            "These are the functions we're considering.",
            "The loss incurred by predicting F of X when the real outcome is Y. OK so I can write the Rademacher averages.",
            "This is just the definition.",
            "Right, the expectation of the supremum of Sigma.",
            "How much the loss vector lines up with Sigma I I I'm going to write this discrete losses, the indicator of.",
            "Alright, so this is the function that takes value one when Y is not equal to F of XI and 0 otherwise.",
            "That's the definition of the loss.",
            "Of the discrete loss, the 01 loss.",
            "OK, but I can rewrite this.",
            "This thing has a half of 1 -- y. I times F of XI.",
            "OK, because when Y is equal to F of XI write this thing is 0 just as it should be.",
            "When iy is different from ffxi?",
            "Alright this thing is minus one and we get to hear divided by two is 1 just as it should be right?",
            "So I haven't changed anything.",
            "I've just rewritten in a linear way but now when it's linear I can throw away this term right?",
            "It doesn't depend on FI just have an expectation of the Sigma rise.",
            "Where they plus minus one uniform, so the expectation is zero that that term disappears and we get the expectation of the supremum of Sigma right times why I times F of XI.",
            "Alright.",
            "Well, if Sigma Rai is uniform plus minus one, what distribution does Sigma I times why I have for any why I?",
            "It's exactly the same distribution, right?",
            "It's uniform plus minus one, so this thing is just the Rademacher averages divided by two.",
            "OK, so in the case of discrete loss, the random ravages of the last class are equal to the Rademacher averages of the original class modular.",
            "This constant half."
        ],
        [
            "Alright, and that gives us.",
            "I don't know if I put it there OK. And that gives us this.",
            "This result.",
            "OK, so we think of this was the second part of the theorem before.",
            "If we think of this class of plus minus one valued functions.",
            "And we have discrete loss.",
            "The 01 loss then with high probability that rapidly approaches one the.",
            "Sorry, let me go back to the original theorem statement.",
            "So this part.",
            "The second part here is a slight refinement on that.",
            "Next next slide, the second part.",
            "Here is what we've just proved right for a class of plus minus one value functions and the 01 loss with probability that rapidly approaches one.",
            "Every function has risk, not much more than empirical risk plus Rademacher averages, plus some little thing.",
            "OK, that's what we just showed that the Rademacher averages of the discrete last class are the same as the Rainmaker averages of this class, modulo the constant 2.",
            "OK, one thing I guess I should point out before we go on to the next theorem.",
            "This term here the the 1 / sqrt N term.",
            "That's always small alright.",
            "Rather, the writer maker averages here.",
            "If you have a class that contains just the constant one in the constant minus one function.",
            "Right then, then the Rademacher averages are of order 1 / sqrt N. OK, so this is this is just like equivalently, if you look at the definition of.",
            "Of the Rademacher averages.",
            "Which I've thrown away.",
            "So if this class contains the constant plus one constant minus one, that's just like taking the absolute value here, right?",
            "The supremum over those plus or minus one guys is just the absolute value of the average of the Sigma rise.",
            "OK, well that's of order 1 / sqrt N. OK. Because the variance grows linearly within.",
            "So this term is this second term is.",
            "Is is always dominated by the Rademacher averages, unless we have a particularly simple class.",
            "I should say for any fixed classes dominated by the Rainmaker averages.",
            "OK, so a refinement of that result.",
            "Here is that so same setup we've got a Class A + -- 1 valued functions.",
            "Now we're saying we're considering just the minimizer of the empirical risk.",
            "OK, so let's say we fix our class of functions F. Maybe it's decision trees of a certain size, then.",
            "Then if we minimize the empirical risk over that class.",
            "So find the F, let's call it F hat that makes the smallest number of mistakes on the on the sample.",
            "Then we can.",
            "We can argue using that previous result that the risk of that minimizer, right?",
            "The probability that it makes a mistake.",
            "The expectation of this of this 01 loss is no more than the minimum over our class of functions of the risk.",
            "So this is the best we could hope for.",
            "We call this the approximation error before, right?",
            "Well, this is.",
            "This is something something like an approximation property of that class is the best we could hope for, given that we're choosing functions from that class capital F. Plus a penalty term of the same size as before.",
            "Slightly different constant.",
            "Alright, so so this so so.",
            "The picture of why this follows from the previous result is that we've shown that the expectations and sample averages close to each other uniformly across the class.",
            "Alright, so the empirical minimizer has its expectation close to the sample average.",
            "The optimal function, the one that minimizes this quantity, the probability of misclassification.",
            "Also has his expectation close to the sample average.",
            "Right, if those two are uniformly close, then when we go from one to the other, we can't be too far.",
            "Can't be too far away, right?",
            "The expectation can't be too far away from the the.",
            "The expectation for the minimizer, the minimal expectation expectation of the empirical minimizer is can't be much bigger than the minimizer expectation.",
            "OK, so so OK, let's suppose that this in film is realized that F star.",
            "This is the best function in our class, the one that minimizes the probability of misclassification.",
            "But the risk then that function in particular has empirical.",
            "Empirical risk close to risk.",
            "Right, but its empirical risk is necessarily worse than the minimizer of the empirical risk.",
            "Right, we were choosing F hat to minimize the sample average.",
            "Well, the optimal guy must have a bigger sample, a sample every average.",
            "That's at least as big.",
            "OK, but now we know that the sample average for this guy is close to his expectation.",
            "OK, this is a single function, you know I don't even need to worry about Rademacher averages here, right?",
            "I can?",
            "I know the deviations between these two through her things inequality says of order 1 / sqrt N. Alright, so that tells us that you know for the particular function F hat, we know it's from.",
            "The previous result is expectation is not much bigger than its sample average.",
            "Well, that sample averages not much bigger than the best expectation.",
            "OK, so we get we get this result immediately.",
            "Alright, so that's an example of an application of these Rademacher averages.",
            "In getting bounds on the risk of a particular choice of function from our class.",
            "If we choose F hat, the function that minimizes the empirical risk, then it's risk is close to the best we could have hoped for, given that we're choosing functions from F, how close will it depends on the complexity of F as measured by these Rademacher averages.",
            "OK, so once again if we go back to think about the definition, the Rademacher averages tell us how much functions in the class line up with this random random direction, right?",
            "If they barely line up at all.",
            "Right then it's hard to fit to that noise, right?",
            "It's hard to pick a function that fits to the noise vector.",
            "That's good.",
            "We'll get our risk close to the optimal risk, right?",
            "The deviation term here is going to be small.",
            "If, on the other hand, we can always have these things lining up, then we might have a you know Rademacher averages, like some constant right.",
            "Or you know, big as big as some constant as a function of N. Then the risk of the empirical minimizer.",
            "We have a rather poor guarantee, right?",
            "We could be, we could be some constant away from the best in the class in that case.",
            "OK."
        ],
        [
            "So.",
            "One other observation, before I before I stop that that we can compute in the.",
            "In the case of the 01 loss, we can compute Rademacher averages.",
            "This is an interesting observation about the computation of these things.",
            "The reader maker average is the is the maximum over the class of this thing.",
            "Well, I can write that as the negative of the minimum alright, and then again, using this observation that these are plus minus one and the Zephyr plus minus one, right?",
            "I can rewrite this product in terms of a.",
            "So.",
            "Oh, I'm sorry.",
            "I'm not doing that just yet, so.",
            "The minimum of this thing I can throw in an extra an extra 1 here and an extra 1 there.",
            "Right?",
            "And then I write this thing as the loss, right?",
            "Because remember, we saw this earlier that that we can rewrite the loss of F of XI at.",
            "At some Yi in terms of a linear, a linear.",
            "Expression of this kind.",
            "OK, so you can see this by case by case analysis.",
            "Thinking of Sigma Rye negative signal having the same sign as F of XI and a different sign.",
            "OK, So what we get at the end is the rental car averages are equal to.",
            "1 minus the minimum over air or I guess I should say infime over F well, F is is finally here.",
            "If takes only plus minus one value, so there are finitely many values of this thing, so the firms achieve 1 minus the minimum over F of.",
            "An empirical risk kind of a quantity, right?",
            "We're looking at finding an F to minimize the empirical risk.",
            "When we consider the wise as being these minus Sigma eyes, right?",
            "So we're trying to line up with.",
            "The minus Sigma rise.",
            "So computing the Rademacher averages is equivalent to minimizing empirical error on the randomly labeled data we take all of our X one through XN and throw in a random plus minus one label, and then try and optimize that.",
            "OK, so later on we'll look at relationships between this notion of complexity, their own maker averages an other notions, so the VC dimension is not something that depends on the probability distribution that generated the the X is, but we can get upper bounds on the Rademacher averages in terms of the."
        ],
        [
            "I am PC dimension.",
            "Alright, so I'll stop.",
            "I'll stop there.",
            "I'm a little late, I'm sorry.",
            "Are there any questions?",
            "Should go directly to coffee.",
            "So we'll have a copy."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And I turned on.",
                    "label": 0
                },
                {
                    "sent": "OK, thank you very much.",
                    "label": 0
                },
                {
                    "sent": "Thank you for the for the invitation to speak here and for organizing the summer school.",
                    "label": 0
                },
                {
                    "sent": "I'm delighted to be here in Taipei.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So today and tomorrow I'm going to give some lectures on.",
                    "label": 0
                },
                {
                    "sent": "Pattern classification theoretical results in pattern classification.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let me start.",
                    "label": 0
                },
                {
                    "sent": "By giving you the overview of.",
                    "label": 0
                },
                {
                    "sent": "Uh, the the two days lectures I want to begin with in this lecture.",
                    "label": 0
                },
                {
                    "sent": "With a formalization of the pattern classification problem.",
                    "label": 1
                },
                {
                    "sent": "So can everybody hear me is this?",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "Great with the formalization of the pattern classification problem.",
                    "label": 0
                },
                {
                    "sent": "And some examples of the types of classes of functions that we're dealing with, which will be reviewing, you know, some of the things that you've seen.",
                    "label": 0
                },
                {
                    "sent": "I want to make sure we do fix the notation.",
                    "label": 0
                },
                {
                    "sent": "And then I'll look at, uh.",
                    "label": 0
                },
                {
                    "sent": "A general way of obtaining risk bounds so so performance guarantees for pattern classification methods.",
                    "label": 1
                },
                {
                    "sent": "Using something called Rademacher averages.",
                    "label": 0
                },
                {
                    "sent": "So that will be in this lecture in the next lecture will look at.",
                    "label": 0
                },
                {
                    "sent": "Some aspects of the VC theory that Nick Sherman anchors theory.",
                    "label": 0
                },
                {
                    "sent": "And we'll get onto convergence of we're going to.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Properties of large margin classifiers tomorrow.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Let me start by looking at the patent classify.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Nation problem.",
                    "label": 0
                },
                {
                    "sent": "And defining the problem.",
                    "label": 0
                },
                {
                    "sent": "So here I'm considering.",
                    "label": 0
                },
                {
                    "sent": "We will assume always that we have IID data, so we have an X probability distribution P. And this XY pair is distributed according to P. It's a distribution on the product.",
                    "label": 0
                },
                {
                    "sent": "SpaceX here is some domain.",
                    "label": 0
                },
                {
                    "sent": "This is the space of possible patterns that we can see.",
                    "label": 0
                },
                {
                    "sent": "Why is the space of labels?",
                    "label": 0
                },
                {
                    "sent": "And we're assuming that the cardinality of why is finite, right?",
                    "label": 0
                },
                {
                    "sent": "We're wanting to classify.",
                    "label": 0
                },
                {
                    "sent": "Elements of X into one of this many classes, an for most of what I'll talk about.",
                    "label": 0
                },
                {
                    "sent": "Over the next two days, the cardinality of Y is going to be just two, right will be looking at the two class case.",
                    "label": 0
                },
                {
                    "sent": "So we assume that we see in XY pairs.",
                    "label": 0
                },
                {
                    "sent": "Alright, that have the same distribution.",
                    "label": 0
                },
                {
                    "sent": "They're independent, and there's a that's the same distribution as that of XY.",
                    "label": 0
                },
                {
                    "sent": "And the aim is the aim here is to use this training data.",
                    "label": 1
                },
                {
                    "sent": "These XY pairs.",
                    "label": 0
                },
                {
                    "sent": "To choose a decision rule.",
                    "label": 1
                },
                {
                    "sent": "That is a function.",
                    "label": 1
                },
                {
                    "sent": "That Maps from X to Y.",
                    "label": 0
                },
                {
                    "sent": "So that the risk of that function is small.",
                    "label": 0
                },
                {
                    "sent": "The risk here is the expectation of the loss, right?",
                    "label": 0
                },
                {
                    "sent": "So we define some loss function L which tells us how bad it is to make the prediction F of X.",
                    "label": 0
                },
                {
                    "sent": "When the true outcome is why?",
                    "label": 0
                },
                {
                    "sent": "Am I?",
                    "label": 0
                },
                {
                    "sent": "OK, is this better?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "At last function L. Measures how bad it is to make a prediction F of X when the true outcome is.",
                    "label": 0
                },
                {
                    "sent": "Why?",
                    "label": 0
                },
                {
                    "sent": "Alright, so we're interested in the expectation of loss expectation under this random choice of the XY pair, right?",
                    "label": 0
                },
                {
                    "sent": "It's distributed according to P. OK, we'll call this the risk.",
                    "label": 1
                },
                {
                    "sent": "And for instance, the case that we're typically concerned with here in the.",
                    "label": 0
                },
                {
                    "sent": "Binary classification case, in particular this loss function would be the discrete loss to 01 loss, right?",
                    "label": 0
                },
                {
                    "sent": "We incur a loss of one when our prediction, yhat is different from the true outcome one.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so some examples.",
                    "label": 0
                },
                {
                    "sent": "The space of patterns X might be a mass spectrogram.",
                    "label": 0
                },
                {
                    "sent": "The Class Y represents different disease States and we're wanting to use this mass spec data from somebody's blood serum to decide whether they've got prostate cancer.",
                    "label": 1
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So you know, I'm thinking quite abstractly the the domain here is is not necessarily Euclidean space.",
                    "label": 0
                },
                {
                    "sent": "Although many of the examples for many of the examples we define, some set of features on this space and then and then look at Euclidean representation in Euclidean space.",
                    "label": 0
                },
                {
                    "sent": "Another example character recognition.",
                    "label": 0
                },
                {
                    "sent": "So this domain X might be features of some handwritten character and the space of labels wires how we want to.",
                    "label": 0
                },
                {
                    "sent": "Classify these these characters right the set of possible characters or X might be some properties of a 3D structure of a candidate drug model molecule and Y represents properties of some property of interest.",
                    "label": 1
                },
                {
                    "sent": "So whether that molecule has some acceptable.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Pharmacological properties like receptor binding affinity or something.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "The the key issues in in patent classifications of problems of this kind.",
                    "label": 0
                },
                {
                    "sent": "Are issues of approximation estimation computation, so the perspective here is we're thinking of F as being chosen from some fixed class capital F. Write some fixed class of functions.",
                    "label": 0
                },
                {
                    "sent": "And then having made that restriction alright, we have an approximation.",
                    "label": 0
                },
                {
                    "sent": "Question of how well can functions in the class F. Solve this pattern classification problem.",
                    "label": 0
                },
                {
                    "sent": "That is, what's the smallest value over all functions in F?",
                    "label": 0
                },
                {
                    "sent": "Of the risk, the expectation of the loss incurred when we predict F of S and the outcome F of X and the outcome is why I might have.",
                    "label": 0
                },
                {
                    "sent": "Flip the arguments from my earlier definition here.",
                    "label": 0
                },
                {
                    "sent": "Alright, so the approximation.",
                    "label": 0
                },
                {
                    "sent": "This is a property of our class of functions and the underlying probability distribution on XX by Y. Estimation is this statistical issue that we only get to choose our F or let's call the estimator F hat right using a finite sample.",
                    "label": 0
                },
                {
                    "sent": "OK, and so the the expectation of the loss might be rather far from the best that we can do in that plus right, because the only information we have comes from a finite sample.",
                    "label": 0
                },
                {
                    "sent": "And of course the computation issue.",
                    "label": 0
                },
                {
                    "sent": "We are concerned that we can use the training data to choose a suitable F efficiently.",
                    "label": 1
                },
                {
                    "sent": "So these are the three things that that we're going to be concerned with.",
                    "label": 0
                },
                {
                    "sent": "So in these talks I'm not going to focus at all on the approximation question.",
                    "label": 0
                },
                {
                    "sent": "I'm going to be looking mainly.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The estimation question and to some extent at the computation question.",
                    "label": 0
                },
                {
                    "sent": "Alright, so let me say a little bit about the classes of functions F and the pattern classification algorithms that.",
                    "label": 1
                },
                {
                    "sent": "Just to give some examples of these, you know there are things here that you've seen in some detail already and things you will see in some detail in these talks.",
                    "label": 0
                },
                {
                    "sent": "But as I say, I'd like to.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You know, make sure we.",
                    "label": 0
                },
                {
                    "sent": "All clear on the on the notation that I'm using.",
                    "label": 0
                },
                {
                    "sent": "When we when we see these examples later.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's think about the class of linear threshold functions.",
                    "label": 0
                },
                {
                    "sent": "Right here we're thinking of Euclidean space.",
                    "label": 0
                },
                {
                    "sent": "So our domain X is just RDD dimensional.",
                    "label": 0
                },
                {
                    "sent": "So there D real inputs right where worrying about classification into.",
                    "label": 0
                },
                {
                    "sent": "Just two classes.",
                    "label": 0
                },
                {
                    "sent": "OK, so from this point on the.",
                    "label": 0
                },
                {
                    "sent": "The set Y is has cardinality too.",
                    "label": 0
                },
                {
                    "sent": "It's just we'll call it plus or minus one.",
                    "label": 0
                },
                {
                    "sent": "The two labels plus minus one and a class of functions here.",
                    "label": 0
                },
                {
                    "sent": "Is the the set of linear threshold functions OK?",
                    "label": 1
                },
                {
                    "sent": "Functions that map from X to the sign of W, the inner product between W&X for some?",
                    "label": 0
                },
                {
                    "sent": "Weight vector W in Rd.",
                    "label": 0
                },
                {
                    "sent": "OK, so in two dimensions.",
                    "label": 0
                },
                {
                    "sent": "Alright, this is an example of blue represents the plus one.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Plus one region, the decision region.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "OK, in a classical algorithm for linear threshold functions.",
                    "label": 1
                },
                {
                    "sent": "The perceptron algorithm.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Involves updates to the parameters.",
                    "label": 1
                },
                {
                    "sent": "Alright, so we can think of that and again this is something that you've.",
                    "label": 0
                },
                {
                    "sent": "You've seen already.",
                    "label": 0
                },
                {
                    "sent": "We can think of that in terms of the updates here involve only the the linear combinations of the patterns XT.",
                    "label": 0
                },
                {
                    "sent": "OK, so we can represent our parameters either in terms of representing function, either in terms of these linear parameters or in terms of coefficients associated with each of the XTS.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Another example is a class computed by neural networks.",
                    "label": 1
                },
                {
                    "sent": "So let's think about sigmoid networks.",
                    "label": 0
                },
                {
                    "sent": "Here, the domain X again is D, the class of functions.",
                    "label": 0
                },
                {
                    "sent": "These are functions that map from an element of Rd to the sign of some linear combination of nonlinear functions of the inputs.",
                    "label": 0
                },
                {
                    "sent": "Those nonlinear functions involve.",
                    "label": 0
                },
                {
                    "sent": "Inner products.",
                    "label": 0
                },
                {
                    "sent": "Pass through some scalar non linearity.",
                    "label": 0
                },
                {
                    "sent": "This this function Sigma.",
                    "label": 1
                },
                {
                    "sent": "Ryan, this is typically squashing function.",
                    "label": 0
                },
                {
                    "sent": "So for instance, you know we might consider this this kind of function that Maps to.",
                    "label": 0
                },
                {
                    "sent": "The interval 01 or some scale version that Maps to minus one one.",
                    "label": 0
                },
                {
                    "sent": "Alright, so we have two types of parameters here.",
                    "label": 0
                },
                {
                    "sent": "There are the ones that enter non linearly and the ones that are linearly before we take the threshold.",
                    "label": 0
                },
                {
                    "sent": "Alright, so.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is another class we might consider.",
                    "label": 0
                },
                {
                    "sent": "The algorithms there typically work by minimizing, so use heuristics to minimize some sort of a smooth criterion, right?",
                    "label": 1
                },
                {
                    "sent": "So, for instance, we might worry about the the sample average of the squared difference between the true label Y and the value F of X. Um?",
                    "label": 0
                },
                {
                    "sent": "Or the value F before we take before we threshold, so this notation he had here I'm using to.",
                    "label": 1
                },
                {
                    "sent": "OK, I've said that in there, using to represent the expectation of the empirical distribution right the sample average.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Of this quantity.",
                    "label": 0
                },
                {
                    "sent": "Another example is decision trees, so here.",
                    "label": 1
                },
                {
                    "sent": "We could we could consider decision trees where we have these can be represented using a tree.",
                    "label": 0
                },
                {
                    "sent": "The nodes of the tree are decisions based on correspond to decisions based on a single axis projection, so again X is D. Alright, we're considering now we can define these things recursively.",
                    "label": 0
                },
                {
                    "sent": "We look at.",
                    "label": 0
                },
                {
                    "sent": "Decision trees of depth zero is ones that just map to some constant constant value either plus or minus one.",
                    "label": 0
                },
                {
                    "sent": "Right and then decision trees of depth.",
                    "label": 1
                },
                {
                    "sent": "I plus one correspond to, you know, take a decision tree of depth of two decision trees of depth I and use those to form our decisions and then add a decision node to the top of that so.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Typically the the class of decisions computed by these nodes might be the class of threshold functions on one on one dimensional projections, where we.",
                    "label": 1
                },
                {
                    "sent": "I'm sorry on single axis projections.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "You know this kind of a thing.",
                    "label": 0
                },
                {
                    "sent": "Alright, and the.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Algorithms that are typically used here, again, their heuristics to optimize some sort of an empirical criterion.",
                    "label": 0
                },
                {
                    "sent": "And they the the standard approach is to grow the decision tree from the root.",
                    "label": 1
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Choosing a leaf of the tree to expand.",
                    "label": 0
                },
                {
                    "sent": "And then adding in a decision node at that leaf.",
                    "label": 1
                },
                {
                    "sent": "So as to minimize some sort of an empirical criterion, some sort of an error criterion based on the on the training data.",
                    "label": 0
                },
                {
                    "sent": "And there are there are various heuristics.",
                    "label": 0
                },
                {
                    "sent": "I mean it's it's common to grow to grow a tree completely until the tree correctly classifieds all of the data and then then prune the tree that prune the tree back according to some criterion some empirical criterion again.",
                    "label": 0
                },
                {
                    "sent": "OK, will be considering these as examples of basis classes, for instance for.",
                    "label": 0
                },
                {
                    "sent": "Methods that.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Combine classifiers.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's think about about those voting methods.",
                    "label": 1
                },
                {
                    "sent": "So here.",
                    "label": 0
                },
                {
                    "sent": "Our class of functions.",
                    "label": 0
                },
                {
                    "sent": "These are functions that again there their threshold are linear combinations, but now not of the the components of the vector X, but are functions defined on X functions from some basis class G. OK, so so here we are taking you can think of this as each FT is a member of our committee, right?",
                    "label": 0
                },
                {
                    "sent": "FT is some basis function.",
                    "label": 0
                },
                {
                    "sent": "Maybe it's a decision tree.",
                    "label": 0
                },
                {
                    "sent": "And we're combining those FT's with some real valued weights, and then we're taking the weighted majority decision, OK?",
                    "label": 0
                },
                {
                    "sent": "OK, so an example.",
                    "label": 0
                },
                {
                    "sent": "That we consider consider later again is is these.",
                    "label": 0
                },
                {
                    "sent": "Geez, are very small decision tree.",
                    "label": 0
                },
                {
                    "sent": "So decision trees of depth one.",
                    "label": 1
                },
                {
                    "sent": "These are.",
                    "label": 1
                },
                {
                    "sent": "These are also called decision stumps.",
                    "label": 0
                },
                {
                    "sent": "OK, so the class here is.",
                    "label": 0
                },
                {
                    "sent": "These are just functions that MAP 2 to two values depending on some linear threshold function on a single single component of the input vector.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, and one class of algorithms for.",
                    "label": 0
                },
                {
                    "sent": "Working with this class of functions.",
                    "label": 0
                },
                {
                    "sent": "Other boosting algorithms that maintain some sort of a probability distribution over the data and choose the basis functions in order.",
                    "label": 1
                },
                {
                    "sent": "In some sequential order, at each step, minimizing.",
                    "label": 1
                },
                {
                    "sent": "Some sort of an empirical criterion, and typically this can be expressed just in terms of this.",
                    "label": 1
                },
                {
                    "sent": "This weighting function is weighted empirical error.",
                    "label": 0
                },
                {
                    "sent": "And the intuition here is that we're adjusting the the distribution over the data so as to emphasize the mistakes that our our.",
                    "label": 0
                },
                {
                    "sent": "Our committee, our previous combination has made on the data.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK. And I guess I don't need to spell out.",
                    "label": 0
                },
                {
                    "sent": "The particular approach taken with.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Without a booster.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Well, let me let me just say that.",
                    "label": 0
                },
                {
                    "sent": "Adaboost is 1 approach here, where the weighting is chosen so so as to.",
                    "label": 0
                },
                {
                    "sent": "The choice of the weighting corresponds to choosing a function F from the linear span of our basis class so as to minimize the sample average of some exponential.",
                    "label": 0
                },
                {
                    "sent": "Exponentially decreasing function of y * F of X. OK, so just.",
                    "label": 0
                },
                {
                    "sent": "Intuitively, you know if F of X is this real valued.",
                    "label": 0
                },
                {
                    "sent": "Real valued function here WHI is takes values plus or minus one so it seems reasonable that we would be trying to find a small value of this criterion which corresponds to y * F of X being large and positive.",
                    "label": 0
                },
                {
                    "sent": "Right, so that means F has the correct sign.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, and.",
                    "label": 0
                },
                {
                    "sent": "And that's all I'll say for now about about boosting algorithms, kernel methods.",
                    "label": 0
                },
                {
                    "sent": "Again, you've seen you've seen this here, we've.",
                    "label": 0
                },
                {
                    "sent": "We've got a rather general domain and input SpaceX on, which we define an inner product and come up with a suitable inner product.",
                    "label": 0
                },
                {
                    "sent": "I should say and come up with a Hilbert space that is a reproducing kernel Hilbert space.",
                    "label": 1
                },
                {
                    "sent": "And the class of functions that we're considering.",
                    "label": 0
                },
                {
                    "sent": "We can view SVM's as working with.",
                    "label": 0
                },
                {
                    "sent": "A bounded subset of linear functions, right?",
                    "label": 0
                },
                {
                    "sent": "So we look at.",
                    "label": 0
                },
                {
                    "sent": "Functions that compute just in a product.",
                    "label": 0
                },
                {
                    "sent": "Right, but the the functions are bounded.",
                    "label": 0
                },
                {
                    "sent": "The RKS norm of the functions is bounded.",
                    "label": 0
                },
                {
                    "sent": "Or equivalently, we can parameterise them by an element of our Hobart space and think of the parameter W is having a bounded norm.",
                    "label": 0
                },
                {
                    "sent": "And again, just as in the perceptron case, you know the the neat thing about this kind of approach is that even with the general inner product on a complicated space, we can always represent the function implicitly using this dual representation.",
                    "label": 0
                },
                {
                    "sent": "By recording just the weights associated with each, just a weight associated with each.",
                    "label": 0
                },
                {
                    "sent": "Each of the exercise in our training.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right in the approach that's used in the typical SVM is to.",
                    "label": 0
                },
                {
                    "sent": "We consider that class of functions and we minimize some empirical criterion.",
                    "label": 0
                },
                {
                    "sent": "Alright, this is the sample average of a cost function, again involving Y * F of X + a penalty term, so this is a regularization.",
                    "label": 0
                },
                {
                    "sent": "Kind of approach, we have a regularised empirical criterion here.",
                    "label": 0
                },
                {
                    "sent": "Right and the cost function that we're concerned with, right?",
                    "label": 0
                },
                {
                    "sent": "In this case, is a is a piecewise linear function.",
                    "label": 0
                },
                {
                    "sent": "It's the hinge loss.",
                    "label": 0
                },
                {
                    "sent": "Alright, so.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You Susan tended to give you an overview of the kinds of approaches that I want to consider.",
                    "label": 0
                },
                {
                    "sent": "Function classes and algorithms for pattern classification.",
                    "label": 1
                },
                {
                    "sent": "Now let's get onto.",
                    "label": 1
                },
                {
                    "sent": "Performance guarantees, so getting risk bounds for.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Of this kind.",
                    "label": 0
                },
                {
                    "sent": "So that the general approach that I want to use here is the is Rademacher averages.",
                    "label": 0
                },
                {
                    "sent": "I'll start by telling you a bit about you know the very idea of risk bounds.",
                    "label": 0
                },
                {
                    "sent": "I guess that we want to understand how we should control the complexity of the functions that we have, so it's the best trade off the the competing issues that we face.",
                    "label": 0
                },
                {
                    "sent": "These approximation, in particularly approximation estimation issues.",
                    "label": 0
                },
                {
                    "sent": "I'm going to introduce some concentration inequality's that tell us how sample averages converge to.",
                    "label": 0
                },
                {
                    "sent": "To expectations and how concentrated these things are, I guess a bit more generally than just sample averages were looking at concentration of other of more general random variables about their expectation, and then we'll be using these ideas.",
                    "label": 0
                },
                {
                    "sent": "Improving risk bounds using a measure of complexity called Rademacher averages.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Will.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Will get onto those in a moment.",
                    "label": 0
                },
                {
                    "sent": "OK, but just first a bit of.",
                    "label": 0
                },
                {
                    "sent": "A bit of intuition.",
                    "label": 0
                },
                {
                    "sent": "So if we think of this, the framework, as I've outlined that we have a class of functions capital F. And we'd like to choose some function from that class so as to minimize the expectation of the loss or the minimize the risk.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "But we have these competing issues.",
                    "label": 0
                },
                {
                    "sent": "If we were to choose a function from a more complex class, then we're going to do better in terms of the approximation properties, right?",
                    "label": 0
                },
                {
                    "sent": "The infima over the class that the minimum over the class of the risk for a bigger class is something that will be smaller, but will suffer on the estimation side right?",
                    "label": 0
                },
                {
                    "sent": "And more complex class.",
                    "label": 0
                },
                {
                    "sent": "We only have information about the class presented to us in the form of these finite set of labeled examples, OK?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The key issue here is trading off these two properties.",
                    "label": 1
                },
                {
                    "sent": "The approximation properties in the estimation properties.",
                    "label": 1
                },
                {
                    "sent": "So coming up with estimates of the risk in terms of, for instance, the sample size in some measure of the complexity of F tells us how to control the complexity of F. For instance, using some method of sieves, some approach where we say for a given sample size we can work with a class that's this complex and as the sample size grows, we can choose some function from a bigger and bigger class.",
                    "label": 1
                },
                {
                    "sent": "Or an approach that's very very closely related is a regularization approach.",
                    "label": 0
                },
                {
                    "sent": "For instance, you know control introducing an extra parameter into an empirical criterion.",
                    "label": 0
                },
                {
                    "sent": "Such as the the RKS norm regularization parameter in the SBM.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "These are two general approaches of controlling controlling complexity.",
                    "label": 0
                },
                {
                    "sent": "So let's think now about.",
                    "label": 0
                },
                {
                    "sent": "Suppose we have a case where we've got a very rich class.",
                    "label": 0
                },
                {
                    "sent": "Capital F and we split it up into some hierarchy, right?",
                    "label": 1
                },
                {
                    "sent": "So we're thinking of choosing functions from this class, but it's way too rich to to.",
                    "label": 0
                },
                {
                    "sent": "To estimate some function from that class near optimally using a finite sample.",
                    "label": 0
                },
                {
                    "sent": "So we split it up.",
                    "label": 0
                },
                {
                    "sent": "We come up with some hierarchy.",
                    "label": 0
                },
                {
                    "sent": "We represent functions.",
                    "label": 0
                },
                {
                    "sent": "We represent this class as a union of of simpler classes.",
                    "label": 0
                },
                {
                    "sent": "F1F2 and so on, where for each K what we're going to do is choose the best F sub K in the class capital FK.",
                    "label": 1
                },
                {
                    "sent": "OK, and for instance we might do that by minimizing empirical risk.",
                    "label": 0
                },
                {
                    "sent": "And then we'll choose.",
                    "label": 0
                },
                {
                    "sent": "And if K right, one of these optimal guys so as to minimize the complexity?",
                    "label": 0
                },
                {
                    "sent": "Penalized empirical error.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is a generic approach that we might take.",
                    "label": 0
                },
                {
                    "sent": "You could think of, you could think of this.",
                    "label": 0
                },
                {
                    "sent": "Hierarchical representation, for instance, for things like decision trees, K, might my index K might be the restriction on the number of decision nodes in the tree.",
                    "label": 0
                },
                {
                    "sent": "Or 4.",
                    "label": 0
                },
                {
                    "sent": "The reproducing kernel Hilbert space.",
                    "label": 0
                },
                {
                    "sent": "The index K might allow an increase increasing radius of a ball in an arc HS right F sub K would be a subset of all in the dark ages of radius RK.",
                    "label": 0
                },
                {
                    "sent": "Where are Kay is increasing with K?",
                    "label": 0
                },
                {
                    "sent": "Right, and then we're thinking of.",
                    "label": 0
                },
                {
                    "sent": "So here is 1 general approach.",
                    "label": 0
                },
                {
                    "sent": "We're thinking of choosing some function from the from this Union so as to minimize.",
                    "label": 0
                },
                {
                    "sent": "A sample based estimate of risk.",
                    "label": 0
                },
                {
                    "sent": "Plus a penalty term involving the complexity of the case class OK could have written this just as P sub K. OK, so in the Decision Tree case this would be a penalty that increases with the number of nodes in the decision tree.",
                    "label": 0
                },
                {
                    "sent": "In the OK chest case, it's a penalty that increases with the radius of the ball in the disk.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Injury alright, so that's that's a kind of method of sieves which with the complexity.",
                    "label": 1
                },
                {
                    "sent": "Penalty there a regularization approach.",
                    "label": 0
                },
                {
                    "sent": "We could again consider this rich class.",
                    "label": 1
                },
                {
                    "sent": "But instead of doing an explicit partition into a union of.",
                    "label": 0
                },
                {
                    "sent": "Classes we could minimize directly over this class are complexity penalized empirical error.",
                    "label": 1
                },
                {
                    "sent": "Alright, so here we have.",
                    "label": 1
                },
                {
                    "sent": "This is a sample average of.",
                    "label": 0
                },
                {
                    "sent": "This is a sample based estimate of risk and here we have a penalty term that depends on the function F itself.",
                    "label": 0
                },
                {
                    "sent": "Alright, so this might be for instance in the arcade chess example.",
                    "label": 0
                },
                {
                    "sent": "This might be something involving the norm of the HS norm of the function F. Well, that's not so different from the method of sieves on the previous slide, right?",
                    "label": 0
                },
                {
                    "sent": "If we think about our the decomposition now into the set of functions that have this complexity penalty smaller than some value.",
                    "label": 0
                },
                {
                    "sent": "Right that that defines.",
                    "label": 0
                },
                {
                    "sent": "So now we can express F as a union of this kind union of classes of this code.",
                    "label": 0
                },
                {
                    "sent": "OK, so so coming up with bounds on risk in terms of.",
                    "label": 0
                },
                {
                    "sent": "A sample size and various notions of complexity of functions or function classes tell us what is a suitable complexity penalty to introduce here, right, so?",
                    "label": 1
                },
                {
                    "sent": "So how we should restrict F when we represented as a union of?",
                    "label": 0
                },
                {
                    "sent": "These F sub K or equivalently.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We should regularize.",
                    "label": 0
                },
                {
                    "sent": "F functions.",
                    "label": 0
                },
                {
                    "sent": "Alright, so the key tool in obtaining these risk bounds that I'm going to be telling you about over the next.",
                    "label": 0
                },
                {
                    "sent": "The next couple of days are Rademacher averages.",
                    "label": 0
                },
                {
                    "sent": "So this is a.",
                    "label": 0
                },
                {
                    "sent": "This is an important definition and it's going to be central to you know what I what I have to say.",
                    "label": 0
                },
                {
                    "sent": "Certainly for the rest of today.",
                    "label": 0
                },
                {
                    "sent": "Alright, so.",
                    "label": 0
                },
                {
                    "sent": "The Rademacher averages are defined.",
                    "label": 1
                },
                {
                    "sent": "In this way.",
                    "label": 0
                },
                {
                    "sent": "So we use the notation R sub N of of F. This is our function class and this operator is.",
                    "label": 0
                },
                {
                    "sent": "Defined as, so we have the supremum over the class of an average of these Sigma rise times F of XI.",
                    "label": 0
                },
                {
                    "sent": "Alright, so this is a random variable.",
                    "label": 0
                },
                {
                    "sent": "The Sigma rise here are called Rademacher Random variables, so these are IID uniform.",
                    "label": 0
                },
                {
                    "sent": "1 + -- 1.",
                    "label": 0
                },
                {
                    "sent": "OK, so we're looking here at an inner product between F the excuse me the function F evaluated at each of the endpoints X one through XN in our in our sample.",
                    "label": 0
                },
                {
                    "sent": "Write an inner product between that vector of values and this random plus minus one vector right of the Sigma's.",
                    "label": 0
                },
                {
                    "sent": "So our end of F is the supremum.",
                    "label": 0
                },
                {
                    "sent": "Overall functions in our class of this of this inner product.",
                    "label": 0
                },
                {
                    "sent": "So we're saying take a random vector Sigma right?",
                    "label": 0
                },
                {
                    "sent": "So first of all, let's fix the sample X one through XN.",
                    "label": 0
                },
                {
                    "sent": "Right then taken a random vector Sigma one through Sigma N of plus minus one values.",
                    "label": 0
                },
                {
                    "sent": "Now look at how much each F in our class evaluated at X one through XN.",
                    "label": 0
                },
                {
                    "sent": "How much that lines up with this random vector?",
                    "label": 0
                },
                {
                    "sent": "OK, what's the biggest inner product we can find as F ranges over the class?",
                    "label": 0
                },
                {
                    "sent": "What's the biggest inner product we can find between F of X1 through XN and Sigma one through Sigma N?",
                    "label": 0
                },
                {
                    "sent": "OK. And this is the value of that biggest inner product.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's a random variable.",
                    "label": 0
                },
                {
                    "sent": "I guess there are.",
                    "label": 0
                },
                {
                    "sent": "There are two things in here.",
                    "label": 0
                },
                {
                    "sent": "There's the sample X one through XN, that's random, and there's the Sigma one through Sigma, and those are also random.",
                    "label": 0
                },
                {
                    "sent": "OK, so this thing is a random variable.",
                    "label": 0
                },
                {
                    "sent": "And we're going to, in fact will see this is tightly concentrated around its expectation, or any any of the conditional expectations that we want to consider.",
                    "label": 0
                },
                {
                    "sent": "I totally concentrated around their expectation.",
                    "label": 0
                },
                {
                    "sent": "But let's think now just about removing that randomness is considered the expectation of this thing.",
                    "label": 0
                },
                {
                    "sent": "It measures how well our class can correlate with the noise vector Sigma.",
                    "label": 0
                },
                {
                    "sent": "Right, so you're picking the Sigma is just some random direction, and then we're saying now try and find an F that lines up with that direction.",
                    "label": 0
                },
                {
                    "sent": "OK, it's not a uniformly chosen random direction, it's just on the vertices of the plus or minus one cube.",
                    "label": 0
                },
                {
                    "sent": "In fact, we could define this thing not in terms of Rademacher averages, but in terms of Gaussians or elements of.",
                    "label": 0
                },
                {
                    "sent": "Uniformly over the sphere and you know all of the results that I tell you will change by.",
                    "label": 0
                },
                {
                    "sent": "I guess no more than a log factor anywhere, right?",
                    "label": 0
                },
                {
                    "sent": "So so you can think about this.",
                    "label": 0
                },
                {
                    "sent": "Sigma is just being a random direction.",
                    "label": 0
                },
                {
                    "sent": "Right, and we're asking so now.",
                    "label": 0
                },
                {
                    "sent": "How much can we line up with that random direction if we line up?",
                    "label": 0
                },
                {
                    "sent": "If we can always line up so?",
                    "label": 0
                },
                {
                    "sent": "So for essentially all choices of this direction we can.",
                    "label": 0
                },
                {
                    "sent": "We can come up with an F that has some nice big value of this inner product, right then, that tells us that we're unlikely to be able to infer very much from from the training data, right?",
                    "label": 0
                },
                {
                    "sent": "Because we can get essentially any labels we want any sign we want from our F of X. OK, so that's a bad thing, right from the statistical point of view.",
                    "label": 0
                },
                {
                    "sent": "So one other thing, I guess I should point out this is this is a notion of complexity, so that's one way to think of it, right?",
                    "label": 0
                },
                {
                    "sent": "We're measuring how complex our classes.",
                    "label": 0
                },
                {
                    "sent": "But we're measuring that complexity with respect to the probability distribution that we see the distribution that generates the X is at least.",
                    "label": 0
                },
                {
                    "sent": "So the marginal distribution on the X is, and it's also of course, so it depends on on the combination of the probability distribution and the function class F.",
                    "label": 1
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "So here's a theorem.",
                    "label": 0
                },
                {
                    "sent": "That gives us a bound on on the risk of a.",
                    "label": 0
                },
                {
                    "sent": "Of a function in some class.",
                    "label": 0
                },
                {
                    "sent": "In terms of.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Sample averages.",
                    "label": 0
                },
                {
                    "sent": "Or empirical risks?",
                    "label": 0
                },
                {
                    "sent": "I'm going to express it not in, not in terms of risk, so I'm just saying, look, we've got some class of functions that take value in some bounded interval.",
                    "label": 0
                },
                {
                    "sent": "And I want to know about expectations compared to sample averages.",
                    "label": 0
                },
                {
                    "sent": "OK, so the case to think of is is these functions are loss loss functions right?",
                    "label": 0
                },
                {
                    "sent": "The loss incurred on a sequence of XY pairs.",
                    "label": 0
                },
                {
                    "sent": "So the empirical loss.",
                    "label": 0
                },
                {
                    "sent": "The sample average of the of the loss versus the expectation of the loss or the OR the risk as we've defined it.",
                    "label": 0
                },
                {
                    "sent": "OK, that's the case to think of.",
                    "label": 0
                },
                {
                    "sent": "So what's the result?",
                    "label": 0
                },
                {
                    "sent": "We've got our class G of.",
                    "label": 0
                },
                {
                    "sent": "Functions that take values in some interval.",
                    "label": 0
                },
                {
                    "sent": "We can say with probability that gets close to one uniformly across this class.",
                    "label": 0
                },
                {
                    "sent": "So for every function in the class, expectations are not much bigger than sample averages.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "And how much bigger will?",
                    "label": 0
                },
                {
                    "sent": "There's some small small term that depends on you know how close we want this probability to be to one right into this number X. OK, that's like a one over square root of anything that's small.",
                    "label": 0
                },
                {
                    "sent": "And then we've got something that's the expectation of these Rademacher averages.",
                    "label": 0
                },
                {
                    "sent": "OK, and so when we think about this, G. As being the the discrete loss that we incur for a particular class of plus minus one valued functions.",
                    "label": 0
                },
                {
                    "sent": "Alright, we can write the special case down here.",
                    "label": 0
                },
                {
                    "sent": "It turns out these two are related.",
                    "label": 0
                },
                {
                    "sent": "We'll see in a moment.",
                    "label": 0
                },
                {
                    "sent": "We can write that the risk.",
                    "label": 0
                },
                {
                    "sent": "Of so uniformly over the class F, the risk of a function F is no more than the sample average for the empirical risk.",
                    "label": 0
                },
                {
                    "sent": "Plus some penalty term.",
                    "label": 0
                },
                {
                    "sent": "Involving the complexity of the class, the random maker averages.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "So we'll have a look at this at why this theorem is true, but but first.",
                    "label": 0
                },
                {
                    "sent": "Let me point out a few things.",
                    "label": 0
                },
                {
                    "sent": "Let me just reiterate the Rademacher averages.",
                    "label": 0
                },
                {
                    "sent": "Here are a property of both the class and the probability distribution, right?",
                    "label": 0
                },
                {
                    "sent": "So we're capturing somehow.",
                    "label": 0
                },
                {
                    "sent": "How the probability distribution emphasizes or exercises the complexity of the class?",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Later, we'll see that we can come up with estimates of this sort of a quantity in terms of distribution.",
                    "label": 0
                },
                {
                    "sent": "Independent notions of complexity, like VC dimension and covering numbers of various other things.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Let's say a little bit about the proof of this result.",
                    "label": 0
                },
                {
                    "sent": "Yeah, great I can't see.",
                    "label": 0
                },
                {
                    "sent": "01 yes, class.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "Right so so here I'm this class G is that you should think of as the class of loss functions, right?",
                    "label": 0
                },
                {
                    "sent": "So for every so G is defined as the set of.",
                    "label": 0
                },
                {
                    "sent": "Let's call the functions L sub F as F ranges over the class capital F where L sub F is the loss function.",
                    "label": 0
                },
                {
                    "sent": "The function that Maps from an XY pair to the loss incured when you predict F of X and the outcome is why?",
                    "label": 0
                },
                {
                    "sent": "OK?",
                    "label": 0
                },
                {
                    "sent": "So these things are the plus minus one valued functions.",
                    "label": 0
                },
                {
                    "sent": "We used to predict.",
                    "label": 0
                },
                {
                    "sent": "These things are the losses and the domain.",
                    "label": 0
                },
                {
                    "sent": "Here is X.",
                    "label": 0
                },
                {
                    "sent": "These things are the losses that we incur.",
                    "label": 0
                },
                {
                    "sent": "Right when we use a particular function to predict and the domain is X cross Y.",
                    "label": 0
                },
                {
                    "sent": "Zero, the loss is bounded between zero and one that's right and down.",
                    "label": 0
                },
                {
                    "sent": "Here we're thinking of the special case where the function is.",
                    "label": 0
                },
                {
                    "sent": "So so OK.",
                    "label": 0
                },
                {
                    "sent": "I guess I didn't say earlier, you know so.",
                    "label": 0
                },
                {
                    "sent": "So this the first part of the theorem, here, you know is more general than just the pattern classification kind of setting, but.",
                    "label": 0
                },
                {
                    "sent": "When we apply it, you know will always be worrying about loss classes of this.",
                    "label": 0
                },
                {
                    "sent": "Well, actually, that's not true for tomorrow, but for today will always be worrying about loss classes for plus minus one value functions.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So so yeah, this is the the general result is for loss classes, and we're concerned about loss classes of plus minus one value.",
                    "label": 0
                },
                {
                    "sent": "Classes.",
                    "label": 0
                },
                {
                    "sent": "Are there any other questions?",
                    "label": 0
                },
                {
                    "sent": "The previous slide.",
                    "label": 0
                },
                {
                    "sent": "Why are Easter Sigma fixed through a research the voice messed up to three an cases?",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "The the.",
                    "label": 0
                },
                {
                    "sent": "The Sigma IR.",
                    "label": 0
                },
                {
                    "sent": "IID uniform and plus minus one.",
                    "label": 0
                },
                {
                    "sent": "So they are random variables, so this thing is a random variable, right?",
                    "label": 0
                },
                {
                    "sent": "So it's a random variable because it depends on the random X one through XN.",
                    "label": 0
                },
                {
                    "sent": "And it depends on the random Sigma one through Sigma in.",
                    "label": 0
                },
                {
                    "sent": "OK, so we're not doing any optimization over Sigma, we're doing an optimization over the function F. Essentially, you want the random variable from very small.",
                    "label": 0
                },
                {
                    "sent": "You don't want to.",
                    "label": 0
                },
                {
                    "sent": "This random variable that's right.",
                    "label": 0
                },
                {
                    "sent": "That's right, so so if you think about, you know, throw that Supreme away and think about a fixed F. Right then this thing has mean zero, right?",
                    "label": 0
                },
                {
                    "sent": "Each sigmai has mean zero and so the expectation without the soup is zero.",
                    "label": 0
                },
                {
                    "sent": "OK, so we're doing a maximization, so will always do at least as well as zero.",
                    "label": 0
                },
                {
                    "sent": "So this this this thing.",
                    "label": 0
                },
                {
                    "sent": "This random variable takes a value that's at least as big as zero.",
                    "label": 0
                },
                {
                    "sent": "And the bigger it is, the more that we can find a function in our class to line up with a random vector.",
                    "label": 0
                },
                {
                    "sent": "OK, so the richer classes.",
                    "label": 0
                },
                {
                    "sent": "Alright, and now when we look at how that appears in the theorem.",
                    "label": 0
                },
                {
                    "sent": "It's the theorem tells us that if we've got a class.",
                    "label": 0
                },
                {
                    "sent": "A class of functions that take values in some bounded interval.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Then expectations are uniformly close to sample averages where provided that this notion of complexity is small.",
                    "label": 0
                },
                {
                    "sent": "Right, so if we are in the case where you know we're not doing much better than if we throw this Supreme away and we have just a single function, this thing would be 0 right?",
                    "label": 0
                },
                {
                    "sent": "If we have a much richer class than that, and the supremum letters line up really well and this is a large value, then the theorem becomes weaker, right?",
                    "label": 0
                },
                {
                    "sent": "We get a much bigger quantity here on the right hand side the we can't guarantee that the.",
                    "label": 0
                },
                {
                    "sent": "Expectation is not much bigger than the the sample average, and I've written the inequality in One Direction here.",
                    "label": 0
                },
                {
                    "sent": "I mean, I could have put absolute values around the difference between the expectation in the sample average and I could.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "You know the interval being 01 is not really crucial.",
                    "label": 0
                },
                {
                    "sent": "It could be any bounded interval.",
                    "label": 0
                },
                {
                    "sent": "So I could consider negative functions negative.",
                    "label": 0
                },
                {
                    "sent": "The set of negative G where G comes from G and get the same thing.",
                    "label": 0
                },
                {
                    "sent": "So you know, I mean I can get exactly the same inequality but 2 sided.",
                    "label": 0
                },
                {
                    "sent": "I guess I'm saying.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And I should say in everything that I'm that I'm doing, I'm really relying on the fact that we have bounded random variables.",
                    "label": 0
                },
                {
                    "sent": "We'll see later that this is this is crucial for the concentration inequality's that we that we need.",
                    "label": 0
                },
                {
                    "sent": "I mean, I guess it could be relaxed if you know something about the tales of of certain distributions that will appear, but I don't go into that at all.",
                    "label": 0
                },
                {
                    "sent": "And in our case, for binary valued functions, in fact, for everything that we do, you know these tools are powerful enough, we can.",
                    "label": 0
                },
                {
                    "sent": "We can always work with bounded loss functions.",
                    "label": 0
                },
                {
                    "sent": "OK, so so let's take a look at.",
                    "label": 0
                },
                {
                    "sent": "How this theorem is proved?",
                    "label": 0
                },
                {
                    "sent": "What we're looking at here?",
                    "label": 0
                },
                {
                    "sent": "I guess one crucial thing that maybe I should emphasize again is that we're talking about a a result that's uniform over the class, right?",
                    "label": 0
                },
                {
                    "sent": "So with high probability, right?",
                    "label": 0
                },
                {
                    "sent": "Every function in our class has expectation sample, average close.",
                    "label": 0
                },
                {
                    "sent": "OK, and that means if we choose some function to minimize the empirical risk right, minimize the sample average of the loss.",
                    "label": 0
                },
                {
                    "sent": "Then we know that the loss for that function that minimizer is going to be not too big.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "You know it's a.",
                    "label": 0
                },
                {
                    "sent": "It's a uniform convergence result.",
                    "label": 0
                },
                {
                    "sent": "So it it tells us about the uniform deviations between.",
                    "label": 0
                },
                {
                    "sent": "Expectations and sample averages.",
                    "label": 0
                },
                {
                    "sent": "OK, So what we're really concerned with here.",
                    "label": 0
                },
                {
                    "sent": "He's saying, you know, that the probability of the event that the maximum over this class of the difference between these two is big.",
                    "label": 0
                },
                {
                    "sent": "That probability should be.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "So we are interested in this quantity.",
                    "label": 0
                },
                {
                    "sent": "OK, the maximum over our class G of the difference between expectations and sample averages.",
                    "label": 0
                },
                {
                    "sent": "OK, and the concentration result that we use for that particular theorem is is a. Gen one.",
                    "label": 0
                },
                {
                    "sent": "That's cold, Mcdiarmid's inequality is also known as hurting Azuma and.",
                    "label": 0
                },
                {
                    "sent": "There are, there's another name that this case for the moment, but you know this is this is a result that I guess appeared in a paper of or something equivalent in a paper of hurting, you know, a very long time ago.",
                    "label": 0
                },
                {
                    "sent": "So this result is a concentration result for bounded random variables.",
                    "label": 0
                },
                {
                    "sent": "That tells us that.",
                    "label": 0
                },
                {
                    "sent": "That if.",
                    "label": 0
                },
                {
                    "sent": "If in particular we have a random variable such as this one that depends on X1 through XN, alright, so this thing is just the maximum over our class of the expectation of sample averages.",
                    "label": 0
                },
                {
                    "sent": "OK, that's random, because it's a, it's a function of the random variables X one through XN.",
                    "label": 0
                },
                {
                    "sent": "Through this sample average, now Mcdermott's inequality tells us that if we have a function of IID random variables, as we do here.",
                    "label": 0
                },
                {
                    "sent": "Right like then?",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Then we get concentration of the of that random variable about its expectation.",
                    "label": 0
                },
                {
                    "sent": "Provided that no one of those independent random variables has a big influence.",
                    "label": 0
                },
                {
                    "sent": "OK, so how do we formalize that?",
                    "label": 0
                },
                {
                    "sent": "So the random variable we're thinking of is this one in our case, but let's think now about, well, OK, so this thing is a function of X1 through XN, and the crucial condition that lets us apply Mcdermott's inequality is that when one of these independent random variables changes, the function that we have can't change by much.",
                    "label": 0
                },
                {
                    "sent": "So how do we measure that?",
                    "label": 0
                },
                {
                    "sent": "Well, the sample average of GG is a function.",
                    "label": 0
                },
                {
                    "sent": "That takes values in the interval 01, right?",
                    "label": 0
                },
                {
                    "sent": "So the sample average.",
                    "label": 0
                },
                {
                    "sent": "Can't change by any more than 1 / N OK might go from one extreme like 0 at a particular XI GX I might change from zero to 1 if we change that XI.",
                    "label": 0
                },
                {
                    "sent": "OK, so the same thing must be true for the supremum.",
                    "label": 0
                },
                {
                    "sent": "If we change one of the excise this thing can't change by more than 1 / N and that means that this random variable is concentrated around its expectation.",
                    "label": 0
                },
                {
                    "sent": "So precisely the form of Mcdem's inequality is that this random variable is not much bigger than its expectation plus a little bit.",
                    "label": 0
                },
                {
                    "sent": "This little bit depends on the the fluctuations that we see when we change one of those random variables.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is a very general and nice and easy to apply inequality right?",
                    "label": 0
                },
                {
                    "sent": "We just we're talking about a random variable that can be expressed as a function of a bunch of independent random variables.",
                    "label": 0
                },
                {
                    "sent": "If we change any one of those.",
                    "label": 0
                },
                {
                    "sent": "Does the function change by not too much?",
                    "label": 0
                },
                {
                    "sent": "And if that's the case, then the our random variable is is concentrated around its expectation at this kind of level, it depends on the size of the of the fluctuations.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so that's at the heart of the proof.",
                    "label": 0
                },
                {
                    "sent": "Alright, so let me state this concentration inequality precisely.",
                    "label": 0
                },
                {
                    "sent": "So we have.",
                    "label": 0
                },
                {
                    "sent": "In independent random variables, I'll call them X one through XN.",
                    "label": 1
                },
                {
                    "sent": "Now, um.",
                    "label": 0
                },
                {
                    "sent": "And we have a function that Maps from from some domain X Maps from the space that these.",
                    "label": 0
                },
                {
                    "sent": "That these line into to the reels.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "That's this is not true.",
                    "label": 0
                },
                {
                    "sent": "This should be a bounded interval in fact.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Thanks, but no, no this is true.",
                    "label": 0
                },
                {
                    "sent": "OK, so it Maps match the reels and then we have that.",
                    "label": 0
                },
                {
                    "sent": "Whenever we take any value of X1 through XN an any and any other X NEI Annie XI prime.",
                    "label": 0
                },
                {
                    "sent": "OK, so maximizing over all of the arguments of our function.",
                    "label": 0
                },
                {
                    "sent": "If we look at how our function G changes when we change X I2, XI prime.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "The the biggest change that we can get is CI.",
                    "label": 0
                },
                {
                    "sent": "OK, if we have this condition satisfied, this is the the bounded differences condition.",
                    "label": 0
                },
                {
                    "sent": "There's another name for this inequality, the one I forgot about differences in equality.",
                    "label": 0
                },
                {
                    "sent": "Then, with high probability, the deviation between our random variable and its expectation is small on the order of the two norm of this vector of these maximal deviations.",
                    "label": 0
                },
                {
                    "sent": "OK, so when we apply that in our case our G takes has fluctuations that are of order 1 / N OK, so we get a sum of of N terms.",
                    "label": 1
                },
                {
                    "sent": "Of 1 / N ^2 and we get our sqrt X / N. Turn down here.",
                    "label": 0
                },
                {
                    "sent": "OK, alright, so that's taking us a step in the right direction.",
                    "label": 0
                },
                {
                    "sent": "We've gone away from you know remember we're trying to.",
                    "label": 0
                },
                {
                    "sent": "We're trying to show that that expectations are not much bigger than sample averages.",
                    "label": 0
                },
                {
                    "sent": "With uniformly across the cloud across the class, we're trying to show that the the supremum.",
                    "label": 0
                },
                {
                    "sent": "For over functions of functions G in our class of differences, here is not too big and and what we first shown is that that random variable is not much bigger than its expectation.",
                    "label": 0
                },
                {
                    "sent": "OK G. Quality.",
                    "label": 0
                },
                {
                    "sent": "There's no condition saying that she has to be bounded.",
                    "label": 0
                },
                {
                    "sent": "There's no condition saying that G has to be bounded, we have.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "So G is bounded here implicitly, so so the point is, we're always looking at differences.",
                    "label": 0
                },
                {
                    "sent": "Right and and for any change of the of these variables were getting a small a small change, so GG is necessarily bounded because we were getting no more than a some of these changes to write.",
                    "label": 0
                },
                {
                    "sent": "Jeez, not necessarily bounded.",
                    "label": 0
                },
                {
                    "sent": "If we subtract some some value of G at some fixed value of X1 through XN.",
                    "label": 0
                },
                {
                    "sent": "Right then then so sent, just centering G around 0.",
                    "label": 0
                },
                {
                    "sent": "So for some value of X1 through XN this thing is 0.",
                    "label": 0
                },
                {
                    "sent": "Then G is bounded by the sum of the CIS.",
                    "label": 0
                },
                {
                    "sent": "Alright, and the way that we use the boundedness of G?",
                    "label": 0
                },
                {
                    "sent": "So I guess what's confusing here is that there are two different genes floating around.",
                    "label": 0
                },
                {
                    "sent": "G means two different things on this slide and on this slide.",
                    "label": 0
                },
                {
                    "sent": "OK, so here we have a class of bounded functions.",
                    "label": 0
                },
                {
                    "sent": "The fact that they are bounded.",
                    "label": 0
                },
                {
                    "sent": "Right means that the sample average can't change by much when we change one of the arguments.",
                    "label": 0
                },
                {
                    "sent": "OK, the random variable we're considering to apply Mick Demons inequality is the supremum over G of the expectation minus sample average.",
                    "label": 0
                },
                {
                    "sent": "So on this slide in stating Mcdem's inequality, I shouldn't have used G, right?",
                    "label": 0
                },
                {
                    "sent": "I should use some other and some other symbol for the random variable, right?",
                    "label": 0
                },
                {
                    "sent": "So the random variable we're talking about here?",
                    "label": 0
                },
                {
                    "sent": "Is in our case this thing?",
                    "label": 0
                },
                {
                    "sent": "Right, so sorry for that was an unfortunate choice of of notation here.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So I want to say a little bit about why about Mcdermott's inequality.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And why it's true?",
                    "label": 0
                },
                {
                    "sent": "And some of the ingredients of the proof here will will pop up later when we consider the the VC dimension.",
                    "label": 0
                },
                {
                    "sent": "OK, so we're looking here at deviations between the function G of these N random variables and the expectation of G. OK.",
                    "label": 0
                },
                {
                    "sent": "So I want to express that.",
                    "label": 0
                },
                {
                    "sent": "As a sum over a martingale difference sequence.",
                    "label": 1
                },
                {
                    "sent": "So I mean we're not using any properties of martingales here, so you don't have to know what they are.",
                    "label": 0
                },
                {
                    "sent": "So so we define the initial sequence X one through XI and worry about how the conditional expectation expectation changes as we see the random variable.",
                    "label": 0
                },
                {
                    "sent": "Right, so this is our function G. And we consider the how the expectation has increased.",
                    "label": 0
                },
                {
                    "sent": "So VI is the increase in the expectation conditioned on seeing X one through XI over what the conditional expectation was when we'd seen X one through X -- 1.",
                    "label": 0
                },
                {
                    "sent": "When we condition on just the first time, I just one of these guys alright, then the random variable G minus its expectation is just the sum of these things, right?",
                    "label": 1
                },
                {
                    "sent": "This is a telescoping sum, the first one, the expectation of G. Given nothing.",
                    "label": 0
                },
                {
                    "sent": "Well, that's this and the last one the expectation of G given X one through XN.",
                    "label": 0
                },
                {
                    "sent": "Well that's this.",
                    "label": 0
                },
                {
                    "sent": "Right, so we can write it as a sum of these things and now it's a sum of those guys.",
                    "label": 0
                },
                {
                    "sent": "That we want to bound the deviations of this thing.",
                    "label": 0
                },
                {
                    "sent": "Let's say with high probability this sum is is small.",
                    "label": 0
                },
                {
                    "sent": "OK, so you know I went through the steps, but the expectations of these things given the past are all zero.",
                    "label": 0
                },
                {
                    "sent": "OK, so this allows us to apply ideas of of.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sting going back to hurting.",
                    "label": 0
                },
                {
                    "sent": "And I'm going to to go through the argument here because.",
                    "label": 0
                },
                {
                    "sent": "It's something that we will see we will see later on.",
                    "label": 0
                },
                {
                    "sent": "So OK, so we can write the deviation between our random variable and its expectation as the sum of these differences between conditional expectations.",
                    "label": 0
                },
                {
                    "sent": "And now here's a trick that pops up again and again, right?",
                    "label": 0
                },
                {
                    "sent": "So the probability that this thing is bigger than that thing?",
                    "label": 0
                },
                {
                    "sent": "Well, let's take some monotone transformation of those of the two sides.",
                    "label": 0
                },
                {
                    "sent": "OK, in particular the monitoring transformation we going to take is the exponential function.",
                    "label": 0
                },
                {
                    "sent": "With some positive constant S. OK, so this is bigger than that, precisely when ITA this is bigger than E to that.",
                    "label": 0
                },
                {
                    "sent": "Or either the S times this.",
                    "label": 0
                },
                {
                    "sent": "OK, and now this is the.",
                    "label": 0
                },
                {
                    "sent": "This is something that we can bound using Markov's inequality.",
                    "label": 0
                },
                {
                    "sent": "OK so have you.",
                    "label": 0
                },
                {
                    "sent": "Does everybody know about Markov's inequality?",
                    "label": 0
                },
                {
                    "sent": "If you do, nobody's admitting.",
                    "label": 0
                },
                {
                    "sent": "So this is just saying, you know the that the expectation of some non negative random variable right is at least as big as the probability that it's bigger than something divided by that.",
                    "label": 0
                },
                {
                    "sent": "Sometimes that's something.",
                    "label": 0
                },
                {
                    "sent": "Right so.",
                    "label": 0
                },
                {
                    "sent": "So we can get an upper bound on this probability in terms of expectation of this thing times either minus St. OK, this is called the churn off the turnoff.",
                    "label": 0
                },
                {
                    "sent": "Bound right.",
                    "label": 0
                },
                {
                    "sent": "This is an idea that's used in shernoff bounds, and this trick appears in a lot of places.",
                    "label": 0
                },
                {
                    "sent": "Well this thing this is an expectation of E to the S times some some.",
                    "label": 0
                },
                {
                    "sent": "OK, that's a moment generating function, right?",
                    "label": 0
                },
                {
                    "sent": "We have a random variable here and we're considering the expectation of E to the S times random variable.",
                    "label": 0
                },
                {
                    "sent": "OK, who's who's not met moment generating functions before?",
                    "label": 0
                },
                {
                    "sent": "If you OK. Of the I mean, this is this is.",
                    "label": 0
                },
                {
                    "sent": "Modular sometimes changes the Laplace transform, so for the other electrical engineers.",
                    "label": 0
                },
                {
                    "sent": "Among us, it's essentially the same, the same as the Laplace transform.",
                    "label": 0
                },
                {
                    "sent": "So what we're concerned with now?",
                    "label": 0
                },
                {
                    "sent": "I mean, we can pull this into the minus St out.",
                    "label": 0
                },
                {
                    "sent": "We're concerned just with controlling the moment generating function of this random variable.",
                    "label": 0
                },
                {
                    "sent": "OK, and we can express that as an expectation of this product.",
                    "label": 0
                },
                {
                    "sent": "Our veizer not independent.",
                    "label": 0
                },
                {
                    "sent": "You know the things inequality relies on independence of these things.",
                    "label": 0
                },
                {
                    "sent": "We have something close to independence because of our.",
                    "label": 0
                },
                {
                    "sent": "Well, we have enough properties to to make things work by by conditioning appropriately.",
                    "label": 0
                },
                {
                    "sent": "I won't go into the details of that, but you know the whole game from now on is controlling the moment generating function of these of this random variable.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, and it turns out.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "OK, yeah, conditioned on something appropriate.",
                    "label": 1
                },
                {
                    "sent": "Alright, so if we have a mean zero random variable that lies in a bounded range, right?",
                    "label": 0
                },
                {
                    "sent": "This is Hurting's inequality.",
                    "label": 0
                },
                {
                    "sent": "OK, hurting first prove something of this form, maybe with a.",
                    "label": 0
                },
                {
                    "sent": "And what I think he got a different constant and that was.",
                    "label": 0
                },
                {
                    "sent": "Now actually having gotten improve got the right constant so you can show the moment generating function of abounded random variable is bounded in terms of this E to the X ^2.",
                    "label": 0
                },
                {
                    "sent": "Kind of a quantity.",
                    "label": 0
                },
                {
                    "sent": "OK, and it's the bounded differences property that lets us that lets us argue that the appropriate random variables here are bounded.",
                    "label": 1
                },
                {
                    "sent": "OK, so so now we get a bound on our.",
                    "label": 0
                },
                {
                    "sent": "Moment generating function in terms of the this variable S squared and in terms of the some of the differences squared, and we just play with the variable S to come up with to come up with a bound on the probability that we get big deviations.",
                    "label": 0
                },
                {
                    "sent": "And that's that's the McDermott inequality, right that the probability of the deviation between G and its expectation being large is bounded by this decreasing exponential in T ^2.",
                    "label": 0
                },
                {
                    "sent": "Right, so we get some sort of a something that looks like a Gaussian tail, right?",
                    "label": 0
                },
                {
                    "sent": "Provided that the.",
                    "label": 0
                },
                {
                    "sent": "The random variable G has this bound of differences property.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's.",
                    "label": 0
                },
                {
                    "sent": "That's where Mcdavid's inequality comes from.",
                    "label": 0
                },
                {
                    "sent": "This idea of controlling.",
                    "label": 0
                },
                {
                    "sent": "The moment generating function of a abounded random variable is something that will meet again.",
                    "label": 1
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "OK, so where are we?",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so let's make Damon's inequality.",
                    "label": 0
                },
                {
                    "sent": "Just remind you were headed for for this.",
                    "label": 0
                },
                {
                    "sent": "This result.",
                    "label": 0
                },
                {
                    "sent": "All right, that tells us that.",
                    "label": 0
                },
                {
                    "sent": "Expectations are not much bigger than sample averages.",
                    "label": 0
                },
                {
                    "sent": "And so far we.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I've got that the supremum.",
                    "label": 0
                },
                {
                    "sent": "Over the class of the deviations is close to the expectation of that thing, right?",
                    "label": 0
                },
                {
                    "sent": "A little bit extra because of that arises from Mcdem's inequality.",
                    "label": 0
                },
                {
                    "sent": "So now we just want to control the expectation of this thing.",
                    "label": 0
                },
                {
                    "sent": "OK. Alright, so and this is where the Rademacher averages pop up in a very natural way.",
                    "label": 0
                },
                {
                    "sent": "Alright, so these these things.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um, very close to the Rademacher averages.",
                    "label": 0
                },
                {
                    "sent": "Alright, so I'm going to write to a string of inequalities and there's really nothing.",
                    "label": 0
                },
                {
                    "sent": "Nothing hard here.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "Expected maximal deviation between expectations and sample averages.",
                    "label": 0
                },
                {
                    "sent": "OK, I want to rewrite that deviation as an expectation.",
                    "label": 0
                },
                {
                    "sent": "What have I done?",
                    "label": 0
                },
                {
                    "sent": "Given the XI, what have I done?",
                    "label": 0
                },
                {
                    "sent": "So I wanted to rewrite this as an expectation of a conditional expectation.",
                    "label": 0
                },
                {
                    "sent": "I've I've dropped one here anyway, so so this should be that we can think of this expectation here as being G of XI.",
                    "label": 0
                },
                {
                    "sent": "G of XI prime.",
                    "label": 0
                },
                {
                    "sent": "Minus the sample average of G. So I'm defining a new ghost sample, right?",
                    "label": 0
                },
                {
                    "sent": "If we think of X1 through XN.",
                    "label": 0
                },
                {
                    "sent": "As having a having exactly the same distribution being IID with the same distribution as XX One prime through XN prime having the same distribution as XX One through XN.",
                    "label": 0
                },
                {
                    "sent": "Alright, then we can.",
                    "label": 0
                },
                {
                    "sent": "Then we can rewrite this difference as an expectation of a sample average of G of XI prime right minus.",
                    "label": 0
                },
                {
                    "sent": "And this thing is also a sample average.",
                    "label": 0
                },
                {
                    "sent": "OK, so now I'm over here.",
                    "label": 0
                },
                {
                    "sent": "I'm conditioning on the X1 through XN.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "OK, so that's this is a note this, given the XI means given X one through XN.",
                    "label": 0
                },
                {
                    "sent": "This is why I should have written.",
                    "label": 0
                },
                {
                    "sent": "Right, and the expectation there is just worrying about.",
                    "label": 0
                },
                {
                    "sent": "The X one prime through XN prime.",
                    "label": 0
                },
                {
                    "sent": "So now I can take this expectation outside and I get an inequality, right?",
                    "label": 0
                },
                {
                    "sent": "But now I have something that looks just like G of XI prime minus G of XI.",
                    "label": 0
                },
                {
                    "sent": "OK, So what have I done to this point?",
                    "label": 0
                },
                {
                    "sent": "I've replaced the expectation over G here with another sample average.",
                    "label": 0
                },
                {
                    "sent": "Write an average over an independent sample X one prime through XN prime.",
                    "label": 0
                },
                {
                    "sent": "OK, so now this thing is quite symmetric, right?",
                    "label": 0
                },
                {
                    "sent": "These have exactly the same distribution.",
                    "label": 0
                },
                {
                    "sent": "They're independent, they have exactly the same distribution.",
                    "label": 0
                },
                {
                    "sent": "OK so I could have as easily put G of XI prime minus G of XI or I could have put G of XI minus G of XI prime.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "Both of those things have exactly the same distribution.",
                    "label": 0
                },
                {
                    "sent": "And so I can put a sigmai in here.",
                    "label": 0
                },
                {
                    "sent": "Right, for any fixed value of Sigma I I haven't changed things because this is just.",
                    "label": 0
                },
                {
                    "sent": "Right, the difference between G at some random, at least.",
                    "label": 0
                },
                {
                    "sent": "The distribution of this thing is unchanged.",
                    "label": 0
                },
                {
                    "sent": "Right, because it's just the difference between G at some random X ING at some other random and independent XI.",
                    "label": 0
                },
                {
                    "sent": "OK, so I can throw these Sigma rise in.",
                    "label": 0
                },
                {
                    "sent": "The plus or minus ones without without changing anything here.",
                    "label": 0
                },
                {
                    "sent": "But now this is looking a lot like Rademacher averages.",
                    "label": 0
                },
                {
                    "sent": "Or I've got a minus in there.",
                    "label": 0
                },
                {
                    "sent": "Let's split this up into a sum of that one Sigma IG of XI and this one.",
                    "label": 0
                },
                {
                    "sent": "G of XR prime in signal, RG of XI and then I have you know that I can write an inequality.",
                    "label": 0
                },
                {
                    "sent": "It's no more than the sum of those two right?",
                    "label": 0
                },
                {
                    "sent": "The expected supremum of the difference is no more than taking a Supreme over this one in the supremum over that one.",
                    "label": 0
                },
                {
                    "sent": "Which is this?",
                    "label": 0
                },
                {
                    "sent": "And that's just the random crap images.",
                    "label": 0
                },
                {
                    "sent": "OK, so these things arise in quite a natural way.",
                    "label": 0
                },
                {
                    "sent": "As soon as we make the observation that the expectation can be written as a sample average over these these.",
                    "label": 0
                },
                {
                    "sent": "Independent choices of X1 through XN.",
                    "label": 0
                },
                {
                    "sent": "Then the introduction of the Red America random variables changes.",
                    "label": 0
                },
                {
                    "sent": "Nothing, has exactly the same distribution and we get this.",
                    "label": 0
                },
                {
                    "sent": "OK, we've introduced a constant factor 2 in here through this sort of an upper bound.",
                    "label": 0
                },
                {
                    "sent": "Alright, it turns out that that there is a corresponding lower bound, right that the expectation of the maximal deviations between these two is.",
                    "label": 0
                },
                {
                    "sent": "At least as big as some constant times.",
                    "label": 0
                },
                {
                    "sent": "The Rademacher averages OK, so all we're giving away in these inequalities is maybe a constant factor.",
                    "label": 0
                },
                {
                    "sent": "Right, so in measuring, I mean I don't state this explicitly in here, but in measuring maximal deviations between expectations and sample averages, the Rademacher averages captured that precisely within a constant factor.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "I mean, there was one more thing that you know this.",
                    "label": 0
                },
                {
                    "sent": "This tells us that that gives us this result right?",
                    "label": 0
                },
                {
                    "sent": "The maximum over G of the deviation between expectation and sample averages is no more than this thing.",
                    "label": 0
                },
                {
                    "sent": "Right twice the expectation that marriage is plus a little bit that arises from the Mcdem inequality.",
                    "label": 0
                },
                {
                    "sent": "To see the second part, or we're doing down here is applying this for the class of loss functions.",
                    "label": 0
                },
                {
                    "sent": "OK, so when we consider the expectation of G, we're worrying about the risk right?",
                    "label": 0
                },
                {
                    "sent": "The expected loss for some F. The sample average is the sample average of the loss, so all we really need to do to go from here to here.",
                    "label": 0
                },
                {
                    "sent": "Is argue that the Rademacher averages for the class of loss functions is no bigger than the Rademacher averages for the original class.",
                    "label": 0
                },
                {
                    "sent": "Write the class of plus minus one valued functions.",
                    "label": 0
                },
                {
                    "sent": "OK, so so let's think for the discrete loss.",
                    "label": 0
                },
                {
                    "sent": "These are the functions we're considering.",
                    "label": 0
                },
                {
                    "sent": "The loss incurred by predicting F of X when the real outcome is Y. OK so I can write the Rademacher averages.",
                    "label": 0
                },
                {
                    "sent": "This is just the definition.",
                    "label": 0
                },
                {
                    "sent": "Right, the expectation of the supremum of Sigma.",
                    "label": 0
                },
                {
                    "sent": "How much the loss vector lines up with Sigma I I I'm going to write this discrete losses, the indicator of.",
                    "label": 0
                },
                {
                    "sent": "Alright, so this is the function that takes value one when Y is not equal to F of XI and 0 otherwise.",
                    "label": 0
                },
                {
                    "sent": "That's the definition of the loss.",
                    "label": 0
                },
                {
                    "sent": "Of the discrete loss, the 01 loss.",
                    "label": 0
                },
                {
                    "sent": "OK, but I can rewrite this.",
                    "label": 0
                },
                {
                    "sent": "This thing has a half of 1 -- y. I times F of XI.",
                    "label": 0
                },
                {
                    "sent": "OK, because when Y is equal to F of XI write this thing is 0 just as it should be.",
                    "label": 0
                },
                {
                    "sent": "When iy is different from ffxi?",
                    "label": 0
                },
                {
                    "sent": "Alright this thing is minus one and we get to hear divided by two is 1 just as it should be right?",
                    "label": 0
                },
                {
                    "sent": "So I haven't changed anything.",
                    "label": 0
                },
                {
                    "sent": "I've just rewritten in a linear way but now when it's linear I can throw away this term right?",
                    "label": 0
                },
                {
                    "sent": "It doesn't depend on FI just have an expectation of the Sigma rise.",
                    "label": 0
                },
                {
                    "sent": "Where they plus minus one uniform, so the expectation is zero that that term disappears and we get the expectation of the supremum of Sigma right times why I times F of XI.",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                },
                {
                    "sent": "Well, if Sigma Rai is uniform plus minus one, what distribution does Sigma I times why I have for any why I?",
                    "label": 0
                },
                {
                    "sent": "It's exactly the same distribution, right?",
                    "label": 0
                },
                {
                    "sent": "It's uniform plus minus one, so this thing is just the Rademacher averages divided by two.",
                    "label": 0
                },
                {
                    "sent": "OK, so in the case of discrete loss, the random ravages of the last class are equal to the Rademacher averages of the original class modular.",
                    "label": 0
                },
                {
                    "sent": "This constant half.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, and that gives us.",
                    "label": 0
                },
                {
                    "sent": "I don't know if I put it there OK. And that gives us this.",
                    "label": 0
                },
                {
                    "sent": "This result.",
                    "label": 0
                },
                {
                    "sent": "OK, so we think of this was the second part of the theorem before.",
                    "label": 0
                },
                {
                    "sent": "If we think of this class of plus minus one valued functions.",
                    "label": 0
                },
                {
                    "sent": "And we have discrete loss.",
                    "label": 0
                },
                {
                    "sent": "The 01 loss then with high probability that rapidly approaches one the.",
                    "label": 0
                },
                {
                    "sent": "Sorry, let me go back to the original theorem statement.",
                    "label": 0
                },
                {
                    "sent": "So this part.",
                    "label": 0
                },
                {
                    "sent": "The second part here is a slight refinement on that.",
                    "label": 0
                },
                {
                    "sent": "Next next slide, the second part.",
                    "label": 0
                },
                {
                    "sent": "Here is what we've just proved right for a class of plus minus one value functions and the 01 loss with probability that rapidly approaches one.",
                    "label": 1
                },
                {
                    "sent": "Every function has risk, not much more than empirical risk plus Rademacher averages, plus some little thing.",
                    "label": 0
                },
                {
                    "sent": "OK, that's what we just showed that the Rademacher averages of the discrete last class are the same as the Rainmaker averages of this class, modulo the constant 2.",
                    "label": 0
                },
                {
                    "sent": "OK, one thing I guess I should point out before we go on to the next theorem.",
                    "label": 0
                },
                {
                    "sent": "This term here the the 1 / sqrt N term.",
                    "label": 0
                },
                {
                    "sent": "That's always small alright.",
                    "label": 0
                },
                {
                    "sent": "Rather, the writer maker averages here.",
                    "label": 0
                },
                {
                    "sent": "If you have a class that contains just the constant one in the constant minus one function.",
                    "label": 0
                },
                {
                    "sent": "Right then, then the Rademacher averages are of order 1 / sqrt N. OK, so this is this is just like equivalently, if you look at the definition of.",
                    "label": 0
                },
                {
                    "sent": "Of the Rademacher averages.",
                    "label": 0
                },
                {
                    "sent": "Which I've thrown away.",
                    "label": 0
                },
                {
                    "sent": "So if this class contains the constant plus one constant minus one, that's just like taking the absolute value here, right?",
                    "label": 0
                },
                {
                    "sent": "The supremum over those plus or minus one guys is just the absolute value of the average of the Sigma rise.",
                    "label": 0
                },
                {
                    "sent": "OK, well that's of order 1 / sqrt N. OK. Because the variance grows linearly within.",
                    "label": 0
                },
                {
                    "sent": "So this term is this second term is.",
                    "label": 0
                },
                {
                    "sent": "Is is always dominated by the Rademacher averages, unless we have a particularly simple class.",
                    "label": 0
                },
                {
                    "sent": "I should say for any fixed classes dominated by the Rainmaker averages.",
                    "label": 0
                },
                {
                    "sent": "OK, so a refinement of that result.",
                    "label": 0
                },
                {
                    "sent": "Here is that so same setup we've got a Class A + -- 1 valued functions.",
                    "label": 0
                },
                {
                    "sent": "Now we're saying we're considering just the minimizer of the empirical risk.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's say we fix our class of functions F. Maybe it's decision trees of a certain size, then.",
                    "label": 0
                },
                {
                    "sent": "Then if we minimize the empirical risk over that class.",
                    "label": 0
                },
                {
                    "sent": "So find the F, let's call it F hat that makes the smallest number of mistakes on the on the sample.",
                    "label": 0
                },
                {
                    "sent": "Then we can.",
                    "label": 0
                },
                {
                    "sent": "We can argue using that previous result that the risk of that minimizer, right?",
                    "label": 0
                },
                {
                    "sent": "The probability that it makes a mistake.",
                    "label": 0
                },
                {
                    "sent": "The expectation of this of this 01 loss is no more than the minimum over our class of functions of the risk.",
                    "label": 0
                },
                {
                    "sent": "So this is the best we could hope for.",
                    "label": 0
                },
                {
                    "sent": "We call this the approximation error before, right?",
                    "label": 0
                },
                {
                    "sent": "Well, this is.",
                    "label": 0
                },
                {
                    "sent": "This is something something like an approximation property of that class is the best we could hope for, given that we're choosing functions from that class capital F. Plus a penalty term of the same size as before.",
                    "label": 0
                },
                {
                    "sent": "Slightly different constant.",
                    "label": 0
                },
                {
                    "sent": "Alright, so so this so so.",
                    "label": 0
                },
                {
                    "sent": "The picture of why this follows from the previous result is that we've shown that the expectations and sample averages close to each other uniformly across the class.",
                    "label": 0
                },
                {
                    "sent": "Alright, so the empirical minimizer has its expectation close to the sample average.",
                    "label": 0
                },
                {
                    "sent": "The optimal function, the one that minimizes this quantity, the probability of misclassification.",
                    "label": 0
                },
                {
                    "sent": "Also has his expectation close to the sample average.",
                    "label": 0
                },
                {
                    "sent": "Right, if those two are uniformly close, then when we go from one to the other, we can't be too far.",
                    "label": 0
                },
                {
                    "sent": "Can't be too far away, right?",
                    "label": 0
                },
                {
                    "sent": "The expectation can't be too far away from the the.",
                    "label": 1
                },
                {
                    "sent": "The expectation for the minimizer, the minimal expectation expectation of the empirical minimizer is can't be much bigger than the minimizer expectation.",
                    "label": 0
                },
                {
                    "sent": "OK, so so OK, let's suppose that this in film is realized that F star.",
                    "label": 0
                },
                {
                    "sent": "This is the best function in our class, the one that minimizes the probability of misclassification.",
                    "label": 0
                },
                {
                    "sent": "But the risk then that function in particular has empirical.",
                    "label": 0
                },
                {
                    "sent": "Empirical risk close to risk.",
                    "label": 0
                },
                {
                    "sent": "Right, but its empirical risk is necessarily worse than the minimizer of the empirical risk.",
                    "label": 0
                },
                {
                    "sent": "Right, we were choosing F hat to minimize the sample average.",
                    "label": 1
                },
                {
                    "sent": "Well, the optimal guy must have a bigger sample, a sample every average.",
                    "label": 0
                },
                {
                    "sent": "That's at least as big.",
                    "label": 0
                },
                {
                    "sent": "OK, but now we know that the sample average for this guy is close to his expectation.",
                    "label": 0
                },
                {
                    "sent": "OK, this is a single function, you know I don't even need to worry about Rademacher averages here, right?",
                    "label": 0
                },
                {
                    "sent": "I can?",
                    "label": 0
                },
                {
                    "sent": "I know the deviations between these two through her things inequality says of order 1 / sqrt N. Alright, so that tells us that you know for the particular function F hat, we know it's from.",
                    "label": 0
                },
                {
                    "sent": "The previous result is expectation is not much bigger than its sample average.",
                    "label": 1
                },
                {
                    "sent": "Well, that sample averages not much bigger than the best expectation.",
                    "label": 0
                },
                {
                    "sent": "OK, so we get we get this result immediately.",
                    "label": 0
                },
                {
                    "sent": "Alright, so that's an example of an application of these Rademacher averages.",
                    "label": 0
                },
                {
                    "sent": "In getting bounds on the risk of a particular choice of function from our class.",
                    "label": 0
                },
                {
                    "sent": "If we choose F hat, the function that minimizes the empirical risk, then it's risk is close to the best we could have hoped for, given that we're choosing functions from F, how close will it depends on the complexity of F as measured by these Rademacher averages.",
                    "label": 0
                },
                {
                    "sent": "OK, so once again if we go back to think about the definition, the Rademacher averages tell us how much functions in the class line up with this random random direction, right?",
                    "label": 0
                },
                {
                    "sent": "If they barely line up at all.",
                    "label": 0
                },
                {
                    "sent": "Right then it's hard to fit to that noise, right?",
                    "label": 0
                },
                {
                    "sent": "It's hard to pick a function that fits to the noise vector.",
                    "label": 0
                },
                {
                    "sent": "That's good.",
                    "label": 0
                },
                {
                    "sent": "We'll get our risk close to the optimal risk, right?",
                    "label": 0
                },
                {
                    "sent": "The deviation term here is going to be small.",
                    "label": 0
                },
                {
                    "sent": "If, on the other hand, we can always have these things lining up, then we might have a you know Rademacher averages, like some constant right.",
                    "label": 0
                },
                {
                    "sent": "Or you know, big as big as some constant as a function of N. Then the risk of the empirical minimizer.",
                    "label": 0
                },
                {
                    "sent": "We have a rather poor guarantee, right?",
                    "label": 0
                },
                {
                    "sent": "We could be, we could be some constant away from the best in the class in that case.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "One other observation, before I before I stop that that we can compute in the.",
                    "label": 0
                },
                {
                    "sent": "In the case of the 01 loss, we can compute Rademacher averages.",
                    "label": 0
                },
                {
                    "sent": "This is an interesting observation about the computation of these things.",
                    "label": 0
                },
                {
                    "sent": "The reader maker average is the is the maximum over the class of this thing.",
                    "label": 0
                },
                {
                    "sent": "Well, I can write that as the negative of the minimum alright, and then again, using this observation that these are plus minus one and the Zephyr plus minus one, right?",
                    "label": 0
                },
                {
                    "sent": "I can rewrite this product in terms of a.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Oh, I'm sorry.",
                    "label": 0
                },
                {
                    "sent": "I'm not doing that just yet, so.",
                    "label": 0
                },
                {
                    "sent": "The minimum of this thing I can throw in an extra an extra 1 here and an extra 1 there.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "And then I write this thing as the loss, right?",
                    "label": 0
                },
                {
                    "sent": "Because remember, we saw this earlier that that we can rewrite the loss of F of XI at.",
                    "label": 0
                },
                {
                    "sent": "At some Yi in terms of a linear, a linear.",
                    "label": 0
                },
                {
                    "sent": "Expression of this kind.",
                    "label": 0
                },
                {
                    "sent": "OK, so you can see this by case by case analysis.",
                    "label": 0
                },
                {
                    "sent": "Thinking of Sigma Rye negative signal having the same sign as F of XI and a different sign.",
                    "label": 0
                },
                {
                    "sent": "OK, So what we get at the end is the rental car averages are equal to.",
                    "label": 0
                },
                {
                    "sent": "1 minus the minimum over air or I guess I should say infime over F well, F is is finally here.",
                    "label": 0
                },
                {
                    "sent": "If takes only plus minus one value, so there are finitely many values of this thing, so the firms achieve 1 minus the minimum over F of.",
                    "label": 0
                },
                {
                    "sent": "An empirical risk kind of a quantity, right?",
                    "label": 0
                },
                {
                    "sent": "We're looking at finding an F to minimize the empirical risk.",
                    "label": 0
                },
                {
                    "sent": "When we consider the wise as being these minus Sigma eyes, right?",
                    "label": 0
                },
                {
                    "sent": "So we're trying to line up with.",
                    "label": 0
                },
                {
                    "sent": "The minus Sigma rise.",
                    "label": 0
                },
                {
                    "sent": "So computing the Rademacher averages is equivalent to minimizing empirical error on the randomly labeled data we take all of our X one through XN and throw in a random plus minus one label, and then try and optimize that.",
                    "label": 1
                },
                {
                    "sent": "OK, so later on we'll look at relationships between this notion of complexity, their own maker averages an other notions, so the VC dimension is not something that depends on the probability distribution that generated the the X is, but we can get upper bounds on the Rademacher averages in terms of the.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I am PC dimension.",
                    "label": 0
                },
                {
                    "sent": "Alright, so I'll stop.",
                    "label": 0
                },
                {
                    "sent": "I'll stop there.",
                    "label": 0
                },
                {
                    "sent": "I'm a little late, I'm sorry.",
                    "label": 0
                },
                {
                    "sent": "Are there any questions?",
                    "label": 0
                },
                {
                    "sent": "Should go directly to coffee.",
                    "label": 0
                },
                {
                    "sent": "So we'll have a copy.",
                    "label": 0
                }
            ]
        }
    }
}