{
    "id": "vc3jieeqr3evmgogdgvrs6jonu377sao",
    "title": "Stumping along a summary",
    "info": {
        "author": [
            "Christophe Salperwyck, France Telecom Research",
            "Tanguy Urvoy, France Telecom Research"
        ],
        "published": "July 25, 2011",
        "recorded": "July 2011",
        "category": [
            "Top->Computer Science->Data Mining"
        ]
    },
    "url": "http://videolectures.net/explorationexploitation2011_salperwyck_urvoy_contr/",
    "segmentation": [
        [
            "When I work on this challenge, is there he will present the second part of the presentation.",
            "This is a it's organization is about the stamping around the scenario.",
            "So we are both working in or around Maps.",
            "Which is a."
        ],
        [
            "The company, so the outline of the presentation.",
            "The first one, but I will.",
            "Pretty skip it because it was already planted by.",
            "By Louis.",
            "Then it's our approach is an approach in three years.",
            "First we have an online to marry that we built on the data stream.",
            "So using these at this online summary, then we are creating best predictors.",
            "Anne and then we are the last phases to combine online or this predictor together.",
            "The self doubt is the foundation of our experiment on result, so we are we have the challenge that I set from Adobe.",
            "But as we are also doing advertising in Orange will solve our own data set, so would you try to reuse the same protocol now on that assets?",
            "The last part will be a conclusion and discussion."
        ],
        [
            "Oh yeah, this one.",
            "I'm skipping 'cause it was already."
        ],
        [
            "Ended."
        ],
        [
            "So our approach, so as I tell you to three approach, so the first one is a summary."
        ],
        [
            "Those are the stream.",
            "So there are some challenges constraints which were our limited time 100 millisecond for printing and learning limited memory.",
            "And it was so it was in Java, so we try to avoid it through too many application to be nice with the garbage collector.",
            "So that's why we wanted to have a summary with a small memory footprint which can narrow fast updates and fast queries."
        ],
        [
            "So in terms of was numerical on numenor features, so first we will explain how we do a Sumerian.",
            "The numerical features.",
            "So if you have a static distribution and we want to answer a question like what are the clicks or no clicks counts for future forgiven feature XY in Orange AB?",
            "So to answer these questions from the database community, you have some methods which is was proposed by Green Valley in Canada, which is acidic GK merge and print algorithm which basically do an online inquiry, continues to gram how it works is algorithms algorithm maintains an RF paper view Igy D1.",
            "Basically why is values in the stream GY is a number of value see between V y -- 1 VY.",
            "Which is basically the the higher the histogram, the Taiwan is a error on the high of this histogram, so the good properties of this summary is that it is online and use bonded Marie to build quite Frank.",
            "If they can seize Instagram, it is insensitive to data order and Alta data distribution and have stronger guarantees.",
            "So we.",
            "Resume what we would like to have for building on."
        ],
        [
            "Are predictors on it?",
            "Phone number features.",
            "The main program was too that we didn't know how many values will appear for feature.",
            "So for instance we have some features like client IDs, cookies or city names and can have lots of values.",
            "But at the same time, we don't recall but this rare values because outdated cooking the optimal cities probably done content that much information.",
            "So the solution to deal with that was using hashing, so we were harshing their values into a number fixed number of buckets.",
            "And then just count the number of click and no click inside.",
            "If you want to to improve, it also can be done with several hashing methods as proposed in the continent sketch."
        ],
        [
            "So now that we build the summary of the data, we will build our base predators on it."
        ],
        [
            "So our best predictors where our probability estimation trees, the output of each of them, was a quick rate estimate speech return with Jeannie and pretty.",
            "For numerical features, we use simple decision steps, which have two lives and which give back the left and right estimate.",
            "We also try a deeper unified trees which are gradually unfolding at the new leaves, and then you leave where I did with the data arrival.",
            "Fundamental features, target Ryze, Ashe, temp, which is basically just asking the value and then treat it as a continuous value.",
            "I tried to best versus all, which is just returning the estimate for the best value and if not this value 00.",
            "So.",
            "With this we could do two to kind of classifier, also univariate trees, trees which work just within single feature.",
            "For that we just need a global summary.",
            "With that we can rebuild.",
            "I mean we are the trees can be rebuilt from the summary at each tape and we will also do multivariate trees.",
            "So likely combine several features.",
            "So try to commit try to explain before.",
            "So in that case we need one summary paragraph and then when we find a cut it's a definitive action.",
            "It's much more memory consuming because if the trees is large then you need to have many summaries."
        ],
        [
            "So then we are.",
            "We have this base predictors which most of them were univariate.",
            "So we want to keep combine them together so the output."
        ],
        [
            "So the output is a linear combination of predictions.",
            "Nutrition, usually in that case is to work bad predictors.",
            "For that you can use for example exponential weighting.",
            "Target trade in resource solution, which is an on line in our anchor which which proposes to maximize the AUC.",
            "Another solution can be to use a simpler edging which basically optimize to Macy's nursing so you have the same weight on each predator.",
            "We chose this solution because we couldn't find clear different clear difference with the other.",
            "Nation and at least in that case we can optimize the better our base predictors.",
            "I also try unlike begging which problem proposed by Amazon reseller.",
            "So this is basically what I used to win the solution.",
            "That's also why it's for the.",
            "It's using much more time than the other approach because.",
            "End times begging so it end times time more time to calculate."
        ],
        [
            "So now we will.",
            "Continue and present to the respirations or research.",
            "So yes, we made experiment on two datasets.",
            "We started with Adobe Data sets which is a challenge data set, but we also tried some experiment on our own data set which was made from arrange portal Webmail page.",
            "There is a small difference, but the difference is that the click rate is a bit lower.",
            "And we we had only 33 nominal features in this data set, so we didn't have continuous features."
        ],
        [
            "So let's start with Adobe Data."
        ],
        [
            "Set.",
            "So this curve gives the running of different different strategies the red one, the lowest one is the reward curve for the random strategy, and the best one, the yellow one, is the perfect player is it is a player who know exactly where the click are.",
            "And the other curves are the different strategies we trialed on the different entrant in the challenge.",
            "So in this drawing that we see that the performance of the perfect player is so good that we cannot see the difference between the others.",
            "So we remove."
        ],
        [
            "Move.",
            "And we remove the perfect player.",
            "And here we have also an interesting thing.",
            "We tried several random random seeds and random strategy.",
            "The red and the year is a red on the green one.",
            "There is a lot of violence in the click rate, so here you can see the reward curve in the top and the bottom you can see the instantaneous click rates that was computed with.",
            "Exponential smoothing.",
            "So what we see clearly that we are solution is is better on the reward curve and also if we check on the on the on the click rate.",
            "It's also a bit better.",
            "Mostad mostad lacrate"
        ],
        [
            "Another experiment that we made was to stop learning after half the data was was done.",
            "Just here and here we see the deviation between the red model, which keeps learning and the green one which stop learnings.",
            "We wanted to check if if the distribution was static or if it was the dynamic of their maybe drift in the model.",
            "So clearly if you continue learning you win something, but there is no significant change.",
            "Clearly not clearly significant.",
            "Change."
        ],
        [
            "Another experiment that we made was to train a model on the full data set, so this is the purple One.",
            "This is a discretization model which provides an estimate of the probability.",
            "So we decided to split this feature which was featured.",
            "96 is split the feature in 333 buckets.",
            "We part and it provides a different probabilities here.",
            "And here we checked for different number of different step in the learning learning of the model.",
            "So we tried around 100 clicks.",
            "So we have quite a lot of unstable model and then the model stabilize and converge to something which is quite similar to the global model."
        ],
        [
            "So for Orange bottle that I said."
        ],
        [
            "Act in fact we we try exactly the same experiment with the one that I said and we had very close results.",
            "The two solutions that we checked, which were univariate trees and the best solution also which was a combination of random forests.",
            "The two the two model works quite equivalent.",
            "On this data set also."
        ],
        [
            "This is with perfect player without unlimited perfect player.",
            "That's all that I have to present yes with."
        ],
        [
            "But so to conclude, first we say thank you for this challenge.",
            "It was very fun.",
            "We had a lot of fun in playing with this data.",
            "It was a really interesting simulation scheme.",
            "We were wondering this problem of offline evaluation is very important for us and it was a very good, interesting idea to for get being too realistic in order to have something which works efficiently and.",
            "And this was, I think it is really interesting idea.",
            "And for the experiment we made one thing that we saw that the combination of a summary with Greenwell on Canal merge, Rasputina, gnashing provides a good good foothold for for click prediction.",
            "And surprisingly, the just simple decision stunned, which were very, very basic trees.",
            "They seem to be quite competitive anyway, because because because the data is very noisy, because we had very low click rates, the clicker very rare.",
            "So in the end when if I go back to my experiment we had here."
        ],
        [
            "What we see in this curve.",
            "We had a lot of competitor.",
            "But in fact the purple one is just a combination of some of binary step.",
            "So it's something which is very very very simple.",
            "And it's it was not the best solution we had, but it was very, very correct that that would be a conclusion.",
            "That was maybe because of that that we called the talk.",
            "Stamping along a summary.",
            "And that's all.",
            "Thank you very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "When I work on this challenge, is there he will present the second part of the presentation.",
                    "label": 0
                },
                {
                    "sent": "This is a it's organization is about the stamping around the scenario.",
                    "label": 0
                },
                {
                    "sent": "So we are both working in or around Maps.",
                    "label": 0
                },
                {
                    "sent": "Which is a.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The company, so the outline of the presentation.",
                    "label": 0
                },
                {
                    "sent": "The first one, but I will.",
                    "label": 0
                },
                {
                    "sent": "Pretty skip it because it was already planted by.",
                    "label": 0
                },
                {
                    "sent": "By Louis.",
                    "label": 0
                },
                {
                    "sent": "Then it's our approach is an approach in three years.",
                    "label": 0
                },
                {
                    "sent": "First we have an online to marry that we built on the data stream.",
                    "label": 0
                },
                {
                    "sent": "So using these at this online summary, then we are creating best predictors.",
                    "label": 1
                },
                {
                    "sent": "Anne and then we are the last phases to combine online or this predictor together.",
                    "label": 0
                },
                {
                    "sent": "The self doubt is the foundation of our experiment on result, so we are we have the challenge that I set from Adobe.",
                    "label": 0
                },
                {
                    "sent": "But as we are also doing advertising in Orange will solve our own data set, so would you try to reuse the same protocol now on that assets?",
                    "label": 0
                },
                {
                    "sent": "The last part will be a conclusion and discussion.",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Oh yeah, this one.",
                    "label": 0
                },
                {
                    "sent": "I'm skipping 'cause it was already.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Ended.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So our approach, so as I tell you to three approach, so the first one is a summary.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Those are the stream.",
                    "label": 0
                },
                {
                    "sent": "So there are some challenges constraints which were our limited time 100 millisecond for printing and learning limited memory.",
                    "label": 1
                },
                {
                    "sent": "And it was so it was in Java, so we try to avoid it through too many application to be nice with the garbage collector.",
                    "label": 0
                },
                {
                    "sent": "So that's why we wanted to have a summary with a small memory footprint which can narrow fast updates and fast queries.",
                    "label": 1
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in terms of was numerical on numenor features, so first we will explain how we do a Sumerian.",
                    "label": 0
                },
                {
                    "sent": "The numerical features.",
                    "label": 0
                },
                {
                    "sent": "So if you have a static distribution and we want to answer a question like what are the clicks or no clicks counts for future forgiven feature XY in Orange AB?",
                    "label": 1
                },
                {
                    "sent": "So to answer these questions from the database community, you have some methods which is was proposed by Green Valley in Canada, which is acidic GK merge and print algorithm which basically do an online inquiry, continues to gram how it works is algorithms algorithm maintains an RF paper view Igy D1.",
                    "label": 1
                },
                {
                    "sent": "Basically why is values in the stream GY is a number of value see between V y -- 1 VY.",
                    "label": 1
                },
                {
                    "sent": "Which is basically the the higher the histogram, the Taiwan is a error on the high of this histogram, so the good properties of this summary is that it is online and use bonded Marie to build quite Frank.",
                    "label": 0
                },
                {
                    "sent": "If they can seize Instagram, it is insensitive to data order and Alta data distribution and have stronger guarantees.",
                    "label": 0
                },
                {
                    "sent": "So we.",
                    "label": 0
                },
                {
                    "sent": "Resume what we would like to have for building on.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Are predictors on it?",
                    "label": 0
                },
                {
                    "sent": "Phone number features.",
                    "label": 0
                },
                {
                    "sent": "The main program was too that we didn't know how many values will appear for feature.",
                    "label": 0
                },
                {
                    "sent": "So for instance we have some features like client IDs, cookies or city names and can have lots of values.",
                    "label": 1
                },
                {
                    "sent": "But at the same time, we don't recall but this rare values because outdated cooking the optimal cities probably done content that much information.",
                    "label": 1
                },
                {
                    "sent": "So the solution to deal with that was using hashing, so we were harshing their values into a number fixed number of buckets.",
                    "label": 1
                },
                {
                    "sent": "And then just count the number of click and no click inside.",
                    "label": 0
                },
                {
                    "sent": "If you want to to improve, it also can be done with several hashing methods as proposed in the continent sketch.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now that we build the summary of the data, we will build our base predators on it.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So our best predictors where our probability estimation trees, the output of each of them, was a quick rate estimate speech return with Jeannie and pretty.",
                    "label": 1
                },
                {
                    "sent": "For numerical features, we use simple decision steps, which have two lives and which give back the left and right estimate.",
                    "label": 1
                },
                {
                    "sent": "We also try a deeper unified trees which are gradually unfolding at the new leaves, and then you leave where I did with the data arrival.",
                    "label": 0
                },
                {
                    "sent": "Fundamental features, target Ryze, Ashe, temp, which is basically just asking the value and then treat it as a continuous value.",
                    "label": 0
                },
                {
                    "sent": "I tried to best versus all, which is just returning the estimate for the best value and if not this value 00.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 1
                },
                {
                    "sent": "With this we could do two to kind of classifier, also univariate trees, trees which work just within single feature.",
                    "label": 0
                },
                {
                    "sent": "For that we just need a global summary.",
                    "label": 0
                },
                {
                    "sent": "With that we can rebuild.",
                    "label": 1
                },
                {
                    "sent": "I mean we are the trees can be rebuilt from the summary at each tape and we will also do multivariate trees.",
                    "label": 0
                },
                {
                    "sent": "So likely combine several features.",
                    "label": 0
                },
                {
                    "sent": "So try to commit try to explain before.",
                    "label": 0
                },
                {
                    "sent": "So in that case we need one summary paragraph and then when we find a cut it's a definitive action.",
                    "label": 1
                },
                {
                    "sent": "It's much more memory consuming because if the trees is large then you need to have many summaries.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So then we are.",
                    "label": 0
                },
                {
                    "sent": "We have this base predictors which most of them were univariate.",
                    "label": 0
                },
                {
                    "sent": "So we want to keep combine them together so the output.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the output is a linear combination of predictions.",
                    "label": 1
                },
                {
                    "sent": "Nutrition, usually in that case is to work bad predictors.",
                    "label": 1
                },
                {
                    "sent": "For that you can use for example exponential weighting.",
                    "label": 0
                },
                {
                    "sent": "Target trade in resource solution, which is an on line in our anchor which which proposes to maximize the AUC.",
                    "label": 0
                },
                {
                    "sent": "Another solution can be to use a simpler edging which basically optimize to Macy's nursing so you have the same weight on each predator.",
                    "label": 0
                },
                {
                    "sent": "We chose this solution because we couldn't find clear different clear difference with the other.",
                    "label": 0
                },
                {
                    "sent": "Nation and at least in that case we can optimize the better our base predictors.",
                    "label": 0
                },
                {
                    "sent": "I also try unlike begging which problem proposed by Amazon reseller.",
                    "label": 0
                },
                {
                    "sent": "So this is basically what I used to win the solution.",
                    "label": 0
                },
                {
                    "sent": "That's also why it's for the.",
                    "label": 0
                },
                {
                    "sent": "It's using much more time than the other approach because.",
                    "label": 0
                },
                {
                    "sent": "End times begging so it end times time more time to calculate.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now we will.",
                    "label": 0
                },
                {
                    "sent": "Continue and present to the respirations or research.",
                    "label": 0
                },
                {
                    "sent": "So yes, we made experiment on two datasets.",
                    "label": 0
                },
                {
                    "sent": "We started with Adobe Data sets which is a challenge data set, but we also tried some experiment on our own data set which was made from arrange portal Webmail page.",
                    "label": 1
                },
                {
                    "sent": "There is a small difference, but the difference is that the click rate is a bit lower.",
                    "label": 1
                },
                {
                    "sent": "And we we had only 33 nominal features in this data set, so we didn't have continuous features.",
                    "label": 1
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's start with Adobe Data.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Set.",
                    "label": 0
                },
                {
                    "sent": "So this curve gives the running of different different strategies the red one, the lowest one is the reward curve for the random strategy, and the best one, the yellow one, is the perfect player is it is a player who know exactly where the click are.",
                    "label": 0
                },
                {
                    "sent": "And the other curves are the different strategies we trialed on the different entrant in the challenge.",
                    "label": 0
                },
                {
                    "sent": "So in this drawing that we see that the performance of the perfect player is so good that we cannot see the difference between the others.",
                    "label": 0
                },
                {
                    "sent": "So we remove.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Move.",
                    "label": 0
                },
                {
                    "sent": "And we remove the perfect player.",
                    "label": 1
                },
                {
                    "sent": "And here we have also an interesting thing.",
                    "label": 0
                },
                {
                    "sent": "We tried several random random seeds and random strategy.",
                    "label": 0
                },
                {
                    "sent": "The red and the year is a red on the green one.",
                    "label": 0
                },
                {
                    "sent": "There is a lot of violence in the click rate, so here you can see the reward curve in the top and the bottom you can see the instantaneous click rates that was computed with.",
                    "label": 0
                },
                {
                    "sent": "Exponential smoothing.",
                    "label": 0
                },
                {
                    "sent": "So what we see clearly that we are solution is is better on the reward curve and also if we check on the on the on the click rate.",
                    "label": 0
                },
                {
                    "sent": "It's also a bit better.",
                    "label": 0
                },
                {
                    "sent": "Mostad mostad lacrate",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another experiment that we made was to stop learning after half the data was was done.",
                    "label": 0
                },
                {
                    "sent": "Just here and here we see the deviation between the red model, which keeps learning and the green one which stop learnings.",
                    "label": 0
                },
                {
                    "sent": "We wanted to check if if the distribution was static or if it was the dynamic of their maybe drift in the model.",
                    "label": 0
                },
                {
                    "sent": "So clearly if you continue learning you win something, but there is no significant change.",
                    "label": 0
                },
                {
                    "sent": "Clearly not clearly significant.",
                    "label": 0
                },
                {
                    "sent": "Change.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another experiment that we made was to train a model on the full data set, so this is the purple One.",
                    "label": 0
                },
                {
                    "sent": "This is a discretization model which provides an estimate of the probability.",
                    "label": 0
                },
                {
                    "sent": "So we decided to split this feature which was featured.",
                    "label": 0
                },
                {
                    "sent": "96 is split the feature in 333 buckets.",
                    "label": 0
                },
                {
                    "sent": "We part and it provides a different probabilities here.",
                    "label": 0
                },
                {
                    "sent": "And here we checked for different number of different step in the learning learning of the model.",
                    "label": 0
                },
                {
                    "sent": "So we tried around 100 clicks.",
                    "label": 0
                },
                {
                    "sent": "So we have quite a lot of unstable model and then the model stabilize and converge to something which is quite similar to the global model.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for Orange bottle that I said.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Act in fact we we try exactly the same experiment with the one that I said and we had very close results.",
                    "label": 0
                },
                {
                    "sent": "The two solutions that we checked, which were univariate trees and the best solution also which was a combination of random forests.",
                    "label": 0
                },
                {
                    "sent": "The two the two model works quite equivalent.",
                    "label": 0
                },
                {
                    "sent": "On this data set also.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is with perfect player without unlimited perfect player.",
                    "label": 0
                },
                {
                    "sent": "That's all that I have to present yes with.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But so to conclude, first we say thank you for this challenge.",
                    "label": 1
                },
                {
                    "sent": "It was very fun.",
                    "label": 0
                },
                {
                    "sent": "We had a lot of fun in playing with this data.",
                    "label": 1
                },
                {
                    "sent": "It was a really interesting simulation scheme.",
                    "label": 0
                },
                {
                    "sent": "We were wondering this problem of offline evaluation is very important for us and it was a very good, interesting idea to for get being too realistic in order to have something which works efficiently and.",
                    "label": 0
                },
                {
                    "sent": "And this was, I think it is really interesting idea.",
                    "label": 0
                },
                {
                    "sent": "And for the experiment we made one thing that we saw that the combination of a summary with Greenwell on Canal merge, Rasputina, gnashing provides a good good foothold for for click prediction.",
                    "label": 1
                },
                {
                    "sent": "And surprisingly, the just simple decision stunned, which were very, very basic trees.",
                    "label": 0
                },
                {
                    "sent": "They seem to be quite competitive anyway, because because because the data is very noisy, because we had very low click rates, the clicker very rare.",
                    "label": 0
                },
                {
                    "sent": "So in the end when if I go back to my experiment we had here.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What we see in this curve.",
                    "label": 0
                },
                {
                    "sent": "We had a lot of competitor.",
                    "label": 0
                },
                {
                    "sent": "But in fact the purple one is just a combination of some of binary step.",
                    "label": 0
                },
                {
                    "sent": "So it's something which is very very very simple.",
                    "label": 0
                },
                {
                    "sent": "And it's it was not the best solution we had, but it was very, very correct that that would be a conclusion.",
                    "label": 0
                },
                {
                    "sent": "That was maybe because of that that we called the talk.",
                    "label": 0
                },
                {
                    "sent": "Stamping along a summary.",
                    "label": 0
                },
                {
                    "sent": "And that's all.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                }
            ]
        }
    }
}