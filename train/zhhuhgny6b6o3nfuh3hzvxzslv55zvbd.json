{
    "id": "zhhuhgny6b6o3nfuh3hzvxzslv55zvbd",
    "title": "What to do about M-open? A decision theoretic (distribution free) solution",
    "info": {
        "author": [
            "Christopher Holmes, Oxford Centre for Gene Function, University of Oxford"
        ],
        "published": "Jan. 24, 2012",
        "recorded": "December 2011",
        "category": [
            "Top->Computer Science->Machine Learning->Bayesian Learning"
        ]
    },
    "url": "http://videolectures.net/nipsworkshops2011_holmes_decision/",
    "segmentation": [
        [
            "So this is slightly.",
            "You know slightly outside the stuff that's been being discussed today, it's do with foundations of Bayesian inference, and it's to do with the problem, which you might not have known about and a solution.",
            "So in one sense I'm going to tell you about a problem you didn't know you had, but then I'm going to solve it for you so you only have 10 minutes of warrior.",
            "OK, and it's to do with this notion of M open.",
            "Which is the elephant in the room.",
            "I think for Bayesian for Bayesian inference or Bayesian statisticians and this is joint work with Stephen Walker at the University of Kent, and I'm in Department of Statistics at Oxford as well as.",
            "Welcome trust center Human Genetics."
        ],
        [
            "And here's the motivating example.",
            "It's very kind of simple.",
            "Example is the kind of problems I would often work on, and it goes like this.",
            "OK, so suppose you wish to infer the median patient survival time, so I'm interested in estimating or make an inference or or making statements of my belief about survival time, the median survival time for a particular cancer, say.",
            "Yeah, an F node is some unknown distribution you don't know obviously what these survival times follow.",
            "Suppose you hold subjective beliefs.",
            "You've got some prior beliefs about where that median might be.",
            "You don't believe that F nought follow some parametric form.",
            "You're not going to assume that it's why bull or gamma, for example.",
            "And you're going to, you know you're going to obtain some uncensored, say observations of survival time.",
            "And we want to be Bayesian and what I want to do is update my beliefs about \u03c0.",
            "Fly here to express posterior beliefs.",
            "And the simple question is, how can we do this in a in a kind of coherent manner?",
            "OK, here in inference manner."
        ],
        [
            "K. So.",
            "What's the nonparametric solution to this problem?",
            "Well, you know the nonparametric solution is well, if you don't know what F nought is, you know we're going to introduce a prior which has very wide support.",
            "So nonparametric prior on F. Which we could update given the observations and then I can form my beliefs about the median survival time by integrating over the posterior of all measures under support of my prior.",
            "As such but it seems a little bit to me, it seems a little bit cumbersome from 2 perspectives.",
            "Well, first of all, you know I started off with just trying to express beliefs about the median.",
            "It's very kind of simple statement of beliefs, and yet I'm forced into this express in a prior over the space of all possible densities.",
            "So that seems a little bit unwieldly.",
            "And Secondly, we know that all models are wrong.",
            "And and this is really the question, this is where the M Open part comes in, and if all models are wrong.",
            "What does \u03c0 of F?",
            "What is your posterior distribution actually represent?",
            "OK."
        ],
        [
            "OK, so to generalize this slightly, we are now going to consider theater to index a set of probabilistic models.",
            "So this would be a standard sampling distribution, or you can think of it as your likelihood.",
            "Well, what do we know?",
            "What we know?",
            "Bayesian inference is a closed hypothesis space, which means that both the prior and posterior obviously integrate to one.",
            "And the strong interpretation of that is that with probability one, you believe that fnord, the unknown sampling distribution of your data is contained within the support of your prior.",
            "So in words, in order to do Bayesian inference, you have to believe that F nought the true data generating mechanism.",
            "I nature is contained under the support of your model.",
            "Your prior OK. And if that's the case, if you really do believe this, you know there are certain situations in simulation where you might do and then this is known as enclosed and it's discussed in some detail in Bernardo and Smith's book on Bayesian theory."
        ],
        [
            "OK, but and of course you know if you believe that all models are wrong.",
            "Then formally, the probability that natures sampling distribution is equal to equivalent to one of your the sampling distributions for a setting of your prior is 0, then affectively it means that your prior on theater is 0.",
            "OK, and you re damn open.",
            "OK, so F nought lies outside of the support of your prior and therefore your true prior on theater is 0.",
            "And we.",
            "And you know you're stuck at that point.",
            "OK."
        ],
        [
            "And so the question that we've been thinking about for the last couple of years, Steven and I is, you know, how should inference proceed when none of the models are true?",
            "Yeah, so how can we formally proceed when we don't believe that we have the true model under the support of our prior and we had some nice discussion today from Igor about some of the consistent season about prize that have wide support.",
            "But often when we're in regression settings, we still even under these very kind of beautiful nonparametric priors, we still don't actually believe that we're capturing nature precisely.",
            "And so we are interested in providing a decision theoretic solution to this problem without recourse to true parameterized models.",
            "And a byproduct of this and This is why you can kind of.",
            "Hey there.",
            "Go home happy is that you could actually derive Bayes theorem under much weaker conditions than having the true model under your prior.",
            "You need a slightly weaker condition, which is one of model sufficiency rather than the closed hypothesis space."
        ],
        [
            "OK, so you know where do we really start from?",
            "Well, of course you know we all know.",
            "We all know that all models are wrong.",
            "You know, but some are useful and you know this very famous quote from George Box.",
            "And so when we're thinking of this from a decision theoretic perspective already, from any perspective, we say a model is useful.",
            "You know precisely what do we mean by that statement.",
            "OK, so we use a model of course because it's useful.",
            "What do we mean by by useful?",
            "Well, we're using the model for some purpose.",
            "And in a sense, every respective of whether the model is true or not.",
            "You know action still need to be taken.",
            "So for me, you know, looking at genetic loci for looking in randomized clinical trials where the prover, drug, etc etc.",
            "And so when we say a model is useful from the perspective of this talk, we're going to say model is useful if it aids in some decision process.",
            "So I'm using the model to a decision process."
        ],
        [
            "And so to formalize this, suppose we have unstructured information.",
            "We have data.",
            "We could Aksumite exchangeable, say, X1 to XN, and it is as decision makers we are benefiting from using a model.",
            "Rather than the raw information.",
            "OK, so we have your or information contained in a data matrix.",
            "And here we can think of the model is just as an output from some computer program.",
            "So myself as a decision maker I benefit from stuffing the information into a model into a computer algorithm and looking at the output.",
            "OK. Now clearly information can be neither gained.",
            "Well, it can only be lost.",
            "Yeah, by just considering the output, save some summary statistics and so really hear the model.",
            "Theater taking input.",
            "I is chosen serves to kind of distill or compress those aspects of the information which are most relevant to the decision task, and that's why we, you know, that's why we model while we don't just look at raw information, look at just data."
        ],
        [
            "OK then.",
            "And so in fitting the model, we're going to assume that there is some target value.",
            "Which were going tonight theater nought?",
            "That we are hoping to learn about.",
            "And we're going to be precise about this.",
            "Is that what we're going to do is we're going to assume that in the limit of infinite information, so says my sample size goes to Infinity, then this optimal value of Theta is revealed by the model.",
            "OK, so for me Theater 0 is the output from my computer program.",
            "Given an infinite amount of information.",
            "OK, so trivial example.",
            "Suppose my computer program is computing a logistic regression model.",
            "Or, as you know, a simple classification model.",
            "Then Theatre 0 would be say the dependent on your model would be say, the maximum likelihood estimate or the maximum posteriori estimate as the sample size tended to Infinity.",
            "I if you know if you could, my study could contain every individual available."
        ],
        [
            "OK, so now we're going to.",
            "Introduced this notion of model sufficiency.",
            "So we say that a model.",
            "Is sufficient for the decision process.",
            "If, in the limit of infinite information, the output from the model is a sufficient statistic for the decision process.",
            "OK. A consequence of this is that should that value that you're targeting, Thetan ought ever become known to you.",
            "Then the inference task is solved.",
            "And the optimal action.",
            "Say on the space of the utility on the space of actions given theater North is revealed.",
            "OK hi.",
            "Could you clarify what you mean by sufficient for the decision process as it means to computer posteriorly?",
            "It means that this is the kind of the way to think about it.",
            "Yeah, if you choose to say user logistic regression model or whatever the model it is.",
            "Yeah, if I tell you where your PSU where your posterior will converge to.",
            "Under an infinite sample size, then you would not need to perform the experiment and you would happily walk away choosing your optimal action.",
            "Yeah, so if I told you if I told you where your Bayesian posterior would converge to under an infinite sample size, you wouldn't need to run.",
            "You wouldn't need to do your inference task.",
            "Yeah, you would know.",
            "Where the optimal value of theater Nord is.",
            "OK, so in this sense theater note can be thought of as a sufficient statistic for the decision task and the remaining information.",
            "In I is ancilla RE.",
            "OK, and so.",
            "In order to for us to make headway into M open, what I'm going to say is that when you when you choose to use a model, you're happy with this statement.",
            "Yeah, you're happy using that model in so much that if I gave you an infinite amount of information, you know as a Bayesian you're not allowed to change your model.",
            "Are you the model you adopt?",
            "Shouldn't depend on how much or how little information you gain the data you're going to work with.",
            "But the choice of the model is saying I'm happy that in the limit of infinite information I could choose the optimal action.",
            "In front of me.",
            "OK, so that's our notion of model sufficiency.",
            "We're going to select a sufficient model.",
            "The model that's sufficient."
        ],
        [
            "The decision process.",
            "Hi, could you give an example of when that wouldn't be true and trying to understand why is it?"
        ],
        [
            "Be happy because you assume that model is true.",
            "I'm not quite sure I so I can imagine it wouldn't be true is that if I.",
            "Suppose you had a logistic regression classifier.",
            "And you started working on some finite data and you know Bayes ghost descended on you and told you that that theater, nor was this that.",
            "Would you really walk away?",
            "You kind of attempted to to do something else.",
            "Yeah, to fit another model perhaps.",
            "So I'm saying that.",
            "That we have to be under this principle is strong principle of model sufficiency and would we ever.",
            "The other questions we had entering, where this would clearly be true.",
            "Freddy parametric model maker.",
            "Um?",
            "Well, what I'm saying is, is that it currently is empirically true, because people adopt models and make decisions based on the output of the model.",
            "Yeah, I'm formalizing this by saying that that statement has to be that if I gave you an infinite amount of information, you'd be happy to use that model.",
            "Yeah, in fact, in practice, of course, Bayesians choose their model based on how much data they're going to get.",
            "If I tell you I'm going to give you 10 data points, or you know 5 billion data points, people normally choose their models differently, But in theory they shouldn't, yeah.",
            "OK."
        ],
        [
            "So, so now the interpretation of your prior is going to change.",
            "Yeah, and your interpretation of your pry or subjective beliefs is in the unknown value of theater nought that yields the optimal decisions.",
            "So your prior on theater is going to be the probability that in the infinite amount of information the say the posterior is going to converge to this particular point.",
            "Yeah, and that's fundamentally different from the conventional construction of a prior so piously to no longer represents your beliefs about the true F nought, as you don't believe the model is true.",
            "It's simply about the optimal values.",
            "Say that the posterior concentrates to theater nought in the limit of infinite information.",
            "OK, so that's what your price is going to be, and so so a natural question is, well, does that?",
            "Does that point theater not have any any meaning?",
            "Or strong meaning with respect to what nature is the true sampling distribution F nought?",
            "Well."
        ],
        [
            "Well, we know that for most kind of regular models.",
            "That that's eaten or has kind of has strong interpretation so well motivated target is theater nought.",
            "Within my parametric or even nonparametric prior index by Theta is going to minimize.",
            "I wish to target the theater North that minimizes the Kullback Leibler divergent between the true.",
            "Unknown sampling distribution F nought and the one contained within my model space so theater is going to tend to the point in your model space which brings your sampling distribution closest to nature.",
            "Sampling distribution under Kullback Leibler divergent.",
            "And so here your prior represents.",
            "You probably saw the value of theater that minimizes the KL divergent's you know.",
            "And Moreover if you use Bayesian inference with a proxy likelihood because you don't believe that the data really comes.",
            "You know you don't believe that you have the true model so so so F of X given theater is just a proxy.",
            "We know that, for example, the maximum likelihood estimate.",
            "One of the robustness properties of Emily's as well as of M. APS is that they minimize the Kullback Leibler divergent between F nought and F data.",
            "So in other words, your Bayesian map, typically under an infinite sample size, will or maximum likelihood estimate will just minimize kullback Leibler divergent."
        ],
        [
            "OK, so so so that part of it is kind of covered the prior, so we've now changed our interpretation of the prior.",
            "Well now we're going to need to change our interpretation of the likelihood because having defined what Pi theater is we wish to update it.",
            "Based on information and we can't use F of X given Theta because we don't believe that X comes from F of X given Theta.",
            "OK, so we can't use Bayes theorem OK.",
            "However, what you can do is try and proceed.",
            "If all out, well, not even if all else fails, you should you go back to decision theory.",
            "Which is can we proceed in a coherent manner?",
            "Yeah, so I have a. I have a product represents my beliefs.",
            "I have some information and I wish to proceed to update my beliefs coherently.",
            "And a coherent thing to do from a decision theoretic perspective, is to define a loss function on the space of all probability measure well on the space of measures over theater.",
            "Yeah, the quantify the relative utility of the model of the probability measure.",
            "I'm going to call that \u03c0 star.",
            "Over theater, given the information in the data and your prior beliefs.",
            "And what we're going to do now is we're now going to select a posterior measure.",
            "That maximizes that offers best beliefs that represents your best beliefs about the value of theater nought in light of information.",
            "We're gonna assume additivity of loss, yeah, namely that the loss between the posterior measure.",
            "So Pi Staff theater is going to be your posterior update.",
            "The update on theater given information, and we're going to say that there's a component of the loss which relates the posterior to the information in the data, and a component that relates to loss to the prior.",
            "I'm with then going to select your optimal pie star, which minimizes your expected loss, and that's the formal way to proceed.",
            "The decision theoretic way to proceed."
        ],
        [
            "OK.",
            "So if we assume that the information arises as individual pieces of data X1 to XN.",
            "We're going to assume a log additive loss function, so we're going to say that the loss between the posterior measure \u03c0 star and the information in the data can be decomposed into a sum and additive sum of loss functions for individual units of data XI.",
            "\u03a0 Star is a probability measure on theater, and so how can we govern?",
            "Or how can we?",
            "How can we express our loss in a posterior measure with respect to a single piece of information while Pi star is over is a posterior on Theta and we're going to take the appropriate loss to be given by its expectation.",
            "Yeah, so you can think of this loss function is recording the expected relative loss in replacing the information in XI with this \u03c0 star."
        ],
        [
            "So, So what might that loss function looks like?",
            "Well, if we believe we have a good proxy model for F nought, or if you're saying FM close.",
            "So if you if you believe that you have the true model, then the natural choice for this for this loss function is the self information loss, and in fact it's the honest loss function.",
            "So this is what's derived from a proper local scoring rule high.",
            "Loss function distinct from the loss function that you're eventually going to be using.",
            "To get to get your posterior because I mean, I'm kind of thinking that if they were the same then you may be kind of.",
            "Buy a senior results towards in the 1st place you fight.",
            "You would be biased in your likelihood towards cheating.",
            "The results.",
            "Are you going to want to achieve and?",
            "Yeah."
        ],
        [
            "This has to be an honest so in any indecision theory this has to be an honest loss function that represents your subjective beliefs about the information in XI.",
            "With respect to \u03c0 star.",
            "Would you be reiterating this information and later on using your 'cause?",
            "I'm assuming that in a Bayesian framework you would be using it last function to to find your your posterior that separate here.",
            "So what you do with your posterior pipi star theater given data.",
            "That's a different game.",
            "That's a different aspect of using loss functions and utility.",
            "If you're using a loss function to capture your likelihood, what the choice of loss function affect your or limit your choices loss function later on to find a posterior distribution.",
            "No, I don't see I don't see why why that should.",
            "Yeah.",
            "So this just has two to measure.",
            "Well, it's really.",
            "It's this, it's it's.",
            "You're recording your subjective beliefs about the information in a data more a unit of data relative to.",
            "The posterior measure or your posterior beliefs about where theater North lies.",
            "So if you believe that."
        ],
        [
            "If you believe you're in enclosed, then you're forced into using something like self information loss.",
            "If you're being honest.",
            "OK, and then the loss function just looks like the negative log likelihood or your negative log sampling density.",
            "So equally and the example I'll show later on for survival analysis.",
            "You can use partial likelihood or partial loss, so if you believe that only part of the information in the data is has utility for your decision process, you only have to put a loss on those aspects of the data that you believe are relevant.",
            "The key point is that this loss, relative to theater nought is relative to theater, not which is the sufficient model for your decision."
        ],
        [
            "OK. For coherency, it turns out and this is where I kind of joined the story.",
            "So Steven has a very nice technical paper on that.",
            "The use of kullback Leiber loss.",
            "For updating information, yeah.",
            "And so it turns out that Kullback Leibler loss is the only loss function that you can use.",
            "What to maintain coherency.",
            "And by that I mean that if I gave you one data set.",
            "Or if I gave you 2 datasets, which was just that single data set broken into half.",
            "Yeah, then for coherency we would want the updating to be the same.",
            "Yeah, so if I give you a prior, you update with the first data set and then you take your posterior from that as your prior into your next data set.",
            "Then that has to be the same as having the problem with the whole data set to start with and the callback library loss is the only one that can give you that that coherency property.",
            "So the loss to the prior from the posterior to the prior, we're going to take to be callback librar.",
            "OK, and so here \u03c0 starter I is the records Fidelity to the data and PY startapp.",
            "I records Fidelity to the prime.",
            "So."
        ],
        [
            "What we're doing is where we kind of were trying to select.",
            "An optimal posterior measure that represents best beliefs.",
            "And we say we want pie start to minimize this loss, and if you just put this in and and fiddle around a bit.",
            "It's straightforward to show that the Pi star that minimizes the loss is given by the minimum of the Kullback Leibler divergent between the prior times.",
            "The exponentiated negative log loss, and this is now starting to look very familiar.",
            "And so in particular."
        ],
        [
            "Under this decision theoretic construction, you are led to to select this \u03c0 star.",
            "As your best updated beliefs for theater.",
            "So to Bayesians, when you would look at this, you know this looks like standard likelihood times prior, and this would be your integrated marginal likelihood.",
            "Well, this has some slightly different meaning here.",
            "This is a kind of a prior predictive utility or as an integrative loss with respect to the prior.",
            "But, crucially, we do not have to assume I'm close to get to this position.",
            "OK."
        ],
        [
            "So some points to note here.",
            "If you really believe that you are, you have a true model contained under your prior be at nonparametric prior or parametric prior, then you're led to use the negative log likelihood and you recover Bayes theorem.",
            "However, this has been obtained under much weaker conditions, just loss functions, just loss functions of Fidelity of data to the posterior, and loss functions of Fidelity to the prior to the posterior.",
            "And in particular, we just treat the priors another piece of information has the same kind of meaning as.",
            "This is the data, yeah?",
            "And Moreover, when only certain aspects of the data are relevant to the decision task, you're free to define partial loss functions.",
            "So in particular, you can define a partial likelihood loss, saying survival analysis and get more general Bayesian updated.",
            "It also allows for other tricky things for a pure subjective things like model checking, you know we know, look formally, you're not allowed to do model checking under Bayesian inference.",
            "Of course you'd be a fool if you didn't, but but formally you're not allowed to because your priors, your pry it, cetera."
        ],
        [
            "OK, and so Canonical forms for the loss might be self information, partial log likelihood.",
            "Or equally you can use other things like robust estimating equations if you want if your loss.",
            "Wants to be down weighted relative to say outliers."
        ],
        [
            "OK, so I'm just going to, I've got a few minutes just quickly just talk you through just one illustration.",
            "So this is how this is kind of a motivating example in survival analysis and how we can use this to really to do general Bayesian updating and how it could help.",
            "So here.",
            "I'm interested in the variable selection problem, so I have some data, some time to event data under sensor in an.",
            "I'm interested I have some covariates and I'm interested which covariates to say relevant to the time to event to distinguish in variation in time to event.",
            "And this is a bit taken from a particular data set from Rossi, and it's on prisoner reoffending rates, so these were prisoners released.",
            "They were followed for 50 for a year, 52 weeks following release, and so the response data is the week of release.",
            "Or whether they just left the study that censoring as well as they could either be an event I if they re arrested or if you get to the end of the study and they weren't rearrested then you get a zero.",
            "Yeah and they treat that as right censoring, which is like a little bit harsh 'cause it means at some point they would get arrested, yeah?",
            "But anyhow, so we're going to treat that as just right censored data."
        ],
        [
            "And then we have some set of covariates, whether they receive financial aid, how old they are, whether they had work experience, whether they were married.",
            "Number of prod, convention, convictions etc etc.",
            "OK."
        ],
        [
            "So, so the point to note here is that if you were doing this full Bayesian survival analysis, we've got this tricky thing that if we want to use a log linear proportional hazards just a standard Cox proportional hazards model, we have this nasty baseline hazard rate here.",
            "And as Bayesians you kind of forced A to assume you have the true model and be you've got to put a prior over it of course.",
            "So H dot is the baseline hazard.",
            "So people do this and they put these.",
            "You know, very elegant nonparametric measures over this baseline hazard.",
            "But they can be not.",
            "I won't say unwieldly, but the reason why Cox proportional hazards is so widely used is that they treat H and orders a nuisance process and just concentrate inference on, say, the regression coefficients in here.",
            "So under the framework we've just presented with free, if H nought.",
            "Is ancillary to the decision process I if I was prepared to make a decision based on the output of a Cox proportional hazard model under infinite information, then I'm then I'm perfectly valid to drop this.",
            "Yeah, to drop this in my loss function to the data which we do and we get a partial loss."
        ],
        [
            "And then, given that we can just do spike and slab priors and examine the posterior distribution of a variable being important to that, we look at the posterior best posterior measure on the import."
        ],
        [
            "And the key thing here is that that that partial loss uses this integrated utility log utility rather than being formally a marginal likelihood.",
            "And then you can implement this in reversible jump MCMC.",
            "Not if you do."
        ],
        [
            "That and you kind of you can do kind of efficient updating, so this is just a trivial little sampler and we can see that it's you know moving around the space and."
        ],
        [
            "Get.",
            "Posterior probabilities or best posterior probabilities about the inclusion probabilities.",
            "And So what we can see here is that age seems to be very important.",
            "Prior convictions is very important.",
            "Marriage is slightly more important than work experience, etc.",
            "There's some kind of randomized control trial.",
            "I thought you could continue.",
            "Yeah, prisoners you make them get married or they do work experience you can.",
            "I'm sure ethics wouldn't approve all mighty hard to gain on on that but."
        ],
        [
            "OK, so so just a couple of points and then to wrap up.",
            "So one thing I think is interesting is that if you drop the loss to the prior.",
            "The app, so if we say OK, I'm going to take no loss to my prior beliefs.",
            "I'm going to now minimize my posterior with respect to the information in the data.",
            "And what that leads to is all of your posterior measure collapsing around the Emily.",
            "That is, after a single observation, your best beliefs about Theta lie at the maximum likelihood estimate, and that's clearly kind of incoherent and not to be advocated."
        ],
        [
            "The second point to note is that if you if you use a flat prior.",
            "Yeah, then then what this what we minimize the kullback Leibler divergent's what we see is you end up with Pi Hat star which maximizes the utility to the data subject to an entropy penalty.",
            "OK, and so look at the likelihood function as a normalized posterior measure is equivalent to use in a loss which maximizes this posterior loss with respect to this entropy constraint."
        ],
        [
            "OK, there's lots of.",
            "This is my final slide.",
            "There's lots of open questions and current work that we're working on.",
            "I think one way to think about this is there's clear connections with penalized likelihood or penalized log likelihood methods, so you know lasuen splines.",
            "So in those situations, you try and find an optimal theater which maximizes the likelihood.",
            "Subject is concerned, some constraint and one kind of interested interpretation of Bayesian inference is actually.",
            "What you're trying to do is is trying to try to find a posterior measure.",
            "So rather than trying to maximize the point you're trying to maximize the probability measure, and so all that I've kind of presented it.",
            "You can think of is trying to select a probability measure which maximizes your information in the data, plus are kind of a penalty which comes from prior information.",
            "This normalizing constant, which is so important to Bayesian inference, you know the evidance or marginal likelihood here has this kind of notion of a normalized expected utility, and so I think there's lots of interesting things to be done.",
            "There's some other problems, open questions and but I'd like to stop and thank you for listening, thanks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is slightly.",
                    "label": 0
                },
                {
                    "sent": "You know slightly outside the stuff that's been being discussed today, it's do with foundations of Bayesian inference, and it's to do with the problem, which you might not have known about and a solution.",
                    "label": 0
                },
                {
                    "sent": "So in one sense I'm going to tell you about a problem you didn't know you had, but then I'm going to solve it for you so you only have 10 minutes of warrior.",
                    "label": 0
                },
                {
                    "sent": "OK, and it's to do with this notion of M open.",
                    "label": 0
                },
                {
                    "sent": "Which is the elephant in the room.",
                    "label": 0
                },
                {
                    "sent": "I think for Bayesian for Bayesian inference or Bayesian statisticians and this is joint work with Stephen Walker at the University of Kent, and I'm in Department of Statistics at Oxford as well as.",
                    "label": 1
                },
                {
                    "sent": "Welcome trust center Human Genetics.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And here's the motivating example.",
                    "label": 1
                },
                {
                    "sent": "It's very kind of simple.",
                    "label": 0
                },
                {
                    "sent": "Example is the kind of problems I would often work on, and it goes like this.",
                    "label": 0
                },
                {
                    "sent": "OK, so suppose you wish to infer the median patient survival time, so I'm interested in estimating or make an inference or or making statements of my belief about survival time, the median survival time for a particular cancer, say.",
                    "label": 1
                },
                {
                    "sent": "Yeah, an F node is some unknown distribution you don't know obviously what these survival times follow.",
                    "label": 1
                },
                {
                    "sent": "Suppose you hold subjective beliefs.",
                    "label": 0
                },
                {
                    "sent": "You've got some prior beliefs about where that median might be.",
                    "label": 1
                },
                {
                    "sent": "You don't believe that F nought follow some parametric form.",
                    "label": 0
                },
                {
                    "sent": "You're not going to assume that it's why bull or gamma, for example.",
                    "label": 1
                },
                {
                    "sent": "And you're going to, you know you're going to obtain some uncensored, say observations of survival time.",
                    "label": 1
                },
                {
                    "sent": "And we want to be Bayesian and what I want to do is update my beliefs about \u03c0.",
                    "label": 0
                },
                {
                    "sent": "Fly here to express posterior beliefs.",
                    "label": 0
                },
                {
                    "sent": "And the simple question is, how can we do this in a in a kind of coherent manner?",
                    "label": 0
                },
                {
                    "sent": "OK, here in inference manner.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "K. So.",
                    "label": 0
                },
                {
                    "sent": "What's the nonparametric solution to this problem?",
                    "label": 0
                },
                {
                    "sent": "Well, you know the nonparametric solution is well, if you don't know what F nought is, you know we're going to introduce a prior which has very wide support.",
                    "label": 0
                },
                {
                    "sent": "So nonparametric prior on F. Which we could update given the observations and then I can form my beliefs about the median survival time by integrating over the posterior of all measures under support of my prior.",
                    "label": 0
                },
                {
                    "sent": "As such but it seems a little bit to me, it seems a little bit cumbersome from 2 perspectives.",
                    "label": 0
                },
                {
                    "sent": "Well, first of all, you know I started off with just trying to express beliefs about the median.",
                    "label": 1
                },
                {
                    "sent": "It's very kind of simple statement of beliefs, and yet I'm forced into this express in a prior over the space of all possible densities.",
                    "label": 0
                },
                {
                    "sent": "So that seems a little bit unwieldly.",
                    "label": 0
                },
                {
                    "sent": "And Secondly, we know that all models are wrong.",
                    "label": 1
                },
                {
                    "sent": "And and this is really the question, this is where the M Open part comes in, and if all models are wrong.",
                    "label": 0
                },
                {
                    "sent": "What does \u03c0 of F?",
                    "label": 0
                },
                {
                    "sent": "What is your posterior distribution actually represent?",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so to generalize this slightly, we are now going to consider theater to index a set of probabilistic models.",
                    "label": 1
                },
                {
                    "sent": "So this would be a standard sampling distribution, or you can think of it as your likelihood.",
                    "label": 0
                },
                {
                    "sent": "Well, what do we know?",
                    "label": 0
                },
                {
                    "sent": "What we know?",
                    "label": 0
                },
                {
                    "sent": "Bayesian inference is a closed hypothesis space, which means that both the prior and posterior obviously integrate to one.",
                    "label": 1
                },
                {
                    "sent": "And the strong interpretation of that is that with probability one, you believe that fnord, the unknown sampling distribution of your data is contained within the support of your prior.",
                    "label": 1
                },
                {
                    "sent": "So in words, in order to do Bayesian inference, you have to believe that F nought the true data generating mechanism.",
                    "label": 0
                },
                {
                    "sent": "I nature is contained under the support of your model.",
                    "label": 0
                },
                {
                    "sent": "Your prior OK. And if that's the case, if you really do believe this, you know there are certain situations in simulation where you might do and then this is known as enclosed and it's discussed in some detail in Bernardo and Smith's book on Bayesian theory.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, but and of course you know if you believe that all models are wrong.",
                    "label": 1
                },
                {
                    "sent": "Then formally, the probability that natures sampling distribution is equal to equivalent to one of your the sampling distributions for a setting of your prior is 0, then affectively it means that your prior on theater is 0.",
                    "label": 0
                },
                {
                    "sent": "OK, and you re damn open.",
                    "label": 1
                },
                {
                    "sent": "OK, so F nought lies outside of the support of your prior and therefore your true prior on theater is 0.",
                    "label": 1
                },
                {
                    "sent": "And we.",
                    "label": 0
                },
                {
                    "sent": "And you know you're stuck at that point.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so the question that we've been thinking about for the last couple of years, Steven and I is, you know, how should inference proceed when none of the models are true?",
                    "label": 1
                },
                {
                    "sent": "Yeah, so how can we formally proceed when we don't believe that we have the true model under the support of our prior and we had some nice discussion today from Igor about some of the consistent season about prize that have wide support.",
                    "label": 0
                },
                {
                    "sent": "But often when we're in regression settings, we still even under these very kind of beautiful nonparametric priors, we still don't actually believe that we're capturing nature precisely.",
                    "label": 0
                },
                {
                    "sent": "And so we are interested in providing a decision theoretic solution to this problem without recourse to true parameterized models.",
                    "label": 1
                },
                {
                    "sent": "And a byproduct of this and This is why you can kind of.",
                    "label": 0
                },
                {
                    "sent": "Hey there.",
                    "label": 1
                },
                {
                    "sent": "Go home happy is that you could actually derive Bayes theorem under much weaker conditions than having the true model under your prior.",
                    "label": 0
                },
                {
                    "sent": "You need a slightly weaker condition, which is one of model sufficiency rather than the closed hypothesis space.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so you know where do we really start from?",
                    "label": 0
                },
                {
                    "sent": "Well, of course you know we all know.",
                    "label": 0
                },
                {
                    "sent": "We all know that all models are wrong.",
                    "label": 1
                },
                {
                    "sent": "You know, but some are useful and you know this very famous quote from George Box.",
                    "label": 0
                },
                {
                    "sent": "And so when we're thinking of this from a decision theoretic perspective already, from any perspective, we say a model is useful.",
                    "label": 0
                },
                {
                    "sent": "You know precisely what do we mean by that statement.",
                    "label": 1
                },
                {
                    "sent": "OK, so we use a model of course because it's useful.",
                    "label": 0
                },
                {
                    "sent": "What do we mean by by useful?",
                    "label": 1
                },
                {
                    "sent": "Well, we're using the model for some purpose.",
                    "label": 0
                },
                {
                    "sent": "And in a sense, every respective of whether the model is true or not.",
                    "label": 1
                },
                {
                    "sent": "You know action still need to be taken.",
                    "label": 0
                },
                {
                    "sent": "So for me, you know, looking at genetic loci for looking in randomized clinical trials where the prover, drug, etc etc.",
                    "label": 0
                },
                {
                    "sent": "And so when we say a model is useful from the perspective of this talk, we're going to say model is useful if it aids in some decision process.",
                    "label": 1
                },
                {
                    "sent": "So I'm using the model to a decision process.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so to formalize this, suppose we have unstructured information.",
                    "label": 1
                },
                {
                    "sent": "We have data.",
                    "label": 1
                },
                {
                    "sent": "We could Aksumite exchangeable, say, X1 to XN, and it is as decision makers we are benefiting from using a model.",
                    "label": 0
                },
                {
                    "sent": "Rather than the raw information.",
                    "label": 1
                },
                {
                    "sent": "OK, so we have your or information contained in a data matrix.",
                    "label": 0
                },
                {
                    "sent": "And here we can think of the model is just as an output from some computer program.",
                    "label": 1
                },
                {
                    "sent": "So myself as a decision maker I benefit from stuffing the information into a model into a computer algorithm and looking at the output.",
                    "label": 0
                },
                {
                    "sent": "OK. Now clearly information can be neither gained.",
                    "label": 1
                },
                {
                    "sent": "Well, it can only be lost.",
                    "label": 0
                },
                {
                    "sent": "Yeah, by just considering the output, save some summary statistics and so really hear the model.",
                    "label": 0
                },
                {
                    "sent": "Theater taking input.",
                    "label": 0
                },
                {
                    "sent": "I is chosen serves to kind of distill or compress those aspects of the information which are most relevant to the decision task, and that's why we, you know, that's why we model while we don't just look at raw information, look at just data.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK then.",
                    "label": 0
                },
                {
                    "sent": "And so in fitting the model, we're going to assume that there is some target value.",
                    "label": 1
                },
                {
                    "sent": "Which were going tonight theater nought?",
                    "label": 0
                },
                {
                    "sent": "That we are hoping to learn about.",
                    "label": 1
                },
                {
                    "sent": "And we're going to be precise about this.",
                    "label": 0
                },
                {
                    "sent": "Is that what we're going to do is we're going to assume that in the limit of infinite information, so says my sample size goes to Infinity, then this optimal value of Theta is revealed by the model.",
                    "label": 1
                },
                {
                    "sent": "OK, so for me Theater 0 is the output from my computer program.",
                    "label": 1
                },
                {
                    "sent": "Given an infinite amount of information.",
                    "label": 0
                },
                {
                    "sent": "OK, so trivial example.",
                    "label": 1
                },
                {
                    "sent": "Suppose my computer program is computing a logistic regression model.",
                    "label": 0
                },
                {
                    "sent": "Or, as you know, a simple classification model.",
                    "label": 0
                },
                {
                    "sent": "Then Theatre 0 would be say the dependent on your model would be say, the maximum likelihood estimate or the maximum posteriori estimate as the sample size tended to Infinity.",
                    "label": 0
                },
                {
                    "sent": "I if you know if you could, my study could contain every individual available.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so now we're going to.",
                    "label": 0
                },
                {
                    "sent": "Introduced this notion of model sufficiency.",
                    "label": 1
                },
                {
                    "sent": "So we say that a model.",
                    "label": 1
                },
                {
                    "sent": "Is sufficient for the decision process.",
                    "label": 1
                },
                {
                    "sent": "If, in the limit of infinite information, the output from the model is a sufficient statistic for the decision process.",
                    "label": 1
                },
                {
                    "sent": "OK. A consequence of this is that should that value that you're targeting, Thetan ought ever become known to you.",
                    "label": 0
                },
                {
                    "sent": "Then the inference task is solved.",
                    "label": 0
                },
                {
                    "sent": "And the optimal action.",
                    "label": 0
                },
                {
                    "sent": "Say on the space of the utility on the space of actions given theater North is revealed.",
                    "label": 0
                },
                {
                    "sent": "OK hi.",
                    "label": 1
                },
                {
                    "sent": "Could you clarify what you mean by sufficient for the decision process as it means to computer posteriorly?",
                    "label": 0
                },
                {
                    "sent": "It means that this is the kind of the way to think about it.",
                    "label": 0
                },
                {
                    "sent": "Yeah, if you choose to say user logistic regression model or whatever the model it is.",
                    "label": 0
                },
                {
                    "sent": "Yeah, if I tell you where your PSU where your posterior will converge to.",
                    "label": 0
                },
                {
                    "sent": "Under an infinite sample size, then you would not need to perform the experiment and you would happily walk away choosing your optimal action.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so if I told you if I told you where your Bayesian posterior would converge to under an infinite sample size, you wouldn't need to run.",
                    "label": 0
                },
                {
                    "sent": "You wouldn't need to do your inference task.",
                    "label": 0
                },
                {
                    "sent": "Yeah, you would know.",
                    "label": 0
                },
                {
                    "sent": "Where the optimal value of theater Nord is.",
                    "label": 0
                },
                {
                    "sent": "OK, so in this sense theater note can be thought of as a sufficient statistic for the decision task and the remaining information.",
                    "label": 1
                },
                {
                    "sent": "In I is ancilla RE.",
                    "label": 0
                },
                {
                    "sent": "OK, and so.",
                    "label": 0
                },
                {
                    "sent": "In order to for us to make headway into M open, what I'm going to say is that when you when you choose to use a model, you're happy with this statement.",
                    "label": 0
                },
                {
                    "sent": "Yeah, you're happy using that model in so much that if I gave you an infinite amount of information, you know as a Bayesian you're not allowed to change your model.",
                    "label": 0
                },
                {
                    "sent": "Are you the model you adopt?",
                    "label": 0
                },
                {
                    "sent": "Shouldn't depend on how much or how little information you gain the data you're going to work with.",
                    "label": 0
                },
                {
                    "sent": "But the choice of the model is saying I'm happy that in the limit of infinite information I could choose the optimal action.",
                    "label": 0
                },
                {
                    "sent": "In front of me.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's our notion of model sufficiency.",
                    "label": 0
                },
                {
                    "sent": "We're going to select a sufficient model.",
                    "label": 0
                },
                {
                    "sent": "The model that's sufficient.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The decision process.",
                    "label": 0
                },
                {
                    "sent": "Hi, could you give an example of when that wouldn't be true and trying to understand why is it?",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Be happy because you assume that model is true.",
                    "label": 0
                },
                {
                    "sent": "I'm not quite sure I so I can imagine it wouldn't be true is that if I.",
                    "label": 0
                },
                {
                    "sent": "Suppose you had a logistic regression classifier.",
                    "label": 1
                },
                {
                    "sent": "And you started working on some finite data and you know Bayes ghost descended on you and told you that that theater, nor was this that.",
                    "label": 0
                },
                {
                    "sent": "Would you really walk away?",
                    "label": 0
                },
                {
                    "sent": "You kind of attempted to to do something else.",
                    "label": 1
                },
                {
                    "sent": "Yeah, to fit another model perhaps.",
                    "label": 0
                },
                {
                    "sent": "So I'm saying that.",
                    "label": 0
                },
                {
                    "sent": "That we have to be under this principle is strong principle of model sufficiency and would we ever.",
                    "label": 1
                },
                {
                    "sent": "The other questions we had entering, where this would clearly be true.",
                    "label": 1
                },
                {
                    "sent": "Freddy parametric model maker.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 1
                },
                {
                    "sent": "Well, what I'm saying is, is that it currently is empirically true, because people adopt models and make decisions based on the output of the model.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I'm formalizing this by saying that that statement has to be that if I gave you an infinite amount of information, you'd be happy to use that model.",
                    "label": 0
                },
                {
                    "sent": "Yeah, in fact, in practice, of course, Bayesians choose their model based on how much data they're going to get.",
                    "label": 0
                },
                {
                    "sent": "If I tell you I'm going to give you 10 data points, or you know 5 billion data points, people normally choose their models differently, But in theory they shouldn't, yeah.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, so now the interpretation of your prior is going to change.",
                    "label": 0
                },
                {
                    "sent": "Yeah, and your interpretation of your pry or subjective beliefs is in the unknown value of theater nought that yields the optimal decisions.",
                    "label": 1
                },
                {
                    "sent": "So your prior on theater is going to be the probability that in the infinite amount of information the say the posterior is going to converge to this particular point.",
                    "label": 0
                },
                {
                    "sent": "Yeah, and that's fundamentally different from the conventional construction of a prior so piously to no longer represents your beliefs about the true F nought, as you don't believe the model is true.",
                    "label": 1
                },
                {
                    "sent": "It's simply about the optimal values.",
                    "label": 1
                },
                {
                    "sent": "Say that the posterior concentrates to theater nought in the limit of infinite information.",
                    "label": 1
                },
                {
                    "sent": "OK, so that's what your price is going to be, and so so a natural question is, well, does that?",
                    "label": 0
                },
                {
                    "sent": "Does that point theater not have any any meaning?",
                    "label": 0
                },
                {
                    "sent": "Or strong meaning with respect to what nature is the true sampling distribution F nought?",
                    "label": 0
                },
                {
                    "sent": "Well.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well, we know that for most kind of regular models.",
                    "label": 0
                },
                {
                    "sent": "That that's eaten or has kind of has strong interpretation so well motivated target is theater nought.",
                    "label": 0
                },
                {
                    "sent": "Within my parametric or even nonparametric prior index by Theta is going to minimize.",
                    "label": 0
                },
                {
                    "sent": "I wish to target the theater North that minimizes the Kullback Leibler divergent between the true.",
                    "label": 1
                },
                {
                    "sent": "Unknown sampling distribution F nought and the one contained within my model space so theater is going to tend to the point in your model space which brings your sampling distribution closest to nature.",
                    "label": 1
                },
                {
                    "sent": "Sampling distribution under Kullback Leibler divergent.",
                    "label": 0
                },
                {
                    "sent": "And so here your prior represents.",
                    "label": 1
                },
                {
                    "sent": "You probably saw the value of theater that minimizes the KL divergent's you know.",
                    "label": 0
                },
                {
                    "sent": "And Moreover if you use Bayesian inference with a proxy likelihood because you don't believe that the data really comes.",
                    "label": 0
                },
                {
                    "sent": "You know you don't believe that you have the true model so so so F of X given theater is just a proxy.",
                    "label": 0
                },
                {
                    "sent": "We know that, for example, the maximum likelihood estimate.",
                    "label": 0
                },
                {
                    "sent": "One of the robustness properties of Emily's as well as of M. APS is that they minimize the Kullback Leibler divergent between F nought and F data.",
                    "label": 0
                },
                {
                    "sent": "So in other words, your Bayesian map, typically under an infinite sample size, will or maximum likelihood estimate will just minimize kullback Leibler divergent.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so so so that part of it is kind of covered the prior, so we've now changed our interpretation of the prior.",
                    "label": 0
                },
                {
                    "sent": "Well now we're going to need to change our interpretation of the likelihood because having defined what Pi theater is we wish to update it.",
                    "label": 1
                },
                {
                    "sent": "Based on information and we can't use F of X given Theta because we don't believe that X comes from F of X given Theta.",
                    "label": 1
                },
                {
                    "sent": "OK, so we can't use Bayes theorem OK.",
                    "label": 0
                },
                {
                    "sent": "However, what you can do is try and proceed.",
                    "label": 1
                },
                {
                    "sent": "If all out, well, not even if all else fails, you should you go back to decision theory.",
                    "label": 0
                },
                {
                    "sent": "Which is can we proceed in a coherent manner?",
                    "label": 1
                },
                {
                    "sent": "Yeah, so I have a. I have a product represents my beliefs.",
                    "label": 0
                },
                {
                    "sent": "I have some information and I wish to proceed to update my beliefs coherently.",
                    "label": 0
                },
                {
                    "sent": "And a coherent thing to do from a decision theoretic perspective, is to define a loss function on the space of all probability measure well on the space of measures over theater.",
                    "label": 1
                },
                {
                    "sent": "Yeah, the quantify the relative utility of the model of the probability measure.",
                    "label": 0
                },
                {
                    "sent": "I'm going to call that \u03c0 star.",
                    "label": 0
                },
                {
                    "sent": "Over theater, given the information in the data and your prior beliefs.",
                    "label": 0
                },
                {
                    "sent": "And what we're going to do now is we're now going to select a posterior measure.",
                    "label": 1
                },
                {
                    "sent": "That maximizes that offers best beliefs that represents your best beliefs about the value of theater nought in light of information.",
                    "label": 0
                },
                {
                    "sent": "We're gonna assume additivity of loss, yeah, namely that the loss between the posterior measure.",
                    "label": 1
                },
                {
                    "sent": "So Pi Staff theater is going to be your posterior update.",
                    "label": 0
                },
                {
                    "sent": "The update on theater given information, and we're going to say that there's a component of the loss which relates the posterior to the information in the data, and a component that relates to loss to the prior.",
                    "label": 0
                },
                {
                    "sent": "I'm with then going to select your optimal pie star, which minimizes your expected loss, and that's the formal way to proceed.",
                    "label": 0
                },
                {
                    "sent": "The decision theoretic way to proceed.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So if we assume that the information arises as individual pieces of data X1 to XN.",
                    "label": 1
                },
                {
                    "sent": "We're going to assume a log additive loss function, so we're going to say that the loss between the posterior measure \u03c0 star and the information in the data can be decomposed into a sum and additive sum of loss functions for individual units of data XI.",
                    "label": 1
                },
                {
                    "sent": "\u03a0 Star is a probability measure on theater, and so how can we govern?",
                    "label": 0
                },
                {
                    "sent": "Or how can we?",
                    "label": 0
                },
                {
                    "sent": "How can we express our loss in a posterior measure with respect to a single piece of information while Pi star is over is a posterior on Theta and we're going to take the appropriate loss to be given by its expectation.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so you can think of this loss function is recording the expected relative loss in replacing the information in XI with this \u03c0 star.",
                    "label": 1
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, So what might that loss function looks like?",
                    "label": 0
                },
                {
                    "sent": "Well, if we believe we have a good proxy model for F nought, or if you're saying FM close.",
                    "label": 1
                },
                {
                    "sent": "So if you if you believe that you have the true model, then the natural choice for this for this loss function is the self information loss, and in fact it's the honest loss function.",
                    "label": 0
                },
                {
                    "sent": "So this is what's derived from a proper local scoring rule high.",
                    "label": 0
                },
                {
                    "sent": "Loss function distinct from the loss function that you're eventually going to be using.",
                    "label": 0
                },
                {
                    "sent": "To get to get your posterior because I mean, I'm kind of thinking that if they were the same then you may be kind of.",
                    "label": 0
                },
                {
                    "sent": "Buy a senior results towards in the 1st place you fight.",
                    "label": 0
                },
                {
                    "sent": "You would be biased in your likelihood towards cheating.",
                    "label": 0
                },
                {
                    "sent": "The results.",
                    "label": 0
                },
                {
                    "sent": "Are you going to want to achieve and?",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This has to be an honest so in any indecision theory this has to be an honest loss function that represents your subjective beliefs about the information in XI.",
                    "label": 0
                },
                {
                    "sent": "With respect to \u03c0 star.",
                    "label": 0
                },
                {
                    "sent": "Would you be reiterating this information and later on using your 'cause?",
                    "label": 0
                },
                {
                    "sent": "I'm assuming that in a Bayesian framework you would be using it last function to to find your your posterior that separate here.",
                    "label": 0
                },
                {
                    "sent": "So what you do with your posterior pipi star theater given data.",
                    "label": 0
                },
                {
                    "sent": "That's a different game.",
                    "label": 0
                },
                {
                    "sent": "That's a different aspect of using loss functions and utility.",
                    "label": 0
                },
                {
                    "sent": "If you're using a loss function to capture your likelihood, what the choice of loss function affect your or limit your choices loss function later on to find a posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "No, I don't see I don't see why why that should.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "So this just has two to measure.",
                    "label": 0
                },
                {
                    "sent": "Well, it's really.",
                    "label": 0
                },
                {
                    "sent": "It's this, it's it's.",
                    "label": 0
                },
                {
                    "sent": "You're recording your subjective beliefs about the information in a data more a unit of data relative to.",
                    "label": 0
                },
                {
                    "sent": "The posterior measure or your posterior beliefs about where theater North lies.",
                    "label": 0
                },
                {
                    "sent": "So if you believe that.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If you believe you're in enclosed, then you're forced into using something like self information loss.",
                    "label": 0
                },
                {
                    "sent": "If you're being honest.",
                    "label": 0
                },
                {
                    "sent": "OK, and then the loss function just looks like the negative log likelihood or your negative log sampling density.",
                    "label": 0
                },
                {
                    "sent": "So equally and the example I'll show later on for survival analysis.",
                    "label": 0
                },
                {
                    "sent": "You can use partial likelihood or partial loss, so if you believe that only part of the information in the data is has utility for your decision process, you only have to put a loss on those aspects of the data that you believe are relevant.",
                    "label": 0
                },
                {
                    "sent": "The key point is that this loss, relative to theater nought is relative to theater, not which is the sufficient model for your decision.",
                    "label": 1
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK. For coherency, it turns out and this is where I kind of joined the story.",
                    "label": 0
                },
                {
                    "sent": "So Steven has a very nice technical paper on that.",
                    "label": 0
                },
                {
                    "sent": "The use of kullback Leiber loss.",
                    "label": 0
                },
                {
                    "sent": "For updating information, yeah.",
                    "label": 0
                },
                {
                    "sent": "And so it turns out that Kullback Leibler loss is the only loss function that you can use.",
                    "label": 0
                },
                {
                    "sent": "What to maintain coherency.",
                    "label": 0
                },
                {
                    "sent": "And by that I mean that if I gave you one data set.",
                    "label": 0
                },
                {
                    "sent": "Or if I gave you 2 datasets, which was just that single data set broken into half.",
                    "label": 0
                },
                {
                    "sent": "Yeah, then for coherency we would want the updating to be the same.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so if I give you a prior, you update with the first data set and then you take your posterior from that as your prior into your next data set.",
                    "label": 0
                },
                {
                    "sent": "Then that has to be the same as having the problem with the whole data set to start with and the callback library loss is the only one that can give you that that coherency property.",
                    "label": 0
                },
                {
                    "sent": "So the loss to the prior from the posterior to the prior, we're going to take to be callback librar.",
                    "label": 0
                },
                {
                    "sent": "OK, and so here \u03c0 starter I is the records Fidelity to the data and PY startapp.",
                    "label": 1
                },
                {
                    "sent": "I records Fidelity to the prime.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What we're doing is where we kind of were trying to select.",
                    "label": 0
                },
                {
                    "sent": "An optimal posterior measure that represents best beliefs.",
                    "label": 0
                },
                {
                    "sent": "And we say we want pie start to minimize this loss, and if you just put this in and and fiddle around a bit.",
                    "label": 0
                },
                {
                    "sent": "It's straightforward to show that the Pi star that minimizes the loss is given by the minimum of the Kullback Leibler divergent between the prior times.",
                    "label": 0
                },
                {
                    "sent": "The exponentiated negative log loss, and this is now starting to look very familiar.",
                    "label": 0
                },
                {
                    "sent": "And so in particular.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Under this decision theoretic construction, you are led to to select this \u03c0 star.",
                    "label": 1
                },
                {
                    "sent": "As your best updated beliefs for theater.",
                    "label": 0
                },
                {
                    "sent": "So to Bayesians, when you would look at this, you know this looks like standard likelihood times prior, and this would be your integrated marginal likelihood.",
                    "label": 1
                },
                {
                    "sent": "Well, this has some slightly different meaning here.",
                    "label": 0
                },
                {
                    "sent": "This is a kind of a prior predictive utility or as an integrative loss with respect to the prior.",
                    "label": 0
                },
                {
                    "sent": "But, crucially, we do not have to assume I'm close to get to this position.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So some points to note here.",
                    "label": 0
                },
                {
                    "sent": "If you really believe that you are, you have a true model contained under your prior be at nonparametric prior or parametric prior, then you're led to use the negative log likelihood and you recover Bayes theorem.",
                    "label": 1
                },
                {
                    "sent": "However, this has been obtained under much weaker conditions, just loss functions, just loss functions of Fidelity of data to the posterior, and loss functions of Fidelity to the prior to the posterior.",
                    "label": 1
                },
                {
                    "sent": "And in particular, we just treat the priors another piece of information has the same kind of meaning as.",
                    "label": 0
                },
                {
                    "sent": "This is the data, yeah?",
                    "label": 1
                },
                {
                    "sent": "And Moreover, when only certain aspects of the data are relevant to the decision task, you're free to define partial loss functions.",
                    "label": 1
                },
                {
                    "sent": "So in particular, you can define a partial likelihood loss, saying survival analysis and get more general Bayesian updated.",
                    "label": 0
                },
                {
                    "sent": "It also allows for other tricky things for a pure subjective things like model checking, you know we know, look formally, you're not allowed to do model checking under Bayesian inference.",
                    "label": 0
                },
                {
                    "sent": "Of course you'd be a fool if you didn't, but but formally you're not allowed to because your priors, your pry it, cetera.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, and so Canonical forms for the loss might be self information, partial log likelihood.",
                    "label": 1
                },
                {
                    "sent": "Or equally you can use other things like robust estimating equations if you want if your loss.",
                    "label": 0
                },
                {
                    "sent": "Wants to be down weighted relative to say outliers.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so I'm just going to, I've got a few minutes just quickly just talk you through just one illustration.",
                    "label": 0
                },
                {
                    "sent": "So this is how this is kind of a motivating example in survival analysis and how we can use this to really to do general Bayesian updating and how it could help.",
                    "label": 1
                },
                {
                    "sent": "So here.",
                    "label": 1
                },
                {
                    "sent": "I'm interested in the variable selection problem, so I have some data, some time to event data under sensor in an.",
                    "label": 0
                },
                {
                    "sent": "I'm interested I have some covariates and I'm interested which covariates to say relevant to the time to event to distinguish in variation in time to event.",
                    "label": 1
                },
                {
                    "sent": "And this is a bit taken from a particular data set from Rossi, and it's on prisoner reoffending rates, so these were prisoners released.",
                    "label": 1
                },
                {
                    "sent": "They were followed for 50 for a year, 52 weeks following release, and so the response data is the week of release.",
                    "label": 0
                },
                {
                    "sent": "Or whether they just left the study that censoring as well as they could either be an event I if they re arrested or if you get to the end of the study and they weren't rearrested then you get a zero.",
                    "label": 0
                },
                {
                    "sent": "Yeah and they treat that as right censoring, which is like a little bit harsh 'cause it means at some point they would get arrested, yeah?",
                    "label": 0
                },
                {
                    "sent": "But anyhow, so we're going to treat that as just right censored data.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then we have some set of covariates, whether they receive financial aid, how old they are, whether they had work experience, whether they were married.",
                    "label": 1
                },
                {
                    "sent": "Number of prod, convention, convictions etc etc.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, so the point to note here is that if you were doing this full Bayesian survival analysis, we've got this tricky thing that if we want to use a log linear proportional hazards just a standard Cox proportional hazards model, we have this nasty baseline hazard rate here.",
                    "label": 1
                },
                {
                    "sent": "And as Bayesians you kind of forced A to assume you have the true model and be you've got to put a prior over it of course.",
                    "label": 1
                },
                {
                    "sent": "So H dot is the baseline hazard.",
                    "label": 0
                },
                {
                    "sent": "So people do this and they put these.",
                    "label": 0
                },
                {
                    "sent": "You know, very elegant nonparametric measures over this baseline hazard.",
                    "label": 1
                },
                {
                    "sent": "But they can be not.",
                    "label": 1
                },
                {
                    "sent": "I won't say unwieldly, but the reason why Cox proportional hazards is so widely used is that they treat H and orders a nuisance process and just concentrate inference on, say, the regression coefficients in here.",
                    "label": 0
                },
                {
                    "sent": "So under the framework we've just presented with free, if H nought.",
                    "label": 0
                },
                {
                    "sent": "Is ancillary to the decision process I if I was prepared to make a decision based on the output of a Cox proportional hazard model under infinite information, then I'm then I'm perfectly valid to drop this.",
                    "label": 0
                },
                {
                    "sent": "Yeah, to drop this in my loss function to the data which we do and we get a partial loss.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then, given that we can just do spike and slab priors and examine the posterior distribution of a variable being important to that, we look at the posterior best posterior measure on the import.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the key thing here is that that that partial loss uses this integrated utility log utility rather than being formally a marginal likelihood.",
                    "label": 0
                },
                {
                    "sent": "And then you can implement this in reversible jump MCMC.",
                    "label": 1
                },
                {
                    "sent": "Not if you do.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That and you kind of you can do kind of efficient updating, so this is just a trivial little sampler and we can see that it's you know moving around the space and.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Get.",
                    "label": 0
                },
                {
                    "sent": "Posterior probabilities or best posterior probabilities about the inclusion probabilities.",
                    "label": 0
                },
                {
                    "sent": "And So what we can see here is that age seems to be very important.",
                    "label": 0
                },
                {
                    "sent": "Prior convictions is very important.",
                    "label": 0
                },
                {
                    "sent": "Marriage is slightly more important than work experience, etc.",
                    "label": 0
                },
                {
                    "sent": "There's some kind of randomized control trial.",
                    "label": 0
                },
                {
                    "sent": "I thought you could continue.",
                    "label": 0
                },
                {
                    "sent": "Yeah, prisoners you make them get married or they do work experience you can.",
                    "label": 0
                },
                {
                    "sent": "I'm sure ethics wouldn't approve all mighty hard to gain on on that but.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so so just a couple of points and then to wrap up.",
                    "label": 0
                },
                {
                    "sent": "So one thing I think is interesting is that if you drop the loss to the prior.",
                    "label": 0
                },
                {
                    "sent": "The app, so if we say OK, I'm going to take no loss to my prior beliefs.",
                    "label": 0
                },
                {
                    "sent": "I'm going to now minimize my posterior with respect to the information in the data.",
                    "label": 0
                },
                {
                    "sent": "And what that leads to is all of your posterior measure collapsing around the Emily.",
                    "label": 0
                },
                {
                    "sent": "That is, after a single observation, your best beliefs about Theta lie at the maximum likelihood estimate, and that's clearly kind of incoherent and not to be advocated.",
                    "label": 1
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The second point to note is that if you if you use a flat prior.",
                    "label": 1
                },
                {
                    "sent": "Yeah, then then what this what we minimize the kullback Leibler divergent's what we see is you end up with Pi Hat star which maximizes the utility to the data subject to an entropy penalty.",
                    "label": 1
                },
                {
                    "sent": "OK, and so look at the likelihood function as a normalized posterior measure is equivalent to use in a loss which maximizes this posterior loss with respect to this entropy constraint.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, there's lots of.",
                    "label": 0
                },
                {
                    "sent": "This is my final slide.",
                    "label": 0
                },
                {
                    "sent": "There's lots of open questions and current work that we're working on.",
                    "label": 1
                },
                {
                    "sent": "I think one way to think about this is there's clear connections with penalized likelihood or penalized log likelihood methods, so you know lasuen splines.",
                    "label": 1
                },
                {
                    "sent": "So in those situations, you try and find an optimal theater which maximizes the likelihood.",
                    "label": 1
                },
                {
                    "sent": "Subject is concerned, some constraint and one kind of interested interpretation of Bayesian inference is actually.",
                    "label": 0
                },
                {
                    "sent": "What you're trying to do is is trying to try to find a posterior measure.",
                    "label": 0
                },
                {
                    "sent": "So rather than trying to maximize the point you're trying to maximize the probability measure, and so all that I've kind of presented it.",
                    "label": 0
                },
                {
                    "sent": "You can think of is trying to select a probability measure which maximizes your information in the data, plus are kind of a penalty which comes from prior information.",
                    "label": 0
                },
                {
                    "sent": "This normalizing constant, which is so important to Bayesian inference, you know the evidance or marginal likelihood here has this kind of notion of a normalized expected utility, and so I think there's lots of interesting things to be done.",
                    "label": 0
                },
                {
                    "sent": "There's some other problems, open questions and but I'd like to stop and thank you for listening, thanks.",
                    "label": 0
                }
            ]
        }
    }
}