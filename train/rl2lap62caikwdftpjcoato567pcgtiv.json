{
    "id": "rl2lap62caikwdftpjcoato567pcgtiv",
    "title": "Bayes-Optimal Scorers for Bipartite Ranking",
    "info": {
        "author": [
            "Aditya Menon, NICTA, Australia's ICT Research Centre of Excellence"
        ],
        "published": "July 15, 2014",
        "recorded": "June 2014",
        "category": [
            "Top->Computer Science->Machine Learning->Unsupervised Learning",
            "Top->Computer Science->Machine Learning->Supervised Learning",
            "Top->Computer Science->Machine Learning->Statistical Learning",
            "Top->Computer Science->Machine Learning->On-line Learning",
            "Top->Computer Science->Machine Learning->Computational Learning Theory"
        ]
    },
    "url": "http://videolectures.net/colt2014_menon_ranking/",
    "segmentation": [
        [
            "So this talk is Bayes optimal scores for bipartite ranking.",
            "I'm Aditya is a joint work with Bob Williamson."
        ],
        [
            "So this paper is about bipartite ranking.",
            "What's the problem?",
            "So here we have access to samples from some distribution over instances and binary labels.",
            "We are interested in producing a scorer which Maps an instance to a real number and we evaluate the score up, typically based on the area under the IRC code, which is the probability that are random positive instance gets a higher score than a random negative instance."
        ],
        [
            "So since the AOC has baked into it, essentially an indicator function or 01 loss, it's difficult to directly maximize.",
            "So a natural strategy is to say, well, let's just replace this function with something more convenient.",
            "So pick some surrogate loss and use that in place of the 01 and minimize the resulting quantity and we're going to call this quantity the L bipartite risk."
        ],
        [
            "So given this risk, we can ask well what's the optimal thing to do under the stress.",
            "So what are the Bayes optimal scores?",
            "Which are the scores that actually minimize this risk?",
            "OK, and if our goal is actually to be maximizing the AUC, or equivalently minimizing the risk for 01 or minimally, we'd like that the optimal scores under L agree with the optimal squirrels under 01, right?",
            "And So what are the optimal scores?",
            "Well, for the cases 01 more for the AUC, the Neyman Pearson lemma gives us a pretty thorough characterization.",
            "It says that these are all increasing transformations of ITA.",
            "What's Eater is the underlying probability of an instance being labeled positive.",
            "So we're interested in figuring out well, So what are the optimal scores for a more general class of L?"
        ],
        [
            "OK, so there's a very well known reduction of bipartite ranking to a classification problem on pairs of instances.",
            "We just need to set up appropriate product distributions over the class conditional for the original binary classification distribution, and so this seems like this gives a very natural way in which we could compute the optimal squirrels right?",
            "Because we have a pretty good understanding about binary classification, in particular, the optimal score.",
            "Also binary classification problem.",
            "So this is fine, but the only slight glitch is that when we're working on this space of pairs of instances where really considering a restricted set of scores.",
            "And in particular, we only considering scores over pairs of instances that are decomposable.",
            "What does that mean?",
            "That means that they are expressible as the difference of scores on the individual instances, right?",
            "This was kind of inherent in the definition of the AUC, so what's the problem with that?",
            "Well, this is effectively restricted function class, right?",
            "So restriction on the space of all possible scores on these pairs, and so if we want to analyze the optimal scores on a point wise manner, looking at the conditional risk, this is no longer possible in general."
        ],
        [
            "So you can make some progress by kind of introducing kind of viewing this problem using the tools of proper composite losses.",
            "So we've seen this in one of the earlier talks, so these are basically the fundamental losses of class probability estimation.",
            "The binary labels.",
            "So why is that so?",
            "Well, so the optimal scores for these losses in the binary classification setting precisely some fixed transform sigh of your eater, your probability of Y given X, and this transformation function PSI is sometimes called the link function corresponding to the loss.",
            "This captures, for example, that we just stick exponential and squared loss."
        ],
        [
            "So why are these losses useful ones?",
            "So if you try to study, So what are the Bayes optimal scores under this family of target losses?",
            "It turns out that under some conditions on the loss, you can very trivially characterize what the optimum scores of the optimal bipartite scores are.",
            "So particular it's going to turn out.",
            "These are just the fixed Mount on Transformers site, plus obviously a translation term, and so in particular these are going to coincide or agree with the optimal scores for 01.",
            "But so the.",
            "This is fine.",
            "This is intuitive.",
            "The only real mystery is kind of why we have this condition on the link on the loss, and in particular the condition is that the link function or the inverse link has to belong to the scale sigmoid family, right?"
        ],
        [
            "And so it turns out that we can deepen the mystery as well so we can not only characterize the optimal solutions.",
            "We can also import, for example, target trigger points.",
            "How does excessive risk with this vector loss L correspond to access rights with respect to 01 or effectively AUC?",
            "So."
        ],
        [
            "You know where this kind of what's with this condition on the link function?",
            "So where is this mystery arising?",
            "So essentially a trivial case where we can make progress is saying well, so the problem was we were.",
            "We said we had a restricted function class on the pair scores, but let's say that the optimal pair score was in fact decomposable way that it is in fact expressible as a difference of scores on the individual instances.",
            "In that case we can effectively ignore the restriction and kind of consider the minimization over all possible skirts, and then we can very easily import the results that we know from binary classification.",
            "So all this requires is that we have a handle on the eater, but now on the pairs of instances, right?",
            "So I called Peter Pack so the heater is the probability of a pair of instances having a positive label.",
            "And so it turns out it's not very hard to show that the Eater pair has this particular form, which involves a particular composition of your heater on the individual instance and essentially your sigmoid function like a standard sigmoid function.",
            "And So what does this mean so well, if you're working with the proper compensate lost, then the optimal scores are a transformation of ureter.",
            "So in this case the transformation of this particular combination of your Sigma and heater, and So what you essentially need, is some condition on site such that it essentially cancels out the sigmoid function and when you get that, you essentially get the decomposable score at the end."
        ],
        [
            "So that's fine, but so it actually also turns out that you can compute the optimal scores for more general case where you have don't have a decomposable score, it needs more effort.",
            "It could also compute optimal scores for a general class of risk that work for ranking the best problems.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this talk is Bayes optimal scores for bipartite ranking.",
                    "label": 0
                },
                {
                    "sent": "I'm Aditya is a joint work with Bob Williamson.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this paper is about bipartite ranking.",
                    "label": 1
                },
                {
                    "sent": "What's the problem?",
                    "label": 1
                },
                {
                    "sent": "So here we have access to samples from some distribution over instances and binary labels.",
                    "label": 0
                },
                {
                    "sent": "We are interested in producing a scorer which Maps an instance to a real number and we evaluate the score up, typically based on the area under the IRC code, which is the probability that are random positive instance gets a higher score than a random negative instance.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So since the AOC has baked into it, essentially an indicator function or 01 loss, it's difficult to directly maximize.",
                    "label": 1
                },
                {
                    "sent": "So a natural strategy is to say, well, let's just replace this function with something more convenient.",
                    "label": 0
                },
                {
                    "sent": "So pick some surrogate loss and use that in place of the 01 and minimize the resulting quantity and we're going to call this quantity the L bipartite risk.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So given this risk, we can ask well what's the optimal thing to do under the stress.",
                    "label": 0
                },
                {
                    "sent": "So what are the Bayes optimal scores?",
                    "label": 0
                },
                {
                    "sent": "Which are the scores that actually minimize this risk?",
                    "label": 0
                },
                {
                    "sent": "OK, and if our goal is actually to be maximizing the AUC, or equivalently minimizing the risk for 01 or minimally, we'd like that the optimal scores under L agree with the optimal squirrels under 01, right?",
                    "label": 0
                },
                {
                    "sent": "And So what are the optimal scores?",
                    "label": 0
                },
                {
                    "sent": "Well, for the cases 01 more for the AUC, the Neyman Pearson lemma gives us a pretty thorough characterization.",
                    "label": 0
                },
                {
                    "sent": "It says that these are all increasing transformations of ITA.",
                    "label": 0
                },
                {
                    "sent": "What's Eater is the underlying probability of an instance being labeled positive.",
                    "label": 0
                },
                {
                    "sent": "So we're interested in figuring out well, So what are the optimal scores for a more general class of L?",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so there's a very well known reduction of bipartite ranking to a classification problem on pairs of instances.",
                    "label": 1
                },
                {
                    "sent": "We just need to set up appropriate product distributions over the class conditional for the original binary classification distribution, and so this seems like this gives a very natural way in which we could compute the optimal squirrels right?",
                    "label": 0
                },
                {
                    "sent": "Because we have a pretty good understanding about binary classification, in particular, the optimal score.",
                    "label": 0
                },
                {
                    "sent": "Also binary classification problem.",
                    "label": 0
                },
                {
                    "sent": "So this is fine, but the only slight glitch is that when we're working on this space of pairs of instances where really considering a restricted set of scores.",
                    "label": 0
                },
                {
                    "sent": "And in particular, we only considering scores over pairs of instances that are decomposable.",
                    "label": 0
                },
                {
                    "sent": "What does that mean?",
                    "label": 0
                },
                {
                    "sent": "That means that they are expressible as the difference of scores on the individual instances, right?",
                    "label": 0
                },
                {
                    "sent": "This was kind of inherent in the definition of the AUC, so what's the problem with that?",
                    "label": 0
                },
                {
                    "sent": "Well, this is effectively restricted function class, right?",
                    "label": 1
                },
                {
                    "sent": "So restriction on the space of all possible scores on these pairs, and so if we want to analyze the optimal scores on a point wise manner, looking at the conditional risk, this is no longer possible in general.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So you can make some progress by kind of introducing kind of viewing this problem using the tools of proper composite losses.",
                    "label": 1
                },
                {
                    "sent": "So we've seen this in one of the earlier talks, so these are basically the fundamental losses of class probability estimation.",
                    "label": 1
                },
                {
                    "sent": "The binary labels.",
                    "label": 0
                },
                {
                    "sent": "So why is that so?",
                    "label": 0
                },
                {
                    "sent": "Well, so the optimal scores for these losses in the binary classification setting precisely some fixed transform sigh of your eater, your probability of Y given X, and this transformation function PSI is sometimes called the link function corresponding to the loss.",
                    "label": 0
                },
                {
                    "sent": "This captures, for example, that we just stick exponential and squared loss.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So why are these losses useful ones?",
                    "label": 0
                },
                {
                    "sent": "So if you try to study, So what are the Bayes optimal scores under this family of target losses?",
                    "label": 0
                },
                {
                    "sent": "It turns out that under some conditions on the loss, you can very trivially characterize what the optimum scores of the optimal bipartite scores are.",
                    "label": 0
                },
                {
                    "sent": "So particular it's going to turn out.",
                    "label": 0
                },
                {
                    "sent": "These are just the fixed Mount on Transformers site, plus obviously a translation term, and so in particular these are going to coincide or agree with the optimal scores for 01.",
                    "label": 0
                },
                {
                    "sent": "But so the.",
                    "label": 0
                },
                {
                    "sent": "This is fine.",
                    "label": 0
                },
                {
                    "sent": "This is intuitive.",
                    "label": 0
                },
                {
                    "sent": "The only real mystery is kind of why we have this condition on the link on the loss, and in particular the condition is that the link function or the inverse link has to belong to the scale sigmoid family, right?",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so it turns out that we can deepen the mystery as well so we can not only characterize the optimal solutions.",
                    "label": 0
                },
                {
                    "sent": "We can also import, for example, target trigger points.",
                    "label": 0
                },
                {
                    "sent": "How does excessive risk with this vector loss L correspond to access rights with respect to 01 or effectively AUC?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You know where this kind of what's with this condition on the link function?",
                    "label": 0
                },
                {
                    "sent": "So where is this mystery arising?",
                    "label": 0
                },
                {
                    "sent": "So essentially a trivial case where we can make progress is saying well, so the problem was we were.",
                    "label": 0
                },
                {
                    "sent": "We said we had a restricted function class on the pair scores, but let's say that the optimal pair score was in fact decomposable way that it is in fact expressible as a difference of scores on the individual instances.",
                    "label": 0
                },
                {
                    "sent": "In that case we can effectively ignore the restriction and kind of consider the minimization over all possible skirts, and then we can very easily import the results that we know from binary classification.",
                    "label": 0
                },
                {
                    "sent": "So all this requires is that we have a handle on the eater, but now on the pairs of instances, right?",
                    "label": 0
                },
                {
                    "sent": "So I called Peter Pack so the heater is the probability of a pair of instances having a positive label.",
                    "label": 1
                },
                {
                    "sent": "And so it turns out it's not very hard to show that the Eater pair has this particular form, which involves a particular composition of your heater on the individual instance and essentially your sigmoid function like a standard sigmoid function.",
                    "label": 0
                },
                {
                    "sent": "And So what does this mean so well, if you're working with the proper compensate lost, then the optimal scores are a transformation of ureter.",
                    "label": 0
                },
                {
                    "sent": "So in this case the transformation of this particular combination of your Sigma and heater, and So what you essentially need, is some condition on site such that it essentially cancels out the sigmoid function and when you get that, you essentially get the decomposable score at the end.",
                    "label": 1
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So that's fine, but so it actually also turns out that you can compute the optimal scores for more general case where you have don't have a decomposable score, it needs more effort.",
                    "label": 0
                },
                {
                    "sent": "It could also compute optimal scores for a general class of risk that work for ranking the best problems.",
                    "label": 1
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}