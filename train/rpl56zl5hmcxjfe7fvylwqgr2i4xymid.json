{
    "id": "rpl56zl5hmcxjfe7fvylwqgr2i4xymid",
    "title": "Kernel Based Identification of Systems with Multiple Outputs Using Nuclear Norm Regularization",
    "info": {
        "author": [
            "Tillmann Falck, Optimization in Engineering Center (OPTEC), KU Leuven"
        ],
        "published": "Aug. 26, 2013",
        "recorded": "July 2013",
        "category": [
            "Top->Computer Science->Optimization Methods",
            "Top->Computer Science->Machine Learning->Kernel Methods->Support Vector Machines",
            "Top->Computer Science->Compressed Sensing",
            "Top->Computer Science->Machine Learning->Regularization"
        ]
    },
    "url": "http://videolectures.net/roks2013_falck_identification/",
    "segmentation": [
        [
            "This is joint work with my former supervisors, Baltimore join Circuits both here in London.",
            "As Michael was saying, it's it's about.",
            "Kernel based identification on your systems.",
            "Having multiple outputs using a particular form of regularization.",
            "So the."
        ],
        [
            "This talk will basically start with an introduction where it's all about little bit about non neural system identification.",
            "What the whole objective is, because I'm not sure whether everybody is familiar with this domain and also like introduce the basic notation, I'm going to need, then I'm going to derive kernel based model under this nuclear norm regularization in the context of a primal dual setup which is in contrast to.",
            "Reproducing kernel Hilbert spaces which we have already seen in some of the previous talks.",
            "Before I give an motivational example, which is really, really small, but choose hopefully some of the potential of this technique.",
            "Then I'll briefly touch optimization aspects and on the last slides complete this talk and give an outlook."
        ],
        [
            "Say what now on your system identification is about is basically you have a dynamical system which has a nonlinear behavior in the dynamical systems characterized that it has some memory, so depends on the inputs that came before.",
            "So what you're usually trying to do and system identification is given a data set of inputs and outputs.",
            "Form or estimate the mathematic model that describes the system you're interested in, so you are able to.",
            "To predict outputs to two unknown inputs, it's it's really a regression problem so.",
            "Has been used for what's very popular for for system identification and you're sitting is any non linear regression technique you can come up with can come up with kernel based methods and especially support vector machines have been quite successful.",
            "Successful because they are a good method for for non linear regression.",
            "Applications are for example, load forecasting and electricity networks or virtual sensors where you don't are able to acquire measurements of a particular particular input, so.",
            "Well, it's not."
        ],
        [
            "So usually not in your system identification is restricted to single input, single output systems, and what I was looking at is multiple output systems on the slides here and in the presentation I restrict myself to two single inputs, but the method can be easily extended to multiple inputs and then the equations just get a bit more.",
            "More messy.",
            "So."
        ],
        [
            "The traditional approach, an insistent notification if you have multiple outputs is just cut the problem part and solve the coupled independent problems per output an.",
            "Depending on the problem you are looking at, this is clearly not the optimal solution."
        ],
        [
            "So what I'm proposing is to keep this system as is as it's done trying to model like the whole system, including the multiple outputs and not doing the decomposition."
        ],
        [
            "As an as an application example, consider an electricity network where you have different.",
            "Different customers connected to your to the network, so some of them might be might be industrial.",
            "Some of them might visit residential or and like and all these have have different consumption profiles, but within a class.",
            "So the industrial profiles probably like factories that work in shifts where very regular consumption profiles.",
            "Same for residential areas where you have the most consumption in the mornings and evenings.",
            "Where people are actually at home and consuming energy.",
            "So if you."
        ],
        [
            "If you split up the electricity network, network and model, each part of the network as a single entity and don't use the information contained in the remaining data, you're probably losing losing performance so well.",
            "I'm proposing is that in data sets which have related outputs, it should be adventurous to exploit this knowledge, the relation between the different outputs."
        ],
        [
            "So the the key contributions of this talk are the time formulating a kernel based model or kernel bison only or identification technique that is suitable for systems with multiple outputs where the multiple outputs have certain relation.",
            "The second contribution is basically to do the liberation in a primal dual framework which has certain implications and I think advantages over other approaches.",
            "What I'm hoping to explain later on.",
            "The challenges are basically finding a kernel based problem formulation.",
            "If you're relying on reproducing kernel Hilbert spaces, you can use the representative sealed room that was proven by by some of the most guys sitting sitting right here.",
            "And work from there.",
            "But if you're working on Primal Dual framework, you have to do some some additional work, and I'm going to present that one as a final problem.",
            "There is the issue of numerical solution because it's it's going to be an SDP problem.",
            "It's numerically not that easy to scale, and I'm at least going to show where the bull necks are in at least so far."
        ],
        [
            "So what I'm going to propose, or what I'm going to use is the nuclear norm as stated in the title.",
            "Why using the nuclear norm or first the short short introduction to the nuclear norm?",
            "It's a matrix norm.",
            "It's defined as the sum of the singular values of this matrix, and as the sum of the singular values that can be seen as the L1 norm of those singular values, and therefore induces sparsity in the singular values.",
            "And that corresponds to promoting.",
            "A low rank of this matrix, and if you recall the example I was trying to give with the actresses network like a relation between the different models.",
            "If you have only like a handful of customer profiles and a lot of different measurement stations you expect, or you could explore what I'm hoping is that the the model has a low rank in the feature map feature vector.",
            "If you consider a support vector model where you basically have the other columns of W correspond to.",
            "The para meters of an individual individual model, so by.",
            "By applying the nuclear norm regularization to a support vector like model of this form, you basically promote relation between those models in the future space."
        ],
        [
            "The primal formulation is quite straightforward, so if you're familiar with the least first formulation of support vector machines, this one is quite similar.",
            "The the only difference is basically that I have the linear equality constraints not only for one output, but for for outputs the the error term for the model residuals is exactly the same, just that I'm taking the sum over them and the important differences here in the regularization term.",
            "Instead of a quadratic regularization term, I use this nuclear norm regularization over here.",
            "As I said on the previous slides.",
            "You can derive a kernel based model in two ways.",
            "One possibility is to do it in this formulation, which corresponds to the primal dual framework.",
            "The other one is to use repositioning or kernel it reproducing kernel Hilbert spaces and the corresponding represent a theorem.",
            "If you do it in this setting, there is basically five steps you have to you have to solve your first start by writing down the branch and then take the derivative with respect to the optimization variables.",
            "It would be our like WB&E and in this case, and in the Lagrangian, although the LaGrange multipliers formulate the cake Eden conditions based on that formulates or solve the dual optimization problem and then substitute the doer solution into the primal model, the complicated part."
        ],
        [
            "This will be to take derivatives with respect to the optimization variable, because this thing is not differentiable an.",
            "To finally substitute the dual solution into the primal model, because what you usually have is an expansion of the parimeter vectors in terms of your dual solution, and you don't get this immediately in this problem formulation, but."
        ],
        [
            "First, some some motivation why I'm doing this in a primal dual approach.",
            "The primal dual approach has the advantage that's usually quite straightforward to incorporate.",
            "It incorporates additional structure into the estimation problem.",
            "You could for example, at symmetry constraints so that one.",
            "One model should should mimic another one.",
            "You could add ordering constraints.",
            "You could add positivity constraints and in the very simple case, or in a context of system identification, if you have structured systems, an example or how much time systems which basically consists of nonlinear function which is static, which doesn't have any memory and a linear dynamic system which covers all the nonlinearity, you can model the first part again by some some.",
            "Or some SVM like structure.",
            "Use an AR type of filter for the OR.",
            "Eric's type of filter for the linear system combine those and you end up with a year.",
            "Approximate joint model because here I substituted the function F into the filter over here, and then I'll have the product of the W vector and the B coefficients, which I then subsidized in this W sub Q.",
            "So now incorporated at least approximately this.",
            "This model structure and then up with us in this case, even the system that has naturally.",
            "A larger number of.",
            "Of outputs, these cube virtual outfits that I created and then have a low rank structure because this matrix as it's been result of a rank one matrix representation which I relaxed at should have a rank one at the other solution.",
            "So in this case the nuclear norm regularization makes a lot of sense."
        ],
        [
            "See if I know go to take the primal formulation and write down the Lagrangian for that problem.",
            "You get this guy over here, and as I said before, the nuclear norm is not differentiable, so you have to reformulate it in one way or another VM.",
            "The two reformulations I'm aware of, or that I have used is a reformulation based on the dual norm where you express.",
            "The nuclear norm as a maximization over the the inner product of the pyramids of vector or the perimiter matrix W with the test.",
            "Test matrix C, which itself is contained in the unit normal of the dual norm to the nuclear norm, which in this case is the spectral norm or the largest eigenvalue or singular value of the matrix.",
            "See another possibility, which is a little bit more abstract is to use conic duality, which we have also heard of before today, and there are you just constrain or you introduce another perimetre T which you replace in the objective function.",
            "And then constrain the WWT to be in the cone that corresponds to the nuclear norm cone and then use Konig duality to derive the the system."
        ],
        [
            "So if you now write down the KKT conditions and substitute them into the grunge and you will obtain this dual optimization problem which is now not formulated in terms of the feature map fight anymore, but in terms of the of the kernel function and that way it's finite dimensional.",
            "And we can actually compute the solution in this form.",
            "It's in.",
            "In this case it's an SDP problem, so it can be readily solved with general purpose solvers.",
            "The the only problem is, as I was mentioning before, usually once you obtain in support vector machines is in the KKT condition for the model parameter, W is an expansion of the W in terms of the feature map in the office.",
            "So in a regular support vector machine where you have a quadratic regularizer.",
            "You would obtain a formulation where it says W equals the sum of the LaGrange multipliers times the feature map.",
            "You don't get this here, so you have to look for.",
            "I had to look for different solution and why."
        ],
        [
            "I came up with the characterization, or well, I yeah.",
            "Well, I tried to do was to characterize the solution set.",
            "That corresponds to to the dual solution.",
            "So I looked at all the primal variables W that satisfy the nuclear norm.",
            "At the same time as satisfying the value of the objective function, so I could show that the duality gap of this problem was was zero.",
            "So the objective value of primal and you'll have to be equal.",
            "I exploited that one and also the special structure of the the solution sets.",
            "And if you plug those in again into the into the primal model from model formulation, you obtain such an SDP feasibility problem.",
            "And this feasibility problem connects basically.",
            "Your dual solution given in the LaGrange multipliers to the original model formal formulation given in in the multi ring with this W. I got sore what you do.",
            "You have to exploit to make this a finite dimensional problem is basically that the matrix C is an expansion now in terms of feature map and LaGrange multipliers.",
            "But you only need access to the inner product of this one, so you actually only need to compute the kernel for this one and then extract some.",
            "Some singular values are actually the eigenvalues of some matrix."
        ],
        [
            "What you end up is a mole representation in the primal, which is exactly as we started with, so it's it's also the very same as in incentive support vector machines and the dual.",
            "It's also very, very similar.",
            "This is the model representation of a 1 dimensional support vector machine, or of a support vector machine for one output where this is the visual representation for the method I I'm proposing where you have this.",
            "Kind of mixing matrix or as in the talk before we had this learning of output kernels and this what I guess this matrix Q over here will correspond to a special matrix L. In the talk we have seen before where the structure of Q is dominated by the regularization term I imposed in the beginning."
        ],
        [
            "So I have a very very simple toy example.",
            "It has just 50 training samples.",
            "I'm using a static or fixed validation set of 100 samples and then another 150 samples to evaluate.",
            "The different models I'm comparing the number of outputs is 20.",
            "The number of independent components or different models that are directing is 3 an to do some very controlled experiments.",
            "I just generate a feature matrix.",
            "Directly, just drawing drawing random numbers I'm doing actually the same for for the ground truth of the model parameters, which I construct as a low rank matrix and add some some additive white noise.",
            "The methods I'm I'm comparing other proposed methods which I indicate by MIMO then.",
            "Something I denote as are are in the in the figures to to come, which are basically Ellis SVM models, in which are given the OR which are solved from the primal.",
            "So it's a it's rich regression, but it's I could equivalently solve individual and then there would be an Alicia model.",
            "It's trained on the individual outputs, an ID model selection for each of the individual individual outputs, so it's a fair comparison.",
            "In that way, as a third model, I have ordinary least squares.",
            "That is of course the fastest one to compute an to have have a benchmark.",
            "I'm comparing it to ordinary squares, which only has to estimate part of the data, so I'm providing this or as Oracle, I provide the true matrix AR to the estimation, so I get some some bench."
        ],
        [
            "This one is the mobile performance or the different model performances on the validation set for all S and.",
            "Or else plus Oracle, it's a constant because there is no regularization termita tune.",
            "Also for the LS SVM based model it's a constant because like each different model had an individual regularization parameter and I just choose the best model, indicated it here for the for the proposed method we see that there is a nice nice path and you can clearly identify the best regularization parameter which are used to obtain."
        ],
        [
            "The results shown shown on this slide, which are the root mean squared errors per output on the test set, and you can see that.",
            "In comparison to the the LS SVM based model which was trained on the individual outputs, you see a very nice improvement for most of the most of the outputs."
        ],
        [
            "So why was I using a very small toy example therefore?",
            "Let's have a look at the at the problems I have to solve and the primal.",
            "It's a nuclear norm regularised optimization problem in the dual.",
            "I actually have to solve 2 optimization problems this.",
            "This SDP basically, and another feasibility problem which also boils down to solving an SDP.",
            "But this one is only in like Dimension M * M, Where this is much, much larger."
        ],
        [
            "In terms of number of dimensions, it's it's quite different if you only have one input, then the the dual is actually formulation is quite nice because as in standard atlases VMS or standard as the problem complexity scales in the data and not in the number of dimensions of the feature space, which can be very very large.",
            "Whereas if you have L inputs.",
            "Instead of just one, you get, not.",
            "Only N squirt in the number of data, but it's N ^2 * L squared.",
            "If you solve the dual problem.",
            "So in that case I'm not really sure which of the two formulations to solve without to get an approximation of the feature map and then solve it in the primal or work with the dual.",
            "Representation and deal with the with the higher dimensions.",
            "So."
        ],
        [
            "They're basically or.",
            "I investigated two strategies for solution.",
            "The one is based on an SDP formulation.",
            "As I was saying, most or all of the problems RSVP representable and with tools like CBX it's extremely simple to implement those.",
            "The advantage is that they have a very high accuracy, which I do need if I solve the dual problem because I have this feasibility problem and that depends that the duality gap is really small.",
            "Because otherwise I can't make the reconstruction of the connection between dual and primal.",
            "Downside is those don't exploit any of this structure in the problem, therefore have very high runtime costs and I'm limited to very small problems.",
            "Another thing I tried to do was implement a very basic accelerated gradient projection scheme.",
            "Had a higher effort structure, can be exploited, but if I.",
            "If I was trying to solve the dual, I was not able to reconstruct my primal solution because I had a lot like the duality gap wasn't small enough for me to be successful in reconstructing the.",
            "The relation between the two solutions."
        ],
        [
            "See and in conclusion, I proposed a novel identification schemes for nonlinear systems having multiple outputs.",
            "This identification scheme exploits relations between output variables and I hope that I've illustrated at least a little bit that this this method is promising on a small toy example set, and I'll see.",
            "Present its derivation of a nuclear norm regularised kernel based model in a primal dual setting and this primal dual setting is very easy to incorporate in this primal dual setting.",
            "It's very easy to incorporate additional structure or additional prior information in the form of constraints or or playing around with the primal estimation problem."
        ],
        [
            "As challenges in outlook via the prime challenges for me certainly to work on the numerical solution and then.",
            "To be able to apply it on large scale real data real world datasets, because that's where the interest is.",
            "Some other possible avenues for for research would be to look at other regularization schemes because the nuclear norm is not the only matrix regularizer you can come up with, and my my personal opinion is that in the field of system an indication there is actually a lot of this structure that could be exploited, so I would be hoping that there is a lot of a lot to benefit from from these kind of models.",
            "With this I would like to conclude.",
            "The presentation and thank you for your attention and."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is joint work with my former supervisors, Baltimore join Circuits both here in London.",
                    "label": 0
                },
                {
                    "sent": "As Michael was saying, it's it's about.",
                    "label": 0
                },
                {
                    "sent": "Kernel based identification on your systems.",
                    "label": 1
                },
                {
                    "sent": "Having multiple outputs using a particular form of regularization.",
                    "label": 0
                },
                {
                    "sent": "So the.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This talk will basically start with an introduction where it's all about little bit about non neural system identification.",
                    "label": 0
                },
                {
                    "sent": "What the whole objective is, because I'm not sure whether everybody is familiar with this domain and also like introduce the basic notation, I'm going to need, then I'm going to derive kernel based model under this nuclear norm regularization in the context of a primal dual setup which is in contrast to.",
                    "label": 1
                },
                {
                    "sent": "Reproducing kernel Hilbert spaces which we have already seen in some of the previous talks.",
                    "label": 0
                },
                {
                    "sent": "Before I give an motivational example, which is really, really small, but choose hopefully some of the potential of this technique.",
                    "label": 1
                },
                {
                    "sent": "Then I'll briefly touch optimization aspects and on the last slides complete this talk and give an outlook.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Say what now on your system identification is about is basically you have a dynamical system which has a nonlinear behavior in the dynamical systems characterized that it has some memory, so depends on the inputs that came before.",
                    "label": 0
                },
                {
                    "sent": "So what you're usually trying to do and system identification is given a data set of inputs and outputs.",
                    "label": 0
                },
                {
                    "sent": "Form or estimate the mathematic model that describes the system you're interested in, so you are able to.",
                    "label": 0
                },
                {
                    "sent": "To predict outputs to two unknown inputs, it's it's really a regression problem so.",
                    "label": 0
                },
                {
                    "sent": "Has been used for what's very popular for for system identification and you're sitting is any non linear regression technique you can come up with can come up with kernel based methods and especially support vector machines have been quite successful.",
                    "label": 1
                },
                {
                    "sent": "Successful because they are a good method for for non linear regression.",
                    "label": 1
                },
                {
                    "sent": "Applications are for example, load forecasting and electricity networks or virtual sensors where you don't are able to acquire measurements of a particular particular input, so.",
                    "label": 0
                },
                {
                    "sent": "Well, it's not.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So usually not in your system identification is restricted to single input, single output systems, and what I was looking at is multiple output systems on the slides here and in the presentation I restrict myself to two single inputs, but the method can be easily extended to multiple inputs and then the equations just get a bit more.",
                    "label": 0
                },
                {
                    "sent": "More messy.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The traditional approach, an insistent notification if you have multiple outputs is just cut the problem part and solve the coupled independent problems per output an.",
                    "label": 0
                },
                {
                    "sent": "Depending on the problem you are looking at, this is clearly not the optimal solution.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what I'm proposing is to keep this system as is as it's done trying to model like the whole system, including the multiple outputs and not doing the decomposition.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As an as an application example, consider an electricity network where you have different.",
                    "label": 0
                },
                {
                    "sent": "Different customers connected to your to the network, so some of them might be might be industrial.",
                    "label": 0
                },
                {
                    "sent": "Some of them might visit residential or and like and all these have have different consumption profiles, but within a class.",
                    "label": 0
                },
                {
                    "sent": "So the industrial profiles probably like factories that work in shifts where very regular consumption profiles.",
                    "label": 0
                },
                {
                    "sent": "Same for residential areas where you have the most consumption in the mornings and evenings.",
                    "label": 0
                },
                {
                    "sent": "Where people are actually at home and consuming energy.",
                    "label": 0
                },
                {
                    "sent": "So if you.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you split up the electricity network, network and model, each part of the network as a single entity and don't use the information contained in the remaining data, you're probably losing losing performance so well.",
                    "label": 0
                },
                {
                    "sent": "I'm proposing is that in data sets which have related outputs, it should be adventurous to exploit this knowledge, the relation between the different outputs.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the the key contributions of this talk are the time formulating a kernel based model or kernel bison only or identification technique that is suitable for systems with multiple outputs where the multiple outputs have certain relation.",
                    "label": 1
                },
                {
                    "sent": "The second contribution is basically to do the liberation in a primal dual framework which has certain implications and I think advantages over other approaches.",
                    "label": 0
                },
                {
                    "sent": "What I'm hoping to explain later on.",
                    "label": 1
                },
                {
                    "sent": "The challenges are basically finding a kernel based problem formulation.",
                    "label": 0
                },
                {
                    "sent": "If you're relying on reproducing kernel Hilbert spaces, you can use the representative sealed room that was proven by by some of the most guys sitting sitting right here.",
                    "label": 0
                },
                {
                    "sent": "And work from there.",
                    "label": 0
                },
                {
                    "sent": "But if you're working on Primal Dual framework, you have to do some some additional work, and I'm going to present that one as a final problem.",
                    "label": 0
                },
                {
                    "sent": "There is the issue of numerical solution because it's it's going to be an SDP problem.",
                    "label": 0
                },
                {
                    "sent": "It's numerically not that easy to scale, and I'm at least going to show where the bull necks are in at least so far.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what I'm going to propose, or what I'm going to use is the nuclear norm as stated in the title.",
                    "label": 0
                },
                {
                    "sent": "Why using the nuclear norm or first the short short introduction to the nuclear norm?",
                    "label": 0
                },
                {
                    "sent": "It's a matrix norm.",
                    "label": 0
                },
                {
                    "sent": "It's defined as the sum of the singular values of this matrix, and as the sum of the singular values that can be seen as the L1 norm of those singular values, and therefore induces sparsity in the singular values.",
                    "label": 1
                },
                {
                    "sent": "And that corresponds to promoting.",
                    "label": 0
                },
                {
                    "sent": "A low rank of this matrix, and if you recall the example I was trying to give with the actresses network like a relation between the different models.",
                    "label": 0
                },
                {
                    "sent": "If you have only like a handful of customer profiles and a lot of different measurement stations you expect, or you could explore what I'm hoping is that the the model has a low rank in the feature map feature vector.",
                    "label": 0
                },
                {
                    "sent": "If you consider a support vector model where you basically have the other columns of W correspond to.",
                    "label": 0
                },
                {
                    "sent": "The para meters of an individual individual model, so by.",
                    "label": 0
                },
                {
                    "sent": "By applying the nuclear norm regularization to a support vector like model of this form, you basically promote relation between those models in the future space.",
                    "label": 1
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The primal formulation is quite straightforward, so if you're familiar with the least first formulation of support vector machines, this one is quite similar.",
                    "label": 0
                },
                {
                    "sent": "The the only difference is basically that I have the linear equality constraints not only for one output, but for for outputs the the error term for the model residuals is exactly the same, just that I'm taking the sum over them and the important differences here in the regularization term.",
                    "label": 0
                },
                {
                    "sent": "Instead of a quadratic regularization term, I use this nuclear norm regularization over here.",
                    "label": 1
                },
                {
                    "sent": "As I said on the previous slides.",
                    "label": 1
                },
                {
                    "sent": "You can derive a kernel based model in two ways.",
                    "label": 0
                },
                {
                    "sent": "One possibility is to do it in this formulation, which corresponds to the primal dual framework.",
                    "label": 0
                },
                {
                    "sent": "The other one is to use repositioning or kernel it reproducing kernel Hilbert spaces and the corresponding represent a theorem.",
                    "label": 0
                },
                {
                    "sent": "If you do it in this setting, there is basically five steps you have to you have to solve your first start by writing down the branch and then take the derivative with respect to the optimization variables.",
                    "label": 1
                },
                {
                    "sent": "It would be our like WB&E and in this case, and in the Lagrangian, although the LaGrange multipliers formulate the cake Eden conditions based on that formulates or solve the dual optimization problem and then substitute the doer solution into the primal model, the complicated part.",
                    "label": 1
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This will be to take derivatives with respect to the optimization variable, because this thing is not differentiable an.",
                    "label": 0
                },
                {
                    "sent": "To finally substitute the dual solution into the primal model, because what you usually have is an expansion of the parimeter vectors in terms of your dual solution, and you don't get this immediately in this problem formulation, but.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "First, some some motivation why I'm doing this in a primal dual approach.",
                    "label": 0
                },
                {
                    "sent": "The primal dual approach has the advantage that's usually quite straightforward to incorporate.",
                    "label": 1
                },
                {
                    "sent": "It incorporates additional structure into the estimation problem.",
                    "label": 0
                },
                {
                    "sent": "You could for example, at symmetry constraints so that one.",
                    "label": 0
                },
                {
                    "sent": "One model should should mimic another one.",
                    "label": 0
                },
                {
                    "sent": "You could add ordering constraints.",
                    "label": 0
                },
                {
                    "sent": "You could add positivity constraints and in the very simple case, or in a context of system identification, if you have structured systems, an example or how much time systems which basically consists of nonlinear function which is static, which doesn't have any memory and a linear dynamic system which covers all the nonlinearity, you can model the first part again by some some.",
                    "label": 0
                },
                {
                    "sent": "Or some SVM like structure.",
                    "label": 0
                },
                {
                    "sent": "Use an AR type of filter for the OR.",
                    "label": 1
                },
                {
                    "sent": "Eric's type of filter for the linear system combine those and you end up with a year.",
                    "label": 0
                },
                {
                    "sent": "Approximate joint model because here I substituted the function F into the filter over here, and then I'll have the product of the W vector and the B coefficients, which I then subsidized in this W sub Q.",
                    "label": 0
                },
                {
                    "sent": "So now incorporated at least approximately this.",
                    "label": 0
                },
                {
                    "sent": "This model structure and then up with us in this case, even the system that has naturally.",
                    "label": 0
                },
                {
                    "sent": "A larger number of.",
                    "label": 0
                },
                {
                    "sent": "Of outputs, these cube virtual outfits that I created and then have a low rank structure because this matrix as it's been result of a rank one matrix representation which I relaxed at should have a rank one at the other solution.",
                    "label": 1
                },
                {
                    "sent": "So in this case the nuclear norm regularization makes a lot of sense.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "See if I know go to take the primal formulation and write down the Lagrangian for that problem.",
                    "label": 0
                },
                {
                    "sent": "You get this guy over here, and as I said before, the nuclear norm is not differentiable, so you have to reformulate it in one way or another VM.",
                    "label": 1
                },
                {
                    "sent": "The two reformulations I'm aware of, or that I have used is a reformulation based on the dual norm where you express.",
                    "label": 1
                },
                {
                    "sent": "The nuclear norm as a maximization over the the inner product of the pyramids of vector or the perimiter matrix W with the test.",
                    "label": 0
                },
                {
                    "sent": "Test matrix C, which itself is contained in the unit normal of the dual norm to the nuclear norm, which in this case is the spectral norm or the largest eigenvalue or singular value of the matrix.",
                    "label": 0
                },
                {
                    "sent": "See another possibility, which is a little bit more abstract is to use conic duality, which we have also heard of before today, and there are you just constrain or you introduce another perimetre T which you replace in the objective function.",
                    "label": 0
                },
                {
                    "sent": "And then constrain the WWT to be in the cone that corresponds to the nuclear norm cone and then use Konig duality to derive the the system.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if you now write down the KKT conditions and substitute them into the grunge and you will obtain this dual optimization problem which is now not formulated in terms of the feature map fight anymore, but in terms of the of the kernel function and that way it's finite dimensional.",
                    "label": 0
                },
                {
                    "sent": "And we can actually compute the solution in this form.",
                    "label": 0
                },
                {
                    "sent": "It's in.",
                    "label": 0
                },
                {
                    "sent": "In this case it's an SDP problem, so it can be readily solved with general purpose solvers.",
                    "label": 0
                },
                {
                    "sent": "The the only problem is, as I was mentioning before, usually once you obtain in support vector machines is in the KKT condition for the model parameter, W is an expansion of the W in terms of the feature map in the office.",
                    "label": 0
                },
                {
                    "sent": "So in a regular support vector machine where you have a quadratic regularizer.",
                    "label": 0
                },
                {
                    "sent": "You would obtain a formulation where it says W equals the sum of the LaGrange multipliers times the feature map.",
                    "label": 0
                },
                {
                    "sent": "You don't get this here, so you have to look for.",
                    "label": 0
                },
                {
                    "sent": "I had to look for different solution and why.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I came up with the characterization, or well, I yeah.",
                    "label": 0
                },
                {
                    "sent": "Well, I tried to do was to characterize the solution set.",
                    "label": 1
                },
                {
                    "sent": "That corresponds to to the dual solution.",
                    "label": 1
                },
                {
                    "sent": "So I looked at all the primal variables W that satisfy the nuclear norm.",
                    "label": 1
                },
                {
                    "sent": "At the same time as satisfying the value of the objective function, so I could show that the duality gap of this problem was was zero.",
                    "label": 0
                },
                {
                    "sent": "So the objective value of primal and you'll have to be equal.",
                    "label": 0
                },
                {
                    "sent": "I exploited that one and also the special structure of the the solution sets.",
                    "label": 0
                },
                {
                    "sent": "And if you plug those in again into the into the primal model from model formulation, you obtain such an SDP feasibility problem.",
                    "label": 0
                },
                {
                    "sent": "And this feasibility problem connects basically.",
                    "label": 0
                },
                {
                    "sent": "Your dual solution given in the LaGrange multipliers to the original model formal formulation given in in the multi ring with this W. I got sore what you do.",
                    "label": 0
                },
                {
                    "sent": "You have to exploit to make this a finite dimensional problem is basically that the matrix C is an expansion now in terms of feature map and LaGrange multipliers.",
                    "label": 1
                },
                {
                    "sent": "But you only need access to the inner product of this one, so you actually only need to compute the kernel for this one and then extract some.",
                    "label": 0
                },
                {
                    "sent": "Some singular values are actually the eigenvalues of some matrix.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What you end up is a mole representation in the primal, which is exactly as we started with, so it's it's also the very same as in incentive support vector machines and the dual.",
                    "label": 0
                },
                {
                    "sent": "It's also very, very similar.",
                    "label": 0
                },
                {
                    "sent": "This is the model representation of a 1 dimensional support vector machine, or of a support vector machine for one output where this is the visual representation for the method I I'm proposing where you have this.",
                    "label": 0
                },
                {
                    "sent": "Kind of mixing matrix or as in the talk before we had this learning of output kernels and this what I guess this matrix Q over here will correspond to a special matrix L. In the talk we have seen before where the structure of Q is dominated by the regularization term I imposed in the beginning.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I have a very very simple toy example.",
                    "label": 1
                },
                {
                    "sent": "It has just 50 training samples.",
                    "label": 0
                },
                {
                    "sent": "I'm using a static or fixed validation set of 100 samples and then another 150 samples to evaluate.",
                    "label": 0
                },
                {
                    "sent": "The different models I'm comparing the number of outputs is 20.",
                    "label": 1
                },
                {
                    "sent": "The number of independent components or different models that are directing is 3 an to do some very controlled experiments.",
                    "label": 0
                },
                {
                    "sent": "I just generate a feature matrix.",
                    "label": 0
                },
                {
                    "sent": "Directly, just drawing drawing random numbers I'm doing actually the same for for the ground truth of the model parameters, which I construct as a low rank matrix and add some some additive white noise.",
                    "label": 0
                },
                {
                    "sent": "The methods I'm I'm comparing other proposed methods which I indicate by MIMO then.",
                    "label": 1
                },
                {
                    "sent": "Something I denote as are are in the in the figures to to come, which are basically Ellis SVM models, in which are given the OR which are solved from the primal.",
                    "label": 0
                },
                {
                    "sent": "So it's a it's rich regression, but it's I could equivalently solve individual and then there would be an Alicia model.",
                    "label": 0
                },
                {
                    "sent": "It's trained on the individual outputs, an ID model selection for each of the individual individual outputs, so it's a fair comparison.",
                    "label": 1
                },
                {
                    "sent": "In that way, as a third model, I have ordinary least squares.",
                    "label": 0
                },
                {
                    "sent": "That is of course the fastest one to compute an to have have a benchmark.",
                    "label": 0
                },
                {
                    "sent": "I'm comparing it to ordinary squares, which only has to estimate part of the data, so I'm providing this or as Oracle, I provide the true matrix AR to the estimation, so I get some some bench.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This one is the mobile performance or the different model performances on the validation set for all S and.",
                    "label": 0
                },
                {
                    "sent": "Or else plus Oracle, it's a constant because there is no regularization termita tune.",
                    "label": 0
                },
                {
                    "sent": "Also for the LS SVM based model it's a constant because like each different model had an individual regularization parameter and I just choose the best model, indicated it here for the for the proposed method we see that there is a nice nice path and you can clearly identify the best regularization parameter which are used to obtain.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The results shown shown on this slide, which are the root mean squared errors per output on the test set, and you can see that.",
                    "label": 0
                },
                {
                    "sent": "In comparison to the the LS SVM based model which was trained on the individual outputs, you see a very nice improvement for most of the most of the outputs.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So why was I using a very small toy example therefore?",
                    "label": 0
                },
                {
                    "sent": "Let's have a look at the at the problems I have to solve and the primal.",
                    "label": 0
                },
                {
                    "sent": "It's a nuclear norm regularised optimization problem in the dual.",
                    "label": 1
                },
                {
                    "sent": "I actually have to solve 2 optimization problems this.",
                    "label": 0
                },
                {
                    "sent": "This SDP basically, and another feasibility problem which also boils down to solving an SDP.",
                    "label": 0
                },
                {
                    "sent": "But this one is only in like Dimension M * M, Where this is much, much larger.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In terms of number of dimensions, it's it's quite different if you only have one input, then the the dual is actually formulation is quite nice because as in standard atlases VMS or standard as the problem complexity scales in the data and not in the number of dimensions of the feature space, which can be very very large.",
                    "label": 0
                },
                {
                    "sent": "Whereas if you have L inputs.",
                    "label": 1
                },
                {
                    "sent": "Instead of just one, you get, not.",
                    "label": 0
                },
                {
                    "sent": "Only N squirt in the number of data, but it's N ^2 * L squared.",
                    "label": 1
                },
                {
                    "sent": "If you solve the dual problem.",
                    "label": 0
                },
                {
                    "sent": "So in that case I'm not really sure which of the two formulations to solve without to get an approximation of the feature map and then solve it in the primal or work with the dual.",
                    "label": 0
                },
                {
                    "sent": "Representation and deal with the with the higher dimensions.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "They're basically or.",
                    "label": 0
                },
                {
                    "sent": "I investigated two strategies for solution.",
                    "label": 0
                },
                {
                    "sent": "The one is based on an SDP formulation.",
                    "label": 1
                },
                {
                    "sent": "As I was saying, most or all of the problems RSVP representable and with tools like CBX it's extremely simple to implement those.",
                    "label": 0
                },
                {
                    "sent": "The advantage is that they have a very high accuracy, which I do need if I solve the dual problem because I have this feasibility problem and that depends that the duality gap is really small.",
                    "label": 0
                },
                {
                    "sent": "Because otherwise I can't make the reconstruction of the connection between dual and primal.",
                    "label": 0
                },
                {
                    "sent": "Downside is those don't exploit any of this structure in the problem, therefore have very high runtime costs and I'm limited to very small problems.",
                    "label": 1
                },
                {
                    "sent": "Another thing I tried to do was implement a very basic accelerated gradient projection scheme.",
                    "label": 0
                },
                {
                    "sent": "Had a higher effort structure, can be exploited, but if I.",
                    "label": 1
                },
                {
                    "sent": "If I was trying to solve the dual, I was not able to reconstruct my primal solution because I had a lot like the duality gap wasn't small enough for me to be successful in reconstructing the.",
                    "label": 0
                },
                {
                    "sent": "The relation between the two solutions.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "See and in conclusion, I proposed a novel identification schemes for nonlinear systems having multiple outputs.",
                    "label": 1
                },
                {
                    "sent": "This identification scheme exploits relations between output variables and I hope that I've illustrated at least a little bit that this this method is promising on a small toy example set, and I'll see.",
                    "label": 1
                },
                {
                    "sent": "Present its derivation of a nuclear norm regularised kernel based model in a primal dual setting and this primal dual setting is very easy to incorporate in this primal dual setting.",
                    "label": 1
                },
                {
                    "sent": "It's very easy to incorporate additional structure or additional prior information in the form of constraints or or playing around with the primal estimation problem.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As challenges in outlook via the prime challenges for me certainly to work on the numerical solution and then.",
                    "label": 1
                },
                {
                    "sent": "To be able to apply it on large scale real data real world datasets, because that's where the interest is.",
                    "label": 1
                },
                {
                    "sent": "Some other possible avenues for for research would be to look at other regularization schemes because the nuclear norm is not the only matrix regularizer you can come up with, and my my personal opinion is that in the field of system an indication there is actually a lot of this structure that could be exploited, so I would be hoping that there is a lot of a lot to benefit from from these kind of models.",
                    "label": 0
                },
                {
                    "sent": "With this I would like to conclude.",
                    "label": 0
                },
                {
                    "sent": "The presentation and thank you for your attention and.",
                    "label": 0
                }
            ]
        }
    }
}