{
    "id": "x4zq43lf3cllux4zk55z5vbrzeorptbg",
    "title": "Particle Filters",
    "info": {
        "author": [
            "Simon Godsill, University of Cambridge"
        ],
        "published": "Nov. 2, 2009",
        "recorded": "September 2009",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/mlss09uk_godsill_pf/",
    "segmentation": [
        [
            "So I'm one of the locals.",
            "You can't hear me.",
            "I might not live is that is that OK?",
            "Yeah good I'm out of the locals.",
            "Simon Godsil, I'm in signal processing here in the engineering Department, the same Department as Zubin.",
            "Well, I don't mind that, but I will not know, OK?",
            "To be talking about sequential Monte Carlo methods or particle filtering methods, it's in two sessions of the first session.",
            "Today is pretty much a basic session, so people that already know all about particle filters will probably not getting very much about this, or maybe some insights.",
            "Perhaps they can point out their own views on particular things.",
            "I say feel free to ask me questions and point things out along the way within reason.",
            "OK, so the application area that domain we're in is where we're looking at large sequentially evolving datasets where you don't necessarily want to do an inference in batch spending.",
            "A lot of time churning through all of the data in one go, and clearly there are vast numbers of applications that fall into this category.",
            "Sequential data evolving data tracking is where this methodology."
        ],
        [
            "Very first started up with us, or at least in earnest in the 1990s with the Seminole Paper by Neil Gordon and his collaborators Salmon Smith that says, Adrian Smith, the Great Bayesian theorist.",
            "But also in computer vision they started up around about the same time with the Andrew Blakes work and various other applications where these things are used routinely nowadays.",
            "So basically, as you'd expect, in a machine learning Workshop summer school, we mainly going to be distributing with dealing with probability distributions and uncertainty, so we'll be looking for ways to take a Bayesian approach to sequential updating of probability distributions as the data evolves, and in particular the probability distributions of some latent hidden state variables that we want to learn as they evolve.",
            "And obviously for this talk, I'm focusing on the sequential model Monte Carlo methodology.",
            "I think that's synonymous with the term particle filtering.",
            "I don't think there are any differences between those, although there may be some subtle interpretations.",
            "There are numerous papers around about this, I'm just pointing to a handful of them here.",
            "Perhaps Gordon Salmon and Smith was the 1st in recent times.",
            "Although there are papers going back to the 1960s and.",
            "Before where people were using sequential important sampling of various types.",
            "And.",
            "And then these other papers are sort of review papers that involved myself, but there are numerous other papers in this area for you to look out, so we're looking for estimating or finding the posterior probability distributions for some hidden process which."
        ],
        [
            "Call the state of the system, and those will typically be obtained from noisy, convolved or non linearly distorted observations, and we're particularly interested in this myth methodology with things that don't limit the class of functions and nonlinear processes, non Gaussian processes that we can deal with, so they vary in their vanilla form.",
            "They're very generic, they can work with pretty well any nonlinear state space model.",
            "Stochastic states based model you throw at it, at least in principle.",
            "They may take a lot of Monte Carlo samples to do so, but in principle they can do that.",
            "You'll find then that some of the more tailored algorithms, the things that have come about over the last 10 years or so of research may then be directed more towards specific classes of models.",
            "For example, major class of model that's been a big success with these methods is that those which have some partial linear Gaussian structure, so there's a bit of a model bit of the model which you can handle using a standard common filtering.",
            "Methodology and you should do that, and if you're effectively marginalizing that in a posterior probability sense from the equations and then you just do the hard particle filtering part on the nonlinear non Gaussian bit that's left behind.",
            "So that's an example of a case where there are very tailored methods, particular classes of models, but mostly what I'll talk about today, not so much tomorrow, but today will be for these very generic state space stochastic models.",
            "So we'd like to.",
            "Be able to estimate the hidden process online.",
            "I think I've said all of this.",
            "I don't need to go through anymore of this, there's just a handful of applications there."
        ],
        [
            "Let me move on.",
            "Blah blah blah people diesel go online people.",
            "People can read that stuff afterwards."
        ],
        [
            "So whatever I talk about today, well, I guess most people will be familiar with quite a lot of this list actually, especially I guess the first one, so I'll just establish the Bayes theorem form that we need for today.",
            "I will talk a little bit about Monte Carlo methods.",
            "I know that he had Murray's done a nice tutorial already.",
            "I wasn't here for that, so I don't exactly what he's covered, but I'll be.",
            "I'll be, I'll just survey a few bits of Monte Carlo methods that that will need.",
            "For today.",
            "I'll define the framework that we're in, so we pose these things using state space models, stochastic states based models.",
            "And the estimation tasks that were interested in in particular filtering, which is basically learning about the state at the current time as the data evolves.",
            "So as soon as you see the data you want to learn about the posterior distribution for the state at that time, and then if you want to give you or.",
            "Alternatively if you want to give us a bit of self a bit of retrospective look or forward, look through the data to get more reliable estimates out of the data.",
            "We may do smoothing, so that's statistical smoothing.",
            "And.",
            "One of the main building blocks for sequential estimation, and indeed a building block for some of the particle filtering algorithms that will see tomorrow is the Kalman filter.",
            "So I'm going to go through the analytic updating formula for the Kalman filter and the extended Kalman filter, which works for nonlinear models under certain conditions, but I'll consider the common filter in a rather neat probabilistic framework.",
            "Some of you will have seen this.",
            "Before it's available in various textbooks already.",
            "For example, I think I first saw it in the textbook by Kalman, but I know there are also not common common, doesn't like the probabilistic interpretation of the common filter at all, so we had him along, so he's not here today, is it?",
            "We had him along to a workshop on particle filtering in Cambridge of 1990s in 2006, and he pretty well disagreed with the whole foundations of the whole workshop, but he gave us a couple of nice.",
            "7 hours and it was great to have him along, but he doesn't really agree and doesn't really agree that stochastic processes even exist so physically not in a mathematical sense.",
            "So, but I will talk about the Kalman filter from a probabilistic point viewpoint, Bayesian updating of probability densities.",
            "For me, that's the neatest derivation of the of the common filter, and sheds a lot of light on this type of particle filtering area.",
            "Then I'll move into the Monte Carlo filtering area, just pose it generally how you do Monte Carlo filtering, filtering that doesn't quite solve the problem.",
            "It doesn't give you the sequential updating that you need with the particle filter, or at least it's not in a conveniently.",
            "Tractable form.",
            "So then I'll talk about the basic way of doing that.",
            "The sequential Monte Carlo bootstrap filter.",
            "That's that if you, if that's what I would call the vanilla version of particle filters, the simplest version, and then I'll talk about the general version that that allows you to deal with harder models using fewer particles through the choice of appropriate important functions.",
            "Tomorrow we will move on to other types of particle filtering.",
            "I'll also talk about some applications that we've worked on.",
            "Things like the little particle filter, smoothing these particle filters, the rare black polarized particle filter, and a very important area at the moment are MCMC with particle filters so they can be coupled in very powerful ways."
        ],
        [
            "Right base theorem and inference.",
            "Well, I expect we do all know about this, but I'm going to be talking about marginal inference.",
            "We have some observations why quantity of interest.",
            "Let's say that's X and we have some nuisance parameters in the model called those theater.",
            "But we can't form.",
            "If you like a sensor model that tells us what's the probability of our observations conditional on all of those unknowns.",
            "The required X on the nuisance parameters Theatre, and we will formulate the joint posterior probability for all of the unknowns in terms of that likelihood function at a prior distribution jointly over all of the unknowns, the X is in the theaters and of course on the bottom line of Bayes theorem we have this effectively constant term at least constant for any.",
            "Given model and data set Y so that term there is as it as in many Bayesian calculations is going to be neglected as a constant in each step of the particle filtering algorithm.",
            "When we do the Bayesian updating.",
            "And of course, if we want to do marginal inference for the quantity of interest, we will integrate out X using the marginalization identity from probability theory and then that thing would be the thing.",
            "If it's just X we're interested in, that's the that's the quality we would use to do the inference and not the joint."
        ],
        [
            "OK Monte Carlo methods.",
            "So this is actually an output from one of our particle filters or two dimensional particle filter out a particular to a 2 dimensional state vector or particular particular time and it comes from a non linear model that are very simple nonlinear model that's used a lot as a benchmark test model in particle filtering and this was one of the posterior PDF's that came out of that at a particular time.",
            "This is a kernelized density estimate obtained for it and we obtained that.",
            "Instead of trying to solve for this very intractable looking density, it certainly multimodal is probably not Gaussian.",
            "It certainly doesn't look Gaussian.",
            "Doesn't really look like a mixture of Gaussian, not not to a convenient number of components anyway, so we represented instead using the Monte Carlo representation.",
            "And that simply means that, well, ideally we'd like independent random draws from this PDF, and instead of the density will represent it directly in terms of the number of.",
            "Randomly samples points from this PDF, so that's the Monte Carlo representation."
        ],
        [
            "And that's a very convenient representation, in particular for calculating difficult expectations.",
            "So let's suppose we want to workout expectations with respect to some highly complex probability density P of X.",
            "So this one, then the expectation we may require in general will be some functional H of the state variable.",
            "The integral of that with respect to the probability density."
        ],
        [
            "Pay and as I said, we'll do that with Monte Carlo.",
            "Do it by generating random samples from P of X and the notation I use for random samples throughout is a superscript.",
            "So if I have the ice sample out of a large collection of random samples and I'll label that X superscript I for the life of the."
        ],
        [
            "Samples.",
            "Informally, it's quite nice to think about that as a Monte Carlo approximation to the density function itself, and using Dirac functions.",
            "The probability theorists don't like this very much, but it's it certainly gives you the right answers and it's and it's a nice intuitive way of thinking about Monte Carlo representations.",
            "So once we've got a random set of samples for a large number of samples and all drawn from this probability density function.",
            "X somehow, I haven't said how we generate them yet.",
            "We're thinking that we're approximating P of X as a load of point masses.",
            "Basically because these are all samples independent samples from P of X.",
            "These are this is an unweighted sample, so we have 1 / N just to normalize the approximation to appear."
        ],
        [
            "Sex.",
            "And then using this intuitive interpretation, we can easily see how things like approximations to expectations drop out of the formula, because we're going to take the expectation the same expectation that we tried to do before and we will now approximate that by plugging directly in our approximation to P of X, the density of interest.",
            "So that's the 1 / N times the sum of the Delta functions.",
            "Each Delta function.",
            "So I people use different notations for Dirac functions, I know, so the notation I have mostly here, although I think it's which is later on.",
            "Is is to say that this is a direct function centered at the point at the sample point XY considered as a function of the variable X, and I should say that I'm not I'm being LAX about random variables as well.",
            "There's very.",
            "There's no kind of confusion.",
            "I think in this in this talk also random variables and their realizations tend to be denoted by small by lower case variables like this, but I don't think it causes any any any confusion.",
            "In this context, so having done that, I've plugged in approximation to P of X, then because that's a solid Dirac functions, everything drops out, the integral drops out by the sifting property, and I just get an average of the values of the function H evaluated at all the sample points X.",
            "So I replacing an intractable.",
            "An intractable integral by an arithmetic mean related to the sampling positions, so very."
        ],
        [
            "Right forward to make Monte Carlo at Standard Monte Carlo approximation.",
            "In particle filtering so.",
            "You have seen proposal distributions in.",
            "I don't know whether even went through the.",
            "The important sampling in his talk.",
            "But suppose we want to draw instead of P of X, which we can't draw from.",
            "It's this complicated entity.",
            "We will propose from some simpler distribution Q, and the simplest way to correct that to generate a set of samples approximately from P of X is using important sampling, so we can do this by calculating inappropriate bias correction factor if you like that.",
            "The ratio of P of X&Q of X."
        ],
        [
            "So now important sampling is going to work like this.",
            "An important sampling with the base be the basis for most of the particle filters that I talk about.",
            "So the expectation then is done by simply replacing by adding in a Q of X / Q of X into the expectation.",
            "Pulling out a weight P of X / Q of X.",
            "This ratio here and now because I've made a Monte Carlo sample from Q of X.",
            "Instead of from P of XI can plug in our approximation if you like 4 Q of X, which is again the sum of Delta functions where these axes of iron are drawn from Q of X, not not not P of X, so plugging that in again, I get a simple formula for the.",
            "Now it's a weighted average with the weights proportional to the ratio of the target distribution P over the proposal or importance function Q like so."
        ],
        [
            "So the weights are proportional to the ratio they save the target to the proposal, and we can then think informally overweighted Dirac function approximation to the density.",
            "So if we want to do that, then P of X will be represented now in terms of these weights, times Derek function, and to make it make this a proper density function, the WS will need to be normalized to one but still proportional to P. Sorry, still proportional to P / Q."
        ],
        [
            "Right, so of course there are numerous ways of doing Monte Carlo, including Markov chain Monte Carlo, which which you've heard about, in which we will touch a little bit of an tomorrow in the particle filtering context.",
            "Simulated annealing is an example of Monte Carlo important sampling, which is the fundamental building block behind these particle filters quasi Monte Carlo."
        ],
        [
            "And so sequential Monte Carlo methods here.",
            "And just a trick that gets used throughout Monte Carlo inference, which will play a part in my particle filter derivation in a minute.",
            "Monte Carlo folds difficult integrals one integral that it solves nicely is the marginalization integral automatically be cause if I have two quantities, say the state and the nuisance parameter.",
            "In this case drawn from the joint posterior distribution for those unknowns."
        ],
        [
            "Given the data, why then it immediately follows that if I simply extract the samples?"
        ],
        [
            "X from that joint draw those are draws from the marginal for X, and similarly the theaters are draws from the marginal for theater."
        ],
        [
            "Informally, you can.",
            "You can see that drops out just from the factorization of the joint in terms of the marginals times the conditional, so that's the marginal for X, and that's the marginal for theater, so bear that in mind because we use that in the base."
        ],
        [
            "Particle filter derivation in a moment.",
            "But now let me define the state space models and the filtering and smoothing objectives of the basic particle filter.",
            "OK, so state space models are quite a general way of representing time series models.",
            "They include things like hidden Markov models on discrete state space.",
            "Is most of the Standard Time series models things like auto regressive, moving average Arma models, they don't apply to some of the integrated models that appear in finance because you can't represent those with the finite dimensional.",
            "State vector and also all of the special models that we can try for applications in tracking computer vision, finance, communications and so on so."
        ],
        [
            "I think we need anymore of that text or yes yes yes, so I'm going to do all of this derivation in terms of of a Markovian state space model.",
            "In fact, that's not necessary, but it simplifies the notation.",
            "So for example in the rare black guys particle filter that we'll hear more about tomorrow, you're effectively dealing with a non Markovian set up, and it does work, but the notations a bit more cumbersome right?",
            "The notation are uses.",
            "Uh.",
            "Column vectors will be standard typeface, lowercase, so for example the state at time T will typically be X, sub T and the matrices."
        ],
        [
            "This will be just standard typeface capital letters, just to avoid a load of heavy heavy typeface notations.",
            "Will consider a time series, then with states X of T on sometime access nought.",
            "Oh gosh, I never noticed that before N 1 two up to T. The states evolve in time according to a probability model, so this is a stochastic state space model.",
            "And we'll assume, as I say, a Markovian structure, so that if I look at the distribution of a new state at time T + 1, given all of the previous states up to that time, it will only depend on the previous state X of T, and I'll always denote that here, as that density find this probability density function.",
            "I'll do note that as F of X2 plus one given expertise, so that's the dynamical model, or the state space model underlying."
        ],
        [
            "The state's evolution.",
            "We received partial observation again, a stochastic observation of the states through some observation, a sensor function or likelihood function for the set of observations biote which are assumed to be independent conditional upon the states.",
            "So again, that's a kind of a Markovian assumption about the observations.",
            "So a new observation.",
            "Conditional upon any of the, uh, the whole state sequence up to the time T + 1 and any of the previous observations will only depend on the current observations.",
            "So that's Markovian assumption about the observations, and I'll always label the observation density as lower case G. So we've got the dynamical model F and the observation density G. Now these will be assumed will be specified, so we're not learning the dynamical model or the observation model in this in this setup, although of course they can be parameterized by extra parameters, which do mean that we learn the structure of them to some extent, and one could do some kind of nonparametric learning in a Bayesian set up too if you really wanted to learn something within about F&G within this framework."
        ],
        [
            "So there is the model will be using then the state evolution density and the observation density.",
            "And this I'm using this symbol to denote that the random variable to the left is drawn as a sample is drawn from the density on the right."
        ],
        [
            "And because of the independence assumptions that I've made, the conditional independence assumptions, we can write the joint density for all of the states from North through T and all of the data in terms of an initial state density F of X nought.",
            "To get things started.",
            "And then using the probability chain rule we can chain in all of the conditional densities for the state dynamics, the FS.",
            "Times all the observation densities overall times from nought to T. So we can.",
            "This thing is fully specified, so I mean actually, what questions do we need to answer but the?",
            "We want to look at the conditional distribution for X given some set of observations Y.",
            "Then we won't know anything in general about the properties of this joint density, even though we can write it down, we won't know things about its moments and.",
            "Quantities that we want to estimate, except in special analytic cases like the linear Gaussian model.",
            "I also sometimes use the notation X North through T to be the vector of data points from North through T, and Similarly the sorry the vector of States and wine or through T to the vector of observations not through T."
        ],
        [
            "But and represented in a sort of a graphical model type thing to work.",
            "So we have our hidden state sequence proceeding through time connected via the dynamics F. So there's a stochastic model connecting each of these conditional on one another, and then you've got the observations hanging off those via some observation density G."
        ],
        [
            "So just to look at two very simple examples of how you would set that up.",
            "Any auto regressive model observed in noise, so the hidden state process I'm going to call zed.",
            "So instead of two linear autoregressive model is where is made up as a linear weighted sum of previous zeds.",
            "Plus some noise term of T and the observations.",
            "Why are the hidden states out of T + a noise term W?",
            "I will say that A&WT or independently distributed and for the sake of argument argument there zero mean Gaussian.",
            "So the simplest possible set up, I guess just about the variances of those are Sigma re squared and Sigma W respectively.",
            "Uh, those are fixed it now we're not doing parameter learning for this particular state space model set up, although one could in principle append extra parameters onto the state vector within a particle filtering framework.",
            "So the days of I for the AR coefficients, the weights on that prediction, and these are also fixed and known just for this set up here.",
            "And we observe why.",
            "I'm the unknown.",
            "Is the signal set."
        ],
        [
            "So you can form a state vector.",
            "We have to do that by augmenting zed of two with some previous state values, as in a standard sort of state space.",
            "Deterministic state space model.",
            "And then we can set up the state space model in the required form by saying that X of T is a matrix A times the previous X of T. So that's the one start.",
            "It said T -- 1 plus noise term epsilon of T, which is a slightly modified version of UFT and.",
            "Y of T the observation that is a matrix B times the state X just the noise term."
        ],
        [
            "Have tea.",
            "Where the matrix say that you require."
        ],
        [
            "This thing here is simple."
        ],
        [
            "Put together so that the top row gets defines the fundamental equation of the autoregressive model and then the remaining rows.",
            "Just Simply put in the previous elements of X to the next time point, be the observation function.",
            "Then is a is in fact a row vector just pulling in the first element of the state vector X into the observation."
        ],
        [
            "And finally, the noise term has covariance matrix like so.",
            "So just there's only one nonzero covariance element corresponding to the Y of T that you require in the model."
        ],
        [
            "And we can put that directly, then into the form that you need to evaluate density functions and so on.",
            "Because the density function for the dynamics is just a normal density function for X of T + 1 with mean given by a times the previous state X and covariance given by Capital Sigma Re similar X or epsilon and the observation function G of Y given X.",
            "Another normal function centered on BX and with various."
        ],
        [
            "Sigma W ^2.",
            "So this is the simplest, nicest, most benign type of state space model.",
            "It's the linear Gaussian state space model.",
            "Well, I guess the perhaps the hidden Markov model is just as benign in that it's on a discrete state space, but in a continuous state space.",
            "This is the simplest version and.",
            "As an important special case of the state space model is used extensively to construct algorithms even in the nonlinear case, with things like extended carbon filters and in the nonlinear Gaussian case with things like the rare black realized particle filters.",
            "So these these linear models will be."
        ],
        [
            "A fundamental building block in some particle filters.",
            "Or we can look at fully nonlinear model.",
            "This is a sort of benchmark test model that was used in a lot of the early papers in this area.",
            "So here we can reconstruct some arbitrary nonlinear function of the previous state to predict the current state and add some noise onto it then or it doesn't have to be additive as long as you can calculate as long as you can sample from the transition density.",
            "But here it is additive and the observation function again can be some arbitrary, pretty well arbitrary nonlinear function of the state.",
            "And things will still work here.",
            "I've just specified V to be Gaussian and W to be independent Gaussian with particular variance.",
            "Again, that's very easy to put into the state space form that we require for the basic formulation, so the F function, the dynamical model is again a normal distribution centered upon.",
            "This laser pointer is a bit tricky when it keeps dying out centered on the function A of X with various Sigma V squared and the G function of the observation function is a normal distribution centered upon the nonlinear function.",
            "Be a vex with some variance.",
            "Sigma W ^2."
        ],
        [
            "OK, so that's all simple.",
            "Just a simple example of how to set up the state space model for this.",
            "This scenario and the estimation tasks.",
            "Well, let's suppose we've seen all the observation from some time up to the current present time T, and we wish to infer the hidden states.",
            "So there's a sequence of hidden states running from naughty.",
            "Or is that a better one?",
            "Thank you.",
            "Oh nice right?",
            "So we have some hidden states exonaut."
        ],
        [
            "Booty.",
            "And some of the tasks you might want to do within a Monte Carlo filtering setup.",
            "Well, filtering itself is concerned with the marginal distribution of the current state X of T, given all the data from nought through to T. So we might be interested in actually looking at that posterior distribution itself or forming some kind of expectations with respect to it.",
            "For example, if we set the Zeta function just to be XLT itself, then we then we're calculating the posterior mean.",
            "Estimate which is the minimum mean squared error."
        ],
        [
            "Automated for the state X.",
            "We may also wish to allow ourselves some lag to make a more reliable estimate, so we may do smoothing, for example, estimating that the state of lack of."
        ],
        [
            "Low.",
            "Or we may wish to do fixed interval smoothing.",
            "Try and get the distribution of the entire state sequence over some time axis North route."
        ],
        [
            "So and that just illustrates that filtering is concerned with immediate estimation.",
            "As soon as you get the new data point smoothing gives you some look ahead of future data points and hence you should get a tighter distr."
        ],
        [
            "Fusion on the on the states.",
            "Right, so filtering though is the main focus of a lot of this work, so let's consider filtering at time T. Suppose we've solved the filtering problem up to that time, so these things are desired right in a recursive fashion.",
            "Usually we've got the filtering distribution, but we want to update it one time step with the input of a new data point Y T + 1.",
            "In principle, we could do that.",
            "We've got the filtering recursions first of all, a prediction step, so we want to first of all take.",
            "The filtering, distribution, and updated one time into the future to give us the distribution of X T + 1 given all the old data.",
            "Or we could do that by taking the joint distribution of the old state and the new state given all the old data and marginalizing with respect to X. X of T The old state.",
            "We can factorize that in terms of the thing that we have.",
            "So this fact arises in terms of the filtering density that we've already solved that time T. Multiplied by the conditional distribution, the conditional density of the state at time T + 1 given the old state and all the old data.",
            "But because of the assumptions of the model, that's not other than the state transition density F. So we can write that in terms this marginalization in terms of the previous filtering density times the state transition density to take you to."
        ],
        [
            "Time T + 1.",
            "And then Bayes theorem kicks in because we now want to incorporate the effect of a new data point, Whitey plus one.",
            "Well that's got directly then from the mailing terms in the model we've already got the predictive distribution of X T + 1.",
            "Given the old data.",
            "We multiply that by the observation density, the G of Y T + 1 given X, T + 1 divide through by the normalizing constant P of Y T + 1 given YN rooty, then based there was given us directly, then the corrected formula for the new filtering distribution.",
            "So that's all very straightforward, except that you probably can't do this integral in close form.",
            "It could be high dimensional, you've got all the usual problems of.",
            "Dealing with nasty forms.",
            "Naughty unknown forms for for the P and the F There."
        ],
        [
            "And so, but in principle it operates simply.",
            "You just progress through time.",
            "Adding more data points as you go.",
            "Why T + 1 YTY T + 1?",
            "You do the filtering, getting each time step, so we solved it at T -- 1.",
            "You do the prediction Step 2 to predict one state into the future.",
            "Then you correct it using Bayes theorem, predict correct.",
            "So it's a leap frog type approach through time.",
            "But as I say this can't be done in general and approximations must be used, especially when X is high dimensional and F&G are non Gaussian or nonlinear."
        ],
        [
            "Right, so I'm going to go through now.",
            "The basics of the Kalman filter because of the saying that this is fundamental to some of the particle filters, and there's a very fundamental idea underlying sequential updating, Bayesian sequential updating.",
            "Anne.",
            "OK, so it applies for cases where the model is linear and Gaussian.",
            "What do we mean by that?",
            "In fact, there is a slightly more general version of this, but but let's stick with this for them.",
            "For present purposes, the linear, Gaussian state space Model says that the state transition density is the Gaussian distribution, where the mean is a linear function of the previous state.",
            "So a matrix a times the previous state X.",
            "The observation density is similarly linear and Gaussian.",
            "It's a Gaussian density for why with a linear function of the state X, and if you've got that, then you could apply the common filter and the notation is that kind of graphic N is a normal distribution for X with mean vector view and covariance matrix Q."
        ],
        [
            "We can write that equivalently as an additive noise model, so we've got a way of generating the next data point.",
            "The next state point in if we wanted to synthesize some data from the model, we would just write the next state is a times the previous state plus the noise term.",
            "And similarly Y is obtained from the state X plus noise again.",
            "Where these Wiesen WS can be generated independently as zero, mean Gaussian vectors with covariance matrices C&D, respectively.",
            "And I've said that they are independent overtime and also independent of one another.",
            "In fact, you can make them also dependent on one another, and there's a version of the carbon filter that deals with."
        ],
        [
            "Might as well, but we don't need that here.",
            "We do also require everything must be linear Gaussian, so the initial state must be Gaussian distributed.",
            "I think our previous I do notice that F of X and that's the same thing.",
            "The initial probability density for the first state that I'm not."
        ],
        [
            "OK, so the first thing we need to do is to get the prediction step.",
            "So if you remember.",
            "Where we?"
        ],
        [
            "Heading is to solve these two equations and we're going to do it analytically in closed form for the linear Gaussian case.",
            "So the first one involves marginalizing out the current state from the old state from the joint density.",
            "And."
        ],
        [
            "Here it is, so that's what we needed to do.",
            "Carry out this integral."
        ],
        [
            "And we suppose, as before, that we've solved the problem at time T, so it's recursively defined.",
            "We say that we've got the filtering distribution at time T. There's a normal distribution with.",
            "With mean same UTI, covariance PFT."
        ],
        [
            "And we know that to get to the next state from the previous equation that we don't even need to go back to that, we can generate the next state from the previous state just by multiplying by A and adding the random noise."
        ],
        [
            "Speak.",
            "So it's really just standard transformation of variables.",
            "We've taken the random variable X with, multiplied it by matrix A.",
            "Added noise to it so there's convolution there of the densities and produced X of T + 1.",
            "So we can get to the density for XT plus one straightforwardly because we know the density for X of tea.",
            "Is this Gaussian and we've got passed it through that.",
            "Updates."
        ],
        [
            "Set and therefore the density of X T + 1 conditions on the same bit of data is another normal distribution, but it's me.",
            "This modified.",
            "The mean is a times the original mean mu of T because we multiplied by a.",
            "And we've added some noise on so so so so we need to take P and converted into a P * A transpose that deals with this multiplication of X.",
            "But we've also added it on the noise VNV had covariance matrix C, so that gets added on there.",
            "Sorry, no."
        ],
        [
            "I've done that right.",
            "I'm sorry, yeah.",
            "So yeah, so this was the covariance matrix, so we've added on zero mean Gaussian noise V. So hence we added on its covariance matrix C onto the AP, A transpose term.",
            "So that gives you the formula for doing the update if we started with the Gaussian density at time T. Sorry, that's the."
        ],
        [
            "Actionstep and the correction step the updating step via Bayes formula just involves taking what we just calculated.",
            "That prediction density or Gaussian multiplying it by the Gaussian for the observation density.",
            "And correctly normalizing it because for a fixed data set Y, that will be a constant term on the bottom line there.",
            "So we just need to calculate that."
        ],
        [
            "Normalizer for the, for the multivariate density.",
            "And substitute to get him well.",
            "We don't worry about too much about this arrangement, but we've taken the normal distribution for the predicted density for X multiplied it by the observation density for Y conditional upon that new X.",
            "Plugged everything in and rearranged it and found that the correct normal with the right normalizing constant is.",
            "This one."
        ],
        [
            "With this particular mean and covariance, well, don't worry about the details of that you."
        ],
        [
            "Like that through in your own time afterwards, and we can rearrange that using the matrix inversion lemma to give a slightly simpler form.",
            "We don't need all the details."
        ],
        [
            "Is right now I'll just put them there for reference, but the whole recursion gets summarized in terms of a prediction step on the means and covariances and an update state on the means and covariances, which progressives you from a Gaussian at time T to another Galaxy at time T + 1."
        ],
        [
            "There you go.",
            "So so you don't.",
            "We don't need the precise details of that at the moment, I'm just outlining the principles behind it and more importantly what the things you can and can't do with the Kalman filter that arises from that.",
            "So the common filter is a fundamental tool is still substantially used in many estimation and tracking tasks.",
            "You can use it to estimate the system state sequentially by taking a, for example, the mean estimate for the state.",
            "You can obtain an uncertainty estimate about the state using the state covariance.",
            "You can do recursive least squares when the state doesn't evolve.",
            "This time is like a fixed parameter that's basically a type of a common filter.",
            "You can do fixed lag smoothing by augmenting the states, which we include, not just the current state, but some previous states, so that'll get you a bit more mileage.",
            "You have to modify the state space model to give you the correct update on the axes, but otherwise everything follows through the same.",
            "And similarly if you want to do fixed interval smoothing, estimating the whole sequence of X is.",
            "Given a whole sequence of wise, then the common smoother operates backwards in time, so you run a filter forward through the data, and then there are equivalent equations backwards through time that take you back through the data to estimate the posterior distribution of particular time point T. For example, recursively backwards in time, given all of the data."
        ],
        [
            "And you can do similar things with particle filters, so those are also particle smoothers, which I'll talk about tomorrow which which passed the Monte Carlo representation backwards through time.",
            "Having gone forwards through time with the standard filter.",
            "Now probably most useful for our concerns here.",
            "For the particle filtering is the likelihood evaluation, so I really neat thing that you could do with the Kalman filter, which is great for model choice in time series models and parameter estimation in time series models, and also for this special type of particle filter the radio black realized particle filter is likelihood evaluation.",
            "You can effectively marginalized out the complete state sequence and just look at the probability.",
            "For the data.",
            "So that's great for us."
        ],
        [
            "For things like Bayesian model choice, if you want to compare different types of state space model on the same data.",
            "So we can do the same kind of tricks with the mass of the common filter.",
            "The first step of the carbon filter took us to the prediction density.",
            "The prediction of the new state given all the old data.",
            "So that was a Gaussian density which with an updated version of the mean and the covariance from obtained from the previous time step, but nevertheless are Gaussian dense."
        ],
        [
            "See.",
            "But now how will the data points generated from that new state X of T + 1?",
            "Well, we know that from the linear state space Model Y of T + 1, the new data point is just B * X of T + 1 + A new noise term.",
            "Wat plus one.",
            "So that's exactly the same kind of setup that we had before.",
            "Is a linear transformation of a Gaussian random variable X T + 1 plus an independent Gaussian noise W?",
            "So then we know what the distribution of YT plus one is conditional upon.",
            "The past the why North route?"
        ],
        [
            "Hence, using the same idea, the transformation of Gaussian random variables with the addition of a random noise vector, we can immediately obtain the distribution of the new YT plus one given conditional on the same thing as before.",
            "The YN through T. It's now transformed mean.",
            "So you take the predictive mean and multiply by be the observation.",
            "Matrix.",
            "It's the covariance of the added noise and then a corrected version of the of the covariance of the previous state multiplied by this, the state transition matrix.",
            "Sorry, the observation matrix B.",
            "And finally, having attained that conditional, you can use the probability chain rule to obtain the entire likelihood for a whole sequence of data.",
            "Simply chaining all of these conditional densities through time, the new one conditional upon the old set from Northrop.",
            "So effectively you just store all of these as you go and then add on multiply on subsequent ones.",
            "So that's the.",
            "This result will be will be fundamental to coupling of common filters and linear processing with with."
        ],
        [
            "Michael filters what you can't you do with the Kalman filter.",
            "It's only optimal for the linear Gaussian model, so it's not much good for a lot of the scenarios.",
            "We'd like to consider in practice.",
            "And in some cases it will give you the best linear estimator.",
            "The mean squared error sense, but it may not be good enough for models we are interested in.",
            "And there are numerous ways of dealing with more general models or based on numerical approximations to the filtering recursions.",
            "For example, and I'm really not not even touching on the approximation literature.",
            "Here Gaussian, some filters, unscented Kalman filters and so on.",
            "We can.",
            "Consider two important cases, the probably the one of the first attempts at.",
            "This would have been the extended Kalman filter, which linearizes a nonlinear system and uses the carbon filter, and then the Monte Carlo particle filter, which is our main concern."
        ],
        [
            "So the extended Kalman filter?",
            "Well, I shouldn't spend very much time dwelling on this.",
            "But basically if we replace the linear state space model with a nonlinear one, that's got some nonlinearity in the update, the nonlinearity in the observation function through some nonlinear functions ABI can linearize that with the Taylor."
        ],
        [
            "Mansion.",
            "I'm going to basically linearize about some points mu.",
            "And I'm going to.",
            "Then substitute these approximations back into the state space model, leading to a linear approximate system, which I can then solve the common filter, and I'm away again, and there are higher order approximations that you can use which will also give you a better approximation, but they do require you to be able to evaluate these partial do Jacobian terms, and so the partial derivatives it's approximation is unimodal.",
            "The posterior density is always assumed to have just one mode, which which isn't desirable.",
            "And the tracking performance and error covariance estimates are suboptimal and can be very odd."
        ],
        [
            "Reliable.",
            "So.",
            "Yes.",
            "Before him, there was a term that, depending explicitly on T, was a cosine 1.2 T, yeah.",
            "Well, can you even do that in the?",
            "If it depends on two, that's fine.",
            "You would really need arise at each time step.",
            "I think you can.",
            "Can you do that one with a?",
            "Can you do that?",
            "Non linear model with an EKF?",
            "You can't get any.",
            "Yeah, so you basically redo the linearisation each at each time step at the appropriate cause costita.",
            "So the question relates, let me just flip back to this nonlinear model.",
            "I mean I haven't done any care for actually on that model, but I think it can be done.",
            "Yeah."
        ],
        [
            "This one, yeah.",
            "So basically, you're linearisation.",
            "Here's your nonlinear function for the state update, and it's got an awkward term involving time.",
            "I don't think that presents a problem because if you would just get a slightly different linearisation for each time step.",
            "I think it still works.",
            "Yeah it yeah, it just becomes it.",
            "Yeah, so effectively it just becomes a constant offset each time in the linearisation.",
            "Yeah yeah yeah you don't need to write it, so that's that's a red herring.",
            "It doesn't.",
            "That doesn't bother us for that, doesn't bother the ukf.",
            "For this model will bother the Ekso Becausw.",
            "Importantly, it's got multimodality in the observation function, becausw, you've got his X squared term here, which means there's always ambiguity between XP at plus or minus a value.",
            "So the CFV extended carbon filter won't routinely be able to track both both positive and negative going parts of the posterior density, which is one reason why you wouldn't want to use it for that model.",
            "Right, see if I can find where we were.",
            "Yeah, but thanks for pointing that out."
        ],
        [
            "I think we're here, yes.",
            "Right, so Monte Carlo filtering man, so if we're just concerned with calculating expectations with respect to the filtering density, this is the equation with interested in.",
            "The integral is intractable, and we're going to resort to some kind of Monte Carlo integration, so ideally we'd like to be able to draw IID samples from the filtering density somehow.",
            "Plug them in and get estimates.",
            "H hearts of H hat of each bar of the meeting, which will simply be the arithmetic mean of those sampled values H of XI.",
            "XIFT is the ice sample from a large Monte Carlo collection of N Capital N samples."
        ],
        [
            "'cause we can't do that in general we won't have access to direct samples from peer peer from the filtering density.",
            "If we did, we'd pretty much solved the problem from a Monte Carlo perspective anyway, so Monte Carlo is really all about.",
            "Julie, about how do you actually draw samples from, indirectly from some very hard target density?",
            "So in this case we could do this using important sampling.",
            "In principle we can't anyway, so we would take some.",
            "Alternative distribution for X of TSAQ of X of T. Call it the importance function.",
            "And there is a minor technical requirements on that, principally that it has the same support as the least is as large as support as the as the filtering density P of XT given North through T. Now we make N random draws from this proposal function Q instead of P. So you now have a different set of Monte Carlo samples drawn IID from Q of XAT."
        ],
        [
            "Problem almost solved, but not quite so to do important sampling you don't have to make a correction to ensure that the expectation estimate is good and the required correction would be the same as we had for the static important sampling at the start of the talk and call it the importance weight W and it would be the ratio of the filtering density evaluated at the sample X2, Y divided by the importance function.",
            "The density that you sampled from Q.",
            "Again, evaluated at the sample points XI of T."
        ],
        [
            "And then if we've normalized the importance weights, if we don't go ahead and take these WS and normalize them to sum to one, we've got our approximation.",
            "Are Dirac function approximation to the filtering density, so it would approximately be this weighted sum now of the right functions, with the weights proportional to the ratio of the target filtering this density divided by the importance function Q and normalized such that they sum to one but still proportional.",
            "To that ratio."
        ],
        [
            "Which again gives you weighted sample estimates for the expectation.",
            "And this is just restating what we had before."
        ],
        [
            "Yeah, we don't need to work that through.",
            "That's just working through the same steps taking our approximation for filtering density is now our weighted sum of Dirac functions and showing that the expectation drops out as a weighted sum of H is evaluated at the."
        ],
        [
            "Propoints that's right, that's all.",
            "Rather glib.",
            "Actually, of course, we're not going to be able to do this because we won't be able to calculate the weights, so there is going to be another step coming.",
            "But for the time being, let's just talk about resampling briefly.",
            "So in the sequential setting when we're going to be progressing this important sampling from one time point to the next to the next to the next, the whole important sampling paradigm will fall down because we'll find that weights in this weighted importance."
        ],
        [
            "Sampling.",
            "Will become very degenerate overtime because of the way we construct the sample, or we'll see more of that in a moment.",
            "In by degenerate I mean that one weight will carry all the probability math.",
            "So one way would have would be one and the others would all be very close to zero or one would be on."
        ],
        [
            "Well then the others would be very close to zero, which means that it's a very poor Monte Carlo representation of the density.",
            "And so your estimates could be unreliable would be unreliable.",
            "So resampling kind of fixes that.",
            "Now re sampling is a bit of a.",
            "Conceptual problem in particle filtering.",
            "You know, the theorists have done analysis of this resampling thing than under certain circumstances to find out how the errors accumulate overtime and there's stuff you can do a little bit, you can do not for every type of resampling scheme, but it's a bit of a black art.",
            "How why you need it and how it works.",
            "And indeed some people is Radford Neal here this version, Radford had had a long running debate about whether you should use.",
            "Resampling or not, in this type of these type of sequential importance sampling schemes, because they do in fact in the introduced Monte Carlo error, but nevertheless overtime they are absolutely essential for reducing the accumulation of error.",
            "More about that later though, but recently what is it actually it's?",
            "Basically, instead of proceeding through time with weights accumulating as you go through time, we can take the Monte Carlo set and resample it so that they have uniform weights and the way you do that is to take.",
            "Go through N times, where N is the number of particles.",
            "Value could have an even be end times, but some large number of times you simply choose for a new particle X dash device to be equal to the previous.",
            "Any of the previous particles X&Y with probability equal to their weight, so it's a sampling with replacement from a multinomial distribution having weights W and having done that, at least in the limit as the number of particles is very large, you've got an equivalent.",
            "Representation of an particles but with weights set to 1 / N and the idea being that any particles were very tiny weights never or hardly ever get get chosen in this resampling stage, but any with high weights are presumably very important for the representation.",
            "Those get selected very often, so you end up with a replenished set of samples that's good for propagating to the next time step.",
            "Which you wouldn't have had otherwise without the resampling, but you wouldn't want to do this every time step because it does introduce some Monte Carlo error of its own, so you basically wait until the samples have become a bit impoverished and degenerate, and then."
        ],
        [
            "You do the resulting.",
            "OK, so I think that's just text that summarizes what I've said.",
            "This is.",
            "This is the standard multinomial resampling scheme.",
            "There are much better ways you could do this that give you a slightly better performance using ideas from Monte Carlo stratification and so on."
        ],
        [
            "OK, so we have a general scheme here.",
            "Then for approximating the filtering density overtime and also its expectations.",
            "But it doesn't quite work in in the sequential context because we can't calculate the importance weight, so indicate the importance weight.",
            "We needed."
        ],
        [
            "Direct access to the filtering density to evaluate the weight.",
            "We may well be about able to evaluate Q.",
            "The proposal we almost certainly won't be able to evaluate P. The target filtering density, so we need one more."
        ],
        [
            "Step in here."
        ],
        [
            "And this takes us then to the sequential Monte Carlo filter or the particle filter.",
            "So the generic solution to this involves a repeated important sampling and resampling sequentially through time.",
            "And it mimics the filtering recursions in a Monte Carlo fashion, so it does exactly the same thing as the common filter, but using a Monte Carlo version of the filter of the steps."
        ],
        [
            "And so to outline the broad principle behind it, let's suppose that we have a collection of samples.",
            "Again, we've solved the problem at time T, so we have an inner Monte Carlo says that means we've got a collection of samples XI of T, drawn from the correct filtering distribution P of X of T. Given all the data up to T, and again we can write that in terms of unweighted Dirac functions if we like.",
            "Here's where I switched notation.",
            "I'm afraid we're different.",
            "Definition of the Dirac function centered upon XY."
        ],
        [
            "Option of X.",
            "We substitute that into the prediction equation and see what drops out.",
            "So we've got.",
            "This is what we needed to do for the first step.",
            "Of the filtering equations.",
            "So the first step involves taking the filtering distribution from the previous time step, which we've now got.",
            "We've got a Monte Carlo representation for that, multiplying by the state transition density and integrating out the previous state X of T. So we simply take this and plug in the previous times approximation to the filtering density like so.",
            "Where these are the samples obtained at the previous time T. And then do the integral using the sifting property again, so we end up just in the not like with the normal Monte Carlo integral with the arithmetic mean of all the transition densities F evaluated with the previous samples locations XT of I."
        ],
        [
            "And then we can do the correction step because we could take that and plug it directly into the required place.",
            "In the correction formula, the Bayes theorem correction formula so that involves the likelihood function G. And the approximation for the filtering density for the prediction density like so this is a sort of a big mixture density as a kernel kernelized version of the prediction density involving the transition density as a kernel.",
            "Animals with one over and still put on the front there and this constant from the bottom line here the conditional likelihood."
        ],
        [
            "And actually, I mean that really is it because having got their sequential Monte Carlo methods?"
        ],
        [
            "Basically, clever ways of drawing a lot of samples from that updated density.",
            "And how are you going to do that?",
            "You could use any Monte Carlo method.",
            "Do you like you have to avoid some of the pitfalls?",
            "For example, you don't really want to be evaluating this entire summation of N kernels every time you every time you make a new sample, so that might be something you could could avoid.",
            "There's an extra bracket there.",
            "I'm sorry bout that, just notice that.",
            "But apart from that, if you can think of some auxiliary variables, way of avoiding that Salvation, you could use any type of."
        ],
        [
            "Monte Carlo solve this problem.",
            "And that's really what all the different variants of basics are.",
            "Gradual Monte Carlo about efficient ways of drawing from that target density.",
            "So basically just Monte Carlo methods to produce a load of new samples from the approximation to the new filtering density at 2 + 1."
        ],
        [
            "'cause there's a lot of details behind that.",
            "Which is where I'm heading next.",
            "They can be done by any Monte Carlo means you like.",
            "If you can do things like form and envelope function for for the updated target distribution.",
            "This thing here then you could do rejection sampling to get some exact samples from it.",
            "People have done that.",
            "That's the kind of thing that was done by the fairly early days.",
            "Bye bye crunches group.",
            "Other people have tried it.",
            "The most common procedure, as you have gathered by now, is an important sampling approach.",
            "That's a nice, simple, fast way of doing it.",
            "You can put in MCMC here.",
            "There's absolutely nothing.",
            "That stops you just taking."
        ],
        [
            "This thing the updated filtering, distribution and running a uh at MCMC procedure you can always evaluate this target distribution up to a normalizing constant at any proposed value of the new state, so you can simply run a big MCMC chain on this, and this was something that was done by some of the robotics people at Georgia, Georgia Tech, Dirt and Co."
        ],
        [
            "But that's a rather slow filter because you do."
        ],
        [
            "To evaluate this sub examination at every time.",
            "Every time you."
        ],
        [
            "Can you update?"
        ],
        [
            "Then you can put in special Monte Carlo schemes as well."
        ],
        [
            "That may also give."
        ],
        [
            "Results.",
            "And that, then, is the joint posterior distribution for the old state and the new state given the old data.",
            "And then you'd like to take that as before, and we'll call this step one and marginalized out the old state.",
            "And finally, take that marginalized predictive distribution for X T + 1 and plug it into the Bayes formula to get you your updated corrected filtering distribution at T + 1."
        ],
        [
            "So we want to mimic those three steps by Monte Carlo operations.",
            "Start off as usual with the collection of large collection of samples from the correct distribution at."
        ],
        [
            "Time T. Course you could use those at time T to do any estimates you needed at time T, make histogram estimates, calculate Monte Carlo expectations."
        ],
        [
            "Etc.",
            "But now let's simulate step nought or so."
        ],
        [
            "Nought is done simply by appending a new States T + 1 onto the old state X of T. The ice sample of it.",
            "For each particle I.",
            "And drawing a new state XD plus one from the state transition density.",
            "So it's simplest possible update, you could probably think of for this model.",
            "Just take the old XD.",
            "Add a new X T + 1 onto it drawn from the state transition density.",
            "So in the models we've seen so far, that just involves multiplying X of T by a matrix in the linear model and adding some noise to it so that sampling is simple in the nonlinear model.",
            "It was just a matter of calculating the nonlinear function A.",
            "Of X and adding noise to it.",
            "So very often this step is trivial too."
        ],
        [
            "Compute.",
            "Having done that, we've got step nought, because that's now a joint draw from the predicted distribution with XT&X is 2 + 1 given wynaut through T and then.",
            "So and then we've effectively now solved step one."
        ],
        [
            "Because we recall from the basic Monte Carlo properties, we've gotta draw from a joint density for XD and XD plus one we simply throw away the sample for X of T that we have from that pair.",
            "Then automatically with marginalized and we're left with the sample just for X T + 1 given Y nought through T. So we've automatically done step one and we now have a random random sample from the required marginal distribution.",
            "XD plus one given Y.",
            "Not through T."
        ],
        [
            "And then Step 2 is just a reweighting procedure.",
            "We gotta calculate.",
            "We've got plug in.",
            "We've got.",
            "The samples from the predictive distribution.",
            "And Step 2 gives us the appropriate importance.",
            "Weight.",
            "Well, how do we get the importance weight we would need where we want to look at the target distribution for the next time step?",
            "That's clearly what we want and divide it through by what we've proposed.",
            "Well, we now have a sample from that, so the proposal distribution Q is equal to that.",
            "So we put that on the bottom line for Q and expand out the top line using Bayes formula as before, so this was the correction step from Bayes theorem precisely."
        ],
        [
            "Press precisely this."
        ],
        [
            "And it simplifies down then, because now this cancels out in the ratio and we have something that's proportional, just 2G of Y T + 1 given X T + 1, because that term there is a constant.",
            "It only depends on the current data set Y.",
            "And these terms cancel for left, just with the G. So this is a very elegant simple vanilla scheme.",
            "We just propagate forwards to given XT plus one from the from the prior transition density, and the weight is simply then evaluated as the likelihood G."
        ],
        [
            "And then you've got this option of resampling or not resampling, so we can calculate await by accumulating the weights overtime.",
            "If we if we started off with a weighted particle set time T instead of an unweighted one.",
            "Remember we just had a 1 / N sample at the beginning of the iteration.",
            "If we have weights WFT instead, then we need to accumulate those and multiply them through by the new factor G of Y.",
            "Given X, so the new weight becomes the old rate times that G function."
        ],
        [
            "Or if we judge that the samples have become depleted and it's a poor Monte Carlo representation, or hopefully before we get to a polar opposite representation where it's heading that way, then we can re sample the particles from a multinomial again setting the new state to be equal to 1 of the other states with probability proportional to its weight, and reset the weights too."
        ],
        [
            "Over at so, the algorithm is simply this.",
            "You iterate over the all of the time steps.",
            "For each time step, you iterate over all of the particles.",
            "You first propagate a new state for each particle through the state transition density.",
            "Then you calculate a weight, accumulating it by multiplying by any previous weight.",
            "Times the observation density.",
            "And then you can either re sample or not re sample depending on whether the weights look degenerate or not.",
            "And there are automatic ways of."
        ],
        [
            "Determining whether to do that.",
            "And if you apply that to this standard nonlinear model, it's exactly the same model that we had before.",
            "As I said, it's trivial to go ahead and do this update this prediction step.",
            "All you have to do is take the previous sampled XT minus one.",
            "Calculate the nonlinear function A, so calculate this function of X, T -- 1.",
            "Add on a random disturbance and independent disturbance for each particle drawn from the same distribution as V. So that gives you your prediction step.",
            "Your weight calculation, then, is simply involves evaluating a Gaussian density function.",
            "So you go down now from the from the additive representation to the density function representation of G, you need to just calculate the value of the normal density function at.",
            "Why, given the nonlinear function B of X with variant Sigma W ^2.",
            "I'm.",
            "Who?"
        ],
        [
            "See that in operation in a moment, but.",
            "If we look at one time step of that you can see pretty much what's going on with this basic particle filter, so this runs.",
            "Top left down following the Red Arrows.",
            "So at time T you've got a model Monte Carlo approximation to the filtering density at time T. So I represent the samples.",
            "You can't see the individual samples here.",
            "I've shown the samples along the X axis as asterisks there, and I've plotted over top of that affine kernel density representation of those green asterisks.",
            "So that's where you start off.",
            "You first go through the prediction step, so you take for each of these greed asterisks.",
            "You pass it through the transition equation by generating a new sample X T + 1.",
            "Sorry, these are these letters haven't come out very clearly, but basically you just predict a new X2 plus one.",
            "As I showed you from the transition density given the previous state sample XT of I.",
            "So that tends to most dynamical models to spread things out across the X axis, so this sends the particles out across a broader range and we now get a broader kernel density representation of the predictive density now.",
            "So this is now the predicted density of XT plus one given the old data.",
            "Why not through T?",
            "You then gotta take that and calculate the weight.",
            "So for each of these asterisks you go and calculate G, the value of the observation density.",
            "This normal density centered upon.",
            "The new sample X T + 1 I so that means that each of these asterisks now gets a weight associated with its shown by this blue line.",
            "And.",
            "The reason this is.",
            "Multimodal, in fact, know that the blue line is the kernel density estimate for the filtering density now actually.",
            "But the reason this is bimodal, it has two modes is because of the X squared function.",
            "In the observation density so very often there is an ambiguity between whether X was minus something or plus something, and that's being shown up.",
            "Here in the in the Monte Carlo representation is having two possible locations for X of T. So we have 2 + 1 and then the problem here is that while many of the samples sit in good parts of the density in the high probability parts of the density, there's a lot of wasted effort because a lot of them have landed up in places where there's no significant weight or probability mass.",
            "So when you do the resampling step.",
            "Most of those get resampled out, so in fact, in this case all of them got resampled out and you just get left with a bunch of samples sitting on the high probability regions for the target density with nothing in between.",
            "In fact, this was a particle filter that was running with many particles.",
            "I think 10,000 particles and I just took a random selection of the particles to show us the green asterisks.",
            "So in fact you'll see there are more particles sitting here than they were they were originally above there.",
            "That's just because I've chosen 100 out of 10,000 randomly in both cases, and not necessarily the same 100.",
            "OK, let's see if I can just run that and show you some typical output.",
            "Well, let's have a look at some output.",
            "So running over.",
            "Well, let's have a look at the code first.",
            "The code, as you could imagine for this example is very, very simple.",
            "This is basically it.",
            "You pull in.",
            "Do you put in the previous weights?",
            "From the previous time step and you calculate the approach you put in the appropriate state X.",
            "So this is a vector of state, so we might like this can all be vectorized.",
            "So you propagate that one one time step forward.",
            "So you take the previous states xti, we propagate the one step forward through the dynamical model, but all of that is just the nonlinear function A, plus some Gaussian random noise.",
            "So there's a different random noise term for each for each particle.",
            "And then calculate the likelihood function.",
            "In this case the I've calculated something proportional to the likelihood function and in logarithmic form.",
            "So so this is just the exponent of the Gaussian function.",
            "And then there's some, and then you go ahead and do the resampling.",
            "And there are some extra stuff here that I haven't talked about relating to the ordinary particle filter and so on.",
            "But basically if you go through a normal resampling step, you if you do the resampling you, that's the line for it.",
            "And then the weights just get set to 1 / N. And the output of that is can be represented in many different ways, But So what do I have here?",
            "This is time along the X axis, and this is the X value along the Y axis and the blue asterisks.",
            "I should have done this in a different color, so this is a synthetic waveform generated from the same model, same nonlinear model and the blue asterisks show you the true value of the state.",
            "And what I've shown here is an intensity map at each time is the estimated filtering density coming out of the particle filter for using a kernel density representation of the particles?",
            "So basically, wherever you get high intensity, that's a high probability estimate for the state, and usually that's it's over the over the correct estimate for the state.",
            "Sometimes we should be able to see some bimodality appearing in here.",
            "Just trying to spot it out.",
            "It's not.",
            "This is not a very bimodal example, but for example here the state could have been either there or there with a certain probability here.",
            "It could have been there or there.",
            "There or there.",
            "So these are the is able to track the bimodality of the filtering distribution as it moves overtime quite successfully.",
            "Um?",
            "I'm I could show you that I've just run that just before the lecture.",
            "I don't think actually running it in front of you shows you anything more, and I'm kind of running out of time.",
            "So for this first part of the talk, so let me go back to."
        ],
        [
            "Here OK.",
            "So I'll just talk a little bit about how to generalize this to more effective samples will come back to this at the start of tomorrow's lecture, but what we're going to do is.",
            "Trying to better than with that basic bootstrap filter.",
            "The problem is the very problem is the problem is actually."
        ],
        [
            "Publicity and elegance becausw, we are blindly sampling X of T + 1 into the future from the state transition density in a way that does not depend on what new data appears.",
            "It can be a very inefficient Monte Carlo sampler, so we don't really want to do that except in models where it's so simple that it just works nicely and there are some.",
            "But if we want to generalize this and do a bit better.",
            "We could consider this now by working, and this is something that our refer back to tomorrow quite a lot but will look instead of at the marginal for the new state.",
            "Exit 2 + 1.",
            "Let's look at it in the joint space throughout.",
            "So if we work with our proposal density and it's an important function for the old state and the new state which is the filtering density at the previous time, which we have, we've got samples from that.",
            "And then I draw some proposal for the new state given the old state and it maybe it can be dependent on the data as well, and that's important.",
            "Then I then I've got a joint proposal function on XT&X 2 + 1.",
            "I can take that and compare it with the joint target distribution for T and T + 1, so this is now the joint distribution for XT and T + 1 given all the data including the new data.",
            "So I can factorize that as the filtering times the transition times the observations divided by a constant term.",
            "Very similarly.",
            "Then I can calculate an importance weight for this because it will simply be the ratio of this divided by this.",
            "And once I've got that, that gives me a weighted sample from this joint target.",
            "From which I can extract the marginal that I require just for the new state T plus."
        ],
        [
            "So if we do that.",
            "The weight you get simplifies down some terms cancel out and instead of just the observation density for the weight, I now have to factor in the transition density and the proposal.",
            "And here I've omitted it.",
            "But this proposal, as I said, can depend on the data Y as well, so I could put a collar wynaut through T + 1 in there as well effectively, and that's the general sequential importance sampling method that's that's normally adopted for."
        ],
        [
            "For many problems.",
            "And from it you get some special cases.",
            "If curious, set just equal to the transition density itself, then these terms cancel on your back to the normal bootstrap filter that I described first.",
            "If you are able to access the conditional distribution for the new state given the old state and the new data, like a sort of a Gibbs sampling density.",
            "Then and you could sample from that.",
            "Then that's basically the optimal important function which which gives you very nice performance in terms and can be shown to minimize the variance of these weights, which is a good thing."
        ],
        [
            "Think I'm pretty well done, actually and again repeated application overtime would lead to we will come back to this first type first thing tomorrow."
        ],
        [
            "Just to conclude what I'm going to say today.",
            "So we covered today the basic underlying concepts, the Bayesian filtering, Kalman filter, the bootstrap filter, and we started on the general SMC filter.",
            "Tomorrow we will be looking at some of the more advanced topics the general another view of general sequential Monte Carlo, which leads us into things like the auxiliary particle filter and MCMC.",
            "Particle filters would also look at the.",
            "The rare black lies particle filter and some Monte Carlo smoothing.",
            "If we have time, we'll also look at some population Monte Carlo and applications.",
            "Fine, I think that's all for today."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I'm one of the locals.",
                    "label": 0
                },
                {
                    "sent": "You can't hear me.",
                    "label": 0
                },
                {
                    "sent": "I might not live is that is that OK?",
                    "label": 0
                },
                {
                    "sent": "Yeah good I'm out of the locals.",
                    "label": 0
                },
                {
                    "sent": "Simon Godsil, I'm in signal processing here in the engineering Department, the same Department as Zubin.",
                    "label": 0
                },
                {
                    "sent": "Well, I don't mind that, but I will not know, OK?",
                    "label": 0
                },
                {
                    "sent": "To be talking about sequential Monte Carlo methods or particle filtering methods, it's in two sessions of the first session.",
                    "label": 1
                },
                {
                    "sent": "Today is pretty much a basic session, so people that already know all about particle filters will probably not getting very much about this, or maybe some insights.",
                    "label": 0
                },
                {
                    "sent": "Perhaps they can point out their own views on particular things.",
                    "label": 0
                },
                {
                    "sent": "I say feel free to ask me questions and point things out along the way within reason.",
                    "label": 0
                },
                {
                    "sent": "OK, so the application area that domain we're in is where we're looking at large sequentially evolving datasets where you don't necessarily want to do an inference in batch spending.",
                    "label": 0
                },
                {
                    "sent": "A lot of time churning through all of the data in one go, and clearly there are vast numbers of applications that fall into this category.",
                    "label": 0
                },
                {
                    "sent": "Sequential data evolving data tracking is where this methodology.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Very first started up with us, or at least in earnest in the 1990s with the Seminole Paper by Neil Gordon and his collaborators Salmon Smith that says, Adrian Smith, the Great Bayesian theorist.",
                    "label": 0
                },
                {
                    "sent": "But also in computer vision they started up around about the same time with the Andrew Blakes work and various other applications where these things are used routinely nowadays.",
                    "label": 0
                },
                {
                    "sent": "So basically, as you'd expect, in a machine learning Workshop summer school, we mainly going to be distributing with dealing with probability distributions and uncertainty, so we'll be looking for ways to take a Bayesian approach to sequential updating of probability distributions as the data evolves, and in particular the probability distributions of some latent hidden state variables that we want to learn as they evolve.",
                    "label": 1
                },
                {
                    "sent": "And obviously for this talk, I'm focusing on the sequential model Monte Carlo methodology.",
                    "label": 0
                },
                {
                    "sent": "I think that's synonymous with the term particle filtering.",
                    "label": 0
                },
                {
                    "sent": "I don't think there are any differences between those, although there may be some subtle interpretations.",
                    "label": 0
                },
                {
                    "sent": "There are numerous papers around about this, I'm just pointing to a handful of them here.",
                    "label": 0
                },
                {
                    "sent": "Perhaps Gordon Salmon and Smith was the 1st in recent times.",
                    "label": 0
                },
                {
                    "sent": "Although there are papers going back to the 1960s and.",
                    "label": 0
                },
                {
                    "sent": "Before where people were using sequential important sampling of various types.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "And then these other papers are sort of review papers that involved myself, but there are numerous other papers in this area for you to look out, so we're looking for estimating or finding the posterior probability distributions for some hidden process which.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Call the state of the system, and those will typically be obtained from noisy, convolved or non linearly distorted observations, and we're particularly interested in this myth methodology with things that don't limit the class of functions and nonlinear processes, non Gaussian processes that we can deal with, so they vary in their vanilla form.",
                    "label": 1
                },
                {
                    "sent": "They're very generic, they can work with pretty well any nonlinear state space model.",
                    "label": 0
                },
                {
                    "sent": "Stochastic states based model you throw at it, at least in principle.",
                    "label": 0
                },
                {
                    "sent": "They may take a lot of Monte Carlo samples to do so, but in principle they can do that.",
                    "label": 0
                },
                {
                    "sent": "You'll find then that some of the more tailored algorithms, the things that have come about over the last 10 years or so of research may then be directed more towards specific classes of models.",
                    "label": 0
                },
                {
                    "sent": "For example, major class of model that's been a big success with these methods is that those which have some partial linear Gaussian structure, so there's a bit of a model bit of the model which you can handle using a standard common filtering.",
                    "label": 0
                },
                {
                    "sent": "Methodology and you should do that, and if you're effectively marginalizing that in a posterior probability sense from the equations and then you just do the hard particle filtering part on the nonlinear non Gaussian bit that's left behind.",
                    "label": 0
                },
                {
                    "sent": "So that's an example of a case where there are very tailored methods, particular classes of models, but mostly what I'll talk about today, not so much tomorrow, but today will be for these very generic state space stochastic models.",
                    "label": 0
                },
                {
                    "sent": "So we'd like to.",
                    "label": 1
                },
                {
                    "sent": "Be able to estimate the hidden process online.",
                    "label": 0
                },
                {
                    "sent": "I think I've said all of this.",
                    "label": 0
                },
                {
                    "sent": "I don't need to go through anymore of this, there's just a handful of applications there.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let me move on.",
                    "label": 0
                },
                {
                    "sent": "Blah blah blah people diesel go online people.",
                    "label": 0
                },
                {
                    "sent": "People can read that stuff afterwards.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So whatever I talk about today, well, I guess most people will be familiar with quite a lot of this list actually, especially I guess the first one, so I'll just establish the Bayes theorem form that we need for today.",
                    "label": 0
                },
                {
                    "sent": "I will talk a little bit about Monte Carlo methods.",
                    "label": 0
                },
                {
                    "sent": "I know that he had Murray's done a nice tutorial already.",
                    "label": 0
                },
                {
                    "sent": "I wasn't here for that, so I don't exactly what he's covered, but I'll be.",
                    "label": 0
                },
                {
                    "sent": "I'll be, I'll just survey a few bits of Monte Carlo methods that that will need.",
                    "label": 0
                },
                {
                    "sent": "For today.",
                    "label": 0
                },
                {
                    "sent": "I'll define the framework that we're in, so we pose these things using state space models, stochastic states based models.",
                    "label": 0
                },
                {
                    "sent": "And the estimation tasks that were interested in in particular filtering, which is basically learning about the state at the current time as the data evolves.",
                    "label": 0
                },
                {
                    "sent": "So as soon as you see the data you want to learn about the posterior distribution for the state at that time, and then if you want to give you or.",
                    "label": 0
                },
                {
                    "sent": "Alternatively if you want to give us a bit of self a bit of retrospective look or forward, look through the data to get more reliable estimates out of the data.",
                    "label": 0
                },
                {
                    "sent": "We may do smoothing, so that's statistical smoothing.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "One of the main building blocks for sequential estimation, and indeed a building block for some of the particle filtering algorithms that will see tomorrow is the Kalman filter.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to go through the analytic updating formula for the Kalman filter and the extended Kalman filter, which works for nonlinear models under certain conditions, but I'll consider the common filter in a rather neat probabilistic framework.",
                    "label": 0
                },
                {
                    "sent": "Some of you will have seen this.",
                    "label": 0
                },
                {
                    "sent": "Before it's available in various textbooks already.",
                    "label": 0
                },
                {
                    "sent": "For example, I think I first saw it in the textbook by Kalman, but I know there are also not common common, doesn't like the probabilistic interpretation of the common filter at all, so we had him along, so he's not here today, is it?",
                    "label": 0
                },
                {
                    "sent": "We had him along to a workshop on particle filtering in Cambridge of 1990s in 2006, and he pretty well disagreed with the whole foundations of the whole workshop, but he gave us a couple of nice.",
                    "label": 0
                },
                {
                    "sent": "7 hours and it was great to have him along, but he doesn't really agree and doesn't really agree that stochastic processes even exist so physically not in a mathematical sense.",
                    "label": 0
                },
                {
                    "sent": "So, but I will talk about the Kalman filter from a probabilistic point viewpoint, Bayesian updating of probability densities.",
                    "label": 0
                },
                {
                    "sent": "For me, that's the neatest derivation of the of the common filter, and sheds a lot of light on this type of particle filtering area.",
                    "label": 0
                },
                {
                    "sent": "Then I'll move into the Monte Carlo filtering area, just pose it generally how you do Monte Carlo filtering, filtering that doesn't quite solve the problem.",
                    "label": 0
                },
                {
                    "sent": "It doesn't give you the sequential updating that you need with the particle filter, or at least it's not in a conveniently.",
                    "label": 0
                },
                {
                    "sent": "Tractable form.",
                    "label": 0
                },
                {
                    "sent": "So then I'll talk about the basic way of doing that.",
                    "label": 0
                },
                {
                    "sent": "The sequential Monte Carlo bootstrap filter.",
                    "label": 1
                },
                {
                    "sent": "That's that if you, if that's what I would call the vanilla version of particle filters, the simplest version, and then I'll talk about the general version that that allows you to deal with harder models using fewer particles through the choice of appropriate important functions.",
                    "label": 0
                },
                {
                    "sent": "Tomorrow we will move on to other types of particle filtering.",
                    "label": 0
                },
                {
                    "sent": "I'll also talk about some applications that we've worked on.",
                    "label": 0
                },
                {
                    "sent": "Things like the little particle filter, smoothing these particle filters, the rare black polarized particle filter, and a very important area at the moment are MCMC with particle filters so they can be coupled in very powerful ways.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right base theorem and inference.",
                    "label": 1
                },
                {
                    "sent": "Well, I expect we do all know about this, but I'm going to be talking about marginal inference.",
                    "label": 1
                },
                {
                    "sent": "We have some observations why quantity of interest.",
                    "label": 0
                },
                {
                    "sent": "Let's say that's X and we have some nuisance parameters in the model called those theater.",
                    "label": 0
                },
                {
                    "sent": "But we can't form.",
                    "label": 0
                },
                {
                    "sent": "If you like a sensor model that tells us what's the probability of our observations conditional on all of those unknowns.",
                    "label": 0
                },
                {
                    "sent": "The required X on the nuisance parameters Theatre, and we will formulate the joint posterior probability for all of the unknowns in terms of that likelihood function at a prior distribution jointly over all of the unknowns, the X is in the theaters and of course on the bottom line of Bayes theorem we have this effectively constant term at least constant for any.",
                    "label": 0
                },
                {
                    "sent": "Given model and data set Y so that term there is as it as in many Bayesian calculations is going to be neglected as a constant in each step of the particle filtering algorithm.",
                    "label": 0
                },
                {
                    "sent": "When we do the Bayesian updating.",
                    "label": 0
                },
                {
                    "sent": "And of course, if we want to do marginal inference for the quantity of interest, we will integrate out X using the marginalization identity from probability theory and then that thing would be the thing.",
                    "label": 1
                },
                {
                    "sent": "If it's just X we're interested in, that's the that's the quality we would use to do the inference and not the joint.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK Monte Carlo methods.",
                    "label": 0
                },
                {
                    "sent": "So this is actually an output from one of our particle filters or two dimensional particle filter out a particular to a 2 dimensional state vector or particular particular time and it comes from a non linear model that are very simple nonlinear model that's used a lot as a benchmark test model in particle filtering and this was one of the posterior PDF's that came out of that at a particular time.",
                    "label": 0
                },
                {
                    "sent": "This is a kernelized density estimate obtained for it and we obtained that.",
                    "label": 0
                },
                {
                    "sent": "Instead of trying to solve for this very intractable looking density, it certainly multimodal is probably not Gaussian.",
                    "label": 0
                },
                {
                    "sent": "It certainly doesn't look Gaussian.",
                    "label": 0
                },
                {
                    "sent": "Doesn't really look like a mixture of Gaussian, not not to a convenient number of components anyway, so we represented instead using the Monte Carlo representation.",
                    "label": 0
                },
                {
                    "sent": "And that simply means that, well, ideally we'd like independent random draws from this PDF, and instead of the density will represent it directly in terms of the number of.",
                    "label": 0
                },
                {
                    "sent": "Randomly samples points from this PDF, so that's the Monte Carlo representation.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And that's a very convenient representation, in particular for calculating difficult expectations.",
                    "label": 0
                },
                {
                    "sent": "So let's suppose we want to workout expectations with respect to some highly complex probability density P of X.",
                    "label": 1
                },
                {
                    "sent": "So this one, then the expectation we may require in general will be some functional H of the state variable.",
                    "label": 0
                },
                {
                    "sent": "The integral of that with respect to the probability density.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Pay and as I said, we'll do that with Monte Carlo.",
                    "label": 0
                },
                {
                    "sent": "Do it by generating random samples from P of X and the notation I use for random samples throughout is a superscript.",
                    "label": 1
                },
                {
                    "sent": "So if I have the ice sample out of a large collection of random samples and I'll label that X superscript I for the life of the.",
                    "label": 1
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Samples.",
                    "label": 0
                },
                {
                    "sent": "Informally, it's quite nice to think about that as a Monte Carlo approximation to the density function itself, and using Dirac functions.",
                    "label": 1
                },
                {
                    "sent": "The probability theorists don't like this very much, but it's it certainly gives you the right answers and it's and it's a nice intuitive way of thinking about Monte Carlo representations.",
                    "label": 0
                },
                {
                    "sent": "So once we've got a random set of samples for a large number of samples and all drawn from this probability density function.",
                    "label": 0
                },
                {
                    "sent": "X somehow, I haven't said how we generate them yet.",
                    "label": 0
                },
                {
                    "sent": "We're thinking that we're approximating P of X as a load of point masses.",
                    "label": 0
                },
                {
                    "sent": "Basically because these are all samples independent samples from P of X.",
                    "label": 0
                },
                {
                    "sent": "These are this is an unweighted sample, so we have 1 / N just to normalize the approximation to appear.",
                    "label": 1
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sex.",
                    "label": 0
                },
                {
                    "sent": "And then using this intuitive interpretation, we can easily see how things like approximations to expectations drop out of the formula, because we're going to take the expectation the same expectation that we tried to do before and we will now approximate that by plugging directly in our approximation to P of X, the density of interest.",
                    "label": 0
                },
                {
                    "sent": "So that's the 1 / N times the sum of the Delta functions.",
                    "label": 0
                },
                {
                    "sent": "Each Delta function.",
                    "label": 0
                },
                {
                    "sent": "So I people use different notations for Dirac functions, I know, so the notation I have mostly here, although I think it's which is later on.",
                    "label": 0
                },
                {
                    "sent": "Is is to say that this is a direct function centered at the point at the sample point XY considered as a function of the variable X, and I should say that I'm not I'm being LAX about random variables as well.",
                    "label": 0
                },
                {
                    "sent": "There's very.",
                    "label": 0
                },
                {
                    "sent": "There's no kind of confusion.",
                    "label": 0
                },
                {
                    "sent": "I think in this in this talk also random variables and their realizations tend to be denoted by small by lower case variables like this, but I don't think it causes any any any confusion.",
                    "label": 0
                },
                {
                    "sent": "In this context, so having done that, I've plugged in approximation to P of X, then because that's a solid Dirac functions, everything drops out, the integral drops out by the sifting property, and I just get an average of the values of the function H evaluated at all the sample points X.",
                    "label": 0
                },
                {
                    "sent": "So I replacing an intractable.",
                    "label": 0
                },
                {
                    "sent": "An intractable integral by an arithmetic mean related to the sampling positions, so very.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right forward to make Monte Carlo at Standard Monte Carlo approximation.",
                    "label": 0
                },
                {
                    "sent": "In particle filtering so.",
                    "label": 0
                },
                {
                    "sent": "You have seen proposal distributions in.",
                    "label": 0
                },
                {
                    "sent": "I don't know whether even went through the.",
                    "label": 0
                },
                {
                    "sent": "The important sampling in his talk.",
                    "label": 0
                },
                {
                    "sent": "But suppose we want to draw instead of P of X, which we can't draw from.",
                    "label": 1
                },
                {
                    "sent": "It's this complicated entity.",
                    "label": 0
                },
                {
                    "sent": "We will propose from some simpler distribution Q, and the simplest way to correct that to generate a set of samples approximately from P of X is using important sampling, so we can do this by calculating inappropriate bias correction factor if you like that.",
                    "label": 0
                },
                {
                    "sent": "The ratio of P of X&Q of X.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now important sampling is going to work like this.",
                    "label": 0
                },
                {
                    "sent": "An important sampling with the base be the basis for most of the particle filters that I talk about.",
                    "label": 0
                },
                {
                    "sent": "So the expectation then is done by simply replacing by adding in a Q of X / Q of X into the expectation.",
                    "label": 0
                },
                {
                    "sent": "Pulling out a weight P of X / Q of X.",
                    "label": 0
                },
                {
                    "sent": "This ratio here and now because I've made a Monte Carlo sample from Q of X.",
                    "label": 0
                },
                {
                    "sent": "Instead of from P of XI can plug in our approximation if you like 4 Q of X, which is again the sum of Delta functions where these axes of iron are drawn from Q of X, not not not P of X, so plugging that in again, I get a simple formula for the.",
                    "label": 0
                },
                {
                    "sent": "Now it's a weighted average with the weights proportional to the ratio of the target distribution P over the proposal or importance function Q like so.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the weights are proportional to the ratio they save the target to the proposal, and we can then think informally overweighted Dirac function approximation to the density.",
                    "label": 0
                },
                {
                    "sent": "So if we want to do that, then P of X will be represented now in terms of these weights, times Derek function, and to make it make this a proper density function, the WS will need to be normalized to one but still proportional to P. Sorry, still proportional to P / Q.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right, so of course there are numerous ways of doing Monte Carlo, including Markov chain Monte Carlo, which which you've heard about, in which we will touch a little bit of an tomorrow in the particle filtering context.",
                    "label": 0
                },
                {
                    "sent": "Simulated annealing is an example of Monte Carlo important sampling, which is the fundamental building block behind these particle filters quasi Monte Carlo.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so sequential Monte Carlo methods here.",
                    "label": 1
                },
                {
                    "sent": "And just a trick that gets used throughout Monte Carlo inference, which will play a part in my particle filter derivation in a minute.",
                    "label": 0
                },
                {
                    "sent": "Monte Carlo folds difficult integrals one integral that it solves nicely is the marginalization integral automatically be cause if I have two quantities, say the state and the nuisance parameter.",
                    "label": 0
                },
                {
                    "sent": "In this case drawn from the joint posterior distribution for those unknowns.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Given the data, why then it immediately follows that if I simply extract the samples?",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "X from that joint draw those are draws from the marginal for X, and similarly the theaters are draws from the marginal for theater.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Informally, you can.",
                    "label": 0
                },
                {
                    "sent": "You can see that drops out just from the factorization of the joint in terms of the marginals times the conditional, so that's the marginal for X, and that's the marginal for theater, so bear that in mind because we use that in the base.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Particle filter derivation in a moment.",
                    "label": 0
                },
                {
                    "sent": "But now let me define the state space models and the filtering and smoothing objectives of the basic particle filter.",
                    "label": 1
                },
                {
                    "sent": "OK, so state space models are quite a general way of representing time series models.",
                    "label": 0
                },
                {
                    "sent": "They include things like hidden Markov models on discrete state space.",
                    "label": 0
                },
                {
                    "sent": "Is most of the Standard Time series models things like auto regressive, moving average Arma models, they don't apply to some of the integrated models that appear in finance because you can't represent those with the finite dimensional.",
                    "label": 1
                },
                {
                    "sent": "State vector and also all of the special models that we can try for applications in tracking computer vision, finance, communications and so on so.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I think we need anymore of that text or yes yes yes, so I'm going to do all of this derivation in terms of of a Markovian state space model.",
                    "label": 0
                },
                {
                    "sent": "In fact, that's not necessary, but it simplifies the notation.",
                    "label": 0
                },
                {
                    "sent": "So for example in the rare black guys particle filter that we'll hear more about tomorrow, you're effectively dealing with a non Markovian set up, and it does work, but the notations a bit more cumbersome right?",
                    "label": 0
                },
                {
                    "sent": "The notation are uses.",
                    "label": 0
                },
                {
                    "sent": "Uh.",
                    "label": 0
                },
                {
                    "sent": "Column vectors will be standard typeface, lowercase, so for example the state at time T will typically be X, sub T and the matrices.",
                    "label": 1
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This will be just standard typeface capital letters, just to avoid a load of heavy heavy typeface notations.",
                    "label": 1
                },
                {
                    "sent": "Will consider a time series, then with states X of T on sometime access nought.",
                    "label": 1
                },
                {
                    "sent": "Oh gosh, I never noticed that before N 1 two up to T. The states evolve in time according to a probability model, so this is a stochastic state space model.",
                    "label": 1
                },
                {
                    "sent": "And we'll assume, as I say, a Markovian structure, so that if I look at the distribution of a new state at time T + 1, given all of the previous states up to that time, it will only depend on the previous state X of T, and I'll always denote that here, as that density find this probability density function.",
                    "label": 0
                },
                {
                    "sent": "I'll do note that as F of X2 plus one given expertise, so that's the dynamical model, or the state space model underlying.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The state's evolution.",
                    "label": 0
                },
                {
                    "sent": "We received partial observation again, a stochastic observation of the states through some observation, a sensor function or likelihood function for the set of observations biote which are assumed to be independent conditional upon the states.",
                    "label": 1
                },
                {
                    "sent": "So again, that's a kind of a Markovian assumption about the observations.",
                    "label": 0
                },
                {
                    "sent": "So a new observation.",
                    "label": 0
                },
                {
                    "sent": "Conditional upon any of the, uh, the whole state sequence up to the time T + 1 and any of the previous observations will only depend on the current observations.",
                    "label": 0
                },
                {
                    "sent": "So that's Markovian assumption about the observations, and I'll always label the observation density as lower case G. So we've got the dynamical model F and the observation density G. Now these will be assumed will be specified, so we're not learning the dynamical model or the observation model in this in this setup, although of course they can be parameterized by extra parameters, which do mean that we learn the structure of them to some extent, and one could do some kind of nonparametric learning in a Bayesian set up too if you really wanted to learn something within about F&G within this framework.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So there is the model will be using then the state evolution density and the observation density.",
                    "label": 0
                },
                {
                    "sent": "And this I'm using this symbol to denote that the random variable to the left is drawn as a sample is drawn from the density on the right.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And because of the independence assumptions that I've made, the conditional independence assumptions, we can write the joint density for all of the states from North through T and all of the data in terms of an initial state density F of X nought.",
                    "label": 0
                },
                {
                    "sent": "To get things started.",
                    "label": 0
                },
                {
                    "sent": "And then using the probability chain rule we can chain in all of the conditional densities for the state dynamics, the FS.",
                    "label": 1
                },
                {
                    "sent": "Times all the observation densities overall times from nought to T. So we can.",
                    "label": 0
                },
                {
                    "sent": "This thing is fully specified, so I mean actually, what questions do we need to answer but the?",
                    "label": 0
                },
                {
                    "sent": "We want to look at the conditional distribution for X given some set of observations Y.",
                    "label": 0
                },
                {
                    "sent": "Then we won't know anything in general about the properties of this joint density, even though we can write it down, we won't know things about its moments and.",
                    "label": 0
                },
                {
                    "sent": "Quantities that we want to estimate, except in special analytic cases like the linear Gaussian model.",
                    "label": 0
                },
                {
                    "sent": "I also sometimes use the notation X North through T to be the vector of data points from North through T, and Similarly the sorry the vector of States and wine or through T to the vector of observations not through T.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But and represented in a sort of a graphical model type thing to work.",
                    "label": 0
                },
                {
                    "sent": "So we have our hidden state sequence proceeding through time connected via the dynamics F. So there's a stochastic model connecting each of these conditional on one another, and then you've got the observations hanging off those via some observation density G.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So just to look at two very simple examples of how you would set that up.",
                    "label": 0
                },
                {
                    "sent": "Any auto regressive model observed in noise, so the hidden state process I'm going to call zed.",
                    "label": 1
                },
                {
                    "sent": "So instead of two linear autoregressive model is where is made up as a linear weighted sum of previous zeds.",
                    "label": 0
                },
                {
                    "sent": "Plus some noise term of T and the observations.",
                    "label": 1
                },
                {
                    "sent": "Why are the hidden states out of T + a noise term W?",
                    "label": 1
                },
                {
                    "sent": "I will say that A&WT or independently distributed and for the sake of argument argument there zero mean Gaussian.",
                    "label": 0
                },
                {
                    "sent": "So the simplest possible set up, I guess just about the variances of those are Sigma re squared and Sigma W respectively.",
                    "label": 0
                },
                {
                    "sent": "Uh, those are fixed it now we're not doing parameter learning for this particular state space model set up, although one could in principle append extra parameters onto the state vector within a particle filtering framework.",
                    "label": 0
                },
                {
                    "sent": "So the days of I for the AR coefficients, the weights on that prediction, and these are also fixed and known just for this set up here.",
                    "label": 1
                },
                {
                    "sent": "And we observe why.",
                    "label": 0
                },
                {
                    "sent": "I'm the unknown.",
                    "label": 0
                },
                {
                    "sent": "Is the signal set.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So you can form a state vector.",
                    "label": 1
                },
                {
                    "sent": "We have to do that by augmenting zed of two with some previous state values, as in a standard sort of state space.",
                    "label": 0
                },
                {
                    "sent": "Deterministic state space model.",
                    "label": 1
                },
                {
                    "sent": "And then we can set up the state space model in the required form by saying that X of T is a matrix A times the previous X of T. So that's the one start.",
                    "label": 0
                },
                {
                    "sent": "It said T -- 1 plus noise term epsilon of T, which is a slightly modified version of UFT and.",
                    "label": 0
                },
                {
                    "sent": "Y of T the observation that is a matrix B times the state X just the noise term.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Have tea.",
                    "label": 0
                },
                {
                    "sent": "Where the matrix say that you require.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This thing here is simple.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Put together so that the top row gets defines the fundamental equation of the autoregressive model and then the remaining rows.",
                    "label": 0
                },
                {
                    "sent": "Just Simply put in the previous elements of X to the next time point, be the observation function.",
                    "label": 0
                },
                {
                    "sent": "Then is a is in fact a row vector just pulling in the first element of the state vector X into the observation.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And finally, the noise term has covariance matrix like so.",
                    "label": 0
                },
                {
                    "sent": "So just there's only one nonzero covariance element corresponding to the Y of T that you require in the model.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we can put that directly, then into the form that you need to evaluate density functions and so on.",
                    "label": 0
                },
                {
                    "sent": "Because the density function for the dynamics is just a normal density function for X of T + 1 with mean given by a times the previous state X and covariance given by Capital Sigma Re similar X or epsilon and the observation function G of Y given X.",
                    "label": 0
                },
                {
                    "sent": "Another normal function centered on BX and with various.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sigma W ^2.",
                    "label": 0
                },
                {
                    "sent": "So this is the simplest, nicest, most benign type of state space model.",
                    "label": 0
                },
                {
                    "sent": "It's the linear Gaussian state space model.",
                    "label": 1
                },
                {
                    "sent": "Well, I guess the perhaps the hidden Markov model is just as benign in that it's on a discrete state space, but in a continuous state space.",
                    "label": 0
                },
                {
                    "sent": "This is the simplest version and.",
                    "label": 0
                },
                {
                    "sent": "As an important special case of the state space model is used extensively to construct algorithms even in the nonlinear case, with things like extended carbon filters and in the nonlinear Gaussian case with things like the rare black realized particle filters.",
                    "label": 1
                },
                {
                    "sent": "So these these linear models will be.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A fundamental building block in some particle filters.",
                    "label": 0
                },
                {
                    "sent": "Or we can look at fully nonlinear model.",
                    "label": 0
                },
                {
                    "sent": "This is a sort of benchmark test model that was used in a lot of the early papers in this area.",
                    "label": 0
                },
                {
                    "sent": "So here we can reconstruct some arbitrary nonlinear function of the previous state to predict the current state and add some noise onto it then or it doesn't have to be additive as long as you can calculate as long as you can sample from the transition density.",
                    "label": 0
                },
                {
                    "sent": "But here it is additive and the observation function again can be some arbitrary, pretty well arbitrary nonlinear function of the state.",
                    "label": 0
                },
                {
                    "sent": "And things will still work here.",
                    "label": 0
                },
                {
                    "sent": "I've just specified V to be Gaussian and W to be independent Gaussian with particular variance.",
                    "label": 0
                },
                {
                    "sent": "Again, that's very easy to put into the state space form that we require for the basic formulation, so the F function, the dynamical model is again a normal distribution centered upon.",
                    "label": 0
                },
                {
                    "sent": "This laser pointer is a bit tricky when it keeps dying out centered on the function A of X with various Sigma V squared and the G function of the observation function is a normal distribution centered upon the nonlinear function.",
                    "label": 0
                },
                {
                    "sent": "Be a vex with some variance.",
                    "label": 0
                },
                {
                    "sent": "Sigma W ^2.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so that's all simple.",
                    "label": 0
                },
                {
                    "sent": "Just a simple example of how to set up the state space model for this.",
                    "label": 0
                },
                {
                    "sent": "This scenario and the estimation tasks.",
                    "label": 0
                },
                {
                    "sent": "Well, let's suppose we've seen all the observation from some time up to the current present time T, and we wish to infer the hidden states.",
                    "label": 1
                },
                {
                    "sent": "So there's a sequence of hidden states running from naughty.",
                    "label": 0
                },
                {
                    "sent": "Or is that a better one?",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Oh nice right?",
                    "label": 0
                },
                {
                    "sent": "So we have some hidden states exonaut.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Booty.",
                    "label": 0
                },
                {
                    "sent": "And some of the tasks you might want to do within a Monte Carlo filtering setup.",
                    "label": 0
                },
                {
                    "sent": "Well, filtering itself is concerned with the marginal distribution of the current state X of T, given all the data from nought through to T. So we might be interested in actually looking at that posterior distribution itself or forming some kind of expectations with respect to it.",
                    "label": 1
                },
                {
                    "sent": "For example, if we set the Zeta function just to be XLT itself, then we then we're calculating the posterior mean.",
                    "label": 0
                },
                {
                    "sent": "Estimate which is the minimum mean squared error.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Automated for the state X.",
                    "label": 0
                },
                {
                    "sent": "We may also wish to allow ourselves some lag to make a more reliable estimate, so we may do smoothing, for example, estimating that the state of lack of.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Low.",
                    "label": 0
                },
                {
                    "sent": "Or we may wish to do fixed interval smoothing.",
                    "label": 1
                },
                {
                    "sent": "Try and get the distribution of the entire state sequence over some time axis North route.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So and that just illustrates that filtering is concerned with immediate estimation.",
                    "label": 0
                },
                {
                    "sent": "As soon as you get the new data point smoothing gives you some look ahead of future data points and hence you should get a tighter distr.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Fusion on the on the states.",
                    "label": 0
                },
                {
                    "sent": "Right, so filtering though is the main focus of a lot of this work, so let's consider filtering at time T. Suppose we've solved the filtering problem up to that time, so these things are desired right in a recursive fashion.",
                    "label": 1
                },
                {
                    "sent": "Usually we've got the filtering distribution, but we want to update it one time step with the input of a new data point Y T + 1.",
                    "label": 0
                },
                {
                    "sent": "In principle, we could do that.",
                    "label": 0
                },
                {
                    "sent": "We've got the filtering recursions first of all, a prediction step, so we want to first of all take.",
                    "label": 0
                },
                {
                    "sent": "The filtering, distribution, and updated one time into the future to give us the distribution of X T + 1 given all the old data.",
                    "label": 0
                },
                {
                    "sent": "Or we could do that by taking the joint distribution of the old state and the new state given all the old data and marginalizing with respect to X. X of T The old state.",
                    "label": 0
                },
                {
                    "sent": "We can factorize that in terms of the thing that we have.",
                    "label": 0
                },
                {
                    "sent": "So this fact arises in terms of the filtering density that we've already solved that time T. Multiplied by the conditional distribution, the conditional density of the state at time T + 1 given the old state and all the old data.",
                    "label": 0
                },
                {
                    "sent": "But because of the assumptions of the model, that's not other than the state transition density F. So we can write that in terms this marginalization in terms of the previous filtering density times the state transition density to take you to.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Time T + 1.",
                    "label": 0
                },
                {
                    "sent": "And then Bayes theorem kicks in because we now want to incorporate the effect of a new data point, Whitey plus one.",
                    "label": 0
                },
                {
                    "sent": "Well that's got directly then from the mailing terms in the model we've already got the predictive distribution of X T + 1.",
                    "label": 0
                },
                {
                    "sent": "Given the old data.",
                    "label": 0
                },
                {
                    "sent": "We multiply that by the observation density, the G of Y T + 1 given X, T + 1 divide through by the normalizing constant P of Y T + 1 given YN rooty, then based there was given us directly, then the corrected formula for the new filtering distribution.",
                    "label": 0
                },
                {
                    "sent": "So that's all very straightforward, except that you probably can't do this integral in close form.",
                    "label": 0
                },
                {
                    "sent": "It could be high dimensional, you've got all the usual problems of.",
                    "label": 0
                },
                {
                    "sent": "Dealing with nasty forms.",
                    "label": 0
                },
                {
                    "sent": "Naughty unknown forms for for the P and the F There.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so, but in principle it operates simply.",
                    "label": 0
                },
                {
                    "sent": "You just progress through time.",
                    "label": 0
                },
                {
                    "sent": "Adding more data points as you go.",
                    "label": 0
                },
                {
                    "sent": "Why T + 1 YTY T + 1?",
                    "label": 1
                },
                {
                    "sent": "You do the filtering, getting each time step, so we solved it at T -- 1.",
                    "label": 0
                },
                {
                    "sent": "You do the prediction Step 2 to predict one state into the future.",
                    "label": 0
                },
                {
                    "sent": "Then you correct it using Bayes theorem, predict correct.",
                    "label": 0
                },
                {
                    "sent": "So it's a leap frog type approach through time.",
                    "label": 0
                },
                {
                    "sent": "But as I say this can't be done in general and approximations must be used, especially when X is high dimensional and F&G are non Gaussian or nonlinear.",
                    "label": 1
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right, so I'm going to go through now.",
                    "label": 0
                },
                {
                    "sent": "The basics of the Kalman filter because of the saying that this is fundamental to some of the particle filters, and there's a very fundamental idea underlying sequential updating, Bayesian sequential updating.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "OK, so it applies for cases where the model is linear and Gaussian.",
                    "label": 1
                },
                {
                    "sent": "What do we mean by that?",
                    "label": 0
                },
                {
                    "sent": "In fact, there is a slightly more general version of this, but but let's stick with this for them.",
                    "label": 1
                },
                {
                    "sent": "For present purposes, the linear, Gaussian state space Model says that the state transition density is the Gaussian distribution, where the mean is a linear function of the previous state.",
                    "label": 0
                },
                {
                    "sent": "So a matrix a times the previous state X.",
                    "label": 0
                },
                {
                    "sent": "The observation density is similarly linear and Gaussian.",
                    "label": 0
                },
                {
                    "sent": "It's a Gaussian density for why with a linear function of the state X, and if you've got that, then you could apply the common filter and the notation is that kind of graphic N is a normal distribution for X with mean vector view and covariance matrix Q.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We can write that equivalently as an additive noise model, so we've got a way of generating the next data point.",
                    "label": 0
                },
                {
                    "sent": "The next state point in if we wanted to synthesize some data from the model, we would just write the next state is a times the previous state plus the noise term.",
                    "label": 0
                },
                {
                    "sent": "And similarly Y is obtained from the state X plus noise again.",
                    "label": 0
                },
                {
                    "sent": "Where these Wiesen WS can be generated independently as zero, mean Gaussian vectors with covariance matrices C&D, respectively.",
                    "label": 1
                },
                {
                    "sent": "And I've said that they are independent overtime and also independent of one another.",
                    "label": 1
                },
                {
                    "sent": "In fact, you can make them also dependent on one another, and there's a version of the carbon filter that deals with.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Might as well, but we don't need that here.",
                    "label": 0
                },
                {
                    "sent": "We do also require everything must be linear Gaussian, so the initial state must be Gaussian distributed.",
                    "label": 1
                },
                {
                    "sent": "I think our previous I do notice that F of X and that's the same thing.",
                    "label": 0
                },
                {
                    "sent": "The initial probability density for the first state that I'm not.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so the first thing we need to do is to get the prediction step.",
                    "label": 1
                },
                {
                    "sent": "So if you remember.",
                    "label": 0
                },
                {
                    "sent": "Where we?",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Heading is to solve these two equations and we're going to do it analytically in closed form for the linear Gaussian case.",
                    "label": 0
                },
                {
                    "sent": "So the first one involves marginalizing out the current state from the old state from the joint density.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here it is, so that's what we needed to do.",
                    "label": 0
                },
                {
                    "sent": "Carry out this integral.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we suppose, as before, that we've solved the problem at time T, so it's recursively defined.",
                    "label": 0
                },
                {
                    "sent": "We say that we've got the filtering distribution at time T. There's a normal distribution with.",
                    "label": 1
                },
                {
                    "sent": "With mean same UTI, covariance PFT.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we know that to get to the next state from the previous equation that we don't even need to go back to that, we can generate the next state from the previous state just by multiplying by A and adding the random noise.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Speak.",
                    "label": 0
                },
                {
                    "sent": "So it's really just standard transformation of variables.",
                    "label": 1
                },
                {
                    "sent": "We've taken the random variable X with, multiplied it by matrix A.",
                    "label": 0
                },
                {
                    "sent": "Added noise to it so there's convolution there of the densities and produced X of T + 1.",
                    "label": 0
                },
                {
                    "sent": "So we can get to the density for XT plus one straightforwardly because we know the density for X of tea.",
                    "label": 0
                },
                {
                    "sent": "Is this Gaussian and we've got passed it through that.",
                    "label": 0
                },
                {
                    "sent": "Updates.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Set and therefore the density of X T + 1 conditions on the same bit of data is another normal distribution, but it's me.",
                    "label": 0
                },
                {
                    "sent": "This modified.",
                    "label": 0
                },
                {
                    "sent": "The mean is a times the original mean mu of T because we multiplied by a.",
                    "label": 0
                },
                {
                    "sent": "And we've added some noise on so so so so we need to take P and converted into a P * A transpose that deals with this multiplication of X.",
                    "label": 0
                },
                {
                    "sent": "But we've also added it on the noise VNV had covariance matrix C, so that gets added on there.",
                    "label": 0
                },
                {
                    "sent": "Sorry, no.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I've done that right.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry, yeah.",
                    "label": 0
                },
                {
                    "sent": "So yeah, so this was the covariance matrix, so we've added on zero mean Gaussian noise V. So hence we added on its covariance matrix C onto the AP, A transpose term.",
                    "label": 0
                },
                {
                    "sent": "So that gives you the formula for doing the update if we started with the Gaussian density at time T. Sorry, that's the.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Actionstep and the correction step the updating step via Bayes formula just involves taking what we just calculated.",
                    "label": 1
                },
                {
                    "sent": "That prediction density or Gaussian multiplying it by the Gaussian for the observation density.",
                    "label": 0
                },
                {
                    "sent": "And correctly normalizing it because for a fixed data set Y, that will be a constant term on the bottom line there.",
                    "label": 0
                },
                {
                    "sent": "So we just need to calculate that.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Normalizer for the, for the multivariate density.",
                    "label": 0
                },
                {
                    "sent": "And substitute to get him well.",
                    "label": 0
                },
                {
                    "sent": "We don't worry about too much about this arrangement, but we've taken the normal distribution for the predicted density for X multiplied it by the observation density for Y conditional upon that new X.",
                    "label": 0
                },
                {
                    "sent": "Plugged everything in and rearranged it and found that the correct normal with the right normalizing constant is.",
                    "label": 0
                },
                {
                    "sent": "This one.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With this particular mean and covariance, well, don't worry about the details of that you.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Like that through in your own time afterwards, and we can rearrange that using the matrix inversion lemma to give a slightly simpler form.",
                    "label": 0
                },
                {
                    "sent": "We don't need all the details.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is right now I'll just put them there for reference, but the whole recursion gets summarized in terms of a prediction step on the means and covariances and an update state on the means and covariances, which progressives you from a Gaussian at time T to another Galaxy at time T + 1.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There you go.",
                    "label": 0
                },
                {
                    "sent": "So so you don't.",
                    "label": 0
                },
                {
                    "sent": "We don't need the precise details of that at the moment, I'm just outlining the principles behind it and more importantly what the things you can and can't do with the Kalman filter that arises from that.",
                    "label": 0
                },
                {
                    "sent": "So the common filter is a fundamental tool is still substantially used in many estimation and tracking tasks.",
                    "label": 1
                },
                {
                    "sent": "You can use it to estimate the system state sequentially by taking a, for example, the mean estimate for the state.",
                    "label": 1
                },
                {
                    "sent": "You can obtain an uncertainty estimate about the state using the state covariance.",
                    "label": 1
                },
                {
                    "sent": "You can do recursive least squares when the state doesn't evolve.",
                    "label": 0
                },
                {
                    "sent": "This time is like a fixed parameter that's basically a type of a common filter.",
                    "label": 0
                },
                {
                    "sent": "You can do fixed lag smoothing by augmenting the states, which we include, not just the current state, but some previous states, so that'll get you a bit more mileage.",
                    "label": 0
                },
                {
                    "sent": "You have to modify the state space model to give you the correct update on the axes, but otherwise everything follows through the same.",
                    "label": 0
                },
                {
                    "sent": "And similarly if you want to do fixed interval smoothing, estimating the whole sequence of X is.",
                    "label": 0
                },
                {
                    "sent": "Given a whole sequence of wise, then the common smoother operates backwards in time, so you run a filter forward through the data, and then there are equivalent equations backwards through time that take you back through the data to estimate the posterior distribution of particular time point T. For example, recursively backwards in time, given all of the data.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And you can do similar things with particle filters, so those are also particle smoothers, which I'll talk about tomorrow which which passed the Monte Carlo representation backwards through time.",
                    "label": 0
                },
                {
                    "sent": "Having gone forwards through time with the standard filter.",
                    "label": 0
                },
                {
                    "sent": "Now probably most useful for our concerns here.",
                    "label": 0
                },
                {
                    "sent": "For the particle filtering is the likelihood evaluation, so I really neat thing that you could do with the Kalman filter, which is great for model choice in time series models and parameter estimation in time series models, and also for this special type of particle filter the radio black realized particle filter is likelihood evaluation.",
                    "label": 1
                },
                {
                    "sent": "You can effectively marginalized out the complete state sequence and just look at the probability.",
                    "label": 0
                },
                {
                    "sent": "For the data.",
                    "label": 0
                },
                {
                    "sent": "So that's great for us.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For things like Bayesian model choice, if you want to compare different types of state space model on the same data.",
                    "label": 1
                },
                {
                    "sent": "So we can do the same kind of tricks with the mass of the common filter.",
                    "label": 0
                },
                {
                    "sent": "The first step of the carbon filter took us to the prediction density.",
                    "label": 0
                },
                {
                    "sent": "The prediction of the new state given all the old data.",
                    "label": 1
                },
                {
                    "sent": "So that was a Gaussian density which with an updated version of the mean and the covariance from obtained from the previous time step, but nevertheless are Gaussian dense.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "See.",
                    "label": 0
                },
                {
                    "sent": "But now how will the data points generated from that new state X of T + 1?",
                    "label": 0
                },
                {
                    "sent": "Well, we know that from the linear state space Model Y of T + 1, the new data point is just B * X of T + 1 + A new noise term.",
                    "label": 0
                },
                {
                    "sent": "Wat plus one.",
                    "label": 0
                },
                {
                    "sent": "So that's exactly the same kind of setup that we had before.",
                    "label": 0
                },
                {
                    "sent": "Is a linear transformation of a Gaussian random variable X T + 1 plus an independent Gaussian noise W?",
                    "label": 0
                },
                {
                    "sent": "So then we know what the distribution of YT plus one is conditional upon.",
                    "label": 0
                },
                {
                    "sent": "The past the why North route?",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Hence, using the same idea, the transformation of Gaussian random variables with the addition of a random noise vector, we can immediately obtain the distribution of the new YT plus one given conditional on the same thing as before.",
                    "label": 1
                },
                {
                    "sent": "The YN through T. It's now transformed mean.",
                    "label": 0
                },
                {
                    "sent": "So you take the predictive mean and multiply by be the observation.",
                    "label": 0
                },
                {
                    "sent": "Matrix.",
                    "label": 0
                },
                {
                    "sent": "It's the covariance of the added noise and then a corrected version of the of the covariance of the previous state multiplied by this, the state transition matrix.",
                    "label": 0
                },
                {
                    "sent": "Sorry, the observation matrix B.",
                    "label": 0
                },
                {
                    "sent": "And finally, having attained that conditional, you can use the probability chain rule to obtain the entire likelihood for a whole sequence of data.",
                    "label": 1
                },
                {
                    "sent": "Simply chaining all of these conditional densities through time, the new one conditional upon the old set from Northrop.",
                    "label": 0
                },
                {
                    "sent": "So effectively you just store all of these as you go and then add on multiply on subsequent ones.",
                    "label": 0
                },
                {
                    "sent": "So that's the.",
                    "label": 0
                },
                {
                    "sent": "This result will be will be fundamental to coupling of common filters and linear processing with with.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Michael filters what you can't you do with the Kalman filter.",
                    "label": 1
                },
                {
                    "sent": "It's only optimal for the linear Gaussian model, so it's not much good for a lot of the scenarios.",
                    "label": 0
                },
                {
                    "sent": "We'd like to consider in practice.",
                    "label": 0
                },
                {
                    "sent": "And in some cases it will give you the best linear estimator.",
                    "label": 0
                },
                {
                    "sent": "The mean squared error sense, but it may not be good enough for models we are interested in.",
                    "label": 1
                },
                {
                    "sent": "And there are numerous ways of dealing with more general models or based on numerical approximations to the filtering recursions.",
                    "label": 1
                },
                {
                    "sent": "For example, and I'm really not not even touching on the approximation literature.",
                    "label": 0
                },
                {
                    "sent": "Here Gaussian, some filters, unscented Kalman filters and so on.",
                    "label": 1
                },
                {
                    "sent": "We can.",
                    "label": 0
                },
                {
                    "sent": "Consider two important cases, the probably the one of the first attempts at.",
                    "label": 0
                },
                {
                    "sent": "This would have been the extended Kalman filter, which linearizes a nonlinear system and uses the carbon filter, and then the Monte Carlo particle filter, which is our main concern.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the extended Kalman filter?",
                    "label": 1
                },
                {
                    "sent": "Well, I shouldn't spend very much time dwelling on this.",
                    "label": 0
                },
                {
                    "sent": "But basically if we replace the linear state space model with a nonlinear one, that's got some nonlinearity in the update, the nonlinearity in the observation function through some nonlinear functions ABI can linearize that with the Taylor.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Mansion.",
                    "label": 0
                },
                {
                    "sent": "I'm going to basically linearize about some points mu.",
                    "label": 0
                },
                {
                    "sent": "And I'm going to.",
                    "label": 0
                },
                {
                    "sent": "Then substitute these approximations back into the state space model, leading to a linear approximate system, which I can then solve the common filter, and I'm away again, and there are higher order approximations that you can use which will also give you a better approximation, but they do require you to be able to evaluate these partial do Jacobian terms, and so the partial derivatives it's approximation is unimodal.",
                    "label": 0
                },
                {
                    "sent": "The posterior density is always assumed to have just one mode, which which isn't desirable.",
                    "label": 0
                },
                {
                    "sent": "And the tracking performance and error covariance estimates are suboptimal and can be very odd.",
                    "label": 1
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Reliable.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Before him, there was a term that, depending explicitly on T, was a cosine 1.2 T, yeah.",
                    "label": 0
                },
                {
                    "sent": "Well, can you even do that in the?",
                    "label": 0
                },
                {
                    "sent": "If it depends on two, that's fine.",
                    "label": 0
                },
                {
                    "sent": "You would really need arise at each time step.",
                    "label": 0
                },
                {
                    "sent": "I think you can.",
                    "label": 0
                },
                {
                    "sent": "Can you do that one with a?",
                    "label": 0
                },
                {
                    "sent": "Can you do that?",
                    "label": 0
                },
                {
                    "sent": "Non linear model with an EKF?",
                    "label": 0
                },
                {
                    "sent": "You can't get any.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so you basically redo the linearisation each at each time step at the appropriate cause costita.",
                    "label": 0
                },
                {
                    "sent": "So the question relates, let me just flip back to this nonlinear model.",
                    "label": 0
                },
                {
                    "sent": "I mean I haven't done any care for actually on that model, but I think it can be done.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This one, yeah.",
                    "label": 0
                },
                {
                    "sent": "So basically, you're linearisation.",
                    "label": 0
                },
                {
                    "sent": "Here's your nonlinear function for the state update, and it's got an awkward term involving time.",
                    "label": 0
                },
                {
                    "sent": "I don't think that presents a problem because if you would just get a slightly different linearisation for each time step.",
                    "label": 0
                },
                {
                    "sent": "I think it still works.",
                    "label": 0
                },
                {
                    "sent": "Yeah it yeah, it just becomes it.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so effectively it just becomes a constant offset each time in the linearisation.",
                    "label": 0
                },
                {
                    "sent": "Yeah yeah yeah you don't need to write it, so that's that's a red herring.",
                    "label": 0
                },
                {
                    "sent": "It doesn't.",
                    "label": 0
                },
                {
                    "sent": "That doesn't bother us for that, doesn't bother the ukf.",
                    "label": 0
                },
                {
                    "sent": "For this model will bother the Ekso Becausw.",
                    "label": 0
                },
                {
                    "sent": "Importantly, it's got multimodality in the observation function, becausw, you've got his X squared term here, which means there's always ambiguity between XP at plus or minus a value.",
                    "label": 0
                },
                {
                    "sent": "So the CFV extended carbon filter won't routinely be able to track both both positive and negative going parts of the posterior density, which is one reason why you wouldn't want to use it for that model.",
                    "label": 0
                },
                {
                    "sent": "Right, see if I can find where we were.",
                    "label": 0
                },
                {
                    "sent": "Yeah, but thanks for pointing that out.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I think we're here, yes.",
                    "label": 0
                },
                {
                    "sent": "Right, so Monte Carlo filtering man, so if we're just concerned with calculating expectations with respect to the filtering density, this is the equation with interested in.",
                    "label": 0
                },
                {
                    "sent": "The integral is intractable, and we're going to resort to some kind of Monte Carlo integration, so ideally we'd like to be able to draw IID samples from the filtering density somehow.",
                    "label": 1
                },
                {
                    "sent": "Plug them in and get estimates.",
                    "label": 0
                },
                {
                    "sent": "H hearts of H hat of each bar of the meeting, which will simply be the arithmetic mean of those sampled values H of XI.",
                    "label": 0
                },
                {
                    "sent": "XIFT is the ice sample from a large Monte Carlo collection of N Capital N samples.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "'cause we can't do that in general we won't have access to direct samples from peer peer from the filtering density.",
                    "label": 0
                },
                {
                    "sent": "If we did, we'd pretty much solved the problem from a Monte Carlo perspective anyway, so Monte Carlo is really all about.",
                    "label": 0
                },
                {
                    "sent": "Julie, about how do you actually draw samples from, indirectly from some very hard target density?",
                    "label": 0
                },
                {
                    "sent": "So in this case we could do this using important sampling.",
                    "label": 0
                },
                {
                    "sent": "In principle we can't anyway, so we would take some.",
                    "label": 0
                },
                {
                    "sent": "Alternative distribution for X of TSAQ of X of T. Call it the importance function.",
                    "label": 0
                },
                {
                    "sent": "And there is a minor technical requirements on that, principally that it has the same support as the least is as large as support as the as the filtering density P of XT given North through T. Now we make N random draws from this proposal function Q instead of P. So you now have a different set of Monte Carlo samples drawn IID from Q of XAT.",
                    "label": 1
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Problem almost solved, but not quite so to do important sampling you don't have to make a correction to ensure that the expectation estimate is good and the required correction would be the same as we had for the static important sampling at the start of the talk and call it the importance weight W and it would be the ratio of the filtering density evaluated at the sample X2, Y divided by the importance function.",
                    "label": 1
                },
                {
                    "sent": "The density that you sampled from Q.",
                    "label": 0
                },
                {
                    "sent": "Again, evaluated at the sample points XI of T.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then if we've normalized the importance weights, if we don't go ahead and take these WS and normalize them to sum to one, we've got our approximation.",
                    "label": 1
                },
                {
                    "sent": "Are Dirac function approximation to the filtering density, so it would approximately be this weighted sum now of the right functions, with the weights proportional to the ratio of the target filtering this density divided by the importance function Q and normalized such that they sum to one but still proportional.",
                    "label": 1
                },
                {
                    "sent": "To that ratio.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which again gives you weighted sample estimates for the expectation.",
                    "label": 0
                },
                {
                    "sent": "And this is just restating what we had before.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, we don't need to work that through.",
                    "label": 0
                },
                {
                    "sent": "That's just working through the same steps taking our approximation for filtering density is now our weighted sum of Dirac functions and showing that the expectation drops out as a weighted sum of H is evaluated at the.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Propoints that's right, that's all.",
                    "label": 0
                },
                {
                    "sent": "Rather glib.",
                    "label": 0
                },
                {
                    "sent": "Actually, of course, we're not going to be able to do this because we won't be able to calculate the weights, so there is going to be another step coming.",
                    "label": 0
                },
                {
                    "sent": "But for the time being, let's just talk about resampling briefly.",
                    "label": 0
                },
                {
                    "sent": "So in the sequential setting when we're going to be progressing this important sampling from one time point to the next to the next to the next, the whole important sampling paradigm will fall down because we'll find that weights in this weighted importance.",
                    "label": 1
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sampling.",
                    "label": 0
                },
                {
                    "sent": "Will become very degenerate overtime because of the way we construct the sample, or we'll see more of that in a moment.",
                    "label": 0
                },
                {
                    "sent": "In by degenerate I mean that one weight will carry all the probability math.",
                    "label": 0
                },
                {
                    "sent": "So one way would have would be one and the others would all be very close to zero or one would be on.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well then the others would be very close to zero, which means that it's a very poor Monte Carlo representation of the density.",
                    "label": 0
                },
                {
                    "sent": "And so your estimates could be unreliable would be unreliable.",
                    "label": 0
                },
                {
                    "sent": "So resampling kind of fixes that.",
                    "label": 0
                },
                {
                    "sent": "Now re sampling is a bit of a.",
                    "label": 0
                },
                {
                    "sent": "Conceptual problem in particle filtering.",
                    "label": 0
                },
                {
                    "sent": "You know, the theorists have done analysis of this resampling thing than under certain circumstances to find out how the errors accumulate overtime and there's stuff you can do a little bit, you can do not for every type of resampling scheme, but it's a bit of a black art.",
                    "label": 0
                },
                {
                    "sent": "How why you need it and how it works.",
                    "label": 0
                },
                {
                    "sent": "And indeed some people is Radford Neal here this version, Radford had had a long running debate about whether you should use.",
                    "label": 0
                },
                {
                    "sent": "Resampling or not, in this type of these type of sequential importance sampling schemes, because they do in fact in the introduced Monte Carlo error, but nevertheless overtime they are absolutely essential for reducing the accumulation of error.",
                    "label": 0
                },
                {
                    "sent": "More about that later though, but recently what is it actually it's?",
                    "label": 0
                },
                {
                    "sent": "Basically, instead of proceeding through time with weights accumulating as you go through time, we can take the Monte Carlo set and resample it so that they have uniform weights and the way you do that is to take.",
                    "label": 1
                },
                {
                    "sent": "Go through N times, where N is the number of particles.",
                    "label": 0
                },
                {
                    "sent": "Value could have an even be end times, but some large number of times you simply choose for a new particle X dash device to be equal to the previous.",
                    "label": 1
                },
                {
                    "sent": "Any of the previous particles X&Y with probability equal to their weight, so it's a sampling with replacement from a multinomial distribution having weights W and having done that, at least in the limit as the number of particles is very large, you've got an equivalent.",
                    "label": 0
                },
                {
                    "sent": "Representation of an particles but with weights set to 1 / N and the idea being that any particles were very tiny weights never or hardly ever get get chosen in this resampling stage, but any with high weights are presumably very important for the representation.",
                    "label": 0
                },
                {
                    "sent": "Those get selected very often, so you end up with a replenished set of samples that's good for propagating to the next time step.",
                    "label": 0
                },
                {
                    "sent": "Which you wouldn't have had otherwise without the resampling, but you wouldn't want to do this every time step because it does introduce some Monte Carlo error of its own, so you basically wait until the samples have become a bit impoverished and degenerate, and then.",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You do the resulting.",
                    "label": 0
                },
                {
                    "sent": "OK, so I think that's just text that summarizes what I've said.",
                    "label": 0
                },
                {
                    "sent": "This is.",
                    "label": 0
                },
                {
                    "sent": "This is the standard multinomial resampling scheme.",
                    "label": 0
                },
                {
                    "sent": "There are much better ways you could do this that give you a slightly better performance using ideas from Monte Carlo stratification and so on.",
                    "label": 0
                }
            ]
        },
        "clip_80": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so we have a general scheme here.",
                    "label": 1
                },
                {
                    "sent": "Then for approximating the filtering density overtime and also its expectations.",
                    "label": 1
                },
                {
                    "sent": "But it doesn't quite work in in the sequential context because we can't calculate the importance weight, so indicate the importance weight.",
                    "label": 0
                },
                {
                    "sent": "We needed.",
                    "label": 0
                }
            ]
        },
        "clip_81": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Direct access to the filtering density to evaluate the weight.",
                    "label": 0
                },
                {
                    "sent": "We may well be about able to evaluate Q.",
                    "label": 0
                },
                {
                    "sent": "The proposal we almost certainly won't be able to evaluate P. The target filtering density, so we need one more.",
                    "label": 0
                }
            ]
        },
        "clip_82": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Step in here.",
                    "label": 0
                }
            ]
        },
        "clip_83": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And this takes us then to the sequential Monte Carlo filter or the particle filter.",
                    "label": 1
                },
                {
                    "sent": "So the generic solution to this involves a repeated important sampling and resampling sequentially through time.",
                    "label": 0
                },
                {
                    "sent": "And it mimics the filtering recursions in a Monte Carlo fashion, so it does exactly the same thing as the common filter, but using a Monte Carlo version of the filter of the steps.",
                    "label": 0
                }
            ]
        },
        "clip_84": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so to outline the broad principle behind it, let's suppose that we have a collection of samples.",
                    "label": 0
                },
                {
                    "sent": "Again, we've solved the problem at time T, so we have an inner Monte Carlo says that means we've got a collection of samples XI of T, drawn from the correct filtering distribution P of X of T. Given all the data up to T, and again we can write that in terms of unweighted Dirac functions if we like.",
                    "label": 1
                },
                {
                    "sent": "Here's where I switched notation.",
                    "label": 0
                },
                {
                    "sent": "I'm afraid we're different.",
                    "label": 0
                },
                {
                    "sent": "Definition of the Dirac function centered upon XY.",
                    "label": 0
                }
            ]
        },
        "clip_85": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Option of X.",
                    "label": 0
                },
                {
                    "sent": "We substitute that into the prediction equation and see what drops out.",
                    "label": 1
                },
                {
                    "sent": "So we've got.",
                    "label": 0
                },
                {
                    "sent": "This is what we needed to do for the first step.",
                    "label": 0
                },
                {
                    "sent": "Of the filtering equations.",
                    "label": 0
                },
                {
                    "sent": "So the first step involves taking the filtering distribution from the previous time step, which we've now got.",
                    "label": 0
                },
                {
                    "sent": "We've got a Monte Carlo representation for that, multiplying by the state transition density and integrating out the previous state X of T. So we simply take this and plug in the previous times approximation to the filtering density like so.",
                    "label": 0
                },
                {
                    "sent": "Where these are the samples obtained at the previous time T. And then do the integral using the sifting property again, so we end up just in the not like with the normal Monte Carlo integral with the arithmetic mean of all the transition densities F evaluated with the previous samples locations XT of I.",
                    "label": 0
                }
            ]
        },
        "clip_86": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then we can do the correction step because we could take that and plug it directly into the required place.",
                    "label": 1
                },
                {
                    "sent": "In the correction formula, the Bayes theorem correction formula so that involves the likelihood function G. And the approximation for the filtering density for the prediction density like so this is a sort of a big mixture density as a kernel kernelized version of the prediction density involving the transition density as a kernel.",
                    "label": 0
                },
                {
                    "sent": "Animals with one over and still put on the front there and this constant from the bottom line here the conditional likelihood.",
                    "label": 0
                }
            ]
        },
        "clip_87": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And actually, I mean that really is it because having got their sequential Monte Carlo methods?",
                    "label": 0
                }
            ]
        },
        "clip_88": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Basically, clever ways of drawing a lot of samples from that updated density.",
                    "label": 0
                },
                {
                    "sent": "And how are you going to do that?",
                    "label": 0
                },
                {
                    "sent": "You could use any Monte Carlo method.",
                    "label": 0
                },
                {
                    "sent": "Do you like you have to avoid some of the pitfalls?",
                    "label": 0
                },
                {
                    "sent": "For example, you don't really want to be evaluating this entire summation of N kernels every time you every time you make a new sample, so that might be something you could could avoid.",
                    "label": 0
                },
                {
                    "sent": "There's an extra bracket there.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry bout that, just notice that.",
                    "label": 0
                },
                {
                    "sent": "But apart from that, if you can think of some auxiliary variables, way of avoiding that Salvation, you could use any type of.",
                    "label": 0
                }
            ]
        },
        "clip_89": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Monte Carlo solve this problem.",
                    "label": 0
                },
                {
                    "sent": "And that's really what all the different variants of basics are.",
                    "label": 0
                },
                {
                    "sent": "Gradual Monte Carlo about efficient ways of drawing from that target density.",
                    "label": 0
                },
                {
                    "sent": "So basically just Monte Carlo methods to produce a load of new samples from the approximation to the new filtering density at 2 + 1.",
                    "label": 1
                }
            ]
        },
        "clip_90": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "'cause there's a lot of details behind that.",
                    "label": 0
                },
                {
                    "sent": "Which is where I'm heading next.",
                    "label": 0
                },
                {
                    "sent": "They can be done by any Monte Carlo means you like.",
                    "label": 1
                },
                {
                    "sent": "If you can do things like form and envelope function for for the updated target distribution.",
                    "label": 1
                },
                {
                    "sent": "This thing here then you could do rejection sampling to get some exact samples from it.",
                    "label": 0
                },
                {
                    "sent": "People have done that.",
                    "label": 0
                },
                {
                    "sent": "That's the kind of thing that was done by the fairly early days.",
                    "label": 0
                },
                {
                    "sent": "Bye bye crunches group.",
                    "label": 0
                },
                {
                    "sent": "Other people have tried it.",
                    "label": 1
                },
                {
                    "sent": "The most common procedure, as you have gathered by now, is an important sampling approach.",
                    "label": 0
                },
                {
                    "sent": "That's a nice, simple, fast way of doing it.",
                    "label": 0
                },
                {
                    "sent": "You can put in MCMC here.",
                    "label": 0
                },
                {
                    "sent": "There's absolutely nothing.",
                    "label": 0
                },
                {
                    "sent": "That stops you just taking.",
                    "label": 0
                }
            ]
        },
        "clip_91": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This thing the updated filtering, distribution and running a uh at MCMC procedure you can always evaluate this target distribution up to a normalizing constant at any proposed value of the new state, so you can simply run a big MCMC chain on this, and this was something that was done by some of the robotics people at Georgia, Georgia Tech, Dirt and Co.",
                    "label": 0
                }
            ]
        },
        "clip_92": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But that's a rather slow filter because you do.",
                    "label": 0
                }
            ]
        },
        "clip_93": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To evaluate this sub examination at every time.",
                    "label": 0
                },
                {
                    "sent": "Every time you.",
                    "label": 0
                }
            ]
        },
        "clip_94": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Can you update?",
                    "label": 0
                }
            ]
        },
        "clip_95": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then you can put in special Monte Carlo schemes as well.",
                    "label": 0
                }
            ]
        },
        "clip_96": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That may also give.",
                    "label": 0
                }
            ]
        },
        "clip_97": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Results.",
                    "label": 0
                },
                {
                    "sent": "And that, then, is the joint posterior distribution for the old state and the new state given the old data.",
                    "label": 0
                },
                {
                    "sent": "And then you'd like to take that as before, and we'll call this step one and marginalized out the old state.",
                    "label": 0
                },
                {
                    "sent": "And finally, take that marginalized predictive distribution for X T + 1 and plug it into the Bayes formula to get you your updated corrected filtering distribution at T + 1.",
                    "label": 1
                }
            ]
        },
        "clip_98": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we want to mimic those three steps by Monte Carlo operations.",
                    "label": 0
                },
                {
                    "sent": "Start off as usual with the collection of large collection of samples from the correct distribution at.",
                    "label": 0
                }
            ]
        },
        "clip_99": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Time T. Course you could use those at time T to do any estimates you needed at time T, make histogram estimates, calculate Monte Carlo expectations.",
                    "label": 0
                }
            ]
        },
        "clip_100": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Etc.",
                    "label": 0
                },
                {
                    "sent": "But now let's simulate step nought or so.",
                    "label": 0
                }
            ]
        },
        "clip_101": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Nought is done simply by appending a new States T + 1 onto the old state X of T. The ice sample of it.",
                    "label": 0
                },
                {
                    "sent": "For each particle I.",
                    "label": 0
                },
                {
                    "sent": "And drawing a new state XD plus one from the state transition density.",
                    "label": 1
                },
                {
                    "sent": "So it's simplest possible update, you could probably think of for this model.",
                    "label": 0
                },
                {
                    "sent": "Just take the old XD.",
                    "label": 0
                },
                {
                    "sent": "Add a new X T + 1 onto it drawn from the state transition density.",
                    "label": 0
                },
                {
                    "sent": "So in the models we've seen so far, that just involves multiplying X of T by a matrix in the linear model and adding some noise to it so that sampling is simple in the nonlinear model.",
                    "label": 0
                },
                {
                    "sent": "It was just a matter of calculating the nonlinear function A.",
                    "label": 0
                },
                {
                    "sent": "Of X and adding noise to it.",
                    "label": 0
                },
                {
                    "sent": "So very often this step is trivial too.",
                    "label": 0
                }
            ]
        },
        "clip_102": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Compute.",
                    "label": 0
                },
                {
                    "sent": "Having done that, we've got step nought, because that's now a joint draw from the predicted distribution with XT&X is 2 + 1 given wynaut through T and then.",
                    "label": 1
                },
                {
                    "sent": "So and then we've effectively now solved step one.",
                    "label": 0
                }
            ]
        },
        "clip_103": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Because we recall from the basic Monte Carlo properties, we've gotta draw from a joint density for XD and XD plus one we simply throw away the sample for X of T that we have from that pair.",
                    "label": 0
                },
                {
                    "sent": "Then automatically with marginalized and we're left with the sample just for X T + 1 given Y nought through T. So we've automatically done step one and we now have a random random sample from the required marginal distribution.",
                    "label": 1
                },
                {
                    "sent": "XD plus one given Y.",
                    "label": 0
                },
                {
                    "sent": "Not through T.",
                    "label": 0
                }
            ]
        },
        "clip_104": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then Step 2 is just a reweighting procedure.",
                    "label": 0
                },
                {
                    "sent": "We gotta calculate.",
                    "label": 0
                },
                {
                    "sent": "We've got plug in.",
                    "label": 0
                },
                {
                    "sent": "We've got.",
                    "label": 0
                },
                {
                    "sent": "The samples from the predictive distribution.",
                    "label": 0
                },
                {
                    "sent": "And Step 2 gives us the appropriate importance.",
                    "label": 1
                },
                {
                    "sent": "Weight.",
                    "label": 0
                },
                {
                    "sent": "Well, how do we get the importance weight we would need where we want to look at the target distribution for the next time step?",
                    "label": 0
                },
                {
                    "sent": "That's clearly what we want and divide it through by what we've proposed.",
                    "label": 0
                },
                {
                    "sent": "Well, we now have a sample from that, so the proposal distribution Q is equal to that.",
                    "label": 0
                },
                {
                    "sent": "So we put that on the bottom line for Q and expand out the top line using Bayes formula as before, so this was the correction step from Bayes theorem precisely.",
                    "label": 0
                }
            ]
        },
        "clip_105": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Press precisely this.",
                    "label": 0
                }
            ]
        },
        "clip_106": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And it simplifies down then, because now this cancels out in the ratio and we have something that's proportional, just 2G of Y T + 1 given X T + 1, because that term there is a constant.",
                    "label": 0
                },
                {
                    "sent": "It only depends on the current data set Y.",
                    "label": 0
                },
                {
                    "sent": "And these terms cancel for left, just with the G. So this is a very elegant simple vanilla scheme.",
                    "label": 0
                },
                {
                    "sent": "We just propagate forwards to given XT plus one from the from the prior transition density, and the weight is simply then evaluated as the likelihood G.",
                    "label": 0
                }
            ]
        },
        "clip_107": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then you've got this option of resampling or not resampling, so we can calculate await by accumulating the weights overtime.",
                    "label": 1
                },
                {
                    "sent": "If we if we started off with a weighted particle set time T instead of an unweighted one.",
                    "label": 0
                },
                {
                    "sent": "Remember we just had a 1 / N sample at the beginning of the iteration.",
                    "label": 0
                },
                {
                    "sent": "If we have weights WFT instead, then we need to accumulate those and multiply them through by the new factor G of Y.",
                    "label": 0
                },
                {
                    "sent": "Given X, so the new weight becomes the old rate times that G function.",
                    "label": 0
                }
            ]
        },
        "clip_108": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or if we judge that the samples have become depleted and it's a poor Monte Carlo representation, or hopefully before we get to a polar opposite representation where it's heading that way, then we can re sample the particles from a multinomial again setting the new state to be equal to 1 of the other states with probability proportional to its weight, and reset the weights too.",
                    "label": 0
                }
            ]
        },
        "clip_109": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Over at so, the algorithm is simply this.",
                    "label": 0
                },
                {
                    "sent": "You iterate over the all of the time steps.",
                    "label": 0
                },
                {
                    "sent": "For each time step, you iterate over all of the particles.",
                    "label": 0
                },
                {
                    "sent": "You first propagate a new state for each particle through the state transition density.",
                    "label": 0
                },
                {
                    "sent": "Then you calculate a weight, accumulating it by multiplying by any previous weight.",
                    "label": 0
                },
                {
                    "sent": "Times the observation density.",
                    "label": 0
                },
                {
                    "sent": "And then you can either re sample or not re sample depending on whether the weights look degenerate or not.",
                    "label": 0
                },
                {
                    "sent": "And there are automatic ways of.",
                    "label": 0
                }
            ]
        },
        "clip_110": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Determining whether to do that.",
                    "label": 0
                },
                {
                    "sent": "And if you apply that to this standard nonlinear model, it's exactly the same model that we had before.",
                    "label": 1
                },
                {
                    "sent": "As I said, it's trivial to go ahead and do this update this prediction step.",
                    "label": 0
                },
                {
                    "sent": "All you have to do is take the previous sampled XT minus one.",
                    "label": 0
                },
                {
                    "sent": "Calculate the nonlinear function A, so calculate this function of X, T -- 1.",
                    "label": 0
                },
                {
                    "sent": "Add on a random disturbance and independent disturbance for each particle drawn from the same distribution as V. So that gives you your prediction step.",
                    "label": 0
                },
                {
                    "sent": "Your weight calculation, then, is simply involves evaluating a Gaussian density function.",
                    "label": 0
                },
                {
                    "sent": "So you go down now from the from the additive representation to the density function representation of G, you need to just calculate the value of the normal density function at.",
                    "label": 0
                },
                {
                    "sent": "Why, given the nonlinear function B of X with variant Sigma W ^2.",
                    "label": 0
                },
                {
                    "sent": "I'm.",
                    "label": 0
                },
                {
                    "sent": "Who?",
                    "label": 0
                }
            ]
        },
        "clip_111": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "See that in operation in a moment, but.",
                    "label": 0
                },
                {
                    "sent": "If we look at one time step of that you can see pretty much what's going on with this basic particle filter, so this runs.",
                    "label": 0
                },
                {
                    "sent": "Top left down following the Red Arrows.",
                    "label": 0
                },
                {
                    "sent": "So at time T you've got a model Monte Carlo approximation to the filtering density at time T. So I represent the samples.",
                    "label": 0
                },
                {
                    "sent": "You can't see the individual samples here.",
                    "label": 0
                },
                {
                    "sent": "I've shown the samples along the X axis as asterisks there, and I've plotted over top of that affine kernel density representation of those green asterisks.",
                    "label": 0
                },
                {
                    "sent": "So that's where you start off.",
                    "label": 0
                },
                {
                    "sent": "You first go through the prediction step, so you take for each of these greed asterisks.",
                    "label": 0
                },
                {
                    "sent": "You pass it through the transition equation by generating a new sample X T + 1.",
                    "label": 0
                },
                {
                    "sent": "Sorry, these are these letters haven't come out very clearly, but basically you just predict a new X2 plus one.",
                    "label": 0
                },
                {
                    "sent": "As I showed you from the transition density given the previous state sample XT of I.",
                    "label": 0
                },
                {
                    "sent": "So that tends to most dynamical models to spread things out across the X axis, so this sends the particles out across a broader range and we now get a broader kernel density representation of the predictive density now.",
                    "label": 0
                },
                {
                    "sent": "So this is now the predicted density of XT plus one given the old data.",
                    "label": 0
                },
                {
                    "sent": "Why not through T?",
                    "label": 0
                },
                {
                    "sent": "You then gotta take that and calculate the weight.",
                    "label": 0
                },
                {
                    "sent": "So for each of these asterisks you go and calculate G, the value of the observation density.",
                    "label": 0
                },
                {
                    "sent": "This normal density centered upon.",
                    "label": 0
                },
                {
                    "sent": "The new sample X T + 1 I so that means that each of these asterisks now gets a weight associated with its shown by this blue line.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "The reason this is.",
                    "label": 0
                },
                {
                    "sent": "Multimodal, in fact, know that the blue line is the kernel density estimate for the filtering density now actually.",
                    "label": 0
                },
                {
                    "sent": "But the reason this is bimodal, it has two modes is because of the X squared function.",
                    "label": 0
                },
                {
                    "sent": "In the observation density so very often there is an ambiguity between whether X was minus something or plus something, and that's being shown up.",
                    "label": 0
                },
                {
                    "sent": "Here in the in the Monte Carlo representation is having two possible locations for X of T. So we have 2 + 1 and then the problem here is that while many of the samples sit in good parts of the density in the high probability parts of the density, there's a lot of wasted effort because a lot of them have landed up in places where there's no significant weight or probability mass.",
                    "label": 0
                },
                {
                    "sent": "So when you do the resampling step.",
                    "label": 0
                },
                {
                    "sent": "Most of those get resampled out, so in fact, in this case all of them got resampled out and you just get left with a bunch of samples sitting on the high probability regions for the target density with nothing in between.",
                    "label": 0
                },
                {
                    "sent": "In fact, this was a particle filter that was running with many particles.",
                    "label": 0
                },
                {
                    "sent": "I think 10,000 particles and I just took a random selection of the particles to show us the green asterisks.",
                    "label": 0
                },
                {
                    "sent": "So in fact you'll see there are more particles sitting here than they were they were originally above there.",
                    "label": 0
                },
                {
                    "sent": "That's just because I've chosen 100 out of 10,000 randomly in both cases, and not necessarily the same 100.",
                    "label": 0
                },
                {
                    "sent": "OK, let's see if I can just run that and show you some typical output.",
                    "label": 0
                },
                {
                    "sent": "Well, let's have a look at some output.",
                    "label": 0
                },
                {
                    "sent": "So running over.",
                    "label": 0
                },
                {
                    "sent": "Well, let's have a look at the code first.",
                    "label": 0
                },
                {
                    "sent": "The code, as you could imagine for this example is very, very simple.",
                    "label": 0
                },
                {
                    "sent": "This is basically it.",
                    "label": 0
                },
                {
                    "sent": "You pull in.",
                    "label": 0
                },
                {
                    "sent": "Do you put in the previous weights?",
                    "label": 0
                },
                {
                    "sent": "From the previous time step and you calculate the approach you put in the appropriate state X.",
                    "label": 0
                },
                {
                    "sent": "So this is a vector of state, so we might like this can all be vectorized.",
                    "label": 0
                },
                {
                    "sent": "So you propagate that one one time step forward.",
                    "label": 0
                },
                {
                    "sent": "So you take the previous states xti, we propagate the one step forward through the dynamical model, but all of that is just the nonlinear function A, plus some Gaussian random noise.",
                    "label": 0
                },
                {
                    "sent": "So there's a different random noise term for each for each particle.",
                    "label": 0
                },
                {
                    "sent": "And then calculate the likelihood function.",
                    "label": 0
                },
                {
                    "sent": "In this case the I've calculated something proportional to the likelihood function and in logarithmic form.",
                    "label": 0
                },
                {
                    "sent": "So so this is just the exponent of the Gaussian function.",
                    "label": 0
                },
                {
                    "sent": "And then there's some, and then you go ahead and do the resampling.",
                    "label": 0
                },
                {
                    "sent": "And there are some extra stuff here that I haven't talked about relating to the ordinary particle filter and so on.",
                    "label": 0
                },
                {
                    "sent": "But basically if you go through a normal resampling step, you if you do the resampling you, that's the line for it.",
                    "label": 0
                },
                {
                    "sent": "And then the weights just get set to 1 / N. And the output of that is can be represented in many different ways, But So what do I have here?",
                    "label": 0
                },
                {
                    "sent": "This is time along the X axis, and this is the X value along the Y axis and the blue asterisks.",
                    "label": 0
                },
                {
                    "sent": "I should have done this in a different color, so this is a synthetic waveform generated from the same model, same nonlinear model and the blue asterisks show you the true value of the state.",
                    "label": 0
                },
                {
                    "sent": "And what I've shown here is an intensity map at each time is the estimated filtering density coming out of the particle filter for using a kernel density representation of the particles?",
                    "label": 0
                },
                {
                    "sent": "So basically, wherever you get high intensity, that's a high probability estimate for the state, and usually that's it's over the over the correct estimate for the state.",
                    "label": 0
                },
                {
                    "sent": "Sometimes we should be able to see some bimodality appearing in here.",
                    "label": 0
                },
                {
                    "sent": "Just trying to spot it out.",
                    "label": 0
                },
                {
                    "sent": "It's not.",
                    "label": 0
                },
                {
                    "sent": "This is not a very bimodal example, but for example here the state could have been either there or there with a certain probability here.",
                    "label": 0
                },
                {
                    "sent": "It could have been there or there.",
                    "label": 0
                },
                {
                    "sent": "There or there.",
                    "label": 0
                },
                {
                    "sent": "So these are the is able to track the bimodality of the filtering distribution as it moves overtime quite successfully.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "I'm I could show you that I've just run that just before the lecture.",
                    "label": 0
                },
                {
                    "sent": "I don't think actually running it in front of you shows you anything more, and I'm kind of running out of time.",
                    "label": 0
                },
                {
                    "sent": "So for this first part of the talk, so let me go back to.",
                    "label": 0
                }
            ]
        },
        "clip_112": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here OK.",
                    "label": 0
                },
                {
                    "sent": "So I'll just talk a little bit about how to generalize this to more effective samples will come back to this at the start of tomorrow's lecture, but what we're going to do is.",
                    "label": 0
                },
                {
                    "sent": "Trying to better than with that basic bootstrap filter.",
                    "label": 1
                },
                {
                    "sent": "The problem is the very problem is the problem is actually.",
                    "label": 0
                }
            ]
        },
        "clip_113": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Publicity and elegance becausw, we are blindly sampling X of T + 1 into the future from the state transition density in a way that does not depend on what new data appears.",
                    "label": 0
                },
                {
                    "sent": "It can be a very inefficient Monte Carlo sampler, so we don't really want to do that except in models where it's so simple that it just works nicely and there are some.",
                    "label": 0
                },
                {
                    "sent": "But if we want to generalize this and do a bit better.",
                    "label": 0
                },
                {
                    "sent": "We could consider this now by working, and this is something that our refer back to tomorrow quite a lot but will look instead of at the marginal for the new state.",
                    "label": 0
                },
                {
                    "sent": "Exit 2 + 1.",
                    "label": 0
                },
                {
                    "sent": "Let's look at it in the joint space throughout.",
                    "label": 0
                },
                {
                    "sent": "So if we work with our proposal density and it's an important function for the old state and the new state which is the filtering density at the previous time, which we have, we've got samples from that.",
                    "label": 0
                },
                {
                    "sent": "And then I draw some proposal for the new state given the old state and it maybe it can be dependent on the data as well, and that's important.",
                    "label": 0
                },
                {
                    "sent": "Then I then I've got a joint proposal function on XT&X 2 + 1.",
                    "label": 0
                },
                {
                    "sent": "I can take that and compare it with the joint target distribution for T and T + 1, so this is now the joint distribution for XT and T + 1 given all the data including the new data.",
                    "label": 0
                },
                {
                    "sent": "So I can factorize that as the filtering times the transition times the observations divided by a constant term.",
                    "label": 0
                },
                {
                    "sent": "Very similarly.",
                    "label": 0
                },
                {
                    "sent": "Then I can calculate an importance weight for this because it will simply be the ratio of this divided by this.",
                    "label": 0
                },
                {
                    "sent": "And once I've got that, that gives me a weighted sample from this joint target.",
                    "label": 0
                },
                {
                    "sent": "From which I can extract the marginal that I require just for the new state T plus.",
                    "label": 0
                }
            ]
        },
        "clip_114": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So if we do that.",
                    "label": 0
                },
                {
                    "sent": "The weight you get simplifies down some terms cancel out and instead of just the observation density for the weight, I now have to factor in the transition density and the proposal.",
                    "label": 0
                },
                {
                    "sent": "And here I've omitted it.",
                    "label": 0
                },
                {
                    "sent": "But this proposal, as I said, can depend on the data Y as well, so I could put a collar wynaut through T + 1 in there as well effectively, and that's the general sequential importance sampling method that's that's normally adopted for.",
                    "label": 1
                }
            ]
        },
        "clip_115": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For many problems.",
                    "label": 0
                },
                {
                    "sent": "And from it you get some special cases.",
                    "label": 0
                },
                {
                    "sent": "If curious, set just equal to the transition density itself, then these terms cancel on your back to the normal bootstrap filter that I described first.",
                    "label": 0
                },
                {
                    "sent": "If you are able to access the conditional distribution for the new state given the old state and the new data, like a sort of a Gibbs sampling density.",
                    "label": 0
                },
                {
                    "sent": "Then and you could sample from that.",
                    "label": 0
                },
                {
                    "sent": "Then that's basically the optimal important function which which gives you very nice performance in terms and can be shown to minimize the variance of these weights, which is a good thing.",
                    "label": 0
                }
            ]
        },
        "clip_116": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Think I'm pretty well done, actually and again repeated application overtime would lead to we will come back to this first type first thing tomorrow.",
                    "label": 0
                }
            ]
        },
        "clip_117": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Just to conclude what I'm going to say today.",
                    "label": 0
                },
                {
                    "sent": "So we covered today the basic underlying concepts, the Bayesian filtering, Kalman filter, the bootstrap filter, and we started on the general SMC filter.",
                    "label": 1
                },
                {
                    "sent": "Tomorrow we will be looking at some of the more advanced topics the general another view of general sequential Monte Carlo, which leads us into things like the auxiliary particle filter and MCMC.",
                    "label": 0
                },
                {
                    "sent": "Particle filters would also look at the.",
                    "label": 0
                },
                {
                    "sent": "The rare black lies particle filter and some Monte Carlo smoothing.",
                    "label": 0
                },
                {
                    "sent": "If we have time, we'll also look at some population Monte Carlo and applications.",
                    "label": 0
                },
                {
                    "sent": "Fine, I think that's all for today.",
                    "label": 0
                }
            ]
        }
    }
}