{
    "id": "k77d27izqcsceo2nytznzlyje2352nhw",
    "title": "Challenge with Large Scale Problems",
    "info": {
        "author": [
            "S\u00f6ren Sonnenburg, Machine Learning and Intelligent Data Analysis Group, TU Berlin"
        ],
        "published": "Feb. 7, 2008",
        "recorded": "January 2008",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/psm08_sonnenburg_cls/",
    "segmentation": [
        [
            "OK, so I'm I'm afraid that I'm only talking about a small scale challenge now.",
            "Yeah, so data set sizes, which we hope more machine owners can can take part.",
            "I mean can deal with.",
            "So it's only datasets which which people we think may be able still to load into memory.",
            "So no bigger than 32 gigabytes.",
            "OK um."
        ],
        [
            "So that's the outline of the talk, so we're proposing to have a large scale learning challenge, and there's some certain motivating application.",
            "And I would describe some details to advertise this challenge."
        ],
        [
            "OK, so.",
            "First of all, what makes a problem in large scale?",
            "Well basically problems large scale which has a large number of data points like very high dimensionality and even promised even already large scale few for lower number of data points.",
            "If the algorithm is of high effort behind it and the tests like large memory requirements.",
            "So basically anything that reaches current computers limits be at computational memory.",
            "Or transfer costs.",
            "And there are many applications.",
            "Good morning, but informatics now also in astronomy and T security and image recognition."
        ],
        [
            "And our motivation behind all this was basically that we recognize that many, many new SVM solvers, linear system solvers kept appearing, which were all basically faster than one and the other ones, which somehow sound suspicious.",
            "For example, tossing out themes.",
            "Introduced SB Imperf and showed that it was much faster than a Streamlight, but in our own experiments actually assume light was still faster than assume Perth.",
            "Then there was shelved Schwartz.",
            "We are proposing Pigasus, which was again much faster than a Streamlight initium Perth, but and then I try to reproduce the experiment and was slower than the later 2.",
            "Then there can bundle method came out which is actually actually special.",
            "Very special cases of the bundle method.",
            "SVM is SVM Perth and it was strangely.",
            "It was really faster than SVM light and also fascinates PM Perth.",
            "But then as you improve 2.1 came out and it was.",
            "Really similar speech, and now it's nips.",
            "Last year, younger told us that starting going decent is the way to go, and it's the fastest for everything.",
            "So I think from this it's clear it's really difficult to judge which method is faster.",
            "Um?"
        ],
        [
            "And reason for this so definitely that people like Asians on different datasets using different parameters.",
            "The meaning of the parameters were different.",
            "Some use objective value, some test.",
            "I mean I use objective value.",
            "Let's some others use test error is evaluation.",
            "Of course we programming our errors for certain certain inefficient groups in the code or other mistakes.",
            "No one knows of."
        ],
        [
            "OK, so it's clear we need.",
            "We need some fair comparison and it would be good to not, not I or just one person does it, but the authors of these software packages themselves so that is why we are proposing to have such a large scale challenge and grew into something bigger.",
            "So the main goal is now to to answer which learning method is the most accurate given limited resources.",
            "And evaluation will be based on on time.",
            "Some error measure and for SPMS even objective value and additional goals of course.",
            "And we can figure out what's the method that gives the best accuracy on such a data set.",
            "Which is which is the method which achieves the for certain training time the best test error?",
            "And should we use an algorithm which approximates like like it's ready for example?",
            "Or should we use an algorithm which really optimizes to death?",
            "Um?",
            "And then also if we do large scale learning, what should we should be ready to and should we should be only tune like data presentation?",
            "Should we select the right features and then do all the learning?",
            "Or should we optimize the core algorithm?"
        ],
        [
            "OK, so.",
            "Now for the proposal.",
            "So we're proposing to have two tricks.",
            "One's called white competition.",
            "So it's basically do whatever you want.",
            "Just get a better result fast.",
            "Another track is method specific.",
            "So for now we only use.",
            "We only want to evaluate also support vector machine solvers like just a linear SVM and the kernel based systems.",
            "And the setup is that you get a number of datasets.",
            "And different data set sizes.",
            "And of course, you're given some unlabeled validation set where you can compute your outputs on and you're asked to record the training time.",
            "Not only train time, but also time to compute outputs.",
            "Otherwise, Kenya's neighbor would be winning the competition.",
            "And you asked to give 10 intermediate points while the body optimization procedure or algorithm is running such that we can have some performance figures progress overtime.",
            "Some program which calibrates hopefully calibrates an for these different machine types.",
            "But at the end we will take the top ten performing methods and do a re evaluation on a single machine, so should be more fair than.",
            "OK, so then of course we will provide some life life feedback for the validation set and at after the end of the competition we provide the test set and people should then compute outputs on this.",
            "And it can be like many, many tricks can be involved in this, especially in this world competition.",
            "So we ask you review and contributors to like explicitly identify which parts made gave big speedup.",
            "OK."
        ],
        [
            "So we have a number of datasets here, which all nodes on.",
            "Small scale so they are.",
            "It's some data set which is some spice data set I've been working on.",
            "It has only only 55 million examples and only eight like 8 gigabytes in size, so still fits in memory.",
            "Then there's some some webspam based data, which is.",
            "But it's this change is only about two class classification, so it's not like the structure learning you do there.",
            "Then we have some face detection and some some OCR examples.",
            "And some artificial data that that would have been generated on the controlled conditions.",
            "To see how methods perform, for example on very sparse or dense datasets.",
            "Is OK, so actually this offer this data set here seems to be larger, smaller only 500,000 examples.",
            "It's actually the biggest one.",
            "It's free 32 gigabyte in size.",
            "OK, so."
        ],
        [
            "So the timeline we actually want to start this competition somewhere in in February, so if everything goes well, then like closed after the ice email deadline.",
            "Then we plan to have to anti competition competition in June and then do the evaluation and hopefully we get an ICM workshop accepted such that we can meet and discuss vote results and problems and we then consider to have proceedings in lecture notes, computer science and for the best or most original.",
            "Methods OK."
        ],
        [
            "So the evaluation criteria will be basically based on three different figures.",
            "Figure out which is which plots time versus test error or objective value for the SVM trick.",
            "In addition, data set size versus time and data set size versus test error, and from these figures we compute some performance measures.",
            "OK, and the overall winner will be the winner, which ranks best in all of these datasets on average.",
            "OK, so the figure."
        ],
        [
            "Time versus test error is that one and.",
            "A scalar measure we can.",
            "We could use the method which achieves.",
            "I mean we could rank by the minimal test error test error can be anything like the area over this precision recall curve.",
            "Then then we could compute the error under this whole curve method, which is like quickly gets down to low.",
            "To lower errors is of course better.",
            "And then we will also have some some fixed some fixed test error and then ranked methods by the time it takes them to achieve this test error OK then."
        ],
        [
            "You can do the same thing for data set size versus time.",
            "It's basically it's very, very well known plot and which is often with all this product in lock lock and so you have the exponent.",
            "Hope.",
            "Give you an exponent in the in the polynomial, so that's we will use this as a scalar measure here.",
            "And then."
        ],
        [
            "The last figure was data set size versus test error and there actually also.",
            "You can also take the area under this under this curve.",
            "So which data set can can only the few data points which which method can only have few data points learn quite well.",
            "This is also seems also be quite reasonable.",
            "And you can do it at the thing.",
            "You can also again fix the test error.",
            "Um?",
            "And then the method which achieves this test error for the smallest data set size.",
            "This will be based in this in this ranking.",
            "Um?",
            "OK for for SPMS.",
            "Likely adjust."
        ],
        [
            "On this criteria to to also include.",
            "So we will ask people to train SVM's for a cycle given parameter set for given accuracy and see.",
            "And we can figure out hopefully that what what's the difference?",
            "What's the relation between objective and enter test?",
            "Oh, and which of these stopping criteria?",
            "There are many of them best?"
        ],
        [
            "Yeah so.",
            "Yes, it's clear so far.",
            "We definitely would also have to a certain RBF kernel, it's and.",
            "Then in the end."
        ],
        [
            "Oh of course, hope that you would want to take part in this.",
            "We have some life submission system."
        ],
        [
            "And then.",
            "To summarize, this challenge will be start in mid mid February and in June and there are these two tracks like the White competition which is for all classification methods and an SVM specific trick.",
            "We have these four different real world datasets and.",
            "It's artificial controlled datasets.",
            "Valuation figures the relation will be based on these three different figures and scores.",
            "We compute button and from them, so I hope some of you may want to take part in this change.",
            "Thank you.",
            "Huh?"
        ],
        [
            "So the STD question.",
            "A very nice looking criteria is duality gap, because it's quite.",
            "It's already the natural stuff.",
            "And it's in a way much more robust than measuring a validation error which has a lot of noise.",
            "Unless you have an enormous bestseller crossword.",
            "Fortunately yeah, but for some methods you don't have the primary end to do it, so it's not so.",
            "It doesn't have it naturally, but it's not that expensive to compute.",
            "Challenge.",
            "Different differences.",
            "This difference of performance is less than the noise you would have been using a validation set unless the validation set is enormous.",
            "It can be quite annoying.",
            "You have a million.",
            "We tried to do some comparisons of different approximations.",
            "And there's one other point there, which is that there is there three times is that I'm too if you're learning like hyperparameters, nothing.",
            "Those feature selection first time for that time to train the time to test different regimes as if those are different when the other thing is probably.",
            "Look below Fishel data.",
            "Better actually care that there is something to be found as you get bigger datasets, 'cause you probably designed this, but sometimes you get too noisy data set and it really asymptotes often like 1000 people until you have to be careful.",
            "So OK, for these artificial datasets we took care of that we have more data, get better results here.",
            "And it's not.",
            "Also hopefully not so easy to figure out the underlying distributions, but you're right that it's a big.",
            "It's a big problem that people with some methods like FTS disparage, which we could estimate like before hand and you don't know whether this still counts for training to training time or not.",
            "Yeah, and.",
            "Yeah, OK, it's really still an issue I think.",
            "For what?",
            "Because the biggest correction, I mean it had 55 million examples or.",
            "Prediction.",
            "OK, of course even bigger datasets as we see no no no.",
            "But on the other hand I'm not sure whether we would find people to contribute if they have no chance to even load the data into main memory.",
            "So that's the tradeoff.",
            "The number of positive examples.",
            "Problems where you are billions of examples but just the 2000s of positive examples, and that's pretty much it.",
            "That's an easy set of these datasets.",
            "Or it's not possible to see each example more than one time, yeah?",
            "Streaming online malware.",
            "Basically, you're forced to go to your data point.",
            "Yeah, so that's OK. Yeah, I mean.",
            "Now that we didn't OK but didn't want to restrict it to just online methods, OK, I mean maybe one could do it, but there's all these SVM solvers currently are not.",
            "I mean, most of them are not online.",
            "And you want to have these also evaluated.",
            "Of course we could again like split up like smaller datasets, and some do it.",
            "Yeah, for this SVM stand differently but.",
            "Hello."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so I'm I'm afraid that I'm only talking about a small scale challenge now.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so data set sizes, which we hope more machine owners can can take part.",
                    "label": 0
                },
                {
                    "sent": "I mean can deal with.",
                    "label": 0
                },
                {
                    "sent": "So it's only datasets which which people we think may be able still to load into memory.",
                    "label": 0
                },
                {
                    "sent": "So no bigger than 32 gigabytes.",
                    "label": 0
                },
                {
                    "sent": "OK um.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that's the outline of the talk, so we're proposing to have a large scale learning challenge, and there's some certain motivating application.",
                    "label": 0
                },
                {
                    "sent": "And I would describe some details to advertise this challenge.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "First of all, what makes a problem in large scale?",
                    "label": 1
                },
                {
                    "sent": "Well basically problems large scale which has a large number of data points like very high dimensionality and even promised even already large scale few for lower number of data points.",
                    "label": 1
                },
                {
                    "sent": "If the algorithm is of high effort behind it and the tests like large memory requirements.",
                    "label": 0
                },
                {
                    "sent": "So basically anything that reaches current computers limits be at computational memory.",
                    "label": 1
                },
                {
                    "sent": "Or transfer costs.",
                    "label": 0
                },
                {
                    "sent": "And there are many applications.",
                    "label": 0
                },
                {
                    "sent": "Good morning, but informatics now also in astronomy and T security and image recognition.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And our motivation behind all this was basically that we recognize that many, many new SVM solvers, linear system solvers kept appearing, which were all basically faster than one and the other ones, which somehow sound suspicious.",
                    "label": 1
                },
                {
                    "sent": "For example, tossing out themes.",
                    "label": 0
                },
                {
                    "sent": "Introduced SB Imperf and showed that it was much faster than a Streamlight, but in our own experiments actually assume light was still faster than assume Perth.",
                    "label": 1
                },
                {
                    "sent": "Then there was shelved Schwartz.",
                    "label": 1
                },
                {
                    "sent": "We are proposing Pigasus, which was again much faster than a Streamlight initium Perth, but and then I try to reproduce the experiment and was slower than the later 2.",
                    "label": 0
                },
                {
                    "sent": "Then there can bundle method came out which is actually actually special.",
                    "label": 0
                },
                {
                    "sent": "Very special cases of the bundle method.",
                    "label": 0
                },
                {
                    "sent": "SVM is SVM Perth and it was strangely.",
                    "label": 0
                },
                {
                    "sent": "It was really faster than SVM light and also fascinates PM Perth.",
                    "label": 0
                },
                {
                    "sent": "But then as you improve 2.1 came out and it was.",
                    "label": 0
                },
                {
                    "sent": "Really similar speech, and now it's nips.",
                    "label": 0
                },
                {
                    "sent": "Last year, younger told us that starting going decent is the way to go, and it's the fastest for everything.",
                    "label": 1
                },
                {
                    "sent": "So I think from this it's clear it's really difficult to judge which method is faster.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And reason for this so definitely that people like Asians on different datasets using different parameters.",
                    "label": 1
                },
                {
                    "sent": "The meaning of the parameters were different.",
                    "label": 1
                },
                {
                    "sent": "Some use objective value, some test.",
                    "label": 0
                },
                {
                    "sent": "I mean I use objective value.",
                    "label": 0
                },
                {
                    "sent": "Let's some others use test error is evaluation.",
                    "label": 0
                },
                {
                    "sent": "Of course we programming our errors for certain certain inefficient groups in the code or other mistakes.",
                    "label": 0
                },
                {
                    "sent": "No one knows of.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so it's clear we need.",
                    "label": 1
                },
                {
                    "sent": "We need some fair comparison and it would be good to not, not I or just one person does it, but the authors of these software packages themselves so that is why we are proposing to have such a large scale challenge and grew into something bigger.",
                    "label": 1
                },
                {
                    "sent": "So the main goal is now to to answer which learning method is the most accurate given limited resources.",
                    "label": 1
                },
                {
                    "sent": "And evaluation will be based on on time.",
                    "label": 1
                },
                {
                    "sent": "Some error measure and for SPMS even objective value and additional goals of course.",
                    "label": 0
                },
                {
                    "sent": "And we can figure out what's the method that gives the best accuracy on such a data set.",
                    "label": 0
                },
                {
                    "sent": "Which is which is the method which achieves the for certain training time the best test error?",
                    "label": 0
                },
                {
                    "sent": "And should we use an algorithm which approximates like like it's ready for example?",
                    "label": 0
                },
                {
                    "sent": "Or should we use an algorithm which really optimizes to death?",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 1
                },
                {
                    "sent": "And then also if we do large scale learning, what should we should be ready to and should we should be only tune like data presentation?",
                    "label": 0
                },
                {
                    "sent": "Should we select the right features and then do all the learning?",
                    "label": 0
                },
                {
                    "sent": "Or should we optimize the core algorithm?",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Now for the proposal.",
                    "label": 0
                },
                {
                    "sent": "So we're proposing to have two tricks.",
                    "label": 0
                },
                {
                    "sent": "One's called white competition.",
                    "label": 0
                },
                {
                    "sent": "So it's basically do whatever you want.",
                    "label": 0
                },
                {
                    "sent": "Just get a better result fast.",
                    "label": 0
                },
                {
                    "sent": "Another track is method specific.",
                    "label": 1
                },
                {
                    "sent": "So for now we only use.",
                    "label": 0
                },
                {
                    "sent": "We only want to evaluate also support vector machine solvers like just a linear SVM and the kernel based systems.",
                    "label": 0
                },
                {
                    "sent": "And the setup is that you get a number of datasets.",
                    "label": 0
                },
                {
                    "sent": "And different data set sizes.",
                    "label": 0
                },
                {
                    "sent": "And of course, you're given some unlabeled validation set where you can compute your outputs on and you're asked to record the training time.",
                    "label": 1
                },
                {
                    "sent": "Not only train time, but also time to compute outputs.",
                    "label": 0
                },
                {
                    "sent": "Otherwise, Kenya's neighbor would be winning the competition.",
                    "label": 0
                },
                {
                    "sent": "And you asked to give 10 intermediate points while the body optimization procedure or algorithm is running such that we can have some performance figures progress overtime.",
                    "label": 0
                },
                {
                    "sent": "Some program which calibrates hopefully calibrates an for these different machine types.",
                    "label": 0
                },
                {
                    "sent": "But at the end we will take the top ten performing methods and do a re evaluation on a single machine, so should be more fair than.",
                    "label": 1
                },
                {
                    "sent": "OK, so then of course we will provide some life life feedback for the validation set and at after the end of the competition we provide the test set and people should then compute outputs on this.",
                    "label": 1
                },
                {
                    "sent": "And it can be like many, many tricks can be involved in this, especially in this world competition.",
                    "label": 0
                },
                {
                    "sent": "So we ask you review and contributors to like explicitly identify which parts made gave big speedup.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we have a number of datasets here, which all nodes on.",
                    "label": 0
                },
                {
                    "sent": "Small scale so they are.",
                    "label": 0
                },
                {
                    "sent": "It's some data set which is some spice data set I've been working on.",
                    "label": 0
                },
                {
                    "sent": "It has only only 55 million examples and only eight like 8 gigabytes in size, so still fits in memory.",
                    "label": 0
                },
                {
                    "sent": "Then there's some some webspam based data, which is.",
                    "label": 0
                },
                {
                    "sent": "But it's this change is only about two class classification, so it's not like the structure learning you do there.",
                    "label": 0
                },
                {
                    "sent": "Then we have some face detection and some some OCR examples.",
                    "label": 0
                },
                {
                    "sent": "And some artificial data that that would have been generated on the controlled conditions.",
                    "label": 0
                },
                {
                    "sent": "To see how methods perform, for example on very sparse or dense datasets.",
                    "label": 0
                },
                {
                    "sent": "Is OK, so actually this offer this data set here seems to be larger, smaller only 500,000 examples.",
                    "label": 0
                },
                {
                    "sent": "It's actually the biggest one.",
                    "label": 0
                },
                {
                    "sent": "It's free 32 gigabyte in size.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the timeline we actually want to start this competition somewhere in in February, so if everything goes well, then like closed after the ice email deadline.",
                    "label": 0
                },
                {
                    "sent": "Then we plan to have to anti competition competition in June and then do the evaluation and hopefully we get an ICM workshop accepted such that we can meet and discuss vote results and problems and we then consider to have proceedings in lecture notes, computer science and for the best or most original.",
                    "label": 0
                },
                {
                    "sent": "Methods OK.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the evaluation criteria will be basically based on three different figures.",
                    "label": 1
                },
                {
                    "sent": "Figure out which is which plots time versus test error or objective value for the SVM trick.",
                    "label": 1
                },
                {
                    "sent": "In addition, data set size versus time and data set size versus test error, and from these figures we compute some performance measures.",
                    "label": 0
                },
                {
                    "sent": "OK, and the overall winner will be the winner, which ranks best in all of these datasets on average.",
                    "label": 0
                },
                {
                    "sent": "OK, so the figure.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Time versus test error is that one and.",
                    "label": 1
                },
                {
                    "sent": "A scalar measure we can.",
                    "label": 0
                },
                {
                    "sent": "We could use the method which achieves.",
                    "label": 0
                },
                {
                    "sent": "I mean we could rank by the minimal test error test error can be anything like the area over this precision recall curve.",
                    "label": 1
                },
                {
                    "sent": "Then then we could compute the error under this whole curve method, which is like quickly gets down to low.",
                    "label": 0
                },
                {
                    "sent": "To lower errors is of course better.",
                    "label": 0
                },
                {
                    "sent": "And then we will also have some some fixed some fixed test error and then ranked methods by the time it takes them to achieve this test error OK then.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You can do the same thing for data set size versus time.",
                    "label": 1
                },
                {
                    "sent": "It's basically it's very, very well known plot and which is often with all this product in lock lock and so you have the exponent.",
                    "label": 0
                },
                {
                    "sent": "Hope.",
                    "label": 1
                },
                {
                    "sent": "Give you an exponent in the in the polynomial, so that's we will use this as a scalar measure here.",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The last figure was data set size versus test error and there actually also.",
                    "label": 0
                },
                {
                    "sent": "You can also take the area under this under this curve.",
                    "label": 1
                },
                {
                    "sent": "So which data set can can only the few data points which which method can only have few data points learn quite well.",
                    "label": 0
                },
                {
                    "sent": "This is also seems also be quite reasonable.",
                    "label": 0
                },
                {
                    "sent": "And you can do it at the thing.",
                    "label": 0
                },
                {
                    "sent": "You can also again fix the test error.",
                    "label": 1
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And then the method which achieves this test error for the smallest data set size.",
                    "label": 0
                },
                {
                    "sent": "This will be based in this in this ranking.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "OK for for SPMS.",
                    "label": 0
                },
                {
                    "sent": "Likely adjust.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "On this criteria to to also include.",
                    "label": 0
                },
                {
                    "sent": "So we will ask people to train SVM's for a cycle given parameter set for given accuracy and see.",
                    "label": 0
                },
                {
                    "sent": "And we can figure out hopefully that what what's the difference?",
                    "label": 0
                },
                {
                    "sent": "What's the relation between objective and enter test?",
                    "label": 1
                },
                {
                    "sent": "Oh, and which of these stopping criteria?",
                    "label": 0
                },
                {
                    "sent": "There are many of them best?",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah so.",
                    "label": 0
                },
                {
                    "sent": "Yes, it's clear so far.",
                    "label": 0
                },
                {
                    "sent": "We definitely would also have to a certain RBF kernel, it's and.",
                    "label": 0
                },
                {
                    "sent": "Then in the end.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Oh of course, hope that you would want to take part in this.",
                    "label": 0
                },
                {
                    "sent": "We have some life submission system.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then.",
                    "label": 0
                },
                {
                    "sent": "To summarize, this challenge will be start in mid mid February and in June and there are these two tracks like the White competition which is for all classification methods and an SVM specific trick.",
                    "label": 0
                },
                {
                    "sent": "We have these four different real world datasets and.",
                    "label": 1
                },
                {
                    "sent": "It's artificial controlled datasets.",
                    "label": 0
                },
                {
                    "sent": "Valuation figures the relation will be based on these three different figures and scores.",
                    "label": 1
                },
                {
                    "sent": "We compute button and from them, so I hope some of you may want to take part in this change.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Huh?",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the STD question.",
                    "label": 0
                },
                {
                    "sent": "A very nice looking criteria is duality gap, because it's quite.",
                    "label": 0
                },
                {
                    "sent": "It's already the natural stuff.",
                    "label": 0
                },
                {
                    "sent": "And it's in a way much more robust than measuring a validation error which has a lot of noise.",
                    "label": 0
                },
                {
                    "sent": "Unless you have an enormous bestseller crossword.",
                    "label": 0
                },
                {
                    "sent": "Fortunately yeah, but for some methods you don't have the primary end to do it, so it's not so.",
                    "label": 0
                },
                {
                    "sent": "It doesn't have it naturally, but it's not that expensive to compute.",
                    "label": 0
                },
                {
                    "sent": "Challenge.",
                    "label": 0
                },
                {
                    "sent": "Different differences.",
                    "label": 0
                },
                {
                    "sent": "This difference of performance is less than the noise you would have been using a validation set unless the validation set is enormous.",
                    "label": 0
                },
                {
                    "sent": "It can be quite annoying.",
                    "label": 0
                },
                {
                    "sent": "You have a million.",
                    "label": 0
                },
                {
                    "sent": "We tried to do some comparisons of different approximations.",
                    "label": 0
                },
                {
                    "sent": "And there's one other point there, which is that there is there three times is that I'm too if you're learning like hyperparameters, nothing.",
                    "label": 0
                },
                {
                    "sent": "Those feature selection first time for that time to train the time to test different regimes as if those are different when the other thing is probably.",
                    "label": 0
                },
                {
                    "sent": "Look below Fishel data.",
                    "label": 0
                },
                {
                    "sent": "Better actually care that there is something to be found as you get bigger datasets, 'cause you probably designed this, but sometimes you get too noisy data set and it really asymptotes often like 1000 people until you have to be careful.",
                    "label": 0
                },
                {
                    "sent": "So OK, for these artificial datasets we took care of that we have more data, get better results here.",
                    "label": 0
                },
                {
                    "sent": "And it's not.",
                    "label": 0
                },
                {
                    "sent": "Also hopefully not so easy to figure out the underlying distributions, but you're right that it's a big.",
                    "label": 0
                },
                {
                    "sent": "It's a big problem that people with some methods like FTS disparage, which we could estimate like before hand and you don't know whether this still counts for training to training time or not.",
                    "label": 0
                },
                {
                    "sent": "Yeah, and.",
                    "label": 0
                },
                {
                    "sent": "Yeah, OK, it's really still an issue I think.",
                    "label": 0
                },
                {
                    "sent": "For what?",
                    "label": 0
                },
                {
                    "sent": "Because the biggest correction, I mean it had 55 million examples or.",
                    "label": 0
                },
                {
                    "sent": "Prediction.",
                    "label": 0
                },
                {
                    "sent": "OK, of course even bigger datasets as we see no no no.",
                    "label": 0
                },
                {
                    "sent": "But on the other hand I'm not sure whether we would find people to contribute if they have no chance to even load the data into main memory.",
                    "label": 0
                },
                {
                    "sent": "So that's the tradeoff.",
                    "label": 0
                },
                {
                    "sent": "The number of positive examples.",
                    "label": 0
                },
                {
                    "sent": "Problems where you are billions of examples but just the 2000s of positive examples, and that's pretty much it.",
                    "label": 0
                },
                {
                    "sent": "That's an easy set of these datasets.",
                    "label": 0
                },
                {
                    "sent": "Or it's not possible to see each example more than one time, yeah?",
                    "label": 0
                },
                {
                    "sent": "Streaming online malware.",
                    "label": 0
                },
                {
                    "sent": "Basically, you're forced to go to your data point.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so that's OK. Yeah, I mean.",
                    "label": 0
                },
                {
                    "sent": "Now that we didn't OK but didn't want to restrict it to just online methods, OK, I mean maybe one could do it, but there's all these SVM solvers currently are not.",
                    "label": 0
                },
                {
                    "sent": "I mean, most of them are not online.",
                    "label": 0
                },
                {
                    "sent": "And you want to have these also evaluated.",
                    "label": 0
                },
                {
                    "sent": "Of course we could again like split up like smaller datasets, and some do it.",
                    "label": 0
                },
                {
                    "sent": "Yeah, for this SVM stand differently but.",
                    "label": 0
                },
                {
                    "sent": "Hello.",
                    "label": 0
                }
            ]
        }
    }
}