{
    "id": "lpqpup5yewimkxucrffnzyyzfvgrd3ci",
    "title": "Information Geometry",
    "info": {
        "author": [
            "Sanjoy Dasgupta, Department of Computer Science and Engineering, UC San Diego"
        ],
        "published": "Feb. 25, 2007",
        "recorded": "May 2005",
        "category": [
            "Top->Mathematics->Statistics"
        ]
    },
    "url": "http://videolectures.net/mlss05us_dasgupta_ig/",
    "segmentation": [
        [
            "Going to, I'm going to give.",
            "I'm going to give a bit of an introduction to this area that some people call information geometry."
        ],
        [
            "Then just two.",
            "This is.",
            "A lot of what I'm talking about is often described as the maximum entropy principle or maximum entropy methods.",
            "And these are.",
            "These have been very successful in natural language processing and are now being used in other areas as well, like computational biology.",
            "All, I'll introduce it by by sort of a toy example.",
            "OK, there's sort of a clean toy example, so suppose you want to model the distribution of English words.",
            "OK, so for instance, you might be an alien who is just arrived on this planet, and you notice you you find this dictionary.",
            "You see that you see that there are all these words over there and you want to model the distribution over words.",
            "You want to know which ones are frequent, which ones are not frequent.",
            "So our priority, you don't know anything.",
            "You just know that there are these.",
            "You know 50,000 words or whatever, and so you know in the absence of any further knowledge, the sort of the sort of default thing you might do is to just pick the uniform distribution to just pick to just say that everything is equally likely OK.",
            "But now you can collect some samples and you notice a few things.",
            "For instance, you might notice.",
            "OK, well, you know there aren't so many words whose length.",
            "In random samples of words.",
            "Only about 30% of them have length more than five.",
            "This little observation you make.",
            "You know from these small samples that you take.",
            "You might say that OK.",
            "In a random sample, the probability of a word ending in E, the fraction of words that ends in Y is about .45 here, and you notice a few other things like this.",
            "You keep track of a few features and now the question is how do you adjust your distribution accordingly?",
            "So initially you knew nothing.",
            "You pick the uniform distribution.",
            "Now, which distribution do you pick?",
            "You've got a little bit of data, but that's all OK. What's what's the right thing to do now?",
            "So so it turns out that this particular question will this sort of this toy example."
        ],
        [
            "Will let us.",
            "Develop 3.",
            "Three sort of theories that are closely interrelated having to do with entropy, exponential families and information projection, and it will help us understand the connection between these three things.",
            "OK, so so it's a nice excuse to actually develop to sort of theoretically develop these three areas and see what the connections are between them.",
            "Oak."
        ],
        [
            "So let's start with entropy.",
            "OK, so we also focus our."
        ],
        [
            "Question, but let's try and pin down this question.",
            "Let's try and formalize it a little bit.",
            "So we have some domain which in that example was English words.",
            "OK so you know just a big list of words.",
            "You know, 50,000 words say, well, you know hundreds 100,000 words.",
            "And now from a small random sample or whatever, we didn't notice a few things and we can think of that as measuring a few features of each word.",
            "OK, so for instance, let me see if I can work this thing.",
            "So, for instance, we were measuring whether the length of a word is more than five.",
            "OK, so we had this indicator feature, which was one.",
            "If the length is more than five and zero otherwise.",
            "And we notice that the probability of this happening, the probability of the length being more than five was .3.",
            "In other words, the expectation of this feature, the expectation of T was .3.",
            "OK, so the expectation of this indicated variable is just the probability that the length is more than five.",
            "How can we notice that that was .3?",
            "We measured a few other things.",
            "For instance, we had another feature we just checked whether a word ends in E and we notice that the expectation of that feature was .5 and we had a few more things like this.",
            "OK, so we've now got a bunch of constraints.",
            "And we want to continue our previous methodology.",
            "We started knowing nothing and we just picked a uniform distribution over all the words.",
            "Now we know a few things.",
            "And we still want to, you know.",
            "So we want to model these.",
            "We want it to be the case that the new distribution we pick does satisfy these things that we've observed.",
            "But other than, that assumes nothing.",
            "So other than that is as random as possible.",
            "OK, So what is the sort of?",
            "What is the one?",
            "What is the single distribution of?",
            "Or maybe there's not?",
            "Maybe it's not unique, but what is the distribution that satisfies these constraints but otherwise makes no assumptions?",
            "OK or otherwise, is as random as possible, so by the way, stop me at anytime if there if there any questions at all.",
            "OK.",
            "So.",
            "So in order to do this."
        ],
        [
            "So we formalized a lot of it.",
            "We formalized what are constraints are.",
            "We want a distribution that satisfies certain expected value constraints.",
            "The next thing we have to formalize, the only thing we really need to pin down now, is what do I mean by random?",
            "When I say distribution, that's as random as possible.",
            "OK, So what is the randomness in the distribution?",
            "What's the randomness content of a distribution?",
            "So, so how?",
            "How would we define randomness?",
            "This seems like something that you know there's going to be a lot of disagreement about this.",
            "There must be lots of ways to define randomness, you know so so.",
            "So how would we go about it?",
            "So intuitively, let's let's think of some things that we would like to be true of.",
            "Any reasonable definition of randomness.",
            "OK, so for instance, it's natural to think of a fair coin as having one bit of randomness.",
            "OK, the outcome is either a zero or a one.",
            "The equally likely.",
            "It's very natural to think of that as being one bit of randomness.",
            "OK, what if a coin is biased, but if a coin is biased?",
            "If it's more likely to, say turn up heads, then it's less random.",
            "So if we've said that a fair coin is 1 bit of randomness, then a biased coin.",
            "Its randomness contents should be strictly less than one.",
            "OK, so that's something we would like to be true.",
            "What about two independent fair coins?",
            "So now this is 2 bits of randomness.",
            "OK, because they are independent of each other.",
            "They each contain separate amount of information.",
            "If one one of them is 1 bit, two of them should should be 2 bits.",
            "What if the fair coins are dependent?",
            "OK, so the outcome of the second coin depends on the first coin well, then the overall randomness is less than two bits.",
            "OK, for instance, the second coin might be exactly equal to the first coin, in which case there's just one bit of randomness in them.",
            "OK. And here's another thing we'd like to be true.",
            "Sort of extending these things.",
            "Suppose we have a uniform distribution over 32 possible outcomes.",
            "Well, this is something we can code in five bits, each of which is equally plausible.",
            "OK, so so we would like this we you know we would like to say that this has five bits of randomness.",
            "So so these are some, some of the sort of intuitive things that we would like to measure of randomness to capture.",
            "But just putting down a few things like this, there's gotta be a million ways to define randomness, right?",
            "So, so there's one.",
            "However, that seems to be real."
        ],
        [
            "The popular OK.",
            "There's one that sort of.",
            "There's one that everyone seems to use, and it's called the entropy.",
            "So suppose you have a discrete distribution X axis, some random variable which takes on discrete values, and it's got a distribution P. Then the entropy of it is this weird thing.",
            "OK, it's the sum over all possibilities of X of P of X log 1 / P of X. OK, which is expectation with respect to another way to write in just the expectation with respect to random draws from P of log 1 / P of X. OK.",
            "So this is the definition that people seem to use and just looking at it, it looks a little crazy.",
            "You know what do you know?",
            "How can this be the natural notion of randomness?",
            "P log 1 / P X.",
            "What is this thing right?",
            "So so.",
            "So let's first check that it isn't totally crazy.",
            "OK, let's just plug in a few examples and see that it's actually doing the right thing.",
            "In at least you know at least some toy cases.",
            "So for instance, if we look at a fair coin.",
            "Then there are two possible outcomes, each with probability 1/2.",
            "So the entropy is 1/2 log 2 + 1/2 log 2.",
            "Which is one.",
            "OK, so that's something we wanted that the entropy of a fair coin is 1.",
            "Now suppose we have a coin with a bias of 3/4, so then we get 3/4 log 4 thirds.",
            "Plus 1/4, which is the other outcome.",
            "Log 4 and that turns out to be less than one.",
            "It turns out to be .8 one.",
            "OK, so again, this is this is this is what we expected.",
            "Now we knew it should be less than one.",
            "We didn't know how much less than one, but .81 sure, whatever.",
            "OK, that's that's plausable.",
            "What about a coin with bias .99?",
            "Now this is a coin that's almost not random at all.",
            "It's a coin that you know is is almost deterministic, so we would expect that the randomness content of this is something that should be very small.",
            "So let's plug it in.",
            "It should certainly be smaller than the coin with by 3/4, so let's plug in .99, we get .99 log 1 / .99 and we plug it in and it becomes .08.",
            "OK, so that's good.",
            "It's close to 0, which is what we would want, and it's much less than these two numbers.",
            "OK, and finally, let's check a uniform distribution of a key outcomes.",
            "If it's a uniform distribution, all these probabilities are 1 / K, so we get 1 / K log K, and now we submit over K things.",
            "So the answer is log K. OK, so in this basic cases this is doing the right thing.",
            "Now.",
            "I mean qualitatively it's doing the right thing.",
            "We know that this should be smaller than one and we know point it should be the smallest of all in.",
            "That should be fairly close to 0, so qualitatively is doing the right thing.",
            "But again, you know, I'm sure I could cook up, you know, hundreds of other measures that also qualitatively do the right thing on these examples.",
            "OK, so what's special about this one?",
            "So let's take a closer located at least it's past the first round of tests and you know and let's and let's get a little more of a sense of what it's like.",
            "So first of all."
        ],
        [
            "Thing is concave.",
            "OK so if you if you actually just draw the graph of it.",
            "This is for a case of a coin with bias P. It's a concave thing, it's maximized when the coin is exactly a fair coin, at which point the entropy is one OK.",
            "If the coin is totally deterministic, if it's always heads or it's always tails, then the entropy is 0, which is what we'd expect.",
            "There's no randomness at all, and it's symmetric.",
            "A coin with bias 3/4 is the same as a coin with biased 1/4 in terms of its randomness content.",
            "OK, so this is perfectly reasonable.",
            "In that sense, it's fine.",
            "So let's look at."
        ],
        [
            "Some of the let's look at some of the nice properties that this thing is got.",
            "OK, so so so so.",
            "So what are the intuitive properties that this thing has?",
            "So first of all, entropy is got expansibility.",
            "OK, so for instance, suppose I have a distribution which has N possible outcomes with these with some probabilities P1 through PN.",
            "Now I can I add another fake outcome that never occurs.",
            "OK, so the end outcomes and they have some probabilities and now I just tack on another fake outcome, which is never happens.",
            "That clearly should not change the entropy, and that's true.",
            "The entropy remains the same in that's in that situation.",
            "OK.",
            "It's got this property of symmetry.",
            "Which is that?",
            "That if you have a distribution which if you just permute the labels of the points, then then the entropy doesn't change, right and.",
            "Is this so?",
            "That's Elvis Presley.",
            "So.",
            "So.",
            "So right so?",
            "So this is clear, right?",
            "So so the the the notion of randomness should not be sensitive to the names you actually give things.",
            "OK if you change you flip heads and tails, randomness should not change, and that's the property of symmetry.",
            "It's also got this property of additivity, and this is a very useful thing.",
            "OK, so if you have two independent random variables, then the entropy of them taken together is the sum of the individual entropies.",
            "And let's see why."
        ],
        [
            "This is the case.",
            "OK so I have these two things that are independent and now I want to look at their joint entropy.",
            "The sum of them taken together.",
            "Well, that's the sum over all possible outcomes.",
            "X&Y.",
            "Just plug into the definition P of X, log 101 / P of XY.",
            "But in this case, because of independence, P of XY is P of X * P of life.",
            "Anso and because it's a log, I can split this into its two pieces.",
            "Log 1 / P of X plus log 1 / P of Y.",
            "So I get these two individual summations.",
            "And I can now some out the Y and in this case I can send out the X. OK, so I get the the individual entropy of X plus the individual entropy of Y.",
            "Great so so this is another place another of the properties we wanted.",
            "No."
        ],
        [
            "What is the variables are not independent?",
            "In that case we wanted to be the case that the entropy of the joint distribution is at most is is it moves the sum of the individual entropies.",
            "OK, so we wanted so, and that's called subadditivity.",
            "OK so if they are independent then the entropy of the joint is just the sum of the individual entropies.",
            "If they're dependent then it's going to be less than that, and that's another.",
            "That's another good property that it's got.",
            "We've normalized it so that a fair coin has entropy.",
            "One, OK, you could just scale it by an arbitrary constant.",
            "A reasonable normalization is just to say fair coin is entropy one.",
            "And finally we want it to be the case that as as the bias of a coin goes to zero, the entropy also goes to zero.",
            "OK, so as it becomes more deterministic, the entropy goes to zero and it also has that property.",
            "So it's got these six properties that we think you know that intuitively should be true of any measure of randomness.",
            "But now it turns out that entropy is the only measure that satisfies these.",
            "OK, so if you proceed in an axiomatic way, if you say look, I want to, I want to come up with a measure of randomness.",
            "And now let me put down a few properties that any measure of randomness should have all very reasonable sounding properties.",
            "OK, what would they expansibility?",
            "That's totally reasonable.",
            "If you add on a fake new sample, if you add on a fake new.",
            "Outcome that never occurs.",
            "Sure, that should not change the entropy, symmetry, additivity, subadditivity, normalization.",
            "These are very, you know these are.",
            "These are things that you know we would think.",
            "Of course this should be true of a measure of randomness, but entropy is the only one that satisfies all of them OK, and so this justifies why we why we use something with that weird functional form.",
            "You know P log 1 / P. It seems a little crazy at first, but This is why we're stuck with it.",
            "OK, and This is why we have to deal with the thing.",
            "OK, so let's look at some other.",
            "Let's look at some other properties of this measure.",
            "First of all, it's cool."
        ],
        [
            "Mostly related to the KL divergent, so so some of you might already know this distance measure.",
            "It's a very commonly used distance measure between probability distributions.",
            "OK, so suppose I have two probability distributions P&Q and I want to measure the distance between them.",
            "Now the many ways one could do it, one could look one could for instance draw the curves to P&Q and look at the area between the curves.",
            "That's a very intuitive way to do it, and that's L1 distance OK, one could look at the L2 distance between them.",
            "Or one could for some reason plug it into this formula.",
            "That looks a lot more weird than any of those other two possibilities.",
            "And it turns out that this is something that is very widely used in statistics.",
            "OK, So what are the features of this?",
            "What are the properties of this?",
            "Well, first of all it has many.",
            "It has many unpleasant aspects to it.",
            "OK, so first of all, it's not symmetric.",
            "The distance from P to Q is not the same as the distance from Q to P. Not at all a desirable thing.",
            "This thing could easily be infinite if it's the case that Q is zero at a point where P is non zero, then this whole thing becomes infinite.",
            "OK, so so already there are many reasons not to like it, but at least it's the case that.",
            "It's always positive and it's zero only if P&Q are equal.",
            "OK, so so this turns.",
            "This distribution turns out to be.",
            "Very useful in many contexts, like entropy when you're dealing with the product distribution.",
            "These the product in here the log and the product interact very nicely and so when you're dealing with product distribution, systems are to be a very convenient functional form.",
            "OK, in the same way as we saw the additivity property for entropy OK, and also this is closely related to maximum likelihood.",
            "If you have a bunch of data and you have some some parameterized models and you want to pick the maximum likelihood model, picking the maximum likelihood model is the same as picking the model that has the smallest KL divergent to the empirical distribution.",
            "That's the distribution where you just take your data points and assign them all the same way OK.",
            "So, so this is so, how is this thing related to entropy?",
            "To do that?"
        ],
        [
            "We look at the two to see how the KL Divergent is related to the entropy of a distribution P. So let's say a random variable X has distribution P. Let's look at the kill Divergent from P to the uniform distribution.",
            "OK, so that's just plugging into the formula for KL divergent.",
            "That's P log P over the uniform distribution.",
            "Uniform is just one over S everywhere.",
            "OK, so there are there as possible outcomes.",
            "And so.",
            "And again, the log decomposes nicely and we get P log P + P log S. OK, in other words, logs minus minus the entropy of X.",
            "So what this means is the entropy is really telling us the distance from the uniform distribution measured according to this distance measure, the KL divergent and and just this one formula tells us many things.",
            "For instance, it tells us we know that the KL divergences always positive.",
            "So this tells us that the entropy can never be more than logs.",
            "This is an upper bound on the entropy.",
            "It tells us that the maximum entropy distribution we know the most the entropy can be as log as.",
            "And when is the entropy log?",
            "Yes, when we're looking at a uniform distribution over S outcomes.",
            "So the distribution that maximizes the entropy is just the uniform distribution over all of these outcomes.",
            "So, so any questions about about this sort of thing?",
            "OK."
        ],
        [
            "So let's look at one more justification of entropy and then apply it to our problem.",
            "So so to understand this.",
            "Maybe the maybe the way to say it is that when you have a distribution and you take 1 sample from it, there's so much still plasticity in what your output could be.",
            "You know if you have a, if it's a distribution over coins in the coin is biased .75 it could either be zero or one you know there's a lot of randomness in what the output could be.",
            "It's not so, so one way to make it one way to come to to reduce the level of Stochastic City is to draw many samples.",
            "That's when you get a more accurate picture.",
            "That's how you reduce the stochastic city in.",
            "And what you're seeing?",
            "OK, so suppose we draw.",
            "Suppose we have a bunch of draws from some distribution, so X One X2, XN are IID draws from some distribution P OK, and now we've drawn a lot of them, and so we can look at the sequence is that we get.",
            "So if these are coin flips, we just have these sequences 000111, etc.",
            "OK, just long sequences of zeros and ones.",
            "So now let's look at these sequences and just put them into two groups.",
            "We just pick out the sequences whose probability is roughly 2 to the minus.",
            "This OK according to our distribution and all other sequences.",
            "And it turns out that most of the sequences that we observe are going to have roughly the same probability.",
            "OK.",
            "This is called the asymptotic equipartition property.",
            "So what this is saying is that if you look at the space of all."
        ],
        [
            "Sequences that you can possibly generate.",
            "OK, so in the case of a coin would say bias.",
            "3/4 OK, this is all two to the N sequences.",
            "These are the sequence.",
            "These are all the sequences of zeros and ones you can get.",
            "You can possibly generate.",
            "There are just a few of them that are typical.",
            "And these are the sequences whose probability is about 2 to the minus N times the entropy of one of those random variables.",
            "OK, in this case, the entropy of a coin with whatever bias I said, I think .6 or .75.",
            "OK, so although there's a large space of possible outcomes, there is actually a typical set.",
            "And when you draw a large number of sequences, although you know if it's so, when you draw a large number of points, although the distribution of any one point is really stochastic, when you draw a large number of points and look at the sequence is, it's a little bit like a uniform distribution over about two to the NH outcomes.",
            "OK, so the distribution looks.",
            "It's almost like a flat distribution over a smaller set of outcomes.",
            "OK, so instead of two to the N outcomes, two to the N times the entropy which is going to be at most one in the case of a coin flip.",
            "OK, so in this sense the entropy tells us the volume of this typical set.",
            "This typical set has volume to to the N times entropy.",
            "OK, so let's look at some examples of this right."
        ],
        [
            "So for instance, a fair coin.",
            "If we draw N, if we draw N samples from a fair coin and we look at the sequences we get, well then we just have a uniform distribution over all possible outcomes.",
            "OK, so in that case we just occupy this whole space.",
            "All possible outcomes are about equally likely, and each of them has the entropy is 1 in that case, and each of them has probability two to the minus N. OK, so the and the number of outcomes is 2 to the end.",
            "Now let's look at the boy biased coin.",
            "Suppose we look at a coin with bias 3/4.",
            "In this case, when you draw a lot of them, when you draw a lot of when you flip a lot of coins, you're going to find that in the end, about 3/4 of them are heads.",
            "OK, so the typical probability of a sequence like this is going to be about 3/4.",
            "3/4 of the three quarter end of the of the coin tosses are going to be heads and the remaining ones are going to be tailed.",
            "OK. And this is the typical probability most of the sequences will conform to this.",
            "And when you look at the log of this, you find that in fact it is minus 10 times the entropy of 1/4.",
            "So this typical sequence does have probability two to the minus 10 times the entropy.",
            "Again in that case, the typical set is much smaller.",
            "OK, although the two to the end possible outcomes, the typical set is of size just two to the end times the entropy of of 3/4, which is .81.",
            "So, so why is this thing true?",
            "Why is this property true?",
            "OK, so so we've drawn.",
            "We've drawn in samples from some distribution P. OK."
        ],
        [
            "These are IID samples.",
            "Let's define a new random variable Y survive.",
            "And let's define it to be log 1 / P of exhibi.",
            "OK, so this is a random variable.",
            "You the way you do it is in the case of coin tosses, you flip a coin.",
            "You look at the outcome heads or tails, and if it's heads it's log one over the probability of heads.",
            "If it steals it's one over log which log one over the probability of tails.",
            "Now, one way we defined entropy was just as the expectation of this quantity.",
            "OK, so the expectation of Y is just H. So we generate.",
            "We generate all these samples XI, which for each sample we've defined a new random variable Yi and the expectation of Y is just the entropy.",
            "Now by the law of large numbers, we know that if we generate a lot of samples.",
            "Then then this average must converge to its expected value.",
            "OK, so when you generate a lot of samples, the sum of the yiz is going to look very close to age.",
            "What does that mean?",
            "Well, if this sum of the yiz is within epsilon of age.",
            "OK. OK, this so this event is going to happen with probability one.",
            "As you increase the number of points OK. Well, the sum of the wise has a very nice form.",
            "The sum of the wise is just the log.",
            "This log of probability of X1 plus log probability of X2 plus log probability of X3.",
            "Therefore it's just the log one over probability of the entire sequence.",
            "OK, since the points are drawn independently.",
            "And therefore what this tells us is that the probability you are off this particular sequence is going to lie within within epsilon of what we were calling the typical probability it's going to lie within two to the minus N. H minus epsilon in two to the minus H plus epsilon.",
            "OK, so this is this is another way in which this in which entropy turns out to be very natural.",
            "In which entropy turns out to be a natural notion of randomness.",
            "OK, so let's return to our main question and see now that we have a notion of randomness, we can actually."
        ],
        [
            "Try to formalize this question a little bit.",
            "OK, so we had a large set which in this toy example was just English words.",
            "We measured a bunch of features for each word.",
            "OK, so for each word we define sacai features.",
            "The first feature was just that the word has length more than five.",
            "Now we wanted to find a distribution over over S and we wanted to find an assignment of probabilities to all the words.",
            "That satisfied the constraints we'd observed.",
            "OK, we observe that you know 30% of the words have length more than five, so that satisfies these particular constraints, but otherwise is is as random as possible, and now we can formalize that.",
            "We can say that what we want is something that has maximum entropy subject to these constraints.",
            "OK, and this is called the maximum entropy principle.",
            "So now that we actually know a notion of entropy, we can actually formalize this as an optimization problem.",
            "OK, let's see what the problem looks like.",
            "So we're looking for."
        ],
        [
            "Probability distribution P. It's over a set S which is English words.",
            "OK, we can think of this.",
            "Probability distribution is just a really long vector.",
            "OK, so if the 50,000 words it's just a vector with 50,000 entries, which are all probabilities, and so they're all you know greater than or equal to 0, and they add up to one.",
            "OK, so we have this that we have this vector.",
            "It's entries apiece of X, that's the probability of X.",
            "We want them to add up to one, and we want them all to be positive.",
            "OK, so a reasonable probability distribution.",
            "We want to find the thing that has maximum entropy subject to the constraints we observed and the constraints were that the expected values of these features had certain had certain were equal to something.",
            "OK, so for instance, feature one that's I = 1.",
            "Was simply one if the word had length more than five and zero otherwise.",
            "And we wanted it to be the case that the expected value of that feature, the average value of that feature according to this distribution, was .3.",
            "OK.",
            "So so many questions about this this optimization problem.",
            "Now that we have a notion of entropy, we have another way of notion of randomness.",
            "We can write it down precisely.",
            "So the nice thing about this is that the constraints turn out to be linear.",
            "The thing that we're solving for is P. OK, we're solving for this vector.",
            "These are linear constraints.",
            "This is this is just a linear equation over here, so we have a bunch of linear constraints.",
            "These define some sort of polyhedron, and the function we are optimizing is a concave function.",
            "So this entire thing becomes a convex optimization problem, OK?",
            "So convex optimization problem is just a generic is a generic term, which I mean even you know you might say OK with this.",
            "Shouldn't this be a concave optimization problem?",
            "Well, you know maximizing a concave thing is the same as minimizing the negative of it, which is a convex thing.",
            "So we just call all of these things convex optimization problems.",
            "This is the.",
            "This is just the list of words in the dictionary.",
            "OK, so if there's 50,000 of them, it's just the size of S is just 50,000.",
            "OK, so this is the thing we now want to solve.",
            "OK, now this was in the case where I had no prior knowledge at all.",
            "OK, this was the alien who just arrived on Earth and you know, just had this dictionary with him.",
            "Saw the list of words and now wants to fit a distribution to this to this list of words.",
            "OK, what if I had a little bit of prior knowledge?",
            "Maybe I have already constructed some statistical model that you know I'm reasonably happy with, but you know, I looked at the model and I looked at this new data I have and it doesn't really fit.",
            "So I kind of want, you know, I kind of want to stick with that model, but I also want to tweak it.",
            "To accommodate this new data right, what happens in that case?",
            "So in that case we have a prior Pi which is the previous statistical."
        ],
        [
            "Model that you know we just cooked up in some way or the other.",
            "And now what we want to do to know what we want to do is to find something that's close to Pi.",
            "We don't want to go too far away from it, so we want to find something that's close to \u03c0 and yet satisfies these constraints that we've observed.",
            "OK, so in other words, we want to find the distribution P that has the smallest KL divergent dippie.",
            "Subject to these constraints.",
            "OK, subject to be of course has to be a normal probability distribution and it should satisfy the constraints that I've actually observed.",
            "OK about lengths of words etc etc.",
            "Probabilities are different letter combinations.",
            "This is also a convex optimization problem because this function is convex.",
            "OK, so I'm minimizing a convex function over a bunch of linear constraints.",
            "So one nice way to visualize the problem is to see it."
        ],
        [
            "The projection OK.",
            "So think of this whole board as being the simplex of probability distributions.",
            "OK, So what is the simplex of probability distributions?",
            "It's all valid vectors.",
            "Yeah, I'm looking at vectors of length 50,000.",
            "Look at the set of all valid vectors.",
            "In other words, all vectors of length 50,000 that add up to one and a non negative.",
            "Let's call that the whole board.",
            "OK. Now I have some vector over here which is my prior distribution by OK I have some new constraints and because they are linear constraints.",
            "They define a linear subspace of the simplex.",
            "OK, so they define a linear subspace of this starting 50,000 dimensional space that I have, and what I want to do is to project the prior onto that linear subspace.",
            "OK, so I want to find the point on that linear subspace that's as close as possible to the prior.",
            "Now, if the distance measure I was using was just Euclidean distance, then I would just kind of drop this point onto the subspace at a right angle, but it's not.",
            "I'm using this weird, you know, KL divergent thing and so I get kind of a curve distance instead.",
            "OK, it's a different distance measure.",
            "You can't just pump it down, you can just plunk it down onto the.",
            "Until the subspace OK, so this is geometrically the problem we're trying to solve.",
            "We have our previous statistical model.",
            "Our constraints define a linear subspace in the space of probability distributions in the probability simplex, and I want to project onto that subspace.",
            "Why is Euclidean distance?",
            "Hello, you could use the Euclidean distance, but we also we saw that the entropy is the is the most.",
            "This.",
            "In an axiomatic framework, the entropy was the only reasonable definition of randomness, and so once we are using the entropy, then we have to use this.",
            "OK.",
            "So if we if, for instance, our prior was the uniform distribution, what we would want is the maximum entropy distribution in this subspace, and that would be the KL distance to the uniform.",
            "OK, so axiomatic framework has constrained doubts in that sense.",
            "Great, so this is our problem and we saw that.",
            "So this is what the problem looks like geometrically and we saw that when you actually write it out in terms of the equations, it turns out to be a convex optimization problem and that is really useful.",
            "OK, so why does it help to have a convex thing?",
            "Well, one OK on the most naive level you know it's convex.",
            "It looks like this, which means that there's no local Optima.",
            "You know you have this global solution, but that's just the tip of the iceberg.",
            "The real thing is not just that you have that that global solution you have to worry about local Optima.",
            "But it's that once it's expressed as a convex optimization problem.",
            "You can just apply some standard kind of deterministic machinery to characterize the form of the solution.",
            "OK, so it's not just that we know that there's a unique solution and is the global optimum, but it's that because it's convex we can use various tricks to actually show that the solution has a very specific form.",
            "It's very easy to find out the form of the solution.",
            "OK, so let's see how we do that."
        ],
        [
            "So here's the problem.",
            "We're trying to solve.",
            "We're looking at all non negative vectors.",
            "We're minimizing the KL divergences from \u03c0.",
            "We have these linear constraints.",
            "There has to be a probability thing it has to sum up to one.",
            "OK, so let's just apply the method of LaGrange multipliers.",
            "So we're minimizing this quantity.",
            "That's the KL divergent.",
            "We include a LaGrange multiplier for each for each of these.",
            "Constraints and we have a multiplier for this constraint as well.",
            "So we have a total of K + 1 multipliers.",
            "And now we take the derivative.",
            "So we take the derivative of this thing with respect to the thing we're solving for piece of X.",
            "So we actually solving for a whole vector, so we take the derivative with respect to one component at a time.",
            "OK, when the smoke clears, this is what the derivative turns out to be.",
            "You have to set the derivative to zero, and when you do that you find that the distribution has a very specific form.",
            "OK, now you can apply the law.",
            "You can do this LaGrange multiplier thing anytime you like, even when there are lots of local Optima.",
            "But in the case of a convex optimization problem, you know that the solution has to have this form OK, so.",
            "So, so here's the form.",
            "It's the prior distribution that we started with.",
            "OK times.",
            "E to the linear function of the features OK. And then there's some normalizer in front because although this as summed up to one once you multiply by this thing, who knows it is going to sum up to one anymore.",
            "OK, so you take your prior and you multiply it by this thing.",
            "And it turns out that this is actually a very.",
            "This is this is a very very common type of distribution and it's called an exponential family.",
            "This would be called the exponential family generated by Phi.",
            "OK, so the maximum entropy.",
            "The maximum entropy principle has brought us to the exponential family of distributions OK and and.",
            "And so, let's let let's look more at exponential family.",
            "But first let's just peek at what the what the form of our particular."
        ],
        [
            "Problem with the form of the solution was for our particular problem.",
            "OK, so we have this toy problem and now when we look at this solution what it's saying is that it looks like there's some normalization factor.",
            "So I'm just saying proportional.",
            "But otherwise it has a very simple form.",
            "It's just he to the sum linear function of the features.",
            "OK, and this is just really convenient because our priority, we had no idea that the solution was going to be so convenient after all we were solving for a general vector of length 50,000.",
            "It could have been that the solution would require us to write it down as a table with a different number for each particular word, but instead we got this solution that has this amazingly convenient functional form.",
            "It's something that we can express very compactly, and it's something that we can even you know, we might even be able to understand.",
            "OK, so it's a linear function of the features.",
            "OK, So what do these things mean?",
            "What do these these coefficients, which as we've seen, actually LaGrange multipliers?",
            "What do these things mean?",
            "Well, for instance, if Lambda two is .81.",
            "This means that.",
            "If the word ends in E, then you Jack up its probability by a factor of E to the .8 one.",
            "2.25.",
            "OK, so this is the sort of interpretation of these LaGrange multipliers.",
            "OK, great.",
            "So.",
            "OK, so we formulated this maximum entropy problem an you know this worked out very well for us because it gave us a distribution that now has this very convenient functional form.",
            "OK, and I said that that actually the maximum that the."
        ],
        [
            "Solution to this problem in general was just an exponential family.",
            "So what are these exponential families?",
            "What is this thing exponential family of distributions?",
            "OK.",
            "So it turns out that if you look at the statisticians grab bag of distributions, you know the distribution that pop up everywhere."
        ],
        [
            "The Gaussian is all over the place because the central limit theorem for soil is all over the place because of the law of small numbers.",
            "Binomial, the Bernoulli distribution.",
            "That was the you know that the 1st and most basic distribution you know just straight from the gambling tables, right?",
            "So all of these distributions turn out to be exponential families OK, and what one would say is 1 would say that the Gaussian is an exponential family of distributions, each of them is a whole family of distributions.",
            "It's an exponential family.",
            "So what is this thing?",
            "What is this exponential family?",
            "How exactly is it defined, and what is it by us to think of?",
            "What is it by us to look at things in this generality in the generality of exponential families?",
            "So let's define an exponential family in order to define.",
            "In order to do this, you need three things.",
            "First you start off with some input space OK. Then you have some sort of base measure.",
            "On the space which you can think of as a prior OK.",
            "So actually I have a little I have.",
            "This is actually a typo.",
            "You don't actually need the input space to be part of.",
            "Of RR is just an arbitrary input space.",
            "It's just that the base measure would then have to be on this input space OK, and So what is the base measure?",
            "Well, you can think of it like the prior, but in general for the time being you can just think of the base measure as being one.",
            "OK, so you need an input space.",
            "You need a base measure, which let's just think of as being one, and now you need to choose a bunch of features and once you specify these three things, you have an exponential family.",
            "OK, So what do these things look like?",
            "Well, the exponential family generated by this particular base measure, and this particular choice of features.",
            "Just consists of distributions of this form distributions where the probability of X is proportional to whatever the base measure is.",
            "Times E to the linear function of the of the features.",
            "OK.",
            "So each of these distributions is parameterized by a K dimensional vector.",
            "Pair these with this key K dimensional vector specifies the linear combination of the features that goes into this exponent.",
            "Great so.",
            "OK, so as it stands this is looking.",
            "You know this is not even normalized.",
            "I haven't even, you know it's right now, it's just a proportion, right?",
            "So what do we do?",
            "We at least."
        ],
        [
            "To normalize it, right so we have this input space, we've got a base measure.",
            "We've got our features and we're saying that we're going to look at distributions of this form.",
            "OK, so to normalize it we have to stick some normalization constant in the front.",
            "OK, this normalization constant is going to be a different number for every eight.",
            "Are each ETA is a different parameter.",
            "And it defines a different distribution.",
            "So for each one there's a different normalization.",
            "It turns out that the way we usually write this is actually to put the normalization in the exponent.",
            "So instead of writing it right in front over there, we pull it into the exponent, which is no problem at all, and we write it over here.",
            "OK, so this G is the normalization tool.",
            "So the G is set so that it's just the.",
            "So that everything comes out to one, so it's just whatever we had.",
            "Otherwise we just sum it up.",
            "OK, so the normalization would just be the sum of all these things.",
            "That's what G is.",
            "And since we moved it into the exponent, we have to take the log of it.",
            "And this thing is called the log partition function.",
            "Now this thing is going to assume sort of larger significance later on.",
            "As it stands, it seems like this G is no big deal, right?",
            "It's just.",
            "With just some number we gotta stick in front to normalize the thing.",
            "OK, but but it turns out that this is going to have many interesting properties Now this some might not even exist.",
            "It might be that this is infinite, in which case we can't allow that particular value of ater.",
            "So the natural parameter space is the set of eight's for which you can actually, which can actually normalizable.",
            "OK, which actually correspond to valid distributions, so that's a natural parameter space.",
            "So let's look at an example."
        ],
        [
            "So I said for for to find an exponential family you know you start with three things and that uniquely defines the family.",
            "OK, so let's look at.",
            "Suppose I was claiming Bernoulli is an exponential family.",
            "So one of the three things we need, we need the base set, which we know is 01.",
            "The base measure 1.",
            "And we have some flexibility in the choice of features, but since it's just zero and one there are only the only feature that it makes sense to choose is T of X = X, you can throw in other stuff like X, ^2, X cube.",
            "But it's not giving you any extra information.",
            "OK, and once we've chosen these things, the exponential family is uniquely defined.",
            "OK, after this, everything set it's deterministic.",
            "So we set these things down.",
            "And now let's look at the exponential family.",
            "We get.",
            "Well, we know the functional form is going to be that we're going to have these distributions indexed by ETA.",
            "And the probability is going to be proportional to each of the 8X.",
            "OK, so now we need this thing to normalize so well X has only two values, zero and one.",
            "So we get E to the 0 plus each of the ETA.",
            "So a normalization factor is just the lawn of this.",
            "The natural logarithm of this and this is the log partition function.",
            "Any questions about this?",
            "Great.",
            "So this turns out to be defined for all eighters because we never have to worry about this being infinite and therefore the natural parameter space is simply the reals.",
            "So let's look at the distribution.",
            "Since the parameter space in the reals, let's look at the distribution we get when we have parameter ETA.",
            "OK, when we have A to, the distribution looks like this, it's each of the 8X and we have to multiply by the normalization constant, which is this.",
            "OK, in other words, the probability of a .0 is just one over the normalizer.",
            "The probability of one is each of the H over the normalizer.",
            "Certainly a bona fide Bernoulli distribution OK?",
            "So the only problem over here is that although this is a Bernoulli distribution, we're not used to these parameters.",
            "Normally when we specify a Bernoulli, we specified according to the heads probability.",
            "Now we have this weird formalization in which it's specified according to this so called natural parameter that's actually a number between minus Infinity and plus Infinity.",
            "So what's the deal over here?",
            "You know?",
            "So, so there's this natural parameter, and certainly it specifies all the Bernoulli's.",
            "Any Bernoulli distribution can be written this way.",
            "If you want this to be your probability P, you just solve the ETA.",
            "That's no problem at all.",
            "But the parameterisation is not the one we're accustomed to.",
            "We're accustomed to parameterising this between zero and one, not between minus Infinity and plus Infinity.",
            "OK, and so."
        ],
        [
            "If you look at the, if you look at the the thing over here.",
            "The natural parameters line the range from minus Infinity to plus Infinity and minus Infinity corresponds to a coin with bias 0 plus Infinity corresponds to a coin with bias one.",
            "And there's this mapping from these natural parameters to the.",
            "To this.",
            "To this parameters we're more used to the actual bias of the coin.",
            "So so the weird thing about these natural parameters is that although they're the ones that are mathematically natural, they don't actually necessarily correspond to the parameters that are natural for us.",
            "So we end up having these two different parameter spaces when we talk about exponential families, we have the natural parameters, which is the space of the models themselves.",
            "One this is the one that the math wants.",
            "And then this is the one that's more convenient for us.",
            "These are the expectation parameters.",
            "These are the actual mean of the distribution.",
            "OK, so in exponential families we always juggling these two spaces, and there's a one to one map between them, and you can see this particular map over here.",
            "Let's look at another example."
        ],
        [
            "Which will derive in a different way.",
            "OK, so now let's look at Apostle and distribution.",
            "Now Apostle Theater Distribution is a distribution over integers or a distribution over non negative integers and it has mean theater and variance data as well.",
            "It's got the same mean and variance and this is the functional form of the distribution.",
            "The probability of any given X, which in this case is a non negative integer is each of the minus theater translator to be X / X factorial.",
            "So why is this an exponential family?",
            "OK, in order to show that we kind of have to massage it into the right form.",
            "So let's try and rewrite it.",
            "Well, you can write it like this data to the X is Y to the excellent ETA we get the minus, Theta and now it looks much more like an exponential family form.",
            "This is the base measure will be here.",
            "The HX.",
            "This looks like we have.",
            "This is just some linear function of X, which is exactly the form we wanted.",
            "OK.",
            "So so so.",
            "So now our base base is the non negative integers are based measure is just 1 / X factorial.",
            "And our feature is just X itself.",
            "We just need a single feature.",
            "So now when we find the log partition function.",
            "Well, so once once we've specified these three things, we know the rest is deterministic.",
            "We know that the functional form must be this.",
            "And to find the log partition function we just normalize, we just sum, we just sum this over all possibilities.",
            "OK, well this is quite an easy sumby cause because it looks like the Taylor series for each of the.",
            "The Taylor series expansion of the exponential, so it's just each of the ETA.",
            "The log partition function is just each of the ETA, and once again we don't have the natural parameters.",
            "OK, well once again our natural parameters are not.",
            "The ones are not the ones we are familiar with.",
            "The natural parameter space occupies the entire real line.",
            "And the ones we are interested in are actually each of the natural parameter.",
            "OK.",
            "So in this case, the natural parameter is long of Theta.",
            "OK. Let's do."
        ],
        [
            "One more example, and this one's a little trickier because the we need more than one feature.",
            "OK, so we have a Gaussian with mean mu and variance Sigma squared.",
            "So this is the form of the Gaussian, and now we want to write this as an exponential family.",
            "As an exponential family distribution.",
            "If you expand out the square, you end up with terms both in X&X squared, so you need to pick.",
            "You need to pick two features.",
            "X has to be a feature, and X squared also has to be a feature.",
            "And if you pick both of these then you can write the exponent as a linear function.",
            "OK, so in this case our base set is just R based measures.",
            "You know, for convenience I set it to 1 / 2\u03c0.",
            "I could just make it uniform constants don't matter.",
            "And I need to pick two features now for this is not sufficient to just pick one feature, so I pick X and X ^2.",
            "And now just from this I can read off what the natural parameter is going to be.",
            "And once again, we can compute the log partition function, and in this case the natural parameter space is R * R minus.",
            "OK.",
            "So so fine.",
            "So there are a lot of these distributions that are clearly important standard distributions, and we found that these can be coerced into the exponential family form, right?",
            "But what is it by us to actually deal with this formalism, you know?",
            "Is it the case that the you know when we first looked at the exponential family thing, it looked like it was really specific.",
            "It's you know what kind of distributions could possibly have that form now?",
            "It seems like it might be too general.",
            "You know.",
            "We effortlessly expressed the Bernoulli, the POS, or the Gaussian is exponential family.",
            "Models right?",
            "Is it so general that it's not useful for us?",
            "You know why?",
            "Why are we what's so good about this exponential family?",
            "What is special about exponential family distributions?",
            "And it turns out that a lot of the special properties of this distribution lie where one initial."
        ],
        [
            "We would not expect it to lie, namely in the log partition function.",
            "OK, so the way this log partition function came about is that it was just the normalizer.",
            "You know it's just the thing you kind of tack on in front to make it all add up to one.",
            "However, it turns out that this normalizer actually contains a wealth of information about the distribution.",
            "And we're going to use its properties quite heavily.",
            "When we when we get back to maximum entropy.",
            "OK, so first.",
            "First of all, it turns out that this thing is strictly convex.",
            "OK, so for instance, the awesome.",
            "Also, in case it was E to the ADA.",
            "OK, so the exponent which is, you know, which looks like this.",
            "It's a strictly convex function, OK?",
            "Among other things, it means that its derivative is 1 to one.",
            "OK, so if you have a strictly convex function and you look at its derivative, well, the derivative is increasing.",
            "It's a one to one to one to one function.",
            "The derivative actually has other properties.",
            "The derivative turns out to simply be the mean of the distribution.",
            "OK.",
            "So if you take the derivative of this log partition function so this log partition function, you just compute its first derivative and that turns out to be the mean of the distribution.",
            "The expected value under random draws from that distribution of of the feature vector.",
            "OK, so so why is this the case where let's in general the feature vector has many components that ETA one ETA two?",
            "So on, let's take the derivative with respect to the right component.",
            "You take the derivative of this with respect to Theta with respect to Ada I.",
            "Well, the derivative log X is just you know 1 / X DX, so it's it's one over this thing times the derivative of the top, which is this.",
            "OK. And now you can see that this is just the probability of, so it's just the expectation of that particular feature.",
            "OK, and there's and if you do the similar thing for the variable for the second derivative, you get the variance of the distribution.",
            "OK, so just by taking the first derivative second derivative of the log partition function, we end up getting the moments of the distribution.",
            "OK, so there's a wealth of information contained in this log partition function.",
            "OK.",
            "So, So what else you know?",
            "Well, in what other ways this exponential family unique?",
            "OK, what is what is special about why we singled out these distributions as being important?",
            "Once you know what else is unique about them?",
            "So the real the real benefit comes when you start looking at maximum likelihood estimation."
        ],
        [
            "So suppose you're dealing with some exponential family.",
            "OK, and as we've seen to specify, an exponential family, just specify the base measure and the features you're going to look at.",
            "So suppose we're dealing with some exponential family, and now we see a bunch of data and we want to find the best member of the family.",
            "OK, so for instance, we see a bunch of points and we want to Gaussian to them.",
            "So let's find the maximum likelihood choice of the parameter.",
            "OK, so you just plug into this.",
            "We want to maximize the log likelihood.",
            "So take the log of this.",
            "It's 8 * T of XI minus G of beta.",
            "Plus log of HXI.",
            "You rewrite it because you can pull the data out.",
            "OK, you get the sum of these ties and these.",
            "This is just a constant and now you get the sum of the log of excise.",
            "And to maximize this you set the derivative and you take the derivative.",
            "You set it to 0.",
            "Well, if you do that.",
            "What you're doing is you're setting the derivative of the log partition function to simply the the average of the data you saw.",
            "And that's the maximum likelihood choice.",
            "OK, we saw that the derivative of the log partition function is simply the mean of the distribution.",
            "So the maximum likelihood choice is is very simple.",
            "You just take all your data.",
            "You take the average and now you pick the model that has exactly that same mean.",
            "OK.",
            "So.",
            "So this is.",
            "So This is why these models are so useful.",
            "You know, in a lot of modeling context, when you have a lot of data and you want to fit a model to it, you actually need to keep the data around.",
            "You know if you're fitting a linear classifier to it, you need to keep all the labeled points around and you give it to some sort of, you know, give it to some routine that juggles them and come in and spits out a linear classifier.",
            "In this exponential family models, you can have a vast amount of data, but you don't need to keep it around.",
            "All you need is the average and once you have the average you can.",
            "You can find the best fit model without any problem at all.",
            "OK, so these exponential family distributions are the ones that in order to fit them you just need to keep the average of the data.",
            "Yeah.",
            "Yeah, modulo some.",
            "You know modulo some niceness conditions, etc.",
            "So OK, so let's look at an example."
        ],
        [
            "So you have a bunch of data and you find that the mean is 7.5.",
            "What's the what person should you fit to it?",
            "It's easy, whatever plus or has mean 7.5 OK.",
            "But this is where the this is, where a little problem comes up between the two types of parameterisations of these distributions OK.",
            "The one we you know for us it's fine to say yeah, we're just going to pick the fossil with mean 7.5.",
            "But that's not the natural parameter of these possible distributions.",
            "OK, So what is the natural parameter for the person which has been 7.5?",
            "OK, so in the case of possum, it turns out to be easy.",
            "We know that the log partition function is just each of the ADA.",
            "So the derivative is also each of the ETA OK, which means, and this is the mean of the distribution.",
            "So we just set this to be 7.5.",
            "And therefore it has long 7.5.",
            "So in the case of the plus, so it's easy to go from the expectation parameter, which is 7.5 to the natural parameter, just just the natural logarithm of 7.5.",
            "But in general it's not always easy to invert this function G prime is not always easy to say.",
            "OK, these are the means I want.",
            "What is the corresponding natural parameter that can be a hard problem?",
            "And if we look back at all."
        ],
        [
            "Problem, unfortunately, that's one of these.",
            "OK, so.",
            "You know, we know what the not.",
            "We know what the expectations are of all of these features.",
            "That's what we started with.",
            "We know the expected value of this is point .3.",
            "We know the expected value of this is .4 or whatever, but that doesn't help us in figuring out what these parameters should be.",
            "How do we find the setting of these parameters that gives the right expected value for the distribution?",
            "OK, this is not an easy problem and so the way to think of these two spaces is that we have this natural parameter space.",
            "These are the parameters we want.",
            "But the space in which the detail lies is a different space.",
            "OK, and we can compute averages in that space.",
            "So we compute averages and we got this, you know."
        ],
        [
            "So maybe we had a data point here, one here, one here, one here, one here, and we computed the average and we got this.",
            "OK, this was the just the average of all the data and now we want to go back and we want to find the natural parameter that corresponds to that, and that's not an easy problem.",
            "OK, we've got this one to one map.",
            "We saw the G prime is a one to one relationship because G is strictly convex.",
            "But it's hard to go backwards.",
            "OK, so in summary, when you have an exponent when you're dealing with exponential families of distributions.",
            "Finding the Mike maximum likelihood distribution is in some sense an easy task.",
            "But only if you're using the expectation parameterisation.",
            "If you're just looking for an expectation parameter, it's the easiest thing in the world to fit one of these models.",
            "You just set it to the average of the data, but if you're looking for natural parameters then it's a little harder.",
            "It becomes a convex optimization problem, so why is it a convex optimization problem?",
            "Well, let's go back to the equation.",
            "This is what we're trying to solve.",
            "We're trying to find we're trying to maximize this quantity.",
            "Well, we saw the G is strictly convex and everything else is just linear.",
            "So far, so maximizing this equation.",
            "This is a convex optimization problem.",
            "OK, so the problem we want to solve.",
            "The parameters for our model over here.",
            "This is a convex optimization problem.",
            "And this is the thing that we were calling information project."
        ],
        [
            "So let's see how you actually solve this problem.",
            "You know how can you go about solving this thing?",
            "OK.",
            "So.",
            "OK."
        ],
        [
            "So so just to kind of recap and just to step back a little bit.",
            "How do we get to this point OK?",
            "So we started with the problem, which was a maximum entropy problem.",
            "OK, we have this toy problem.",
            "We want to fit a model that makes as few assumptions as possible subject to given constraints.",
            "We found that the solution to maximum entropy problems are always exponential families of distributions.",
            "OK, and now we actually want to solve for these distributions.",
            "OK, so here was the here's a general form of the question we started with.",
            "We had a bunch of priors.",
            "Who knows we had this.",
            "We had a prior knowledge wiki this our earlier statistical model.",
            "Now we have some observations that we make based on, say, a small sample of data that we collect.",
            "And now we want to update our prior.",
            "We want to choose a distribution that's really close to the prior.",
            "But also satisfies these constraints.",
            "And it turned out that the solution to this is to choose the distribution to be an exponential family model.",
            "Specifically, the solution to this is the unique member of the exponential family generated by Pianti.",
            "Which actually satisfies which which has the given expectations.",
            "OK.",
            "So pianti.",
            "The prior Pi and the features T uniquely define an exponential family of distributions and we just have to pick the one that has the given expectations.",
            "OK, so let's look at an example of this right?"
        ],
        [
            "So suppose I just tell you that look, there's some distribution and I know it's mean is zero and the expected value of X squared is 10.",
            "What distribution should I choose now?",
            "Of course, there's infinitely many distributions that have these expected values.",
            "OK, there's no.",
            "There's no shortage of them, but if you were to make the maximum entropy choice, the answer is very simple.",
            "OK, we have a distribution over R. OK, so that's our base space.",
            "We found two expectations, so the features we want are X and X ^2.",
            "OK.",
            "This generates the Gaussian.",
            "These are the features that generate the Gaussian family of distributions.",
            "So now all we have to do is to pick the Gaussian that has this mean and this expected value of X squared.",
            "In other words, this variance.",
            "OK, and that's just the Gaussian zero 10.",
            "OK, so this is the maximum entropy choice, so if you were following the maximum entropy principle, this would be the distribution that you would pick.",
            "Yeah.",
            "Yeah.",
            "Yeah, so over here implicitly I've chosen a base measure that is uniform.",
            "OK, that's just flat, because the base measure corresponding to the.",
            "You're right that in order to uniquely specify an exponential family, I need not just the choice of features, but also a base measure.",
            "And here are just happened to choose.",
            "I just chosen a base measure, that is, that is 1 everywhere.",
            "The Labay measure on the real line.",
            "If you had a prior, if you had a prior over this space, then you would choose that as the base measure and then and then you might end up with something different.",
            "OK, something that in particular you might end up with something that's not a Gaussian.",
            "OK, so any questions about that?",
            "OK."
        ],
        [
            "So now let's figure out what the solution has to look like, OK?",
            "So we have some sample space.",
            "We have some features.",
            "We have some constraints and we have a reference prior.",
            "So here's the key statement.",
            "OK, so the claim is that if there's a distribution of this particular form that happens to satisfy the constraints.",
            "Then it is the unique minimizer.",
            "It's the unique close.",
            "It is the unique distribution that's closest to by.",
            "Subject to these constraints.",
            "And now let's see.",
            "Let's see why this is the case.",
            "OK, so if you can find a distribution that looks like this, that actually satisfies the constraints.",
            "Then that is the unique solution to our problem.",
            "OK, why is that?",
            "Well, let's say P star is this unique distribution.",
            "Let's appease star is a distribution of this form that satisfies the constraints.",
            "Let's show that no other P can possibly do so.",
            "OK."
        ],
        [
            "So we have some distribution P stuff that has the exponential family form OK and it satisfies the constraints.",
            "Will show that any other distribution which satisfies the constraints must be further away from Pi.",
            "Must be strictly further away from Thai.",
            "So how is this the case?",
            "Well, let's look at the distance.",
            "Let's look at how close this other distribution is to \u03c0 compared to how close are exponential family distribution is to \u03c0, and we'll show that this quantity is strictly positive.",
            "OK.",
            "So let's just expand out these terms.",
            "KFC pie, well that's just the definition of KL divergent.",
            "And we do the same for P star.",
            "Now for the next line we just copy this over and we notice that the star because of the exponential family form.",
            "We can write P star over \u03c0 very simply P star.",
            "Is equal to \u03c0 times sum E to the linear function.",
            "Therefore, P star log P star over \u03c0 is just eight dot T of X -- G of ADA.",
            "OK.",
            "So we saw that we saw the P star is of this form, so P star over \u03c0.",
            "Is this very simple linear function?",
            "Great.",
            "Now because because we boiled it down to a linear function, we know that the expectation of this linear function under P star is the same as its expectation under P. Why because?",
            "Well OK, this part is just a constant, so we don't care about that.",
            "This spot is equal to 8 times the expectation of T, and this is so the expectation of T is the same under both distributions because we know that they both satisfy the constraints.",
            "The constraint is that the expectation of T is equal to B.",
            "Right, so you expect therefore.",
            "The expectation of T under P star is equal to the expectation of T under P. And so we can make this switch.",
            "So.",
            "So now when we move further down, we can now swap back the way we got this in the 1st place.",
            "With this log P star of a pie.",
            "So we get that back.",
            "And and now it's very convenient 'cause we have peas and in the front of both of these.",
            "And these pies cancel out.",
            "And what we end up with is just the KL distance from PDP star.",
            "OK.",
            "So we get this very interesting relation.",
            "We get that the difference of these two KL divergences exactly this third KL divergent and since P&P star are not the same, this is strictly positive.",
            "And therefore he is strictly further away from \u03c0.",
            "Then P star is from \u03c0.",
            "Again, that's why peacetime must be the unique minimizer of of the distance divide.",
            "OK, so any questions about this?",
            "This one relation turns out to be extremely useful for us.",
            "We've now derived this relation that the distance from PETA pie is just the distance from P to P star plus the distance from P start a pie.",
            "OK, and this is this is.",
            "Let's see what this looks like geometrically."
        ],
        [
            "So we go back to the geometric picture of our.",
            "So.",
            "So recall that this whole page.",
            "Is the simplex of probability distributions OK?",
            "So so this whole thing, this whole big thing is the simplex of of these probability vectors, which I'll say 50,000 dimensional.",
            "We had some prior distribution, some prior vector.",
            "And we we wanted to project it onto these constraints.",
            "We wanted to find the vector closest to this which satisfies the constraints, and that's the I projection.",
            "Now we see this interesting relation.",
            "We say that pick any other point that also satisfies these constraints.",
            "In other words, pick any other point on this affine subspace of the simplex.",
            "Then we have the relation that the distance from we have this relation over here the distance from PETA pie is equal to the distance from PETA pie starter from distance from P to P star plus the distance from P started by.",
            "This is quite remarkable because this is the Pythagorean theorem.",
            "This is exactly the same relation we have when we are projecting with respect to Euclidean distance.",
            "You know, suppose that instead of using KL distance I was projecting with respect to squared Euclidean distance.",
            "OK, so then I would just project right down over there.",
            "I get that right angle and then if I looked at any other point then I'd have this right angle in the middle and I know that you know this distance squared plus that distance squared was equal to this distance squared.",
            "OK.",
            "So, amazingly, that same Pythagorean relation holds even when one is not using squared Euclidean distance.",
            "It holds also for KL Divergent.",
            "So you take any point, you take its projection onto a linear subspace.",
            "Because we are using Cal, the versions we call we have a special name for.",
            "We call it.",
            "I projection for information projection because instead of using a normal distance measure, we're using this information theoretic distance measure.",
            "But you end up with this same Pythagorean relation.",
            "OK.",
            "So this is a little so this is, this is the geometry part of the thing here.",
            "Sorry this is.",
            "So this is not just in this, not just in the exponential family, but this is the this is the projection.",
            "So P star has to be the projection of \u03c0, and that's also true in the Euclidean case.",
            "In the Euclidean case, the Pythagorean.",
            "If you're projecting onto onto a plane, the Pythagorean theorem only holds when the when you're pivoting on the projection of the point onto the airplane, right?",
            "So you get the right angle.",
            "So this is.",
            "This is literally the generalization of the of the Pythagorean theorem in the Euclidean."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Going to, I'm going to give.",
                    "label": 0
                },
                {
                    "sent": "I'm going to give a bit of an introduction to this area that some people call information geometry.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then just two.",
                    "label": 0
                },
                {
                    "sent": "This is.",
                    "label": 0
                },
                {
                    "sent": "A lot of what I'm talking about is often described as the maximum entropy principle or maximum entropy methods.",
                    "label": 0
                },
                {
                    "sent": "And these are.",
                    "label": 0
                },
                {
                    "sent": "These have been very successful in natural language processing and are now being used in other areas as well, like computational biology.",
                    "label": 0
                },
                {
                    "sent": "All, I'll introduce it by by sort of a toy example.",
                    "label": 0
                },
                {
                    "sent": "OK, there's sort of a clean toy example, so suppose you want to model the distribution of English words.",
                    "label": 1
                },
                {
                    "sent": "OK, so for instance, you might be an alien who is just arrived on this planet, and you notice you you find this dictionary.",
                    "label": 0
                },
                {
                    "sent": "You see that you see that there are all these words over there and you want to model the distribution over words.",
                    "label": 0
                },
                {
                    "sent": "You want to know which ones are frequent, which ones are not frequent.",
                    "label": 0
                },
                {
                    "sent": "So our priority, you don't know anything.",
                    "label": 0
                },
                {
                    "sent": "You just know that there are these.",
                    "label": 0
                },
                {
                    "sent": "You know 50,000 words or whatever, and so you know in the absence of any further knowledge, the sort of the sort of default thing you might do is to just pick the uniform distribution to just pick to just say that everything is equally likely OK.",
                    "label": 0
                },
                {
                    "sent": "But now you can collect some samples and you notice a few things.",
                    "label": 0
                },
                {
                    "sent": "For instance, you might notice.",
                    "label": 0
                },
                {
                    "sent": "OK, well, you know there aren't so many words whose length.",
                    "label": 0
                },
                {
                    "sent": "In random samples of words.",
                    "label": 0
                },
                {
                    "sent": "Only about 30% of them have length more than five.",
                    "label": 0
                },
                {
                    "sent": "This little observation you make.",
                    "label": 0
                },
                {
                    "sent": "You know from these small samples that you take.",
                    "label": 0
                },
                {
                    "sent": "You might say that OK.",
                    "label": 0
                },
                {
                    "sent": "In a random sample, the probability of a word ending in E, the fraction of words that ends in Y is about .45 here, and you notice a few other things like this.",
                    "label": 0
                },
                {
                    "sent": "You keep track of a few features and now the question is how do you adjust your distribution accordingly?",
                    "label": 0
                },
                {
                    "sent": "So initially you knew nothing.",
                    "label": 0
                },
                {
                    "sent": "You pick the uniform distribution.",
                    "label": 0
                },
                {
                    "sent": "Now, which distribution do you pick?",
                    "label": 0
                },
                {
                    "sent": "You've got a little bit of data, but that's all OK. What's what's the right thing to do now?",
                    "label": 0
                },
                {
                    "sent": "So so it turns out that this particular question will this sort of this toy example.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Will let us.",
                    "label": 0
                },
                {
                    "sent": "Develop 3.",
                    "label": 0
                },
                {
                    "sent": "Three sort of theories that are closely interrelated having to do with entropy, exponential families and information projection, and it will help us understand the connection between these three things.",
                    "label": 1
                },
                {
                    "sent": "OK, so so it's a nice excuse to actually develop to sort of theoretically develop these three areas and see what the connections are between them.",
                    "label": 0
                },
                {
                    "sent": "Oak.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's start with entropy.",
                    "label": 0
                },
                {
                    "sent": "OK, so we also focus our.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Question, but let's try and pin down this question.",
                    "label": 0
                },
                {
                    "sent": "Let's try and formalize it a little bit.",
                    "label": 0
                },
                {
                    "sent": "So we have some domain which in that example was English words.",
                    "label": 0
                },
                {
                    "sent": "OK so you know just a big list of words.",
                    "label": 0
                },
                {
                    "sent": "You know, 50,000 words say, well, you know hundreds 100,000 words.",
                    "label": 0
                },
                {
                    "sent": "And now from a small random sample or whatever, we didn't notice a few things and we can think of that as measuring a few features of each word.",
                    "label": 0
                },
                {
                    "sent": "OK, so for instance, let me see if I can work this thing.",
                    "label": 0
                },
                {
                    "sent": "So, for instance, we were measuring whether the length of a word is more than five.",
                    "label": 0
                },
                {
                    "sent": "OK, so we had this indicator feature, which was one.",
                    "label": 0
                },
                {
                    "sent": "If the length is more than five and zero otherwise.",
                    "label": 0
                },
                {
                    "sent": "And we notice that the probability of this happening, the probability of the length being more than five was .3.",
                    "label": 0
                },
                {
                    "sent": "In other words, the expectation of this feature, the expectation of T was .3.",
                    "label": 0
                },
                {
                    "sent": "OK, so the expectation of this indicated variable is just the probability that the length is more than five.",
                    "label": 0
                },
                {
                    "sent": "How can we notice that that was .3?",
                    "label": 0
                },
                {
                    "sent": "We measured a few other things.",
                    "label": 0
                },
                {
                    "sent": "For instance, we had another feature we just checked whether a word ends in E and we notice that the expectation of that feature was .5 and we had a few more things like this.",
                    "label": 0
                },
                {
                    "sent": "OK, so we've now got a bunch of constraints.",
                    "label": 0
                },
                {
                    "sent": "And we want to continue our previous methodology.",
                    "label": 0
                },
                {
                    "sent": "We started knowing nothing and we just picked a uniform distribution over all the words.",
                    "label": 0
                },
                {
                    "sent": "Now we know a few things.",
                    "label": 0
                },
                {
                    "sent": "And we still want to, you know.",
                    "label": 0
                },
                {
                    "sent": "So we want to model these.",
                    "label": 0
                },
                {
                    "sent": "We want it to be the case that the new distribution we pick does satisfy these things that we've observed.",
                    "label": 0
                },
                {
                    "sent": "But other than, that assumes nothing.",
                    "label": 0
                },
                {
                    "sent": "So other than that is as random as possible.",
                    "label": 1
                },
                {
                    "sent": "OK, So what is the sort of?",
                    "label": 0
                },
                {
                    "sent": "What is the one?",
                    "label": 0
                },
                {
                    "sent": "What is the single distribution of?",
                    "label": 0
                },
                {
                    "sent": "Or maybe there's not?",
                    "label": 1
                },
                {
                    "sent": "Maybe it's not unique, but what is the distribution that satisfies these constraints but otherwise makes no assumptions?",
                    "label": 0
                },
                {
                    "sent": "OK or otherwise, is as random as possible, so by the way, stop me at anytime if there if there any questions at all.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So in order to do this.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we formalized a lot of it.",
                    "label": 0
                },
                {
                    "sent": "We formalized what are constraints are.",
                    "label": 0
                },
                {
                    "sent": "We want a distribution that satisfies certain expected value constraints.",
                    "label": 0
                },
                {
                    "sent": "The next thing we have to formalize, the only thing we really need to pin down now, is what do I mean by random?",
                    "label": 0
                },
                {
                    "sent": "When I say distribution, that's as random as possible.",
                    "label": 0
                },
                {
                    "sent": "OK, So what is the randomness in the distribution?",
                    "label": 0
                },
                {
                    "sent": "What's the randomness content of a distribution?",
                    "label": 0
                },
                {
                    "sent": "So, so how?",
                    "label": 0
                },
                {
                    "sent": "How would we define randomness?",
                    "label": 0
                },
                {
                    "sent": "This seems like something that you know there's going to be a lot of disagreement about this.",
                    "label": 0
                },
                {
                    "sent": "There must be lots of ways to define randomness, you know so so.",
                    "label": 0
                },
                {
                    "sent": "So how would we go about it?",
                    "label": 0
                },
                {
                    "sent": "So intuitively, let's let's think of some things that we would like to be true of.",
                    "label": 0
                },
                {
                    "sent": "Any reasonable definition of randomness.",
                    "label": 1
                },
                {
                    "sent": "OK, so for instance, it's natural to think of a fair coin as having one bit of randomness.",
                    "label": 0
                },
                {
                    "sent": "OK, the outcome is either a zero or a one.",
                    "label": 0
                },
                {
                    "sent": "The equally likely.",
                    "label": 0
                },
                {
                    "sent": "It's very natural to think of that as being one bit of randomness.",
                    "label": 0
                },
                {
                    "sent": "OK, what if a coin is biased, but if a coin is biased?",
                    "label": 0
                },
                {
                    "sent": "If it's more likely to, say turn up heads, then it's less random.",
                    "label": 0
                },
                {
                    "sent": "So if we've said that a fair coin is 1 bit of randomness, then a biased coin.",
                    "label": 1
                },
                {
                    "sent": "Its randomness contents should be strictly less than one.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's something we would like to be true.",
                    "label": 1
                },
                {
                    "sent": "What about two independent fair coins?",
                    "label": 0
                },
                {
                    "sent": "So now this is 2 bits of randomness.",
                    "label": 0
                },
                {
                    "sent": "OK, because they are independent of each other.",
                    "label": 0
                },
                {
                    "sent": "They each contain separate amount of information.",
                    "label": 0
                },
                {
                    "sent": "If one one of them is 1 bit, two of them should should be 2 bits.",
                    "label": 0
                },
                {
                    "sent": "What if the fair coins are dependent?",
                    "label": 0
                },
                {
                    "sent": "OK, so the outcome of the second coin depends on the first coin well, then the overall randomness is less than two bits.",
                    "label": 0
                },
                {
                    "sent": "OK, for instance, the second coin might be exactly equal to the first coin, in which case there's just one bit of randomness in them.",
                    "label": 0
                },
                {
                    "sent": "OK. And here's another thing we'd like to be true.",
                    "label": 0
                },
                {
                    "sent": "Sort of extending these things.",
                    "label": 1
                },
                {
                    "sent": "Suppose we have a uniform distribution over 32 possible outcomes.",
                    "label": 0
                },
                {
                    "sent": "Well, this is something we can code in five bits, each of which is equally plausible.",
                    "label": 0
                },
                {
                    "sent": "OK, so so we would like this we you know we would like to say that this has five bits of randomness.",
                    "label": 0
                },
                {
                    "sent": "So so these are some, some of the sort of intuitive things that we would like to measure of randomness to capture.",
                    "label": 0
                },
                {
                    "sent": "But just putting down a few things like this, there's gotta be a million ways to define randomness, right?",
                    "label": 0
                },
                {
                    "sent": "So, so there's one.",
                    "label": 0
                },
                {
                    "sent": "However, that seems to be real.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The popular OK.",
                    "label": 0
                },
                {
                    "sent": "There's one that sort of.",
                    "label": 0
                },
                {
                    "sent": "There's one that everyone seems to use, and it's called the entropy.",
                    "label": 0
                },
                {
                    "sent": "So suppose you have a discrete distribution X axis, some random variable which takes on discrete values, and it's got a distribution P. Then the entropy of it is this weird thing.",
                    "label": 0
                },
                {
                    "sent": "OK, it's the sum over all possibilities of X of P of X log 1 / P of X. OK, which is expectation with respect to another way to write in just the expectation with respect to random draws from P of log 1 / P of X. OK.",
                    "label": 0
                },
                {
                    "sent": "So this is the definition that people seem to use and just looking at it, it looks a little crazy.",
                    "label": 0
                },
                {
                    "sent": "You know what do you know?",
                    "label": 0
                },
                {
                    "sent": "How can this be the natural notion of randomness?",
                    "label": 0
                },
                {
                    "sent": "P log 1 / P X.",
                    "label": 0
                },
                {
                    "sent": "What is this thing right?",
                    "label": 0
                },
                {
                    "sent": "So so.",
                    "label": 0
                },
                {
                    "sent": "So let's first check that it isn't totally crazy.",
                    "label": 0
                },
                {
                    "sent": "OK, let's just plug in a few examples and see that it's actually doing the right thing.",
                    "label": 0
                },
                {
                    "sent": "In at least you know at least some toy cases.",
                    "label": 0
                },
                {
                    "sent": "So for instance, if we look at a fair coin.",
                    "label": 0
                },
                {
                    "sent": "Then there are two possible outcomes, each with probability 1/2.",
                    "label": 0
                },
                {
                    "sent": "So the entropy is 1/2 log 2 + 1/2 log 2.",
                    "label": 1
                },
                {
                    "sent": "Which is one.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's something we wanted that the entropy of a fair coin is 1.",
                    "label": 0
                },
                {
                    "sent": "Now suppose we have a coin with a bias of 3/4, so then we get 3/4 log 4 thirds.",
                    "label": 0
                },
                {
                    "sent": "Plus 1/4, which is the other outcome.",
                    "label": 0
                },
                {
                    "sent": "Log 4 and that turns out to be less than one.",
                    "label": 0
                },
                {
                    "sent": "It turns out to be .8 one.",
                    "label": 0
                },
                {
                    "sent": "OK, so again, this is this is this is what we expected.",
                    "label": 0
                },
                {
                    "sent": "Now we knew it should be less than one.",
                    "label": 0
                },
                {
                    "sent": "We didn't know how much less than one, but .81 sure, whatever.",
                    "label": 0
                },
                {
                    "sent": "OK, that's that's plausable.",
                    "label": 1
                },
                {
                    "sent": "What about a coin with bias .99?",
                    "label": 0
                },
                {
                    "sent": "Now this is a coin that's almost not random at all.",
                    "label": 0
                },
                {
                    "sent": "It's a coin that you know is is almost deterministic, so we would expect that the randomness content of this is something that should be very small.",
                    "label": 0
                },
                {
                    "sent": "So let's plug it in.",
                    "label": 0
                },
                {
                    "sent": "It should certainly be smaller than the coin with by 3/4, so let's plug in .99, we get .99 log 1 / .99 and we plug it in and it becomes .08.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's good.",
                    "label": 0
                },
                {
                    "sent": "It's close to 0, which is what we would want, and it's much less than these two numbers.",
                    "label": 1
                },
                {
                    "sent": "OK, and finally, let's check a uniform distribution of a key outcomes.",
                    "label": 0
                },
                {
                    "sent": "If it's a uniform distribution, all these probabilities are 1 / K, so we get 1 / K log K, and now we submit over K things.",
                    "label": 0
                },
                {
                    "sent": "So the answer is log K. OK, so in this basic cases this is doing the right thing.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "I mean qualitatively it's doing the right thing.",
                    "label": 0
                },
                {
                    "sent": "We know that this should be smaller than one and we know point it should be the smallest of all in.",
                    "label": 0
                },
                {
                    "sent": "That should be fairly close to 0, so qualitatively is doing the right thing.",
                    "label": 0
                },
                {
                    "sent": "But again, you know, I'm sure I could cook up, you know, hundreds of other measures that also qualitatively do the right thing on these examples.",
                    "label": 0
                },
                {
                    "sent": "OK, so what's special about this one?",
                    "label": 0
                },
                {
                    "sent": "So let's take a closer located at least it's past the first round of tests and you know and let's and let's get a little more of a sense of what it's like.",
                    "label": 0
                },
                {
                    "sent": "So first of all.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Thing is concave.",
                    "label": 0
                },
                {
                    "sent": "OK so if you if you actually just draw the graph of it.",
                    "label": 0
                },
                {
                    "sent": "This is for a case of a coin with bias P. It's a concave thing, it's maximized when the coin is exactly a fair coin, at which point the entropy is one OK.",
                    "label": 0
                },
                {
                    "sent": "If the coin is totally deterministic, if it's always heads or it's always tails, then the entropy is 0, which is what we'd expect.",
                    "label": 1
                },
                {
                    "sent": "There's no randomness at all, and it's symmetric.",
                    "label": 0
                },
                {
                    "sent": "A coin with bias 3/4 is the same as a coin with biased 1/4 in terms of its randomness content.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is perfectly reasonable.",
                    "label": 0
                },
                {
                    "sent": "In that sense, it's fine.",
                    "label": 0
                },
                {
                    "sent": "So let's look at.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Some of the let's look at some of the nice properties that this thing is got.",
                    "label": 0
                },
                {
                    "sent": "OK, so so so so.",
                    "label": 0
                },
                {
                    "sent": "So what are the intuitive properties that this thing has?",
                    "label": 0
                },
                {
                    "sent": "So first of all, entropy is got expansibility.",
                    "label": 0
                },
                {
                    "sent": "OK, so for instance, suppose I have a distribution which has N possible outcomes with these with some probabilities P1 through PN.",
                    "label": 0
                },
                {
                    "sent": "Now I can I add another fake outcome that never occurs.",
                    "label": 0
                },
                {
                    "sent": "OK, so the end outcomes and they have some probabilities and now I just tack on another fake outcome, which is never happens.",
                    "label": 0
                },
                {
                    "sent": "That clearly should not change the entropy, and that's true.",
                    "label": 0
                },
                {
                    "sent": "The entropy remains the same in that's in that situation.",
                    "label": 1
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "It's got this property of symmetry.",
                    "label": 0
                },
                {
                    "sent": "Which is that?",
                    "label": 0
                },
                {
                    "sent": "That if you have a distribution which if you just permute the labels of the points, then then the entropy doesn't change, right and.",
                    "label": 0
                },
                {
                    "sent": "Is this so?",
                    "label": 0
                },
                {
                    "sent": "That's Elvis Presley.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So right so?",
                    "label": 0
                },
                {
                    "sent": "So this is clear, right?",
                    "label": 0
                },
                {
                    "sent": "So so the the the notion of randomness should not be sensitive to the names you actually give things.",
                    "label": 1
                },
                {
                    "sent": "OK if you change you flip heads and tails, randomness should not change, and that's the property of symmetry.",
                    "label": 0
                },
                {
                    "sent": "It's also got this property of additivity, and this is a very useful thing.",
                    "label": 0
                },
                {
                    "sent": "OK, so if you have two independent random variables, then the entropy of them taken together is the sum of the individual entropies.",
                    "label": 0
                },
                {
                    "sent": "And let's see why.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is the case.",
                    "label": 0
                },
                {
                    "sent": "OK so I have these two things that are independent and now I want to look at their joint entropy.",
                    "label": 0
                },
                {
                    "sent": "The sum of them taken together.",
                    "label": 0
                },
                {
                    "sent": "Well, that's the sum over all possible outcomes.",
                    "label": 0
                },
                {
                    "sent": "X&Y.",
                    "label": 0
                },
                {
                    "sent": "Just plug into the definition P of X, log 101 / P of XY.",
                    "label": 0
                },
                {
                    "sent": "But in this case, because of independence, P of XY is P of X * P of life.",
                    "label": 0
                },
                {
                    "sent": "Anso and because it's a log, I can split this into its two pieces.",
                    "label": 0
                },
                {
                    "sent": "Log 1 / P of X plus log 1 / P of Y.",
                    "label": 0
                },
                {
                    "sent": "So I get these two individual summations.",
                    "label": 0
                },
                {
                    "sent": "And I can now some out the Y and in this case I can send out the X. OK, so I get the the individual entropy of X plus the individual entropy of Y.",
                    "label": 0
                },
                {
                    "sent": "Great so so this is another place another of the properties we wanted.",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What is the variables are not independent?",
                    "label": 0
                },
                {
                    "sent": "In that case we wanted to be the case that the entropy of the joint distribution is at most is is it moves the sum of the individual entropies.",
                    "label": 0
                },
                {
                    "sent": "OK, so we wanted so, and that's called subadditivity.",
                    "label": 0
                },
                {
                    "sent": "OK so if they are independent then the entropy of the joint is just the sum of the individual entropies.",
                    "label": 0
                },
                {
                    "sent": "If they're dependent then it's going to be less than that, and that's another.",
                    "label": 0
                },
                {
                    "sent": "That's another good property that it's got.",
                    "label": 0
                },
                {
                    "sent": "We've normalized it so that a fair coin has entropy.",
                    "label": 1
                },
                {
                    "sent": "One, OK, you could just scale it by an arbitrary constant.",
                    "label": 0
                },
                {
                    "sent": "A reasonable normalization is just to say fair coin is entropy one.",
                    "label": 0
                },
                {
                    "sent": "And finally we want it to be the case that as as the bias of a coin goes to zero, the entropy also goes to zero.",
                    "label": 1
                },
                {
                    "sent": "OK, so as it becomes more deterministic, the entropy goes to zero and it also has that property.",
                    "label": 0
                },
                {
                    "sent": "So it's got these six properties that we think you know that intuitively should be true of any measure of randomness.",
                    "label": 1
                },
                {
                    "sent": "But now it turns out that entropy is the only measure that satisfies these.",
                    "label": 0
                },
                {
                    "sent": "OK, so if you proceed in an axiomatic way, if you say look, I want to, I want to come up with a measure of randomness.",
                    "label": 0
                },
                {
                    "sent": "And now let me put down a few properties that any measure of randomness should have all very reasonable sounding properties.",
                    "label": 0
                },
                {
                    "sent": "OK, what would they expansibility?",
                    "label": 0
                },
                {
                    "sent": "That's totally reasonable.",
                    "label": 0
                },
                {
                    "sent": "If you add on a fake new sample, if you add on a fake new.",
                    "label": 0
                },
                {
                    "sent": "Outcome that never occurs.",
                    "label": 0
                },
                {
                    "sent": "Sure, that should not change the entropy, symmetry, additivity, subadditivity, normalization.",
                    "label": 0
                },
                {
                    "sent": "These are very, you know these are.",
                    "label": 0
                },
                {
                    "sent": "These are things that you know we would think.",
                    "label": 0
                },
                {
                    "sent": "Of course this should be true of a measure of randomness, but entropy is the only one that satisfies all of them OK, and so this justifies why we why we use something with that weird functional form.",
                    "label": 0
                },
                {
                    "sent": "You know P log 1 / P. It seems a little crazy at first, but This is why we're stuck with it.",
                    "label": 0
                },
                {
                    "sent": "OK, and This is why we have to deal with the thing.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's look at some other.",
                    "label": 0
                },
                {
                    "sent": "Let's look at some other properties of this measure.",
                    "label": 0
                },
                {
                    "sent": "First of all, it's cool.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Mostly related to the KL divergent, so so some of you might already know this distance measure.",
                    "label": 0
                },
                {
                    "sent": "It's a very commonly used distance measure between probability distributions.",
                    "label": 1
                },
                {
                    "sent": "OK, so suppose I have two probability distributions P&Q and I want to measure the distance between them.",
                    "label": 0
                },
                {
                    "sent": "Now the many ways one could do it, one could look one could for instance draw the curves to P&Q and look at the area between the curves.",
                    "label": 0
                },
                {
                    "sent": "That's a very intuitive way to do it, and that's L1 distance OK, one could look at the L2 distance between them.",
                    "label": 0
                },
                {
                    "sent": "Or one could for some reason plug it into this formula.",
                    "label": 0
                },
                {
                    "sent": "That looks a lot more weird than any of those other two possibilities.",
                    "label": 0
                },
                {
                    "sent": "And it turns out that this is something that is very widely used in statistics.",
                    "label": 0
                },
                {
                    "sent": "OK, So what are the features of this?",
                    "label": 0
                },
                {
                    "sent": "What are the properties of this?",
                    "label": 0
                },
                {
                    "sent": "Well, first of all it has many.",
                    "label": 0
                },
                {
                    "sent": "It has many unpleasant aspects to it.",
                    "label": 0
                },
                {
                    "sent": "OK, so first of all, it's not symmetric.",
                    "label": 1
                },
                {
                    "sent": "The distance from P to Q is not the same as the distance from Q to P. Not at all a desirable thing.",
                    "label": 1
                },
                {
                    "sent": "This thing could easily be infinite if it's the case that Q is zero at a point where P is non zero, then this whole thing becomes infinite.",
                    "label": 0
                },
                {
                    "sent": "OK, so so already there are many reasons not to like it, but at least it's the case that.",
                    "label": 0
                },
                {
                    "sent": "It's always positive and it's zero only if P&Q are equal.",
                    "label": 0
                },
                {
                    "sent": "OK, so so this turns.",
                    "label": 0
                },
                {
                    "sent": "This distribution turns out to be.",
                    "label": 0
                },
                {
                    "sent": "Very useful in many contexts, like entropy when you're dealing with the product distribution.",
                    "label": 0
                },
                {
                    "sent": "These the product in here the log and the product interact very nicely and so when you're dealing with product distribution, systems are to be a very convenient functional form.",
                    "label": 0
                },
                {
                    "sent": "OK, in the same way as we saw the additivity property for entropy OK, and also this is closely related to maximum likelihood.",
                    "label": 0
                },
                {
                    "sent": "If you have a bunch of data and you have some some parameterized models and you want to pick the maximum likelihood model, picking the maximum likelihood model is the same as picking the model that has the smallest KL divergent to the empirical distribution.",
                    "label": 0
                },
                {
                    "sent": "That's the distribution where you just take your data points and assign them all the same way OK.",
                    "label": 0
                },
                {
                    "sent": "So, so this is so, how is this thing related to entropy?",
                    "label": 0
                },
                {
                    "sent": "To do that?",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We look at the two to see how the KL Divergent is related to the entropy of a distribution P. So let's say a random variable X has distribution P. Let's look at the kill Divergent from P to the uniform distribution.",
                    "label": 1
                },
                {
                    "sent": "OK, so that's just plugging into the formula for KL divergent.",
                    "label": 0
                },
                {
                    "sent": "That's P log P over the uniform distribution.",
                    "label": 0
                },
                {
                    "sent": "Uniform is just one over S everywhere.",
                    "label": 0
                },
                {
                    "sent": "OK, so there are there as possible outcomes.",
                    "label": 0
                },
                {
                    "sent": "And so.",
                    "label": 0
                },
                {
                    "sent": "And again, the log decomposes nicely and we get P log P + P log S. OK, in other words, logs minus minus the entropy of X.",
                    "label": 0
                },
                {
                    "sent": "So what this means is the entropy is really telling us the distance from the uniform distribution measured according to this distance measure, the KL divergent and and just this one formula tells us many things.",
                    "label": 0
                },
                {
                    "sent": "For instance, it tells us we know that the KL divergences always positive.",
                    "label": 0
                },
                {
                    "sent": "So this tells us that the entropy can never be more than logs.",
                    "label": 0
                },
                {
                    "sent": "This is an upper bound on the entropy.",
                    "label": 0
                },
                {
                    "sent": "It tells us that the maximum entropy distribution we know the most the entropy can be as log as.",
                    "label": 0
                },
                {
                    "sent": "And when is the entropy log?",
                    "label": 0
                },
                {
                    "sent": "Yes, when we're looking at a uniform distribution over S outcomes.",
                    "label": 0
                },
                {
                    "sent": "So the distribution that maximizes the entropy is just the uniform distribution over all of these outcomes.",
                    "label": 0
                },
                {
                    "sent": "So, so any questions about about this sort of thing?",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's look at one more justification of entropy and then apply it to our problem.",
                    "label": 1
                },
                {
                    "sent": "So so to understand this.",
                    "label": 0
                },
                {
                    "sent": "Maybe the maybe the way to say it is that when you have a distribution and you take 1 sample from it, there's so much still plasticity in what your output could be.",
                    "label": 0
                },
                {
                    "sent": "You know if you have a, if it's a distribution over coins in the coin is biased .75 it could either be zero or one you know there's a lot of randomness in what the output could be.",
                    "label": 0
                },
                {
                    "sent": "It's not so, so one way to make it one way to come to to reduce the level of Stochastic City is to draw many samples.",
                    "label": 0
                },
                {
                    "sent": "That's when you get a more accurate picture.",
                    "label": 0
                },
                {
                    "sent": "That's how you reduce the stochastic city in.",
                    "label": 0
                },
                {
                    "sent": "And what you're seeing?",
                    "label": 0
                },
                {
                    "sent": "OK, so suppose we draw.",
                    "label": 0
                },
                {
                    "sent": "Suppose we have a bunch of draws from some distribution, so X One X2, XN are IID draws from some distribution P OK, and now we've drawn a lot of them, and so we can look at the sequence is that we get.",
                    "label": 0
                },
                {
                    "sent": "So if these are coin flips, we just have these sequences 000111, etc.",
                    "label": 0
                },
                {
                    "sent": "OK, just long sequences of zeros and ones.",
                    "label": 0
                },
                {
                    "sent": "So now let's look at these sequences and just put them into two groups.",
                    "label": 1
                },
                {
                    "sent": "We just pick out the sequences whose probability is roughly 2 to the minus.",
                    "label": 1
                },
                {
                    "sent": "This OK according to our distribution and all other sequences.",
                    "label": 0
                },
                {
                    "sent": "And it turns out that most of the sequences that we observe are going to have roughly the same probability.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "This is called the asymptotic equipartition property.",
                    "label": 1
                },
                {
                    "sent": "So what this is saying is that if you look at the space of all.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sequences that you can possibly generate.",
                    "label": 0
                },
                {
                    "sent": "OK, so in the case of a coin would say bias.",
                    "label": 0
                },
                {
                    "sent": "3/4 OK, this is all two to the N sequences.",
                    "label": 0
                },
                {
                    "sent": "These are the sequence.",
                    "label": 0
                },
                {
                    "sent": "These are all the sequences of zeros and ones you can get.",
                    "label": 0
                },
                {
                    "sent": "You can possibly generate.",
                    "label": 0
                },
                {
                    "sent": "There are just a few of them that are typical.",
                    "label": 0
                },
                {
                    "sent": "And these are the sequences whose probability is about 2 to the minus N times the entropy of one of those random variables.",
                    "label": 0
                },
                {
                    "sent": "OK, in this case, the entropy of a coin with whatever bias I said, I think .6 or .75.",
                    "label": 0
                },
                {
                    "sent": "OK, so although there's a large space of possible outcomes, there is actually a typical set.",
                    "label": 1
                },
                {
                    "sent": "And when you draw a large number of sequences, although you know if it's so, when you draw a large number of points, although the distribution of any one point is really stochastic, when you draw a large number of points and look at the sequence is, it's a little bit like a uniform distribution over about two to the NH outcomes.",
                    "label": 1
                },
                {
                    "sent": "OK, so the distribution looks.",
                    "label": 1
                },
                {
                    "sent": "It's almost like a flat distribution over a smaller set of outcomes.",
                    "label": 0
                },
                {
                    "sent": "OK, so instead of two to the N outcomes, two to the N times the entropy which is going to be at most one in the case of a coin flip.",
                    "label": 0
                },
                {
                    "sent": "OK, so in this sense the entropy tells us the volume of this typical set.",
                    "label": 1
                },
                {
                    "sent": "This typical set has volume to to the N times entropy.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's look at some examples of this right.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for instance, a fair coin.",
                    "label": 0
                },
                {
                    "sent": "If we draw N, if we draw N samples from a fair coin and we look at the sequences we get, well then we just have a uniform distribution over all possible outcomes.",
                    "label": 1
                },
                {
                    "sent": "OK, so in that case we just occupy this whole space.",
                    "label": 0
                },
                {
                    "sent": "All possible outcomes are about equally likely, and each of them has the entropy is 1 in that case, and each of them has probability two to the minus N. OK, so the and the number of outcomes is 2 to the end.",
                    "label": 0
                },
                {
                    "sent": "Now let's look at the boy biased coin.",
                    "label": 1
                },
                {
                    "sent": "Suppose we look at a coin with bias 3/4.",
                    "label": 0
                },
                {
                    "sent": "In this case, when you draw a lot of them, when you draw a lot of when you flip a lot of coins, you're going to find that in the end, about 3/4 of them are heads.",
                    "label": 1
                },
                {
                    "sent": "OK, so the typical probability of a sequence like this is going to be about 3/4.",
                    "label": 0
                },
                {
                    "sent": "3/4 of the three quarter end of the of the coin tosses are going to be heads and the remaining ones are going to be tailed.",
                    "label": 0
                },
                {
                    "sent": "OK. And this is the typical probability most of the sequences will conform to this.",
                    "label": 0
                },
                {
                    "sent": "And when you look at the log of this, you find that in fact it is minus 10 times the entropy of 1/4.",
                    "label": 0
                },
                {
                    "sent": "So this typical sequence does have probability two to the minus 10 times the entropy.",
                    "label": 0
                },
                {
                    "sent": "Again in that case, the typical set is much smaller.",
                    "label": 0
                },
                {
                    "sent": "OK, although the two to the end possible outcomes, the typical set is of size just two to the end times the entropy of of 3/4, which is .81.",
                    "label": 0
                },
                {
                    "sent": "So, so why is this thing true?",
                    "label": 0
                },
                {
                    "sent": "Why is this property true?",
                    "label": 0
                },
                {
                    "sent": "OK, so so we've drawn.",
                    "label": 0
                },
                {
                    "sent": "We've drawn in samples from some distribution P. OK.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "These are IID samples.",
                    "label": 0
                },
                {
                    "sent": "Let's define a new random variable Y survive.",
                    "label": 0
                },
                {
                    "sent": "And let's define it to be log 1 / P of exhibi.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is a random variable.",
                    "label": 0
                },
                {
                    "sent": "You the way you do it is in the case of coin tosses, you flip a coin.",
                    "label": 0
                },
                {
                    "sent": "You look at the outcome heads or tails, and if it's heads it's log one over the probability of heads.",
                    "label": 0
                },
                {
                    "sent": "If it steals it's one over log which log one over the probability of tails.",
                    "label": 0
                },
                {
                    "sent": "Now, one way we defined entropy was just as the expectation of this quantity.",
                    "label": 0
                },
                {
                    "sent": "OK, so the expectation of Y is just H. So we generate.",
                    "label": 0
                },
                {
                    "sent": "We generate all these samples XI, which for each sample we've defined a new random variable Yi and the expectation of Y is just the entropy.",
                    "label": 0
                },
                {
                    "sent": "Now by the law of large numbers, we know that if we generate a lot of samples.",
                    "label": 0
                },
                {
                    "sent": "Then then this average must converge to its expected value.",
                    "label": 0
                },
                {
                    "sent": "OK, so when you generate a lot of samples, the sum of the yiz is going to look very close to age.",
                    "label": 0
                },
                {
                    "sent": "What does that mean?",
                    "label": 0
                },
                {
                    "sent": "Well, if this sum of the yiz is within epsilon of age.",
                    "label": 0
                },
                {
                    "sent": "OK. OK, this so this event is going to happen with probability one.",
                    "label": 0
                },
                {
                    "sent": "As you increase the number of points OK. Well, the sum of the wise has a very nice form.",
                    "label": 0
                },
                {
                    "sent": "The sum of the wise is just the log.",
                    "label": 0
                },
                {
                    "sent": "This log of probability of X1 plus log probability of X2 plus log probability of X3.",
                    "label": 0
                },
                {
                    "sent": "Therefore it's just the log one over probability of the entire sequence.",
                    "label": 0
                },
                {
                    "sent": "OK, since the points are drawn independently.",
                    "label": 0
                },
                {
                    "sent": "And therefore what this tells us is that the probability you are off this particular sequence is going to lie within within epsilon of what we were calling the typical probability it's going to lie within two to the minus N. H minus epsilon in two to the minus H plus epsilon.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is this is another way in which this in which entropy turns out to be very natural.",
                    "label": 0
                },
                {
                    "sent": "In which entropy turns out to be a natural notion of randomness.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's return to our main question and see now that we have a notion of randomness, we can actually.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Try to formalize this question a little bit.",
                    "label": 0
                },
                {
                    "sent": "OK, so we had a large set which in this toy example was just English words.",
                    "label": 0
                },
                {
                    "sent": "We measured a bunch of features for each word.",
                    "label": 0
                },
                {
                    "sent": "OK, so for each word we define sacai features.",
                    "label": 0
                },
                {
                    "sent": "The first feature was just that the word has length more than five.",
                    "label": 0
                },
                {
                    "sent": "Now we wanted to find a distribution over over S and we wanted to find an assignment of probabilities to all the words.",
                    "label": 1
                },
                {
                    "sent": "That satisfied the constraints we'd observed.",
                    "label": 0
                },
                {
                    "sent": "OK, we observe that you know 30% of the words have length more than five, so that satisfies these particular constraints, but otherwise is is as random as possible, and now we can formalize that.",
                    "label": 0
                },
                {
                    "sent": "We can say that what we want is something that has maximum entropy subject to these constraints.",
                    "label": 0
                },
                {
                    "sent": "OK, and this is called the maximum entropy principle.",
                    "label": 1
                },
                {
                    "sent": "So now that we actually know a notion of entropy, we can actually formalize this as an optimization problem.",
                    "label": 0
                },
                {
                    "sent": "OK, let's see what the problem looks like.",
                    "label": 0
                },
                {
                    "sent": "So we're looking for.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Probability distribution P. It's over a set S which is English words.",
                    "label": 0
                },
                {
                    "sent": "OK, we can think of this.",
                    "label": 1
                },
                {
                    "sent": "Probability distribution is just a really long vector.",
                    "label": 0
                },
                {
                    "sent": "OK, so if the 50,000 words it's just a vector with 50,000 entries, which are all probabilities, and so they're all you know greater than or equal to 0, and they add up to one.",
                    "label": 0
                },
                {
                    "sent": "OK, so we have this that we have this vector.",
                    "label": 0
                },
                {
                    "sent": "It's entries apiece of X, that's the probability of X.",
                    "label": 0
                },
                {
                    "sent": "We want them to add up to one, and we want them all to be positive.",
                    "label": 0
                },
                {
                    "sent": "OK, so a reasonable probability distribution.",
                    "label": 0
                },
                {
                    "sent": "We want to find the thing that has maximum entropy subject to the constraints we observed and the constraints were that the expected values of these features had certain had certain were equal to something.",
                    "label": 0
                },
                {
                    "sent": "OK, so for instance, feature one that's I = 1.",
                    "label": 0
                },
                {
                    "sent": "Was simply one if the word had length more than five and zero otherwise.",
                    "label": 0
                },
                {
                    "sent": "And we wanted it to be the case that the expected value of that feature, the average value of that feature according to this distribution, was .3.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So so many questions about this this optimization problem.",
                    "label": 0
                },
                {
                    "sent": "Now that we have a notion of entropy, we have another way of notion of randomness.",
                    "label": 0
                },
                {
                    "sent": "We can write it down precisely.",
                    "label": 0
                },
                {
                    "sent": "So the nice thing about this is that the constraints turn out to be linear.",
                    "label": 0
                },
                {
                    "sent": "The thing that we're solving for is P. OK, we're solving for this vector.",
                    "label": 0
                },
                {
                    "sent": "These are linear constraints.",
                    "label": 0
                },
                {
                    "sent": "This is this is just a linear equation over here, so we have a bunch of linear constraints.",
                    "label": 0
                },
                {
                    "sent": "These define some sort of polyhedron, and the function we are optimizing is a concave function.",
                    "label": 0
                },
                {
                    "sent": "So this entire thing becomes a convex optimization problem, OK?",
                    "label": 1
                },
                {
                    "sent": "So convex optimization problem is just a generic is a generic term, which I mean even you know you might say OK with this.",
                    "label": 0
                },
                {
                    "sent": "Shouldn't this be a concave optimization problem?",
                    "label": 0
                },
                {
                    "sent": "Well, you know maximizing a concave thing is the same as minimizing the negative of it, which is a convex thing.",
                    "label": 0
                },
                {
                    "sent": "So we just call all of these things convex optimization problems.",
                    "label": 0
                },
                {
                    "sent": "This is the.",
                    "label": 0
                },
                {
                    "sent": "This is just the list of words in the dictionary.",
                    "label": 0
                },
                {
                    "sent": "OK, so if there's 50,000 of them, it's just the size of S is just 50,000.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is the thing we now want to solve.",
                    "label": 0
                },
                {
                    "sent": "OK, now this was in the case where I had no prior knowledge at all.",
                    "label": 0
                },
                {
                    "sent": "OK, this was the alien who just arrived on Earth and you know, just had this dictionary with him.",
                    "label": 0
                },
                {
                    "sent": "Saw the list of words and now wants to fit a distribution to this to this list of words.",
                    "label": 0
                },
                {
                    "sent": "OK, what if I had a little bit of prior knowledge?",
                    "label": 0
                },
                {
                    "sent": "Maybe I have already constructed some statistical model that you know I'm reasonably happy with, but you know, I looked at the model and I looked at this new data I have and it doesn't really fit.",
                    "label": 0
                },
                {
                    "sent": "So I kind of want, you know, I kind of want to stick with that model, but I also want to tweak it.",
                    "label": 0
                },
                {
                    "sent": "To accommodate this new data right, what happens in that case?",
                    "label": 0
                },
                {
                    "sent": "So in that case we have a prior Pi which is the previous statistical.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Model that you know we just cooked up in some way or the other.",
                    "label": 0
                },
                {
                    "sent": "And now what we want to do to know what we want to do is to find something that's close to Pi.",
                    "label": 0
                },
                {
                    "sent": "We don't want to go too far away from it, so we want to find something that's close to \u03c0 and yet satisfies these constraints that we've observed.",
                    "label": 0
                },
                {
                    "sent": "OK, so in other words, we want to find the distribution P that has the smallest KL divergent dippie.",
                    "label": 1
                },
                {
                    "sent": "Subject to these constraints.",
                    "label": 1
                },
                {
                    "sent": "OK, subject to be of course has to be a normal probability distribution and it should satisfy the constraints that I've actually observed.",
                    "label": 0
                },
                {
                    "sent": "OK about lengths of words etc etc.",
                    "label": 0
                },
                {
                    "sent": "Probabilities are different letter combinations.",
                    "label": 0
                },
                {
                    "sent": "This is also a convex optimization problem because this function is convex.",
                    "label": 1
                },
                {
                    "sent": "OK, so I'm minimizing a convex function over a bunch of linear constraints.",
                    "label": 0
                },
                {
                    "sent": "So one nice way to visualize the problem is to see it.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The projection OK.",
                    "label": 0
                },
                {
                    "sent": "So think of this whole board as being the simplex of probability distributions.",
                    "label": 1
                },
                {
                    "sent": "OK, So what is the simplex of probability distributions?",
                    "label": 0
                },
                {
                    "sent": "It's all valid vectors.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I'm looking at vectors of length 50,000.",
                    "label": 0
                },
                {
                    "sent": "Look at the set of all valid vectors.",
                    "label": 0
                },
                {
                    "sent": "In other words, all vectors of length 50,000 that add up to one and a non negative.",
                    "label": 0
                },
                {
                    "sent": "Let's call that the whole board.",
                    "label": 0
                },
                {
                    "sent": "OK. Now I have some vector over here which is my prior distribution by OK I have some new constraints and because they are linear constraints.",
                    "label": 0
                },
                {
                    "sent": "They define a linear subspace of the simplex.",
                    "label": 0
                },
                {
                    "sent": "OK, so they define a linear subspace of this starting 50,000 dimensional space that I have, and what I want to do is to project the prior onto that linear subspace.",
                    "label": 0
                },
                {
                    "sent": "OK, so I want to find the point on that linear subspace that's as close as possible to the prior.",
                    "label": 0
                },
                {
                    "sent": "Now, if the distance measure I was using was just Euclidean distance, then I would just kind of drop this point onto the subspace at a right angle, but it's not.",
                    "label": 0
                },
                {
                    "sent": "I'm using this weird, you know, KL divergent thing and so I get kind of a curve distance instead.",
                    "label": 0
                },
                {
                    "sent": "OK, it's a different distance measure.",
                    "label": 0
                },
                {
                    "sent": "You can't just pump it down, you can just plunk it down onto the.",
                    "label": 0
                },
                {
                    "sent": "Until the subspace OK, so this is geometrically the problem we're trying to solve.",
                    "label": 0
                },
                {
                    "sent": "We have our previous statistical model.",
                    "label": 0
                },
                {
                    "sent": "Our constraints define a linear subspace in the space of probability distributions in the probability simplex, and I want to project onto that subspace.",
                    "label": 1
                },
                {
                    "sent": "Why is Euclidean distance?",
                    "label": 0
                },
                {
                    "sent": "Hello, you could use the Euclidean distance, but we also we saw that the entropy is the is the most.",
                    "label": 0
                },
                {
                    "sent": "This.",
                    "label": 0
                },
                {
                    "sent": "In an axiomatic framework, the entropy was the only reasonable definition of randomness, and so once we are using the entropy, then we have to use this.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So if we if, for instance, our prior was the uniform distribution, what we would want is the maximum entropy distribution in this subspace, and that would be the KL distance to the uniform.",
                    "label": 0
                },
                {
                    "sent": "OK, so axiomatic framework has constrained doubts in that sense.",
                    "label": 0
                },
                {
                    "sent": "Great, so this is our problem and we saw that.",
                    "label": 0
                },
                {
                    "sent": "So this is what the problem looks like geometrically and we saw that when you actually write it out in terms of the equations, it turns out to be a convex optimization problem and that is really useful.",
                    "label": 0
                },
                {
                    "sent": "OK, so why does it help to have a convex thing?",
                    "label": 0
                },
                {
                    "sent": "Well, one OK on the most naive level you know it's convex.",
                    "label": 0
                },
                {
                    "sent": "It looks like this, which means that there's no local Optima.",
                    "label": 0
                },
                {
                    "sent": "You know you have this global solution, but that's just the tip of the iceberg.",
                    "label": 0
                },
                {
                    "sent": "The real thing is not just that you have that that global solution you have to worry about local Optima.",
                    "label": 0
                },
                {
                    "sent": "But it's that once it's expressed as a convex optimization problem.",
                    "label": 0
                },
                {
                    "sent": "You can just apply some standard kind of deterministic machinery to characterize the form of the solution.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's not just that we know that there's a unique solution and is the global optimum, but it's that because it's convex we can use various tricks to actually show that the solution has a very specific form.",
                    "label": 0
                },
                {
                    "sent": "It's very easy to find out the form of the solution.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's see how we do that.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's the problem.",
                    "label": 0
                },
                {
                    "sent": "We're trying to solve.",
                    "label": 0
                },
                {
                    "sent": "We're looking at all non negative vectors.",
                    "label": 0
                },
                {
                    "sent": "We're minimizing the KL divergences from \u03c0.",
                    "label": 0
                },
                {
                    "sent": "We have these linear constraints.",
                    "label": 0
                },
                {
                    "sent": "There has to be a probability thing it has to sum up to one.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's just apply the method of LaGrange multipliers.",
                    "label": 0
                },
                {
                    "sent": "So we're minimizing this quantity.",
                    "label": 0
                },
                {
                    "sent": "That's the KL divergent.",
                    "label": 0
                },
                {
                    "sent": "We include a LaGrange multiplier for each for each of these.",
                    "label": 0
                },
                {
                    "sent": "Constraints and we have a multiplier for this constraint as well.",
                    "label": 0
                },
                {
                    "sent": "So we have a total of K + 1 multipliers.",
                    "label": 0
                },
                {
                    "sent": "And now we take the derivative.",
                    "label": 0
                },
                {
                    "sent": "So we take the derivative of this thing with respect to the thing we're solving for piece of X.",
                    "label": 0
                },
                {
                    "sent": "So we actually solving for a whole vector, so we take the derivative with respect to one component at a time.",
                    "label": 0
                },
                {
                    "sent": "OK, when the smoke clears, this is what the derivative turns out to be.",
                    "label": 0
                },
                {
                    "sent": "You have to set the derivative to zero, and when you do that you find that the distribution has a very specific form.",
                    "label": 0
                },
                {
                    "sent": "OK, now you can apply the law.",
                    "label": 0
                },
                {
                    "sent": "You can do this LaGrange multiplier thing anytime you like, even when there are lots of local Optima.",
                    "label": 0
                },
                {
                    "sent": "But in the case of a convex optimization problem, you know that the solution has to have this form OK, so.",
                    "label": 0
                },
                {
                    "sent": "So, so here's the form.",
                    "label": 0
                },
                {
                    "sent": "It's the prior distribution that we started with.",
                    "label": 0
                },
                {
                    "sent": "OK times.",
                    "label": 0
                },
                {
                    "sent": "E to the linear function of the features OK. And then there's some normalizer in front because although this as summed up to one once you multiply by this thing, who knows it is going to sum up to one anymore.",
                    "label": 0
                },
                {
                    "sent": "OK, so you take your prior and you multiply it by this thing.",
                    "label": 0
                },
                {
                    "sent": "And it turns out that this is actually a very.",
                    "label": 0
                },
                {
                    "sent": "This is this is a very very common type of distribution and it's called an exponential family.",
                    "label": 0
                },
                {
                    "sent": "This would be called the exponential family generated by Phi.",
                    "label": 1
                },
                {
                    "sent": "OK, so the maximum entropy.",
                    "label": 0
                },
                {
                    "sent": "The maximum entropy principle has brought us to the exponential family of distributions OK and and.",
                    "label": 0
                },
                {
                    "sent": "And so, let's let let's look more at exponential family.",
                    "label": 0
                },
                {
                    "sent": "But first let's just peek at what the what the form of our particular.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Problem with the form of the solution was for our particular problem.",
                    "label": 1
                },
                {
                    "sent": "OK, so we have this toy problem and now when we look at this solution what it's saying is that it looks like there's some normalization factor.",
                    "label": 0
                },
                {
                    "sent": "So I'm just saying proportional.",
                    "label": 0
                },
                {
                    "sent": "But otherwise it has a very simple form.",
                    "label": 0
                },
                {
                    "sent": "It's just he to the sum linear function of the features.",
                    "label": 0
                },
                {
                    "sent": "OK, and this is just really convenient because our priority, we had no idea that the solution was going to be so convenient after all we were solving for a general vector of length 50,000.",
                    "label": 0
                },
                {
                    "sent": "It could have been that the solution would require us to write it down as a table with a different number for each particular word, but instead we got this solution that has this amazingly convenient functional form.",
                    "label": 0
                },
                {
                    "sent": "It's something that we can express very compactly, and it's something that we can even you know, we might even be able to understand.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's a linear function of the features.",
                    "label": 0
                },
                {
                    "sent": "OK, So what do these things mean?",
                    "label": 0
                },
                {
                    "sent": "What do these these coefficients, which as we've seen, actually LaGrange multipliers?",
                    "label": 0
                },
                {
                    "sent": "What do these things mean?",
                    "label": 1
                },
                {
                    "sent": "Well, for instance, if Lambda two is .81.",
                    "label": 1
                },
                {
                    "sent": "This means that.",
                    "label": 0
                },
                {
                    "sent": "If the word ends in E, then you Jack up its probability by a factor of E to the .8 one.",
                    "label": 0
                },
                {
                    "sent": "2.25.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is the sort of interpretation of these LaGrange multipliers.",
                    "label": 0
                },
                {
                    "sent": "OK, great.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "OK, so we formulated this maximum entropy problem an you know this worked out very well for us because it gave us a distribution that now has this very convenient functional form.",
                    "label": 0
                },
                {
                    "sent": "OK, and I said that that actually the maximum that the.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Solution to this problem in general was just an exponential family.",
                    "label": 0
                },
                {
                    "sent": "So what are these exponential families?",
                    "label": 0
                },
                {
                    "sent": "What is this thing exponential family of distributions?",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So it turns out that if you look at the statisticians grab bag of distributions, you know the distribution that pop up everywhere.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The Gaussian is all over the place because the central limit theorem for soil is all over the place because of the law of small numbers.",
                    "label": 0
                },
                {
                    "sent": "Binomial, the Bernoulli distribution.",
                    "label": 0
                },
                {
                    "sent": "That was the you know that the 1st and most basic distribution you know just straight from the gambling tables, right?",
                    "label": 0
                },
                {
                    "sent": "So all of these distributions turn out to be exponential families OK, and what one would say is 1 would say that the Gaussian is an exponential family of distributions, each of them is a whole family of distributions.",
                    "label": 0
                },
                {
                    "sent": "It's an exponential family.",
                    "label": 0
                },
                {
                    "sent": "So what is this thing?",
                    "label": 0
                },
                {
                    "sent": "What is this exponential family?",
                    "label": 0
                },
                {
                    "sent": "How exactly is it defined, and what is it by us to think of?",
                    "label": 0
                },
                {
                    "sent": "What is it by us to look at things in this generality in the generality of exponential families?",
                    "label": 0
                },
                {
                    "sent": "So let's define an exponential family in order to define.",
                    "label": 1
                },
                {
                    "sent": "In order to do this, you need three things.",
                    "label": 0
                },
                {
                    "sent": "First you start off with some input space OK. Then you have some sort of base measure.",
                    "label": 0
                },
                {
                    "sent": "On the space which you can think of as a prior OK.",
                    "label": 0
                },
                {
                    "sent": "So actually I have a little I have.",
                    "label": 0
                },
                {
                    "sent": "This is actually a typo.",
                    "label": 0
                },
                {
                    "sent": "You don't actually need the input space to be part of.",
                    "label": 0
                },
                {
                    "sent": "Of RR is just an arbitrary input space.",
                    "label": 0
                },
                {
                    "sent": "It's just that the base measure would then have to be on this input space OK, and So what is the base measure?",
                    "label": 0
                },
                {
                    "sent": "Well, you can think of it like the prior, but in general for the time being you can just think of the base measure as being one.",
                    "label": 1
                },
                {
                    "sent": "OK, so you need an input space.",
                    "label": 0
                },
                {
                    "sent": "You need a base measure, which let's just think of as being one, and now you need to choose a bunch of features and once you specify these three things, you have an exponential family.",
                    "label": 0
                },
                {
                    "sent": "OK, So what do these things look like?",
                    "label": 0
                },
                {
                    "sent": "Well, the exponential family generated by this particular base measure, and this particular choice of features.",
                    "label": 1
                },
                {
                    "sent": "Just consists of distributions of this form distributions where the probability of X is proportional to whatever the base measure is.",
                    "label": 0
                },
                {
                    "sent": "Times E to the linear function of the of the features.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So each of these distributions is parameterized by a K dimensional vector.",
                    "label": 0
                },
                {
                    "sent": "Pair these with this key K dimensional vector specifies the linear combination of the features that goes into this exponent.",
                    "label": 0
                },
                {
                    "sent": "Great so.",
                    "label": 0
                },
                {
                    "sent": "OK, so as it stands this is looking.",
                    "label": 0
                },
                {
                    "sent": "You know this is not even normalized.",
                    "label": 0
                },
                {
                    "sent": "I haven't even, you know it's right now, it's just a proportion, right?",
                    "label": 0
                },
                {
                    "sent": "So what do we do?",
                    "label": 0
                },
                {
                    "sent": "We at least.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To normalize it, right so we have this input space, we've got a base measure.",
                    "label": 1
                },
                {
                    "sent": "We've got our features and we're saying that we're going to look at distributions of this form.",
                    "label": 0
                },
                {
                    "sent": "OK, so to normalize it we have to stick some normalization constant in the front.",
                    "label": 0
                },
                {
                    "sent": "OK, this normalization constant is going to be a different number for every eight.",
                    "label": 0
                },
                {
                    "sent": "Are each ETA is a different parameter.",
                    "label": 0
                },
                {
                    "sent": "And it defines a different distribution.",
                    "label": 0
                },
                {
                    "sent": "So for each one there's a different normalization.",
                    "label": 0
                },
                {
                    "sent": "It turns out that the way we usually write this is actually to put the normalization in the exponent.",
                    "label": 0
                },
                {
                    "sent": "So instead of writing it right in front over there, we pull it into the exponent, which is no problem at all, and we write it over here.",
                    "label": 0
                },
                {
                    "sent": "OK, so this G is the normalization tool.",
                    "label": 0
                },
                {
                    "sent": "So the G is set so that it's just the.",
                    "label": 0
                },
                {
                    "sent": "So that everything comes out to one, so it's just whatever we had.",
                    "label": 0
                },
                {
                    "sent": "Otherwise we just sum it up.",
                    "label": 0
                },
                {
                    "sent": "OK, so the normalization would just be the sum of all these things.",
                    "label": 0
                },
                {
                    "sent": "That's what G is.",
                    "label": 0
                },
                {
                    "sent": "And since we moved it into the exponent, we have to take the log of it.",
                    "label": 0
                },
                {
                    "sent": "And this thing is called the log partition function.",
                    "label": 1
                },
                {
                    "sent": "Now this thing is going to assume sort of larger significance later on.",
                    "label": 0
                },
                {
                    "sent": "As it stands, it seems like this G is no big deal, right?",
                    "label": 0
                },
                {
                    "sent": "It's just.",
                    "label": 0
                },
                {
                    "sent": "With just some number we gotta stick in front to normalize the thing.",
                    "label": 0
                },
                {
                    "sent": "OK, but but it turns out that this is going to have many interesting properties Now this some might not even exist.",
                    "label": 0
                },
                {
                    "sent": "It might be that this is infinite, in which case we can't allow that particular value of ater.",
                    "label": 1
                },
                {
                    "sent": "So the natural parameter space is the set of eight's for which you can actually, which can actually normalizable.",
                    "label": 1
                },
                {
                    "sent": "OK, which actually correspond to valid distributions, so that's a natural parameter space.",
                    "label": 0
                },
                {
                    "sent": "So let's look at an example.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I said for for to find an exponential family you know you start with three things and that uniquely defines the family.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's look at.",
                    "label": 0
                },
                {
                    "sent": "Suppose I was claiming Bernoulli is an exponential family.",
                    "label": 0
                },
                {
                    "sent": "So one of the three things we need, we need the base set, which we know is 01.",
                    "label": 0
                },
                {
                    "sent": "The base measure 1.",
                    "label": 0
                },
                {
                    "sent": "And we have some flexibility in the choice of features, but since it's just zero and one there are only the only feature that it makes sense to choose is T of X = X, you can throw in other stuff like X, ^2, X cube.",
                    "label": 0
                },
                {
                    "sent": "But it's not giving you any extra information.",
                    "label": 0
                },
                {
                    "sent": "OK, and once we've chosen these things, the exponential family is uniquely defined.",
                    "label": 0
                },
                {
                    "sent": "OK, after this, everything set it's deterministic.",
                    "label": 0
                },
                {
                    "sent": "So we set these things down.",
                    "label": 0
                },
                {
                    "sent": "And now let's look at the exponential family.",
                    "label": 0
                },
                {
                    "sent": "We get.",
                    "label": 0
                },
                {
                    "sent": "Well, we know the functional form is going to be that we're going to have these distributions indexed by ETA.",
                    "label": 0
                },
                {
                    "sent": "And the probability is going to be proportional to each of the 8X.",
                    "label": 0
                },
                {
                    "sent": "OK, so now we need this thing to normalize so well X has only two values, zero and one.",
                    "label": 0
                },
                {
                    "sent": "So we get E to the 0 plus each of the ETA.",
                    "label": 1
                },
                {
                    "sent": "So a normalization factor is just the lawn of this.",
                    "label": 0
                },
                {
                    "sent": "The natural logarithm of this and this is the log partition function.",
                    "label": 1
                },
                {
                    "sent": "Any questions about this?",
                    "label": 0
                },
                {
                    "sent": "Great.",
                    "label": 0
                },
                {
                    "sent": "So this turns out to be defined for all eighters because we never have to worry about this being infinite and therefore the natural parameter space is simply the reals.",
                    "label": 1
                },
                {
                    "sent": "So let's look at the distribution.",
                    "label": 0
                },
                {
                    "sent": "Since the parameter space in the reals, let's look at the distribution we get when we have parameter ETA.",
                    "label": 0
                },
                {
                    "sent": "OK, when we have A to, the distribution looks like this, it's each of the 8X and we have to multiply by the normalization constant, which is this.",
                    "label": 0
                },
                {
                    "sent": "OK, in other words, the probability of a .0 is just one over the normalizer.",
                    "label": 0
                },
                {
                    "sent": "The probability of one is each of the H over the normalizer.",
                    "label": 0
                },
                {
                    "sent": "Certainly a bona fide Bernoulli distribution OK?",
                    "label": 0
                },
                {
                    "sent": "So the only problem over here is that although this is a Bernoulli distribution, we're not used to these parameters.",
                    "label": 0
                },
                {
                    "sent": "Normally when we specify a Bernoulli, we specified according to the heads probability.",
                    "label": 0
                },
                {
                    "sent": "Now we have this weird formalization in which it's specified according to this so called natural parameter that's actually a number between minus Infinity and plus Infinity.",
                    "label": 0
                },
                {
                    "sent": "So what's the deal over here?",
                    "label": 0
                },
                {
                    "sent": "You know?",
                    "label": 0
                },
                {
                    "sent": "So, so there's this natural parameter, and certainly it specifies all the Bernoulli's.",
                    "label": 0
                },
                {
                    "sent": "Any Bernoulli distribution can be written this way.",
                    "label": 0
                },
                {
                    "sent": "If you want this to be your probability P, you just solve the ETA.",
                    "label": 1
                },
                {
                    "sent": "That's no problem at all.",
                    "label": 0
                },
                {
                    "sent": "But the parameterisation is not the one we're accustomed to.",
                    "label": 0
                },
                {
                    "sent": "We're accustomed to parameterising this between zero and one, not between minus Infinity and plus Infinity.",
                    "label": 0
                },
                {
                    "sent": "OK, and so.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you look at the, if you look at the the thing over here.",
                    "label": 0
                },
                {
                    "sent": "The natural parameters line the range from minus Infinity to plus Infinity and minus Infinity corresponds to a coin with bias 0 plus Infinity corresponds to a coin with bias one.",
                    "label": 0
                },
                {
                    "sent": "And there's this mapping from these natural parameters to the.",
                    "label": 0
                },
                {
                    "sent": "To this.",
                    "label": 0
                },
                {
                    "sent": "To this parameters we're more used to the actual bias of the coin.",
                    "label": 0
                },
                {
                    "sent": "So so the weird thing about these natural parameters is that although they're the ones that are mathematically natural, they don't actually necessarily correspond to the parameters that are natural for us.",
                    "label": 0
                },
                {
                    "sent": "So we end up having these two different parameter spaces when we talk about exponential families, we have the natural parameters, which is the space of the models themselves.",
                    "label": 0
                },
                {
                    "sent": "One this is the one that the math wants.",
                    "label": 0
                },
                {
                    "sent": "And then this is the one that's more convenient for us.",
                    "label": 0
                },
                {
                    "sent": "These are the expectation parameters.",
                    "label": 0
                },
                {
                    "sent": "These are the actual mean of the distribution.",
                    "label": 0
                },
                {
                    "sent": "OK, so in exponential families we always juggling these two spaces, and there's a one to one map between them, and you can see this particular map over here.",
                    "label": 0
                },
                {
                    "sent": "Let's look at another example.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Which will derive in a different way.",
                    "label": 0
                },
                {
                    "sent": "OK, so now let's look at Apostle and distribution.",
                    "label": 0
                },
                {
                    "sent": "Now Apostle Theater Distribution is a distribution over integers or a distribution over non negative integers and it has mean theater and variance data as well.",
                    "label": 0
                },
                {
                    "sent": "It's got the same mean and variance and this is the functional form of the distribution.",
                    "label": 0
                },
                {
                    "sent": "The probability of any given X, which in this case is a non negative integer is each of the minus theater translator to be X / X factorial.",
                    "label": 0
                },
                {
                    "sent": "So why is this an exponential family?",
                    "label": 0
                },
                {
                    "sent": "OK, in order to show that we kind of have to massage it into the right form.",
                    "label": 0
                },
                {
                    "sent": "So let's try and rewrite it.",
                    "label": 0
                },
                {
                    "sent": "Well, you can write it like this data to the X is Y to the excellent ETA we get the minus, Theta and now it looks much more like an exponential family form.",
                    "label": 0
                },
                {
                    "sent": "This is the base measure will be here.",
                    "label": 1
                },
                {
                    "sent": "The HX.",
                    "label": 0
                },
                {
                    "sent": "This looks like we have.",
                    "label": 0
                },
                {
                    "sent": "This is just some linear function of X, which is exactly the form we wanted.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So so so.",
                    "label": 0
                },
                {
                    "sent": "So now our base base is the non negative integers are based measure is just 1 / X factorial.",
                    "label": 0
                },
                {
                    "sent": "And our feature is just X itself.",
                    "label": 0
                },
                {
                    "sent": "We just need a single feature.",
                    "label": 0
                },
                {
                    "sent": "So now when we find the log partition function.",
                    "label": 1
                },
                {
                    "sent": "Well, so once once we've specified these three things, we know the rest is deterministic.",
                    "label": 0
                },
                {
                    "sent": "We know that the functional form must be this.",
                    "label": 0
                },
                {
                    "sent": "And to find the log partition function we just normalize, we just sum, we just sum this over all possibilities.",
                    "label": 0
                },
                {
                    "sent": "OK, well this is quite an easy sumby cause because it looks like the Taylor series for each of the.",
                    "label": 0
                },
                {
                    "sent": "The Taylor series expansion of the exponential, so it's just each of the ETA.",
                    "label": 0
                },
                {
                    "sent": "The log partition function is just each of the ETA, and once again we don't have the natural parameters.",
                    "label": 0
                },
                {
                    "sent": "OK, well once again our natural parameters are not.",
                    "label": 0
                },
                {
                    "sent": "The ones are not the ones we are familiar with.",
                    "label": 0
                },
                {
                    "sent": "The natural parameter space occupies the entire real line.",
                    "label": 0
                },
                {
                    "sent": "And the ones we are interested in are actually each of the natural parameter.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So in this case, the natural parameter is long of Theta.",
                    "label": 0
                },
                {
                    "sent": "OK. Let's do.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "One more example, and this one's a little trickier because the we need more than one feature.",
                    "label": 0
                },
                {
                    "sent": "OK, so we have a Gaussian with mean mu and variance Sigma squared.",
                    "label": 1
                },
                {
                    "sent": "So this is the form of the Gaussian, and now we want to write this as an exponential family.",
                    "label": 0
                },
                {
                    "sent": "As an exponential family distribution.",
                    "label": 0
                },
                {
                    "sent": "If you expand out the square, you end up with terms both in X&X squared, so you need to pick.",
                    "label": 0
                },
                {
                    "sent": "You need to pick two features.",
                    "label": 0
                },
                {
                    "sent": "X has to be a feature, and X squared also has to be a feature.",
                    "label": 0
                },
                {
                    "sent": "And if you pick both of these then you can write the exponent as a linear function.",
                    "label": 0
                },
                {
                    "sent": "OK, so in this case our base set is just R based measures.",
                    "label": 0
                },
                {
                    "sent": "You know, for convenience I set it to 1 / 2\u03c0.",
                    "label": 0
                },
                {
                    "sent": "I could just make it uniform constants don't matter.",
                    "label": 0
                },
                {
                    "sent": "And I need to pick two features now for this is not sufficient to just pick one feature, so I pick X and X ^2.",
                    "label": 0
                },
                {
                    "sent": "And now just from this I can read off what the natural parameter is going to be.",
                    "label": 0
                },
                {
                    "sent": "And once again, we can compute the log partition function, and in this case the natural parameter space is R * R minus.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So so fine.",
                    "label": 0
                },
                {
                    "sent": "So there are a lot of these distributions that are clearly important standard distributions, and we found that these can be coerced into the exponential family form, right?",
                    "label": 0
                },
                {
                    "sent": "But what is it by us to actually deal with this formalism, you know?",
                    "label": 0
                },
                {
                    "sent": "Is it the case that the you know when we first looked at the exponential family thing, it looked like it was really specific.",
                    "label": 0
                },
                {
                    "sent": "It's you know what kind of distributions could possibly have that form now?",
                    "label": 0
                },
                {
                    "sent": "It seems like it might be too general.",
                    "label": 0
                },
                {
                    "sent": "You know.",
                    "label": 0
                },
                {
                    "sent": "We effortlessly expressed the Bernoulli, the POS, or the Gaussian is exponential family.",
                    "label": 0
                },
                {
                    "sent": "Models right?",
                    "label": 0
                },
                {
                    "sent": "Is it so general that it's not useful for us?",
                    "label": 0
                },
                {
                    "sent": "You know why?",
                    "label": 0
                },
                {
                    "sent": "Why are we what's so good about this exponential family?",
                    "label": 0
                },
                {
                    "sent": "What is special about exponential family distributions?",
                    "label": 0
                },
                {
                    "sent": "And it turns out that a lot of the special properties of this distribution lie where one initial.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We would not expect it to lie, namely in the log partition function.",
                    "label": 0
                },
                {
                    "sent": "OK, so the way this log partition function came about is that it was just the normalizer.",
                    "label": 0
                },
                {
                    "sent": "You know it's just the thing you kind of tack on in front to make it all add up to one.",
                    "label": 0
                },
                {
                    "sent": "However, it turns out that this normalizer actually contains a wealth of information about the distribution.",
                    "label": 0
                },
                {
                    "sent": "And we're going to use its properties quite heavily.",
                    "label": 0
                },
                {
                    "sent": "When we when we get back to maximum entropy.",
                    "label": 0
                },
                {
                    "sent": "OK, so first.",
                    "label": 0
                },
                {
                    "sent": "First of all, it turns out that this thing is strictly convex.",
                    "label": 1
                },
                {
                    "sent": "OK, so for instance, the awesome.",
                    "label": 0
                },
                {
                    "sent": "Also, in case it was E to the ADA.",
                    "label": 0
                },
                {
                    "sent": "OK, so the exponent which is, you know, which looks like this.",
                    "label": 0
                },
                {
                    "sent": "It's a strictly convex function, OK?",
                    "label": 1
                },
                {
                    "sent": "Among other things, it means that its derivative is 1 to one.",
                    "label": 0
                },
                {
                    "sent": "OK, so if you have a strictly convex function and you look at its derivative, well, the derivative is increasing.",
                    "label": 0
                },
                {
                    "sent": "It's a one to one to one to one function.",
                    "label": 0
                },
                {
                    "sent": "The derivative actually has other properties.",
                    "label": 0
                },
                {
                    "sent": "The derivative turns out to simply be the mean of the distribution.",
                    "label": 1
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So if you take the derivative of this log partition function so this log partition function, you just compute its first derivative and that turns out to be the mean of the distribution.",
                    "label": 0
                },
                {
                    "sent": "The expected value under random draws from that distribution of of the feature vector.",
                    "label": 0
                },
                {
                    "sent": "OK, so so why is this the case where let's in general the feature vector has many components that ETA one ETA two?",
                    "label": 0
                },
                {
                    "sent": "So on, let's take the derivative with respect to the right component.",
                    "label": 0
                },
                {
                    "sent": "You take the derivative of this with respect to Theta with respect to Ada I.",
                    "label": 0
                },
                {
                    "sent": "Well, the derivative log X is just you know 1 / X DX, so it's it's one over this thing times the derivative of the top, which is this.",
                    "label": 0
                },
                {
                    "sent": "OK. And now you can see that this is just the probability of, so it's just the expectation of that particular feature.",
                    "label": 1
                },
                {
                    "sent": "OK, and there's and if you do the similar thing for the variable for the second derivative, you get the variance of the distribution.",
                    "label": 0
                },
                {
                    "sent": "OK, so just by taking the first derivative second derivative of the log partition function, we end up getting the moments of the distribution.",
                    "label": 0
                },
                {
                    "sent": "OK, so there's a wealth of information contained in this log partition function.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So, So what else you know?",
                    "label": 0
                },
                {
                    "sent": "Well, in what other ways this exponential family unique?",
                    "label": 0
                },
                {
                    "sent": "OK, what is what is special about why we singled out these distributions as being important?",
                    "label": 0
                },
                {
                    "sent": "Once you know what else is unique about them?",
                    "label": 0
                },
                {
                    "sent": "So the real the real benefit comes when you start looking at maximum likelihood estimation.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So suppose you're dealing with some exponential family.",
                    "label": 1
                },
                {
                    "sent": "OK, and as we've seen to specify, an exponential family, just specify the base measure and the features you're going to look at.",
                    "label": 0
                },
                {
                    "sent": "So suppose we're dealing with some exponential family, and now we see a bunch of data and we want to find the best member of the family.",
                    "label": 0
                },
                {
                    "sent": "OK, so for instance, we see a bunch of points and we want to Gaussian to them.",
                    "label": 0
                },
                {
                    "sent": "So let's find the maximum likelihood choice of the parameter.",
                    "label": 0
                },
                {
                    "sent": "OK, so you just plug into this.",
                    "label": 0
                },
                {
                    "sent": "We want to maximize the log likelihood.",
                    "label": 0
                },
                {
                    "sent": "So take the log of this.",
                    "label": 0
                },
                {
                    "sent": "It's 8 * T of XI minus G of beta.",
                    "label": 0
                },
                {
                    "sent": "Plus log of HXI.",
                    "label": 0
                },
                {
                    "sent": "You rewrite it because you can pull the data out.",
                    "label": 0
                },
                {
                    "sent": "OK, you get the sum of these ties and these.",
                    "label": 0
                },
                {
                    "sent": "This is just a constant and now you get the sum of the log of excise.",
                    "label": 0
                },
                {
                    "sent": "And to maximize this you set the derivative and you take the derivative.",
                    "label": 0
                },
                {
                    "sent": "You set it to 0.",
                    "label": 0
                },
                {
                    "sent": "Well, if you do that.",
                    "label": 0
                },
                {
                    "sent": "What you're doing is you're setting the derivative of the log partition function to simply the the average of the data you saw.",
                    "label": 1
                },
                {
                    "sent": "And that's the maximum likelihood choice.",
                    "label": 1
                },
                {
                    "sent": "OK, we saw that the derivative of the log partition function is simply the mean of the distribution.",
                    "label": 1
                },
                {
                    "sent": "So the maximum likelihood choice is is very simple.",
                    "label": 0
                },
                {
                    "sent": "You just take all your data.",
                    "label": 0
                },
                {
                    "sent": "You take the average and now you pick the model that has exactly that same mean.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So this is.",
                    "label": 0
                },
                {
                    "sent": "So This is why these models are so useful.",
                    "label": 0
                },
                {
                    "sent": "You know, in a lot of modeling context, when you have a lot of data and you want to fit a model to it, you actually need to keep the data around.",
                    "label": 0
                },
                {
                    "sent": "You know if you're fitting a linear classifier to it, you need to keep all the labeled points around and you give it to some sort of, you know, give it to some routine that juggles them and come in and spits out a linear classifier.",
                    "label": 0
                },
                {
                    "sent": "In this exponential family models, you can have a vast amount of data, but you don't need to keep it around.",
                    "label": 0
                },
                {
                    "sent": "All you need is the average and once you have the average you can.",
                    "label": 0
                },
                {
                    "sent": "You can find the best fit model without any problem at all.",
                    "label": 0
                },
                {
                    "sent": "OK, so these exponential family distributions are the ones that in order to fit them you just need to keep the average of the data.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah, modulo some.",
                    "label": 0
                },
                {
                    "sent": "You know modulo some niceness conditions, etc.",
                    "label": 0
                },
                {
                    "sent": "So OK, so let's look at an example.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So you have a bunch of data and you find that the mean is 7.5.",
                    "label": 0
                },
                {
                    "sent": "What's the what person should you fit to it?",
                    "label": 0
                },
                {
                    "sent": "It's easy, whatever plus or has mean 7.5 OK.",
                    "label": 0
                },
                {
                    "sent": "But this is where the this is, where a little problem comes up between the two types of parameterisations of these distributions OK.",
                    "label": 0
                },
                {
                    "sent": "The one we you know for us it's fine to say yeah, we're just going to pick the fossil with mean 7.5.",
                    "label": 0
                },
                {
                    "sent": "But that's not the natural parameter of these possible distributions.",
                    "label": 0
                },
                {
                    "sent": "OK, So what is the natural parameter for the person which has been 7.5?",
                    "label": 1
                },
                {
                    "sent": "OK, so in the case of possum, it turns out to be easy.",
                    "label": 0
                },
                {
                    "sent": "We know that the log partition function is just each of the ADA.",
                    "label": 0
                },
                {
                    "sent": "So the derivative is also each of the ETA OK, which means, and this is the mean of the distribution.",
                    "label": 0
                },
                {
                    "sent": "So we just set this to be 7.5.",
                    "label": 0
                },
                {
                    "sent": "And therefore it has long 7.5.",
                    "label": 0
                },
                {
                    "sent": "So in the case of the plus, so it's easy to go from the expectation parameter, which is 7.5 to the natural parameter, just just the natural logarithm of 7.5.",
                    "label": 1
                },
                {
                    "sent": "But in general it's not always easy to invert this function G prime is not always easy to say.",
                    "label": 0
                },
                {
                    "sent": "OK, these are the means I want.",
                    "label": 0
                },
                {
                    "sent": "What is the corresponding natural parameter that can be a hard problem?",
                    "label": 0
                },
                {
                    "sent": "And if we look back at all.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Problem, unfortunately, that's one of these.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "You know, we know what the not.",
                    "label": 0
                },
                {
                    "sent": "We know what the expectations are of all of these features.",
                    "label": 0
                },
                {
                    "sent": "That's what we started with.",
                    "label": 0
                },
                {
                    "sent": "We know the expected value of this is point .3.",
                    "label": 1
                },
                {
                    "sent": "We know the expected value of this is .4 or whatever, but that doesn't help us in figuring out what these parameters should be.",
                    "label": 0
                },
                {
                    "sent": "How do we find the setting of these parameters that gives the right expected value for the distribution?",
                    "label": 0
                },
                {
                    "sent": "OK, this is not an easy problem and so the way to think of these two spaces is that we have this natural parameter space.",
                    "label": 0
                },
                {
                    "sent": "These are the parameters we want.",
                    "label": 0
                },
                {
                    "sent": "But the space in which the detail lies is a different space.",
                    "label": 0
                },
                {
                    "sent": "OK, and we can compute averages in that space.",
                    "label": 0
                },
                {
                    "sent": "So we compute averages and we got this, you know.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So maybe we had a data point here, one here, one here, one here, one here, and we computed the average and we got this.",
                    "label": 0
                },
                {
                    "sent": "OK, this was the just the average of all the data and now we want to go back and we want to find the natural parameter that corresponds to that, and that's not an easy problem.",
                    "label": 0
                },
                {
                    "sent": "OK, we've got this one to one map.",
                    "label": 0
                },
                {
                    "sent": "We saw the G prime is a one to one relationship because G is strictly convex.",
                    "label": 0
                },
                {
                    "sent": "But it's hard to go backwards.",
                    "label": 0
                },
                {
                    "sent": "OK, so in summary, when you have an exponent when you're dealing with exponential families of distributions.",
                    "label": 0
                },
                {
                    "sent": "Finding the Mike maximum likelihood distribution is in some sense an easy task.",
                    "label": 1
                },
                {
                    "sent": "But only if you're using the expectation parameterisation.",
                    "label": 0
                },
                {
                    "sent": "If you're just looking for an expectation parameter, it's the easiest thing in the world to fit one of these models.",
                    "label": 0
                },
                {
                    "sent": "You just set it to the average of the data, but if you're looking for natural parameters then it's a little harder.",
                    "label": 0
                },
                {
                    "sent": "It becomes a convex optimization problem, so why is it a convex optimization problem?",
                    "label": 0
                },
                {
                    "sent": "Well, let's go back to the equation.",
                    "label": 0
                },
                {
                    "sent": "This is what we're trying to solve.",
                    "label": 0
                },
                {
                    "sent": "We're trying to find we're trying to maximize this quantity.",
                    "label": 0
                },
                {
                    "sent": "Well, we saw the G is strictly convex and everything else is just linear.",
                    "label": 0
                },
                {
                    "sent": "So far, so maximizing this equation.",
                    "label": 0
                },
                {
                    "sent": "This is a convex optimization problem.",
                    "label": 1
                },
                {
                    "sent": "OK, so the problem we want to solve.",
                    "label": 0
                },
                {
                    "sent": "The parameters for our model over here.",
                    "label": 0
                },
                {
                    "sent": "This is a convex optimization problem.",
                    "label": 0
                },
                {
                    "sent": "And this is the thing that we were calling information project.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's see how you actually solve this problem.",
                    "label": 0
                },
                {
                    "sent": "You know how can you go about solving this thing?",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So so just to kind of recap and just to step back a little bit.",
                    "label": 0
                },
                {
                    "sent": "How do we get to this point OK?",
                    "label": 0
                },
                {
                    "sent": "So we started with the problem, which was a maximum entropy problem.",
                    "label": 0
                },
                {
                    "sent": "OK, we have this toy problem.",
                    "label": 0
                },
                {
                    "sent": "We want to fit a model that makes as few assumptions as possible subject to given constraints.",
                    "label": 0
                },
                {
                    "sent": "We found that the solution to maximum entropy problems are always exponential families of distributions.",
                    "label": 1
                },
                {
                    "sent": "OK, and now we actually want to solve for these distributions.",
                    "label": 0
                },
                {
                    "sent": "OK, so here was the here's a general form of the question we started with.",
                    "label": 0
                },
                {
                    "sent": "We had a bunch of priors.",
                    "label": 0
                },
                {
                    "sent": "Who knows we had this.",
                    "label": 0
                },
                {
                    "sent": "We had a prior knowledge wiki this our earlier statistical model.",
                    "label": 0
                },
                {
                    "sent": "Now we have some observations that we make based on, say, a small sample of data that we collect.",
                    "label": 0
                },
                {
                    "sent": "And now we want to update our prior.",
                    "label": 0
                },
                {
                    "sent": "We want to choose a distribution that's really close to the prior.",
                    "label": 0
                },
                {
                    "sent": "But also satisfies these constraints.",
                    "label": 1
                },
                {
                    "sent": "And it turned out that the solution to this is to choose the distribution to be an exponential family model.",
                    "label": 0
                },
                {
                    "sent": "Specifically, the solution to this is the unique member of the exponential family generated by Pianti.",
                    "label": 1
                },
                {
                    "sent": "Which actually satisfies which which has the given expectations.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So pianti.",
                    "label": 0
                },
                {
                    "sent": "The prior Pi and the features T uniquely define an exponential family of distributions and we just have to pick the one that has the given expectations.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's look at an example of this right?",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So suppose I just tell you that look, there's some distribution and I know it's mean is zero and the expected value of X squared is 10.",
                    "label": 0
                },
                {
                    "sent": "What distribution should I choose now?",
                    "label": 1
                },
                {
                    "sent": "Of course, there's infinitely many distributions that have these expected values.",
                    "label": 0
                },
                {
                    "sent": "OK, there's no.",
                    "label": 0
                },
                {
                    "sent": "There's no shortage of them, but if you were to make the maximum entropy choice, the answer is very simple.",
                    "label": 0
                },
                {
                    "sent": "OK, we have a distribution over R. OK, so that's our base space.",
                    "label": 1
                },
                {
                    "sent": "We found two expectations, so the features we want are X and X ^2.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 1
                },
                {
                    "sent": "This generates the Gaussian.",
                    "label": 0
                },
                {
                    "sent": "These are the features that generate the Gaussian family of distributions.",
                    "label": 0
                },
                {
                    "sent": "So now all we have to do is to pick the Gaussian that has this mean and this expected value of X squared.",
                    "label": 0
                },
                {
                    "sent": "In other words, this variance.",
                    "label": 0
                },
                {
                    "sent": "OK, and that's just the Gaussian zero 10.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is the maximum entropy choice, so if you were following the maximum entropy principle, this would be the distribution that you would pick.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so over here implicitly I've chosen a base measure that is uniform.",
                    "label": 0
                },
                {
                    "sent": "OK, that's just flat, because the base measure corresponding to the.",
                    "label": 0
                },
                {
                    "sent": "You're right that in order to uniquely specify an exponential family, I need not just the choice of features, but also a base measure.",
                    "label": 0
                },
                {
                    "sent": "And here are just happened to choose.",
                    "label": 0
                },
                {
                    "sent": "I just chosen a base measure, that is, that is 1 everywhere.",
                    "label": 0
                },
                {
                    "sent": "The Labay measure on the real line.",
                    "label": 0
                },
                {
                    "sent": "If you had a prior, if you had a prior over this space, then you would choose that as the base measure and then and then you might end up with something different.",
                    "label": 0
                },
                {
                    "sent": "OK, something that in particular you might end up with something that's not a Gaussian.",
                    "label": 0
                },
                {
                    "sent": "OK, so any questions about that?",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now let's figure out what the solution has to look like, OK?",
                    "label": 0
                },
                {
                    "sent": "So we have some sample space.",
                    "label": 1
                },
                {
                    "sent": "We have some features.",
                    "label": 0
                },
                {
                    "sent": "We have some constraints and we have a reference prior.",
                    "label": 0
                },
                {
                    "sent": "So here's the key statement.",
                    "label": 0
                },
                {
                    "sent": "OK, so the claim is that if there's a distribution of this particular form that happens to satisfy the constraints.",
                    "label": 0
                },
                {
                    "sent": "Then it is the unique minimizer.",
                    "label": 1
                },
                {
                    "sent": "It's the unique close.",
                    "label": 0
                },
                {
                    "sent": "It is the unique distribution that's closest to by.",
                    "label": 0
                },
                {
                    "sent": "Subject to these constraints.",
                    "label": 0
                },
                {
                    "sent": "And now let's see.",
                    "label": 0
                },
                {
                    "sent": "Let's see why this is the case.",
                    "label": 0
                },
                {
                    "sent": "OK, so if you can find a distribution that looks like this, that actually satisfies the constraints.",
                    "label": 0
                },
                {
                    "sent": "Then that is the unique solution to our problem.",
                    "label": 0
                },
                {
                    "sent": "OK, why is that?",
                    "label": 0
                },
                {
                    "sent": "Well, let's say P star is this unique distribution.",
                    "label": 1
                },
                {
                    "sent": "Let's appease star is a distribution of this form that satisfies the constraints.",
                    "label": 0
                },
                {
                    "sent": "Let's show that no other P can possibly do so.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we have some distribution P stuff that has the exponential family form OK and it satisfies the constraints.",
                    "label": 0
                },
                {
                    "sent": "Will show that any other distribution which satisfies the constraints must be further away from Pi.",
                    "label": 1
                },
                {
                    "sent": "Must be strictly further away from Thai.",
                    "label": 0
                },
                {
                    "sent": "So how is this the case?",
                    "label": 0
                },
                {
                    "sent": "Well, let's look at the distance.",
                    "label": 0
                },
                {
                    "sent": "Let's look at how close this other distribution is to \u03c0 compared to how close are exponential family distribution is to \u03c0, and we'll show that this quantity is strictly positive.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So let's just expand out these terms.",
                    "label": 0
                },
                {
                    "sent": "KFC pie, well that's just the definition of KL divergent.",
                    "label": 0
                },
                {
                    "sent": "And we do the same for P star.",
                    "label": 0
                },
                {
                    "sent": "Now for the next line we just copy this over and we notice that the star because of the exponential family form.",
                    "label": 0
                },
                {
                    "sent": "We can write P star over \u03c0 very simply P star.",
                    "label": 0
                },
                {
                    "sent": "Is equal to \u03c0 times sum E to the linear function.",
                    "label": 0
                },
                {
                    "sent": "Therefore, P star log P star over \u03c0 is just eight dot T of X -- G of ADA.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So we saw that we saw the P star is of this form, so P star over \u03c0.",
                    "label": 0
                },
                {
                    "sent": "Is this very simple linear function?",
                    "label": 0
                },
                {
                    "sent": "Great.",
                    "label": 0
                },
                {
                    "sent": "Now because because we boiled it down to a linear function, we know that the expectation of this linear function under P star is the same as its expectation under P. Why because?",
                    "label": 0
                },
                {
                    "sent": "Well OK, this part is just a constant, so we don't care about that.",
                    "label": 0
                },
                {
                    "sent": "This spot is equal to 8 times the expectation of T, and this is so the expectation of T is the same under both distributions because we know that they both satisfy the constraints.",
                    "label": 0
                },
                {
                    "sent": "The constraint is that the expectation of T is equal to B.",
                    "label": 0
                },
                {
                    "sent": "Right, so you expect therefore.",
                    "label": 0
                },
                {
                    "sent": "The expectation of T under P star is equal to the expectation of T under P. And so we can make this switch.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So now when we move further down, we can now swap back the way we got this in the 1st place.",
                    "label": 0
                },
                {
                    "sent": "With this log P star of a pie.",
                    "label": 0
                },
                {
                    "sent": "So we get that back.",
                    "label": 0
                },
                {
                    "sent": "And and now it's very convenient 'cause we have peas and in the front of both of these.",
                    "label": 0
                },
                {
                    "sent": "And these pies cancel out.",
                    "label": 0
                },
                {
                    "sent": "And what we end up with is just the KL distance from PDP star.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So we get this very interesting relation.",
                    "label": 0
                },
                {
                    "sent": "We get that the difference of these two KL divergences exactly this third KL divergent and since P&P star are not the same, this is strictly positive.",
                    "label": 0
                },
                {
                    "sent": "And therefore he is strictly further away from \u03c0.",
                    "label": 0
                },
                {
                    "sent": "Then P star is from \u03c0.",
                    "label": 0
                },
                {
                    "sent": "Again, that's why peacetime must be the unique minimizer of of the distance divide.",
                    "label": 0
                },
                {
                    "sent": "OK, so any questions about this?",
                    "label": 0
                },
                {
                    "sent": "This one relation turns out to be extremely useful for us.",
                    "label": 0
                },
                {
                    "sent": "We've now derived this relation that the distance from PETA pie is just the distance from P to P star plus the distance from P start a pie.",
                    "label": 0
                },
                {
                    "sent": "OK, and this is this is.",
                    "label": 0
                },
                {
                    "sent": "Let's see what this looks like geometrically.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we go back to the geometric picture of our.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So recall that this whole page.",
                    "label": 0
                },
                {
                    "sent": "Is the simplex of probability distributions OK?",
                    "label": 0
                },
                {
                    "sent": "So so this whole thing, this whole big thing is the simplex of of these probability vectors, which I'll say 50,000 dimensional.",
                    "label": 0
                },
                {
                    "sent": "We had some prior distribution, some prior vector.",
                    "label": 0
                },
                {
                    "sent": "And we we wanted to project it onto these constraints.",
                    "label": 0
                },
                {
                    "sent": "We wanted to find the vector closest to this which satisfies the constraints, and that's the I projection.",
                    "label": 0
                },
                {
                    "sent": "Now we see this interesting relation.",
                    "label": 0
                },
                {
                    "sent": "We say that pick any other point that also satisfies these constraints.",
                    "label": 0
                },
                {
                    "sent": "In other words, pick any other point on this affine subspace of the simplex.",
                    "label": 1
                },
                {
                    "sent": "Then we have the relation that the distance from we have this relation over here the distance from PETA pie is equal to the distance from PETA pie starter from distance from P to P star plus the distance from P started by.",
                    "label": 0
                },
                {
                    "sent": "This is quite remarkable because this is the Pythagorean theorem.",
                    "label": 0
                },
                {
                    "sent": "This is exactly the same relation we have when we are projecting with respect to Euclidean distance.",
                    "label": 0
                },
                {
                    "sent": "You know, suppose that instead of using KL distance I was projecting with respect to squared Euclidean distance.",
                    "label": 0
                },
                {
                    "sent": "OK, so then I would just project right down over there.",
                    "label": 0
                },
                {
                    "sent": "I get that right angle and then if I looked at any other point then I'd have this right angle in the middle and I know that you know this distance squared plus that distance squared was equal to this distance squared.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So, amazingly, that same Pythagorean relation holds even when one is not using squared Euclidean distance.",
                    "label": 0
                },
                {
                    "sent": "It holds also for KL Divergent.",
                    "label": 0
                },
                {
                    "sent": "So you take any point, you take its projection onto a linear subspace.",
                    "label": 0
                },
                {
                    "sent": "Because we are using Cal, the versions we call we have a special name for.",
                    "label": 0
                },
                {
                    "sent": "We call it.",
                    "label": 0
                },
                {
                    "sent": "I projection for information projection because instead of using a normal distance measure, we're using this information theoretic distance measure.",
                    "label": 0
                },
                {
                    "sent": "But you end up with this same Pythagorean relation.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So this is a little so this is, this is the geometry part of the thing here.",
                    "label": 0
                },
                {
                    "sent": "Sorry this is.",
                    "label": 0
                },
                {
                    "sent": "So this is not just in this, not just in the exponential family, but this is the this is the projection.",
                    "label": 1
                },
                {
                    "sent": "So P star has to be the projection of \u03c0, and that's also true in the Euclidean case.",
                    "label": 0
                },
                {
                    "sent": "In the Euclidean case, the Pythagorean.",
                    "label": 0
                },
                {
                    "sent": "If you're projecting onto onto a plane, the Pythagorean theorem only holds when the when you're pivoting on the projection of the point onto the airplane, right?",
                    "label": 0
                },
                {
                    "sent": "So you get the right angle.",
                    "label": 0
                },
                {
                    "sent": "So this is.",
                    "label": 0
                },
                {
                    "sent": "This is literally the generalization of the of the Pythagorean theorem in the Euclidean.",
                    "label": 0
                }
            ]
        }
    }
}