{
    "id": "cshglatefnfreodmmmq7qe5uyib563fc",
    "title": "Multi-view synchronization of human actions and dynamic scenes",
    "info": {
        "author": [
            "Emilie Dexter, INRIA Ariana, INRIA - The French National Institute for Research in Computer Science and Control"
        ],
        "published": "Dec. 1, 2009",
        "recorded": "September 2009",
        "category": [
            "Top->Computer Science->Computer Vision->Motion and Tracking"
        ]
    },
    "url": "http://videolectures.net/bmvc09_dexter_mvsh/",
    "segmentation": [
        [
            "So my name is Emily Dexter and the subject of my talk to take is a bag is about synchronization of."
        ],
        [
            "Image sequences, so the goal is to temporarily align image sequences of the same dynamic event or of similar dynamic events.",
            "If so, generally out problem due to the fact that the camera motion positions are known and an.",
            "We also assume that we can't model the time warping function existing between sequences.",
            "Such synchronization should be useful for 3D dynamic reconstruction of our analysis of multiview dynam."
        ],
        [
            "Since so the my talk will be divided in three different, But the first one is dedicated to the temporal description for image sequences that we used.",
            "The second one is the.",
            "It is about the proposed method and the last one.",
            "Is focused on the experimental results."
        ],
        [
            "Now let's begin with the temporal description.",
            "As input, we consider a sequence of T images, and we extract for each image some features.",
            "Contrary to previous work we use in this paper, real point trajectories.",
            "So we extract using some coyote trackers, some trajectories and.",
            "In addition, we estimate and compensate the dominant motion.",
            "Then we propose to build a self similarity matrices, where each component they IJ is expressed as a.",
            "Proposed on the slide where.",
            "X represents the position of the point.",
            "The A&J&X indicate the number of the frames considered.",
            "And the key is the index of the trajectories so.",
            "On the right you have an illustration of some self similarity metrics computed for the trajectories for the trajectory of the end.",
            "For golfswing action.",
            "So in addition to the symmetry property of these matrices of this."
        ],
        [
            "Metrics.",
            "The self similarity.",
            "Mattress is are also stable across views, so considering a same band action.",
            "Scene from side and top view.",
            "We compute the self similarity matrices and we can observe that the structure of this mattress matrix.",
            "Are really similar.",
            "And in addition, the self similarity matrices also exhibit the dynamics of the scene, and as you can see on the right.",
            "We have two different matrices corresponding to two different action.",
            "In fact it's for band action.",
            "As full as like this one and four jump action."
        ],
        [
            "So as in our previous work, we propose to consider this metric sees as an image, and we describe the structure of the matrix along the diagonal, and for each point of this diagonal we compute.",
            "An old disk based descriptor and finally the image sequence is represented as a sequence of local descriptor.",
            "However, keeping fixed the.",
            "The size of the window where we compute the descriptor can be extremely problematic when we consider.",
            "When we consider sequences with different frame rates, so we proposed in this paper to compute.",
            "The.",
            "Scale of the point and to adapt the size of the window with regard to this value."
        ],
        [
            "Now we propose a common framework for synchronizing either the same scene scene from different views or similar dynamic events as action and.",
            "The framework is the following.",
            "For each sequence we extract some features.",
            "Trajectories.",
            "In this case we build the self similarity matrices and we compute the descriptors.",
            "Then we apply dynamic time warping algorithm in order to estimate the time warping function existing between sequences."
        ],
        [
            "So now let's move to some results.",
            "The first one is a comparison between different descriptors and the proposed one, so we.",
            "We evaluate.",
            "We propose to evaluate the error estimation of synchronization as explained in the paper.",
            "It correspond to the average distance of point on the estimated warp to the ground truth.",
            "So those three descriptors that we consider on the the first one riford as six.",
            "Consist 2.",
            "Keeping fixed the size of the window, an identical for both sequence.",
            "She's the second one.",
            "Riford as a 6 star.",
            "Considers that the size of the support is fixed for one sequence, but we choose manually this value corresponding to the frame rate existing between sequences and the last one is the proposed so where we compute automatically the size of the support for each diagonal point."
        ],
        [
            "So the results the first table correspond to result obtained considered as more CAT data so.",
            "We simulate different frame rates and four.",
            "Each of the descriptor we evaluate the.",
            "Minimal synchronization error as explained in the paper and as you can see the proposed.",
            "Descriptor given low lower.",
            "Give the lower error values.",
            "Under the second table proposal proposed the similar example, but considering natural image sequences and the.",
            "As you can see.",
            "In general, the proposed descriptor give lower mean synchronization error values.",
            "Except.",
            "In this one."
        ],
        [
            "So now let's move to some video results.",
            "So we consider.",
            "The top video where we play the first views and the second views unsynchronized.",
            "And as you can see.",
            "The shift between seconds is quite huge.",
            "On the right you can see the time warping.",
            "Dynamic time warping is to mission in red and the ground truth.",
            "In blue and as you can see, we are able to recover a part of the ground truth.",
            "If we play the videos along the path, we can have this.",
            "Results and as you can see here, the second view stops at some image which corresponds to this vertical step in the bus."
        ],
        [
            "No another result.",
            "So soon synchronized videos.",
            "In this case we have different frame rates for between.",
            "Videos.",
            "So the ratio is 2.",
            "And as you can see on the right we have as previously the ground truth in blue and the estimated path in red.",
            "And as you can see we are.",
            "We are really close to the ground truth in this part.",
            "But we oscillate around this ground truth.",
            "It is due to the fact that the dynamic time warping algorithm that we use is only able to recover some integer correspondences, so.",
            "In fact, is able to find the best match.",
            "Between seconds.",
            "And if we play the video along the estimated bus.",
            "So now."
        ],
        [
            "Now let's move to some action synchronization, so.",
            "Some drinking action extracted from the movie, coffee and cigarettes.",
            "And as you can see.",
            "The synchronization looks pretty good.",
            "Visually.",
            "While the.",
            "Action will be performed.",
            "It outperformed with a different speed."
        ],
        [
            "Now another result of.",
            "Smoking action extracted from the movie coffee and cigarettes and as you can see, the performance of the actor are quite different.",
            "So.",
            "Particularly this guy on this guy.",
            "And as previously.",
            "So results is visually quite good.",
            "So to conclude."
        ],
        [
            "We have proposed an automatic method for synchronizing image sequences.",
            "It's a generic solution with few constraints.",
            "Um and.",
            "The method is based on the first step of.",
            "Description of match sequences.",
            "Stable on the view changes and the fact that the dynamic time warping can handle some nonlinear time warp.",
            "And in future work we we should compare our result with the others state of art method and.",
            "We assume in this case that we have two videos of the same dynamic event or similar dynamic event, so we should probably address the higher level problem, which means.",
            "We want to match the sequence before perform synchronization.",
            "Thank you very."
        ],
        [
            "Much."
        ],
        [
            "In fact, I think if trajectories are extracted on some background moving object, the self similarity matrices could be different.",
            "Effectively if we observe the subject only on one view, but I think we can add some.",
            "Person detection in order to focus the computation of the matrices only on the person, for example.",
            "So it could be addressed this problem.",
            "I made it manually.",
            "In fact, yeah.",
            "Just talking anyway, yeah, for action it's really fixed, but for.",
            "This type of sequences we recalled, in fact the video and I segmented manually the sequence an observed the delei after segmenting the sequence in order to establish the ground truth.",
            "I think if we compute the self similarity metrics for a long sequence, it should be have some break in the structure of the matrix.",
            "Maybe to identify some different shot.",
            "For some action as working, there is a.",
            "Problem of translation of the person.",
            "So we have to remove it in order to compute the self similarity matrices anget.",
            "Similar structures, in fact."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So my name is Emily Dexter and the subject of my talk to take is a bag is about synchronization of.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Image sequences, so the goal is to temporarily align image sequences of the same dynamic event or of similar dynamic events.",
                    "label": 1
                },
                {
                    "sent": "If so, generally out problem due to the fact that the camera motion positions are known and an.",
                    "label": 0
                },
                {
                    "sent": "We also assume that we can't model the time warping function existing between sequences.",
                    "label": 1
                },
                {
                    "sent": "Such synchronization should be useful for 3D dynamic reconstruction of our analysis of multiview dynam.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Since so the my talk will be divided in three different, But the first one is dedicated to the temporal description for image sequences that we used.",
                    "label": 1
                },
                {
                    "sent": "The second one is the.",
                    "label": 0
                },
                {
                    "sent": "It is about the proposed method and the last one.",
                    "label": 1
                },
                {
                    "sent": "Is focused on the experimental results.",
                    "label": 1
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now let's begin with the temporal description.",
                    "label": 0
                },
                {
                    "sent": "As input, we consider a sequence of T images, and we extract for each image some features.",
                    "label": 1
                },
                {
                    "sent": "Contrary to previous work we use in this paper, real point trajectories.",
                    "label": 0
                },
                {
                    "sent": "So we extract using some coyote trackers, some trajectories and.",
                    "label": 0
                },
                {
                    "sent": "In addition, we estimate and compensate the dominant motion.",
                    "label": 0
                },
                {
                    "sent": "Then we propose to build a self similarity matrices, where each component they IJ is expressed as a.",
                    "label": 0
                },
                {
                    "sent": "Proposed on the slide where.",
                    "label": 0
                },
                {
                    "sent": "X represents the position of the point.",
                    "label": 0
                },
                {
                    "sent": "The A&J&X indicate the number of the frames considered.",
                    "label": 0
                },
                {
                    "sent": "And the key is the index of the trajectories so.",
                    "label": 0
                },
                {
                    "sent": "On the right you have an illustration of some self similarity metrics computed for the trajectories for the trajectory of the end.",
                    "label": 0
                },
                {
                    "sent": "For golfswing action.",
                    "label": 0
                },
                {
                    "sent": "So in addition to the symmetry property of these matrices of this.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Metrics.",
                    "label": 0
                },
                {
                    "sent": "The self similarity.",
                    "label": 0
                },
                {
                    "sent": "Mattress is are also stable across views, so considering a same band action.",
                    "label": 1
                },
                {
                    "sent": "Scene from side and top view.",
                    "label": 1
                },
                {
                    "sent": "We compute the self similarity matrices and we can observe that the structure of this mattress matrix.",
                    "label": 1
                },
                {
                    "sent": "Are really similar.",
                    "label": 0
                },
                {
                    "sent": "And in addition, the self similarity matrices also exhibit the dynamics of the scene, and as you can see on the right.",
                    "label": 0
                },
                {
                    "sent": "We have two different matrices corresponding to two different action.",
                    "label": 0
                },
                {
                    "sent": "In fact it's for band action.",
                    "label": 0
                },
                {
                    "sent": "As full as like this one and four jump action.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So as in our previous work, we propose to consider this metric sees as an image, and we describe the structure of the matrix along the diagonal, and for each point of this diagonal we compute.",
                    "label": 1
                },
                {
                    "sent": "An old disk based descriptor and finally the image sequence is represented as a sequence of local descriptor.",
                    "label": 1
                },
                {
                    "sent": "However, keeping fixed the.",
                    "label": 0
                },
                {
                    "sent": "The size of the window where we compute the descriptor can be extremely problematic when we consider.",
                    "label": 0
                },
                {
                    "sent": "When we consider sequences with different frame rates, so we proposed in this paper to compute.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "Scale of the point and to adapt the size of the window with regard to this value.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now we propose a common framework for synchronizing either the same scene scene from different views or similar dynamic events as action and.",
                    "label": 1
                },
                {
                    "sent": "The framework is the following.",
                    "label": 1
                },
                {
                    "sent": "For each sequence we extract some features.",
                    "label": 0
                },
                {
                    "sent": "Trajectories.",
                    "label": 0
                },
                {
                    "sent": "In this case we build the self similarity matrices and we compute the descriptors.",
                    "label": 0
                },
                {
                    "sent": "Then we apply dynamic time warping algorithm in order to estimate the time warping function existing between sequences.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now let's move to some results.",
                    "label": 0
                },
                {
                    "sent": "The first one is a comparison between different descriptors and the proposed one, so we.",
                    "label": 0
                },
                {
                    "sent": "We evaluate.",
                    "label": 0
                },
                {
                    "sent": "We propose to evaluate the error estimation of synchronization as explained in the paper.",
                    "label": 0
                },
                {
                    "sent": "It correspond to the average distance of point on the estimated warp to the ground truth.",
                    "label": 1
                },
                {
                    "sent": "So those three descriptors that we consider on the the first one riford as six.",
                    "label": 0
                },
                {
                    "sent": "Consist 2.",
                    "label": 1
                },
                {
                    "sent": "Keeping fixed the size of the window, an identical for both sequence.",
                    "label": 0
                },
                {
                    "sent": "She's the second one.",
                    "label": 1
                },
                {
                    "sent": "Riford as a 6 star.",
                    "label": 0
                },
                {
                    "sent": "Considers that the size of the support is fixed for one sequence, but we choose manually this value corresponding to the frame rate existing between sequences and the last one is the proposed so where we compute automatically the size of the support for each diagonal point.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the results the first table correspond to result obtained considered as more CAT data so.",
                    "label": 0
                },
                {
                    "sent": "We simulate different frame rates and four.",
                    "label": 0
                },
                {
                    "sent": "Each of the descriptor we evaluate the.",
                    "label": 0
                },
                {
                    "sent": "Minimal synchronization error as explained in the paper and as you can see the proposed.",
                    "label": 0
                },
                {
                    "sent": "Descriptor given low lower.",
                    "label": 0
                },
                {
                    "sent": "Give the lower error values.",
                    "label": 0
                },
                {
                    "sent": "Under the second table proposal proposed the similar example, but considering natural image sequences and the.",
                    "label": 0
                },
                {
                    "sent": "As you can see.",
                    "label": 0
                },
                {
                    "sent": "In general, the proposed descriptor give lower mean synchronization error values.",
                    "label": 0
                },
                {
                    "sent": "Except.",
                    "label": 0
                },
                {
                    "sent": "In this one.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now let's move to some video results.",
                    "label": 0
                },
                {
                    "sent": "So we consider.",
                    "label": 0
                },
                {
                    "sent": "The top video where we play the first views and the second views unsynchronized.",
                    "label": 0
                },
                {
                    "sent": "And as you can see.",
                    "label": 0
                },
                {
                    "sent": "The shift between seconds is quite huge.",
                    "label": 0
                },
                {
                    "sent": "On the right you can see the time warping.",
                    "label": 0
                },
                {
                    "sent": "Dynamic time warping is to mission in red and the ground truth.",
                    "label": 1
                },
                {
                    "sent": "In blue and as you can see, we are able to recover a part of the ground truth.",
                    "label": 0
                },
                {
                    "sent": "If we play the videos along the path, we can have this.",
                    "label": 0
                },
                {
                    "sent": "Results and as you can see here, the second view stops at some image which corresponds to this vertical step in the bus.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "No another result.",
                    "label": 0
                },
                {
                    "sent": "So soon synchronized videos.",
                    "label": 0
                },
                {
                    "sent": "In this case we have different frame rates for between.",
                    "label": 0
                },
                {
                    "sent": "Videos.",
                    "label": 0
                },
                {
                    "sent": "So the ratio is 2.",
                    "label": 0
                },
                {
                    "sent": "And as you can see on the right we have as previously the ground truth in blue and the estimated path in red.",
                    "label": 0
                },
                {
                    "sent": "And as you can see we are.",
                    "label": 0
                },
                {
                    "sent": "We are really close to the ground truth in this part.",
                    "label": 0
                },
                {
                    "sent": "But we oscillate around this ground truth.",
                    "label": 0
                },
                {
                    "sent": "It is due to the fact that the dynamic time warping algorithm that we use is only able to recover some integer correspondences, so.",
                    "label": 0
                },
                {
                    "sent": "In fact, is able to find the best match.",
                    "label": 0
                },
                {
                    "sent": "Between seconds.",
                    "label": 0
                },
                {
                    "sent": "And if we play the video along the estimated bus.",
                    "label": 0
                },
                {
                    "sent": "So now.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now let's move to some action synchronization, so.",
                    "label": 0
                },
                {
                    "sent": "Some drinking action extracted from the movie, coffee and cigarettes.",
                    "label": 1
                },
                {
                    "sent": "And as you can see.",
                    "label": 0
                },
                {
                    "sent": "The synchronization looks pretty good.",
                    "label": 0
                },
                {
                    "sent": "Visually.",
                    "label": 0
                },
                {
                    "sent": "While the.",
                    "label": 0
                },
                {
                    "sent": "Action will be performed.",
                    "label": 0
                },
                {
                    "sent": "It outperformed with a different speed.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now another result of.",
                    "label": 0
                },
                {
                    "sent": "Smoking action extracted from the movie coffee and cigarettes and as you can see, the performance of the actor are quite different.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Particularly this guy on this guy.",
                    "label": 0
                },
                {
                    "sent": "And as previously.",
                    "label": 0
                },
                {
                    "sent": "So results is visually quite good.",
                    "label": 0
                },
                {
                    "sent": "So to conclude.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We have proposed an automatic method for synchronizing image sequences.",
                    "label": 1
                },
                {
                    "sent": "It's a generic solution with few constraints.",
                    "label": 0
                },
                {
                    "sent": "Um and.",
                    "label": 0
                },
                {
                    "sent": "The method is based on the first step of.",
                    "label": 1
                },
                {
                    "sent": "Description of match sequences.",
                    "label": 0
                },
                {
                    "sent": "Stable on the view changes and the fact that the dynamic time warping can handle some nonlinear time warp.",
                    "label": 0
                },
                {
                    "sent": "And in future work we we should compare our result with the others state of art method and.",
                    "label": 0
                },
                {
                    "sent": "We assume in this case that we have two videos of the same dynamic event or similar dynamic event, so we should probably address the higher level problem, which means.",
                    "label": 0
                },
                {
                    "sent": "We want to match the sequence before perform synchronization.",
                    "label": 0
                },
                {
                    "sent": "Thank you very.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Much.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In fact, I think if trajectories are extracted on some background moving object, the self similarity matrices could be different.",
                    "label": 0
                },
                {
                    "sent": "Effectively if we observe the subject only on one view, but I think we can add some.",
                    "label": 0
                },
                {
                    "sent": "Person detection in order to focus the computation of the matrices only on the person, for example.",
                    "label": 0
                },
                {
                    "sent": "So it could be addressed this problem.",
                    "label": 0
                },
                {
                    "sent": "I made it manually.",
                    "label": 0
                },
                {
                    "sent": "In fact, yeah.",
                    "label": 0
                },
                {
                    "sent": "Just talking anyway, yeah, for action it's really fixed, but for.",
                    "label": 0
                },
                {
                    "sent": "This type of sequences we recalled, in fact the video and I segmented manually the sequence an observed the delei after segmenting the sequence in order to establish the ground truth.",
                    "label": 0
                },
                {
                    "sent": "I think if we compute the self similarity metrics for a long sequence, it should be have some break in the structure of the matrix.",
                    "label": 0
                },
                {
                    "sent": "Maybe to identify some different shot.",
                    "label": 0
                },
                {
                    "sent": "For some action as working, there is a.",
                    "label": 0
                },
                {
                    "sent": "Problem of translation of the person.",
                    "label": 0
                },
                {
                    "sent": "So we have to remove it in order to compute the self similarity matrices anget.",
                    "label": 0
                },
                {
                    "sent": "Similar structures, in fact.",
                    "label": 0
                }
            ]
        }
    }
}