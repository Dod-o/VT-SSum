{
    "id": "mdawbawqiikt2iumnucdrbls4hgfpian",
    "title": "Learning Causal Graphical Models with Latent Variables",
    "info": {
        "author": [
            "Sam Maes, University of Savoie"
        ],
        "published": "Feb. 25, 2007",
        "recorded": "October 2006",
        "category": [
            "Top->Computer Science->Machine Learning->Graphical Models"
        ]
    },
    "url": "http://videolectures.net/learning06_maes_lcgml/",
    "segmentation": [
        [
            "There's no data and you have data."
        ],
        [
            "It can be experimental that is obtained from by performing experiments and then observing what happens.",
            "Second of all, we have to learn the parameters of.",
            "Of the problem, once we have learned destruction of para meters, we can we want to do two types of tasks, maybe probabilistic inference and causal inference.",
            "I'll talk later a few slides to explain what what exactly is probabilistic inference and causal inference and what the difference between the two is, which is quite important for us."
        ],
        [
            "Now these are the septus classical subtasks, but the problem is that there is a in a domain with latent variables.",
            "There is no integral approach to do this, so there is no one paradigm or one modeling representation that can perform all these subtypes at this time for discrete variables.",
            "For example, the two main approaches to R type of modeling with latent variables, which means that the latent variables are kept implicit.",
            "But I'll talk about that later with Slide 2.",
            "So the first approach are the same at coding causal models by the per lap and jintian, and they are specifically suited for performing causal inference, so they have a whole set of algorithms to perform causal inference.",
            "But they have no.",
            "There are no ways, not algorithms to learn them from data or to learn from experiments to learn the para meters.",
            "There is no efficient parametrization, so they're very interesting models to do this causal inference in a theoretic way.",
            "But if you really want to do it, you have to ask yourself, how do we obtain these models and how do we parameterized inefficient way?",
            "Second of all, we have the ancestral graphs, which are the other call of the other causal US lap by Spiritus and his collaborators, and notably Richardson and sang.",
            "And they are specifically suited for.",
            "On one end, structure learning from observational data.",
            "So learning exactly the dependencies and in dependencies that exist in a domain with latent variables.",
            "So these are ancestor graph models.",
            "They, on the other hand, have.",
            "Then the problem that there is at this time they are working on it.",
            "No efficient parametrizations for, no parameterization for discrete variables.",
            "First of all, second problem is they have some causal inference algorithms, but they're very limited.",
            "They're limited that the things that they can calculate the causal inference.",
            "Queries have to be the same for the complete Markov equivalence class, but I'll talk about that later in more detail when I've defined all these terms and they also have no probabilistic inference algorithm, no efficient, because they don't yet have discrete parameterization."
        ],
        [
            "So now might have given the general problem.",
            "The observation was that there was no such thing and we try to provide an integral approach that so that we can do modeling causal modeling in a domain with latent variables.",
            "We tried to provide an integral approach and today I will talk about the learning part really learning or briefly mentioned parametrizations have developed, but I won't talk about it here as the title of the conferences learning 06."
        ],
        [
            "So some background.",
            "First, you have the classical Bayesian network, so there is a probabilistic graphical model.",
            "On the right we have such an example.",
            "It's a medical.",
            "An example of a medical application where we want to, for example, predict the probability that someone has certain disease, tuberculosis or lung cancer given some possible observations.",
            "As someone visited Asia, easier smoker is suffering from short brightness, which is dyspnea, etc.",
            "Now such a graph on the right.",
            "It's an independence model.",
            "It represents in dependencies or conditional independence between the variables in the domain.",
            "Which can be derived from this graph in a certain way, but.",
            "That would lead us into many in too much detail.",
            "So next to this independence model structural model, we also have attached with a probability distribution in the in the following way.",
            "So every variable we have the conditional probability of every variable in domain given its immediate parents in the graph, and we see that these these conditional probabilities they constitute a factorization of the joint probability distribution over VVR.",
            "All the variables in the domain.",
            "Now, typically, typically these classical Bayesian networks are used for probabilistic inference, which is to predict the consequences consequences.",
            "Maybe not the best way to predict what happens after an observation.",
            "For example, we observe that certain person has visited Asia recently, is a smoker and has a positive X Ray for something in his lungs.",
            "So what is the probability that he has a certain disease that is a classical use of?",
            "Of these models, so we see an example here.",
            "I see now what is the probability that someone has cancer given that you smoke and that you had a positive X Ray.",
            "Of."
        ],
        [
            "Spots in his lungs.",
            "Now then, the subclass of these Bayesian networks are the causal Bayesian networks, so they are the same.",
            "They are probabilistic graphical model causal.",
            "Now what does it mean to be causal means that is a Bayesian network for every arrow.",
            "Every immediate arrow corresponds to an immediate causal relation between the variables.",
            "What do we mean by that?",
            "We are definition of causality.",
            "Is the following?",
            "So if there is a fix causes why we say that manipulating variable X will change the distribution of variable.",
            "Why there is a definition of causality?",
            "So we get on the right.",
            "This is the same graph.",
            "This is the original graph.",
            "Actually, this one was a change graph, which is observationally equivalent.",
            "But this is a causal graph where.",
            "The causes every immediate arrow represents A cause.",
            "Now these models can also be used for the probabilistic inference as before, but Additionally if some if some assumptions hold, they can be used for causal inference, and this is predicting the consequence of a manipulation outside of the system, for example.",
            "Well, here this is not.",
            "This is not a good example to show manipulations because not very ethical, but imagine that we would inoculate someone with tuberculosis.",
            "What would be the effect on cancer?",
            "OK, later I'll have more realistic or more ethical examples, but so the big difference that we change the domain that we have, we have learned the model over domain and then we change it by doing a manipulation and using our formal knowledge.",
            "We want to see what effect this will have.",
            "OK, so they said the difference between probabilistic inference where we observe something and see what the consequences will be.",
            "Here we actually manipulate or imagine that we manipulated."
        ],
        [
            "To see what effect that would have.",
            "Now these rules are explained.",
            "Now they have no latent variables, so we have the assumption that every variable that is relevant to us observed.",
            "Now if we drop this assumption that some variables can be observed in general.",
            "So what we want to do is end to model these various implicitly.",
            "Another thing would be to start the estimate is variable, start to estimate their cardinality, then estimated distribution.",
            "That's not the kind of approach where interest interesting, because it's low an it's not necessary for what we want to do is that is necessary.",
            "If you really want values for this latent values, we just want to know their influence on the other variables, how they influence and So what we do is we model then implicitly.",
            "As we can see here.",
            "So the L, L1 and L2 are the latent variables.",
            "We just want to know.",
            "Their place in the in the structure, but we don't want to know we're not going to going to estimate probabilities for them.",
            "So as I said before, there are two main approaches to this.",
            "Implicit modeling of latent variables.",
            "The same archiving cosmos and the maximal ancestor."
        ],
        [
            "So to answer graphs.",
            "Now, OK, not of defined latent variables.",
            "I'll talk a little more about the the difference between probabilistic and causal inference.",
            "So on the left we have the original model to model of very famous example of Bayesian networks.",
            "So it's an alarm system somewhere in California where there can be several cause of an alarm on one at.",
            "It can be a burglary.",
            "On other hand it can be an earthquake because there are a lot of earthquakes there and of course we can have the very rare but the common if both if there's a burglary and earthquake in the same time they can both be the cause of the alarm.",
            "And then the alarm the alarm going off can cause the two neighbors of the person living in the house to call him at his work to say alarm is going off with a certain probability.",
            "Now if we.",
            "If after an observation, so for probabilistic inference that would happen is first in all the observed variables, in this case that the alarm is going off is on.",
            "With that would be instantiated and then this information will be propagated to the other variables.",
            "So that's what happens in the middle.",
            "On the other hand, in manipulation.",
            "After many places, something else will happen.",
            "First of all, the old course is the former causes of the model that we have learned before will be removed 'cause they are no longer causes, because now the model has been manipulated and we have put on the alarm manually as we show here by the new operator and this means that the domain is changed so the burgling earthquakes are no longer the cause of the alarm.",
            "We are the costs, so these edges have already moved from the domain and after this is done we instantiate is valuable to on because you know it's on and then this information is propagated too.",
            "Defenders are still connected to this, so we see that there is a clear difference within probabilistic in causal inference.",
            "And, of course, causal inference is a much stronger, much more difficult problem than a non probabilistic inference.",
            "It gives much more information."
        ],
        [
            "Now we see that was again with with observed variables.",
            "All I will, all variables observed.",
            "Now if we again assume that there are latent variables, then this causal inference becomes much more complicated.",
            "So here we have such an example of three variables where XY&Z are observed in L, the latent variables and observed.",
            "Now if we want to see what happens if we manipulate the variable X to certain value first you have to do is replace the former causes.",
            "We only know the only former code that we know is this latent variable, but we don't know exactly the relation.",
            "So how to remove it in the classical direct way we cannot do it.",
            "The classical wave L would you observe this?",
            "We would have the joint distribution over the four variables, we just divide it by the influence of the latent variable.",
            "I would have the Joint district Joint post experimental distribution over X at Y, but now.",
            "We cannot do this because we don't know how much enough about this later available we can do it in other ways.",
            "Another these algorithms by Tiempo have developed ways to go around.",
            "It actually will go the way is go through variables at conditional variables it and go through that one.",
            "So it is the first phase of the causal inference that causes problems.",
            "OK, let's just want."
        ],
        [
            "To show that this is a problem.",
            "Now, actually, this actual modeling with latent variables we."
        ],
        [
            "Seen before that there are several types.",
            "OK, first of all, the assumptions that we're working.",
            "We have some simplifying assumptions because otherwise the problem is too complicated.",
            "First of all, we assume stability, which means that the independence is found.",
            "In first of all, we assume that there is an underlying model that we want to model the underlying model and then in this underlying model that we want to try to find back from Dayton experiments the independence are structural.",
            "It means that there cannot be.",
            "Two, for example, two influences to pass between variables that exactly cancel each other out, which means that there would be causal influences between the variables.",
            "But you do some strange happening in nature that exactly cancel each other out, because then from observational point of view, these variables would seem independent, but actually there are a lot of things going on.",
            "These are the kind of problems that we cannot handle that are.",
            "Other techniques would have to be used at more from a complex systems.",
            "So that is one of the assumptions that we need to use.",
            "And this is the classical assumption in the in the Bayesian network area.",
            "2nd is a less classical assumption.",
            "Actually nobody talks about it, but we can only handle these problems when there is a maximum one immediate connection between the two variables in the underlying DAG.",
            "And here we see such problems.",
            "This we cannot handle.",
            "The only way we would be able to handle so we have an immediate causal connection between two variables X&Y and we also have one hidden variable exactly exactly causing these two.",
            "These two observed variables.",
            "That's the only way you would be able to.",
            "Find the middle of models like that back is to do an experiment on every variable, every single variable and measure.",
            "Isolate the influence of this arc and then make the difference with the joint distribution, which would be an enormous amount of work and which is not totally not realistic realistic approach.",
            "So we for amount we assume that this cannot be done.",
            "By the way, this is nobody talks about it, but it's a silent assumption in all the work except in this causal inference algorithms they assume that the model is given with these kind of arcs.",
            "And then they can do causal inference on it.",
            "But they never say how they learn such such such a relationship between the variables.",
            "3rd third assumption is no selection bias so.",
            "Some people are like in Richardson work.",
            "They can work with selection bias, but then they just do the learning part.",
            "They don't do the inference and we have seen that the selection bias gives a lot of problems with causal inference.",
            "So for the moment we don't touch that either and we as I've already mentioned, we only."
        ],
        [
            "Work we are interested in discrete variables, so first I'll talk about these two approaches to latent variables.",
            "Now, first of all, we have the same recovering causal models which are specifically suited or developed for causal inference.",
            "So in this case we have an example here down here.",
            "The same example of the underlying deck that we had here."
        ],
        [
            "Of the underlying data that we had here.",
            "So basically everything the only thing that happens after latent variables are replaced by by directed edges, as we will see."
        ],
        [
            "Down here, so in this case a directed edge classical directed edge represents an immediate causal relation, just as in the causal Bayesian network.",
            "But we also have BI directed edges, and they represent a latent common cause.",
            "So like yeah, so now it seems it would seem that the same at current models are very limited.",
            "Family of latent variables, 'cause they seem to only allow latent variables that are that have no parents and at exactly to observe children.",
            "But there is a nice property.",
            "The third bullet important that every such model, every model with arbitrary latent variables in arbitrary relations that can latent variables, can be the parents of more observed variables that can be children of observables, etc.",
            "Arbitrary latent variables, they can be transformed into a same equipment, causing model while remaining the same.",
            "Causal an observational properties with relation to the observed variables, and we are only interested in the observed variables.",
            "So the advantage of this is that we can very complicated models can be can be solved with this.",
            "Quite simple simplified models the same argument 'cause most of the latent variables have very simple structures.",
            "Attached to the structure is a joint probability distribution, in this case, or just a joint distribution over the six variables.",
            "This of course that we need to joint distribution is a very.",
            "Very bad.",
            "Inefficient approach and we the reason Bayesian networks were introduced was to avoid working with joint probability distributions, so, but that was preliminary work by these people.",
            "They are not seem not to be very interested in applying them to real problems.",
            "So what we have provided, a parameterization is more efficient than the joint distribution, but I won't talk about that today."
        ],
        [
            "OK, so the same equipment costing models.",
            "They have their specifically suited for causal inference.",
            "There is no efficient parameterization in the in the literature.",
            "As I said before, there is no probabilistic inference algorithm and there is no learning algorithm.",
            "There is no way to learn these rules.",
            "They don't talk about this.",
            "So we wonder how."
        ],
        [
            "To use them in practice.",
            "Now that was the first representation.",
            "The second representation for latent variables is the one specifically introduced by for learning.",
            "So first I will give a small introduction.",
            "People have noted that the class of the directed acyclic graph.",
            "So the class of Bayesian networks is not complete on their marginalization of latent variables, which means that if there are latent variables in a domain, if we remove them in marginalizing as they call it, we cannot represent these.",
            "All the independence is this domain, with directed acyclic graph.",
            "For example, on the left we have that's in French I see, so we have a health is a hidden variable, a latent variable, and we have two treatments that treatment one and two, both as a result of the same patient.",
            "Now one example deck to represent this domain is the one on the right, but there simply is not a dog.",
            "It can represent exactly all dependencies.",
            "For example here in this deck.",
            "The independence between variable T1 and result 2 is not present because in the original graph there independent due to the separation causes, which I will not explain because with leaders too far, but there will never be a DAG that will explain exactly all the independence and independence between the domain, so that was their motivation for finding another class of graphical models."
        ],
        [
            "Word maximal ancestral graphs which allow which are not a DAG, but which allow also by directed edges, to represent all exactly all the dependencies.",
            "By the way, in the same outgoing calls.",
            "Also not all the dependencies in domain are shown, but I'll come back to that later.",
            "So in this case again we have a graphic directed edges, But in this case the directive not acausal, meaning.",
            "Not just in the immediate cause of Minnie's with the same McGovern customers, but we have an ancestral meaning.",
            "And what do we mean with an ancestor?",
            "Meaning means that in the underlying deck, so that we want to try to mold, there is a causal part between two variables.",
            "That that is the only meaning of a direct attach.",
            "Of course this part can be of length one and then we have the same edge as in the original underlying back, or as in as represented in the same according Cousin model.",
            "But it can also be that it is apart.",
            "OK then, second we have the BI directed edges.",
            "They represent latent common causes before but.",
            "In this case they only allow.",
            "Maximal assessor.",
            "Grassley only allow one edge between two variables, so if there is both an ancestor relation ends a latent common cause between two variables, one of them will only remain, it is their ancestral relation that absorbs the latent common cause, as we call it, so we see that there is a different semantics between these two models.",
            "They each have their merits, and the maximal answer graph.",
            "They learn exactly what is in the data, but then how to use them is another question.",
            "They're not very efficient in user.",
            "I'm not very algorithms are not there.",
            "And on the other hand, we have the same equipment Cosmos.",
            "We don't know how to learn them at this time, but we can use them to do inference or you have the theory to use.",
            "It also had their maximal ancestor graph means that every absent edge represents an independent situation, so they have very nice property because they represent the data the conditional Independencies very nice and maximal assist for gravatar.",
            "Causal information is not of the same quality of."
        ],
        [
            "As a thematic coding cousin model.",
            "So these are maximum sister graphs there organisms to learn them.",
            "They are constrained by its algorithm.",
            "Which learns which has a date and learns from in dependencies or conditional in dependencies in the data.",
            "Do the fast causal inference algorithm by Swift is a nice colleagues.",
            "They also have very recently developed rules for orienting some edges.",
            "And then the result of this and this is a problem only learns into Markov equivalence, which means that it cannot learn the complete graph from data.",
            "We cannot learn the complete causal graph from observational data alone, we can only see go to a certain class of models which are observationally equivalent.",
            "So an example will explain."
        ],
        [
            "This may be, for example, here.",
            "On the left we have the original underlying underlying DAG, and on the right we have the result of learning from observational data.",
            "Given that the data is correct, etc.",
            "So we can see three possible edges marks.",
            "First of all, a circle, which means that we do not know.",
            "We do not know whether it's a circle, whether it must be an edge or not in edge.",
            "We can have the ones that we have certain of.",
            "These are these ones.",
            "For example, we are certain that they have to be edges.",
            "But their ancestral edges and not necessarily causal edges, and then we have the one that we have certain of that they are.",
            "They're not edges, non edges, and there's actually none that we can derive.",
            "There was none in this example.",
            "So now this is the result of learning observational data, which is already a very quiet nice result.",
            "But we can see that there are a lot of grass.",
            "There are a lot of ways that you can fill in these circles.",
            "And still represent the same model.",
            "So what we want to do if you want to do causal inference, you have to find the right graph.",
            "The causal graph represents the causal data exactly.",
            "In order to be able to do causal inference.",
            "And Furthermore we see that there is an edge here between V1 and V6 that is not present in the original deck.",
            "We'll talk about those later, but these edges also have to be removed in order to be able to do causal inference.",
            "But aside from that."
        ],
        [
            "Specifically.",
            "So now there's a uncertain TC packs every edge in the feedback in a CPAC, by the way, is completed partially ancestor graph, which is representative for the Markov equivalence class of maximum access or graphs.",
            "So there are three possible underlying explanations for each edge in such a learned CPAC.",
            "First of all, as in a variable one between variable one variable, 2, the edges there the cost, while the underlying causes an immediate causal relation that's good.",
            "Second one, actually that should say immediate causal relation or immediate ancestor relation should be that should be ancestral.",
            "Second possible causes a latent variable, for example between variable two in variable two, variable 6.",
            "This relation here this edge is due to a latent common causing the underlying back and then the third one, which are quite complicated is due to an inducing part between variable one and variable 6.",
            "And using that means means that in the underlying deck, these two variables here febrile 6 and variable one.",
            "They cannot be separated from each other with observational data, so we cannot condition on one of these variables here between those parts.",
            "To make these these V1 and V6 independent, the only way to make them independent would be to condition on variable on the latent variable number one.",
            "But we cannot do that because it's a latent variable.",
            "So the problem is that it seems from observational data that there is an immediate connection and immediate dependence.",
            "Between V1 and V6.",
            "And we want if you want to cause another want to remove these kind of spurious relationship between these two variables and we found a way to perform experiments to remove these edges, because here it would seem that there is a immediate relation and there is not.",
            "So we want to remove these.",
            "So these are the 3 three possible underlying explanations for each edge.",
            "We want to know what the real underlying explanation why."
        ],
        [
            "In order to learn.",
            "So about mags about these maximal assessor graphs, they only learn to Marco equivalents they have.",
            "There is a causal inference algorithm.",
            "They have told me I was always taught there was number reason, but it's only limited to those calls or expressions that are the same for the complete Markov equivalence class."
        ],
        [
            "So that's very, very limited.",
            "So the only here I don't know exactly what you could be able to calculate, but only the causal inference calculations.",
            "That would be the same for all the graphs that can be filled in.",
            "In this one would be can be calculated in this family of maximal assessor graph, which is obviously very limited.",
            "If you see what the original graph was there.",
            "Also, there are hundreds of weight of, well, whole lot of ways to fill this field.",
            "This graph in so."
        ],
        [
            "That's a very limited causal inference algorithm.",
            "There is no probabilistic inference.",
            "There is no parameterization for discrete variables, they're working.",
            "The rumors are that they are working on it, but for the time it is not there yet.",
            "So what we do what we have done in our work is to use observational learning to learn a civic.",
            "So use existing results and then to use experiments to transform this result into a same according causing model that can be used to do this causal inference and in that way we have part of an integral approach together with this parameterization that we also developed to be able to do modeling with latent variables.",
            "And to do this model."
        ],
        [
            "Modeling in a causal way."
        ],
        [
            "So finally, our own approach.",
            "Causal learning with latent variables.",
            "So we want to perform experience to differentiate between the different cases.",
            "So there are two types.",
            "If you have an arrow that is half half unknown, completely unknown, and then after all edges are directed after type one and type two, we do not have the correct graphics.",
            "We have to remove these edges that are too much that are due to inducing pattern that we do not want because they would fool our cause."
        ],
        [
            "Inference algorithms.",
            "So actually this thing is a little complicated, but it's very simple approach.",
            "The hard way was to prove that it was correct.",
            "So first of all, some notation.",
            "So if we do an experiment on a variable A.",
            "And, uh, we see that B doesn't change.",
            "So this is this strange error with means that it would change the distribution of another variable B.",
            "If it wouldn't change, we would know that it's not a causal relation, but it has to be a latent Common Core.",
            "So for example, here between V5 and V6.",
            "If you don't expand on the 1st, I'll show battery."
        ],
        [
            "It was.",
            "Here we saw that it was a half directed error, so I want to do here.",
            "Now is performing experiment on variable 5 to see what will happen.",
            "We will see in the original model if you perform an experiment on V5, there is no causal part.",
            "A V6 or V6 will not change and therefore therefore we can conclude that this may not be a causal relation.",
            "But man has to be a confounding relation related common cause OK?"
        ],
        [
            "OK, second part is, what if we do an experiment on such an edge and we see that?",
            "We see that the other variables that were interesting changes then it can be.",
            "Then we have to see.",
            "So we see that we perform an experiment, for example, on variable two, I'll go back to the original graph again."
        ],
        [
            "Verbal 2.",
            "OK, after a few steps this would have been after few steps that I didn't show.",
            "This would have been directed.",
            "So what if we do then an experiment on V2 and we see that V4 changes so we cannot immediately conclude that there is an immediate causal path between variable two and V4 because it could be that is changed.",
            "Has gone to another Part 2 V 4 for example.",
            "In this case, could be a path like this.",
            "Could be a path like this, etc.",
            "There are several parts which could.",
            "Several potential directed paths between variable to available for that have to be blocked in order to be sure that the causal relation that we seem to observe from experiments is exactly this relation and not something that goes to another path, OK?",
            "So."
        ],
        [
            "In the experimental example, it's what we do here, for example at this point.",
            "So at this point this we're examining this edge.",
            "All the rest have been have been directed here, and so we see that the only potentially directed part there is between V2 and V4.",
            "Next to this edge.",
            "Is this one all the others?",
            "There is no possible directed path from, so we have to do is to block this spot by conditioning on it.",
            "So we make a distribution is conditioned on this variable tree.",
            "In that way this second.",
            "About this potential directive, part of length two or bigger is blocked, and then we can isolate the influence of this, and in that case there is still an influence between these two variables.",
            "We know that there must be a causal relation between these two these two variables and we can, as we have done here, direct.",
            "The edge in a causal way.",
            "OK, so that is a."
        ],
        [
            "Quite simple for the other case it would be too much detail, but it's quite the same, can quite easily be transformed into type 1."
        ],
        [
            "And then a more interesting case of removing these edges due to inducing parts.",
            "So the first step there is to recognize these edges.",
            "These edges can first of all be by directed or directed.",
            "These edges that are possibly created to do 2 and inducing path.",
            "And this example we have only one which is V1V6.",
            "So what you have to do is to what we're going to do is to block these inducing parts by performing an experiment.",
            "So the only way to block because the definition of an using part is that it cannot be blocked by conditioning.",
            "So the only way to block it is to perform experiment and to remove costs from the system and to see if there still dependence.",
            "So what we will do in this case?",
            "This is the inducing part like this from V1V22V6 is the part that cannot be blocked by conditioning.",
            "So we find available on that path to block by experiment.",
            "So in this case it would be V2.",
            "So we perform an experiment on V2 which removes this in this edge from the domain and then.",
            "We would also remove their other directed paths, which is not the case in this example, and then we'd see see if there is still after that experience independence between these variables V1 and V6.",
            "And would see here.",
            "So here if you perform an experiment on this, this edge would be removed from the domain and this also and V1 would be an isolated variable and it would no longer be a dependence between these two variables.",
            "And therefrom we could conclude that the edge V1 and V6 is not a real confounding factor.",
            "Bill is due to inducing part and if we remove that result of that expense we would have the same equipment cost model as we wanted to obtain.",
            "So."
        ],
        [
            "That's basically our approach, and I can only conclude that we have explained an approach to learning; Columns which are very useful in use together with this parameterization from a combination of observational and experimental data, where the observational techniques are by another group, our existing results and we extend attempt to experimental data.",
            "Now other work I've already mentioned this parametrisation and future work would be to optimize the order of these experiments, because now we don't really optimize them with respect to several decision creator.",
            "We have done this kind of work with.",
            "Time to learn causal Bayesian networks without latent variables, where you take into account if possible, the possible cost and possible results of an experiment.",
            "Because some experiments are more expensive and some experiments give potentially better results.",
            "So then you can use techniques from decision theory to optimize this.",
            "And there's also we could also after each experiment infer edges because an experiment gives information, then we could again use these learning techniques from observational data to infer other edges.",
            "So there are possible future extensions of this work.",
            "That's it, I think.",
            "Yeah, there are questions I'll take.",
            "Data with the.",
            "Just by observing a system not intervening.",
            "So there's a system you have data of a system without performing experiments in it, which is an as opposed to that we have.",
            "We do control randomized experiments.",
            "That's what I call experimental data, and not doing that observational data.",
            "Just seeing a system and collecting data with.",
            "For example, extra astronomical data is observational data.",
            "For example, typically and what you do is experimental, your your results are experimental.",
            "You manipulate the domain, etc.",
            "For example.",
            "1."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There's no data and you have data.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It can be experimental that is obtained from by performing experiments and then observing what happens.",
                    "label": 0
                },
                {
                    "sent": "Second of all, we have to learn the parameters of.",
                    "label": 0
                },
                {
                    "sent": "Of the problem, once we have learned destruction of para meters, we can we want to do two types of tasks, maybe probabilistic inference and causal inference.",
                    "label": 1
                },
                {
                    "sent": "I'll talk later a few slides to explain what what exactly is probabilistic inference and causal inference and what the difference between the two is, which is quite important for us.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now these are the septus classical subtasks, but the problem is that there is a in a domain with latent variables.",
                    "label": 0
                },
                {
                    "sent": "There is no integral approach to do this, so there is no one paradigm or one modeling representation that can perform all these subtypes at this time for discrete variables.",
                    "label": 0
                },
                {
                    "sent": "For example, the two main approaches to R type of modeling with latent variables, which means that the latent variables are kept implicit.",
                    "label": 0
                },
                {
                    "sent": "But I'll talk about that later with Slide 2.",
                    "label": 0
                },
                {
                    "sent": "So the first approach are the same at coding causal models by the per lap and jintian, and they are specifically suited for performing causal inference, so they have a whole set of algorithms to perform causal inference.",
                    "label": 0
                },
                {
                    "sent": "But they have no.",
                    "label": 0
                },
                {
                    "sent": "There are no ways, not algorithms to learn them from data or to learn from experiments to learn the para meters.",
                    "label": 0
                },
                {
                    "sent": "There is no efficient parametrization, so they're very interesting models to do this causal inference in a theoretic way.",
                    "label": 0
                },
                {
                    "sent": "But if you really want to do it, you have to ask yourself, how do we obtain these models and how do we parameterized inefficient way?",
                    "label": 0
                },
                {
                    "sent": "Second of all, we have the ancestral graphs, which are the other call of the other causal US lap by Spiritus and his collaborators, and notably Richardson and sang.",
                    "label": 0
                },
                {
                    "sent": "And they are specifically suited for.",
                    "label": 0
                },
                {
                    "sent": "On one end, structure learning from observational data.",
                    "label": 1
                },
                {
                    "sent": "So learning exactly the dependencies and in dependencies that exist in a domain with latent variables.",
                    "label": 0
                },
                {
                    "sent": "So these are ancestor graph models.",
                    "label": 0
                },
                {
                    "sent": "They, on the other hand, have.",
                    "label": 0
                },
                {
                    "sent": "Then the problem that there is at this time they are working on it.",
                    "label": 0
                },
                {
                    "sent": "No efficient parametrizations for, no parameterization for discrete variables.",
                    "label": 0
                },
                {
                    "sent": "First of all, second problem is they have some causal inference algorithms, but they're very limited.",
                    "label": 0
                },
                {
                    "sent": "They're limited that the things that they can calculate the causal inference.",
                    "label": 0
                },
                {
                    "sent": "Queries have to be the same for the complete Markov equivalence class, but I'll talk about that later in more detail when I've defined all these terms and they also have no probabilistic inference algorithm, no efficient, because they don't yet have discrete parameterization.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now might have given the general problem.",
                    "label": 0
                },
                {
                    "sent": "The observation was that there was no such thing and we try to provide an integral approach that so that we can do modeling causal modeling in a domain with latent variables.",
                    "label": 0
                },
                {
                    "sent": "We tried to provide an integral approach and today I will talk about the learning part really learning or briefly mentioned parametrizations have developed, but I won't talk about it here as the title of the conferences learning 06.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So some background.",
                    "label": 0
                },
                {
                    "sent": "First, you have the classical Bayesian network, so there is a probabilistic graphical model.",
                    "label": 1
                },
                {
                    "sent": "On the right we have such an example.",
                    "label": 0
                },
                {
                    "sent": "It's a medical.",
                    "label": 0
                },
                {
                    "sent": "An example of a medical application where we want to, for example, predict the probability that someone has certain disease, tuberculosis or lung cancer given some possible observations.",
                    "label": 0
                },
                {
                    "sent": "As someone visited Asia, easier smoker is suffering from short brightness, which is dyspnea, etc.",
                    "label": 0
                },
                {
                    "sent": "Now such a graph on the right.",
                    "label": 0
                },
                {
                    "sent": "It's an independence model.",
                    "label": 0
                },
                {
                    "sent": "It represents in dependencies or conditional independence between the variables in the domain.",
                    "label": 0
                },
                {
                    "sent": "Which can be derived from this graph in a certain way, but.",
                    "label": 0
                },
                {
                    "sent": "That would lead us into many in too much detail.",
                    "label": 0
                },
                {
                    "sent": "So next to this independence model structural model, we also have attached with a probability distribution in the in the following way.",
                    "label": 0
                },
                {
                    "sent": "So every variable we have the conditional probability of every variable in domain given its immediate parents in the graph, and we see that these these conditional probabilities they constitute a factorization of the joint probability distribution over VVR.",
                    "label": 0
                },
                {
                    "sent": "All the variables in the domain.",
                    "label": 1
                },
                {
                    "sent": "Now, typically, typically these classical Bayesian networks are used for probabilistic inference, which is to predict the consequences consequences.",
                    "label": 0
                },
                {
                    "sent": "Maybe not the best way to predict what happens after an observation.",
                    "label": 0
                },
                {
                    "sent": "For example, we observe that certain person has visited Asia recently, is a smoker and has a positive X Ray for something in his lungs.",
                    "label": 0
                },
                {
                    "sent": "So what is the probability that he has a certain disease that is a classical use of?",
                    "label": 0
                },
                {
                    "sent": "Of these models, so we see an example here.",
                    "label": 0
                },
                {
                    "sent": "I see now what is the probability that someone has cancer given that you smoke and that you had a positive X Ray.",
                    "label": 0
                },
                {
                    "sent": "Of.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Spots in his lungs.",
                    "label": 0
                },
                {
                    "sent": "Now then, the subclass of these Bayesian networks are the causal Bayesian networks, so they are the same.",
                    "label": 0
                },
                {
                    "sent": "They are probabilistic graphical model causal.",
                    "label": 1
                },
                {
                    "sent": "Now what does it mean to be causal means that is a Bayesian network for every arrow.",
                    "label": 0
                },
                {
                    "sent": "Every immediate arrow corresponds to an immediate causal relation between the variables.",
                    "label": 1
                },
                {
                    "sent": "What do we mean by that?",
                    "label": 0
                },
                {
                    "sent": "We are definition of causality.",
                    "label": 0
                },
                {
                    "sent": "Is the following?",
                    "label": 1
                },
                {
                    "sent": "So if there is a fix causes why we say that manipulating variable X will change the distribution of variable.",
                    "label": 0
                },
                {
                    "sent": "Why there is a definition of causality?",
                    "label": 0
                },
                {
                    "sent": "So we get on the right.",
                    "label": 0
                },
                {
                    "sent": "This is the same graph.",
                    "label": 0
                },
                {
                    "sent": "This is the original graph.",
                    "label": 0
                },
                {
                    "sent": "Actually, this one was a change graph, which is observationally equivalent.",
                    "label": 0
                },
                {
                    "sent": "But this is a causal graph where.",
                    "label": 0
                },
                {
                    "sent": "The causes every immediate arrow represents A cause.",
                    "label": 0
                },
                {
                    "sent": "Now these models can also be used for the probabilistic inference as before, but Additionally if some if some assumptions hold, they can be used for causal inference, and this is predicting the consequence of a manipulation outside of the system, for example.",
                    "label": 0
                },
                {
                    "sent": "Well, here this is not.",
                    "label": 0
                },
                {
                    "sent": "This is not a good example to show manipulations because not very ethical, but imagine that we would inoculate someone with tuberculosis.",
                    "label": 0
                },
                {
                    "sent": "What would be the effect on cancer?",
                    "label": 0
                },
                {
                    "sent": "OK, later I'll have more realistic or more ethical examples, but so the big difference that we change the domain that we have, we have learned the model over domain and then we change it by doing a manipulation and using our formal knowledge.",
                    "label": 0
                },
                {
                    "sent": "We want to see what effect this will have.",
                    "label": 0
                },
                {
                    "sent": "OK, so they said the difference between probabilistic inference where we observe something and see what the consequences will be.",
                    "label": 0
                },
                {
                    "sent": "Here we actually manipulate or imagine that we manipulated.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To see what effect that would have.",
                    "label": 0
                },
                {
                    "sent": "Now these rules are explained.",
                    "label": 0
                },
                {
                    "sent": "Now they have no latent variables, so we have the assumption that every variable that is relevant to us observed.",
                    "label": 0
                },
                {
                    "sent": "Now if we drop this assumption that some variables can be observed in general.",
                    "label": 1
                },
                {
                    "sent": "So what we want to do is end to model these various implicitly.",
                    "label": 0
                },
                {
                    "sent": "Another thing would be to start the estimate is variable, start to estimate their cardinality, then estimated distribution.",
                    "label": 0
                },
                {
                    "sent": "That's not the kind of approach where interest interesting, because it's low an it's not necessary for what we want to do is that is necessary.",
                    "label": 0
                },
                {
                    "sent": "If you really want values for this latent values, we just want to know their influence on the other variables, how they influence and So what we do is we model then implicitly.",
                    "label": 0
                },
                {
                    "sent": "As we can see here.",
                    "label": 0
                },
                {
                    "sent": "So the L, L1 and L2 are the latent variables.",
                    "label": 0
                },
                {
                    "sent": "We just want to know.",
                    "label": 0
                },
                {
                    "sent": "Their place in the in the structure, but we don't want to know we're not going to going to estimate probabilities for them.",
                    "label": 0
                },
                {
                    "sent": "So as I said before, there are two main approaches to this.",
                    "label": 1
                },
                {
                    "sent": "Implicit modeling of latent variables.",
                    "label": 0
                },
                {
                    "sent": "The same archiving cosmos and the maximal ancestor.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to answer graphs.",
                    "label": 0
                },
                {
                    "sent": "Now, OK, not of defined latent variables.",
                    "label": 0
                },
                {
                    "sent": "I'll talk a little more about the the difference between probabilistic and causal inference.",
                    "label": 1
                },
                {
                    "sent": "So on the left we have the original model to model of very famous example of Bayesian networks.",
                    "label": 0
                },
                {
                    "sent": "So it's an alarm system somewhere in California where there can be several cause of an alarm on one at.",
                    "label": 0
                },
                {
                    "sent": "It can be a burglary.",
                    "label": 0
                },
                {
                    "sent": "On other hand it can be an earthquake because there are a lot of earthquakes there and of course we can have the very rare but the common if both if there's a burglary and earthquake in the same time they can both be the cause of the alarm.",
                    "label": 0
                },
                {
                    "sent": "And then the alarm the alarm going off can cause the two neighbors of the person living in the house to call him at his work to say alarm is going off with a certain probability.",
                    "label": 0
                },
                {
                    "sent": "Now if we.",
                    "label": 0
                },
                {
                    "sent": "If after an observation, so for probabilistic inference that would happen is first in all the observed variables, in this case that the alarm is going off is on.",
                    "label": 1
                },
                {
                    "sent": "With that would be instantiated and then this information will be propagated to the other variables.",
                    "label": 0
                },
                {
                    "sent": "So that's what happens in the middle.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, in manipulation.",
                    "label": 0
                },
                {
                    "sent": "After many places, something else will happen.",
                    "label": 0
                },
                {
                    "sent": "First of all, the old course is the former causes of the model that we have learned before will be removed 'cause they are no longer causes, because now the model has been manipulated and we have put on the alarm manually as we show here by the new operator and this means that the domain is changed so the burgling earthquakes are no longer the cause of the alarm.",
                    "label": 0
                },
                {
                    "sent": "We are the costs, so these edges have already moved from the domain and after this is done we instantiate is valuable to on because you know it's on and then this information is propagated too.",
                    "label": 0
                },
                {
                    "sent": "Defenders are still connected to this, so we see that there is a clear difference within probabilistic in causal inference.",
                    "label": 0
                },
                {
                    "sent": "And, of course, causal inference is a much stronger, much more difficult problem than a non probabilistic inference.",
                    "label": 0
                },
                {
                    "sent": "It gives much more information.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now we see that was again with with observed variables.",
                    "label": 0
                },
                {
                    "sent": "All I will, all variables observed.",
                    "label": 0
                },
                {
                    "sent": "Now if we again assume that there are latent variables, then this causal inference becomes much more complicated.",
                    "label": 1
                },
                {
                    "sent": "So here we have such an example of three variables where XY&Z are observed in L, the latent variables and observed.",
                    "label": 1
                },
                {
                    "sent": "Now if we want to see what happens if we manipulate the variable X to certain value first you have to do is replace the former causes.",
                    "label": 0
                },
                {
                    "sent": "We only know the only former code that we know is this latent variable, but we don't know exactly the relation.",
                    "label": 0
                },
                {
                    "sent": "So how to remove it in the classical direct way we cannot do it.",
                    "label": 0
                },
                {
                    "sent": "The classical wave L would you observe this?",
                    "label": 0
                },
                {
                    "sent": "We would have the joint distribution over the four variables, we just divide it by the influence of the latent variable.",
                    "label": 0
                },
                {
                    "sent": "I would have the Joint district Joint post experimental distribution over X at Y, but now.",
                    "label": 0
                },
                {
                    "sent": "We cannot do this because we don't know how much enough about this later available we can do it in other ways.",
                    "label": 0
                },
                {
                    "sent": "Another these algorithms by Tiempo have developed ways to go around.",
                    "label": 0
                },
                {
                    "sent": "It actually will go the way is go through variables at conditional variables it and go through that one.",
                    "label": 0
                },
                {
                    "sent": "So it is the first phase of the causal inference that causes problems.",
                    "label": 0
                },
                {
                    "sent": "OK, let's just want.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To show that this is a problem.",
                    "label": 0
                },
                {
                    "sent": "Now, actually, this actual modeling with latent variables we.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Seen before that there are several types.",
                    "label": 0
                },
                {
                    "sent": "OK, first of all, the assumptions that we're working.",
                    "label": 0
                },
                {
                    "sent": "We have some simplifying assumptions because otherwise the problem is too complicated.",
                    "label": 0
                },
                {
                    "sent": "First of all, we assume stability, which means that the independence is found.",
                    "label": 0
                },
                {
                    "sent": "In first of all, we assume that there is an underlying model that we want to model the underlying model and then in this underlying model that we want to try to find back from Dayton experiments the independence are structural.",
                    "label": 0
                },
                {
                    "sent": "It means that there cannot be.",
                    "label": 0
                },
                {
                    "sent": "Two, for example, two influences to pass between variables that exactly cancel each other out, which means that there would be causal influences between the variables.",
                    "label": 0
                },
                {
                    "sent": "But you do some strange happening in nature that exactly cancel each other out, because then from observational point of view, these variables would seem independent, but actually there are a lot of things going on.",
                    "label": 0
                },
                {
                    "sent": "These are the kind of problems that we cannot handle that are.",
                    "label": 0
                },
                {
                    "sent": "Other techniques would have to be used at more from a complex systems.",
                    "label": 0
                },
                {
                    "sent": "So that is one of the assumptions that we need to use.",
                    "label": 0
                },
                {
                    "sent": "And this is the classical assumption in the in the Bayesian network area.",
                    "label": 0
                },
                {
                    "sent": "2nd is a less classical assumption.",
                    "label": 0
                },
                {
                    "sent": "Actually nobody talks about it, but we can only handle these problems when there is a maximum one immediate connection between the two variables in the underlying DAG.",
                    "label": 1
                },
                {
                    "sent": "And here we see such problems.",
                    "label": 0
                },
                {
                    "sent": "This we cannot handle.",
                    "label": 0
                },
                {
                    "sent": "The only way we would be able to handle so we have an immediate causal connection between two variables X&Y and we also have one hidden variable exactly exactly causing these two.",
                    "label": 0
                },
                {
                    "sent": "These two observed variables.",
                    "label": 0
                },
                {
                    "sent": "That's the only way you would be able to.",
                    "label": 0
                },
                {
                    "sent": "Find the middle of models like that back is to do an experiment on every variable, every single variable and measure.",
                    "label": 0
                },
                {
                    "sent": "Isolate the influence of this arc and then make the difference with the joint distribution, which would be an enormous amount of work and which is not totally not realistic realistic approach.",
                    "label": 0
                },
                {
                    "sent": "So we for amount we assume that this cannot be done.",
                    "label": 0
                },
                {
                    "sent": "By the way, this is nobody talks about it, but it's a silent assumption in all the work except in this causal inference algorithms they assume that the model is given with these kind of arcs.",
                    "label": 0
                },
                {
                    "sent": "And then they can do causal inference on it.",
                    "label": 0
                },
                {
                    "sent": "But they never say how they learn such such such a relationship between the variables.",
                    "label": 1
                },
                {
                    "sent": "3rd third assumption is no selection bias so.",
                    "label": 0
                },
                {
                    "sent": "Some people are like in Richardson work.",
                    "label": 0
                },
                {
                    "sent": "They can work with selection bias, but then they just do the learning part.",
                    "label": 0
                },
                {
                    "sent": "They don't do the inference and we have seen that the selection bias gives a lot of problems with causal inference.",
                    "label": 0
                },
                {
                    "sent": "So for the moment we don't touch that either and we as I've already mentioned, we only.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Work we are interested in discrete variables, so first I'll talk about these two approaches to latent variables.",
                    "label": 1
                },
                {
                    "sent": "Now, first of all, we have the same recovering causal models which are specifically suited or developed for causal inference.",
                    "label": 1
                },
                {
                    "sent": "So in this case we have an example here down here.",
                    "label": 0
                },
                {
                    "sent": "The same example of the underlying deck that we had here.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of the underlying data that we had here.",
                    "label": 0
                },
                {
                    "sent": "So basically everything the only thing that happens after latent variables are replaced by by directed edges, as we will see.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Down here, so in this case a directed edge classical directed edge represents an immediate causal relation, just as in the causal Bayesian network.",
                    "label": 1
                },
                {
                    "sent": "But we also have BI directed edges, and they represent a latent common cause.",
                    "label": 0
                },
                {
                    "sent": "So like yeah, so now it seems it would seem that the same at current models are very limited.",
                    "label": 0
                },
                {
                    "sent": "Family of latent variables, 'cause they seem to only allow latent variables that are that have no parents and at exactly to observe children.",
                    "label": 0
                },
                {
                    "sent": "But there is a nice property.",
                    "label": 0
                },
                {
                    "sent": "The third bullet important that every such model, every model with arbitrary latent variables in arbitrary relations that can latent variables, can be the parents of more observed variables that can be children of observables, etc.",
                    "label": 0
                },
                {
                    "sent": "Arbitrary latent variables, they can be transformed into a same equipment, causing model while remaining the same.",
                    "label": 1
                },
                {
                    "sent": "Causal an observational properties with relation to the observed variables, and we are only interested in the observed variables.",
                    "label": 1
                },
                {
                    "sent": "So the advantage of this is that we can very complicated models can be can be solved with this.",
                    "label": 0
                },
                {
                    "sent": "Quite simple simplified models the same argument 'cause most of the latent variables have very simple structures.",
                    "label": 0
                },
                {
                    "sent": "Attached to the structure is a joint probability distribution, in this case, or just a joint distribution over the six variables.",
                    "label": 0
                },
                {
                    "sent": "This of course that we need to joint distribution is a very.",
                    "label": 0
                },
                {
                    "sent": "Very bad.",
                    "label": 0
                },
                {
                    "sent": "Inefficient approach and we the reason Bayesian networks were introduced was to avoid working with joint probability distributions, so, but that was preliminary work by these people.",
                    "label": 0
                },
                {
                    "sent": "They are not seem not to be very interested in applying them to real problems.",
                    "label": 0
                },
                {
                    "sent": "So what we have provided, a parameterization is more efficient than the joint distribution, but I won't talk about that today.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so the same equipment costing models.",
                    "label": 0
                },
                {
                    "sent": "They have their specifically suited for causal inference.",
                    "label": 0
                },
                {
                    "sent": "There is no efficient parameterization in the in the literature.",
                    "label": 0
                },
                {
                    "sent": "As I said before, there is no probabilistic inference algorithm and there is no learning algorithm.",
                    "label": 1
                },
                {
                    "sent": "There is no way to learn these rules.",
                    "label": 0
                },
                {
                    "sent": "They don't talk about this.",
                    "label": 0
                },
                {
                    "sent": "So we wonder how.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To use them in practice.",
                    "label": 0
                },
                {
                    "sent": "Now that was the first representation.",
                    "label": 0
                },
                {
                    "sent": "The second representation for latent variables is the one specifically introduced by for learning.",
                    "label": 1
                },
                {
                    "sent": "So first I will give a small introduction.",
                    "label": 0
                },
                {
                    "sent": "People have noted that the class of the directed acyclic graph.",
                    "label": 0
                },
                {
                    "sent": "So the class of Bayesian networks is not complete on their marginalization of latent variables, which means that if there are latent variables in a domain, if we remove them in marginalizing as they call it, we cannot represent these.",
                    "label": 1
                },
                {
                    "sent": "All the independence is this domain, with directed acyclic graph.",
                    "label": 0
                },
                {
                    "sent": "For example, on the left we have that's in French I see, so we have a health is a hidden variable, a latent variable, and we have two treatments that treatment one and two, both as a result of the same patient.",
                    "label": 0
                },
                {
                    "sent": "Now one example deck to represent this domain is the one on the right, but there simply is not a dog.",
                    "label": 1
                },
                {
                    "sent": "It can represent exactly all dependencies.",
                    "label": 0
                },
                {
                    "sent": "For example here in this deck.",
                    "label": 0
                },
                {
                    "sent": "The independence between variable T1 and result 2 is not present because in the original graph there independent due to the separation causes, which I will not explain because with leaders too far, but there will never be a DAG that will explain exactly all the independence and independence between the domain, so that was their motivation for finding another class of graphical models.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Word maximal ancestral graphs which allow which are not a DAG, but which allow also by directed edges, to represent all exactly all the dependencies.",
                    "label": 1
                },
                {
                    "sent": "By the way, in the same outgoing calls.",
                    "label": 0
                },
                {
                    "sent": "Also not all the dependencies in domain are shown, but I'll come back to that later.",
                    "label": 0
                },
                {
                    "sent": "So in this case again we have a graphic directed edges, But in this case the directive not acausal, meaning.",
                    "label": 0
                },
                {
                    "sent": "Not just in the immediate cause of Minnie's with the same McGovern customers, but we have an ancestral meaning.",
                    "label": 1
                },
                {
                    "sent": "And what do we mean with an ancestor?",
                    "label": 0
                },
                {
                    "sent": "Meaning means that in the underlying deck, so that we want to try to mold, there is a causal part between two variables.",
                    "label": 0
                },
                {
                    "sent": "That that is the only meaning of a direct attach.",
                    "label": 0
                },
                {
                    "sent": "Of course this part can be of length one and then we have the same edge as in the original underlying back, or as in as represented in the same according Cousin model.",
                    "label": 0
                },
                {
                    "sent": "But it can also be that it is apart.",
                    "label": 1
                },
                {
                    "sent": "OK then, second we have the BI directed edges.",
                    "label": 0
                },
                {
                    "sent": "They represent latent common causes before but.",
                    "label": 0
                },
                {
                    "sent": "In this case they only allow.",
                    "label": 0
                },
                {
                    "sent": "Maximal assessor.",
                    "label": 0
                },
                {
                    "sent": "Grassley only allow one edge between two variables, so if there is both an ancestor relation ends a latent common cause between two variables, one of them will only remain, it is their ancestral relation that absorbs the latent common cause, as we call it, so we see that there is a different semantics between these two models.",
                    "label": 1
                },
                {
                    "sent": "They each have their merits, and the maximal answer graph.",
                    "label": 0
                },
                {
                    "sent": "They learn exactly what is in the data, but then how to use them is another question.",
                    "label": 0
                },
                {
                    "sent": "They're not very efficient in user.",
                    "label": 0
                },
                {
                    "sent": "I'm not very algorithms are not there.",
                    "label": 0
                },
                {
                    "sent": "And on the other hand, we have the same equipment Cosmos.",
                    "label": 1
                },
                {
                    "sent": "We don't know how to learn them at this time, but we can use them to do inference or you have the theory to use.",
                    "label": 0
                },
                {
                    "sent": "It also had their maximal ancestor graph means that every absent edge represents an independent situation, so they have very nice property because they represent the data the conditional Independencies very nice and maximal assist for gravatar.",
                    "label": 0
                },
                {
                    "sent": "Causal information is not of the same quality of.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As a thematic coding cousin model.",
                    "label": 0
                },
                {
                    "sent": "So these are maximum sister graphs there organisms to learn them.",
                    "label": 0
                },
                {
                    "sent": "They are constrained by its algorithm.",
                    "label": 0
                },
                {
                    "sent": "Which learns which has a date and learns from in dependencies or conditional in dependencies in the data.",
                    "label": 1
                },
                {
                    "sent": "Do the fast causal inference algorithm by Swift is a nice colleagues.",
                    "label": 1
                },
                {
                    "sent": "They also have very recently developed rules for orienting some edges.",
                    "label": 0
                },
                {
                    "sent": "And then the result of this and this is a problem only learns into Markov equivalence, which means that it cannot learn the complete graph from data.",
                    "label": 0
                },
                {
                    "sent": "We cannot learn the complete causal graph from observational data alone, we can only see go to a certain class of models which are observationally equivalent.",
                    "label": 0
                },
                {
                    "sent": "So an example will explain.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This may be, for example, here.",
                    "label": 0
                },
                {
                    "sent": "On the left we have the original underlying underlying DAG, and on the right we have the result of learning from observational data.",
                    "label": 0
                },
                {
                    "sent": "Given that the data is correct, etc.",
                    "label": 0
                },
                {
                    "sent": "So we can see three possible edges marks.",
                    "label": 0
                },
                {
                    "sent": "First of all, a circle, which means that we do not know.",
                    "label": 0
                },
                {
                    "sent": "We do not know whether it's a circle, whether it must be an edge or not in edge.",
                    "label": 0
                },
                {
                    "sent": "We can have the ones that we have certain of.",
                    "label": 0
                },
                {
                    "sent": "These are these ones.",
                    "label": 0
                },
                {
                    "sent": "For example, we are certain that they have to be edges.",
                    "label": 0
                },
                {
                    "sent": "But their ancestral edges and not necessarily causal edges, and then we have the one that we have certain of that they are.",
                    "label": 0
                },
                {
                    "sent": "They're not edges, non edges, and there's actually none that we can derive.",
                    "label": 0
                },
                {
                    "sent": "There was none in this example.",
                    "label": 0
                },
                {
                    "sent": "So now this is the result of learning observational data, which is already a very quiet nice result.",
                    "label": 0
                },
                {
                    "sent": "But we can see that there are a lot of grass.",
                    "label": 0
                },
                {
                    "sent": "There are a lot of ways that you can fill in these circles.",
                    "label": 1
                },
                {
                    "sent": "And still represent the same model.",
                    "label": 1
                },
                {
                    "sent": "So what we want to do if you want to do causal inference, you have to find the right graph.",
                    "label": 1
                },
                {
                    "sent": "The causal graph represents the causal data exactly.",
                    "label": 1
                },
                {
                    "sent": "In order to be able to do causal inference.",
                    "label": 0
                },
                {
                    "sent": "And Furthermore we see that there is an edge here between V1 and V6 that is not present in the original deck.",
                    "label": 0
                },
                {
                    "sent": "We'll talk about those later, but these edges also have to be removed in order to be able to do causal inference.",
                    "label": 0
                },
                {
                    "sent": "But aside from that.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Specifically.",
                    "label": 0
                },
                {
                    "sent": "So now there's a uncertain TC packs every edge in the feedback in a CPAC, by the way, is completed partially ancestor graph, which is representative for the Markov equivalence class of maximum access or graphs.",
                    "label": 0
                },
                {
                    "sent": "So there are three possible underlying explanations for each edge in such a learned CPAC.",
                    "label": 0
                },
                {
                    "sent": "First of all, as in a variable one between variable one variable, 2, the edges there the cost, while the underlying causes an immediate causal relation that's good.",
                    "label": 0
                },
                {
                    "sent": "Second one, actually that should say immediate causal relation or immediate ancestor relation should be that should be ancestral.",
                    "label": 0
                },
                {
                    "sent": "Second possible causes a latent variable, for example between variable two in variable two, variable 6.",
                    "label": 0
                },
                {
                    "sent": "This relation here this edge is due to a latent common causing the underlying back and then the third one, which are quite complicated is due to an inducing part between variable one and variable 6.",
                    "label": 0
                },
                {
                    "sent": "And using that means means that in the underlying deck, these two variables here febrile 6 and variable one.",
                    "label": 0
                },
                {
                    "sent": "They cannot be separated from each other with observational data, so we cannot condition on one of these variables here between those parts.",
                    "label": 0
                },
                {
                    "sent": "To make these these V1 and V6 independent, the only way to make them independent would be to condition on variable on the latent variable number one.",
                    "label": 0
                },
                {
                    "sent": "But we cannot do that because it's a latent variable.",
                    "label": 0
                },
                {
                    "sent": "So the problem is that it seems from observational data that there is an immediate connection and immediate dependence.",
                    "label": 1
                },
                {
                    "sent": "Between V1 and V6.",
                    "label": 0
                },
                {
                    "sent": "And we want if you want to cause another want to remove these kind of spurious relationship between these two variables and we found a way to perform experiments to remove these edges, because here it would seem that there is a immediate relation and there is not.",
                    "label": 0
                },
                {
                    "sent": "So we want to remove these.",
                    "label": 1
                },
                {
                    "sent": "So these are the 3 three possible underlying explanations for each edge.",
                    "label": 0
                },
                {
                    "sent": "We want to know what the real underlying explanation why.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In order to learn.",
                    "label": 0
                },
                {
                    "sent": "So about mags about these maximal assessor graphs, they only learn to Marco equivalents they have.",
                    "label": 0
                },
                {
                    "sent": "There is a causal inference algorithm.",
                    "label": 1
                },
                {
                    "sent": "They have told me I was always taught there was number reason, but it's only limited to those calls or expressions that are the same for the complete Markov equivalence class.",
                    "label": 1
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that's very, very limited.",
                    "label": 0
                },
                {
                    "sent": "So the only here I don't know exactly what you could be able to calculate, but only the causal inference calculations.",
                    "label": 0
                },
                {
                    "sent": "That would be the same for all the graphs that can be filled in.",
                    "label": 0
                },
                {
                    "sent": "In this one would be can be calculated in this family of maximal assessor graph, which is obviously very limited.",
                    "label": 0
                },
                {
                    "sent": "If you see what the original graph was there.",
                    "label": 0
                },
                {
                    "sent": "Also, there are hundreds of weight of, well, whole lot of ways to fill this field.",
                    "label": 0
                },
                {
                    "sent": "This graph in so.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That's a very limited causal inference algorithm.",
                    "label": 1
                },
                {
                    "sent": "There is no probabilistic inference.",
                    "label": 0
                },
                {
                    "sent": "There is no parameterization for discrete variables, they're working.",
                    "label": 0
                },
                {
                    "sent": "The rumors are that they are working on it, but for the time it is not there yet.",
                    "label": 0
                },
                {
                    "sent": "So what we do what we have done in our work is to use observational learning to learn a civic.",
                    "label": 1
                },
                {
                    "sent": "So use existing results and then to use experiments to transform this result into a same according causing model that can be used to do this causal inference and in that way we have part of an integral approach together with this parameterization that we also developed to be able to do modeling with latent variables.",
                    "label": 0
                },
                {
                    "sent": "And to do this model.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Modeling in a causal way.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So finally, our own approach.",
                    "label": 0
                },
                {
                    "sent": "Causal learning with latent variables.",
                    "label": 0
                },
                {
                    "sent": "So we want to perform experience to differentiate between the different cases.",
                    "label": 1
                },
                {
                    "sent": "So there are two types.",
                    "label": 0
                },
                {
                    "sent": "If you have an arrow that is half half unknown, completely unknown, and then after all edges are directed after type one and type two, we do not have the correct graphics.",
                    "label": 0
                },
                {
                    "sent": "We have to remove these edges that are too much that are due to inducing pattern that we do not want because they would fool our cause.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Inference algorithms.",
                    "label": 0
                },
                {
                    "sent": "So actually this thing is a little complicated, but it's very simple approach.",
                    "label": 0
                },
                {
                    "sent": "The hard way was to prove that it was correct.",
                    "label": 0
                },
                {
                    "sent": "So first of all, some notation.",
                    "label": 0
                },
                {
                    "sent": "So if we do an experiment on a variable A.",
                    "label": 0
                },
                {
                    "sent": "And, uh, we see that B doesn't change.",
                    "label": 0
                },
                {
                    "sent": "So this is this strange error with means that it would change the distribution of another variable B.",
                    "label": 0
                },
                {
                    "sent": "If it wouldn't change, we would know that it's not a causal relation, but it has to be a latent Common Core.",
                    "label": 0
                },
                {
                    "sent": "So for example, here between V5 and V6.",
                    "label": 0
                },
                {
                    "sent": "If you don't expand on the 1st, I'll show battery.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It was.",
                    "label": 0
                },
                {
                    "sent": "Here we saw that it was a half directed error, so I want to do here.",
                    "label": 0
                },
                {
                    "sent": "Now is performing experiment on variable 5 to see what will happen.",
                    "label": 0
                },
                {
                    "sent": "We will see in the original model if you perform an experiment on V5, there is no causal part.",
                    "label": 1
                },
                {
                    "sent": "A V6 or V6 will not change and therefore therefore we can conclude that this may not be a causal relation.",
                    "label": 1
                },
                {
                    "sent": "But man has to be a confounding relation related common cause OK?",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, second part is, what if we do an experiment on such an edge and we see that?",
                    "label": 0
                },
                {
                    "sent": "We see that the other variables that were interesting changes then it can be.",
                    "label": 0
                },
                {
                    "sent": "Then we have to see.",
                    "label": 0
                },
                {
                    "sent": "So we see that we perform an experiment, for example, on variable two, I'll go back to the original graph again.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Verbal 2.",
                    "label": 0
                },
                {
                    "sent": "OK, after a few steps this would have been after few steps that I didn't show.",
                    "label": 0
                },
                {
                    "sent": "This would have been directed.",
                    "label": 0
                },
                {
                    "sent": "So what if we do then an experiment on V2 and we see that V4 changes so we cannot immediately conclude that there is an immediate causal path between variable two and V4 because it could be that is changed.",
                    "label": 1
                },
                {
                    "sent": "Has gone to another Part 2 V 4 for example.",
                    "label": 0
                },
                {
                    "sent": "In this case, could be a path like this.",
                    "label": 0
                },
                {
                    "sent": "Could be a path like this, etc.",
                    "label": 0
                },
                {
                    "sent": "There are several parts which could.",
                    "label": 0
                },
                {
                    "sent": "Several potential directed paths between variable to available for that have to be blocked in order to be sure that the causal relation that we seem to observe from experiments is exactly this relation and not something that goes to another path, OK?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In the experimental example, it's what we do here, for example at this point.",
                    "label": 0
                },
                {
                    "sent": "So at this point this we're examining this edge.",
                    "label": 0
                },
                {
                    "sent": "All the rest have been have been directed here, and so we see that the only potentially directed part there is between V2 and V4.",
                    "label": 0
                },
                {
                    "sent": "Next to this edge.",
                    "label": 0
                },
                {
                    "sent": "Is this one all the others?",
                    "label": 0
                },
                {
                    "sent": "There is no possible directed path from, so we have to do is to block this spot by conditioning on it.",
                    "label": 1
                },
                {
                    "sent": "So we make a distribution is conditioned on this variable tree.",
                    "label": 0
                },
                {
                    "sent": "In that way this second.",
                    "label": 1
                },
                {
                    "sent": "About this potential directive, part of length two or bigger is blocked, and then we can isolate the influence of this, and in that case there is still an influence between these two variables.",
                    "label": 0
                },
                {
                    "sent": "We know that there must be a causal relation between these two these two variables and we can, as we have done here, direct.",
                    "label": 0
                },
                {
                    "sent": "The edge in a causal way.",
                    "label": 0
                },
                {
                    "sent": "OK, so that is a.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Quite simple for the other case it would be too much detail, but it's quite the same, can quite easily be transformed into type 1.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then a more interesting case of removing these edges due to inducing parts.",
                    "label": 1
                },
                {
                    "sent": "So the first step there is to recognize these edges.",
                    "label": 0
                },
                {
                    "sent": "These edges can first of all be by directed or directed.",
                    "label": 1
                },
                {
                    "sent": "These edges that are possibly created to do 2 and inducing path.",
                    "label": 0
                },
                {
                    "sent": "And this example we have only one which is V1V6.",
                    "label": 0
                },
                {
                    "sent": "So what you have to do is to what we're going to do is to block these inducing parts by performing an experiment.",
                    "label": 0
                },
                {
                    "sent": "So the only way to block because the definition of an using part is that it cannot be blocked by conditioning.",
                    "label": 0
                },
                {
                    "sent": "So the only way to block it is to perform experiment and to remove costs from the system and to see if there still dependence.",
                    "label": 1
                },
                {
                    "sent": "So what we will do in this case?",
                    "label": 0
                },
                {
                    "sent": "This is the inducing part like this from V1V22V6 is the part that cannot be blocked by conditioning.",
                    "label": 0
                },
                {
                    "sent": "So we find available on that path to block by experiment.",
                    "label": 0
                },
                {
                    "sent": "So in this case it would be V2.",
                    "label": 0
                },
                {
                    "sent": "So we perform an experiment on V2 which removes this in this edge from the domain and then.",
                    "label": 0
                },
                {
                    "sent": "We would also remove their other directed paths, which is not the case in this example, and then we'd see see if there is still after that experience independence between these variables V1 and V6.",
                    "label": 0
                },
                {
                    "sent": "And would see here.",
                    "label": 0
                },
                {
                    "sent": "So here if you perform an experiment on this, this edge would be removed from the domain and this also and V1 would be an isolated variable and it would no longer be a dependence between these two variables.",
                    "label": 0
                },
                {
                    "sent": "And therefrom we could conclude that the edge V1 and V6 is not a real confounding factor.",
                    "label": 0
                },
                {
                    "sent": "Bill is due to inducing part and if we remove that result of that expense we would have the same equipment cost model as we wanted to obtain.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That's basically our approach, and I can only conclude that we have explained an approach to learning; Columns which are very useful in use together with this parameterization from a combination of observational and experimental data, where the observational techniques are by another group, our existing results and we extend attempt to experimental data.",
                    "label": 1
                },
                {
                    "sent": "Now other work I've already mentioned this parametrisation and future work would be to optimize the order of these experiments, because now we don't really optimize them with respect to several decision creator.",
                    "label": 0
                },
                {
                    "sent": "We have done this kind of work with.",
                    "label": 0
                },
                {
                    "sent": "Time to learn causal Bayesian networks without latent variables, where you take into account if possible, the possible cost and possible results of an experiment.",
                    "label": 0
                },
                {
                    "sent": "Because some experiments are more expensive and some experiments give potentially better results.",
                    "label": 0
                },
                {
                    "sent": "So then you can use techniques from decision theory to optimize this.",
                    "label": 0
                },
                {
                    "sent": "And there's also we could also after each experiment infer edges because an experiment gives information, then we could again use these learning techniques from observational data to infer other edges.",
                    "label": 0
                },
                {
                    "sent": "So there are possible future extensions of this work.",
                    "label": 0
                },
                {
                    "sent": "That's it, I think.",
                    "label": 0
                },
                {
                    "sent": "Yeah, there are questions I'll take.",
                    "label": 0
                },
                {
                    "sent": "Data with the.",
                    "label": 0
                },
                {
                    "sent": "Just by observing a system not intervening.",
                    "label": 0
                },
                {
                    "sent": "So there's a system you have data of a system without performing experiments in it, which is an as opposed to that we have.",
                    "label": 0
                },
                {
                    "sent": "We do control randomized experiments.",
                    "label": 0
                },
                {
                    "sent": "That's what I call experimental data, and not doing that observational data.",
                    "label": 0
                },
                {
                    "sent": "Just seeing a system and collecting data with.",
                    "label": 0
                },
                {
                    "sent": "For example, extra astronomical data is observational data.",
                    "label": 0
                },
                {
                    "sent": "For example, typically and what you do is experimental, your your results are experimental.",
                    "label": 0
                },
                {
                    "sent": "You manipulate the domain, etc.",
                    "label": 0
                },
                {
                    "sent": "For example.",
                    "label": 0
                },
                {
                    "sent": "1.",
                    "label": 0
                }
            ]
        }
    }
}