{
    "id": "4dy4msfppouty4y7qmcb7yucmq7u6cvo",
    "title": "Graph Theory",
    "info": {
        "author": [
            "R\u00e9mi Monasson, National Center for Scientific Research (CNRS)"
        ],
        "published": "Nov. 21, 2013",
        "recorded": "September 2013",
        "category": [
            "Top->Physics->Statistical Physics",
            "Top->Computer Science->Network Analysis"
        ]
    },
    "url": "http://videolectures.net/netadis2013_monasson_graph_theory/",
    "segmentation": [
        [
            "My name is reminiscent working in Paris and I was asked by one of the organizers to tell you something about graphs from graph so so I do my best so.",
            "But the first question I'd like to ask you is who in the audience already know, know or knows a lot about random graphs and who never heard about them.",
            "OK, you all know something about random crap.",
            "So I think maybe the first part of the lecture will be just a basic reminder about random graph properties and then I'll try to introduce some statistical physical approach to the typical properties of random graphs and also large deviations.",
            "I mean reference properties that you see with very tiny probabilities when the size of a graph is large.",
            "So."
        ],
        [
            "So there will be 3 lectures.",
            "The first one as I said would be about typical on rare properties of random graph, so I will mostly specialize to elders for any random graphs that is possible graphs.",
            "But I will say also a few words about other graphs.",
            "We fixed degree distributions, which is not necessarily a person.",
            "Then tomorrow we'll talk about dynamical processes on one graph, modifying the structure of graphs on how we can monitor the dynamical evolution of these processes.",
            "In an analytical way and we talk about the server replica metal.",
            "So we first 2 lectures will be illustrated at some examples of the optimization problems or I should say more precisely, random Boolean systems of equations and so it's a nice example of something which is a practical kind of practical interests where you can see a lot of concepts like phase transitions in random graphs.",
            "You can see really the whole how these concepts can be studied on how they.",
            "The emerge in the study of this model, and then the last lecture will be slightly different since I'll talk about special map, so it's kind of random graphs in 212 dimensions you will see how I define this later on Wednesday and we talk about spin glass models for storing random special Maps, which are kind of, let's say, hopeful like models and how they are connected to a recent experiments in your biology, and how analytical theories of this.",
            "Static and the dynamic properties of these random special map models can be can be done.",
            "So at the end of the lecture today, I will give you one exercise that you are free to study an awful next time and I'll do exactly the same thing tomorrow morning and then the solution of exercises are on the web page I just created, which is here and you finally saw the lecture notes of all the different lectures here, so please have a look at the web page and if you find mistakes in the notes I'm sure are plenty of mistakes.",
            "Just let me know so that I can update the notes OK.",
            "So I don't know if you really had time to write down the webpage.",
            "OK, So what I'm going to tell you more precisely today about is so I'll make a very short."
        ],
        [
            "Introduction to statistical ensembles of random graphs and remind you of the basic properties of the small components and large components in random graphs.",
            "And then.",
            "I illustrate all these properties in the special in the special case of the population transition in random took exercise, which I would define later in detail, and then how this all these properties are.",
            "More properties can be found like using the postmodern in statistical mechanics and how also all these techniques can be extending to find dimensions and to study population transition in finding dimension.",
            "So let me start now.",
            "So most of what I'm going to tell you will be on the blackboard, so I hope that everybody can see the blackboard.",
            "So I will consider two ensembles of random graphs which are most of the time.",
            "Say.",
            "Consider only mathematical literature because for most typical properties of random graphs they lead to equivalent properties.",
            "But since the second part of the lecture will be interesting in rare events they actually are different, so we first.",
            "And somber is is following so so you have a set of points which are called vertices.",
            "So end artices.",
            "And in between vertices will have some edges or bonds.",
            "So this is 1 edge.",
            "And in the first ansambl, the number of edges is fixed, so this is a fixed.",
            "Number of edges and samples.",
            "So let me call this sticks number me number of edges and what we do with you.",
            "Just throw randomly the edges among the total set of possible edges so you see you have an over.",
            "Two sets of vertices.",
            "I will select any pairs among this number of pairs of vertices and I will draw a cheese in between.",
            "OK, so each possibility has equal weight, so there is a flat uniform measure over all possible graphs built this way.",
            "So the probability of graphs in this case.",
            "Is simply.",
            "One over the number of possible choices of any among any other tool.",
            "So obviously hear me can be any number between zero and two, but I will mostly specialize in the case where the number of edges scales at the number of vertices in the last 10 limit, so of interest is the case where any will be proportional to end with a constant factor.",
            "Here proportionately factor which I could see over 2 and see.",
            "Simply is the average degree.",
            "This is the average number of neighbors of a vertex here in the graph.",
            "OK, so here Annie's fixed.",
            "So the second sample we consider is a fixed probability and sample.",
            "So in the fixed probability and summer what I do is that I don't fix me exactly, but I just fixed the average value of any.",
            "OK, so how do I do that?",
            "I will consider all the pairs of vertices 1 by 1.",
            "And for each pair of vertices here I will put an edge with probability P. So probability of a net.",
            "Is it big enough?",
            "Can you read here or is it too small?",
            "Just let me know.",
            "It's OK, so probability of edge.",
            "Will be which I copy.",
            "I will call it C over Anna.",
            "OK, I just repeat this process for each pair for every pair of vertices.",
            "OK, so at the end of the game I get a random number of edges.",
            "Whose average value will be C of N times the number of pairs of vertices.",
            "OK, which is which case like C N / 2 when N is large, so C here is the average degree.",
            "For graphics, so I get the same definition for C, which is always the average degree between samples are different in the sense that here the number of edges is fixed, while here it's creating.",
            "So for most typical properties, when N is very large, it doesn't matter at all, since the typical fluctuation I get here from the number of edges are of the order of square root, a banner which is very small compared to the average number which is of your door panel.",
            "So being in the fixed number of edges or fixed probability of edges and samples doesn't change anything for typical properties.",
            "But if we look at large deviations like these events, which take place with very small probabilities, that makes a big difference.",
            "So why are we interesting in reference, so that plenty of physical applications to reference?",
            "So let me just say two of them, so first one is for instance, if you're interested in first order phase transitions.",
            "So suppose for instance you have two different phases.",
            "And you may be trapped in one of the two phases, which is just a metastable state.",
            "OK, so something which is very interesting if you unlimited metastable state and this is not the most stable state, then you may be trapped in this state for a very long time.",
            "So what you want to know, for instance, is the large time of the metastable state, how long it will take before you escape, and find the thermodynamically stable phase.",
            "And this happens through a rare event which is a large situation compared to the typical properties of the metastable phase.",
            "OK, so it's a rare event, but which is very important because that's something which will eventually take place and will lead you to the thermodynamical equilibrium.",
            "Another example you can think, for instance, in many dynamical processes with absorbing states that it states that once you are there then you won't move anymore.",
            "So let me give you an example.",
            "In the ecological system, for instance, you have a population or it's a different species interacting in some environment and these different species will just eat each other or create each other and so on.",
            "OK so.",
            "So you get a system of equation if you want to model the system where you have all the population number of species which interact together.",
            "Now what is very important, of course, is that you can track the population levels as a function of time, and maybe you will see some fluctuation because there might be some randomness in the system.",
            "Obviously something which is very important to know is whether all the species will survive or what is the probability after some time T that one of the species, for instance, will disappear, which is called extinction probability that something very important in the logical system.",
            "So this may happen through large fluctuations, but you see here, so it's very unlikely that one of the species will disappear.",
            "But if it happens, there are dramatic consequences.",
            "So the question is not only of.",
            "I mean we are interesting in very small probabilities because our events with very large consequences OK.",
            "So in this one, part of a lecture.",
            "This is with what I will consider.",
            "OK, so we have these two examples here so that when somebody have as I said, same typical properties for most properties.",
            "But there are this one is more is more useful in let's say it's better, more convenient in numerical simulations because you know numerical simulation, it's easy to let's say if you fix the number of edges then you just have to draw randomly the number the pairs on which we said she's will come OK will be attached true.",
            "And that's it.",
            "It takes time proportional to and E so proportional to the number of edges.",
            "Now if you do analytical studies, this one is better simply because you have less correlations.",
            "OK, because all repairs are independent from each other, so this one is more convenient from an analytical point of view.",
            "So one important property in these two models, and let's look at this one here, is the distribution of a number of degree of degrees.",
            "So the distribution of the number of neighbors.",
            "So let me consider one vertex.",
            "Yes.",
            "If we go to come dynamically.",
            "C remains constant because me and Ann are increasing at the same rate, yes.",
            "Yes, absolutely piece case like one event, yes.",
            "Damn, it limits Pickles to zero while she remains constant.",
            "Yes, this is OK. You can consider the limit where P is fixed.",
            "Then you will get a number of edges of the order of square.",
            "Which is fine.",
            "It's a well defined random sample statistical sample.",
            "But I'm mostly interested in the case of value across where the average degree of a node of a vertex is of your of 1.",
            "So P goes goes to 0 like one of them.",
            "Well, I mean, you could also consider the case where piece or the 1 / N ^2 you would have a finite number of edges in the graph when angles are in the old cases are of interest.",
            "It depends on what you want to study.",
            "So let me consider one vertex here on this path will be connected to a certain number of neighbors just after the random graph has been drawn.",
            "An 1 interesting quantity is the distribution of a number of neighbors.",
            "So rule of these.",
            "So what is wrong V?",
            "Then you see how to choose among the vertices.",
            "The other vertices here.",
            "I will put an edge or not and So what I will do is I will choose if I got the neighbors I will choose among N -- 1 vertices here which neighbors which vertices will be the neighbors.",
            "And the probability of having such an edge in between these vertex and the neighbors here will be C of N. For each, for each edge.",
            "So I got C of N times to the power VI and all the other vertices are not connected to vertex.",
            "I'm considering here.",
            "So we have a probability 1 -- C of N. To the power N -- 1 -- P. And this has a well defined limit when N goes to Infinity at 6V.",
            "Which is just a portion of it.",
            "So we get to post on low of para meters C, which obviously as C as an average value, which is exactly the definition of see here the average degree, but we get the whole statistics of a number of neighbors of a note here.",
            "So this person law is just a consequence of my statistical examples.",
            "I could have defined random graphs in a different way and I would have found maybe different statistical distribution.",
            "OK, so in fact many people have studied other random graph and samples where the degree distribution is not a person law, but it's any arbitrary law you can think of OK.",
            "So the other statistical ensemble.",
            "With a different law.",
            "Rudy.",
            "So let me give you 2 examples.",
            "So one interesting case is the case where he decree does not fluctuate all the vertices in the graph has exactly the same degree K. Sophie's degree.",
            "K. Or see if you prefer OK.",
            "So these are called, let's say a fixed number of fixed degree graph random graphs and other examples which is very popular and so are scale free graph.",
            "Where Ravi decreases as 1 / E two V2 some power towns.",
            "So it's a power law decreasing here with some expanding towel for large.",
            "Decrease.",
            "But if you see, you can define whatever you want and the interesting quantities.",
            "Characterizing this distribution here is the generating function.",
            "So let me just introduce two things which will be useful in forming.",
            "One thing is the generating function for ALDI.",
            "It's just another way of characterizing World B, which is just the sum, so G is 0X.",
            "It's just the sum of Y role of VX to the V. So I just build the series whose coefficients here are the different probabilities of having the vertices.",
            "The neighbors OK.",
            "So that's a generating function for the number of neighbors.",
            "And we can build another generating function which will be useful when we talk about percolation transition a little bit later today, which is the following, which is the number of descendants of a vertex.",
            "So what do I mean by that?",
            "I mean the following things.",
            "So again, let me look at a random graph here which was built through some process.",
            "I'm not specifying the process here to build the graph, I'm just assuming that there is a process which is able to generate on graphs with such a degree distribution here OK.",
            "So I give you some very succinct references on the web page and you will see that the book Bible Bash variable Bash for instance, where you will find some examples of how to generate random graphs with any probability distribution for decrease.",
            "So suppose I I've drawn my graph and I would like to know what is the if I pick up an edge, for instance here randomly.",
            "Let's say this edge here and then I pick up 1 / 2.",
            "Vertices in coming onto that edge.",
            "So for instance this one.",
            "What is the average number of descendants policy?",
            "What is the probability distribution for the number of descendants of this node here?",
            "So you see I pick up an edge, I pick up the node which is attached to the edge.",
            "So this node by definition is linked to another vertex here, but it will.",
            "The neighbors, which I could with descendants of the nodes.",
            "So what is the distribution of the primes, which is the number of these salads?",
            "E prime?",
            "It can be the same distribution afro's robe.",
            "It can be something different.",
            "So what is the value of this distribution?",
            "So we see when I pick up an edge here randomly and then one of the nodes which is attached to the edge, then the probability of picking a node here vertex with V neighbors.",
            "And then, oh sorry if I pick up an edge and then one of the two nodes here, then I will pick up.",
            "Yes this this not having the neighbors with probability proportional to Roe V, obviously.",
            "But then also with probability proportional to V, simply because what I'm doing here is I'm not picking up.",
            "I mean, one of the of the of the edge of the vertices here randomly.",
            "What I do first is I pick up randomly and match.",
            "And the property that is as is attached to vertex of degree D is proportional to V. OK, so the probability of picking a node with the neighbors here will be proportional to V times through P. We need proportional to this, obviously depriving the number of descendants will be D -- 1.",
            "So which means that the probability.",
            "Stop having.",
            "Deep on descendants.",
            "Which I call rule one of the prime.",
            "Will be proportional to V Prime plus one.",
            "Times through V Prime plus one and then that should be normalized and I should some of the V prime going from zero to Infinity Infinity here.",
            "And you see what I got here is just the average degree of a vertex in the graph.",
            "So this is just D here, which is the sum of the V of Robbie.",
            "So this distribution here will be useful.",
            "We will use it a little bit later in the lecture and you see it might be equal, or it might be different from this one.",
            "Because they describe two different random processes, one is you pick up a vertex and then you will just draw some edges from this vertex.",
            "OK, so you will have a distribution of neighbors, the other one is you pick up an edge and you look at one of the two vertices attached to the edge and you see how many other neighbors this vertex has, which is something else.",
            "OK, so for instance, if I look at the statistical example where all vertices have exactly K neighbors.",
            "Then obviously this is simply a Chronicle, Delta in the equal to take 2K.",
            "And this is simply a Chronicle, Delta in vehicle 2K minus one in V prime equal to K -- 1.",
            "Now what is interesting is that if you look at the at the case where the distribution is Poisson here.",
            "Which is the case of two and samples I've introduced before.",
            "What will be the distribution here?",
            "Can you guess what will be the distribution here for this one?",
            "Sorry.",
            "Yes, but I multiplied by this here so it will be again a person with the same average degree.",
            "In fact, if you have personal events, OK, suppose you have a note here which is connected to this one.",
            "Since the all the edges are just personal, once they are drawn independently from each other, knowing that this vertex here has already one neighbor here doesn't tell you anything about the other one.",
            "So Ravi Prime will be exactly the same Romana V. Prime will be saved as well.",
            "OK, so.",
            "I will use that little bit later, so let me go back now to the 1st.",
            "Two statistical example are introduced.",
            "And let us try to see what are the listed typical properties of these random graphs.",
            "So just to make life a bit simpler, let's consider a fixed probability and sample.",
            "Fixed probability of an edge.",
            "Which I called P equal to see about N. And I want to describe the typical features of a graph.",
            "So I will have some some some vertices here and some edges and I would like to know what the graph looks like so."
        ],
        [
            "So here are some examples.",
            "So they were drawn actually in the.",
            "With the different samples, but I told you they will.",
            "Typical parties at the same.",
            "And here you see just random randomly drawn graphs, which I obtained for SQL 2.5.",
            "Sequel to one ounce equal to two.",
            "I just did a random commit and not a random convenient permutation of the vertices, and I put them in the on the plane so that no edge cross each other here obviously because there is no reason why the graph should be planner.",
            "OK, so it's just a convenient way of putting graphs.",
            "So you see, at low degree you would expect a random graph to be like that.",
            "A lot of vertices will be isolated and you will find also some small components connected components, so a quantity of interest is how many connected components do you have?",
            "So this is something we would be very interested in.",
            "How many of them?",
            "And a distribution of sizes.",
            "Obviously, all of these quantities are stochastic quantities, but we would like to compute the average and also the distribution.",
            "Then, um.",
            "If you look at very high degree average degree, so for instance equal to here you see that there might be.",
            "Components where we find structures which are complex.",
            "For instance, here you see a cycle.",
            "Which you don't find hearing this random realization at Lowe's, he.",
            "So an interesting question is how many cycles do you get in components?",
            "OK, so components, maybe 3?",
            "Or they may be more complicated, so side trees with some unicycles or more complicated here you see two different cycles and so on.",
            "So we'd like to know something about the distribution of cycles, or let's say the presence of cycles.",
            "So what we want to do is to characterize the structural properties of these crowds.",
            "OK, so.",
            "So what can we say?",
            "So let's have a look at these properties, very simple.",
            "The relation of these properties, which is not a rigorous derivation, but the results I'm going to show you are exact and they can be proven exactly.",
            "So what I will consider the following, so I will consider sub graph.",
            "G. Prime.",
            "With the vertices.",
            "So for instance on edges.",
            "So for instance, I can consider case where I've got V equal to 4.",
            "An equal to three, which is just a star graph.",
            "So V = 4.",
            "He equals 3.",
            "And this graph is labeled, so it means that vertices.",
            "Carry some numbers 1234.",
            "So it's a labor graph.",
            "So what do I mean by labor?",
            "I mean that, for instance, this graph here and this one are not the same.",
            "If I change the ordering.",
            "Here are the numbers.",
            "Then I get something else.",
            "OK. Well, if I had unlabelled graph they would be equal job.",
            "Just ask on four different vertices.",
            "And the question I'm asking now is how many copies of these subgraphs will find in my random graph.",
            "Typically.",
            "Only see let's count something simple simple.",
            "Let's count how many copies will I find in my own graph of this sub graph on average.",
            "So average number of copies.",
            "Then you see, maybe I will find that this average numbers is very high or I will find it's very small and then it's a way, let's say, to probe the random graphs to see what is inside and what it looks like.",
            "OK, just a simple way of identifying the different components connected components of a graph.",
            "So this graph here I should have said before, is it connected subgraphs so it's made of one single speed piece?",
            "I can go from any vertex to another one through the set of edges.",
            "OK, so how do I do that?",
            "So first in order to compute this average number of copies, I must so localize all these copies.",
            "So how do I do that?",
            "I first have to choose the number.",
            "I mean choose the vertices among the N vertices available vertices, so will have a convenient manufacture envy, which is a choice of vertices.",
            "OK, then I will label these vertices with vertices I have chosen from one to V, for instance one to four here in this example and then I get my label sub graph.",
            "Now I want to build the sorry I get my labor set of vertices.",
            "Now I want to build the edges and I will do.",
            "I will do that with the fix probability of an agent sample.",
            "So how many?",
            "How many edges two should I draw?",
            "I should draw exactly E edges in between these virtues here.",
            "So that will be done with probability C of N to the East.",
            "And I want to make sure that there is no other edges in between these vertices here which I don't want and with the other vertices.",
            "In the remaining part of the graph.",
            "OK, so this will be done with probability 1 -- C of N for the number of forbidden connection or forbidden edges if you prefer.",
            "So I've got forbidden edges inside the.",
            "My subgraph here and how many of them do I have.",
            "I have the times 3 -- 1 / 2 -- E. And then I've got forbidden connection with the remaining part of the graph, which is V * N -- V forbidden edges.",
            "So it's a probability.",
            "So what I've written here is this part.",
            "Here is just the probability that this B points higher identified these vertices.",
            "We have randomly drawn edges and at the end the sub graph which I obtain is looks like this one here the G prime I have selected at the beginning.",
            "The remaining part of the graph will do something else.",
            "I don't care what I want to be sure is that the subgraphs which I built from my vertices will be exactly this one.",
            "OK, and then here I count how many ways I have to choose the video vertices.",
            "So this is the average number of copies of this label graph.",
            "So let's count a little bit further and see what happens when N is large.",
            "So I will assume that the subgraphs G prime is small, that is V prime D small.",
            "So small means here.",
            "Small compared to Anna.",
            "So it's not very well precise, well defined mathematical notion.",
            "You will see a limit later.",
            "What it means precisely?",
            "I'm assuming it goes.",
            "It is smaller than anything I need in order to have a well defined limit quantity here.",
            "So I can.",
            "So this is the number of copies here, number of G prime.",
            "The average number so number of G prime.",
            "Let me just simplify it, this formula here.",
            "So you see I can approximate this combinatorial factor here by end to the V / V factorial.",
            "OK, so this is N * N -- 1 and minus two and so on.",
            "Two N -- B + 1 which is essentially end to the V when is large compared to V. Then I got C of N2E.",
            "And the whole thing here, when these small and E will be small because he is at most B squared of two, will be dominated by the end.",
            "This is the important term here in the sun at the exponent.",
            "So I get and then I will use 1 -- 3 / N is almost exponential minus C of M, so this is exponential minus C. D. So let me just write it again as C to the E. C factorial exponential minus CD and to the V -- E. Wolf sorry the vector.",
            "Yes, thank you.",
            "OK, so let's look at what happens when N is large.",
            "So the only dependency on anything here in this factor here.",
            "So we have you see three different cases, either D -- E is positive, or that's equal to 0, it's negative.",
            "So what can be the largest value of Y -- E if I fix V?",
            "So what is the largest possible value for East Given B?",
            "With a connected connected component, yes.",
            "Yes, you see if I go to the largest possible case for B, if I got a tree OK, this is the minimal way of connecting vertices.",
            "I cannot do something.",
            "With a smaller number of edges, because it will be disconnected and you see if I got equal 2 I get one edge.",
            "If I got V equal to four I get 3 edges and so on.",
            "It's always v -- 1 so if I D minus equal 1.",
            "Is the largest possible value for D -- E?",
            "OK, and then that correspond to trees.",
            "So if I do that, if I look at this case, I see that the number of copies of my tree G prime is a tree will be proportional to N, so I got a large number of them on average.",
            "And then I get a number of copies which will be.",
            "End time see today.",
            "Um?",
            "The factorial.",
            "Sorry, maybe I'm just want to.",
            "I'm confused about the so E is D -- 1.",
            "Sorry so I have a mistake in my notes, but it's OK. OK, so I may find a large number of trees in my random graph and this is typically what I found using these two small examples here.",
            "So one of the questions we would like to ask is what is the typical value of VI will find.",
            "Obviously I can find trees with only two vertices with four vertices, three vertices and so on.",
            "But if any is fine it now if I gotta find it.",
            "But large random graph.",
            "So N is very large but finite.",
            "What will be the maximum value of Yi will find?",
            "OK, So what is the largest tree I will find in a random graph with N?",
            "Versus it's very fine question.",
            "So what we can see is, so let's look at when for which value of the this quantity becomes equal to 1.",
            "You see, if V increases, this factor here will decrease very fast.",
            "Actually the whole thing will decrease and then it will go down.",
            "At some point this will be exactly equal to 1 / N and then the average number of trees with a larger value of vertices V will be smaller than one one on average.",
            "That means that the probability of having this this trees will be.",
            "Small, OK, so I won't find it anymore.",
            "So before I do that, just be careful that here I've considered the number.",
            "Of copies of 1 particular label trees.",
            "If I want to know what is the average number of trees with vertices.",
            "I have an online one graph.",
            "I have to count how many label trees with vertices there are.",
            "So in this I want to calculation.",
            "Actually it's the result of a famous theorem by Kelly in 1889.",
            "I just give you the result on this."
        ],
        [
            "Right here.",
            "With an example drawn from the I mean taken from the Wikipedia web page.",
            "If you go to Kayla's formula you find this.",
            "So I just copied it from the Wikipedia web page and the answer is V. Two V -- 2.",
            "So again, you can find links to the demonstration of this fact.",
            "I won't do that.",
            "That will be take a little bit of time, but here is an example.",
            "So you see for V equal to two, then you have.",
            "One possible tree here with two vertices on one edge obviously, and then if you take the equal to three, you see three different trees you can make.",
            "So the labels here correspond to the colors.",
            "You have three different colors, so labels 123 and basically what you have to choose is the vertex which is in between.",
            "So there are three different possibilities, so you have three different trees.",
            "So it works so far you see 32V one is 3 and now if you look at the number of trees you can do with four different vertices then are two different structures.",
            "Either you get linear structure this way or you get a star like shape.",
            "So there are four different starlike shapes because you choose the color of the vertex in the middle, and here you have to choose the ordering.",
            "If you can't then against this formula works.",
            "So there is a general demonstration proof of the formula.",
            "And I will just use it and then I will conclude that the average number.",
            "Of trees.",
            "With the vertices.",
            "Is equal to end times C two V -- 1 / 3 factorial V to V -- 2 exponential minus CD.",
            "So now we can answer the question as just before.",
            "What is the maximum size of the tree I will find in my in typical random realization my graph.",
            "So what I want to see is when for which value of the this number here this average number becomes equal to 1.",
            "OK so D will be large.",
            "So we have to be careful here, but yes.",
            "John, John oh hello John.",
            "Nice to see you.",
            "OK so I said these should be small with compared to end in order to get this formula right but then now I'm looking at large B so then we'll see whether the two statements can be compatible or not OK, let me push this formula to large fee and look at the asymptotics of this formula so I get N. So now I will have an exponential V time something.",
            "So what is this something here I can neglect?",
            "The one compared to VI don't care and get a log C. Then I get plus B -- 2, But the minus two is not important here, so it will be plus one.",
            "Because press log, sorry.",
            "And here I gotta minus C. This is the numerator.",
            "And let's look at the denominator, which is just so your V and I will use stealing formula.",
            "I know, but Factorial V is essentially exponential V log D. Minus D plus terms of Yoda flog V. OK, just starting from there.",
            "So you see that a few things cancel.",
            "So this one cancel this one here.",
            "And the outcome of formulas that I get.",
            "Find exponential D. Minus Y.",
            "Plus one or, let's say, let's put the minus in front.",
            "Here I get C -- 1 minus loxy.",
            "So you see that for LG VI get an exponential decrease of the average number of trees with the vertices here.",
            "So that means that there will be a cut off from the maximum size of the number of maximal number of vertices, which is when this average number here become equal to 1 so VMAX.",
            "We just did Max.",
            "Will be so let me just write.",
            "This is equal to 1.",
            "I take the log is Logan.",
            "Over C -- 1 minus loxy.",
            "OK.",
            "So this is nice because this is much larger than one, so it makes sense to make the expansion in the case a synthetic expansion when we is large, but it's certainly much more of an animal, so all the calculations I've done before where I completely neglected this squared compared to N and so on.",
            "OK, so the larger subtree largest country I should find, my random graph should be on the order of log North vertices, and we have a more precise scaling here."
        ],
        [
            "So this is what I should find.",
            "There should be one copy of a graph with this number of vertices.",
            "So you see that this maximum number depends on C. So if C is very small.",
            "Then minus look see is very large and Logan over something very large is very small, so VMAX is very small, which makes sense if I have a few edges.",
            "I do not expect the largest subgraphs of tree to be very large.",
            "OK, we can be logged over something which is very large, but now if you look at this quantity here and this quantity goes to zero when he goes to one.",
            "OK, so we expect the you see we have a problem here because then the number of vertices will be larger than Anna.",
            "At some point.",
            "It seems too close to 1, which is certainly not possible with because anything total number of vertices in the graph.",
            "So that means that the assumption we are made here breakdown if C is too close one.",
            "So something takes place when she goes to one.",
            "OK, so everything I did here was very large.",
            "See find it and then you see that everything is breaking down when sequels to one.",
            "So what happens when C is equal to 1?",
            "So I will just give the result and then we'll see a little bit later how that can be shown or found back.",
            "Let's say using statistical mechanics arguments that when she goes to and actually what we get, is that.",
            "We have other things which have a lot of cycles.",
            "OK, so just one more comment before I go to SQL one.",
            "You see forces smaller than one.",
            "We have seen that we have many trees, but I've not considered the other cases where V minus is equal to 0 or B minus is equal to minus 1 -- 2 and so on.",
            "So let's do that very quickly.",
            "So for V minus equal to 0, which is the next case here.",
            "So how many components do we have with the minus equal to 0?",
            "Then we get a finite number of them because this is entrance zero on average.",
            "So we come a little bit later too that when I consider the random access, that problem will compute the average number of components with.",
            "Minus equal to 0.",
            "So what does that mean?",
            "That the minus is equal to 0?",
            "Which kind of graphs have the minus equal to 0?",
            "There are trees where I put an additional edge.",
            "OK, and then I get a tree with a cycle, so it's not a tree anymore, it's a unicycle.",
            "OK on the graph subgraph with unicycle so the number of subscribers should be on the order of 1.",
            "On average, OK, and then if IV minus is equal to minus 1 -- 2 and so on, you see that this numbers goes to 0, so on average I get to vanish in number when N goes to Infinity, which means I don't find these subgraphs in my random graph with high probability, so I can simply neglect them.",
            "So this is not true.",
            "When she goes to one, because when sequence one then I get the objects which are more complicated than trees.",
            "And let me just give you the result and then we'll see what happens when she is not even once.",
            "So when secret one.",
            "Then then we have the largest component.",
            "I'm not on the order of log in anymore.",
            "They will contain N to the 2/3 vertices.",
            "So I'm not giving any proof of that will come back to this point later.",
            "At the end of electric I've got enough time, but this is a important result of calculation, so SQL one is called percolation threshold for the obvious reason that foresee larger than one.",
            "Then we get a large component.",
            "So the largest components now contain.",
            "Define attraction.",
            "Open up the Overbrook cinegraph.",
            "And this function I called gamma of C. That means that the number there will be one big component here, for instance, which contains a number of vertices of the order of angle.",
            "And the fraction.",
            "The factor here is a number between zero and one, which is a function of C. Obviously there will be, so you can see it here from this very simple example, but there will be other small disconnected components which have some statistics like the one we find foresees more than one below the percolation threshold.",
            "They will be just isolated trees.",
            "So what is the value of gamma C?",
            "And how many components do we have?",
            "Process large one so here."
        ],
        [
            "Uncurved so.",
            "So this card here is the fraction of the vertices which are inside the largest component which is called the giant component.",
            "So when see smaller than one, this is zero, simply because the largest component as we saw it contains Logan purchases.",
            "So Logan over N goes to zero when angles Infinity, while when C is larger than one, you get a number of vertices of the order of North.",
            "So Gamma C is solution of equation.",
            "1 minus gamma is equal to exponential minus C, and this is what is plotted here.",
            "So gamma is equal to 0 is always a solution of this equation and this is the only solution you get when season one and for the large man when you get another solution for this equation, which is the right value for fractional vertices in the giant component.",
            "We can also compute, for instance, the number of clusters.",
            "So the number of connected components, if you prefer, so foresees more than one solution is very simple, because most components are trees.",
            "That means that each time you add a new edge, so you suppose you suppose you built from the empty graph your random graph by adding more and more edges.",
            "So this is increasing.",
            "So each time you add a new edge, what you're doing is simply aggregating one isolated vertex to tree, so.",
            "The number of connected component decreased linearly with the average connectivity here and you get the slope which is 2.",
            "Minus two sorry OK, which can be easily understood because each time we put an edge then the degree of two nodes will increase.",
            "OK so there is a factor 2 between the the slope.",
            "I mean the DE over the equal to two OK is equal to 1/2.",
            "Sorry so you get this low power minus well here when you add edges.",
            "Above the critical threshold, what happens is that in many cases you will add edges to a giant component and the number of components will not decrease, so the decrease rate.",
            "Here the decay rate of the number of components get smaller than this one, and you get this this curve here.",
            "This moose curve going down very smoothly and much more slowly than the beginning here.",
            "So how can we understand in a very empirical way this formula?",
            "So it's very easy to understand.",
            "So let me just give a very."
        ],
        [
            "Empirical derivation.",
            "So suppose you accept that there is a large component when C is larger than one, and here is the situation of my random graph.",
            "OK, with a certain number of edges, and now what I will do, I will add a new edge.",
            "Sorry I will.",
            "I will add a new vertex to my random graph and in order to make to make this vertex typical for the new random graphs that will update, I will obtain at the end of the process.",
            "I'm assuming that the number of neighbors of these new vectors is is personeel.",
            "So it's a personal with partner to see.",
            "OK, so you see you have this random graph here you are adding a new vertex with some edges like this and you are gluing these different edges on the different.",
            "Vertis is here.",
            "So the question is, how will the size of a giant component change when I do that?",
            "OK so I can make a very simple reasoning here which is.",
            "So what is the probability that my new vertex here will not belong to the giant component?",
            "So what is this probability?",
            "I'm assuming that the giant components contains a fraction gamma over different sites here.",
            "So what is this probability if I just throw randomly the edges?",
            "So why do I have to do is I have to pick up the neighbors of this vertex here outside the giant component?",
            "OK, and I'll just be independent processes, so we probably have this.",
            "Would be 1 minus gamma Trudy.",
            "Right?",
            "So probably that I pick up the neighbor which is not in the giant component is 1 minus gamma and that has to be repeated these times.",
            "If I constrain to, this is conditioned to the number of neighbors here.",
            "Now, if the number of neighbors D is a person law in order to get the average probability here, I just have to sum up on the on the on the person distribution for V. OK, so this is conditioned to D and now with total probability the right probability that this new vertex does not belong to the giant component, not condition to V. Will be some of the going from zero to Infinity of C2V D factorial exponential minus CD, which is the personal for V * 1 minus, B. OK, and you see what this is simply an exponential minus C + C -- C gamma, which is exponential minus Sigma.",
            "But then if I assume that you know if I have N vertices, a random graph with N vertices on N + 1 vertices doesn't change the fraction of citing the giant component when N goes to Infinity.",
            "Just correction of the other one over North.",
            "Then it means that this probability here should be equal to 1 minus gamma.",
            "This is just.",
            "City of being outside the giant component, get one minus gamma is equal to exponential minus Sigma, which is what I want.",
            "So this is not a rigorous derivation, but you understand.",
            "I mean, it's a very simple duration which gives you the flavor of a real argument.",
            "So obviously there are plenty of things we could discuss, for instance, how many big components do we have?",
            "So at the critical point when sequel to one, we may have many different components with end to the 2/3.",
            "Crystals, but as soon as we are both equal 1 then you see that having more than two giant components will be very unstable because it's very likely when when you add an edge then you will connect together.",
            "The two giant components, so one of them will disappear very soon and you get only one.",
            "So the only this argument very simple explains why there would be only one giant component with high probability.",
            "OK.",
            "So I think this is basically what I wanted to say about the heuristic description of random graphs.",
            "And just one point here, everything was done with the personal distribution.",
            "Then you can ask what happens if I've got a different degree distribution.",
            "For instance, carefree, fixed number of neighbors and so back.",
            "Then as I write in the notes and you can see on the web then.",
            "There will be some equivalent condition for C for the average connectivity and this equivalent condition, which I write here.",
            "Is the following that you can understand so you can do the same argument and the argument would be simply that suppose you have you have this graph here.",
            "Sorry you have this graph here.",
            "So now it's not a person graph anymore, it's it's another example, but I can always do my heuristic argument here and add a new vertex vertex here.",
            "So this new vertex will have some degree distribution here, which is given by by Roman.",
            "Or remember what we do right before and then the condition will be written.",
            "In this way we can do the computation and I'm just giving you.",
            "The result is that the condition will be the sum over V. Often the kinds V -- 2 Roe V should be larger than 0.",
            "So there are two possibilities.",
            "Either this condition is satisfied and the giant there will be a giant component in the random graph, or it's violated.",
            "So this left hand side is negative, then there will be many different small disconnected components in the graph.",
            "OK, and you can see that for every person in case you find my exactly equal 1 when you apply this question.",
            "So I don't want to give more details but just saying that the same argument can be done."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "My name is reminiscent working in Paris and I was asked by one of the organizers to tell you something about graphs from graph so so I do my best so.",
                    "label": 0
                },
                {
                    "sent": "But the first question I'd like to ask you is who in the audience already know, know or knows a lot about random graphs and who never heard about them.",
                    "label": 0
                },
                {
                    "sent": "OK, you all know something about random crap.",
                    "label": 0
                },
                {
                    "sent": "So I think maybe the first part of the lecture will be just a basic reminder about random graph properties and then I'll try to introduce some statistical physical approach to the typical properties of random graphs and also large deviations.",
                    "label": 0
                },
                {
                    "sent": "I mean reference properties that you see with very tiny probabilities when the size of a graph is large.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So there will be 3 lectures.",
                    "label": 0
                },
                {
                    "sent": "The first one as I said would be about typical on rare properties of random graph, so I will mostly specialize to elders for any random graphs that is possible graphs.",
                    "label": 0
                },
                {
                    "sent": "But I will say also a few words about other graphs.",
                    "label": 0
                },
                {
                    "sent": "We fixed degree distributions, which is not necessarily a person.",
                    "label": 0
                },
                {
                    "sent": "Then tomorrow we'll talk about dynamical processes on one graph, modifying the structure of graphs on how we can monitor the dynamical evolution of these processes.",
                    "label": 0
                },
                {
                    "sent": "In an analytical way and we talk about the server replica metal.",
                    "label": 0
                },
                {
                    "sent": "So we first 2 lectures will be illustrated at some examples of the optimization problems or I should say more precisely, random Boolean systems of equations and so it's a nice example of something which is a practical kind of practical interests where you can see a lot of concepts like phase transitions in random graphs.",
                    "label": 0
                },
                {
                    "sent": "You can see really the whole how these concepts can be studied on how they.",
                    "label": 0
                },
                {
                    "sent": "The emerge in the study of this model, and then the last lecture will be slightly different since I'll talk about special map, so it's kind of random graphs in 212 dimensions you will see how I define this later on Wednesday and we talk about spin glass models for storing random special Maps, which are kind of, let's say, hopeful like models and how they are connected to a recent experiments in your biology, and how analytical theories of this.",
                    "label": 0
                },
                {
                    "sent": "Static and the dynamic properties of these random special map models can be can be done.",
                    "label": 0
                },
                {
                    "sent": "So at the end of the lecture today, I will give you one exercise that you are free to study an awful next time and I'll do exactly the same thing tomorrow morning and then the solution of exercises are on the web page I just created, which is here and you finally saw the lecture notes of all the different lectures here, so please have a look at the web page and if you find mistakes in the notes I'm sure are plenty of mistakes.",
                    "label": 1
                },
                {
                    "sent": "Just let me know so that I can update the notes OK.",
                    "label": 0
                },
                {
                    "sent": "So I don't know if you really had time to write down the webpage.",
                    "label": 0
                },
                {
                    "sent": "OK, So what I'm going to tell you more precisely today about is so I'll make a very short.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Introduction to statistical ensembles of random graphs and remind you of the basic properties of the small components and large components in random graphs.",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 0
                },
                {
                    "sent": "I illustrate all these properties in the special in the special case of the population transition in random took exercise, which I would define later in detail, and then how this all these properties are.",
                    "label": 0
                },
                {
                    "sent": "More properties can be found like using the postmodern in statistical mechanics and how also all these techniques can be extending to find dimensions and to study population transition in finding dimension.",
                    "label": 0
                },
                {
                    "sent": "So let me start now.",
                    "label": 0
                },
                {
                    "sent": "So most of what I'm going to tell you will be on the blackboard, so I hope that everybody can see the blackboard.",
                    "label": 0
                },
                {
                    "sent": "So I will consider two ensembles of random graphs which are most of the time.",
                    "label": 0
                },
                {
                    "sent": "Say.",
                    "label": 0
                },
                {
                    "sent": "Consider only mathematical literature because for most typical properties of random graphs they lead to equivalent properties.",
                    "label": 0
                },
                {
                    "sent": "But since the second part of the lecture will be interesting in rare events they actually are different, so we first.",
                    "label": 0
                },
                {
                    "sent": "And somber is is following so so you have a set of points which are called vertices.",
                    "label": 0
                },
                {
                    "sent": "So end artices.",
                    "label": 0
                },
                {
                    "sent": "And in between vertices will have some edges or bonds.",
                    "label": 0
                },
                {
                    "sent": "So this is 1 edge.",
                    "label": 0
                },
                {
                    "sent": "And in the first ansambl, the number of edges is fixed, so this is a fixed.",
                    "label": 0
                },
                {
                    "sent": "Number of edges and samples.",
                    "label": 0
                },
                {
                    "sent": "So let me call this sticks number me number of edges and what we do with you.",
                    "label": 0
                },
                {
                    "sent": "Just throw randomly the edges among the total set of possible edges so you see you have an over.",
                    "label": 0
                },
                {
                    "sent": "Two sets of vertices.",
                    "label": 0
                },
                {
                    "sent": "I will select any pairs among this number of pairs of vertices and I will draw a cheese in between.",
                    "label": 0
                },
                {
                    "sent": "OK, so each possibility has equal weight, so there is a flat uniform measure over all possible graphs built this way.",
                    "label": 0
                },
                {
                    "sent": "So the probability of graphs in this case.",
                    "label": 0
                },
                {
                    "sent": "Is simply.",
                    "label": 0
                },
                {
                    "sent": "One over the number of possible choices of any among any other tool.",
                    "label": 0
                },
                {
                    "sent": "So obviously hear me can be any number between zero and two, but I will mostly specialize in the case where the number of edges scales at the number of vertices in the last 10 limit, so of interest is the case where any will be proportional to end with a constant factor.",
                    "label": 0
                },
                {
                    "sent": "Here proportionately factor which I could see over 2 and see.",
                    "label": 0
                },
                {
                    "sent": "Simply is the average degree.",
                    "label": 0
                },
                {
                    "sent": "This is the average number of neighbors of a vertex here in the graph.",
                    "label": 0
                },
                {
                    "sent": "OK, so here Annie's fixed.",
                    "label": 0
                },
                {
                    "sent": "So the second sample we consider is a fixed probability and sample.",
                    "label": 0
                },
                {
                    "sent": "So in the fixed probability and summer what I do is that I don't fix me exactly, but I just fixed the average value of any.",
                    "label": 0
                },
                {
                    "sent": "OK, so how do I do that?",
                    "label": 0
                },
                {
                    "sent": "I will consider all the pairs of vertices 1 by 1.",
                    "label": 0
                },
                {
                    "sent": "And for each pair of vertices here I will put an edge with probability P. So probability of a net.",
                    "label": 0
                },
                {
                    "sent": "Is it big enough?",
                    "label": 0
                },
                {
                    "sent": "Can you read here or is it too small?",
                    "label": 0
                },
                {
                    "sent": "Just let me know.",
                    "label": 0
                },
                {
                    "sent": "It's OK, so probability of edge.",
                    "label": 0
                },
                {
                    "sent": "Will be which I copy.",
                    "label": 0
                },
                {
                    "sent": "I will call it C over Anna.",
                    "label": 0
                },
                {
                    "sent": "OK, I just repeat this process for each pair for every pair of vertices.",
                    "label": 0
                },
                {
                    "sent": "OK, so at the end of the game I get a random number of edges.",
                    "label": 0
                },
                {
                    "sent": "Whose average value will be C of N times the number of pairs of vertices.",
                    "label": 0
                },
                {
                    "sent": "OK, which is which case like C N / 2 when N is large, so C here is the average degree.",
                    "label": 0
                },
                {
                    "sent": "For graphics, so I get the same definition for C, which is always the average degree between samples are different in the sense that here the number of edges is fixed, while here it's creating.",
                    "label": 0
                },
                {
                    "sent": "So for most typical properties, when N is very large, it doesn't matter at all, since the typical fluctuation I get here from the number of edges are of the order of square root, a banner which is very small compared to the average number which is of your door panel.",
                    "label": 0
                },
                {
                    "sent": "So being in the fixed number of edges or fixed probability of edges and samples doesn't change anything for typical properties.",
                    "label": 0
                },
                {
                    "sent": "But if we look at large deviations like these events, which take place with very small probabilities, that makes a big difference.",
                    "label": 0
                },
                {
                    "sent": "So why are we interesting in reference, so that plenty of physical applications to reference?",
                    "label": 0
                },
                {
                    "sent": "So let me just say two of them, so first one is for instance, if you're interested in first order phase transitions.",
                    "label": 0
                },
                {
                    "sent": "So suppose for instance you have two different phases.",
                    "label": 0
                },
                {
                    "sent": "And you may be trapped in one of the two phases, which is just a metastable state.",
                    "label": 0
                },
                {
                    "sent": "OK, so something which is very interesting if you unlimited metastable state and this is not the most stable state, then you may be trapped in this state for a very long time.",
                    "label": 0
                },
                {
                    "sent": "So what you want to know, for instance, is the large time of the metastable state, how long it will take before you escape, and find the thermodynamically stable phase.",
                    "label": 0
                },
                {
                    "sent": "And this happens through a rare event which is a large situation compared to the typical properties of the metastable phase.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's a rare event, but which is very important because that's something which will eventually take place and will lead you to the thermodynamical equilibrium.",
                    "label": 0
                },
                {
                    "sent": "Another example you can think, for instance, in many dynamical processes with absorbing states that it states that once you are there then you won't move anymore.",
                    "label": 0
                },
                {
                    "sent": "So let me give you an example.",
                    "label": 0
                },
                {
                    "sent": "In the ecological system, for instance, you have a population or it's a different species interacting in some environment and these different species will just eat each other or create each other and so on.",
                    "label": 0
                },
                {
                    "sent": "OK so.",
                    "label": 0
                },
                {
                    "sent": "So you get a system of equation if you want to model the system where you have all the population number of species which interact together.",
                    "label": 0
                },
                {
                    "sent": "Now what is very important, of course, is that you can track the population levels as a function of time, and maybe you will see some fluctuation because there might be some randomness in the system.",
                    "label": 0
                },
                {
                    "sent": "Obviously something which is very important to know is whether all the species will survive or what is the probability after some time T that one of the species, for instance, will disappear, which is called extinction probability that something very important in the logical system.",
                    "label": 0
                },
                {
                    "sent": "So this may happen through large fluctuations, but you see here, so it's very unlikely that one of the species will disappear.",
                    "label": 0
                },
                {
                    "sent": "But if it happens, there are dramatic consequences.",
                    "label": 0
                },
                {
                    "sent": "So the question is not only of.",
                    "label": 0
                },
                {
                    "sent": "I mean we are interesting in very small probabilities because our events with very large consequences OK.",
                    "label": 0
                },
                {
                    "sent": "So in this one, part of a lecture.",
                    "label": 0
                },
                {
                    "sent": "This is with what I will consider.",
                    "label": 0
                },
                {
                    "sent": "OK, so we have these two examples here so that when somebody have as I said, same typical properties for most properties.",
                    "label": 0
                },
                {
                    "sent": "But there are this one is more is more useful in let's say it's better, more convenient in numerical simulations because you know numerical simulation, it's easy to let's say if you fix the number of edges then you just have to draw randomly the number the pairs on which we said she's will come OK will be attached true.",
                    "label": 0
                },
                {
                    "sent": "And that's it.",
                    "label": 0
                },
                {
                    "sent": "It takes time proportional to and E so proportional to the number of edges.",
                    "label": 0
                },
                {
                    "sent": "Now if you do analytical studies, this one is better simply because you have less correlations.",
                    "label": 0
                },
                {
                    "sent": "OK, because all repairs are independent from each other, so this one is more convenient from an analytical point of view.",
                    "label": 0
                },
                {
                    "sent": "So one important property in these two models, and let's look at this one here, is the distribution of a number of degree of degrees.",
                    "label": 0
                },
                {
                    "sent": "So the distribution of the number of neighbors.",
                    "label": 0
                },
                {
                    "sent": "So let me consider one vertex.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "If we go to come dynamically.",
                    "label": 0
                },
                {
                    "sent": "C remains constant because me and Ann are increasing at the same rate, yes.",
                    "label": 0
                },
                {
                    "sent": "Yes, absolutely piece case like one event, yes.",
                    "label": 0
                },
                {
                    "sent": "Damn, it limits Pickles to zero while she remains constant.",
                    "label": 0
                },
                {
                    "sent": "Yes, this is OK. You can consider the limit where P is fixed.",
                    "label": 0
                },
                {
                    "sent": "Then you will get a number of edges of the order of square.",
                    "label": 0
                },
                {
                    "sent": "Which is fine.",
                    "label": 0
                },
                {
                    "sent": "It's a well defined random sample statistical sample.",
                    "label": 0
                },
                {
                    "sent": "But I'm mostly interested in the case of value across where the average degree of a node of a vertex is of your of 1.",
                    "label": 0
                },
                {
                    "sent": "So P goes goes to 0 like one of them.",
                    "label": 0
                },
                {
                    "sent": "Well, I mean, you could also consider the case where piece or the 1 / N ^2 you would have a finite number of edges in the graph when angles are in the old cases are of interest.",
                    "label": 0
                },
                {
                    "sent": "It depends on what you want to study.",
                    "label": 0
                },
                {
                    "sent": "So let me consider one vertex here on this path will be connected to a certain number of neighbors just after the random graph has been drawn.",
                    "label": 0
                },
                {
                    "sent": "An 1 interesting quantity is the distribution of a number of neighbors.",
                    "label": 0
                },
                {
                    "sent": "So rule of these.",
                    "label": 0
                },
                {
                    "sent": "So what is wrong V?",
                    "label": 0
                },
                {
                    "sent": "Then you see how to choose among the vertices.",
                    "label": 0
                },
                {
                    "sent": "The other vertices here.",
                    "label": 0
                },
                {
                    "sent": "I will put an edge or not and So what I will do is I will choose if I got the neighbors I will choose among N -- 1 vertices here which neighbors which vertices will be the neighbors.",
                    "label": 0
                },
                {
                    "sent": "And the probability of having such an edge in between these vertex and the neighbors here will be C of N. For each, for each edge.",
                    "label": 0
                },
                {
                    "sent": "So I got C of N times to the power VI and all the other vertices are not connected to vertex.",
                    "label": 0
                },
                {
                    "sent": "I'm considering here.",
                    "label": 0
                },
                {
                    "sent": "So we have a probability 1 -- C of N. To the power N -- 1 -- P. And this has a well defined limit when N goes to Infinity at 6V.",
                    "label": 0
                },
                {
                    "sent": "Which is just a portion of it.",
                    "label": 0
                },
                {
                    "sent": "So we get to post on low of para meters C, which obviously as C as an average value, which is exactly the definition of see here the average degree, but we get the whole statistics of a number of neighbors of a note here.",
                    "label": 0
                },
                {
                    "sent": "So this person law is just a consequence of my statistical examples.",
                    "label": 0
                },
                {
                    "sent": "I could have defined random graphs in a different way and I would have found maybe different statistical distribution.",
                    "label": 0
                },
                {
                    "sent": "OK, so in fact many people have studied other random graph and samples where the degree distribution is not a person law, but it's any arbitrary law you can think of OK.",
                    "label": 0
                },
                {
                    "sent": "So the other statistical ensemble.",
                    "label": 0
                },
                {
                    "sent": "With a different law.",
                    "label": 0
                },
                {
                    "sent": "Rudy.",
                    "label": 0
                },
                {
                    "sent": "So let me give you 2 examples.",
                    "label": 0
                },
                {
                    "sent": "So one interesting case is the case where he decree does not fluctuate all the vertices in the graph has exactly the same degree K. Sophie's degree.",
                    "label": 0
                },
                {
                    "sent": "K. Or see if you prefer OK.",
                    "label": 0
                },
                {
                    "sent": "So these are called, let's say a fixed number of fixed degree graph random graphs and other examples which is very popular and so are scale free graph.",
                    "label": 0
                },
                {
                    "sent": "Where Ravi decreases as 1 / E two V2 some power towns.",
                    "label": 0
                },
                {
                    "sent": "So it's a power law decreasing here with some expanding towel for large.",
                    "label": 0
                },
                {
                    "sent": "Decrease.",
                    "label": 0
                },
                {
                    "sent": "But if you see, you can define whatever you want and the interesting quantities.",
                    "label": 0
                },
                {
                    "sent": "Characterizing this distribution here is the generating function.",
                    "label": 0
                },
                {
                    "sent": "So let me just introduce two things which will be useful in forming.",
                    "label": 0
                },
                {
                    "sent": "One thing is the generating function for ALDI.",
                    "label": 0
                },
                {
                    "sent": "It's just another way of characterizing World B, which is just the sum, so G is 0X.",
                    "label": 0
                },
                {
                    "sent": "It's just the sum of Y role of VX to the V. So I just build the series whose coefficients here are the different probabilities of having the vertices.",
                    "label": 0
                },
                {
                    "sent": "The neighbors OK.",
                    "label": 0
                },
                {
                    "sent": "So that's a generating function for the number of neighbors.",
                    "label": 0
                },
                {
                    "sent": "And we can build another generating function which will be useful when we talk about percolation transition a little bit later today, which is the following, which is the number of descendants of a vertex.",
                    "label": 0
                },
                {
                    "sent": "So what do I mean by that?",
                    "label": 0
                },
                {
                    "sent": "I mean the following things.",
                    "label": 0
                },
                {
                    "sent": "So again, let me look at a random graph here which was built through some process.",
                    "label": 0
                },
                {
                    "sent": "I'm not specifying the process here to build the graph, I'm just assuming that there is a process which is able to generate on graphs with such a degree distribution here OK.",
                    "label": 0
                },
                {
                    "sent": "So I give you some very succinct references on the web page and you will see that the book Bible Bash variable Bash for instance, where you will find some examples of how to generate random graphs with any probability distribution for decrease.",
                    "label": 0
                },
                {
                    "sent": "So suppose I I've drawn my graph and I would like to know what is the if I pick up an edge, for instance here randomly.",
                    "label": 0
                },
                {
                    "sent": "Let's say this edge here and then I pick up 1 / 2.",
                    "label": 0
                },
                {
                    "sent": "Vertices in coming onto that edge.",
                    "label": 0
                },
                {
                    "sent": "So for instance this one.",
                    "label": 0
                },
                {
                    "sent": "What is the average number of descendants policy?",
                    "label": 0
                },
                {
                    "sent": "What is the probability distribution for the number of descendants of this node here?",
                    "label": 0
                },
                {
                    "sent": "So you see I pick up an edge, I pick up the node which is attached to the edge.",
                    "label": 0
                },
                {
                    "sent": "So this node by definition is linked to another vertex here, but it will.",
                    "label": 0
                },
                {
                    "sent": "The neighbors, which I could with descendants of the nodes.",
                    "label": 0
                },
                {
                    "sent": "So what is the distribution of the primes, which is the number of these salads?",
                    "label": 0
                },
                {
                    "sent": "E prime?",
                    "label": 0
                },
                {
                    "sent": "It can be the same distribution afro's robe.",
                    "label": 0
                },
                {
                    "sent": "It can be something different.",
                    "label": 0
                },
                {
                    "sent": "So what is the value of this distribution?",
                    "label": 0
                },
                {
                    "sent": "So we see when I pick up an edge here randomly and then one of the nodes which is attached to the edge, then the probability of picking a node here vertex with V neighbors.",
                    "label": 0
                },
                {
                    "sent": "And then, oh sorry if I pick up an edge and then one of the two nodes here, then I will pick up.",
                    "label": 0
                },
                {
                    "sent": "Yes this this not having the neighbors with probability proportional to Roe V, obviously.",
                    "label": 0
                },
                {
                    "sent": "But then also with probability proportional to V, simply because what I'm doing here is I'm not picking up.",
                    "label": 0
                },
                {
                    "sent": "I mean, one of the of the of the edge of the vertices here randomly.",
                    "label": 0
                },
                {
                    "sent": "What I do first is I pick up randomly and match.",
                    "label": 0
                },
                {
                    "sent": "And the property that is as is attached to vertex of degree D is proportional to V. OK, so the probability of picking a node with the neighbors here will be proportional to V times through P. We need proportional to this, obviously depriving the number of descendants will be D -- 1.",
                    "label": 0
                },
                {
                    "sent": "So which means that the probability.",
                    "label": 0
                },
                {
                    "sent": "Stop having.",
                    "label": 0
                },
                {
                    "sent": "Deep on descendants.",
                    "label": 0
                },
                {
                    "sent": "Which I call rule one of the prime.",
                    "label": 0
                },
                {
                    "sent": "Will be proportional to V Prime plus one.",
                    "label": 0
                },
                {
                    "sent": "Times through V Prime plus one and then that should be normalized and I should some of the V prime going from zero to Infinity Infinity here.",
                    "label": 0
                },
                {
                    "sent": "And you see what I got here is just the average degree of a vertex in the graph.",
                    "label": 0
                },
                {
                    "sent": "So this is just D here, which is the sum of the V of Robbie.",
                    "label": 0
                },
                {
                    "sent": "So this distribution here will be useful.",
                    "label": 0
                },
                {
                    "sent": "We will use it a little bit later in the lecture and you see it might be equal, or it might be different from this one.",
                    "label": 0
                },
                {
                    "sent": "Because they describe two different random processes, one is you pick up a vertex and then you will just draw some edges from this vertex.",
                    "label": 0
                },
                {
                    "sent": "OK, so you will have a distribution of neighbors, the other one is you pick up an edge and you look at one of the two vertices attached to the edge and you see how many other neighbors this vertex has, which is something else.",
                    "label": 0
                },
                {
                    "sent": "OK, so for instance, if I look at the statistical example where all vertices have exactly K neighbors.",
                    "label": 0
                },
                {
                    "sent": "Then obviously this is simply a Chronicle, Delta in the equal to take 2K.",
                    "label": 0
                },
                {
                    "sent": "And this is simply a Chronicle, Delta in vehicle 2K minus one in V prime equal to K -- 1.",
                    "label": 0
                },
                {
                    "sent": "Now what is interesting is that if you look at the at the case where the distribution is Poisson here.",
                    "label": 0
                },
                {
                    "sent": "Which is the case of two and samples I've introduced before.",
                    "label": 0
                },
                {
                    "sent": "What will be the distribution here?",
                    "label": 0
                },
                {
                    "sent": "Can you guess what will be the distribution here for this one?",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "Yes, but I multiplied by this here so it will be again a person with the same average degree.",
                    "label": 0
                },
                {
                    "sent": "In fact, if you have personal events, OK, suppose you have a note here which is connected to this one.",
                    "label": 0
                },
                {
                    "sent": "Since the all the edges are just personal, once they are drawn independently from each other, knowing that this vertex here has already one neighbor here doesn't tell you anything about the other one.",
                    "label": 0
                },
                {
                    "sent": "So Ravi Prime will be exactly the same Romana V. Prime will be saved as well.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "I will use that little bit later, so let me go back now to the 1st.",
                    "label": 0
                },
                {
                    "sent": "Two statistical example are introduced.",
                    "label": 0
                },
                {
                    "sent": "And let us try to see what are the listed typical properties of these random graphs.",
                    "label": 0
                },
                {
                    "sent": "So just to make life a bit simpler, let's consider a fixed probability and sample.",
                    "label": 0
                },
                {
                    "sent": "Fixed probability of an edge.",
                    "label": 0
                },
                {
                    "sent": "Which I called P equal to see about N. And I want to describe the typical features of a graph.",
                    "label": 0
                },
                {
                    "sent": "So I will have some some some vertices here and some edges and I would like to know what the graph looks like so.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here are some examples.",
                    "label": 0
                },
                {
                    "sent": "So they were drawn actually in the.",
                    "label": 0
                },
                {
                    "sent": "With the different samples, but I told you they will.",
                    "label": 0
                },
                {
                    "sent": "Typical parties at the same.",
                    "label": 0
                },
                {
                    "sent": "And here you see just random randomly drawn graphs, which I obtained for SQL 2.5.",
                    "label": 0
                },
                {
                    "sent": "Sequel to one ounce equal to two.",
                    "label": 0
                },
                {
                    "sent": "I just did a random commit and not a random convenient permutation of the vertices, and I put them in the on the plane so that no edge cross each other here obviously because there is no reason why the graph should be planner.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's just a convenient way of putting graphs.",
                    "label": 0
                },
                {
                    "sent": "So you see, at low degree you would expect a random graph to be like that.",
                    "label": 0
                },
                {
                    "sent": "A lot of vertices will be isolated and you will find also some small components connected components, so a quantity of interest is how many connected components do you have?",
                    "label": 0
                },
                {
                    "sent": "So this is something we would be very interested in.",
                    "label": 0
                },
                {
                    "sent": "How many of them?",
                    "label": 0
                },
                {
                    "sent": "And a distribution of sizes.",
                    "label": 0
                },
                {
                    "sent": "Obviously, all of these quantities are stochastic quantities, but we would like to compute the average and also the distribution.",
                    "label": 0
                },
                {
                    "sent": "Then, um.",
                    "label": 0
                },
                {
                    "sent": "If you look at very high degree average degree, so for instance equal to here you see that there might be.",
                    "label": 0
                },
                {
                    "sent": "Components where we find structures which are complex.",
                    "label": 0
                },
                {
                    "sent": "For instance, here you see a cycle.",
                    "label": 0
                },
                {
                    "sent": "Which you don't find hearing this random realization at Lowe's, he.",
                    "label": 0
                },
                {
                    "sent": "So an interesting question is how many cycles do you get in components?",
                    "label": 0
                },
                {
                    "sent": "OK, so components, maybe 3?",
                    "label": 0
                },
                {
                    "sent": "Or they may be more complicated, so side trees with some unicycles or more complicated here you see two different cycles and so on.",
                    "label": 0
                },
                {
                    "sent": "So we'd like to know something about the distribution of cycles, or let's say the presence of cycles.",
                    "label": 0
                },
                {
                    "sent": "So what we want to do is to characterize the structural properties of these crowds.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "So what can we say?",
                    "label": 0
                },
                {
                    "sent": "So let's have a look at these properties, very simple.",
                    "label": 0
                },
                {
                    "sent": "The relation of these properties, which is not a rigorous derivation, but the results I'm going to show you are exact and they can be proven exactly.",
                    "label": 0
                },
                {
                    "sent": "So what I will consider the following, so I will consider sub graph.",
                    "label": 0
                },
                {
                    "sent": "G. Prime.",
                    "label": 0
                },
                {
                    "sent": "With the vertices.",
                    "label": 0
                },
                {
                    "sent": "So for instance on edges.",
                    "label": 0
                },
                {
                    "sent": "So for instance, I can consider case where I've got V equal to 4.",
                    "label": 0
                },
                {
                    "sent": "An equal to three, which is just a star graph.",
                    "label": 0
                },
                {
                    "sent": "So V = 4.",
                    "label": 0
                },
                {
                    "sent": "He equals 3.",
                    "label": 0
                },
                {
                    "sent": "And this graph is labeled, so it means that vertices.",
                    "label": 0
                },
                {
                    "sent": "Carry some numbers 1234.",
                    "label": 0
                },
                {
                    "sent": "So it's a labor graph.",
                    "label": 0
                },
                {
                    "sent": "So what do I mean by labor?",
                    "label": 0
                },
                {
                    "sent": "I mean that, for instance, this graph here and this one are not the same.",
                    "label": 0
                },
                {
                    "sent": "If I change the ordering.",
                    "label": 0
                },
                {
                    "sent": "Here are the numbers.",
                    "label": 0
                },
                {
                    "sent": "Then I get something else.",
                    "label": 0
                },
                {
                    "sent": "OK. Well, if I had unlabelled graph they would be equal job.",
                    "label": 0
                },
                {
                    "sent": "Just ask on four different vertices.",
                    "label": 0
                },
                {
                    "sent": "And the question I'm asking now is how many copies of these subgraphs will find in my random graph.",
                    "label": 0
                },
                {
                    "sent": "Typically.",
                    "label": 0
                },
                {
                    "sent": "Only see let's count something simple simple.",
                    "label": 0
                },
                {
                    "sent": "Let's count how many copies will I find in my own graph of this sub graph on average.",
                    "label": 0
                },
                {
                    "sent": "So average number of copies.",
                    "label": 0
                },
                {
                    "sent": "Then you see, maybe I will find that this average numbers is very high or I will find it's very small and then it's a way, let's say, to probe the random graphs to see what is inside and what it looks like.",
                    "label": 0
                },
                {
                    "sent": "OK, just a simple way of identifying the different components connected components of a graph.",
                    "label": 0
                },
                {
                    "sent": "So this graph here I should have said before, is it connected subgraphs so it's made of one single speed piece?",
                    "label": 0
                },
                {
                    "sent": "I can go from any vertex to another one through the set of edges.",
                    "label": 0
                },
                {
                    "sent": "OK, so how do I do that?",
                    "label": 0
                },
                {
                    "sent": "So first in order to compute this average number of copies, I must so localize all these copies.",
                    "label": 0
                },
                {
                    "sent": "So how do I do that?",
                    "label": 0
                },
                {
                    "sent": "I first have to choose the number.",
                    "label": 0
                },
                {
                    "sent": "I mean choose the vertices among the N vertices available vertices, so will have a convenient manufacture envy, which is a choice of vertices.",
                    "label": 0
                },
                {
                    "sent": "OK, then I will label these vertices with vertices I have chosen from one to V, for instance one to four here in this example and then I get my label sub graph.",
                    "label": 0
                },
                {
                    "sent": "Now I want to build the sorry I get my labor set of vertices.",
                    "label": 0
                },
                {
                    "sent": "Now I want to build the edges and I will do.",
                    "label": 0
                },
                {
                    "sent": "I will do that with the fix probability of an agent sample.",
                    "label": 0
                },
                {
                    "sent": "So how many?",
                    "label": 0
                },
                {
                    "sent": "How many edges two should I draw?",
                    "label": 0
                },
                {
                    "sent": "I should draw exactly E edges in between these virtues here.",
                    "label": 0
                },
                {
                    "sent": "So that will be done with probability C of N to the East.",
                    "label": 0
                },
                {
                    "sent": "And I want to make sure that there is no other edges in between these vertices here which I don't want and with the other vertices.",
                    "label": 0
                },
                {
                    "sent": "In the remaining part of the graph.",
                    "label": 0
                },
                {
                    "sent": "OK, so this will be done with probability 1 -- C of N for the number of forbidden connection or forbidden edges if you prefer.",
                    "label": 0
                },
                {
                    "sent": "So I've got forbidden edges inside the.",
                    "label": 0
                },
                {
                    "sent": "My subgraph here and how many of them do I have.",
                    "label": 0
                },
                {
                    "sent": "I have the times 3 -- 1 / 2 -- E. And then I've got forbidden connection with the remaining part of the graph, which is V * N -- V forbidden edges.",
                    "label": 0
                },
                {
                    "sent": "So it's a probability.",
                    "label": 0
                },
                {
                    "sent": "So what I've written here is this part.",
                    "label": 0
                },
                {
                    "sent": "Here is just the probability that this B points higher identified these vertices.",
                    "label": 0
                },
                {
                    "sent": "We have randomly drawn edges and at the end the sub graph which I obtain is looks like this one here the G prime I have selected at the beginning.",
                    "label": 0
                },
                {
                    "sent": "The remaining part of the graph will do something else.",
                    "label": 0
                },
                {
                    "sent": "I don't care what I want to be sure is that the subgraphs which I built from my vertices will be exactly this one.",
                    "label": 0
                },
                {
                    "sent": "OK, and then here I count how many ways I have to choose the video vertices.",
                    "label": 0
                },
                {
                    "sent": "So this is the average number of copies of this label graph.",
                    "label": 0
                },
                {
                    "sent": "So let's count a little bit further and see what happens when N is large.",
                    "label": 0
                },
                {
                    "sent": "So I will assume that the subgraphs G prime is small, that is V prime D small.",
                    "label": 0
                },
                {
                    "sent": "So small means here.",
                    "label": 0
                },
                {
                    "sent": "Small compared to Anna.",
                    "label": 0
                },
                {
                    "sent": "So it's not very well precise, well defined mathematical notion.",
                    "label": 0
                },
                {
                    "sent": "You will see a limit later.",
                    "label": 0
                },
                {
                    "sent": "What it means precisely?",
                    "label": 0
                },
                {
                    "sent": "I'm assuming it goes.",
                    "label": 0
                },
                {
                    "sent": "It is smaller than anything I need in order to have a well defined limit quantity here.",
                    "label": 0
                },
                {
                    "sent": "So I can.",
                    "label": 0
                },
                {
                    "sent": "So this is the number of copies here, number of G prime.",
                    "label": 0
                },
                {
                    "sent": "The average number so number of G prime.",
                    "label": 0
                },
                {
                    "sent": "Let me just simplify it, this formula here.",
                    "label": 0
                },
                {
                    "sent": "So you see I can approximate this combinatorial factor here by end to the V / V factorial.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is N * N -- 1 and minus two and so on.",
                    "label": 0
                },
                {
                    "sent": "Two N -- B + 1 which is essentially end to the V when is large compared to V. Then I got C of N2E.",
                    "label": 0
                },
                {
                    "sent": "And the whole thing here, when these small and E will be small because he is at most B squared of two, will be dominated by the end.",
                    "label": 0
                },
                {
                    "sent": "This is the important term here in the sun at the exponent.",
                    "label": 0
                },
                {
                    "sent": "So I get and then I will use 1 -- 3 / N is almost exponential minus C of M, so this is exponential minus C. D. So let me just write it again as C to the E. C factorial exponential minus CD and to the V -- E. Wolf sorry the vector.",
                    "label": 0
                },
                {
                    "sent": "Yes, thank you.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's look at what happens when N is large.",
                    "label": 0
                },
                {
                    "sent": "So the only dependency on anything here in this factor here.",
                    "label": 0
                },
                {
                    "sent": "So we have you see three different cases, either D -- E is positive, or that's equal to 0, it's negative.",
                    "label": 0
                },
                {
                    "sent": "So what can be the largest value of Y -- E if I fix V?",
                    "label": 0
                },
                {
                    "sent": "So what is the largest possible value for East Given B?",
                    "label": 0
                },
                {
                    "sent": "With a connected connected component, yes.",
                    "label": 0
                },
                {
                    "sent": "Yes, you see if I go to the largest possible case for B, if I got a tree OK, this is the minimal way of connecting vertices.",
                    "label": 0
                },
                {
                    "sent": "I cannot do something.",
                    "label": 0
                },
                {
                    "sent": "With a smaller number of edges, because it will be disconnected and you see if I got equal 2 I get one edge.",
                    "label": 0
                },
                {
                    "sent": "If I got V equal to four I get 3 edges and so on.",
                    "label": 0
                },
                {
                    "sent": "It's always v -- 1 so if I D minus equal 1.",
                    "label": 0
                },
                {
                    "sent": "Is the largest possible value for D -- E?",
                    "label": 0
                },
                {
                    "sent": "OK, and then that correspond to trees.",
                    "label": 0
                },
                {
                    "sent": "So if I do that, if I look at this case, I see that the number of copies of my tree G prime is a tree will be proportional to N, so I got a large number of them on average.",
                    "label": 0
                },
                {
                    "sent": "And then I get a number of copies which will be.",
                    "label": 0
                },
                {
                    "sent": "End time see today.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "The factorial.",
                    "label": 0
                },
                {
                    "sent": "Sorry, maybe I'm just want to.",
                    "label": 0
                },
                {
                    "sent": "I'm confused about the so E is D -- 1.",
                    "label": 0
                },
                {
                    "sent": "Sorry so I have a mistake in my notes, but it's OK. OK, so I may find a large number of trees in my random graph and this is typically what I found using these two small examples here.",
                    "label": 0
                },
                {
                    "sent": "So one of the questions we would like to ask is what is the typical value of VI will find.",
                    "label": 0
                },
                {
                    "sent": "Obviously I can find trees with only two vertices with four vertices, three vertices and so on.",
                    "label": 0
                },
                {
                    "sent": "But if any is fine it now if I gotta find it.",
                    "label": 0
                },
                {
                    "sent": "But large random graph.",
                    "label": 0
                },
                {
                    "sent": "So N is very large but finite.",
                    "label": 0
                },
                {
                    "sent": "What will be the maximum value of Yi will find?",
                    "label": 0
                },
                {
                    "sent": "OK, So what is the largest tree I will find in a random graph with N?",
                    "label": 0
                },
                {
                    "sent": "Versus it's very fine question.",
                    "label": 0
                },
                {
                    "sent": "So what we can see is, so let's look at when for which value of the this quantity becomes equal to 1.",
                    "label": 0
                },
                {
                    "sent": "You see, if V increases, this factor here will decrease very fast.",
                    "label": 0
                },
                {
                    "sent": "Actually the whole thing will decrease and then it will go down.",
                    "label": 0
                },
                {
                    "sent": "At some point this will be exactly equal to 1 / N and then the average number of trees with a larger value of vertices V will be smaller than one one on average.",
                    "label": 0
                },
                {
                    "sent": "That means that the probability of having this this trees will be.",
                    "label": 0
                },
                {
                    "sent": "Small, OK, so I won't find it anymore.",
                    "label": 0
                },
                {
                    "sent": "So before I do that, just be careful that here I've considered the number.",
                    "label": 0
                },
                {
                    "sent": "Of copies of 1 particular label trees.",
                    "label": 0
                },
                {
                    "sent": "If I want to know what is the average number of trees with vertices.",
                    "label": 0
                },
                {
                    "sent": "I have an online one graph.",
                    "label": 0
                },
                {
                    "sent": "I have to count how many label trees with vertices there are.",
                    "label": 0
                },
                {
                    "sent": "So in this I want to calculation.",
                    "label": 0
                },
                {
                    "sent": "Actually it's the result of a famous theorem by Kelly in 1889.",
                    "label": 0
                },
                {
                    "sent": "I just give you the result on this.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right here.",
                    "label": 0
                },
                {
                    "sent": "With an example drawn from the I mean taken from the Wikipedia web page.",
                    "label": 0
                },
                {
                    "sent": "If you go to Kayla's formula you find this.",
                    "label": 0
                },
                {
                    "sent": "So I just copied it from the Wikipedia web page and the answer is V. Two V -- 2.",
                    "label": 0
                },
                {
                    "sent": "So again, you can find links to the demonstration of this fact.",
                    "label": 0
                },
                {
                    "sent": "I won't do that.",
                    "label": 0
                },
                {
                    "sent": "That will be take a little bit of time, but here is an example.",
                    "label": 0
                },
                {
                    "sent": "So you see for V equal to two, then you have.",
                    "label": 0
                },
                {
                    "sent": "One possible tree here with two vertices on one edge obviously, and then if you take the equal to three, you see three different trees you can make.",
                    "label": 0
                },
                {
                    "sent": "So the labels here correspond to the colors.",
                    "label": 0
                },
                {
                    "sent": "You have three different colors, so labels 123 and basically what you have to choose is the vertex which is in between.",
                    "label": 0
                },
                {
                    "sent": "So there are three different possibilities, so you have three different trees.",
                    "label": 0
                },
                {
                    "sent": "So it works so far you see 32V one is 3 and now if you look at the number of trees you can do with four different vertices then are two different structures.",
                    "label": 0
                },
                {
                    "sent": "Either you get linear structure this way or you get a star like shape.",
                    "label": 0
                },
                {
                    "sent": "So there are four different starlike shapes because you choose the color of the vertex in the middle, and here you have to choose the ordering.",
                    "label": 0
                },
                {
                    "sent": "If you can't then against this formula works.",
                    "label": 0
                },
                {
                    "sent": "So there is a general demonstration proof of the formula.",
                    "label": 0
                },
                {
                    "sent": "And I will just use it and then I will conclude that the average number.",
                    "label": 0
                },
                {
                    "sent": "Of trees.",
                    "label": 0
                },
                {
                    "sent": "With the vertices.",
                    "label": 0
                },
                {
                    "sent": "Is equal to end times C two V -- 1 / 3 factorial V to V -- 2 exponential minus CD.",
                    "label": 0
                },
                {
                    "sent": "So now we can answer the question as just before.",
                    "label": 0
                },
                {
                    "sent": "What is the maximum size of the tree I will find in my in typical random realization my graph.",
                    "label": 0
                },
                {
                    "sent": "So what I want to see is when for which value of the this number here this average number becomes equal to 1.",
                    "label": 0
                },
                {
                    "sent": "OK so D will be large.",
                    "label": 0
                },
                {
                    "sent": "So we have to be careful here, but yes.",
                    "label": 0
                },
                {
                    "sent": "John, John oh hello John.",
                    "label": 0
                },
                {
                    "sent": "Nice to see you.",
                    "label": 0
                },
                {
                    "sent": "OK so I said these should be small with compared to end in order to get this formula right but then now I'm looking at large B so then we'll see whether the two statements can be compatible or not OK, let me push this formula to large fee and look at the asymptotics of this formula so I get N. So now I will have an exponential V time something.",
                    "label": 0
                },
                {
                    "sent": "So what is this something here I can neglect?",
                    "label": 0
                },
                {
                    "sent": "The one compared to VI don't care and get a log C. Then I get plus B -- 2, But the minus two is not important here, so it will be plus one.",
                    "label": 0
                },
                {
                    "sent": "Because press log, sorry.",
                    "label": 0
                },
                {
                    "sent": "And here I gotta minus C. This is the numerator.",
                    "label": 0
                },
                {
                    "sent": "And let's look at the denominator, which is just so your V and I will use stealing formula.",
                    "label": 0
                },
                {
                    "sent": "I know, but Factorial V is essentially exponential V log D. Minus D plus terms of Yoda flog V. OK, just starting from there.",
                    "label": 0
                },
                {
                    "sent": "So you see that a few things cancel.",
                    "label": 0
                },
                {
                    "sent": "So this one cancel this one here.",
                    "label": 0
                },
                {
                    "sent": "And the outcome of formulas that I get.",
                    "label": 0
                },
                {
                    "sent": "Find exponential D. Minus Y.",
                    "label": 0
                },
                {
                    "sent": "Plus one or, let's say, let's put the minus in front.",
                    "label": 0
                },
                {
                    "sent": "Here I get C -- 1 minus loxy.",
                    "label": 0
                },
                {
                    "sent": "So you see that for LG VI get an exponential decrease of the average number of trees with the vertices here.",
                    "label": 1
                },
                {
                    "sent": "So that means that there will be a cut off from the maximum size of the number of maximal number of vertices, which is when this average number here become equal to 1 so VMAX.",
                    "label": 0
                },
                {
                    "sent": "We just did Max.",
                    "label": 0
                },
                {
                    "sent": "Will be so let me just write.",
                    "label": 0
                },
                {
                    "sent": "This is equal to 1.",
                    "label": 0
                },
                {
                    "sent": "I take the log is Logan.",
                    "label": 0
                },
                {
                    "sent": "Over C -- 1 minus loxy.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So this is nice because this is much larger than one, so it makes sense to make the expansion in the case a synthetic expansion when we is large, but it's certainly much more of an animal, so all the calculations I've done before where I completely neglected this squared compared to N and so on.",
                    "label": 0
                },
                {
                    "sent": "OK, so the larger subtree largest country I should find, my random graph should be on the order of log North vertices, and we have a more precise scaling here.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is what I should find.",
                    "label": 0
                },
                {
                    "sent": "There should be one copy of a graph with this number of vertices.",
                    "label": 0
                },
                {
                    "sent": "So you see that this maximum number depends on C. So if C is very small.",
                    "label": 0
                },
                {
                    "sent": "Then minus look see is very large and Logan over something very large is very small, so VMAX is very small, which makes sense if I have a few edges.",
                    "label": 0
                },
                {
                    "sent": "I do not expect the largest subgraphs of tree to be very large.",
                    "label": 0
                },
                {
                    "sent": "OK, we can be logged over something which is very large, but now if you look at this quantity here and this quantity goes to zero when he goes to one.",
                    "label": 0
                },
                {
                    "sent": "OK, so we expect the you see we have a problem here because then the number of vertices will be larger than Anna.",
                    "label": 0
                },
                {
                    "sent": "At some point.",
                    "label": 0
                },
                {
                    "sent": "It seems too close to 1, which is certainly not possible with because anything total number of vertices in the graph.",
                    "label": 0
                },
                {
                    "sent": "So that means that the assumption we are made here breakdown if C is too close one.",
                    "label": 0
                },
                {
                    "sent": "So something takes place when she goes to one.",
                    "label": 0
                },
                {
                    "sent": "OK, so everything I did here was very large.",
                    "label": 0
                },
                {
                    "sent": "See find it and then you see that everything is breaking down when sequels to one.",
                    "label": 0
                },
                {
                    "sent": "So what happens when C is equal to 1?",
                    "label": 0
                },
                {
                    "sent": "So I will just give the result and then we'll see a little bit later how that can be shown or found back.",
                    "label": 0
                },
                {
                    "sent": "Let's say using statistical mechanics arguments that when she goes to and actually what we get, is that.",
                    "label": 0
                },
                {
                    "sent": "We have other things which have a lot of cycles.",
                    "label": 0
                },
                {
                    "sent": "OK, so just one more comment before I go to SQL one.",
                    "label": 0
                },
                {
                    "sent": "You see forces smaller than one.",
                    "label": 0
                },
                {
                    "sent": "We have seen that we have many trees, but I've not considered the other cases where V minus is equal to 0 or B minus is equal to minus 1 -- 2 and so on.",
                    "label": 0
                },
                {
                    "sent": "So let's do that very quickly.",
                    "label": 0
                },
                {
                    "sent": "So for V minus equal to 0, which is the next case here.",
                    "label": 0
                },
                {
                    "sent": "So how many components do we have with the minus equal to 0?",
                    "label": 0
                },
                {
                    "sent": "Then we get a finite number of them because this is entrance zero on average.",
                    "label": 0
                },
                {
                    "sent": "So we come a little bit later too that when I consider the random access, that problem will compute the average number of components with.",
                    "label": 0
                },
                {
                    "sent": "Minus equal to 0.",
                    "label": 0
                },
                {
                    "sent": "So what does that mean?",
                    "label": 0
                },
                {
                    "sent": "That the minus is equal to 0?",
                    "label": 0
                },
                {
                    "sent": "Which kind of graphs have the minus equal to 0?",
                    "label": 0
                },
                {
                    "sent": "There are trees where I put an additional edge.",
                    "label": 0
                },
                {
                    "sent": "OK, and then I get a tree with a cycle, so it's not a tree anymore, it's a unicycle.",
                    "label": 0
                },
                {
                    "sent": "OK on the graph subgraph with unicycle so the number of subscribers should be on the order of 1.",
                    "label": 0
                },
                {
                    "sent": "On average, OK, and then if IV minus is equal to minus 1 -- 2 and so on, you see that this numbers goes to 0, so on average I get to vanish in number when N goes to Infinity, which means I don't find these subgraphs in my random graph with high probability, so I can simply neglect them.",
                    "label": 0
                },
                {
                    "sent": "So this is not true.",
                    "label": 0
                },
                {
                    "sent": "When she goes to one, because when sequence one then I get the objects which are more complicated than trees.",
                    "label": 0
                },
                {
                    "sent": "And let me just give you the result and then we'll see what happens when she is not even once.",
                    "label": 0
                },
                {
                    "sent": "So when secret one.",
                    "label": 0
                },
                {
                    "sent": "Then then we have the largest component.",
                    "label": 0
                },
                {
                    "sent": "I'm not on the order of log in anymore.",
                    "label": 0
                },
                {
                    "sent": "They will contain N to the 2/3 vertices.",
                    "label": 0
                },
                {
                    "sent": "So I'm not giving any proof of that will come back to this point later.",
                    "label": 0
                },
                {
                    "sent": "At the end of electric I've got enough time, but this is a important result of calculation, so SQL one is called percolation threshold for the obvious reason that foresee larger than one.",
                    "label": 0
                },
                {
                    "sent": "Then we get a large component.",
                    "label": 0
                },
                {
                    "sent": "So the largest components now contain.",
                    "label": 0
                },
                {
                    "sent": "Define attraction.",
                    "label": 0
                },
                {
                    "sent": "Open up the Overbrook cinegraph.",
                    "label": 0
                },
                {
                    "sent": "And this function I called gamma of C. That means that the number there will be one big component here, for instance, which contains a number of vertices of the order of angle.",
                    "label": 0
                },
                {
                    "sent": "And the fraction.",
                    "label": 0
                },
                {
                    "sent": "The factor here is a number between zero and one, which is a function of C. Obviously there will be, so you can see it here from this very simple example, but there will be other small disconnected components which have some statistics like the one we find foresees more than one below the percolation threshold.",
                    "label": 0
                },
                {
                    "sent": "They will be just isolated trees.",
                    "label": 0
                },
                {
                    "sent": "So what is the value of gamma C?",
                    "label": 0
                },
                {
                    "sent": "And how many components do we have?",
                    "label": 0
                },
                {
                    "sent": "Process large one so here.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Uncurved so.",
                    "label": 0
                },
                {
                    "sent": "So this card here is the fraction of the vertices which are inside the largest component which is called the giant component.",
                    "label": 0
                },
                {
                    "sent": "So when see smaller than one, this is zero, simply because the largest component as we saw it contains Logan purchases.",
                    "label": 0
                },
                {
                    "sent": "So Logan over N goes to zero when angles Infinity, while when C is larger than one, you get a number of vertices of the order of North.",
                    "label": 0
                },
                {
                    "sent": "So Gamma C is solution of equation.",
                    "label": 0
                },
                {
                    "sent": "1 minus gamma is equal to exponential minus C, and this is what is plotted here.",
                    "label": 0
                },
                {
                    "sent": "So gamma is equal to 0 is always a solution of this equation and this is the only solution you get when season one and for the large man when you get another solution for this equation, which is the right value for fractional vertices in the giant component.",
                    "label": 0
                },
                {
                    "sent": "We can also compute, for instance, the number of clusters.",
                    "label": 0
                },
                {
                    "sent": "So the number of connected components, if you prefer, so foresees more than one solution is very simple, because most components are trees.",
                    "label": 0
                },
                {
                    "sent": "That means that each time you add a new edge, so you suppose you suppose you built from the empty graph your random graph by adding more and more edges.",
                    "label": 0
                },
                {
                    "sent": "So this is increasing.",
                    "label": 0
                },
                {
                    "sent": "So each time you add a new edge, what you're doing is simply aggregating one isolated vertex to tree, so.",
                    "label": 0
                },
                {
                    "sent": "The number of connected component decreased linearly with the average connectivity here and you get the slope which is 2.",
                    "label": 0
                },
                {
                    "sent": "Minus two sorry OK, which can be easily understood because each time we put an edge then the degree of two nodes will increase.",
                    "label": 0
                },
                {
                    "sent": "OK so there is a factor 2 between the the slope.",
                    "label": 0
                },
                {
                    "sent": "I mean the DE over the equal to two OK is equal to 1/2.",
                    "label": 0
                },
                {
                    "sent": "Sorry so you get this low power minus well here when you add edges.",
                    "label": 0
                },
                {
                    "sent": "Above the critical threshold, what happens is that in many cases you will add edges to a giant component and the number of components will not decrease, so the decrease rate.",
                    "label": 0
                },
                {
                    "sent": "Here the decay rate of the number of components get smaller than this one, and you get this this curve here.",
                    "label": 0
                },
                {
                    "sent": "This moose curve going down very smoothly and much more slowly than the beginning here.",
                    "label": 0
                },
                {
                    "sent": "So how can we understand in a very empirical way this formula?",
                    "label": 0
                },
                {
                    "sent": "So it's very easy to understand.",
                    "label": 0
                },
                {
                    "sent": "So let me just give a very.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Empirical derivation.",
                    "label": 0
                },
                {
                    "sent": "So suppose you accept that there is a large component when C is larger than one, and here is the situation of my random graph.",
                    "label": 0
                },
                {
                    "sent": "OK, with a certain number of edges, and now what I will do, I will add a new edge.",
                    "label": 0
                },
                {
                    "sent": "Sorry I will.",
                    "label": 0
                },
                {
                    "sent": "I will add a new vertex to my random graph and in order to make to make this vertex typical for the new random graphs that will update, I will obtain at the end of the process.",
                    "label": 0
                },
                {
                    "sent": "I'm assuming that the number of neighbors of these new vectors is is personeel.",
                    "label": 0
                },
                {
                    "sent": "So it's a personal with partner to see.",
                    "label": 0
                },
                {
                    "sent": "OK, so you see you have this random graph here you are adding a new vertex with some edges like this and you are gluing these different edges on the different.",
                    "label": 0
                },
                {
                    "sent": "Vertis is here.",
                    "label": 0
                },
                {
                    "sent": "So the question is, how will the size of a giant component change when I do that?",
                    "label": 0
                },
                {
                    "sent": "OK so I can make a very simple reasoning here which is.",
                    "label": 0
                },
                {
                    "sent": "So what is the probability that my new vertex here will not belong to the giant component?",
                    "label": 0
                },
                {
                    "sent": "So what is this probability?",
                    "label": 0
                },
                {
                    "sent": "I'm assuming that the giant components contains a fraction gamma over different sites here.",
                    "label": 0
                },
                {
                    "sent": "So what is this probability if I just throw randomly the edges?",
                    "label": 0
                },
                {
                    "sent": "So why do I have to do is I have to pick up the neighbors of this vertex here outside the giant component?",
                    "label": 0
                },
                {
                    "sent": "OK, and I'll just be independent processes, so we probably have this.",
                    "label": 0
                },
                {
                    "sent": "Would be 1 minus gamma Trudy.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "So probably that I pick up the neighbor which is not in the giant component is 1 minus gamma and that has to be repeated these times.",
                    "label": 0
                },
                {
                    "sent": "If I constrain to, this is conditioned to the number of neighbors here.",
                    "label": 0
                },
                {
                    "sent": "Now, if the number of neighbors D is a person law in order to get the average probability here, I just have to sum up on the on the on the person distribution for V. OK, so this is conditioned to D and now with total probability the right probability that this new vertex does not belong to the giant component, not condition to V. Will be some of the going from zero to Infinity of C2V D factorial exponential minus CD, which is the personal for V * 1 minus, B. OK, and you see what this is simply an exponential minus C + C -- C gamma, which is exponential minus Sigma.",
                    "label": 0
                },
                {
                    "sent": "But then if I assume that you know if I have N vertices, a random graph with N vertices on N + 1 vertices doesn't change the fraction of citing the giant component when N goes to Infinity.",
                    "label": 0
                },
                {
                    "sent": "Just correction of the other one over North.",
                    "label": 0
                },
                {
                    "sent": "Then it means that this probability here should be equal to 1 minus gamma.",
                    "label": 0
                },
                {
                    "sent": "This is just.",
                    "label": 0
                },
                {
                    "sent": "City of being outside the giant component, get one minus gamma is equal to exponential minus Sigma, which is what I want.",
                    "label": 0
                },
                {
                    "sent": "So this is not a rigorous derivation, but you understand.",
                    "label": 0
                },
                {
                    "sent": "I mean, it's a very simple duration which gives you the flavor of a real argument.",
                    "label": 0
                },
                {
                    "sent": "So obviously there are plenty of things we could discuss, for instance, how many big components do we have?",
                    "label": 0
                },
                {
                    "sent": "So at the critical point when sequel to one, we may have many different components with end to the 2/3.",
                    "label": 0
                },
                {
                    "sent": "Crystals, but as soon as we are both equal 1 then you see that having more than two giant components will be very unstable because it's very likely when when you add an edge then you will connect together.",
                    "label": 0
                },
                {
                    "sent": "The two giant components, so one of them will disappear very soon and you get only one.",
                    "label": 0
                },
                {
                    "sent": "So the only this argument very simple explains why there would be only one giant component with high probability.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So I think this is basically what I wanted to say about the heuristic description of random graphs.",
                    "label": 0
                },
                {
                    "sent": "And just one point here, everything was done with the personal distribution.",
                    "label": 0
                },
                {
                    "sent": "Then you can ask what happens if I've got a different degree distribution.",
                    "label": 0
                },
                {
                    "sent": "For instance, carefree, fixed number of neighbors and so back.",
                    "label": 0
                },
                {
                    "sent": "Then as I write in the notes and you can see on the web then.",
                    "label": 0
                },
                {
                    "sent": "There will be some equivalent condition for C for the average connectivity and this equivalent condition, which I write here.",
                    "label": 0
                },
                {
                    "sent": "Is the following that you can understand so you can do the same argument and the argument would be simply that suppose you have you have this graph here.",
                    "label": 0
                },
                {
                    "sent": "Sorry you have this graph here.",
                    "label": 0
                },
                {
                    "sent": "So now it's not a person graph anymore, it's it's another example, but I can always do my heuristic argument here and add a new vertex vertex here.",
                    "label": 0
                },
                {
                    "sent": "So this new vertex will have some degree distribution here, which is given by by Roman.",
                    "label": 0
                },
                {
                    "sent": "Or remember what we do right before and then the condition will be written.",
                    "label": 0
                },
                {
                    "sent": "In this way we can do the computation and I'm just giving you.",
                    "label": 0
                },
                {
                    "sent": "The result is that the condition will be the sum over V. Often the kinds V -- 2 Roe V should be larger than 0.",
                    "label": 0
                },
                {
                    "sent": "So there are two possibilities.",
                    "label": 0
                },
                {
                    "sent": "Either this condition is satisfied and the giant there will be a giant component in the random graph, or it's violated.",
                    "label": 0
                },
                {
                    "sent": "So this left hand side is negative, then there will be many different small disconnected components in the graph.",
                    "label": 0
                },
                {
                    "sent": "OK, and you can see that for every person in case you find my exactly equal 1 when you apply this question.",
                    "label": 0
                },
                {
                    "sent": "So I don't want to give more details but just saying that the same argument can be done.",
                    "label": 0
                }
            ]
        }
    }
}