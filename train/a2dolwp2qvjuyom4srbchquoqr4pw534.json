{
    "id": "a2dolwp2qvjuyom4srbchquoqr4pw534",
    "title": "Pascal Challenge: Linear Support Vector Machines",
    "info": {
        "author": [
            "Hsiang-Fu Yu, Department of Computer Science and Information Engineering, National Taiwan University"
        ],
        "published": "Sept. 1, 2008",
        "recorded": "July 2008",
        "category": [
            "Top->Computer Science->Machine Learning->Kernel Methods->Support Vector Machines"
        ]
    },
    "url": "http://videolectures.net/icml08_yu_pc/",
    "segmentation": [
        [
            "This is today's online.",
            "First I will give some introduction to linear SVM.",
            "An data analysis in this challenge.",
            "Then my implementation to participate this challenge and some discussion."
        ],
        [
            "Introduction There are four track in Pascal Challenge and we participate.",
            "Linear swim check.",
            "The reason is linear SVM is our recently research focus and we have no time to work on other there other track.",
            "So today's talk will focus on the linear as we check."
        ],
        [
            "OK, so what's the problem?",
            "We want to solve in linear SVM.",
            "We are given a training, a set of training instance with labels Yi, an feature vector XI.",
            "And each label Yi must be one or minus one.",
            "What we want to do is find a weighting vector W to minimize this function.",
            "And W transpose W / 2 is the regularization term.",
            "ANSI is the penalty parameter, at least is a loss function.",
            "There are two type of loss function stands for two type of linear SVM.",
            "When last function is like this.",
            "We gather at one SVM when the loss function like this we get the error two SVM we call these two phone primal phone of any SVM and in linear SVM track we are request to work on at one SVM only.",
            "In addition to South Lincoln SVN in Primal, we can also solve.",
            "Linux VM in its dual."
        ],
        [
            "Frank Primal dual relationship.",
            "We can derive the dual phone of advice would like this in this problem we try to find a vector Alpha to minimize function.",
            "And the component of Alpha is bounded by zero and parameter C. The metric you.",
            "Is composed of the inner product of each feature factor and their labels, and E is a vector of all wise.",
            "And or two SVN.",
            "Then the deal of the dual form of L2 SVM is similar.",
            "And not that.",
            "The dimension of Vector Alpha is the size of the instance of the training set, so.",
            "Each component of Alpha I stands for corresponds for one instance in training set.",
            "OK."
        ],
        [
            "Now.",
            "Is the package we used to participate in ESPN track?",
            "Leave a linear library for linear SVM.",
            "In live linear it implements two optimization method.",
            "One is your coordinate.",
            "Dissent by this measure itself, the dual form of L1L2 SVM.",
            "The another method is trust region Newton Mason.",
            "Leave linear use this method to solve large logical regression and the primary form of level 2 SVN.",
            "At least packages available at least address and not that.",
            "Since we are request works on at one SVN and dual coding at decent is the only approach to South at once via live linear.",
            "So let me briefly describe the this method."
        ],
        [
            "This method is very simple, we just minimize one variable of your phone at a time.",
            "The algorithm schemes like this.",
            "While Vector Alpha is not optimal, we just choose a variable of dual and optimize it.",
            "And the detail of this algorithm is in this paper, and there was a talk about this yesterday.",
            "This method is very suitable for large sparse data.",
            "What is the largest fast data mean when the number of instance an number of features are very large?",
            "We call this data spots and large.",
            "For example documents an."
        ],
        [
            "This method is less suitable if this situation.",
            "Well, she is large.",
            "The penalty primacies large or the data is not scaled to the small range.",
            "And from the equation over SVM, the meaning of two situations are then.",
            "Another situation is when a number of features are small.",
            "Unfortunately that most that I said in this chat challenge at this case, so a dual coding dual coordinate dissent may not be the most most suitable method here.",
            "But we have no choice since we need to focus on at once via and this is the only approach to software wise.",
            "We're independent."
        ],
        [
            "OK.",
            "So now, is there some difficulty we encountered an hour solution?",
            "And the target of live linear is to suffer large sparse data, so it only stole the feature with null value.",
            "So each feature.",
            "Consume tell fights.",
            "Things it must store the index and value for each visual of instance.",
            "Index consume 4 by their value.",
            "Add bytes, but our machine has only 8 gigabyte memory and organizers machine has 32 gigabyte memory and they will run our code in their machine.",
            "But if we use.",
            "Live near directory.",
            "The memory requirement would be larger than 32 gigabyte machine.",
            "But our target and our goal is to solve the whole set for each data that ends at that.",
            "I say in the machine OK."
        ],
        [
            "Now OK, so.",
            "The data set is very large, so we must do some data analysis before we solve."
        ],
        [
            "8.",
            "And they are.",
            "500,000 instance in this six 8A beta Gamma, Delta, Epsilon and ETA and for Alpha Beta, Gamma Delta.",
            "They are.",
            "But 500 features and these features are very dense visors.",
            "Dance mean this mean each feature of instance all along you only row and memory requirement for this full data are three gigabytes.",
            "That's OK for our machine or a carbide machine.",
            "But for absent and they they are 2003 dance that feature.",
            "An memory requirement became.",
            "Celf gigabytes that's beyond the capacity of our MB machine."
        ],
        [
            "Ford set an OCR.",
            "The number of instances became much larger.",
            "And they still have a very stance features.",
            "If we use live linear directory, the memory requirements beyond even the larger than organized 32 recognition.",
            "And fall."
        ],
        [
            "DNA.",
            "No, it is an interesting.",
            "Characteristic, that's the future value of DNA is either zero or one.",
            "An one appears once every four features necessary.",
            "Interesting characteristic.",
            "So that's the density of DNA become .25.",
            "And we use the linear directory we need.",
            "120 gigabytes that's impossible, and for that they will spend the instance number of instant is the smallest among the ten day has a in this challenge, but it but they are very lot of feature number feature.",
            "The density is very small and this data says the only sparse data, say in this challenge."
        ],
        [
            "K. Next, so to overcome the memory difficulty, we have some modification of would do some modification."
        ],
        [
            "Until evening.",
            "For sparse data, actually we spend only.",
            "We use floats rather than double to store the future value.",
            "So each feature value consumed ad buys 4 bytes for index.",
            "4 bytes for value.",
            "So we best West Bank can be handled.",
            "And for dense data the most data say in this challenge we solve things.",
            "The index is no longer needed.",
            "So we stole the value for dense data only and each bag future value consume 4 bytes only so fast and OCR another dance data can be solved using this method on.",
            "Organizers machine."
        ],
        [
            "OK.",
            "But how about DNA?",
            "Quality and design.",
            "Another distance structure to solve it.",
            "Recall that the.",
            "Characteristic recall other DNS characteristic.",
            "Its future value is either one or zero, so we can store in its value in a bit.",
            "Alright, sorry we can store index only for 01 data.",
            "Uses short integer rather integer to store it and weak memory of DNA is reduced to.",
            "20 gigabytes."
        ],
        [
            "Whistle, Leboeuf, modification.",
            "We are able to change the whole set of each problem.",
            "Every challenge.",
            "And we are the only group in linear track to achieving this goal."
        ],
        [
            "For example, this is a DNA.",
            "There are 50 million instance India.",
            "Say at least figure.",
            "Is the data size versus CPU time?",
            "From this figure, the red line represents our submission level linear.",
            "You can see that the other groups of up to 1 million instance an hours submission suffer wholesale 50,000,000."
        ],
        [
            "OK, so we should approve three structure.",
            "All the answers can be solved on organizes machine, but before, but we need to submit some results on such submission.",
            "Result generated on our machine a gabite limits.",
            "So to generate the result we need another way to do it.",
            "For DNA we use only a bit array to store feature vector of each for each instance.",
            "For example, this binary binary represents the value of feature with index equal to or at one another feature value just level."
        ],
        [
            "Anne.",
            "With this modification.",
            "We can only 5 gigabytes.",
            "For DNA.",
            "And we believe a linear direct directory.",
            "We need 120 gigabyte and we submitted code.",
            "We need 20 gigabyte.",
            "So this is amazing memory reduction.",
            "But the tradeoff is that dance bitwise operation may slow down the training speed.",
            "OK."
        ],
        [
            "Next four OCIN face.",
            "We propose a different level shrinking method.",
            "What is shrinking in optimization if some variable already at optimal, we can ignore it.",
            "So the problem will be strong.",
            "So what is our different levels?",
            "Drink first we turn on we chat 1 million subset of data.",
            "And we predicted arrest data.",
            "Will remove that instance with this level times predictive value greater than 1.2.",
            "Why would do this?",
            "Because we guess this offer I corresponding to list corresponding other iPhone remove instance.",
            "Will be zero when we train a holiday.",
            "So we just remove it and we check the remaining set at remaining elements.",
            "And we can use this method to.",
            "Handle affects ossia within a GB machine."
        ],
        [
            "OK, now the stopping condition in linear SVM check we are request to find a solution to certificate.",
            "Submitted this equation.",
            "That relative duality gap must less than one point toward one, but live linear.",
            "Does not produce primal value with the dual coding dual coordinate dissemination.",
            "But we can calculate an approximate primal value called primal plan needs.",
            "And the detail we were not shown here.",
            "And since we use approximate primal value, so we use a small stampings tolerance, one polling point, or at as our starting current."
        ],
        [
            "OK, there's some discussions.",
            "First is the evaluation evaluation.",
            "We take that as an example.",
            "Oh, evaluate all criterion of Pascal training.",
            "A linear soundtrack are based on these three.",
            "Figure this one thick is a time versus object value.",
            "We penalty prime.",
            "It equals points or what?",
            "And right one is the figure of facts versus time.",
            "With parameter apparently parameter equals points or one and this one is a C defensive versus time.",
            "Oh criterion based on this three figure and we know that there are three criteria based on this vehicle, one for this.",
            "One for this.",
            "So we know that we see equal points or one is very important."
        ],
        [
            "And.",
            "Our code is that very fast when C equals point or one.",
            "Like this, this is your time in the objective.",
            "Our code in Ark with our code the objectives decrease very fast.",
            "And this is a data example.",
            "This is that data.",
            "There are half million instance we can solve around in around 10 minutes, 10 minutes 10 seconds."
        ],
        [
            "But we our code slow for gamma Delta DNA when C equals.",
            "OK, when C = 10.",
            "The reason is there are large feature value, for example as gamma.",
            "The minus five and minus three are larger than artificial value.",
            "And we take data.",
            "Example example again.",
            "When the sea is 10.",
            "The training time is very high and very long.",
            "So we set the maximum number of iteration for large C. For this three day, I say.",
            "OK, and.",
            "And you can see that someone just.",
            "Don't submit the Pixie better."
        ],
        [
            "OK, in practice.",
            "Small sees is enough.",
            "For example, the best across validation accuracy for gamma occurs when she is very small.",
            "And see should decrease other data size increases so someone use.",
            "See over at all as a penalty parameter rather than see."
        ],
        [
            "OK, now is another discussion.",
            "Solving primal or dual.",
            "Recall that the number of variable in primal is the number of features and the number of variable in dual is the number of the.",
            "Instance in terms of training set.",
            "So when the number of features not large, solving linear SVM, new primer will be better.",
            "This is a experience between these two approach.",
            "We can see these two figure.",
            "The blue one and the red one.",
            "The red light stands for Trust region Newton mass.",
            "In linear this South, the primal form of their two SVN.",
            "Another way one.",
            "Stands for.",
            "Dua Cody net Dissent method is offered you a form of land to SVN when C equals why the Delta and Gamma's dare say like this.",
            "Families two big we can see that one thing to mention the Y axis.",
            "Is the relative primal value difference between the different with optimum?",
            "And we can see that."
        ],
        [
            "With this large trust region, Newton method is faster.",
            "4 gig for Gamma and Delta, then codeigniter design.",
            "But you are calling that coordinate coordinate design is faster when she is smaller.",
            "We can know that different method we must use different methods for different situations."
        ],
        [
            "OK, OK some conclusion.",
            "We successfully China wholesale for each data in this challenge and only one.",
            "Group to pass one only one and for larger than say we need different approach.",
            "To solve the given problem with the.",
            "Different property and parameters thank.",
            "Old yeller labels are priests, except one works amazing.",
            "Useful for this particular problem, where there is only one.",
            "So I think our proposed this level drinking method is likely you see, like like you say.",
            "Why don't you normalize?",
            "Because we are not allowed to another feature selection or they had prepartion in linear accident check.",
            "When?",
            "Apples are correctly predicted.",
            "You just remove them.",
            "In less method.",
            "No, no, we have a condition where the label times predict value.",
            "In 1.1 point, yes yes.",
            "Did you try to verify this?",
            "Use different values for this threshold.",
            "So yes, we which in this parameter to tow ladder data, remaining data size fit our memory and the result shows that the objective is very close to the training horse they are saying.",
            "We can see the evaluation page now.",
            "It has some results here.",
            "2000 years ago.",
            "Trying to do the same varying this might be relevant.",
            "Yes.",
            "Yes.",
            "1000 or did you use?",
            "Yeah.",
            "I would just do cross validation on hold that holds it.",
            "OK, so thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is today's online.",
                    "label": 0
                },
                {
                    "sent": "First I will give some introduction to linear SVM.",
                    "label": 0
                },
                {
                    "sent": "An data analysis in this challenge.",
                    "label": 0
                },
                {
                    "sent": "Then my implementation to participate this challenge and some discussion.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Introduction There are four track in Pascal Challenge and we participate.",
                    "label": 0
                },
                {
                    "sent": "Linear swim check.",
                    "label": 0
                },
                {
                    "sent": "The reason is linear SVM is our recently research focus and we have no time to work on other there other track.",
                    "label": 1
                },
                {
                    "sent": "So today's talk will focus on the linear as we check.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so what's the problem?",
                    "label": 0
                },
                {
                    "sent": "We want to solve in linear SVM.",
                    "label": 0
                },
                {
                    "sent": "We are given a training, a set of training instance with labels Yi, an feature vector XI.",
                    "label": 0
                },
                {
                    "sent": "And each label Yi must be one or minus one.",
                    "label": 0
                },
                {
                    "sent": "What we want to do is find a weighting vector W to minimize this function.",
                    "label": 0
                },
                {
                    "sent": "And W transpose W / 2 is the regularization term.",
                    "label": 0
                },
                {
                    "sent": "ANSI is the penalty parameter, at least is a loss function.",
                    "label": 0
                },
                {
                    "sent": "There are two type of loss function stands for two type of linear SVM.",
                    "label": 0
                },
                {
                    "sent": "When last function is like this.",
                    "label": 0
                },
                {
                    "sent": "We gather at one SVM when the loss function like this we get the error two SVM we call these two phone primal phone of any SVM and in linear SVM track we are request to work on at one SVM only.",
                    "label": 1
                },
                {
                    "sent": "In addition to South Lincoln SVN in Primal, we can also solve.",
                    "label": 0
                },
                {
                    "sent": "Linux VM in its dual.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Frank Primal dual relationship.",
                    "label": 0
                },
                {
                    "sent": "We can derive the dual phone of advice would like this in this problem we try to find a vector Alpha to minimize function.",
                    "label": 0
                },
                {
                    "sent": "And the component of Alpha is bounded by zero and parameter C. The metric you.",
                    "label": 0
                },
                {
                    "sent": "Is composed of the inner product of each feature factor and their labels, and E is a vector of all wise.",
                    "label": 1
                },
                {
                    "sent": "And or two SVN.",
                    "label": 1
                },
                {
                    "sent": "Then the deal of the dual form of L2 SVM is similar.",
                    "label": 0
                },
                {
                    "sent": "And not that.",
                    "label": 0
                },
                {
                    "sent": "The dimension of Vector Alpha is the size of the instance of the training set, so.",
                    "label": 0
                },
                {
                    "sent": "Each component of Alpha I stands for corresponds for one instance in training set.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "Is the package we used to participate in ESPN track?",
                    "label": 0
                },
                {
                    "sent": "Leave a linear library for linear SVM.",
                    "label": 1
                },
                {
                    "sent": "In live linear it implements two optimization method.",
                    "label": 0
                },
                {
                    "sent": "One is your coordinate.",
                    "label": 1
                },
                {
                    "sent": "Dissent by this measure itself, the dual form of L1L2 SVM.",
                    "label": 0
                },
                {
                    "sent": "The another method is trust region Newton Mason.",
                    "label": 0
                },
                {
                    "sent": "Leave linear use this method to solve large logical regression and the primary form of level 2 SVN.",
                    "label": 0
                },
                {
                    "sent": "At least packages available at least address and not that.",
                    "label": 0
                },
                {
                    "sent": "Since we are request works on at one SVN and dual coding at decent is the only approach to South at once via live linear.",
                    "label": 0
                },
                {
                    "sent": "So let me briefly describe the this method.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This method is very simple, we just minimize one variable of your phone at a time.",
                    "label": 1
                },
                {
                    "sent": "The algorithm schemes like this.",
                    "label": 1
                },
                {
                    "sent": "While Vector Alpha is not optimal, we just choose a variable of dual and optimize it.",
                    "label": 0
                },
                {
                    "sent": "And the detail of this algorithm is in this paper, and there was a talk about this yesterday.",
                    "label": 0
                },
                {
                    "sent": "This method is very suitable for large sparse data.",
                    "label": 1
                },
                {
                    "sent": "What is the largest fast data mean when the number of instance an number of features are very large?",
                    "label": 0
                },
                {
                    "sent": "We call this data spots and large.",
                    "label": 0
                },
                {
                    "sent": "For example documents an.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This method is less suitable if this situation.",
                    "label": 1
                },
                {
                    "sent": "Well, she is large.",
                    "label": 0
                },
                {
                    "sent": "The penalty primacies large or the data is not scaled to the small range.",
                    "label": 1
                },
                {
                    "sent": "And from the equation over SVM, the meaning of two situations are then.",
                    "label": 0
                },
                {
                    "sent": "Another situation is when a number of features are small.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately that most that I said in this chat challenge at this case, so a dual coding dual coordinate dissent may not be the most most suitable method here.",
                    "label": 1
                },
                {
                    "sent": "But we have no choice since we need to focus on at once via and this is the only approach to software wise.",
                    "label": 1
                },
                {
                    "sent": "We're independent.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So now, is there some difficulty we encountered an hour solution?",
                    "label": 0
                },
                {
                    "sent": "And the target of live linear is to suffer large sparse data, so it only stole the feature with null value.",
                    "label": 0
                },
                {
                    "sent": "So each feature.",
                    "label": 0
                },
                {
                    "sent": "Consume tell fights.",
                    "label": 0
                },
                {
                    "sent": "Things it must store the index and value for each visual of instance.",
                    "label": 0
                },
                {
                    "sent": "Index consume 4 by their value.",
                    "label": 0
                },
                {
                    "sent": "Add bytes, but our machine has only 8 gigabyte memory and organizers machine has 32 gigabyte memory and they will run our code in their machine.",
                    "label": 1
                },
                {
                    "sent": "But if we use.",
                    "label": 0
                },
                {
                    "sent": "Live near directory.",
                    "label": 0
                },
                {
                    "sent": "The memory requirement would be larger than 32 gigabyte machine.",
                    "label": 0
                },
                {
                    "sent": "But our target and our goal is to solve the whole set for each data that ends at that.",
                    "label": 1
                },
                {
                    "sent": "I say in the machine OK.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now OK, so.",
                    "label": 0
                },
                {
                    "sent": "The data set is very large, so we must do some data analysis before we solve.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "8.",
                    "label": 0
                },
                {
                    "sent": "And they are.",
                    "label": 0
                },
                {
                    "sent": "500,000 instance in this six 8A beta Gamma, Delta, Epsilon and ETA and for Alpha Beta, Gamma Delta.",
                    "label": 1
                },
                {
                    "sent": "They are.",
                    "label": 0
                },
                {
                    "sent": "But 500 features and these features are very dense visors.",
                    "label": 0
                },
                {
                    "sent": "Dance mean this mean each feature of instance all along you only row and memory requirement for this full data are three gigabytes.",
                    "label": 0
                },
                {
                    "sent": "That's OK for our machine or a carbide machine.",
                    "label": 0
                },
                {
                    "sent": "But for absent and they they are 2003 dance that feature.",
                    "label": 0
                },
                {
                    "sent": "An memory requirement became.",
                    "label": 0
                },
                {
                    "sent": "Celf gigabytes that's beyond the capacity of our MB machine.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Ford set an OCR.",
                    "label": 0
                },
                {
                    "sent": "The number of instances became much larger.",
                    "label": 0
                },
                {
                    "sent": "And they still have a very stance features.",
                    "label": 0
                },
                {
                    "sent": "If we use live linear directory, the memory requirements beyond even the larger than organized 32 recognition.",
                    "label": 0
                },
                {
                    "sent": "And fall.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "DNA.",
                    "label": 0
                },
                {
                    "sent": "No, it is an interesting.",
                    "label": 0
                },
                {
                    "sent": "Characteristic, that's the future value of DNA is either zero or one.",
                    "label": 0
                },
                {
                    "sent": "An one appears once every four features necessary.",
                    "label": 1
                },
                {
                    "sent": "Interesting characteristic.",
                    "label": 0
                },
                {
                    "sent": "So that's the density of DNA become .25.",
                    "label": 0
                },
                {
                    "sent": "And we use the linear directory we need.",
                    "label": 0
                },
                {
                    "sent": "120 gigabytes that's impossible, and for that they will spend the instance number of instant is the smallest among the ten day has a in this challenge, but it but they are very lot of feature number feature.",
                    "label": 1
                },
                {
                    "sent": "The density is very small and this data says the only sparse data, say in this challenge.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "K. Next, so to overcome the memory difficulty, we have some modification of would do some modification.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Until evening.",
                    "label": 0
                },
                {
                    "sent": "For sparse data, actually we spend only.",
                    "label": 1
                },
                {
                    "sent": "We use floats rather than double to store the future value.",
                    "label": 1
                },
                {
                    "sent": "So each feature value consumed ad buys 4 bytes for index.",
                    "label": 1
                },
                {
                    "sent": "4 bytes for value.",
                    "label": 0
                },
                {
                    "sent": "So we best West Bank can be handled.",
                    "label": 0
                },
                {
                    "sent": "And for dense data the most data say in this challenge we solve things.",
                    "label": 0
                },
                {
                    "sent": "The index is no longer needed.",
                    "label": 0
                },
                {
                    "sent": "So we stole the value for dense data only and each bag future value consume 4 bytes only so fast and OCR another dance data can be solved using this method on.",
                    "label": 1
                },
                {
                    "sent": "Organizers machine.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "But how about DNA?",
                    "label": 0
                },
                {
                    "sent": "Quality and design.",
                    "label": 0
                },
                {
                    "sent": "Another distance structure to solve it.",
                    "label": 0
                },
                {
                    "sent": "Recall that the.",
                    "label": 0
                },
                {
                    "sent": "Characteristic recall other DNS characteristic.",
                    "label": 0
                },
                {
                    "sent": "Its future value is either one or zero, so we can store in its value in a bit.",
                    "label": 0
                },
                {
                    "sent": "Alright, sorry we can store index only for 01 data.",
                    "label": 1
                },
                {
                    "sent": "Uses short integer rather integer to store it and weak memory of DNA is reduced to.",
                    "label": 0
                },
                {
                    "sent": "20 gigabytes.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Whistle, Leboeuf, modification.",
                    "label": 0
                },
                {
                    "sent": "We are able to change the whole set of each problem.",
                    "label": 1
                },
                {
                    "sent": "Every challenge.",
                    "label": 1
                },
                {
                    "sent": "And we are the only group in linear track to achieving this goal.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For example, this is a DNA.",
                    "label": 0
                },
                {
                    "sent": "There are 50 million instance India.",
                    "label": 0
                },
                {
                    "sent": "Say at least figure.",
                    "label": 0
                },
                {
                    "sent": "Is the data size versus CPU time?",
                    "label": 1
                },
                {
                    "sent": "From this figure, the red line represents our submission level linear.",
                    "label": 0
                },
                {
                    "sent": "You can see that the other groups of up to 1 million instance an hours submission suffer wholesale 50,000,000.",
                    "label": 1
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so we should approve three structure.",
                    "label": 0
                },
                {
                    "sent": "All the answers can be solved on organizes machine, but before, but we need to submit some results on such submission.",
                    "label": 1
                },
                {
                    "sent": "Result generated on our machine a gabite limits.",
                    "label": 1
                },
                {
                    "sent": "So to generate the result we need another way to do it.",
                    "label": 0
                },
                {
                    "sent": "For DNA we use only a bit array to store feature vector of each for each instance.",
                    "label": 1
                },
                {
                    "sent": "For example, this binary binary represents the value of feature with index equal to or at one another feature value just level.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "With this modification.",
                    "label": 0
                },
                {
                    "sent": "We can only 5 gigabytes.",
                    "label": 0
                },
                {
                    "sent": "For DNA.",
                    "label": 0
                },
                {
                    "sent": "And we believe a linear direct directory.",
                    "label": 0
                },
                {
                    "sent": "We need 120 gigabyte and we submitted code.",
                    "label": 1
                },
                {
                    "sent": "We need 20 gigabyte.",
                    "label": 0
                },
                {
                    "sent": "So this is amazing memory reduction.",
                    "label": 0
                },
                {
                    "sent": "But the tradeoff is that dance bitwise operation may slow down the training speed.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Next four OCIN face.",
                    "label": 0
                },
                {
                    "sent": "We propose a different level shrinking method.",
                    "label": 0
                },
                {
                    "sent": "What is shrinking in optimization if some variable already at optimal, we can ignore it.",
                    "label": 0
                },
                {
                    "sent": "So the problem will be strong.",
                    "label": 0
                },
                {
                    "sent": "So what is our different levels?",
                    "label": 0
                },
                {
                    "sent": "Drink first we turn on we chat 1 million subset of data.",
                    "label": 0
                },
                {
                    "sent": "And we predicted arrest data.",
                    "label": 0
                },
                {
                    "sent": "Will remove that instance with this level times predictive value greater than 1.2.",
                    "label": 0
                },
                {
                    "sent": "Why would do this?",
                    "label": 0
                },
                {
                    "sent": "Because we guess this offer I corresponding to list corresponding other iPhone remove instance.",
                    "label": 0
                },
                {
                    "sent": "Will be zero when we train a holiday.",
                    "label": 0
                },
                {
                    "sent": "So we just remove it and we check the remaining set at remaining elements.",
                    "label": 1
                },
                {
                    "sent": "And we can use this method to.",
                    "label": 0
                },
                {
                    "sent": "Handle affects ossia within a GB machine.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, now the stopping condition in linear SVM check we are request to find a solution to certificate.",
                    "label": 1
                },
                {
                    "sent": "Submitted this equation.",
                    "label": 0
                },
                {
                    "sent": "That relative duality gap must less than one point toward one, but live linear.",
                    "label": 1
                },
                {
                    "sent": "Does not produce primal value with the dual coding dual coordinate dissemination.",
                    "label": 0
                },
                {
                    "sent": "But we can calculate an approximate primal value called primal plan needs.",
                    "label": 1
                },
                {
                    "sent": "And the detail we were not shown here.",
                    "label": 0
                },
                {
                    "sent": "And since we use approximate primal value, so we use a small stampings tolerance, one polling point, or at as our starting current.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, there's some discussions.",
                    "label": 0
                },
                {
                    "sent": "First is the evaluation evaluation.",
                    "label": 0
                },
                {
                    "sent": "We take that as an example.",
                    "label": 0
                },
                {
                    "sent": "Oh, evaluate all criterion of Pascal training.",
                    "label": 0
                },
                {
                    "sent": "A linear soundtrack are based on these three.",
                    "label": 0
                },
                {
                    "sent": "Figure this one thick is a time versus object value.",
                    "label": 1
                },
                {
                    "sent": "We penalty prime.",
                    "label": 0
                },
                {
                    "sent": "It equals points or what?",
                    "label": 1
                },
                {
                    "sent": "And right one is the figure of facts versus time.",
                    "label": 0
                },
                {
                    "sent": "With parameter apparently parameter equals points or one and this one is a C defensive versus time.",
                    "label": 0
                },
                {
                    "sent": "Oh criterion based on this three figure and we know that there are three criteria based on this vehicle, one for this.",
                    "label": 0
                },
                {
                    "sent": "One for this.",
                    "label": 0
                },
                {
                    "sent": "So we know that we see equal points or one is very important.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Our code is that very fast when C equals point or one.",
                    "label": 1
                },
                {
                    "sent": "Like this, this is your time in the objective.",
                    "label": 0
                },
                {
                    "sent": "Our code in Ark with our code the objectives decrease very fast.",
                    "label": 0
                },
                {
                    "sent": "And this is a data example.",
                    "label": 0
                },
                {
                    "sent": "This is that data.",
                    "label": 0
                },
                {
                    "sent": "There are half million instance we can solve around in around 10 minutes, 10 minutes 10 seconds.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But we our code slow for gamma Delta DNA when C equals.",
                    "label": 1
                },
                {
                    "sent": "OK, when C = 10.",
                    "label": 0
                },
                {
                    "sent": "The reason is there are large feature value, for example as gamma.",
                    "label": 0
                },
                {
                    "sent": "The minus five and minus three are larger than artificial value.",
                    "label": 0
                },
                {
                    "sent": "And we take data.",
                    "label": 0
                },
                {
                    "sent": "Example example again.",
                    "label": 0
                },
                {
                    "sent": "When the sea is 10.",
                    "label": 0
                },
                {
                    "sent": "The training time is very high and very long.",
                    "label": 0
                },
                {
                    "sent": "So we set the maximum number of iteration for large C. For this three day, I say.",
                    "label": 0
                },
                {
                    "sent": "OK, and.",
                    "label": 0
                },
                {
                    "sent": "And you can see that someone just.",
                    "label": 0
                },
                {
                    "sent": "Don't submit the Pixie better.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, in practice.",
                    "label": 0
                },
                {
                    "sent": "Small sees is enough.",
                    "label": 0
                },
                {
                    "sent": "For example, the best across validation accuracy for gamma occurs when she is very small.",
                    "label": 0
                },
                {
                    "sent": "And see should decrease other data size increases so someone use.",
                    "label": 1
                },
                {
                    "sent": "See over at all as a penalty parameter rather than see.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, now is another discussion.",
                    "label": 0
                },
                {
                    "sent": "Solving primal or dual.",
                    "label": 0
                },
                {
                    "sent": "Recall that the number of variable in primal is the number of features and the number of variable in dual is the number of the.",
                    "label": 0
                },
                {
                    "sent": "Instance in terms of training set.",
                    "label": 0
                },
                {
                    "sent": "So when the number of features not large, solving linear SVM, new primer will be better.",
                    "label": 0
                },
                {
                    "sent": "This is a experience between these two approach.",
                    "label": 0
                },
                {
                    "sent": "We can see these two figure.",
                    "label": 0
                },
                {
                    "sent": "The blue one and the red one.",
                    "label": 0
                },
                {
                    "sent": "The red light stands for Trust region Newton mass.",
                    "label": 1
                },
                {
                    "sent": "In linear this South, the primal form of their two SVN.",
                    "label": 0
                },
                {
                    "sent": "Another way one.",
                    "label": 0
                },
                {
                    "sent": "Stands for.",
                    "label": 0
                },
                {
                    "sent": "Dua Cody net Dissent method is offered you a form of land to SVN when C equals why the Delta and Gamma's dare say like this.",
                    "label": 0
                },
                {
                    "sent": "Families two big we can see that one thing to mention the Y axis.",
                    "label": 0
                },
                {
                    "sent": "Is the relative primal value difference between the different with optimum?",
                    "label": 0
                },
                {
                    "sent": "And we can see that.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "With this large trust region, Newton method is faster.",
                    "label": 1
                },
                {
                    "sent": "4 gig for Gamma and Delta, then codeigniter design.",
                    "label": 0
                },
                {
                    "sent": "But you are calling that coordinate coordinate design is faster when she is smaller.",
                    "label": 1
                },
                {
                    "sent": "We can know that different method we must use different methods for different situations.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, OK some conclusion.",
                    "label": 0
                },
                {
                    "sent": "We successfully China wholesale for each data in this challenge and only one.",
                    "label": 1
                },
                {
                    "sent": "Group to pass one only one and for larger than say we need different approach.",
                    "label": 0
                },
                {
                    "sent": "To solve the given problem with the.",
                    "label": 0
                },
                {
                    "sent": "Different property and parameters thank.",
                    "label": 0
                },
                {
                    "sent": "Old yeller labels are priests, except one works amazing.",
                    "label": 0
                },
                {
                    "sent": "Useful for this particular problem, where there is only one.",
                    "label": 0
                },
                {
                    "sent": "So I think our proposed this level drinking method is likely you see, like like you say.",
                    "label": 0
                },
                {
                    "sent": "Why don't you normalize?",
                    "label": 0
                },
                {
                    "sent": "Because we are not allowed to another feature selection or they had prepartion in linear accident check.",
                    "label": 0
                },
                {
                    "sent": "When?",
                    "label": 0
                },
                {
                    "sent": "Apples are correctly predicted.",
                    "label": 0
                },
                {
                    "sent": "You just remove them.",
                    "label": 0
                },
                {
                    "sent": "In less method.",
                    "label": 0
                },
                {
                    "sent": "No, no, we have a condition where the label times predict value.",
                    "label": 0
                },
                {
                    "sent": "In 1.1 point, yes yes.",
                    "label": 0
                },
                {
                    "sent": "Did you try to verify this?",
                    "label": 0
                },
                {
                    "sent": "Use different values for this threshold.",
                    "label": 0
                },
                {
                    "sent": "So yes, we which in this parameter to tow ladder data, remaining data size fit our memory and the result shows that the objective is very close to the training horse they are saying.",
                    "label": 0
                },
                {
                    "sent": "We can see the evaluation page now.",
                    "label": 0
                },
                {
                    "sent": "It has some results here.",
                    "label": 0
                },
                {
                    "sent": "2000 years ago.",
                    "label": 0
                },
                {
                    "sent": "Trying to do the same varying this might be relevant.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "1000 or did you use?",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "I would just do cross validation on hold that holds it.",
                    "label": 0
                },
                {
                    "sent": "OK, so thank you.",
                    "label": 0
                }
            ]
        }
    }
}