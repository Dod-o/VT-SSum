{
    "id": "scbiprodn6pvumw3p2qzg5f3lcjvhr5c",
    "title": "S-SEER: A Multimodal Office Activity Recognition System with Selective Perception",
    "info": {
        "author": [
            "Nuria Oliver, Tel Aviv University"
        ],
        "published": "Feb. 25, 2007",
        "recorded": "June 2004",
        "category": [
            "Top->Computer Science->Machine Learning->Markov Processes",
            "Top->Computer Science->Computer Vision"
        ]
    },
    "url": "http://videolectures.net/mlmi04ch_oliver_moars/",
    "segmentation": [
        [
            "Yeah, this is all.",
            "Thank you for that introduction and thank you for inviting me to come here to talk a little bit about one of the projects that I've been working on recently.",
            "This is joint war with Eric Horvitz and we're both from the Microsoft Research Lab in Redmond, and instead of Washington in the US."
        ],
        [
            "So this is an overview of the talk.",
            "First I will give a little bit of background on this original system that we developed called this year system.",
            "Which is a good platform for testing our ideas on human behavior modeling using machine learning techniques.",
            "I will describe this a pretty high level talk, so if you have any detailed questions you can either ask me later or look at the papers where everything is describing much more detail.",
            "I will present later some ideas that we have used from decision theory to create framework for selective perception for in real time choosing which sensors the system can use or which features the system is going to compute from those sensors.",
            "That leads to a new system that we call selective OS here will describe some experiments that we have run with the system and also a video of it and then a summary and future directions of research.",
            "So it's not Daniel mentioned in his his introduction.",
            "One of the main goals of my research is the automatic recognition of human."
        ],
        [
            "Behavior from sensors.",
            "One of my dreams is to have computers that can perceive and understand what is happening and react inconsequence some of the applications are more natural.",
            "Human computer interaction.",
            "Of course we saw Sarans office awareness the surprise and let's talk about this and office related projects.",
            "So is for a smart office.",
            "Distributed teams were you know that people working in different countries, for example, you know this year.",
            "On projects and you might want to have awareness of what the other people are doing while preserving their privacy, so you might not want to broadcast.",
            "The only on the video, but you might want to broadcast some high level information of what they're doing, such as if they are not.",
            "If they work in the computer right there on the phone, and things like that.",
            "And then there are also some Accessibility and medical applications.",
            "We have another project in which we are collaborating with G Medical for creating a new perceptual interface for surgeons because they need to be necrophilia sterile environment so they can't use the mouse.",
            "On the keyboard where the operating but they have computers in the operating room to access to a CAT, scans of the patients.",
            "So we have a canal project where they can browse different CAT scan images just using their hands."
        ],
        [
            "Some of the challenges that we seen something.",
            "Imagine little systems.",
            "Well, first, sort of one of our approaches is that we want perception to be central in the system as opposed to peripheral.",
            "But one of the main problems by doing that is that if you want to process all the perceptual information, you normally take 100% of the CPU power, so you can't really use the computer for anything else, so it's kind of useless because you have a computer that can.",
            "See what you're doing, but then they can do anything else, so the main focus of this talk is how to find strategies for allocating the resources for perception in a smart way in such a way that you can still recognize what is happening while taking the minimum CPU possible.",
            "And you can do that resource allocation either in design time and or in real time.",
            "I will show the version of the system that does in real time."
        ],
        [
            "Background system, as I mentioned that we developed to test our ideas and human behavior modeling in an office setting is called SEER and these are the two main papers about it and it's a prototype for doing real time multi model Multi scale office activity recognition.",
            "It can recognize activities in the office such as a phone conversation face to face conversation.",
            "If you're working on the computer, if there is nobody there.",
            "If you're giving a presentation to someone and so forth, all the activities can be trained.",
            "In real time from example by you doing that.",
            "So if you have any other activities that you like doing in the office, I don't know like eating or something, you could just run with that."
        ],
        [
            "These are the sensors that we use, so we use a FireWire camera.",
            "Standard camera, not particularly like greater solution or anything like that.",
            "Sample at a friends for second.",
            "I have two mini microphones mounted on its side of the monitor and I use them.",
            "Use two of them to do to be able to do sound localization.",
            "Lately I have been playing with another microphone array that has been developed our lab or a different group.",
            "Four microphones on the video that I'm going to show is actually using this microphone array.",
            "I only care about this alkalization whether the sound is coming from the left of the monitor, the right of the monitor on the center of miles, or so.",
            "It's just like a three valued discrete signal.",
            "Even though with this microphone array we can get very accurate angle of the beam of sound, and then it also monitors the keyboard and the mouse activities."
        ],
        [
            "Invented the machine learning approach for almost like a decade.",
            "I have been working on graphical models for human behavior recognition, in particular hidden Markov models and variations of them.",
            "So for this project I also sounds great deliver graphical models.",
            "I also tried an approach based on hidden Markov models and this is just a slide to sort of like show the notation that I would use it to talk.",
            "The shaded knows how the observations and hmm, and then these are the states.",
            "Each color look like.",
            "Personal the pie is across the different state and all of you are familiar with hmm, so I'm not gonna bother."
        ],
        [
            "Scribing much about them and as I have been mentioned a couple of talks ago, there are important limitations of Hmm's for multi modal reasoning and multiple channel information reasoning.",
            "The first one is that the 1st order Markov assumption that is cannot address long-term interactions or multiple times rarities and human behavior can be described in many different levels of abstraction.",
            "So that's a drawback of using a single item.",
            "It assumes single process dynamics, but many times you have multiple process dynamics.",
            "For example, in the product that we're describing before, when there are multiple people.",
            "Obviously each person is different process, so you know probably a single item and is not good idea.",
            "The context is limited to a single state variable, so if you have, you know a lot of sensors or a lot of data.",
            "This state space becomes quickly very intractable.",
            "I need a huge amount of training data in order to be able to learn other parameters, and normally you don't have that huge amount of data.",
            "But in our empirical experiences that a single later man is a very recent representation that is very fragile to changes in the environment when you have sensors and it is very often you know the lighting conditions are different, there is a cloud account, so you know the sun is gone, so the camera.",
            "It is different.",
            "There might be different background noise in the office, so you need to have a system that is very robust to all these changes in environment and a single edge man, at least in our experience, wasn't good enough."
        ],
        [
            "So we explore any architecture called layer.",
            "It Maps.",
            "The goal is to decompose the parameter space to sort of like, embed the information about the problem in the structure of the network and that way we also have many fewer parameters to learn.",
            "And what we do is we segment the problem into distance into different layers, one on top of each other so they can hierarchical manner and they opened at a different time granularities.",
            "So I'll explain more about them later.",
            "But it seems like a nice architecture to explain human behavior.",
            "Because of that proper."
        ],
        [
            "So for example, so you are on the phone and your office.",
            "You're using video and audio as your sensors.",
            "So on the audio channel you could observe a sequence of the phone ringing and then you know speech silence, silence.",
            "On the video channel, you could observe that there is a person present that sometimes might be moving, sometimes, maybe static and so forth, and then at a higher level you could infer that the person is on the phone.",
            "So this is the kind of interpretation that they want.",
            "We want to have.",
            "We want to be able to say for each channel what is happening, But then at a higher level you know what is the activity that is taking place in the office.",
            "And This is why the layer architecture seems to be a very appropriate architecture for this kind of."
        ],
        [
            "Sedation.",
            "So this is an example of how it could be a three layer architecture of items, and this will be the bottom layer which will be connected to your sensors and I use A to mention at this Community fashion, meaning that each HMM models are different Class A different model.",
            "For example, if this were audio items, I will have an item and modeling speech, another one for modeling music, another modeling for bringing another family, background noise, keyboard, typing, noise, whatever door shouting, whatever analysis you want tomorrow.",
            "Each of them is trying to interpret the data in real time and it's giving you a likelihood and then the way you infer what is happening is by choosing the item and it has the highest level.",
            "Say you're talking and Hmm's speech has the highest language, so you would say this speech going on.",
            "So these else here represent the likelihoods for each of the HMM at each time step.",
            "Say even compose a vector of T of them, and then what you do is you use those likelihoods.",
            "As the inputs to the next layer of which amounts.",
            "So this segments never see the real data, they only see the information results of the previous data.",
            "Ma'am inconsequence there are much more robust to changes in the environment because they are not connected to the sensors, so there is a change here.",
            "You know those estimates can handle the noise and these ones are much more insensitive to that another property of this architecture is that in order to have an observation for this layer you need to wait.",
            "For these items to give you the inferential result, so the timeline reality at this layer is larger than that I'm right here.",
            "So say you take 20 frames, you process 20 frames to provide one likelihood, But then you need twenty of these likelihoods to be able to process sequence here, so 20, and we've got to start to save 400 samples here or something like that.",
            "So the higher you go into therapy they hire sort of like, that's the temporal abstraction you are dealing with and then.",
            "And so forth.",
            "You can sort of like continue doing that."
        ],
        [
            "So having explained Bolton right, the machine learning and essentials this is the architecture of the SEER system, which is the prototype that we built for office awareness.",
            "We have another channel.",
            "We have a video channel.",
            "We have some localization channel and we also monitor the keyboard and the mouse activities on the audio channel.",
            "We have three main kinds of features that we compute.",
            "We do PCA on the LPC coefficients.",
            "We compute the energy and the mean of the violence and fundamental frequency and we use computers right now with the feature vector for the Bank of vitamins are doing all your classification.",
            "These are the kinds of sounds the system can classify and then they can all be training real time.",
            "So when you.",
            "Put the system in your office.",
            "There's probably different background noise than you know.",
            "Whatever in my office, so you could just very easily train it on the video side.",
            "We have four kinds of features.",
            "We compute the skin color probability in YDY space, motion density, program progress, imitation and phase density.",
            "The only feature that I don't I haven't done myself with the face detector, which was that developed in the Beijing.",
            "Laugh in China in the same way we have a Bank of vitamins classifying whether there is one person present when active person present, multiple people are mildly present, then the inferential results of this classification.",
            "This classification, where the sound is coming from, and whether there has been keyboard, mouse activity or not in the past seconds and five seconds is past is composing to another feature vector, which is the input to the next layer.",
            "And in this layer we can classify typical office activities such as those they are."
        ],
        [
            "So I will send out some experiments or the results that we got using layer.",
            "It demands versus items for the Office activity task and I was happy to see that people are idiots.",
            "They produce amateur results in, you know, in seen advantage of using the layer architecture for human behavior.",
            "So we have 60 minutes of office data, terminal productivity, 6 activities we use 50% of the data for training, 54 for testing this at the kind of icons.",
            "'cause you'll see that later on the video.",
            "So this icons are the icons at the system outputs whenever is recognizing something, so you'll see those appearing later as well.",
            "So if your person other person present other means that you're just working on the computer, you know, write an email or writing code, or like browsing the web, whatever.",
            "So we got match for our accuracy on layer to mess with Hmm's and of course there was a huge reduction in the dimensionality because we had embedded a lot of information in the structure of the problem.",
            "By having all these different layers as opposed to having a single later ma'am with all the data coming from all the sensors in one parameter space."
        ],
        [
            "Another important property that I don't know if you guys have noticed too is that not only you get better accuracy, but you get sharper classifications, meaning that the distance between the most likely model at the second most likely model are much larger when you use a layer architecture that we use HMM, so the system is more confident about what is happening.",
            "This graph represents on the X axis is the time, and on the Y we have normalized likelihood.",
            "For each of the models I know you can.",
            "I know where my pointer is.",
            "For one second, yeah, so these are the different activities and I don't know if it's visible from the back, but each column is.",
            "This is some testing data where we perform each of the different actions in sequence.",
            "So further were like working on the computer in the phone conversation there was then I was given a presentation face to face, competition, etc.",
            "Ideally you would like to see the top line here being the one that corresponds to the right model.",
            "But the most important point in this graph is not that.",
            "But is how far the second best model is, which is telling you know how confident the system is on you know which activities happening.",
            "So when we use it to Maps many times we had two models that were like almost the same language, so the system was confused about what was going on.",
            "But when we went to bypass when we went to their layer to map."
        ],
        [
            "Texture you know the winner happens to be the right one.",
            "Most of the cases, but more importantly, the second best model is always pretty far away from the best model, which is a nice property 'cause he makes system more reliable to noise and support.",
            "The second part of this talk and sort of like the main focus actually is on using selecting perception policies in a multi model system.",
            "So as I've described CR performance pretty well, but it usually takes.",
            "Here to model the CPU even if you have, you know a better CPU then you know there so you know they can always stick with more activities and then you can always take out the CPU again.",
            "So the goal of this research is to understand the value of the observations and to make decisions about which observations or which sensors to use in such a way that you gain the maximum information coming from those sensors at minimum cost.",
            "And I will talk about three different policies that we have worked on.",
            "To dynamically select the sensors or compute features from those answers, one of them is based on decision theory using the expected value of information and the other two are just sort of like for comparison reasons.",
            "One is you heuristic."
        ],
        [
            "Approach where with this client, some observation of frequencies and we say you know every I don't know 10 frames, you use the camera every turn in French is use audio and so forth, and then a random selection where you randomly select features or or sensors."
        ],
        [
            "There is a lot of related work, mostly on decision theory, and there isn't that much related work on using decision theory for perception and multimodal systems.",
            "I think the closest worked this is when it was used in the area of Activision, as it's not, it's not the same, but it's quite late in the sense that they use in vision as well."
        ],
        [
            "So we discussed it in more detail how we use each of these different policies for sensor sensor selection and feature selection.",
            "I don't know if you're familiar with value of information, unexpected values, information.",
            "I remind that most of you are familiar with it.",
            "So we compute the suspected value of information considering the value of eliminating uncertainty about the state of certain observational features under consideration.",
            "For example, and I will talk about features and sensors in discriminatively.",
            "I just say features for a more general purpose or a feature would be.",
            "For example, if you have a vision sensor, you can have four different features.",
            "Computer from that sets, or you know motion face detection program versus background detection, askew's skin color detection.",
            "The idea is to choose any possible combination of those."
        ],
        [
            "Features in real time.",
            "So there are 16 possible combinations that you could do.",
            "You could say I don't.",
            "I don't use any feature or I only compute the scheme or I only do motion or the motion and face detection and support, and the goal is how do you make the system in an automatic and mathematically someway choose which features to use in real time."
        ],
        [
            "Another tool uses decision theory approach.",
            "The utility model is very important because it is telling you.",
            "Sort of like what is there.",
            "Expected utility of the system when it takes different actions.",
            "The normal way to do it is to assess different utilities, which is the value of saying that, say, activity don't know phone conversation.",
            "You know what is the value of saying that there's a phone conversation, when in reality you are working on the computer.",
            "So you build a utility matrix that is telling you you know, sort of like the utility of every possible activity with every other one.",
            "If it is on the feature side, it will be.",
            "On the vision side, for example, we will achieve saying that there's one person present when in reality there is an active person present, or they're saying when there is 1% person, one day is now the president.",
            "Probably useful to save one person without a present so you know you said some of them to 0, some of them to one SQL."
        ],
        [
            "This is the standard equation for the expected value of observing and computer some features when we input.",
            "When we incorporate.",
            "So this is the current.",
            "The evidence up till now and these are the features that we are trying to determine whether to compute them or not.",
            "And this is the expression for determining whether to compute them off.",
            "So this is the expected value of using this particular features when I have the index.",
            "And here is the instantly instantly.",
            "Instantiation of a particular feature combination, so we discretize all the feature space and then we just have to go through all the possible values that they have for all the possible combinations."
        ],
        [
            "The net expected value is just the spectacle using the features.",
            "Man is expected value without using their minus the cost of computing those features.",
            "And again, how do you find this?",
            "Cost is actually quite interesting and relatively critical to this analysis.",
            "In the experiments that I will describe, we computed the cost as the computational cost, or using those features because that was our measure.",
            "So like driven force we wanted to reduce the computational course.",
            "The computational load that of the system.",
            "But there are other costs that you can use.",
            "You can associate the costs with the latency that users will observe.",
            "For example, you could say that I don't care if it takes 100% of the CPU when there is nobody there because it's not bothering the user, but if the user is working, you know I really don't want to love the CPU anymore, so you can impute higher costs when you know that the user is there versus not.",
            "And because this system can know whether this is there not you could actually have those.",
            "Context dependent costs and I have sent results on that as well."
        ],
        [
            "Skip that, so this is just to show how the framework works when we have the selective perception, so we have the same probabilistic models as before and we use the probability models from the layer.",
            "It's a match from the 80 ma'am as the probabilities that you need in the equations for the decision theory and then the selective Perception Module tells us which features to compute or which sensors to use and those will be the observations the HMS will have in the next frame.",
            "So these items don't see everything all the time, so you need to marginalise over their features or the sensors that you are using.",
            "Because many of the you know the feature vector, many of them maybe not observed at certain point."
        ],
        [
            "This is Jose equation for the decision theory approach when the probabilities for the features are just in the framework of HMM.",
            "So you can express everything using like the Alpha, an variables from data Maps, so it's."
        ],
        [
            "Nice because you can do this in real time.",
            "There is some overhead from doing this computation, so this is the overhead that is normally not very significant.",
            "Uh.",
            "So the second policy that we compare."
        ],
        [
            "Our decision theory approach with is this heuristic policy, where we defined a duty cycle and a period for each feature for its sensor.",
            "So this upsets at this for different sensors, so you say you know I'm doing all the only every N frames for you know X frames and so forth.",
            "We sort of we try to tune them to get the best results in sort of like an analytical way."
        ],
        [
            "And then the last policy just randomly selecting sensors and features."
        ],
        [
            "So this is the standards here, architecture of cheer.",
            "And then when we add the selective perception module so we can have it at any layer, the results that are going to show on the video correspond to using selective selective perception only at this layer.",
            "But we have also done experiments where we do it at every every layer.",
            "So at this layer would mean whether you are using some localization or not, whether you're using the keyboard and the mouse or not.",
            "And then whether you are using audio or or not or video and also whether you're closing your eyes or yourself like Putin.",
            "Your house, new year."
        ],
        [
            "Or not.",
            "I think I'm just going to skip that for the sake of time.",
            "This is just some."
        ],
        [
            "Charles intensive accuracy for this particular data set, we got very good results using all the features, but we also got pretty good results with the EVI approach and you know this and results with the other approaches and in terms of the computational power CPU consumption, which was our motivation without a significant reduction on the CPU consumption.",
            "When the user was interacting with the computer in particular, which is when you were giving a presentation on when you were working on the computer.",
            "So that was encouraging, because we actually, you know, is taking, say 20% of the CPU versus 60% CPU, so you can actually you know, do not see.",
            "They don't feel that many latency is in the computer anymore."
        ],
        [
            "Another thing that we did and I explained it before, is having a richer cost model that depends on what you're doing.",
            "So instead of having a fixed cost model, which is the computational cost of computing the features, we added the condition that on which activities you were doing on the context in such a way that would penalize the cost.",
            "If you were interacting with the computer and we would be penalized if you were not interacting with the computer and then in that case what happened was that."
        ],
        [
            "The red, the red numbers are with activity dependent costs, which is the constant cost and something interesting to observe is that when when the user was interacting with the computer, you know the CPU.",
            "Sorry activation time features was very low, whereas when there was nobody there or this one conversation means that there is nobody there but someone is talking in the corridor, so you can hear something, but you're not really interact with the computer, so we actually chose to use the sensors all the time because it's not it's not bothering the user.",
            "And that would lead to better recognition results eventually.",
            "So this is a video of how it works.",
            "Hold on.",
            "With my mouse."
        ],
        [
            "I'll post it a little bit.",
            "I don't know if it's going to be high clear enough.",
            "Hopefully will so it describes it.",
            "Just have audio, but it describes all the different features of the system, so I'll put it here for second, so this is.",
            "What the communists and this is actually the image that we process is so pretty low resolution image this is the audio signal.",
            "This is where the sound is coming from.",
            "You will see here some negative and positive number which other angles of where the sound is coming from and then here is this keyboard mouse activity.",
            "You see like keyboard or mouse and this changes very quickly, so it's not.",
            "You might see very easily and then this Blue Square here is where the face is using the face detector.",
            "So this tracking as you can see here, the changing of these numbers.",
            "But if you see some signal kills I'm talking and then it just changing the numbers here where the sound is coming from.",
            "As I'm moving from the left to the right to monitor as you see, the face detector doesn't always find the face, but it's not a problem because we have other features that we're using.",
            "And then here when I'm topping sort of like it switches to keyboard activity and then something interesting is that he knows where the keyboard is because it the keyboard makes a noise.",
            "So it's always like around the same angle than typing.",
            "So that's interesting because you can actually you know find where the phone is or where the keyboard is just by doing this analyzation that here is showing the visual, let me pause it again detection.",
            "So this is the scheme probability for the pixels is doing an online background learning.",
            "As well be to be able to handle with illumination changes and so forth.",
            "So if you turn the lights on, doesn't matter if we learn about learning the background all the time.",
            "Here you have the log likelihoods for each of the items and you can train it as you can see here in real time and then it's telling you what is the winner.",
            "We said we want active person present so that will change.",
            "As you know I'm moving around.",
            "And then when you see that blue pixels here is because it's very confident they face because the face detector found the face.",
            "So you see that it's pretty noisy background.",
            "But then he learned it, adapted to the new background.",
            "And then he says nobody present here, most likely more.",
            "And then I say come in, he goes to one active person present and you see there was some noise in the background.",
            "So Learnset overtime this is the background noise is learning it overtime.",
            "Nice going to show the audio side of it which is and again another Bank of it amounts.",
            "Here are the different amounts use recognizing speech.",
            "If you see a signal here.",
            "You know, this means that there's some sign I didn't record the audio.",
            "So now this ambient noise.",
            "And I was trying to call the phone so have fun drinking so now this is the sound for the flooring and ice is raining here.",
            "I guess I'm your noise mess page 'cause I was talking and so forth, so this is the kind of.",
            "Recognition that you can do in parallel for each of the lower level it's mass and then this is the higher level which is doing the activity recognition.",
            "So this is the kind of icon that it shows right now and these I will explain later.",
            "This is the activation of the different sensors.",
            "So now is detecting there's one person present.",
            "There is a speech ambient noise, especially in noise and then recognize it was a phone conversation.",
            "Now I'm working on the computer.",
            "I change here to person, present other activity, and then I'll be a noise.",
            "Two is the keyboard typing.",
            "So still thinks I'm there, but then realizes I'm not there anymore and there's nobody around and I actually opened this a little bit later.",
            "Let me post here what you see.",
            "Here is a normalized likelihoods for each of the models.",
            "This is just to give an idea of how the language change overtime, how they go up and down depending on their activity that is happening.",
            "And in these bars here represent each of the sensors, that is, whether it is active or not.",
            "This is for the selective perception part.",
            "So when they're all up, it means that they are being used and is like video, audio, sound localization, and then keyboard and mouse activities.",
            "And this is the same.",
            "So when they when the light is green is using the sensor when the light is red is not using the sensor.",
            "But I'm not.",
            "It's not active right now, but I will be active later, so I'll explain there.",
            "So then I was talking to someone else, something you so hear something.",
            "And then the type system conversation going on.",
            "Nothing you see here, like the different likelihoods.",
            "Anything now is going to show the selective perception part.",
            "If you have any questions, maybe you can ask me.",
            "Counseling.",
            "So, as I mentioned before, you'll see these bars going up and down, and this lights turning red or green depending on whether using the sensor.",
            "Also right not only using the keyboard and the mouse, did you see here is turning the video and the audio on and off.",
            "As you know, as it wants, whenever it's not very confident about what's happening.",
            "Is interesting that for this particular cost model that we have.",
            "It never uses this alkalization.",
            "Also, because I I'm not showing here a face to face conversation when there's a face to face conversation, there is more utility in using the same localization because you know that these two sound sources, but I don't have an example of that, so it never used it so localization.",
            "And it always uses the cover on the master 'cause he has like almost 0 cost.",
            "Computational speaking, so we never actually.",
            "Sometimes it turns it off, but very rarely.",
            "So as you can imagine, the CPU consumption when it's only using the keyboard and the mouse is like negligible, so you can actually use this in the background while you know you're using the computer for something else, and you know if you are working with other people remotely, you could just transfer to them.",
            "This kind of icon, which is a high level interpretation of what is happening as opposed to having to broadcast, you know they already on the video in real time.",
            "I think there for a friend you thought it was a face to face conversation.",
            "Sometimes sometimes this happens is Warframe because of the other languages.",
            "Go up and down.",
            "Well, I think I'm just not posting here because it keeps going.",
            "But you get an idea."
        ],
        [
            "Before he does so, this is also I'm finishing my dog right now.",
            "In summary, we have used a decision theoretic approach for feature selection and sensor selection, multi model systems, and one of the main sort of like our main driving force was you know how can we have a perceptual system that we can use in, you know in real life and we can reduce the computational cost quite significantly while.",
            "Preserving good recognition accuracy.",
            "In operative studies, it seems that the decision theory approach gives the best tradeoff between computational needs and accuracy."
        ],
        [
            "I have a lot of future or that we want to do.",
            "We want to explore different utility models and different cost models.",
            "There's another nice idea that we have which is right now when you don't use a sensor or you can use a feature it assumes is on now so it is ignoring the fact that he has some value.",
            "Maybe in the previous frame.",
            "So what we want to explore is to actually maybe fixing the value around that previous now point and somehow you know.",
            "Having a certain like covariance that increases overtime, so the system is not completely uncertain about what the feature was because he saw it.",
            "You know one in the previous frame.",
            "We are also exploring this decision theory approach, not just the graphical models but also to that dynamic Bayesian networks.",
            "And then there is also the issue of, you know, detecting not just what the person is doing but also the emotional state of the."
        ],
        [
            "And this is it.",
            "Thank you.",
            "So we have a few minutes for questions.",
            "Wants to start position.",
            "Minimum duration model to prevent switching.",
            "One second of no I have.",
            "I have used that I wasn't using it when I did the the demo, but we had sort of like a little bit of yeah we had a duration.",
            "So you need to have a certain activity for a certain time.",
            "Yeah, we've done that when we have that also.",
            "Please ignore some transition time between when if we don't have the duration model, just ignore the transition time between the different activities, so ignore you know 20 frames or whatever.",
            "Precious.",
            "This.",
            "Other the current system can deal with six different activities.",
            "So what would you guess to how many different activities with this scale out message?",
            "That's the first part in the second part.",
            "I could imagine that there are two different activities going on at the same time, so of course it can be on the phone and Eva and working on the computer.",
            "Yeah, yeah.",
            "So yeah.",
            "For example very often on the phone and I'm doing something else like working on the computer so you could train it.",
            "You could train it as working on the phone, plus you know talking on the phone while working on the computer as another activity is all trained from example.",
            "So you could train it with an example like that.",
            "So I think you know that would be another activity to classify in terms of how many more we could do.",
            "I really don't know.",
            "I you know I want to extend it tomorrow.",
            "I think we probably do easily.",
            "Maybe 10.",
            "I don't know.",
            "I'm just guessing.",
            "But yeah, I think that's an interesting question.",
            "But the nice thing about it is that as you can do everything in on the fly is very.",
            "I've demo'd this system in different venues and it's always been very robust because the only thing that had to retrain was the background noise and maybe you know that was it and the rest of it is all adaptive.",
            "So I have I have there's a number of people that want to try in their offices as well and you know see what kind of experiences they get.",
            "So I imagine they might have different activities that they do.",
            "As I mentioned before.",
            "OK, well let's thank you again for thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yeah, this is all.",
                    "label": 0
                },
                {
                    "sent": "Thank you for that introduction and thank you for inviting me to come here to talk a little bit about one of the projects that I've been working on recently.",
                    "label": 0
                },
                {
                    "sent": "This is joint war with Eric Horvitz and we're both from the Microsoft Research Lab in Redmond, and instead of Washington in the US.",
                    "label": 1
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is an overview of the talk.",
                    "label": 1
                },
                {
                    "sent": "First I will give a little bit of background on this original system that we developed called this year system.",
                    "label": 0
                },
                {
                    "sent": "Which is a good platform for testing our ideas on human behavior modeling using machine learning techniques.",
                    "label": 0
                },
                {
                    "sent": "I will describe this a pretty high level talk, so if you have any detailed questions you can either ask me later or look at the papers where everything is describing much more detail.",
                    "label": 0
                },
                {
                    "sent": "I will present later some ideas that we have used from decision theory to create framework for selective perception for in real time choosing which sensors the system can use or which features the system is going to compute from those sensors.",
                    "label": 0
                },
                {
                    "sent": "That leads to a new system that we call selective OS here will describe some experiments that we have run with the system and also a video of it and then a summary and future directions of research.",
                    "label": 0
                },
                {
                    "sent": "So it's not Daniel mentioned in his his introduction.",
                    "label": 0
                },
                {
                    "sent": "One of the main goals of my research is the automatic recognition of human.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Behavior from sensors.",
                    "label": 0
                },
                {
                    "sent": "One of my dreams is to have computers that can perceive and understand what is happening and react inconsequence some of the applications are more natural.",
                    "label": 0
                },
                {
                    "sent": "Human computer interaction.",
                    "label": 0
                },
                {
                    "sent": "Of course we saw Sarans office awareness the surprise and let's talk about this and office related projects.",
                    "label": 0
                },
                {
                    "sent": "So is for a smart office.",
                    "label": 0
                },
                {
                    "sent": "Distributed teams were you know that people working in different countries, for example, you know this year.",
                    "label": 1
                },
                {
                    "sent": "On projects and you might want to have awareness of what the other people are doing while preserving their privacy, so you might not want to broadcast.",
                    "label": 0
                },
                {
                    "sent": "The only on the video, but you might want to broadcast some high level information of what they're doing, such as if they are not.",
                    "label": 0
                },
                {
                    "sent": "If they work in the computer right there on the phone, and things like that.",
                    "label": 0
                },
                {
                    "sent": "And then there are also some Accessibility and medical applications.",
                    "label": 1
                },
                {
                    "sent": "We have another project in which we are collaborating with G Medical for creating a new perceptual interface for surgeons because they need to be necrophilia sterile environment so they can't use the mouse.",
                    "label": 0
                },
                {
                    "sent": "On the keyboard where the operating but they have computers in the operating room to access to a CAT, scans of the patients.",
                    "label": 0
                },
                {
                    "sent": "So we have a canal project where they can browse different CAT scan images just using their hands.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Some of the challenges that we seen something.",
                    "label": 0
                },
                {
                    "sent": "Imagine little systems.",
                    "label": 0
                },
                {
                    "sent": "Well, first, sort of one of our approaches is that we want perception to be central in the system as opposed to peripheral.",
                    "label": 0
                },
                {
                    "sent": "But one of the main problems by doing that is that if you want to process all the perceptual information, you normally take 100% of the CPU power, so you can't really use the computer for anything else, so it's kind of useless because you have a computer that can.",
                    "label": 0
                },
                {
                    "sent": "See what you're doing, but then they can do anything else, so the main focus of this talk is how to find strategies for allocating the resources for perception in a smart way in such a way that you can still recognize what is happening while taking the minimum CPU possible.",
                    "label": 1
                },
                {
                    "sent": "And you can do that resource allocation either in design time and or in real time.",
                    "label": 0
                },
                {
                    "sent": "I will show the version of the system that does in real time.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Background system, as I mentioned that we developed to test our ideas and human behavior modeling in an office setting is called SEER and these are the two main papers about it and it's a prototype for doing real time multi model Multi scale office activity recognition.",
                    "label": 0
                },
                {
                    "sent": "It can recognize activities in the office such as a phone conversation face to face conversation.",
                    "label": 0
                },
                {
                    "sent": "If you're working on the computer, if there is nobody there.",
                    "label": 1
                },
                {
                    "sent": "If you're giving a presentation to someone and so forth, all the activities can be trained.",
                    "label": 0
                },
                {
                    "sent": "In real time from example by you doing that.",
                    "label": 0
                },
                {
                    "sent": "So if you have any other activities that you like doing in the office, I don't know like eating or something, you could just run with that.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "These are the sensors that we use, so we use a FireWire camera.",
                    "label": 1
                },
                {
                    "sent": "Standard camera, not particularly like greater solution or anything like that.",
                    "label": 0
                },
                {
                    "sent": "Sample at a friends for second.",
                    "label": 0
                },
                {
                    "sent": "I have two mini microphones mounted on its side of the monitor and I use them.",
                    "label": 0
                },
                {
                    "sent": "Use two of them to do to be able to do sound localization.",
                    "label": 0
                },
                {
                    "sent": "Lately I have been playing with another microphone array that has been developed our lab or a different group.",
                    "label": 0
                },
                {
                    "sent": "Four microphones on the video that I'm going to show is actually using this microphone array.",
                    "label": 0
                },
                {
                    "sent": "I only care about this alkalization whether the sound is coming from the left of the monitor, the right of the monitor on the center of miles, or so.",
                    "label": 0
                },
                {
                    "sent": "It's just like a three valued discrete signal.",
                    "label": 0
                },
                {
                    "sent": "Even though with this microphone array we can get very accurate angle of the beam of sound, and then it also monitors the keyboard and the mouse activities.",
                    "label": 1
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Invented the machine learning approach for almost like a decade.",
                    "label": 0
                },
                {
                    "sent": "I have been working on graphical models for human behavior recognition, in particular hidden Markov models and variations of them.",
                    "label": 0
                },
                {
                    "sent": "So for this project I also sounds great deliver graphical models.",
                    "label": 0
                },
                {
                    "sent": "I also tried an approach based on hidden Markov models and this is just a slide to sort of like show the notation that I would use it to talk.",
                    "label": 0
                },
                {
                    "sent": "The shaded knows how the observations and hmm, and then these are the states.",
                    "label": 0
                },
                {
                    "sent": "Each color look like.",
                    "label": 0
                },
                {
                    "sent": "Personal the pie is across the different state and all of you are familiar with hmm, so I'm not gonna bother.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Scribing much about them and as I have been mentioned a couple of talks ago, there are important limitations of Hmm's for multi modal reasoning and multiple channel information reasoning.",
                    "label": 1
                },
                {
                    "sent": "The first one is that the 1st order Markov assumption that is cannot address long-term interactions or multiple times rarities and human behavior can be described in many different levels of abstraction.",
                    "label": 0
                },
                {
                    "sent": "So that's a drawback of using a single item.",
                    "label": 0
                },
                {
                    "sent": "It assumes single process dynamics, but many times you have multiple process dynamics.",
                    "label": 0
                },
                {
                    "sent": "For example, in the product that we're describing before, when there are multiple people.",
                    "label": 0
                },
                {
                    "sent": "Obviously each person is different process, so you know probably a single item and is not good idea.",
                    "label": 0
                },
                {
                    "sent": "The context is limited to a single state variable, so if you have, you know a lot of sensors or a lot of data.",
                    "label": 1
                },
                {
                    "sent": "This state space becomes quickly very intractable.",
                    "label": 0
                },
                {
                    "sent": "I need a huge amount of training data in order to be able to learn other parameters, and normally you don't have that huge amount of data.",
                    "label": 0
                },
                {
                    "sent": "But in our empirical experiences that a single later man is a very recent representation that is very fragile to changes in the environment when you have sensors and it is very often you know the lighting conditions are different, there is a cloud account, so you know the sun is gone, so the camera.",
                    "label": 0
                },
                {
                    "sent": "It is different.",
                    "label": 0
                },
                {
                    "sent": "There might be different background noise in the office, so you need to have a system that is very robust to all these changes in environment and a single edge man, at least in our experience, wasn't good enough.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we explore any architecture called layer.",
                    "label": 0
                },
                {
                    "sent": "It Maps.",
                    "label": 0
                },
                {
                    "sent": "The goal is to decompose the parameter space to sort of like, embed the information about the problem in the structure of the network and that way we also have many fewer parameters to learn.",
                    "label": 1
                },
                {
                    "sent": "And what we do is we segment the problem into distance into different layers, one on top of each other so they can hierarchical manner and they opened at a different time granularities.",
                    "label": 1
                },
                {
                    "sent": "So I'll explain more about them later.",
                    "label": 0
                },
                {
                    "sent": "But it seems like a nice architecture to explain human behavior.",
                    "label": 0
                },
                {
                    "sent": "Because of that proper.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for example, so you are on the phone and your office.",
                    "label": 0
                },
                {
                    "sent": "You're using video and audio as your sensors.",
                    "label": 0
                },
                {
                    "sent": "So on the audio channel you could observe a sequence of the phone ringing and then you know speech silence, silence.",
                    "label": 1
                },
                {
                    "sent": "On the video channel, you could observe that there is a person present that sometimes might be moving, sometimes, maybe static and so forth, and then at a higher level you could infer that the person is on the phone.",
                    "label": 0
                },
                {
                    "sent": "So this is the kind of interpretation that they want.",
                    "label": 0
                },
                {
                    "sent": "We want to have.",
                    "label": 0
                },
                {
                    "sent": "We want to be able to say for each channel what is happening, But then at a higher level you know what is the activity that is taking place in the office.",
                    "label": 0
                },
                {
                    "sent": "And This is why the layer architecture seems to be a very appropriate architecture for this kind of.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sedation.",
                    "label": 0
                },
                {
                    "sent": "So this is an example of how it could be a three layer architecture of items, and this will be the bottom layer which will be connected to your sensors and I use A to mention at this Community fashion, meaning that each HMM models are different Class A different model.",
                    "label": 0
                },
                {
                    "sent": "For example, if this were audio items, I will have an item and modeling speech, another one for modeling music, another modeling for bringing another family, background noise, keyboard, typing, noise, whatever door shouting, whatever analysis you want tomorrow.",
                    "label": 0
                },
                {
                    "sent": "Each of them is trying to interpret the data in real time and it's giving you a likelihood and then the way you infer what is happening is by choosing the item and it has the highest level.",
                    "label": 0
                },
                {
                    "sent": "Say you're talking and Hmm's speech has the highest language, so you would say this speech going on.",
                    "label": 0
                },
                {
                    "sent": "So these else here represent the likelihoods for each of the HMM at each time step.",
                    "label": 0
                },
                {
                    "sent": "Say even compose a vector of T of them, and then what you do is you use those likelihoods.",
                    "label": 0
                },
                {
                    "sent": "As the inputs to the next layer of which amounts.",
                    "label": 0
                },
                {
                    "sent": "So this segments never see the real data, they only see the information results of the previous data.",
                    "label": 0
                },
                {
                    "sent": "Ma'am inconsequence there are much more robust to changes in the environment because they are not connected to the sensors, so there is a change here.",
                    "label": 0
                },
                {
                    "sent": "You know those estimates can handle the noise and these ones are much more insensitive to that another property of this architecture is that in order to have an observation for this layer you need to wait.",
                    "label": 0
                },
                {
                    "sent": "For these items to give you the inferential result, so the timeline reality at this layer is larger than that I'm right here.",
                    "label": 0
                },
                {
                    "sent": "So say you take 20 frames, you process 20 frames to provide one likelihood, But then you need twenty of these likelihoods to be able to process sequence here, so 20, and we've got to start to save 400 samples here or something like that.",
                    "label": 0
                },
                {
                    "sent": "So the higher you go into therapy they hire sort of like, that's the temporal abstraction you are dealing with and then.",
                    "label": 0
                },
                {
                    "sent": "And so forth.",
                    "label": 0
                },
                {
                    "sent": "You can sort of like continue doing that.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So having explained Bolton right, the machine learning and essentials this is the architecture of the SEER system, which is the prototype that we built for office awareness.",
                    "label": 0
                },
                {
                    "sent": "We have another channel.",
                    "label": 0
                },
                {
                    "sent": "We have a video channel.",
                    "label": 0
                },
                {
                    "sent": "We have some localization channel and we also monitor the keyboard and the mouse activities on the audio channel.",
                    "label": 0
                },
                {
                    "sent": "We have three main kinds of features that we compute.",
                    "label": 0
                },
                {
                    "sent": "We do PCA on the LPC coefficients.",
                    "label": 1
                },
                {
                    "sent": "We compute the energy and the mean of the violence and fundamental frequency and we use computers right now with the feature vector for the Bank of vitamins are doing all your classification.",
                    "label": 0
                },
                {
                    "sent": "These are the kinds of sounds the system can classify and then they can all be training real time.",
                    "label": 0
                },
                {
                    "sent": "So when you.",
                    "label": 0
                },
                {
                    "sent": "Put the system in your office.",
                    "label": 0
                },
                {
                    "sent": "There's probably different background noise than you know.",
                    "label": 0
                },
                {
                    "sent": "Whatever in my office, so you could just very easily train it on the video side.",
                    "label": 0
                },
                {
                    "sent": "We have four kinds of features.",
                    "label": 0
                },
                {
                    "sent": "We compute the skin color probability in YDY space, motion density, program progress, imitation and phase density.",
                    "label": 1
                },
                {
                    "sent": "The only feature that I don't I haven't done myself with the face detector, which was that developed in the Beijing.",
                    "label": 0
                },
                {
                    "sent": "Laugh in China in the same way we have a Bank of vitamins classifying whether there is one person present when active person present, multiple people are mildly present, then the inferential results of this classification.",
                    "label": 1
                },
                {
                    "sent": "This classification, where the sound is coming from, and whether there has been keyboard, mouse activity or not in the past seconds and five seconds is past is composing to another feature vector, which is the input to the next layer.",
                    "label": 0
                },
                {
                    "sent": "And in this layer we can classify typical office activities such as those they are.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I will send out some experiments or the results that we got using layer.",
                    "label": 0
                },
                {
                    "sent": "It demands versus items for the Office activity task and I was happy to see that people are idiots.",
                    "label": 0
                },
                {
                    "sent": "They produce amateur results in, you know, in seen advantage of using the layer architecture for human behavior.",
                    "label": 0
                },
                {
                    "sent": "So we have 60 minutes of office data, terminal productivity, 6 activities we use 50% of the data for training, 54 for testing this at the kind of icons.",
                    "label": 1
                },
                {
                    "sent": "'cause you'll see that later on the video.",
                    "label": 0
                },
                {
                    "sent": "So this icons are the icons at the system outputs whenever is recognizing something, so you'll see those appearing later as well.",
                    "label": 1
                },
                {
                    "sent": "So if your person other person present other means that you're just working on the computer, you know, write an email or writing code, or like browsing the web, whatever.",
                    "label": 0
                },
                {
                    "sent": "So we got match for our accuracy on layer to mess with Hmm's and of course there was a huge reduction in the dimensionality because we had embedded a lot of information in the structure of the problem.",
                    "label": 0
                },
                {
                    "sent": "By having all these different layers as opposed to having a single later ma'am with all the data coming from all the sensors in one parameter space.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another important property that I don't know if you guys have noticed too is that not only you get better accuracy, but you get sharper classifications, meaning that the distance between the most likely model at the second most likely model are much larger when you use a layer architecture that we use HMM, so the system is more confident about what is happening.",
                    "label": 0
                },
                {
                    "sent": "This graph represents on the X axis is the time, and on the Y we have normalized likelihood.",
                    "label": 0
                },
                {
                    "sent": "For each of the models I know you can.",
                    "label": 0
                },
                {
                    "sent": "I know where my pointer is.",
                    "label": 0
                },
                {
                    "sent": "For one second, yeah, so these are the different activities and I don't know if it's visible from the back, but each column is.",
                    "label": 0
                },
                {
                    "sent": "This is some testing data where we perform each of the different actions in sequence.",
                    "label": 0
                },
                {
                    "sent": "So further were like working on the computer in the phone conversation there was then I was given a presentation face to face, competition, etc.",
                    "label": 0
                },
                {
                    "sent": "Ideally you would like to see the top line here being the one that corresponds to the right model.",
                    "label": 0
                },
                {
                    "sent": "But the most important point in this graph is not that.",
                    "label": 0
                },
                {
                    "sent": "But is how far the second best model is, which is telling you know how confident the system is on you know which activities happening.",
                    "label": 0
                },
                {
                    "sent": "So when we use it to Maps many times we had two models that were like almost the same language, so the system was confused about what was going on.",
                    "label": 0
                },
                {
                    "sent": "But when we went to bypass when we went to their layer to map.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Texture you know the winner happens to be the right one.",
                    "label": 0
                },
                {
                    "sent": "Most of the cases, but more importantly, the second best model is always pretty far away from the best model, which is a nice property 'cause he makes system more reliable to noise and support.",
                    "label": 0
                },
                {
                    "sent": "The second part of this talk and sort of like the main focus actually is on using selecting perception policies in a multi model system.",
                    "label": 0
                },
                {
                    "sent": "So as I've described CR performance pretty well, but it usually takes.",
                    "label": 0
                },
                {
                    "sent": "Here to model the CPU even if you have, you know a better CPU then you know there so you know they can always stick with more activities and then you can always take out the CPU again.",
                    "label": 0
                },
                {
                    "sent": "So the goal of this research is to understand the value of the observations and to make decisions about which observations or which sensors to use in such a way that you gain the maximum information coming from those sensors at minimum cost.",
                    "label": 0
                },
                {
                    "sent": "And I will talk about three different policies that we have worked on.",
                    "label": 0
                },
                {
                    "sent": "To dynamically select the sensors or compute features from those answers, one of them is based on decision theory using the expected value of information and the other two are just sort of like for comparison reasons.",
                    "label": 0
                },
                {
                    "sent": "One is you heuristic.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Approach where with this client, some observation of frequencies and we say you know every I don't know 10 frames, you use the camera every turn in French is use audio and so forth, and then a random selection where you randomly select features or or sensors.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There is a lot of related work, mostly on decision theory, and there isn't that much related work on using decision theory for perception and multimodal systems.",
                    "label": 0
                },
                {
                    "sent": "I think the closest worked this is when it was used in the area of Activision, as it's not, it's not the same, but it's quite late in the sense that they use in vision as well.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we discussed it in more detail how we use each of these different policies for sensor sensor selection and feature selection.",
                    "label": 0
                },
                {
                    "sent": "I don't know if you're familiar with value of information, unexpected values, information.",
                    "label": 0
                },
                {
                    "sent": "I remind that most of you are familiar with it.",
                    "label": 0
                },
                {
                    "sent": "So we compute the suspected value of information considering the value of eliminating uncertainty about the state of certain observational features under consideration.",
                    "label": 1
                },
                {
                    "sent": "For example, and I will talk about features and sensors in discriminatively.",
                    "label": 0
                },
                {
                    "sent": "I just say features for a more general purpose or a feature would be.",
                    "label": 0
                },
                {
                    "sent": "For example, if you have a vision sensor, you can have four different features.",
                    "label": 0
                },
                {
                    "sent": "Computer from that sets, or you know motion face detection program versus background detection, askew's skin color detection.",
                    "label": 0
                },
                {
                    "sent": "The idea is to choose any possible combination of those.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Features in real time.",
                    "label": 0
                },
                {
                    "sent": "So there are 16 possible combinations that you could do.",
                    "label": 0
                },
                {
                    "sent": "You could say I don't.",
                    "label": 0
                },
                {
                    "sent": "I don't use any feature or I only compute the scheme or I only do motion or the motion and face detection and support, and the goal is how do you make the system in an automatic and mathematically someway choose which features to use in real time.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Another tool uses decision theory approach.",
                    "label": 0
                },
                {
                    "sent": "The utility model is very important because it is telling you.",
                    "label": 1
                },
                {
                    "sent": "Sort of like what is there.",
                    "label": 0
                },
                {
                    "sent": "Expected utility of the system when it takes different actions.",
                    "label": 1
                },
                {
                    "sent": "The normal way to do it is to assess different utilities, which is the value of saying that, say, activity don't know phone conversation.",
                    "label": 1
                },
                {
                    "sent": "You know what is the value of saying that there's a phone conversation, when in reality you are working on the computer.",
                    "label": 0
                },
                {
                    "sent": "So you build a utility matrix that is telling you you know, sort of like the utility of every possible activity with every other one.",
                    "label": 0
                },
                {
                    "sent": "If it is on the feature side, it will be.",
                    "label": 0
                },
                {
                    "sent": "On the vision side, for example, we will achieve saying that there's one person present when in reality there is an active person present, or they're saying when there is 1% person, one day is now the president.",
                    "label": 0
                },
                {
                    "sent": "Probably useful to save one person without a present so you know you said some of them to 0, some of them to one SQL.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is the standard equation for the expected value of observing and computer some features when we input.",
                    "label": 1
                },
                {
                    "sent": "When we incorporate.",
                    "label": 1
                },
                {
                    "sent": "So this is the current.",
                    "label": 0
                },
                {
                    "sent": "The evidence up till now and these are the features that we are trying to determine whether to compute them or not.",
                    "label": 1
                },
                {
                    "sent": "And this is the expression for determining whether to compute them off.",
                    "label": 0
                },
                {
                    "sent": "So this is the expected value of using this particular features when I have the index.",
                    "label": 0
                },
                {
                    "sent": "And here is the instantly instantly.",
                    "label": 1
                },
                {
                    "sent": "Instantiation of a particular feature combination, so we discretize all the feature space and then we just have to go through all the possible values that they have for all the possible combinations.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The net expected value is just the spectacle using the features.",
                    "label": 1
                },
                {
                    "sent": "Man is expected value without using their minus the cost of computing those features.",
                    "label": 0
                },
                {
                    "sent": "And again, how do you find this?",
                    "label": 0
                },
                {
                    "sent": "Cost is actually quite interesting and relatively critical to this analysis.",
                    "label": 0
                },
                {
                    "sent": "In the experiments that I will describe, we computed the cost as the computational cost, or using those features because that was our measure.",
                    "label": 0
                },
                {
                    "sent": "So like driven force we wanted to reduce the computational course.",
                    "label": 1
                },
                {
                    "sent": "The computational load that of the system.",
                    "label": 0
                },
                {
                    "sent": "But there are other costs that you can use.",
                    "label": 0
                },
                {
                    "sent": "You can associate the costs with the latency that users will observe.",
                    "label": 0
                },
                {
                    "sent": "For example, you could say that I don't care if it takes 100% of the CPU when there is nobody there because it's not bothering the user, but if the user is working, you know I really don't want to love the CPU anymore, so you can impute higher costs when you know that the user is there versus not.",
                    "label": 0
                },
                {
                    "sent": "And because this system can know whether this is there not you could actually have those.",
                    "label": 0
                },
                {
                    "sent": "Context dependent costs and I have sent results on that as well.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Skip that, so this is just to show how the framework works when we have the selective perception, so we have the same probabilistic models as before and we use the probability models from the layer.",
                    "label": 0
                },
                {
                    "sent": "It's a match from the 80 ma'am as the probabilities that you need in the equations for the decision theory and then the selective Perception Module tells us which features to compute or which sensors to use and those will be the observations the HMS will have in the next frame.",
                    "label": 0
                },
                {
                    "sent": "So these items don't see everything all the time, so you need to marginalise over their features or the sensors that you are using.",
                    "label": 0
                },
                {
                    "sent": "Because many of the you know the feature vector, many of them maybe not observed at certain point.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is Jose equation for the decision theory approach when the probabilities for the features are just in the framework of HMM.",
                    "label": 0
                },
                {
                    "sent": "So you can express everything using like the Alpha, an variables from data Maps, so it's.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Nice because you can do this in real time.",
                    "label": 0
                },
                {
                    "sent": "There is some overhead from doing this computation, so this is the overhead that is normally not very significant.",
                    "label": 0
                },
                {
                    "sent": "Uh.",
                    "label": 0
                },
                {
                    "sent": "So the second policy that we compare.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Our decision theory approach with is this heuristic policy, where we defined a duty cycle and a period for each feature for its sensor.",
                    "label": 0
                },
                {
                    "sent": "So this upsets at this for different sensors, so you say you know I'm doing all the only every N frames for you know X frames and so forth.",
                    "label": 0
                },
                {
                    "sent": "We sort of we try to tune them to get the best results in sort of like an analytical way.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then the last policy just randomly selecting sensors and features.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is the standards here, architecture of cheer.",
                    "label": 0
                },
                {
                    "sent": "And then when we add the selective perception module so we can have it at any layer, the results that are going to show on the video correspond to using selective selective perception only at this layer.",
                    "label": 0
                },
                {
                    "sent": "But we have also done experiments where we do it at every every layer.",
                    "label": 0
                },
                {
                    "sent": "So at this layer would mean whether you are using some localization or not, whether you're using the keyboard and the mouse or not.",
                    "label": 0
                },
                {
                    "sent": "And then whether you are using audio or or not or video and also whether you're closing your eyes or yourself like Putin.",
                    "label": 0
                },
                {
                    "sent": "Your house, new year.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or not.",
                    "label": 0
                },
                {
                    "sent": "I think I'm just going to skip that for the sake of time.",
                    "label": 0
                },
                {
                    "sent": "This is just some.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Charles intensive accuracy for this particular data set, we got very good results using all the features, but we also got pretty good results with the EVI approach and you know this and results with the other approaches and in terms of the computational power CPU consumption, which was our motivation without a significant reduction on the CPU consumption.",
                    "label": 0
                },
                {
                    "sent": "When the user was interacting with the computer in particular, which is when you were giving a presentation on when you were working on the computer.",
                    "label": 0
                },
                {
                    "sent": "So that was encouraging, because we actually, you know, is taking, say 20% of the CPU versus 60% CPU, so you can actually you know, do not see.",
                    "label": 0
                },
                {
                    "sent": "They don't feel that many latency is in the computer anymore.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another thing that we did and I explained it before, is having a richer cost model that depends on what you're doing.",
                    "label": 0
                },
                {
                    "sent": "So instead of having a fixed cost model, which is the computational cost of computing the features, we added the condition that on which activities you were doing on the context in such a way that would penalize the cost.",
                    "label": 0
                },
                {
                    "sent": "If you were interacting with the computer and we would be penalized if you were not interacting with the computer and then in that case what happened was that.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The red, the red numbers are with activity dependent costs, which is the constant cost and something interesting to observe is that when when the user was interacting with the computer, you know the CPU.",
                    "label": 0
                },
                {
                    "sent": "Sorry activation time features was very low, whereas when there was nobody there or this one conversation means that there is nobody there but someone is talking in the corridor, so you can hear something, but you're not really interact with the computer, so we actually chose to use the sensors all the time because it's not it's not bothering the user.",
                    "label": 0
                },
                {
                    "sent": "And that would lead to better recognition results eventually.",
                    "label": 0
                },
                {
                    "sent": "So this is a video of how it works.",
                    "label": 0
                },
                {
                    "sent": "Hold on.",
                    "label": 0
                },
                {
                    "sent": "With my mouse.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'll post it a little bit.",
                    "label": 0
                },
                {
                    "sent": "I don't know if it's going to be high clear enough.",
                    "label": 0
                },
                {
                    "sent": "Hopefully will so it describes it.",
                    "label": 0
                },
                {
                    "sent": "Just have audio, but it describes all the different features of the system, so I'll put it here for second, so this is.",
                    "label": 0
                },
                {
                    "sent": "What the communists and this is actually the image that we process is so pretty low resolution image this is the audio signal.",
                    "label": 0
                },
                {
                    "sent": "This is where the sound is coming from.",
                    "label": 0
                },
                {
                    "sent": "You will see here some negative and positive number which other angles of where the sound is coming from and then here is this keyboard mouse activity.",
                    "label": 0
                },
                {
                    "sent": "You see like keyboard or mouse and this changes very quickly, so it's not.",
                    "label": 0
                },
                {
                    "sent": "You might see very easily and then this Blue Square here is where the face is using the face detector.",
                    "label": 0
                },
                {
                    "sent": "So this tracking as you can see here, the changing of these numbers.",
                    "label": 0
                },
                {
                    "sent": "But if you see some signal kills I'm talking and then it just changing the numbers here where the sound is coming from.",
                    "label": 0
                },
                {
                    "sent": "As I'm moving from the left to the right to monitor as you see, the face detector doesn't always find the face, but it's not a problem because we have other features that we're using.",
                    "label": 0
                },
                {
                    "sent": "And then here when I'm topping sort of like it switches to keyboard activity and then something interesting is that he knows where the keyboard is because it the keyboard makes a noise.",
                    "label": 0
                },
                {
                    "sent": "So it's always like around the same angle than typing.",
                    "label": 0
                },
                {
                    "sent": "So that's interesting because you can actually you know find where the phone is or where the keyboard is just by doing this analyzation that here is showing the visual, let me pause it again detection.",
                    "label": 0
                },
                {
                    "sent": "So this is the scheme probability for the pixels is doing an online background learning.",
                    "label": 0
                },
                {
                    "sent": "As well be to be able to handle with illumination changes and so forth.",
                    "label": 0
                },
                {
                    "sent": "So if you turn the lights on, doesn't matter if we learn about learning the background all the time.",
                    "label": 0
                },
                {
                    "sent": "Here you have the log likelihoods for each of the items and you can train it as you can see here in real time and then it's telling you what is the winner.",
                    "label": 0
                },
                {
                    "sent": "We said we want active person present so that will change.",
                    "label": 0
                },
                {
                    "sent": "As you know I'm moving around.",
                    "label": 0
                },
                {
                    "sent": "And then when you see that blue pixels here is because it's very confident they face because the face detector found the face.",
                    "label": 0
                },
                {
                    "sent": "So you see that it's pretty noisy background.",
                    "label": 0
                },
                {
                    "sent": "But then he learned it, adapted to the new background.",
                    "label": 0
                },
                {
                    "sent": "And then he says nobody present here, most likely more.",
                    "label": 1
                },
                {
                    "sent": "And then I say come in, he goes to one active person present and you see there was some noise in the background.",
                    "label": 0
                },
                {
                    "sent": "So Learnset overtime this is the background noise is learning it overtime.",
                    "label": 0
                },
                {
                    "sent": "Nice going to show the audio side of it which is and again another Bank of it amounts.",
                    "label": 0
                },
                {
                    "sent": "Here are the different amounts use recognizing speech.",
                    "label": 0
                },
                {
                    "sent": "If you see a signal here.",
                    "label": 0
                },
                {
                    "sent": "You know, this means that there's some sign I didn't record the audio.",
                    "label": 0
                },
                {
                    "sent": "So now this ambient noise.",
                    "label": 0
                },
                {
                    "sent": "And I was trying to call the phone so have fun drinking so now this is the sound for the flooring and ice is raining here.",
                    "label": 0
                },
                {
                    "sent": "I guess I'm your noise mess page 'cause I was talking and so forth, so this is the kind of.",
                    "label": 0
                },
                {
                    "sent": "Recognition that you can do in parallel for each of the lower level it's mass and then this is the higher level which is doing the activity recognition.",
                    "label": 0
                },
                {
                    "sent": "So this is the kind of icon that it shows right now and these I will explain later.",
                    "label": 0
                },
                {
                    "sent": "This is the activation of the different sensors.",
                    "label": 1
                },
                {
                    "sent": "So now is detecting there's one person present.",
                    "label": 0
                },
                {
                    "sent": "There is a speech ambient noise, especially in noise and then recognize it was a phone conversation.",
                    "label": 1
                },
                {
                    "sent": "Now I'm working on the computer.",
                    "label": 0
                },
                {
                    "sent": "I change here to person, present other activity, and then I'll be a noise.",
                    "label": 0
                },
                {
                    "sent": "Two is the keyboard typing.",
                    "label": 0
                },
                {
                    "sent": "So still thinks I'm there, but then realizes I'm not there anymore and there's nobody around and I actually opened this a little bit later.",
                    "label": 0
                },
                {
                    "sent": "Let me post here what you see.",
                    "label": 0
                },
                {
                    "sent": "Here is a normalized likelihoods for each of the models.",
                    "label": 0
                },
                {
                    "sent": "This is just to give an idea of how the language change overtime, how they go up and down depending on their activity that is happening.",
                    "label": 0
                },
                {
                    "sent": "And in these bars here represent each of the sensors, that is, whether it is active or not.",
                    "label": 0
                },
                {
                    "sent": "This is for the selective perception part.",
                    "label": 1
                },
                {
                    "sent": "So when they're all up, it means that they are being used and is like video, audio, sound localization, and then keyboard and mouse activities.",
                    "label": 0
                },
                {
                    "sent": "And this is the same.",
                    "label": 0
                },
                {
                    "sent": "So when they when the light is green is using the sensor when the light is red is not using the sensor.",
                    "label": 0
                },
                {
                    "sent": "But I'm not.",
                    "label": 0
                },
                {
                    "sent": "It's not active right now, but I will be active later, so I'll explain there.",
                    "label": 0
                },
                {
                    "sent": "So then I was talking to someone else, something you so hear something.",
                    "label": 0
                },
                {
                    "sent": "And then the type system conversation going on.",
                    "label": 0
                },
                {
                    "sent": "Nothing you see here, like the different likelihoods.",
                    "label": 0
                },
                {
                    "sent": "Anything now is going to show the selective perception part.",
                    "label": 0
                },
                {
                    "sent": "If you have any questions, maybe you can ask me.",
                    "label": 0
                },
                {
                    "sent": "Counseling.",
                    "label": 0
                },
                {
                    "sent": "So, as I mentioned before, you'll see these bars going up and down, and this lights turning red or green depending on whether using the sensor.",
                    "label": 0
                },
                {
                    "sent": "Also right not only using the keyboard and the mouse, did you see here is turning the video and the audio on and off.",
                    "label": 0
                },
                {
                    "sent": "As you know, as it wants, whenever it's not very confident about what's happening.",
                    "label": 0
                },
                {
                    "sent": "Is interesting that for this particular cost model that we have.",
                    "label": 0
                },
                {
                    "sent": "It never uses this alkalization.",
                    "label": 0
                },
                {
                    "sent": "Also, because I I'm not showing here a face to face conversation when there's a face to face conversation, there is more utility in using the same localization because you know that these two sound sources, but I don't have an example of that, so it never used it so localization.",
                    "label": 0
                },
                {
                    "sent": "And it always uses the cover on the master 'cause he has like almost 0 cost.",
                    "label": 0
                },
                {
                    "sent": "Computational speaking, so we never actually.",
                    "label": 0
                },
                {
                    "sent": "Sometimes it turns it off, but very rarely.",
                    "label": 0
                },
                {
                    "sent": "So as you can imagine, the CPU consumption when it's only using the keyboard and the mouse is like negligible, so you can actually use this in the background while you know you're using the computer for something else, and you know if you are working with other people remotely, you could just transfer to them.",
                    "label": 0
                },
                {
                    "sent": "This kind of icon, which is a high level interpretation of what is happening as opposed to having to broadcast, you know they already on the video in real time.",
                    "label": 0
                },
                {
                    "sent": "I think there for a friend you thought it was a face to face conversation.",
                    "label": 1
                },
                {
                    "sent": "Sometimes sometimes this happens is Warframe because of the other languages.",
                    "label": 0
                },
                {
                    "sent": "Go up and down.",
                    "label": 0
                },
                {
                    "sent": "Well, I think I'm just not posting here because it keeps going.",
                    "label": 0
                },
                {
                    "sent": "But you get an idea.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Before he does so, this is also I'm finishing my dog right now.",
                    "label": 0
                },
                {
                    "sent": "In summary, we have used a decision theoretic approach for feature selection and sensor selection, multi model systems, and one of the main sort of like our main driving force was you know how can we have a perceptual system that we can use in, you know in real life and we can reduce the computational cost quite significantly while.",
                    "label": 0
                },
                {
                    "sent": "Preserving good recognition accuracy.",
                    "label": 0
                },
                {
                    "sent": "In operative studies, it seems that the decision theory approach gives the best tradeoff between computational needs and accuracy.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I have a lot of future or that we want to do.",
                    "label": 0
                },
                {
                    "sent": "We want to explore different utility models and different cost models.",
                    "label": 0
                },
                {
                    "sent": "There's another nice idea that we have which is right now when you don't use a sensor or you can use a feature it assumes is on now so it is ignoring the fact that he has some value.",
                    "label": 0
                },
                {
                    "sent": "Maybe in the previous frame.",
                    "label": 0
                },
                {
                    "sent": "So what we want to explore is to actually maybe fixing the value around that previous now point and somehow you know.",
                    "label": 0
                },
                {
                    "sent": "Having a certain like covariance that increases overtime, so the system is not completely uncertain about what the feature was because he saw it.",
                    "label": 0
                },
                {
                    "sent": "You know one in the previous frame.",
                    "label": 0
                },
                {
                    "sent": "We are also exploring this decision theory approach, not just the graphical models but also to that dynamic Bayesian networks.",
                    "label": 0
                },
                {
                    "sent": "And then there is also the issue of, you know, detecting not just what the person is doing but also the emotional state of the.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is it.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "So we have a few minutes for questions.",
                    "label": 0
                },
                {
                    "sent": "Wants to start position.",
                    "label": 0
                },
                {
                    "sent": "Minimum duration model to prevent switching.",
                    "label": 0
                },
                {
                    "sent": "One second of no I have.",
                    "label": 0
                },
                {
                    "sent": "I have used that I wasn't using it when I did the the demo, but we had sort of like a little bit of yeah we had a duration.",
                    "label": 0
                },
                {
                    "sent": "So you need to have a certain activity for a certain time.",
                    "label": 0
                },
                {
                    "sent": "Yeah, we've done that when we have that also.",
                    "label": 0
                },
                {
                    "sent": "Please ignore some transition time between when if we don't have the duration model, just ignore the transition time between the different activities, so ignore you know 20 frames or whatever.",
                    "label": 0
                },
                {
                    "sent": "Precious.",
                    "label": 0
                },
                {
                    "sent": "This.",
                    "label": 0
                },
                {
                    "sent": "Other the current system can deal with six different activities.",
                    "label": 0
                },
                {
                    "sent": "So what would you guess to how many different activities with this scale out message?",
                    "label": 0
                },
                {
                    "sent": "That's the first part in the second part.",
                    "label": 0
                },
                {
                    "sent": "I could imagine that there are two different activities going on at the same time, so of course it can be on the phone and Eva and working on the computer.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah.",
                    "label": 0
                },
                {
                    "sent": "So yeah.",
                    "label": 0
                },
                {
                    "sent": "For example very often on the phone and I'm doing something else like working on the computer so you could train it.",
                    "label": 0
                },
                {
                    "sent": "You could train it as working on the phone, plus you know talking on the phone while working on the computer as another activity is all trained from example.",
                    "label": 0
                },
                {
                    "sent": "So you could train it with an example like that.",
                    "label": 0
                },
                {
                    "sent": "So I think you know that would be another activity to classify in terms of how many more we could do.",
                    "label": 0
                },
                {
                    "sent": "I really don't know.",
                    "label": 0
                },
                {
                    "sent": "I you know I want to extend it tomorrow.",
                    "label": 0
                },
                {
                    "sent": "I think we probably do easily.",
                    "label": 0
                },
                {
                    "sent": "Maybe 10.",
                    "label": 0
                },
                {
                    "sent": "I don't know.",
                    "label": 0
                },
                {
                    "sent": "I'm just guessing.",
                    "label": 0
                },
                {
                    "sent": "But yeah, I think that's an interesting question.",
                    "label": 0
                },
                {
                    "sent": "But the nice thing about it is that as you can do everything in on the fly is very.",
                    "label": 0
                },
                {
                    "sent": "I've demo'd this system in different venues and it's always been very robust because the only thing that had to retrain was the background noise and maybe you know that was it and the rest of it is all adaptive.",
                    "label": 0
                },
                {
                    "sent": "So I have I have there's a number of people that want to try in their offices as well and you know see what kind of experiences they get.",
                    "label": 0
                },
                {
                    "sent": "So I imagine they might have different activities that they do.",
                    "label": 0
                },
                {
                    "sent": "As I mentioned before.",
                    "label": 0
                },
                {
                    "sent": "OK, well let's thank you again for thank you.",
                    "label": 0
                }
            ]
        }
    }
}