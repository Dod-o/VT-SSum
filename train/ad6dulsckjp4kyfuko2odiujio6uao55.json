{
    "id": "ad6dulsckjp4kyfuko2odiujio6uao55",
    "title": "Machine learning",
    "info": {
        "author": [
            "Bla\u017e Fortuna, Artificial Intelligence Laboratory, Jo\u017eef Stefan Institute"
        ],
        "published": "Oct. 6, 2016",
        "recorded": "September 2016",
        "category": [
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/eswc2016_fortuna_machine_learning/",
    "segmentation": [
        [
            "In the morning.",
            "Over some probability and statistics and County ideas.",
            "Some introduction to data science and what have we covered in our next.",
            "His first.",
            "What do we understand by machine learning?",
            "Then go over some ideas over some problems that are typically solved machine learning and will be added.",
            "Check couple of methods so hopefully by the end of this, however, we have a better understanding.",
            "To use machine learning and what?",
            "How to use it?"
        ],
        [
            "Richard Pryor motivation.",
            "So let's say we are given appropriate task to develop a program that enterprise all the persons in this Africa.",
            "So this is one article you see, there's a stop talking about American Medical.",
            "Theresa May now some other entities, but they're not personal, so maybe they are not what they want to cover.",
            "You don't want identify.",
            "Other question is how would one approach developing such a program?"
        ],
        [
            "So let's say one way would be so OK we can.",
            "Down open hours, dedicated understaffed.",
            "OK let's say we have a list of common person language that sounds like a good way to start.",
            "Identify all the all the words in the document that are from this list.",
            "Maybe then add some rules.",
            "So many rules checking as they were the leader capital character.",
            "English people names usually start with capital characters.",
            "Then we can also try to find some expressions.",
            "Maybe it's written somewhere somebody said and people usually talk, so maybe somebody is also a person and so on.",
            "So this is if you can go down and drive this route, but it's kind of tedious and it's.",
            "Cards to this kind of brittle rules to comfort."
        ],
        [
            "Nova.",
            "Let's say that we would have a cap collection of hospitals already, so we're giving the big corpus and all the names people names are annotated in there.",
            "Now the question is, can be trained a program from this kind of training it or something this labeled corpus?",
            "Can we train a program that would recognize people?",
            "And this is exactly what we do with machine learning approaches.",
            "And in our example, how would that look like?",
            "So first we have to we decided we do will go by label identifying putting towards this belong to a person name or not.",
            "So we break the people commenting towards and describe each word by some characteristic.",
            "So maybe everything that's on the previous slide could be used as one of the features.",
            "But we don't really need to tell the system is it would feature bad features.",
            "How does it interact with the others?",
            "So example beyond the capital stop the capital character.",
            "It's on the list of common names.",
            "What are the words in the context?",
            "Then we mark each work from our from our focus as a person for others.",
            "So this is what our collection of African gives us.",
            "And then we have a.",
            "We take one of our one of the machine learning algorithms applied to this.",
            "And we show each other this training data and outcomes the model.",
            "And the model is basically a function that you give it to work and can tell is it a person or is it other.",
            "But it's kind of very handily high level overview.",
            "And but the main idea is instead of approaching the problem from starts or saying, how is a person, then trying to maybe figure out rules and so on.",
            "We want to go for the other way.",
            "Can we see a lot of annotated data and let this machine do the figuring out of the room you just provided the signal?"
        ],
        [
            "So their features.",
            "Now get out there.",
            "So first we check with this machine learning.",
            "Then they check the standard machine learning problems so but the different traffic controller problems surprised and supervising song.",
            "Then we do a bit more into detail.",
            "So how do we represent data?",
            "What actually is a model of the presenter model?",
            "How to fit a model?",
            "It's a good model and then how to evaluate?",
            "So how good are we doing?",
            "OK, so."
        ],
        [
            "Course that is.",
            "Of course, the polling says subfield of computer science.",
            "Nicole from.",
            "When will the machine became machines become more powerful?",
            "So it's kind of evolved from this pattern pattern recognition, computational learning theory, artificial intelligence, but nowadays it would be largely considered kind of a subfield of AI intelligence.",
            "And this is an old boat from 59, so there are some summers at the field of study that gives computers the ability to learn without being explicitly programmed so.",
            "We give means of computer code, so we give it to material material to learn from.",
            "They give it kind of approaches for learning from this material and then we let it go and hopefully the out we get a model.",
            "We get out the program that is better if you'd try to program incrementally.",
            "And machine learning to work.",
            "Most people working on machine learning, but they do.",
            "They mostly remains.",
            "The core task would be developing algorithms.",
            "Efficient algorithm can learn models from.",
            "Inefficient ways?"
        ],
        [
            "So this is 1 slide from this year's Kennedy, so lots of things are kind of on the borderline between statistics and other science.",
            "And then what was the machine learning considered a separate field or, heads?",
            "Or this data science, especially with computer scientists are better than statisticians at marketing.",
            "And it's not so.",
            "This also the cloudless code.",
            "But the data scientist do so.",
            "It's kind of in between computer science and statistics."
        ],
        [
            "Get out terminology so we'll be using couple of words throughout this talk.",
            "Maybe just to get them down.",
            "So first this training data.",
            "So what we what we consider building data so it's the input data feed to the machine learning algorithm.",
            "It can be labeled.",
            "It can be unlabeled.",
            "We see differences.",
            "And one example of me, if you're doing sentiment classification, so we have a collection of tweets and preached, we say is it positive?",
            "Is it negative?",
            "Is it neutral sentiment?",
            "And this this is kind of the training data.",
            "So we want we want the machine to replicate.",
            "So getting from a tree to sentiment label.",
            "Then another victim is model, so that is a model.",
            "Basically, can we look at it as a function that is kind of the writers using some machine learning algorithm and it takes the input data and produces the desired output.",
            "So in that example the beginning input could be award out would be saying easy to a person, or is it not a person?",
            "And what is it then?",
            "The last word is prediction, so that is a prediction.",
            "So if you take a data point, applying the model to get a prediction.",
            "Now."
        ],
        [
            "Quick demo.",
            "So we had to switch.",
            "Had been what we'll be doing is binary classification, which needed more details about it later.",
            "But what is?",
            "Let's suppose, V. Are given a data set.",
            "We have a.",
            "Our space is a 2 dimensional thing.",
            "We have some points that we would like to classify as positive.",
            "We have some points, two points that we would like to classify as negative.",
            "Basically we just want to.",
            "Discriminate between them so.",
            "Are being given a collection of points for somebody say they are ready for some sailor blue.",
            "Another question is.",
            "Can you learn a model?",
            "It will that that will be able to predict when you point that will appoint it appears here.",
            "Is it blue or red?",
            "So looking at this picture here would probably say should be blue here it should be read here, not sure so.",
            "And then one by one easy way to do this.",
            "Is by.",
            "Throwing up like between the two clouds, this is called the linear model and here and everything that's in this side of the line is blue.",
            "Everything that's on this side of the line is correct, so.",
            "In that sense, so this line was picked by some criterion to be the optimal line for this collection of data points.",
            "But you can see that if we say here, we can based on this model you can say it's correct.",
            "You don't really know.",
            "We don't have any evidence from here.",
            "Now the models can get arbitrarily more complex.",
            "So let's say we have some more red points down here.",
            "No, we can try Steam to draw a line, but you see.",
            "So maybe for some blue ones we make a mistake.",
            "For some relevance, make a mistake if you try to put a lien on and hear what we can do is increase the complexity of the model.",
            "So we can say instead of a line where it can be.",
            "Sorry.",
            "Compared to put the appointment of 2nd degrees or Parabola Tweet and we see that in this one it's doing better already.",
            "The complexity of it more as well.",
            "So you develop internally and then you see OK. Now if you draw this kind of a semicircle around this point it.",
            "In particular, whether this model in general as well, it's hard to tell this case 'cause it's a.",
            "We made it quite complex already.",
            "What would the predictions here?",
            "So everything that is covered?",
            "What kind of white should be read?",
            "Everything that is dark grey.",
            "It should be blue.",
            "So disappointed here we would predict it blue and here on the edge.",
            "It's kind of on the edge and then you can either tell maybe here it's feeling blue but less confident blue here and still have not been responsive.",
            "Interest just kind of so this would be kind of very anecdotal view of.",
            "With machine learning algorithms do."
        ],
        [
            "You know what are the standard problems that we typically solve in machine learning approaches, so there are few classes will mostly focus on the first one first 2 classes, so one class is called supervised learning.",
            "So the idea here is we're given inputs.",
            "Plus we are also given the outputs the desired output.",
            "So example would be.",
            "I work in a label easy to person or not a person.",
            "It could be example would be a tweet and a sentiment of that week.",
            "So we already tell the machine.",
            "But do we want to the output and now the task is just to figure out the best possible function to get this output.",
            "The second class is called a supervised and unsupervised means that we don't really have any output labels, so it's up to.",
            "Are there whoever is applying machine learning to know what he's doing and see what can he get out?",
            "The typical goal would be here too.",
            "We want to extract, detect some patterns that we cluster input.",
            "Follow this and we'll see some concrete examples of this that another class would be reinforcement learning so they won't be touching this.",
            "The idea here is that we have a program that is not given up from the input data and output data, but its position in some more dynamical environment.",
            "And it's adjusting the model that it's interacting with environment and this alcohol was so this.",
            "Using an example of reinforcement learning using neural networks for example, and then there are some kind of grey areas or not that the semi supervised where we are working with the both labeled and unlabeled data and typically the idea is we are giving a bit of flavor data, lots of unlabeled data can be better than just working with the label.",
            "Data directly induces an examples for that as well."
        ],
        [
            "So first supervised learning.",
            "So what's the kind of prototypical example we have training data we have inputs for this will be their access and the expected outputs.",
            "That would be wise.",
            "Again, pairs of a set of this kind of pairs and the goal is given these pairs, find a function that can measure given input to the desired output.",
            "And then we have a couple of tasks, so this couldn't.",
            "Breakdown into different types of functions presented in classification.",
            "The output space would be a set of small set of discrete values.",
            "In regression we are projecting into space in the ranking.",
            "The goal is to identify best possible order of the input data."
        ],
        [
            "So let's fication here.",
            "Why is appealing settle any special case where we have only two like you saw before random blue people it positive or negative?",
            "It's called binary classification.",
            "So then we just have pairs, but it is the input so that week and out is the sum is either plus or minus other positive sentiment, for example, or negative sentiment.",
            "Functions of the map.",
            "You could store plus or minus and we call this function on binary classifier.",
            "Computer for example.",
            "So we have a red points.",
            "We have blue points.",
            "And the binary classifier basically some boundary splitting our input space into into a half into tool to grasp."
        ],
        [
            "If you have more than two labels.",
            "So then it's for Utah.",
            "Typically will be multiclass.",
            "Problem for this means that output weaken, the output is one of K, brings only one and this can be either.",
            "We can convert it to several binary problems so we can have a separate classifier for each of the K states, separate binary classifier and then pick the value of the most confident one we can have one versus one, so we could have for each pair of output value, train a binary classifier and then the label that has the most votes.",
            "Means and some problems at logistics regression, multinomial logistic regression, correcting paragraphs or multiclass problems?",
            "But it's a design.",
            "It's good to keep this distinction between binary classification and multiclass classification, because binary is really a special special case that can be just that.",
            "Many problems can be translated."
        ],
        [
            "So send them any problems can be translated to binary classification.",
            "Another case would be multi label.",
            "So here we are assigning multiple labels to one instance.",
            "Example of this would be for example topic classification.",
            "We have a document in the document, could talk about sports tennis will be games, so we have multiple levels and how to do this with binary classification.",
            "So we'll just have to train a classifier for each of the labels.",
            "And then given a new document called, Run.",
            "For the binary classifiers and assign it all the labels which are binary classifiers.",
            "And we can also use it store.",
            "Lewis called the Structured output prediction, so then the output is not.",
            "Simple structure like value from a set.",
            "Here are subset, but maybe the output is 3 or something more complex.",
            "We can again translate it to a binary classification problem."
        ],
        [
            "Some examples document station, so we have an article, so it's in our case will be documents analyzer.",
            "Output space would be topics and technology, sports entertainment is wrong and what we want is a function that can map out.",
            "Documentum is after me too.",
            "What about topics?"
        ],
        [
            "Another example is sentiment analysis, so here we have two tweets.",
            "So the input, so the expense would be other University fees, and the output would be.",
            "Space two classes, positive, negative or neutral.",
            "And there are two examples.",
            "So first 20 angry about care segment like this.",
            "The classifier."
        ],
        [
            "Another example would be object detection.",
            "Or do we just?",
            "Image and the goal is to identify all the areas in the image and give them that have a bit correspond to some object in our database is here we have a bike.",
            "Here we have a person and all together you would kind of person on the bike.",
            "Classification problem."
        ],
        [
            "Another party later, but different problem with beauty creation.",
            "So here we are mapping from our your output space would be real numbers.",
            "Exam."
        ],
        [
            "Let's say I would input data is the how well a student is doing the high school output data is covered.",
            "The student is doing the University and then can we predict from his high school grades can predict how it will be doing at University?",
            "Again, regression problem.",
            "So we're predicting the number."
        ],
        [
            "Would be.",
            "Probability of default.",
            "So this is a lot.",
            "Risk management you want to secure?",
            "Working because different companies you might want to maybe compute the risk of individual company spelling.",
            "This is called probability of default.",
            "And again here input is the company or company described by some parameters and the output is hearing some country actually and the output would be the likelihood that the country will not be able to replace some of its levels in real time.",
            "And again the output is a number, so we can include it as a regulation."
        ],
        [
            "Another problem would be that supervised problem is ranking.",
            "So here the idea is we are given a set of objects.",
            "X1 to XN, maybe a very as well, and what we want to do is find give back unordered set of items and the training data can be provided either pointwise so that we can have a set of items and preach item in which position should it be?",
            "But it can be, which is typically easier.",
            "It can be paralyzed saying that this article should be ranked higher than this.",
            "For example."
        ],
        [
            "If you go to Google search for Dubrovnik.",
            "There are empty 8 million pages at the back.",
            "We get to decide which ones to put to the top, and it doesn't have by ranking function and just means that this.",
            "The eventual technique was scored the highest by this ranking function.",
            "No help with the one train is so well together.",
            "Drink water for this, so if you just observing but people are clicking so after somebody's back super quick and then clicks on a Lonely Planet, that's some signal so it doesn't Lonely Planet page should be ranked.",
            "Maybe at this particular should be rent.",
            "About the Wikipedia page, maybe you can tell us something about this one that it's only benefit page should be named above.",
            "Maybe we don't know.",
            "Plus maybe the user stopped reading here so the signal protected the lower and then by assembling many of these kinds of training person you can train a ranking function under example Dolphins.",
            "So that's a dolphin.",
            "The top ranking is a GameCube simulator.",
            "Followed by the animal again.",
            "How to decide which which one first, which is the ranking function?"
        ],
        [
            "Another ranking problem for probably pick and sticking to ranking would be recommendation.",
            "Or in this case is a user accommodation, so you're using is leading this article.",
            "Can be comment.",
            "Looking for articles.",
            "And this.",
            "The four articles will typically be so we have a pool of particles theory, commanding articles from the last day last week.",
            "Last year what are the top four arrancar Pickles?",
            "Weather input?",
            "Harry is the user context, so he's reading this article here, at least in the session here.",
            "At least in his history.",
            "Again, this is kind of.",
            "And then if somebody if you will go and click this we can say OK, so this this article should be ranked higher than these three when you're training and we handle through usage, generate more training data.",
            "So this would be examples of.",
            "Supervise."
        ],
        [
            "Supervised so here we just get the examples input data, but we don't really have any.",
            "Any guidance on the output?",
            "And what can we do in this case?",
            "Is an issue because of tasks would be like clustering, anomaly detection, emotionality reductions."
        ],
        [
            "Number one so class clustering.",
            "So clustering is.",
            "One of our standard flow classification and clustering.",
            "We wanna be standard over tools in the machine learning toolbox.",
            "Full of clustering, so we're given a bunch of objects we want to identify some groups of objects that are still share some characteristics that is different given by some similarity function.",
            "So that means if you have a you see some objects would be this points.",
            "Here we would like to say that the ones that are closer to each other maybe shared, should belong to the same group, where there is another not so close to each other should not belong in the same group.",
            "You can see that here.",
            "From party blocks and we would want our clustering algorithm to figure up to these two blocks.",
            "Now one thing that is very important it is that this pretty much depends on the similarity measure that you give it.",
            "So the similarity measure is the distance.",
            "Then it will say OK if you would be able to capture this.",
            "If you imagine that you project all these data, the white exist, then the distance on the Y axis doesn't really tell us anything about these two clusters, and in that sense it's.",
            "And one thing because of this is also it's like nontrivial to do a proper evaluation of two different clustering approaches, and it's very much.",
            "So any?"
        ],
        [
            "Use optical, so let's say we have a stream of.",
            "All or most of the news articles published in in some period of time.",
            "Well, if you would cluster similar articles together, what we get is handled events.",
            "So.",
            "So clustering one day of news, this would be kind of top events and you considered so Trump says something has 2000 capitals Galaxy Note 7, exploding his thousand particles and so on.",
            "So these are all the articles that were talking about Samsung Galaxy Note 7 for some aspect of it.",
            "The study or together and we were not seem that enough to something else.",
            "Some other classes.",
            "And if you look inside, we see the connected lots of kind of similar articles talking about the same topic, and this is the similarity.",
            "For example, this clustering algorithm was using.",
            "So putting articles about same entities and topics together.",
            "Another one."
        ],
        [
            "Supervised another area for supervised methods would be anomaly detection.",
            "So here they used to identify event.",
            "So there is a stream of events of observations and we want to identify when observation event is not.",
            "Does not conform to something that is expected.",
            "It's good to know that anomaly is a very domain specific term.",
            "Presently, if you have this again, so who is missing here?",
            "Kind of a bad thing there is.",
            "If you have an earthquake.",
            "Not missing here would be a good thing.",
            "So very we have to visit.",
            "You have to make taking this domain into account."
        ],
        [
            "How we usually deal with the density?",
            "That would be the anomaly detection.",
            "So one standard of ways to eventu.",
            "Big kind of density so that the estimated distribution and agree and then of the space of all the observations sending a new observational demand falls into low likelihood space.",
            "Then we say, OK, let's anomaly, and these are some examples of clearest neighbors.",
            "Would be nice for one class SVM.",
            "So before we're looking at this, we were trying to speed this space in half.",
            "Now here we have a bunch of points we're not trying to see the space in half, but.",
            "We have three branches, be the spacing help, but we're splitting it in a way so we have all the points in months and our space should be as small as possible, so that's kind of different things and everything that should be outside another point that belongs clearly says Anomaly.",
            "It belongs here this way, but that's expected.",
            "Clustering could be used for that as well so.",
            "Another"
        ],
        [
            "Radio 4 infection.",
            "There is two different given some car dimensional data and we would like to identify a couple of real dimensional couple of dimensions.",
            "For.",
            "That's still capture the most information is data, but as most information mean, every principal component analysis is 1 standard approach, but they're most information.",
            "It mean capturing the most varieties of the data.",
            "So power data would be in a crowd like this.",
            "They would say, OK, this is the most important dimension because it has the most variety along.",
            "Another approach to this would be similar in composition.",
            "There we are trying to find a low rank matrix.",
            "It approximates the data.",
            "Correlation analysis for multiple data."
        ],
        [
            "Another another this is related to anomaly detection in some way, whether unsupervised area between exit estimation.",
            "So here again we're doing a bunch of formulation and ideas can be estimated.",
            "The density function of this.",
            "In the last one."
        ],
        [
            "We are out in quarters.",
            "So here this is using a neural network artificial neural network and the idea here is that we have our input.",
            "This is what we're given and we say our inputs should approximately correspond to what the input.",
            "But we try to squeeze it through some kind of low dimensional representation.",
            "And this is useful either.",
            "Exclamation, so visualization.",
            "So if you want high dimensional data and you want to put it on the monitor, then we have to put it in somehow into D and then getting here for points to do.",
            "It means that we have now haptics and why and you can say OK, Now we can flood escape the later on the screen.",
            "Other thing is unsupervised feature learning and this is now especially for the image.",
            "Image sure computer vision, so sending lots of images or little parts of images through this and see what they're kind of.",
            "The prototypical things that.",
            "Gets built in cities or other features."
        ],
        [
            "Now one class of.",
            "Yet another class of problems that lies in the boundary would be.",
            "The idea here is we are we have some label data, but we also have access to lots of unlabeled data.",
            "So sometimes this is something this is the case sometimes not.",
            "For example, if you have lots of documents but it's very expensive to label the documents and you would get 100 documents table and have a million documents in the site so we can use this to use this unlabeled documents to better get the feel of the space.",
            "There must be a venture.",
            "Much would be the ones that they are not able to.",
            "Once with this one is would be marked as labeled.",
            "We could see this kind of distribution that is underlying the data from this unlabeled documents, and it's easy to say maybe for this one.",
            "Let's say this green picture.",
            "It's a screen.",
            "This one is red, whereas if you wouldn't care if you wouldn't have this language once the model would probably be quite distant.",
            "This approach is usually called transduction."
        ],
        [
            "Another nice one is active learning.",
            "Useful technique, so the idea here is we are given with a.",
            "And we have access to our expert that can label a document.",
            "Now the question is so we don't have enough money for the expert to label all the data set.",
            "Can we select some small subset that would be optimal for the task we are trying to accomplish some classification?",
            "Jesus Christ."
        ],
        [
            "So let's see there.",
            "We have a data set of companies which company is described by something some features.",
            "And we want to train a classifier between detect financial companies.",
            "So this would be the ones here and we had somebody went down, provided some examples and Barclays.",
            "This is Goldman Sachs or financial companies.",
            "Apple is not a financial company, General Motor Sport or not.",
            "And then these other ones.",
            "We don't really know and now we would run the model like we did before by clicking by do you run this demo before and we get this kind of line saying OK, these are these are.",
            "Company.",
            "Actually this is.",
            "And then we select and then we algorithms goes and says OK, Apple is efinancial company or not and the user says no.",
            "The label in blue.",
            "Anything around the\nOut the line is a bit higher then the algorithm says.",
            "What about Microsoft?",
            "Microsoft Financial company.",
            "And the expert says no.",
            "We are here and we saw that stopping from these two and these two companies and asking fewer there.",
            "Now we slowly converge to open Mark Citigroup.",
            "This one you're slowly converging to the good place and the way we were selecting this user algorithms away for selecting which company to label.",
            "It was mostly on how close it is to the decision boundary, meaning how uncertain the model is about where to put it.",
            "And the intuition goes, if we can label this uncertain elements, and so we are introducing certainty in the system.",
            "In helping the model.",
            "So this would be kind of there.",
            "Function right?",
            "That's already, how would you do that if you know what I mean, you could have whatever is going on distribution or something.",
            "Yeah, yeah strange.",
            "I'm just wondering how you combine that with model selection for each model that candidates can do active learning.",
            "You could run, so depending you could run it with different model parameters in parallel.",
            "Can you different model parameters to select the?",
            "Think not think maybe for not on the level of.",
            "Because people do it sometimes for optimizing kind of learning for this, regularization parameters model selection, I think is already kind of.",
            "Also, lots of approaches depend on the explicit model being used, so here we are allowing a model big align some degree curve decision tree would be not really have the same effect.",
            "In this case we have optimized."
        ],
        [
            "So we went to different.",
            "Examples of different problems that we can that people are solving.",
            "Surely there are many more so, but this is just a scratch the surface and now we'll go kind of through the pipeline how to how starting to feel a bunch of data, how to get to a working model.",
            "So the first thing is data representation.",
            "So if you are giving the text and the algorithm expects a lectern input, how do we go from one to the other one example?",
            "So what we should data points are typically represented by features or attributes, so it's just called.",
            "Whenever I say pictures, I mean some.",
            "Parameters and one you related to the example.",
            "Is it?",
            "Is it exact representation?",
            "Depends on open the algorithm.",
            "So if you're working with decision trees then they work with the individual attributes and distinguish between continuous and discrete attributes.",
            "For example, if you work with the linear models like logistic, regression, SVM.",
            "They work with vectors for most directors there, so we have to get our data to something that we can encode into as a point in a vector space.",
            "Then there are approaches that only require similarity measure.",
            "So given to data points we don't need it's representation.",
            "You just need to tell how similar they are some degree.",
            "Methods for example.",
            "And then also.",
            "Actually learning representation.",
            "So if you start with words indeed figure out their vector representation can be learned from the data itself."
        ],
        [
            "So under standard example that will be using like the House in the account of camera.",
            "Amazon Session is text presentation and a vector space model would be one of the standard representations and the idea of vector space model.",
            "So we take document and we first identify all the unique words that occur in this document.",
            "Or in the purpose of the documents, and then each word becomes one dimension.",
            "Example later and then for the individual document.",
            "So it's a vector in this space which which each word corresponding to.",
            "And then you see the value in that dimension is 1, but the network of course if the document is there otherwise.",
            "So this can be more complicated, so you can use different rates, but this is a basic level.",
            "We're just for a document saying those are the current feature or not."
        ],
        [
            "So here we have 3.",
            "We have three documents.",
            "But my turned off the two documents tricks without my phone 2, three and here are a couple of thoughts that I slept from these documents for.",
            "There are many more, so this typically working with vector space model.",
            "You're quite early.",
            "Get to hundreds of thousands of dimensions, so whatever algorithm using they have to be able to copy that.",
            "Then we have we think, OK, the first words we say Angela and we see it appears in all the documents.",
            "Now we can do also called engrams.",
            "So obviously is bigram so frequently Co occurring words that occur together, and this kind of allows us to extract decreases as well.",
            "Brexit occurs in the first one.",
            "You don't need a second and the problem is you want and now at the end if you need.",
            "If you have three vectors and now if you compare the distance between these factors we can see how all this on some level, usually more topical level.",
            "How similar we are.",
            "So the distance between these large dimensional data points which we don't measure.",
            "Video preview and distance, but you measured it causing distance, which is kind of.",
            "Normalize these vectors and then check the angle between them, is this?",
            "Kind of compensates for the length of the document, so it's easier also to compare short and long documents."
        ],
        [
            "Now there are a couple of.",
            "Or a couple of things that's good to know, so this this is disappointed that representation is also called bag of words back in a sense that we take all the words of the document and we threw them in.",
            "We disregard the order, but most often we would also count how many times individual work occurs, so it's not always 10 or something, it's like.",
            "There are different ways how to actually compute the weights in the world, so it's not obvious that one is the best or surely surely it's not the best way.",
            "So how for a different word, for example?"
        ],
        [
            "He's great, he's comparing Brexit position.",
            "Which one is more important in our representation?",
            "This would often depend on the data set.",
            "So if and what are the topics?",
            "It doesn't appear weak."
        ],
        [
            "Problem can be stopped once you can have both good or other filler words that are hard to that could occur often include make.",
            "Documents look seem that even though they don't really share any kind of more important words.",
            "So one simple way is just to ignore this promising and fixed set of common words.",
            "And The thing is, if you have words of different forms of banks, banking, stuff like that, we would all want to normalize it tomorrow.",
            "Thank you.",
            "Can use understanding organization for this kind of cutting the ending.",
            "M Hayden nationality.",
            "So for a large corpus you can easily end up with millions of words and not easy way of dealing with this is using hashing trick where we don't actually remember.",
            "We don't say we don't assign.",
            "We from each quarter computer cash.",
            "And then we divide this cash order some 100,000 and what we get out is actually our dimension.",
            "So this kind of gives us kibitzers to 100,000 dimension.",
            "For example it's another week and also the likelihood of distorting.",
            "Do not remember that is very low.",
            "And, uh."
        ],
        [
            "Approach that we can do is actually learn the presentation.",
            "Another so just to be here is, so this is this vote to make.",
            "And the idea here is can be in given words and how they Co occur, how they recording documents, which one, what is a Co occur?",
            "It can be identify end dimensional vectors so that words that occur in similar context.",
            "So words that have investment and stuff around it would be.",
            "Close in space.",
            "And we can see if you do that for this.",
            "Once examples we have animals in them some ports and would be closer to each other than others.",
            "So this is a."
        ],
        [
            "Another modality of data attack of data would be time seriously here very given measurements.",
            "Series of data points in time order.",
            "So for example, temperature readings once per day or once per hour that I've been greetings here we have number of airline passengers per year or different stuff.",
            "And if you want to do some example regression on this or some classification on this, we would also want to represent or let's say here, here.",
            "We want to make some decision of how the things we draw, but are the features that we should use and then we have some.",
            "You can complete surrender statistics, mean deviation so on.",
            "We can use time delay embedding.",
            "So just use last N values either overtime series or any of these features.",
            "Or we can also.",
            "Transport the time series into some frequency domain, for example, extracted features from there.",
            "But the important thing here is that depending on the data that we get to each data packet have some specifics that it's good to know before he started crying or doing anything.",
            "On top of that."
        ],
        [
            "So so much for that presentation.",
            "So.",
            "Model is working, machine is kind of the output of the training program.",
            "So we can put it specification for example, so it's a function function function, right?",
            "I'm not.",
            "We have different types of models, with some others can be just discriminative so that we saw before the number example is line and that model hotel is something on one side or the other, but it didn't really tell us much more about the data.",
            "You can have generative models, but from the model we can go out and actually generate examples that look very much like our data set.",
            "Alien.",
            "So which model we want also depends on the task.",
            "It's mark."
        ],
        [
            "Have we got a couple of super models and how they look like for the most one of the most common models is a linear model, so it's very simple, so we have a linear function.",
            "We take the features.",
            "We multiply the feature vector with some.",
            "And we get it prediction.",
            "Then if you specification we can check that maybe the sign of the prediction to say it's a positive or negative, but that's it.",
            "In the end, we are searching for the linear model.",
            "What we are searching for is basically the parameter vector W. When they can be off, they are kind of nice and easy behaved.",
            "Yeah, typically on expanding not so expensive to train.",
            "Most prediction is quite fast, so just the number will never compile in the number of features that we have nausea features.",
            "Probably.",
            "They can't get you not enough veterans.",
            "And here we see examples.",
            "We have house size and price later and it's not really noticeable relationship.",
            "So it goes kind of like this and if you want to if you go try to fit it with the line it kind of fits but not really.",
            "She tried to put a rubber tree kind of looks better already if you fit a polynomial of degree 6 St we can hit each point exactly but I think looking at this time everybody would agree that it's probably.",
            "It doesn't generalize building other data, and this is what we call overthinking, and we do that."
        ],
        [
            "Geometric interpretation of classifier.",
            "It's basically the W vector would be a normal of these hyperplanes.",
            "That is dividing the positive and negative straight.",
            "This would be."
        ],
        [
            "Their position is that we have a support each feature to get away.",
            "Positive features vote for a positive plus negative features.",
            "Features for negative class.",
            "We sent them altogether remove to platter features from them up together and we see the final both conclusion.",
            "Larger debates, typically stronger divorce, also depending on the picture size, but that's kind of the interpretation and we will see later in the hands of 1 computers entities.",
            "No."
        ],
        [
            "How can we increase the?",
            "How can we get more fixed?",
            "With a bit more complex data, so we can't really do believe that model for efficient approaches, one would be kernel methods, so there is a bunch of algorithms where that can be written in a way that you only interact with the data points throughout the DOT product.",
            "And these dogs properties, typically called our kernel and the story behind it goes the following.",
            "So have a some mapping.",
            "It takes data from other input space in Maps into some high dimensional space, can be high in a sense of loss of dimension, number of dimension.",
            "And if you can, you can compute dot product in there.",
            "Without explicitly mapping the data for this other space and then this will be called.",
            "And the intuition behind his death.",
            "In one way we are doing our learning problem in a much higher dimensional space.",
            "So what's linear Del sooner up there is not linear.",
            "Once we projected the decision now.",
            "Thank you some examples.",
            "So let's say we have a.",
            "Well this would be negative positive class.",
            "I believe that model would go like this.",
            "Now if you use a polynomial kernel.",
            "So this is what you are drinking the example before the 2nd degree we got this kind of problem.",
            "Use degree treat regarding a more complex so the higher the degree, the more complicated the water can be and basically this line here is a.",
            "Actually are.",
            "The state line, but in some higher dimensional space or not to do dimensionally, but in some foreign Nationals.",
            "If you look if you try to write it down."
        ],
        [
            "So this would be there.",
            "So what we do is take the.",
            "We have two elements X&Y and we want to compete with the DOT product between them so we still do the DOT product between them, but we.",
            "Would that be greedy?",
            "And if you go down and help, right, right, right it out.",
            "So let's say we have a our feature space just so we have two dimensions.",
            "Our degree of the polynomial kernel is 2 and C would be once this constant factor.",
            "So what happens?",
            "So we have these two vectors.",
            "We write them down, so we have a basically.",
            "Exactly, so the dot product plus one.",
            "Now this is an equation data and then we go down.",
            "We modified.",
            "We get this wrong thing here and we can try to break it apart and write it again as a two individual vectors.",
            "But one has only elements from XML.",
            "He's only elements provide.",
            "We can see that.",
            "Actually this corresponds to.",
            "Don't product enough 123456 dimensional space.",
            "This not State Bank before."
        ],
        [
            "So this curve is actually projection of straight line from 6 dimensional space down here and that is nice."
        ],
        [
            "See that.",
            "So that we have two pictures.",
            "So linear model can't capture interaction, so it can always feature one is active or not.",
            "Feature two is one or zero, for example as well.",
            "But linear model can say is feature one or two 10?",
            "Or is they're both positive?",
            "For example there is.",
            "Here you see we have a product X 1 * X Two.",
            "So through just by going through this kernel, methods for this polynomial kernel, we are able to capture the signal.",
            "So this interaction this file.",
            "Paralyzing connections between features.",
            "Now if we increase the degree then we get the interaction between 3 features variance one.",
            "In the extreme."
        ],
        [
            "We can go to the cabin Ocean kernel very basically mapped infinite dimensional space in the capture or possible interactions.",
            "Describe complex.",
            "Again here.",
            "It's very easy to overfit now."
        ],
        [
            "Another way of dealing with this will help increase the capacity would be going through supplying the artificial neural effort.",
            "And, uh.",
            "Or this is an example of neural network, but we're basically trying to do is an approximate the function, so like.",
            "Other approaches, but we use network coding.",
            "So here you have nodes.",
            "Notes, notes, notes for everything in between, and.",
            "These are called neurons.",
            "So one note can depend on more.",
            "One of the more inputs and they can send the signal outdoor one more outlets and each each architecture of the network would be how are basically this topology of the graph.",
            "And then also there, but we've kept it specifies that activation, so lot of the functions.",
            "And how does this note here?",
            "How does it take that list to the inputs?",
            "And how does it integrate them together?"
        ],
        [
            "This would be with their project right?",
            "So here we have a supervised approach, so the output will be presented, classes or aggression.",
            "Must have at least three layers.",
            "You could layer output layer at least one hidden layer.",
            "Activation functions can be either linear, so after you take the outputs and you multiply them with a linear function, we get the value or it can be nonlinear optical.",
            "Take that input and send it for some nonlinear function sigmoid or something like that.",
            "And we can do because if you have to go to outlook, you can use something for the softmax, skip now.",
            "Skip this, go to the demo."
        ],
        [
            "This one is a playground.",
            "Tensorflow don't work.",
            "Want to play so once we do here we select the training data.",
            "So let's start with something simple.",
            "Then you select whether our features so features will be Hicks one and X2.",
            "So basically we have two coordinates.",
            "And we don't give any hidden layers for start and that means that output is just a linear combination of these two guys if we start.",
            "We'll end up with that.",
            "Now we go for something more complex.",
            "Also this is.",
            "Maybe it would be better.",
            "Yes, you do not seem right.",
            "Yeah, just.",
            "It's more right.",
            "So we see there are blue points.",
            "It's kind of a check chess board like.",
            "And if you try to pick the line for Secondry is everything's trying.",
            "I mean the the model doesn't have the capacity to capture this now.",
            "One simple thing would be you can increase the features so if you add a product feature so that at least some before that this polynomial of 2nd degree would already include.",
            "So if we add one more feature so the product of fixed right.",
            "Here we get up.",
            "Get perfect terms classification.",
            "But this is a this was a.",
            "Basically you are messing up the inputs, so we're kind of in the future engineer.",
            "And you know how to compensate this with a more structured ways.",
            "Using for this kernel methods that we saw before, but another option since we have a neural network here.",
            "Another way of dealing with the nonlinearities introduced this linear layers.",
            "So now we have this goalkeeper features that get mapped into the intermediary values that then get mapped into the classification.",
            "Now we feel like this.",
            "We have only two neurons, limited trying.",
            "It's doing something so I can see it before I get more complex, so most of the blue on blue most of the orange are orange.",
            "Sacrificed.",
            "Life increase the capacity.",
            "Free.",
            "Is not.",
            "At 4:00 components kind of stock ticker.",
            "Starting to bend.",
            "It's struggling, but it's kind of something is happening at another layer.",
            "Explain the learning curve so this is a.",
            "Two parameters, so distortion training loss.",
            "So we can you know that.",
            "So the idea here is the.",
            "Applying the model of this points and training last week, how well are we doing from the training data?",
            "So if you're not doing that in the training data, then proposal under fell on the other data.",
            "If you're doing well on the training data doesn't mean that we will do well on the other data 'cause we might be overheating.",
            "Freeze.",
            "Welcome home.",
            "Good point if it starts to repeat.",
            "Do you have an accent?",
            "Do you have any information or what is happening happening in the Community players?",
            "So this is the the if you just use this feature of the classifier, you will kind of.",
            "It captures this kind of signal.",
            "Then as you're learning you can see that this one basically now also added his serious kind of does.",
            "He's doing this prediction.",
            "This one is doing kind of complementary and then did not get refined here and then kind of summed up together, but it's.",
            "There's lots of.",
            "So this is these are simple examples here, so it's you know it's easy to experiment.",
            "So when you get a bigger system, you really need to spend some time to get also the learning parameter, right and everything.",
            "And is adding features, so adding the number of layers.",
            "So now look like.",
            "So how is the number of layers then?",
            "I'm bout know that they didn't layers and the teachers is just trying to find out if I know.",
            "I mean, you can see Kappa some.",
            "For some problems you have a bad, understood architectures that you could even use.",
            "So what is secure signing?",
            "Something that is not?",
            "It wasn't done with these dynamics, you're with lots of experimentation in your future, so it's not like this that you are doing it and then you are getting inside what is happening in this hidden layer.",
            "So you get we will ever get an intuition of what we were.",
            "For example, if you are.",
            "Bismarck motor"
        ],
        [
            "So this is a neural network for solving the problem we were doing in the motivation.",
            "So this name entity recognition, for example, uses exactly so it has a.",
            "It starts with the word on.",
            "It takes its context and it first Maps them into.",
            "Each word is mapped into 50 dimensional vector for example.",
            "Then it is good transformation and then again the softmax to figure out the class.",
            "Now for this, if you look at this later segment after you run documents for awhile, look at this vector.",
            "Then it turns out that words that are similar by some connected similar class would have vectors that are closer together than words that are not in the same class.",
            "But this is something that is very specific to this kind of architecture.",
            "If you have some different things, there are some different wiring.",
            "Then again, you would have to go down and check what exactly it means, whereas for this lower layers it's hard to.",
            "Maybe with lots of handwaving there lots of effort you could figure out, maybe some meetings, but it's very hard to understand what's happening there.",
            "Networks with dancer players and it gets more or less impossible.",
            "We can do visualizations for example like this or before an outing, whether if you have an image problem then you can see how this image is broken into simple features and then each layer would kind of capture capture with more complex features.",
            "But again, we see images.",
            "You can visualize some degree crucifying reversing back to the image or text is a bit harder already cause.",
            "It's hard to get from.",
            "Metrics question text document, so it's.",
            "It's a large degree to black folks.",
            "And also it can be so can be also quite the month.",
            "Side effects are very good performance other side and can help out everybody which classification we have.",
            "Some examples when you take the image you just slightly distorted so you wouldn't even notice the difference and it will be classified in a completely different class.",
            "And vice versa, I can give you some which looks more like like random noise to you and you would classify it in it.",
            "Look like it was classified into some quick class just because this intermediary layers are hard to prove.",
            "Is something going this is understanding during that time?",
            "Is 1 big coffee gonna just came from this CBD conference and flus topic, which is not really addressed, or it's unlocking here couple of races.",
            "What time is the black box?",
            "Which.",
            "Intermediate euros right?",
            "There are some kind of Lego pieces building blocks which.",
            "Allow people to do this or could be like the solution in a better way, but the question is.",
            "Alchemist and is building blocks.",
            "This label pieces so this is on here.",
            "And I'm sorry.",
            "Oh 13 case of images.",
            "Somehow we can see this some elements with text, some kind of compare things may be less clear, but.",
            "General instructions, and really there's no solution will.",
            "Community doesn't have any proprietary.",
            "Yes, please question.",
            "Canada.",
            "Hello.",
            "You can include the regulations or controlling your criteria so you want before in the examples.",
            "Here we had a good support at one or after regularization model or we have this early stopping for something that fits their things.",
            "Yeah, it's not not definition.",
            "I just wanted to check, for example using features exponent extremely revealing some variable values.",
            "Can you just show in one year what is the equation that represents one of the like probably the first Hinrichs.",
            "So just want to visualize it like Mathematica.",
            "Like instead of having so many features, if I just have two features, for example, it's an experience.",
            "These are just make up related to each feature or something, so can you just represent once mathematical?",
            "He wasn't one of those like running for student there here.",
            "Yes, so here.",
            "It could be.",
            "This is just.",
            "So linear function with some weights times X1 plus wait times X2 that extends to downloads capabilities.",
            "So this is kind of activations functions, so that would be.",
            "Example of like we have like maybe 1 hidden layer can be limited to hidden there just so gross when we.",
            "Each year we learn something and then we go to the next layer, right?",
            "What is the I mean, just one simple decoration?",
            "Probably that takes from the features in the sense that to the to the next leader.",
            "So just want to let the."
        ],
        [
            "For example.",
            "Let's say we have a one possible step from input to the hidden person.",
            "There would be have a metrics that takes this three element and outputs for element.",
            "So 3 by 4 matrix.",
            "While computing it, we need the weights of each of the training will give you.",
            "Is the Matrix A in this case for example.",
            "So this is what you're optimizing over.",
            "Well, this is fixed.",
            "The output is fixed.",
            "But you're optimizing.",
            "These are figure out out either the piece metrics A.",
            "Either that's it, yeah.",
            "They are random and then they are changed.",
            "Reminder.",
            "Yes.",
            "You can understand why random or you can have some.",
            "We have different different.",
            "These guys."
        ],
        [
            "You cannot.",
            "So it can hear we are solving limited recognition.",
            "We can solve a similar problem or similar problem problem for example this.",
            "Word two vec very does this, and then the task is to predict which work will be in the middle, and you can use the this layer for correct and plug it in here and use that as the starting point, and then you're already forward to back.",
            "It's much easier to generate lots of training data and from entities, and this is one way of how we can boost the performance, so not starting from random from something.",
            "Maybe could you explain the principle of black backdrop?",
            "This might be sort of.",
            "The loss.",
            "Maybe just one, maybe since you're short answer for already, can you show the evil example spiral?",
            "So here we want to separate threads thoughts from blocks, right?",
            "So you see, it's pretty unpleasant.",
            "With.",
            "These settings you won't be able to do much better.",
            "Could be stronger in prison.",
            "Still longer.",
            "At other features.",
            "The nondeterministic difference.",
            "And a few more layers actually is very.",
            "Very generous.",
            "So doesn't mean that when you do something on this you really do like this.",
            "You have feature your layers and then yeah, this is black magic.",
            "Well these people do.",
            "Puppy.",
            "Anyway.",
            "Which.",
            "Same here.",
            "It could be.",
            "I mean, there's very some you there or something.",
            "Busy.",
            "Then you get some feeling, but there's lots of craft in training.",
            "Switch back now.",
            "So I think I think here the problem is the debt is how you how you nonlinear, so you need hundreds of layers to order two previous necessarily at your stuff enough there.",
            "So the question was how many monkey are you try and so we can we can you can you can approximate any function with the neural network.",
            "Just question is how many letters from any?",
            "But also definitely trading deficit in order to function in this area.",
            "We need to look at this neural networks and not not something outside whatever blush was saying before.",
            "So whenever is just another function approximator.",
            "So fancy now, however, it does everything.",
            "Well, let's forget what we used to do and now this will solve at least once.",
            "I mean all the participants around your metrics are exactly the same.",
            "I mean, who had training testing an error?",
            "Little great, I mean all these terms are still there, right?",
            "We just we have different functional groups.",
            "So this may be both in line with your question.",
            "So how do we actually?"
        ],
        [
            "So now that we decided our model is this.",
            "Metrics are this vector or something.",
            "How do you find the best one?",
            "Another question first is what do you mean by fast?",
            "So we have kind of two parts.",
            "One, we would want the model to work put value on the training set so even some loss function measuring the error or something on the training set.",
            "We want to be as better good as possible and the other sense case we also found another way side both on the model to generalize well to unseen data.",
            "So if you have something that was not in the training set.",
            "The whole point was that we would also work well on that, and this is kind of two competing parts.",
            "Now they go through each of them."
        ],
        [
            "So first question is how to measure loss and with the general principle is we compare the model.",
            "With the expected outputs.",
            "So in our in the tensor flow before here this also, this points are expected outputs.",
            "The color debate is our output and now we want to describe this relationship.",
            "You want to describe this relationship.",
            "With some function that we can optimize over though.",
            "Preferably easily optimized and what your networks are doing is already is back propagation, so you can write all the equation down and do the stochastic gradient descent.",
            "And this is one of my other purchasing check from work here.",
            "So if you're doing this week."
        ],
        [
            "And how do we measure loss?",
            "So one straightforward, straightforward will say that.",
            "If our prediction is the same as the training data prediction, then we say it's good, so there's no.",
            "It's zero if the prediction is.",
            "If the if the difference of declassification says.",
            "So.",
            "Recover predictions is different than the training data size.",
            "Then you count 1.",
            "Now if we do that on the whole training data, we can write down into the equation.",
            "And then this is something that we can go down and putting some optimization software in the figure and it would spit out the best F for this loss.",
            "Another way of looking at this sheet so this hinge loss.",
            "So here we say either our.",
            "Our classifier is good and if it says if we take the output, it must be quite confident in the prediction as well as soon as it's not confident saying that it's not with the design of the function, but it has to be actually bigger than money for the confidence as soon as it's outside lower than this, we start applying penalty and the penalty linearly increase.",
            "The bigger the misclassification is.",
            "So this is called conditionals."
        ],
        [
            "Another way of looking at it is maximum likelihood, so we are given a training data.",
            "We have our model and then we can consider because ask ourself what's the likelihood of this data given this model?",
            "OK, so for our output for our training data, but is there a likelihood of disease classification with a flexible to the outputs?",
            "And the closer it is to the this is the training output, training input and the higher the likelihood of this is the happier we are.",
            "Again, we can write it down as a function.",
            "We can derive optimizing and so on so.",
            "For today.",
            "That's the general idea we want to capture the loss we want to capture the.",
            "Property of the model to work well on the training data, as some optimizable function.",
            "Then we optimize it by finding the most."
        ],
        [
            "Now the other problem is how do we ensure that we generalize well?",
            "So let's say we are.",
            "So before, so we likely to course.",
            "Might be good.",
            "Movie 6 is already obviously overheating and now with stand."
        ],
        [
            "Be kind of welcome razors so we would like to find the simplest model possible that still produces good result.",
            "Now the question is how to?",
            "How do we define a simple?"
        ],
        [
            "So this is we do usually by regularization, and regularization can be either.",
            "Not directly included in the optimization function.",
            "So in our case linear model, the norm of the vector, typically of the normal vector typically corresponds to the margin.",
            "So how it's positioned over with respect to the training data and the smaller the smaller the the normal, the larger the margin.",
            "So that's one way of shooting it.",
            "Your networks you also do.",
            "You will take your training data, take out a bit of a small set that you call validation, set and value optimizing on the training data and error will go down as we're getting more than one, we're approximately better and better.",
            "At some point the validation set, so the one that is.",
            "Part of the training set that is not used in the optimization.",
            "The error there will start to increase.",
            "Its OK if you got it here then maybe we have a very generalizable model.",
            "For example.",
            "Decision tree and then prune the branches to get a simpler model."
        ],
        [
            "Enough.",
            "Support vector machines, so because it's nicely German metric interpretation, so let's say we have a. Positives and negatives.",
            "There are many possible models we can lines that we can drop them between them now, which one will be preferred and one approach is to say we want the one that produces maximum margin.",
            "Now if you would put this link here then the margin so between the line and the nearest negative index positive example is quite small versus if you put the line like this it's quite the decryption.",
            "Now the task comes down to we want to find the plane that.",
            "First, it separates plus in using the maximum margin."
        ],
        [
            "Write this down.",
            "We get down to want to minimize the North of the model.",
            "Given that we are classifying correctly, but this is not typically not possible because we have noise.",
            "Assumes perfect supportability.",
            "And then you can say OK, relax.",
            "So we still want small normal, but we also small ones.",
            "One small loss.",
            "So this is this hinge loss before.",
            "If you put these two together you basically get.",
            "So much from the mother."
        ],
        [
            "Now the last part is how do we know we say?",
            "Be.",
            "But the data we representatives and how we train the model on it?",
            "How good are we doing so?",
            "There are three questions, kind of major questions we want to ask yourself.",
            "So what is?",
            "How do even tell?",
            "How would we drink?",
            "How can you be?",
            "But we will measure.",
            "Second question, how well do we have the model generalized?",
            "The last one is is it better than other models?",
            "So the last time goes in line with Canvas presented today."
        ],
        [
            "Or how to quantify model performance?",
            "So typically they would.",
            "If you kept up bunch of evaluation metrics for different types of problems.",
            "Depends on the problem.",
            "Also, transportation be measured differently than regression.",
            "And also depends a lot on the domain and what is actually cause.",
            "There have been some domains.",
            "We don't care if if we find more like positive examples, but really don't want to miss anybody some other domain.",
            "So different types of wrong answers called different amount of cost plus cost, different amount of money and maybe we would factor related according to this or how much money we are losing that we're making even the mother.",
            "So this is really specific and it's easy for a supervised it's easier models.",
            "Account created, nothing else where we are given explicit outputs that we want.",
            "Which might be noisy as soon as they're kind of high quality and it gets quite hard for unsupervised problems 'cause it's given to different clusterings.",
            "Traffic televisions better without some good.",
            "They're coming of age to qualify better."
        ],
        [
            "An example for binary classification, but we typically measure, so we have a prediction.",
            "We have the truth table and then we can each instance.",
            "Can be positioned into rolling stuff with the test set, which probably several 100, except it has to be simple.",
            "We check for each element from the test set, which are the prediction.",
            "We check the actual label and we see 2 positive means that they are.",
            "They both agree to negative means they go for grip on the negative class.",
            "Then you have false negative false positive which is kind of.",
            "The different types of mistake, and from this we can get to the kind of basic classification measure.",
            "So one is precision.",
            "Precision tells you from all the positive ones how T. Or are they.",
            "So how many of the massive positives are actually positives?",
            "Another one is very cold, so from all the positives, how many degree dentify?",
            "So these are kind of usually you get high precision but just classifying everything was negative was that it didn't make any any.",
            "Mistake, we just be very Conservative and Liberal.",
            "Few positive, but then it gets very lonely cold and vice versa.",
            "You can always label everything positive, having terrible precision and a very good report.",
            "And then one way of combining this is called F1 measure which is geometric mean."
        ],
        [
            "Another way of looking at the model models is this RC cards.",
            "So the idea here is that we computed two characteristics for each model, so one is this true positive rate which is a.",
            "So I know how many.",
            "So many positives to be fined and false positive rates is how many false negatives?",
            "How many negatives to be put in the politics classes very well?",
            "We did them.",
            "And if you.",
            "Optimal position would be here, and the random would be kind of District 2."
        ],
        [
            "And what is nice is if you have some lots of models and we have some confidence.",
            "Suppose we could take the predictions sorted by the office and scores and then slowly as we increase the threshold.",
            "Threshold for where we say something is positive.",
            "So we start here everything being zero, and so we jump up and go up there.",
            "And the better the model, the most deep discoveries.",
            "You cannot do this if your mother doesn't have the confidence right.",
            "Mother fucker.",
            "You just need to get some samples.",
            "Existing next weekend, something modern.",
            "Season 3"
        ],
        [
            "Progression.",
            "See, these are the measurements.",
            "This is the model rule.",
            "Check how far the much measurement is and then we have other means.",
            "Carrera should be some dispense with the user receivables control, confidence and determination which we do.",
            "That and it ends on which tells us how well they behaves."
        ],
        [
            "Now the question two was how well do we generalize?",
            "So for generalization, so one rule so that we have to be always very careful about never test from trimmings training data.",
            "This is conducive.",
            "It gives full sense, false sense of performance and the model.",
            "It doesn't tell you much, so it's always good to.",
            "Split if you have the training.",
            "A lot of Liberator disputed existing turning data in training and test parts.",
            "We train on the training part and then compute the valuation measures of the test part.",
            "And it's kind of sounds straightforward, but it's always.",
            "Holistic and always very easy.",
            "There's some information on the training data.",
            "Would look into the test.",
            "Set one up if you have a.",
            "Stream of particles newsarticles in time.",
            "And you would randomly split in training and test and then do topic classification of those.",
            "Then it's a bit unfair.",
            "It was maybe artikkel.",
            "We will use the model.",
            "In reality is you have the past data you train on and then you apply it in the future articles.",
            "So you have to do this time wise place of your entity or curse in the future.",
            "If you want to handle it fell around as well and this kind of random script will not work well.",
            "Also feature extraction is running, so you're doing the TF IDF for some weighting scheme on the documents.",
            "Do you want to do it only on the training set, not from the combination of everything, because it's so again here.",
            "So it's always good to another difficult rule of thumb.",
            "If you run your algorithm, you test it.",
            "You get a very good result.",
            "The first question should always be but very in-depth training data linking to the testing for the test data leading to the training process, so this is."
        ],
        [
            "And how do we get confidence about it so when easy way of obtaining multiple metrics from the same training data is to do something called cross validation?",
            "And the idea here is that we instead of doing last month train Pass Street, you can do many tenfold cost reductions on standard thing.",
            "And that's where you get more number of metrics is and then you can start doing some statistical tests and therefore significance significance and one extreme of that would be leave one out very quickly, take all the training data, remove an example training and test it on the one piece.",
            "One example.",
            "And you do this for each individual example for this can be quite possible."
        ],
        [
            "And now the last question is, is a trained model?",
            "Is it better than what the literature says about this type of problems?",
            "And typical approach would be so this goes in line against with statistics from before we have to models F1F2.",
            "Can you tell which is better?",
            "We compute valuation metrics on a different speeds of train test.",
            "And because the Hippocrates, do they have the same mean?",
            "This would be an example of the test.",
            "This permutation test channel showing before the thing would be, but the two sets drawn from the same distribution or not so.",
            "They have tested that and this is something that we can then say to models are statistically different.",
            "They produced super different output and one is better because it has a higher need for examples."
        ],
        [
            "That's it."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In the morning.",
                    "label": 0
                },
                {
                    "sent": "Over some probability and statistics and County ideas.",
                    "label": 0
                },
                {
                    "sent": "Some introduction to data science and what have we covered in our next.",
                    "label": 0
                },
                {
                    "sent": "His first.",
                    "label": 0
                },
                {
                    "sent": "What do we understand by machine learning?",
                    "label": 0
                },
                {
                    "sent": "Then go over some ideas over some problems that are typically solved machine learning and will be added.",
                    "label": 0
                },
                {
                    "sent": "Check couple of methods so hopefully by the end of this, however, we have a better understanding.",
                    "label": 0
                },
                {
                    "sent": "To use machine learning and what?",
                    "label": 1
                },
                {
                    "sent": "How to use it?",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Richard Pryor motivation.",
                    "label": 0
                },
                {
                    "sent": "So let's say we are given appropriate task to develop a program that enterprise all the persons in this Africa.",
                    "label": 1
                },
                {
                    "sent": "So this is one article you see, there's a stop talking about American Medical.",
                    "label": 0
                },
                {
                    "sent": "Theresa May now some other entities, but they're not personal, so maybe they are not what they want to cover.",
                    "label": 0
                },
                {
                    "sent": "You don't want identify.",
                    "label": 0
                },
                {
                    "sent": "Other question is how would one approach developing such a program?",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's say one way would be so OK we can.",
                    "label": 0
                },
                {
                    "sent": "Down open hours, dedicated understaffed.",
                    "label": 0
                },
                {
                    "sent": "OK let's say we have a list of common person language that sounds like a good way to start.",
                    "label": 1
                },
                {
                    "sent": "Identify all the all the words in the document that are from this list.",
                    "label": 0
                },
                {
                    "sent": "Maybe then add some rules.",
                    "label": 0
                },
                {
                    "sent": "So many rules checking as they were the leader capital character.",
                    "label": 1
                },
                {
                    "sent": "English people names usually start with capital characters.",
                    "label": 0
                },
                {
                    "sent": "Then we can also try to find some expressions.",
                    "label": 0
                },
                {
                    "sent": "Maybe it's written somewhere somebody said and people usually talk, so maybe somebody is also a person and so on.",
                    "label": 0
                },
                {
                    "sent": "So this is if you can go down and drive this route, but it's kind of tedious and it's.",
                    "label": 0
                },
                {
                    "sent": "Cards to this kind of brittle rules to comfort.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Nova.",
                    "label": 0
                },
                {
                    "sent": "Let's say that we would have a cap collection of hospitals already, so we're giving the big corpus and all the names people names are annotated in there.",
                    "label": 0
                },
                {
                    "sent": "Now the question is, can be trained a program from this kind of training it or something this labeled corpus?",
                    "label": 0
                },
                {
                    "sent": "Can we train a program that would recognize people?",
                    "label": 1
                },
                {
                    "sent": "And this is exactly what we do with machine learning approaches.",
                    "label": 1
                },
                {
                    "sent": "And in our example, how would that look like?",
                    "label": 0
                },
                {
                    "sent": "So first we have to we decided we do will go by label identifying putting towards this belong to a person name or not.",
                    "label": 0
                },
                {
                    "sent": "So we break the people commenting towards and describe each word by some characteristic.",
                    "label": 1
                },
                {
                    "sent": "So maybe everything that's on the previous slide could be used as one of the features.",
                    "label": 0
                },
                {
                    "sent": "But we don't really need to tell the system is it would feature bad features.",
                    "label": 0
                },
                {
                    "sent": "How does it interact with the others?",
                    "label": 0
                },
                {
                    "sent": "So example beyond the capital stop the capital character.",
                    "label": 0
                },
                {
                    "sent": "It's on the list of common names.",
                    "label": 1
                },
                {
                    "sent": "What are the words in the context?",
                    "label": 0
                },
                {
                    "sent": "Then we mark each work from our from our focus as a person for others.",
                    "label": 0
                },
                {
                    "sent": "So this is what our collection of African gives us.",
                    "label": 0
                },
                {
                    "sent": "And then we have a.",
                    "label": 0
                },
                {
                    "sent": "We take one of our one of the machine learning algorithms applied to this.",
                    "label": 0
                },
                {
                    "sent": "And we show each other this training data and outcomes the model.",
                    "label": 0
                },
                {
                    "sent": "And the model is basically a function that you give it to work and can tell is it a person or is it other.",
                    "label": 0
                },
                {
                    "sent": "But it's kind of very handily high level overview.",
                    "label": 0
                },
                {
                    "sent": "And but the main idea is instead of approaching the problem from starts or saying, how is a person, then trying to maybe figure out rules and so on.",
                    "label": 0
                },
                {
                    "sent": "We want to go for the other way.",
                    "label": 0
                },
                {
                    "sent": "Can we see a lot of annotated data and let this machine do the figuring out of the room you just provided the signal?",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So their features.",
                    "label": 0
                },
                {
                    "sent": "Now get out there.",
                    "label": 0
                },
                {
                    "sent": "So first we check with this machine learning.",
                    "label": 0
                },
                {
                    "sent": "Then they check the standard machine learning problems so but the different traffic controller problems surprised and supervising song.",
                    "label": 0
                },
                {
                    "sent": "Then we do a bit more into detail.",
                    "label": 0
                },
                {
                    "sent": "So how do we represent data?",
                    "label": 0
                },
                {
                    "sent": "What actually is a model of the presenter model?",
                    "label": 0
                },
                {
                    "sent": "How to fit a model?",
                    "label": 1
                },
                {
                    "sent": "It's a good model and then how to evaluate?",
                    "label": 0
                },
                {
                    "sent": "So how good are we doing?",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Course that is.",
                    "label": 0
                },
                {
                    "sent": "Of course, the polling says subfield of computer science.",
                    "label": 1
                },
                {
                    "sent": "Nicole from.",
                    "label": 0
                },
                {
                    "sent": "When will the machine became machines become more powerful?",
                    "label": 0
                },
                {
                    "sent": "So it's kind of evolved from this pattern pattern recognition, computational learning theory, artificial intelligence, but nowadays it would be largely considered kind of a subfield of AI intelligence.",
                    "label": 1
                },
                {
                    "sent": "And this is an old boat from 59, so there are some summers at the field of study that gives computers the ability to learn without being explicitly programmed so.",
                    "label": 1
                },
                {
                    "sent": "We give means of computer code, so we give it to material material to learn from.",
                    "label": 1
                },
                {
                    "sent": "They give it kind of approaches for learning from this material and then we let it go and hopefully the out we get a model.",
                    "label": 0
                },
                {
                    "sent": "We get out the program that is better if you'd try to program incrementally.",
                    "label": 0
                },
                {
                    "sent": "And machine learning to work.",
                    "label": 1
                },
                {
                    "sent": "Most people working on machine learning, but they do.",
                    "label": 0
                },
                {
                    "sent": "They mostly remains.",
                    "label": 0
                },
                {
                    "sent": "The core task would be developing algorithms.",
                    "label": 0
                },
                {
                    "sent": "Efficient algorithm can learn models from.",
                    "label": 0
                },
                {
                    "sent": "Inefficient ways?",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is 1 slide from this year's Kennedy, so lots of things are kind of on the borderline between statistics and other science.",
                    "label": 0
                },
                {
                    "sent": "And then what was the machine learning considered a separate field or, heads?",
                    "label": 0
                },
                {
                    "sent": "Or this data science, especially with computer scientists are better than statisticians at marketing.",
                    "label": 0
                },
                {
                    "sent": "And it's not so.",
                    "label": 0
                },
                {
                    "sent": "This also the cloudless code.",
                    "label": 0
                },
                {
                    "sent": "But the data scientist do so.",
                    "label": 0
                },
                {
                    "sent": "It's kind of in between computer science and statistics.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Get out terminology so we'll be using couple of words throughout this talk.",
                    "label": 0
                },
                {
                    "sent": "Maybe just to get them down.",
                    "label": 0
                },
                {
                    "sent": "So first this training data.",
                    "label": 1
                },
                {
                    "sent": "So what we what we consider building data so it's the input data feed to the machine learning algorithm.",
                    "label": 1
                },
                {
                    "sent": "It can be labeled.",
                    "label": 0
                },
                {
                    "sent": "It can be unlabeled.",
                    "label": 0
                },
                {
                    "sent": "We see differences.",
                    "label": 0
                },
                {
                    "sent": "And one example of me, if you're doing sentiment classification, so we have a collection of tweets and preached, we say is it positive?",
                    "label": 0
                },
                {
                    "sent": "Is it negative?",
                    "label": 0
                },
                {
                    "sent": "Is it neutral sentiment?",
                    "label": 1
                },
                {
                    "sent": "And this this is kind of the training data.",
                    "label": 0
                },
                {
                    "sent": "So we want we want the machine to replicate.",
                    "label": 0
                },
                {
                    "sent": "So getting from a tree to sentiment label.",
                    "label": 0
                },
                {
                    "sent": "Then another victim is model, so that is a model.",
                    "label": 0
                },
                {
                    "sent": "Basically, can we look at it as a function that is kind of the writers using some machine learning algorithm and it takes the input data and produces the desired output.",
                    "label": 0
                },
                {
                    "sent": "So in that example the beginning input could be award out would be saying easy to a person, or is it not a person?",
                    "label": 0
                },
                {
                    "sent": "And what is it then?",
                    "label": 1
                },
                {
                    "sent": "The last word is prediction, so that is a prediction.",
                    "label": 0
                },
                {
                    "sent": "So if you take a data point, applying the model to get a prediction.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Quick demo.",
                    "label": 0
                },
                {
                    "sent": "So we had to switch.",
                    "label": 0
                },
                {
                    "sent": "Had been what we'll be doing is binary classification, which needed more details about it later.",
                    "label": 0
                },
                {
                    "sent": "But what is?",
                    "label": 0
                },
                {
                    "sent": "Let's suppose, V. Are given a data set.",
                    "label": 0
                },
                {
                    "sent": "We have a.",
                    "label": 0
                },
                {
                    "sent": "Our space is a 2 dimensional thing.",
                    "label": 0
                },
                {
                    "sent": "We have some points that we would like to classify as positive.",
                    "label": 0
                },
                {
                    "sent": "We have some points, two points that we would like to classify as negative.",
                    "label": 0
                },
                {
                    "sent": "Basically we just want to.",
                    "label": 0
                },
                {
                    "sent": "Discriminate between them so.",
                    "label": 0
                },
                {
                    "sent": "Are being given a collection of points for somebody say they are ready for some sailor blue.",
                    "label": 0
                },
                {
                    "sent": "Another question is.",
                    "label": 0
                },
                {
                    "sent": "Can you learn a model?",
                    "label": 0
                },
                {
                    "sent": "It will that that will be able to predict when you point that will appoint it appears here.",
                    "label": 0
                },
                {
                    "sent": "Is it blue or red?",
                    "label": 0
                },
                {
                    "sent": "So looking at this picture here would probably say should be blue here it should be read here, not sure so.",
                    "label": 0
                },
                {
                    "sent": "And then one by one easy way to do this.",
                    "label": 0
                },
                {
                    "sent": "Is by.",
                    "label": 0
                },
                {
                    "sent": "Throwing up like between the two clouds, this is called the linear model and here and everything that's in this side of the line is blue.",
                    "label": 0
                },
                {
                    "sent": "Everything that's on this side of the line is correct, so.",
                    "label": 0
                },
                {
                    "sent": "In that sense, so this line was picked by some criterion to be the optimal line for this collection of data points.",
                    "label": 0
                },
                {
                    "sent": "But you can see that if we say here, we can based on this model you can say it's correct.",
                    "label": 0
                },
                {
                    "sent": "You don't really know.",
                    "label": 0
                },
                {
                    "sent": "We don't have any evidence from here.",
                    "label": 0
                },
                {
                    "sent": "Now the models can get arbitrarily more complex.",
                    "label": 0
                },
                {
                    "sent": "So let's say we have some more red points down here.",
                    "label": 0
                },
                {
                    "sent": "No, we can try Steam to draw a line, but you see.",
                    "label": 0
                },
                {
                    "sent": "So maybe for some blue ones we make a mistake.",
                    "label": 0
                },
                {
                    "sent": "For some relevance, make a mistake if you try to put a lien on and hear what we can do is increase the complexity of the model.",
                    "label": 0
                },
                {
                    "sent": "So we can say instead of a line where it can be.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "Compared to put the appointment of 2nd degrees or Parabola Tweet and we see that in this one it's doing better already.",
                    "label": 0
                },
                {
                    "sent": "The complexity of it more as well.",
                    "label": 0
                },
                {
                    "sent": "So you develop internally and then you see OK. Now if you draw this kind of a semicircle around this point it.",
                    "label": 0
                },
                {
                    "sent": "In particular, whether this model in general as well, it's hard to tell this case 'cause it's a.",
                    "label": 0
                },
                {
                    "sent": "We made it quite complex already.",
                    "label": 0
                },
                {
                    "sent": "What would the predictions here?",
                    "label": 0
                },
                {
                    "sent": "So everything that is covered?",
                    "label": 0
                },
                {
                    "sent": "What kind of white should be read?",
                    "label": 0
                },
                {
                    "sent": "Everything that is dark grey.",
                    "label": 0
                },
                {
                    "sent": "It should be blue.",
                    "label": 0
                },
                {
                    "sent": "So disappointed here we would predict it blue and here on the edge.",
                    "label": 0
                },
                {
                    "sent": "It's kind of on the edge and then you can either tell maybe here it's feeling blue but less confident blue here and still have not been responsive.",
                    "label": 0
                },
                {
                    "sent": "Interest just kind of so this would be kind of very anecdotal view of.",
                    "label": 0
                },
                {
                    "sent": "With machine learning algorithms do.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You know what are the standard problems that we typically solve in machine learning approaches, so there are few classes will mostly focus on the first one first 2 classes, so one class is called supervised learning.",
                    "label": 1
                },
                {
                    "sent": "So the idea here is we're given inputs.",
                    "label": 0
                },
                {
                    "sent": "Plus we are also given the outputs the desired output.",
                    "label": 0
                },
                {
                    "sent": "So example would be.",
                    "label": 0
                },
                {
                    "sent": "I work in a label easy to person or not a person.",
                    "label": 0
                },
                {
                    "sent": "It could be example would be a tweet and a sentiment of that week.",
                    "label": 0
                },
                {
                    "sent": "So we already tell the machine.",
                    "label": 0
                },
                {
                    "sent": "But do we want to the output and now the task is just to figure out the best possible function to get this output.",
                    "label": 0
                },
                {
                    "sent": "The second class is called a supervised and unsupervised means that we don't really have any output labels, so it's up to.",
                    "label": 1
                },
                {
                    "sent": "Are there whoever is applying machine learning to know what he's doing and see what can he get out?",
                    "label": 1
                },
                {
                    "sent": "The typical goal would be here too.",
                    "label": 0
                },
                {
                    "sent": "We want to extract, detect some patterns that we cluster input.",
                    "label": 1
                },
                {
                    "sent": "Follow this and we'll see some concrete examples of this that another class would be reinforcement learning so they won't be touching this.",
                    "label": 0
                },
                {
                    "sent": "The idea here is that we have a program that is not given up from the input data and output data, but its position in some more dynamical environment.",
                    "label": 0
                },
                {
                    "sent": "And it's adjusting the model that it's interacting with environment and this alcohol was so this.",
                    "label": 0
                },
                {
                    "sent": "Using an example of reinforcement learning using neural networks for example, and then there are some kind of grey areas or not that the semi supervised where we are working with the both labeled and unlabeled data and typically the idea is we are giving a bit of flavor data, lots of unlabeled data can be better than just working with the label.",
                    "label": 0
                },
                {
                    "sent": "Data directly induces an examples for that as well.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So first supervised learning.",
                    "label": 0
                },
                {
                    "sent": "So what's the kind of prototypical example we have training data we have inputs for this will be their access and the expected outputs.",
                    "label": 1
                },
                {
                    "sent": "That would be wise.",
                    "label": 0
                },
                {
                    "sent": "Again, pairs of a set of this kind of pairs and the goal is given these pairs, find a function that can measure given input to the desired output.",
                    "label": 0
                },
                {
                    "sent": "And then we have a couple of tasks, so this couldn't.",
                    "label": 0
                },
                {
                    "sent": "Breakdown into different types of functions presented in classification.",
                    "label": 0
                },
                {
                    "sent": "The output space would be a set of small set of discrete values.",
                    "label": 0
                },
                {
                    "sent": "In regression we are projecting into space in the ranking.",
                    "label": 0
                },
                {
                    "sent": "The goal is to identify best possible order of the input data.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's fication here.",
                    "label": 0
                },
                {
                    "sent": "Why is appealing settle any special case where we have only two like you saw before random blue people it positive or negative?",
                    "label": 1
                },
                {
                    "sent": "It's called binary classification.",
                    "label": 0
                },
                {
                    "sent": "So then we just have pairs, but it is the input so that week and out is the sum is either plus or minus other positive sentiment, for example, or negative sentiment.",
                    "label": 0
                },
                {
                    "sent": "Functions of the map.",
                    "label": 0
                },
                {
                    "sent": "You could store plus or minus and we call this function on binary classifier.",
                    "label": 1
                },
                {
                    "sent": "Computer for example.",
                    "label": 0
                },
                {
                    "sent": "So we have a red points.",
                    "label": 0
                },
                {
                    "sent": "We have blue points.",
                    "label": 0
                },
                {
                    "sent": "And the binary classifier basically some boundary splitting our input space into into a half into tool to grasp.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If you have more than two labels.",
                    "label": 0
                },
                {
                    "sent": "So then it's for Utah.",
                    "label": 0
                },
                {
                    "sent": "Typically will be multiclass.",
                    "label": 0
                },
                {
                    "sent": "Problem for this means that output weaken, the output is one of K, brings only one and this can be either.",
                    "label": 0
                },
                {
                    "sent": "We can convert it to several binary problems so we can have a separate classifier for each of the K states, separate binary classifier and then pick the value of the most confident one we can have one versus one, so we could have for each pair of output value, train a binary classifier and then the label that has the most votes.",
                    "label": 1
                },
                {
                    "sent": "Means and some problems at logistics regression, multinomial logistic regression, correcting paragraphs or multiclass problems?",
                    "label": 1
                },
                {
                    "sent": "But it's a design.",
                    "label": 0
                },
                {
                    "sent": "It's good to keep this distinction between binary classification and multiclass classification, because binary is really a special special case that can be just that.",
                    "label": 1
                },
                {
                    "sent": "Many problems can be translated.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So send them any problems can be translated to binary classification.",
                    "label": 1
                },
                {
                    "sent": "Another case would be multi label.",
                    "label": 0
                },
                {
                    "sent": "So here we are assigning multiple labels to one instance.",
                    "label": 0
                },
                {
                    "sent": "Example of this would be for example topic classification.",
                    "label": 0
                },
                {
                    "sent": "We have a document in the document, could talk about sports tennis will be games, so we have multiple levels and how to do this with binary classification.",
                    "label": 1
                },
                {
                    "sent": "So we'll just have to train a classifier for each of the labels.",
                    "label": 0
                },
                {
                    "sent": "And then given a new document called, Run.",
                    "label": 0
                },
                {
                    "sent": "For the binary classifiers and assign it all the labels which are binary classifiers.",
                    "label": 0
                },
                {
                    "sent": "And we can also use it store.",
                    "label": 0
                },
                {
                    "sent": "Lewis called the Structured output prediction, so then the output is not.",
                    "label": 0
                },
                {
                    "sent": "Simple structure like value from a set.",
                    "label": 0
                },
                {
                    "sent": "Here are subset, but maybe the output is 3 or something more complex.",
                    "label": 0
                },
                {
                    "sent": "We can again translate it to a binary classification problem.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some examples document station, so we have an article, so it's in our case will be documents analyzer.",
                    "label": 0
                },
                {
                    "sent": "Output space would be topics and technology, sports entertainment is wrong and what we want is a function that can map out.",
                    "label": 0
                },
                {
                    "sent": "Documentum is after me too.",
                    "label": 0
                },
                {
                    "sent": "What about topics?",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Another example is sentiment analysis, so here we have two tweets.",
                    "label": 1
                },
                {
                    "sent": "So the input, so the expense would be other University fees, and the output would be.",
                    "label": 0
                },
                {
                    "sent": "Space two classes, positive, negative or neutral.",
                    "label": 0
                },
                {
                    "sent": "And there are two examples.",
                    "label": 0
                },
                {
                    "sent": "So first 20 angry about care segment like this.",
                    "label": 0
                },
                {
                    "sent": "The classifier.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Another example would be object detection.",
                    "label": 1
                },
                {
                    "sent": "Or do we just?",
                    "label": 0
                },
                {
                    "sent": "Image and the goal is to identify all the areas in the image and give them that have a bit correspond to some object in our database is here we have a bike.",
                    "label": 0
                },
                {
                    "sent": "Here we have a person and all together you would kind of person on the bike.",
                    "label": 0
                },
                {
                    "sent": "Classification problem.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another party later, but different problem with beauty creation.",
                    "label": 0
                },
                {
                    "sent": "So here we are mapping from our your output space would be real numbers.",
                    "label": 0
                },
                {
                    "sent": "Exam.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's say I would input data is the how well a student is doing the high school output data is covered.",
                    "label": 0
                },
                {
                    "sent": "The student is doing the University and then can we predict from his high school grades can predict how it will be doing at University?",
                    "label": 0
                },
                {
                    "sent": "Again, regression problem.",
                    "label": 0
                },
                {
                    "sent": "So we're predicting the number.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Would be.",
                    "label": 0
                },
                {
                    "sent": "Probability of default.",
                    "label": 0
                },
                {
                    "sent": "So this is a lot.",
                    "label": 0
                },
                {
                    "sent": "Risk management you want to secure?",
                    "label": 0
                },
                {
                    "sent": "Working because different companies you might want to maybe compute the risk of individual company spelling.",
                    "label": 0
                },
                {
                    "sent": "This is called probability of default.",
                    "label": 1
                },
                {
                    "sent": "And again here input is the company or company described by some parameters and the output is hearing some country actually and the output would be the likelihood that the country will not be able to replace some of its levels in real time.",
                    "label": 0
                },
                {
                    "sent": "And again the output is a number, so we can include it as a regulation.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Another problem would be that supervised problem is ranking.",
                    "label": 0
                },
                {
                    "sent": "So here the idea is we are given a set of objects.",
                    "label": 1
                },
                {
                    "sent": "X1 to XN, maybe a very as well, and what we want to do is find give back unordered set of items and the training data can be provided either pointwise so that we can have a set of items and preach item in which position should it be?",
                    "label": 0
                },
                {
                    "sent": "But it can be, which is typically easier.",
                    "label": 0
                },
                {
                    "sent": "It can be paralyzed saying that this article should be ranked higher than this.",
                    "label": 0
                },
                {
                    "sent": "For example.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you go to Google search for Dubrovnik.",
                    "label": 0
                },
                {
                    "sent": "There are empty 8 million pages at the back.",
                    "label": 0
                },
                {
                    "sent": "We get to decide which ones to put to the top, and it doesn't have by ranking function and just means that this.",
                    "label": 0
                },
                {
                    "sent": "The eventual technique was scored the highest by this ranking function.",
                    "label": 0
                },
                {
                    "sent": "No help with the one train is so well together.",
                    "label": 0
                },
                {
                    "sent": "Drink water for this, so if you just observing but people are clicking so after somebody's back super quick and then clicks on a Lonely Planet, that's some signal so it doesn't Lonely Planet page should be ranked.",
                    "label": 0
                },
                {
                    "sent": "Maybe at this particular should be rent.",
                    "label": 0
                },
                {
                    "sent": "About the Wikipedia page, maybe you can tell us something about this one that it's only benefit page should be named above.",
                    "label": 0
                },
                {
                    "sent": "Maybe we don't know.",
                    "label": 0
                },
                {
                    "sent": "Plus maybe the user stopped reading here so the signal protected the lower and then by assembling many of these kinds of training person you can train a ranking function under example Dolphins.",
                    "label": 0
                },
                {
                    "sent": "So that's a dolphin.",
                    "label": 0
                },
                {
                    "sent": "The top ranking is a GameCube simulator.",
                    "label": 0
                },
                {
                    "sent": "Followed by the animal again.",
                    "label": 0
                },
                {
                    "sent": "How to decide which which one first, which is the ranking function?",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another ranking problem for probably pick and sticking to ranking would be recommendation.",
                    "label": 0
                },
                {
                    "sent": "Or in this case is a user accommodation, so you're using is leading this article.",
                    "label": 0
                },
                {
                    "sent": "Can be comment.",
                    "label": 0
                },
                {
                    "sent": "Looking for articles.",
                    "label": 0
                },
                {
                    "sent": "And this.",
                    "label": 0
                },
                {
                    "sent": "The four articles will typically be so we have a pool of particles theory, commanding articles from the last day last week.",
                    "label": 0
                },
                {
                    "sent": "Last year what are the top four arrancar Pickles?",
                    "label": 0
                },
                {
                    "sent": "Weather input?",
                    "label": 0
                },
                {
                    "sent": "Harry is the user context, so he's reading this article here, at least in the session here.",
                    "label": 0
                },
                {
                    "sent": "At least in his history.",
                    "label": 0
                },
                {
                    "sent": "Again, this is kind of.",
                    "label": 0
                },
                {
                    "sent": "And then if somebody if you will go and click this we can say OK, so this this article should be ranked higher than these three when you're training and we handle through usage, generate more training data.",
                    "label": 0
                },
                {
                    "sent": "So this would be examples of.",
                    "label": 0
                },
                {
                    "sent": "Supervise.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Supervised so here we just get the examples input data, but we don't really have any.",
                    "label": 0
                },
                {
                    "sent": "Any guidance on the output?",
                    "label": 0
                },
                {
                    "sent": "And what can we do in this case?",
                    "label": 0
                },
                {
                    "sent": "Is an issue because of tasks would be like clustering, anomaly detection, emotionality reductions.",
                    "label": 1
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Number one so class clustering.",
                    "label": 0
                },
                {
                    "sent": "So clustering is.",
                    "label": 0
                },
                {
                    "sent": "One of our standard flow classification and clustering.",
                    "label": 0
                },
                {
                    "sent": "We wanna be standard over tools in the machine learning toolbox.",
                    "label": 0
                },
                {
                    "sent": "Full of clustering, so we're given a bunch of objects we want to identify some groups of objects that are still share some characteristics that is different given by some similarity function.",
                    "label": 0
                },
                {
                    "sent": "So that means if you have a you see some objects would be this points.",
                    "label": 0
                },
                {
                    "sent": "Here we would like to say that the ones that are closer to each other maybe shared, should belong to the same group, where there is another not so close to each other should not belong in the same group.",
                    "label": 1
                },
                {
                    "sent": "You can see that here.",
                    "label": 0
                },
                {
                    "sent": "From party blocks and we would want our clustering algorithm to figure up to these two blocks.",
                    "label": 0
                },
                {
                    "sent": "Now one thing that is very important it is that this pretty much depends on the similarity measure that you give it.",
                    "label": 0
                },
                {
                    "sent": "So the similarity measure is the distance.",
                    "label": 0
                },
                {
                    "sent": "Then it will say OK if you would be able to capture this.",
                    "label": 0
                },
                {
                    "sent": "If you imagine that you project all these data, the white exist, then the distance on the Y axis doesn't really tell us anything about these two clusters, and in that sense it's.",
                    "label": 0
                },
                {
                    "sent": "And one thing because of this is also it's like nontrivial to do a proper evaluation of two different clustering approaches, and it's very much.",
                    "label": 0
                },
                {
                    "sent": "So any?",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Use optical, so let's say we have a stream of.",
                    "label": 0
                },
                {
                    "sent": "All or most of the news articles published in in some period of time.",
                    "label": 1
                },
                {
                    "sent": "Well, if you would cluster similar articles together, what we get is handled events.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So clustering one day of news, this would be kind of top events and you considered so Trump says something has 2000 capitals Galaxy Note 7, exploding his thousand particles and so on.",
                    "label": 0
                },
                {
                    "sent": "So these are all the articles that were talking about Samsung Galaxy Note 7 for some aspect of it.",
                    "label": 0
                },
                {
                    "sent": "The study or together and we were not seem that enough to something else.",
                    "label": 0
                },
                {
                    "sent": "Some other classes.",
                    "label": 0
                },
                {
                    "sent": "And if you look inside, we see the connected lots of kind of similar articles talking about the same topic, and this is the similarity.",
                    "label": 0
                },
                {
                    "sent": "For example, this clustering algorithm was using.",
                    "label": 0
                },
                {
                    "sent": "So putting articles about same entities and topics together.",
                    "label": 0
                },
                {
                    "sent": "Another one.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Supervised another area for supervised methods would be anomaly detection.",
                    "label": 0
                },
                {
                    "sent": "So here they used to identify event.",
                    "label": 0
                },
                {
                    "sent": "So there is a stream of events of observations and we want to identify when observation event is not.",
                    "label": 0
                },
                {
                    "sent": "Does not conform to something that is expected.",
                    "label": 1
                },
                {
                    "sent": "It's good to know that anomaly is a very domain specific term.",
                    "label": 1
                },
                {
                    "sent": "Presently, if you have this again, so who is missing here?",
                    "label": 0
                },
                {
                    "sent": "Kind of a bad thing there is.",
                    "label": 0
                },
                {
                    "sent": "If you have an earthquake.",
                    "label": 0
                },
                {
                    "sent": "Not missing here would be a good thing.",
                    "label": 0
                },
                {
                    "sent": "So very we have to visit.",
                    "label": 0
                },
                {
                    "sent": "You have to make taking this domain into account.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How we usually deal with the density?",
                    "label": 0
                },
                {
                    "sent": "That would be the anomaly detection.",
                    "label": 0
                },
                {
                    "sent": "So one standard of ways to eventu.",
                    "label": 0
                },
                {
                    "sent": "Big kind of density so that the estimated distribution and agree and then of the space of all the observations sending a new observational demand falls into low likelihood space.",
                    "label": 0
                },
                {
                    "sent": "Then we say, OK, let's anomaly, and these are some examples of clearest neighbors.",
                    "label": 0
                },
                {
                    "sent": "Would be nice for one class SVM.",
                    "label": 0
                },
                {
                    "sent": "So before we're looking at this, we were trying to speed this space in half.",
                    "label": 0
                },
                {
                    "sent": "Now here we have a bunch of points we're not trying to see the space in half, but.",
                    "label": 0
                },
                {
                    "sent": "We have three branches, be the spacing help, but we're splitting it in a way so we have all the points in months and our space should be as small as possible, so that's kind of different things and everything that should be outside another point that belongs clearly says Anomaly.",
                    "label": 0
                },
                {
                    "sent": "It belongs here this way, but that's expected.",
                    "label": 0
                },
                {
                    "sent": "Clustering could be used for that as well so.",
                    "label": 0
                },
                {
                    "sent": "Another",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Radio 4 infection.",
                    "label": 0
                },
                {
                    "sent": "There is two different given some car dimensional data and we would like to identify a couple of real dimensional couple of dimensions.",
                    "label": 0
                },
                {
                    "sent": "For.",
                    "label": 0
                },
                {
                    "sent": "That's still capture the most information is data, but as most information mean, every principal component analysis is 1 standard approach, but they're most information.",
                    "label": 1
                },
                {
                    "sent": "It mean capturing the most varieties of the data.",
                    "label": 0
                },
                {
                    "sent": "So power data would be in a crowd like this.",
                    "label": 0
                },
                {
                    "sent": "They would say, OK, this is the most important dimension because it has the most variety along.",
                    "label": 0
                },
                {
                    "sent": "Another approach to this would be similar in composition.",
                    "label": 0
                },
                {
                    "sent": "There we are trying to find a low rank matrix.",
                    "label": 0
                },
                {
                    "sent": "It approximates the data.",
                    "label": 1
                },
                {
                    "sent": "Correlation analysis for multiple data.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another another this is related to anomaly detection in some way, whether unsupervised area between exit estimation.",
                    "label": 0
                },
                {
                    "sent": "So here again we're doing a bunch of formulation and ideas can be estimated.",
                    "label": 0
                },
                {
                    "sent": "The density function of this.",
                    "label": 0
                },
                {
                    "sent": "In the last one.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We are out in quarters.",
                    "label": 0
                },
                {
                    "sent": "So here this is using a neural network artificial neural network and the idea here is that we have our input.",
                    "label": 1
                },
                {
                    "sent": "This is what we're given and we say our inputs should approximately correspond to what the input.",
                    "label": 0
                },
                {
                    "sent": "But we try to squeeze it through some kind of low dimensional representation.",
                    "label": 0
                },
                {
                    "sent": "And this is useful either.",
                    "label": 0
                },
                {
                    "sent": "Exclamation, so visualization.",
                    "label": 0
                },
                {
                    "sent": "So if you want high dimensional data and you want to put it on the monitor, then we have to put it in somehow into D and then getting here for points to do.",
                    "label": 0
                },
                {
                    "sent": "It means that we have now haptics and why and you can say OK, Now we can flood escape the later on the screen.",
                    "label": 0
                },
                {
                    "sent": "Other thing is unsupervised feature learning and this is now especially for the image.",
                    "label": 1
                },
                {
                    "sent": "Image sure computer vision, so sending lots of images or little parts of images through this and see what they're kind of.",
                    "label": 0
                },
                {
                    "sent": "The prototypical things that.",
                    "label": 0
                },
                {
                    "sent": "Gets built in cities or other features.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now one class of.",
                    "label": 0
                },
                {
                    "sent": "Yet another class of problems that lies in the boundary would be.",
                    "label": 0
                },
                {
                    "sent": "The idea here is we are we have some label data, but we also have access to lots of unlabeled data.",
                    "label": 0
                },
                {
                    "sent": "So sometimes this is something this is the case sometimes not.",
                    "label": 0
                },
                {
                    "sent": "For example, if you have lots of documents but it's very expensive to label the documents and you would get 100 documents table and have a million documents in the site so we can use this to use this unlabeled documents to better get the feel of the space.",
                    "label": 0
                },
                {
                    "sent": "There must be a venture.",
                    "label": 0
                },
                {
                    "sent": "Much would be the ones that they are not able to.",
                    "label": 0
                },
                {
                    "sent": "Once with this one is would be marked as labeled.",
                    "label": 0
                },
                {
                    "sent": "We could see this kind of distribution that is underlying the data from this unlabeled documents, and it's easy to say maybe for this one.",
                    "label": 0
                },
                {
                    "sent": "Let's say this green picture.",
                    "label": 0
                },
                {
                    "sent": "It's a screen.",
                    "label": 0
                },
                {
                    "sent": "This one is red, whereas if you wouldn't care if you wouldn't have this language once the model would probably be quite distant.",
                    "label": 0
                },
                {
                    "sent": "This approach is usually called transduction.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another nice one is active learning.",
                    "label": 0
                },
                {
                    "sent": "Useful technique, so the idea here is we are given with a.",
                    "label": 0
                },
                {
                    "sent": "And we have access to our expert that can label a document.",
                    "label": 0
                },
                {
                    "sent": "Now the question is so we don't have enough money for the expert to label all the data set.",
                    "label": 0
                },
                {
                    "sent": "Can we select some small subset that would be optimal for the task we are trying to accomplish some classification?",
                    "label": 0
                },
                {
                    "sent": "Jesus Christ.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's see there.",
                    "label": 0
                },
                {
                    "sent": "We have a data set of companies which company is described by something some features.",
                    "label": 0
                },
                {
                    "sent": "And we want to train a classifier between detect financial companies.",
                    "label": 0
                },
                {
                    "sent": "So this would be the ones here and we had somebody went down, provided some examples and Barclays.",
                    "label": 0
                },
                {
                    "sent": "This is Goldman Sachs or financial companies.",
                    "label": 0
                },
                {
                    "sent": "Apple is not a financial company, General Motor Sport or not.",
                    "label": 0
                },
                {
                    "sent": "And then these other ones.",
                    "label": 0
                },
                {
                    "sent": "We don't really know and now we would run the model like we did before by clicking by do you run this demo before and we get this kind of line saying OK, these are these are.",
                    "label": 0
                },
                {
                    "sent": "Company.",
                    "label": 0
                },
                {
                    "sent": "Actually this is.",
                    "label": 0
                },
                {
                    "sent": "And then we select and then we algorithms goes and says OK, Apple is efinancial company or not and the user says no.",
                    "label": 0
                },
                {
                    "sent": "The label in blue.",
                    "label": 0
                },
                {
                    "sent": "Anything around the\nOut the line is a bit higher then the algorithm says.",
                    "label": 0
                },
                {
                    "sent": "What about Microsoft?",
                    "label": 0
                },
                {
                    "sent": "Microsoft Financial company.",
                    "label": 0
                },
                {
                    "sent": "And the expert says no.",
                    "label": 0
                },
                {
                    "sent": "We are here and we saw that stopping from these two and these two companies and asking fewer there.",
                    "label": 0
                },
                {
                    "sent": "Now we slowly converge to open Mark Citigroup.",
                    "label": 0
                },
                {
                    "sent": "This one you're slowly converging to the good place and the way we were selecting this user algorithms away for selecting which company to label.",
                    "label": 0
                },
                {
                    "sent": "It was mostly on how close it is to the decision boundary, meaning how uncertain the model is about where to put it.",
                    "label": 0
                },
                {
                    "sent": "And the intuition goes, if we can label this uncertain elements, and so we are introducing certainty in the system.",
                    "label": 0
                },
                {
                    "sent": "In helping the model.",
                    "label": 0
                },
                {
                    "sent": "So this would be kind of there.",
                    "label": 0
                },
                {
                    "sent": "Function right?",
                    "label": 0
                },
                {
                    "sent": "That's already, how would you do that if you know what I mean, you could have whatever is going on distribution or something.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah strange.",
                    "label": 0
                },
                {
                    "sent": "I'm just wondering how you combine that with model selection for each model that candidates can do active learning.",
                    "label": 0
                },
                {
                    "sent": "You could run, so depending you could run it with different model parameters in parallel.",
                    "label": 0
                },
                {
                    "sent": "Can you different model parameters to select the?",
                    "label": 0
                },
                {
                    "sent": "Think not think maybe for not on the level of.",
                    "label": 0
                },
                {
                    "sent": "Because people do it sometimes for optimizing kind of learning for this, regularization parameters model selection, I think is already kind of.",
                    "label": 0
                },
                {
                    "sent": "Also, lots of approaches depend on the explicit model being used, so here we are allowing a model big align some degree curve decision tree would be not really have the same effect.",
                    "label": 0
                },
                {
                    "sent": "In this case we have optimized.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we went to different.",
                    "label": 0
                },
                {
                    "sent": "Examples of different problems that we can that people are solving.",
                    "label": 0
                },
                {
                    "sent": "Surely there are many more so, but this is just a scratch the surface and now we'll go kind of through the pipeline how to how starting to feel a bunch of data, how to get to a working model.",
                    "label": 0
                },
                {
                    "sent": "So the first thing is data representation.",
                    "label": 0
                },
                {
                    "sent": "So if you are giving the text and the algorithm expects a lectern input, how do we go from one to the other one example?",
                    "label": 0
                },
                {
                    "sent": "So what we should data points are typically represented by features or attributes, so it's just called.",
                    "label": 1
                },
                {
                    "sent": "Whenever I say pictures, I mean some.",
                    "label": 0
                },
                {
                    "sent": "Parameters and one you related to the example.",
                    "label": 0
                },
                {
                    "sent": "Is it?",
                    "label": 0
                },
                {
                    "sent": "Is it exact representation?",
                    "label": 1
                },
                {
                    "sent": "Depends on open the algorithm.",
                    "label": 0
                },
                {
                    "sent": "So if you're working with decision trees then they work with the individual attributes and distinguish between continuous and discrete attributes.",
                    "label": 1
                },
                {
                    "sent": "For example, if you work with the linear models like logistic, regression, SVM.",
                    "label": 0
                },
                {
                    "sent": "They work with vectors for most directors there, so we have to get our data to something that we can encode into as a point in a vector space.",
                    "label": 1
                },
                {
                    "sent": "Then there are approaches that only require similarity measure.",
                    "label": 0
                },
                {
                    "sent": "So given to data points we don't need it's representation.",
                    "label": 0
                },
                {
                    "sent": "You just need to tell how similar they are some degree.",
                    "label": 0
                },
                {
                    "sent": "Methods for example.",
                    "label": 0
                },
                {
                    "sent": "And then also.",
                    "label": 0
                },
                {
                    "sent": "Actually learning representation.",
                    "label": 0
                },
                {
                    "sent": "So if you start with words indeed figure out their vector representation can be learned from the data itself.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So under standard example that will be using like the House in the account of camera.",
                    "label": 0
                },
                {
                    "sent": "Amazon Session is text presentation and a vector space model would be one of the standard representations and the idea of vector space model.",
                    "label": 1
                },
                {
                    "sent": "So we take document and we first identify all the unique words that occur in this document.",
                    "label": 1
                },
                {
                    "sent": "Or in the purpose of the documents, and then each word becomes one dimension.",
                    "label": 1
                },
                {
                    "sent": "Example later and then for the individual document.",
                    "label": 0
                },
                {
                    "sent": "So it's a vector in this space which which each word corresponding to.",
                    "label": 0
                },
                {
                    "sent": "And then you see the value in that dimension is 1, but the network of course if the document is there otherwise.",
                    "label": 0
                },
                {
                    "sent": "So this can be more complicated, so you can use different rates, but this is a basic level.",
                    "label": 0
                },
                {
                    "sent": "We're just for a document saying those are the current feature or not.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here we have 3.",
                    "label": 0
                },
                {
                    "sent": "We have three documents.",
                    "label": 0
                },
                {
                    "sent": "But my turned off the two documents tricks without my phone 2, three and here are a couple of thoughts that I slept from these documents for.",
                    "label": 0
                },
                {
                    "sent": "There are many more, so this typically working with vector space model.",
                    "label": 0
                },
                {
                    "sent": "You're quite early.",
                    "label": 0
                },
                {
                    "sent": "Get to hundreds of thousands of dimensions, so whatever algorithm using they have to be able to copy that.",
                    "label": 0
                },
                {
                    "sent": "Then we have we think, OK, the first words we say Angela and we see it appears in all the documents.",
                    "label": 0
                },
                {
                    "sent": "Now we can do also called engrams.",
                    "label": 0
                },
                {
                    "sent": "So obviously is bigram so frequently Co occurring words that occur together, and this kind of allows us to extract decreases as well.",
                    "label": 0
                },
                {
                    "sent": "Brexit occurs in the first one.",
                    "label": 0
                },
                {
                    "sent": "You don't need a second and the problem is you want and now at the end if you need.",
                    "label": 0
                },
                {
                    "sent": "If you have three vectors and now if you compare the distance between these factors we can see how all this on some level, usually more topical level.",
                    "label": 0
                },
                {
                    "sent": "How similar we are.",
                    "label": 0
                },
                {
                    "sent": "So the distance between these large dimensional data points which we don't measure.",
                    "label": 0
                },
                {
                    "sent": "Video preview and distance, but you measured it causing distance, which is kind of.",
                    "label": 0
                },
                {
                    "sent": "Normalize these vectors and then check the angle between them, is this?",
                    "label": 0
                },
                {
                    "sent": "Kind of compensates for the length of the document, so it's easier also to compare short and long documents.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now there are a couple of.",
                    "label": 0
                },
                {
                    "sent": "Or a couple of things that's good to know, so this this is disappointed that representation is also called bag of words back in a sense that we take all the words of the document and we threw them in.",
                    "label": 0
                },
                {
                    "sent": "We disregard the order, but most often we would also count how many times individual work occurs, so it's not always 10 or something, it's like.",
                    "label": 0
                },
                {
                    "sent": "There are different ways how to actually compute the weights in the world, so it's not obvious that one is the best or surely surely it's not the best way.",
                    "label": 0
                },
                {
                    "sent": "So how for a different word, for example?",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "He's great, he's comparing Brexit position.",
                    "label": 0
                },
                {
                    "sent": "Which one is more important in our representation?",
                    "label": 0
                },
                {
                    "sent": "This would often depend on the data set.",
                    "label": 0
                },
                {
                    "sent": "So if and what are the topics?",
                    "label": 0
                },
                {
                    "sent": "It doesn't appear weak.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Problem can be stopped once you can have both good or other filler words that are hard to that could occur often include make.",
                    "label": 0
                },
                {
                    "sent": "Documents look seem that even though they don't really share any kind of more important words.",
                    "label": 0
                },
                {
                    "sent": "So one simple way is just to ignore this promising and fixed set of common words.",
                    "label": 0
                },
                {
                    "sent": "And The thing is, if you have words of different forms of banks, banking, stuff like that, we would all want to normalize it tomorrow.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Can use understanding organization for this kind of cutting the ending.",
                    "label": 0
                },
                {
                    "sent": "M Hayden nationality.",
                    "label": 0
                },
                {
                    "sent": "So for a large corpus you can easily end up with millions of words and not easy way of dealing with this is using hashing trick where we don't actually remember.",
                    "label": 0
                },
                {
                    "sent": "We don't say we don't assign.",
                    "label": 0
                },
                {
                    "sent": "We from each quarter computer cash.",
                    "label": 0
                },
                {
                    "sent": "And then we divide this cash order some 100,000 and what we get out is actually our dimension.",
                    "label": 0
                },
                {
                    "sent": "So this kind of gives us kibitzers to 100,000 dimension.",
                    "label": 0
                },
                {
                    "sent": "For example it's another week and also the likelihood of distorting.",
                    "label": 0
                },
                {
                    "sent": "Do not remember that is very low.",
                    "label": 0
                },
                {
                    "sent": "And, uh.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Approach that we can do is actually learn the presentation.",
                    "label": 0
                },
                {
                    "sent": "Another so just to be here is, so this is this vote to make.",
                    "label": 0
                },
                {
                    "sent": "And the idea here is can be in given words and how they Co occur, how they recording documents, which one, what is a Co occur?",
                    "label": 0
                },
                {
                    "sent": "It can be identify end dimensional vectors so that words that occur in similar context.",
                    "label": 0
                },
                {
                    "sent": "So words that have investment and stuff around it would be.",
                    "label": 0
                },
                {
                    "sent": "Close in space.",
                    "label": 0
                },
                {
                    "sent": "And we can see if you do that for this.",
                    "label": 0
                },
                {
                    "sent": "Once examples we have animals in them some ports and would be closer to each other than others.",
                    "label": 0
                },
                {
                    "sent": "So this is a.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Another modality of data attack of data would be time seriously here very given measurements.",
                    "label": 0
                },
                {
                    "sent": "Series of data points in time order.",
                    "label": 1
                },
                {
                    "sent": "So for example, temperature readings once per day or once per hour that I've been greetings here we have number of airline passengers per year or different stuff.",
                    "label": 0
                },
                {
                    "sent": "And if you want to do some example regression on this or some classification on this, we would also want to represent or let's say here, here.",
                    "label": 0
                },
                {
                    "sent": "We want to make some decision of how the things we draw, but are the features that we should use and then we have some.",
                    "label": 0
                },
                {
                    "sent": "You can complete surrender statistics, mean deviation so on.",
                    "label": 0
                },
                {
                    "sent": "We can use time delay embedding.",
                    "label": 0
                },
                {
                    "sent": "So just use last N values either overtime series or any of these features.",
                    "label": 0
                },
                {
                    "sent": "Or we can also.",
                    "label": 0
                },
                {
                    "sent": "Transport the time series into some frequency domain, for example, extracted features from there.",
                    "label": 0
                },
                {
                    "sent": "But the important thing here is that depending on the data that we get to each data packet have some specifics that it's good to know before he started crying or doing anything.",
                    "label": 0
                },
                {
                    "sent": "On top of that.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So so much for that presentation.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Model is working, machine is kind of the output of the training program.",
                    "label": 1
                },
                {
                    "sent": "So we can put it specification for example, so it's a function function function, right?",
                    "label": 0
                },
                {
                    "sent": "I'm not.",
                    "label": 0
                },
                {
                    "sent": "We have different types of models, with some others can be just discriminative so that we saw before the number example is line and that model hotel is something on one side or the other, but it didn't really tell us much more about the data.",
                    "label": 1
                },
                {
                    "sent": "You can have generative models, but from the model we can go out and actually generate examples that look very much like our data set.",
                    "label": 0
                },
                {
                    "sent": "Alien.",
                    "label": 1
                },
                {
                    "sent": "So which model we want also depends on the task.",
                    "label": 0
                },
                {
                    "sent": "It's mark.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Have we got a couple of super models and how they look like for the most one of the most common models is a linear model, so it's very simple, so we have a linear function.",
                    "label": 1
                },
                {
                    "sent": "We take the features.",
                    "label": 0
                },
                {
                    "sent": "We multiply the feature vector with some.",
                    "label": 0
                },
                {
                    "sent": "And we get it prediction.",
                    "label": 0
                },
                {
                    "sent": "Then if you specification we can check that maybe the sign of the prediction to say it's a positive or negative, but that's it.",
                    "label": 1
                },
                {
                    "sent": "In the end, we are searching for the linear model.",
                    "label": 0
                },
                {
                    "sent": "What we are searching for is basically the parameter vector W. When they can be off, they are kind of nice and easy behaved.",
                    "label": 0
                },
                {
                    "sent": "Yeah, typically on expanding not so expensive to train.",
                    "label": 1
                },
                {
                    "sent": "Most prediction is quite fast, so just the number will never compile in the number of features that we have nausea features.",
                    "label": 0
                },
                {
                    "sent": "Probably.",
                    "label": 0
                },
                {
                    "sent": "They can't get you not enough veterans.",
                    "label": 0
                },
                {
                    "sent": "And here we see examples.",
                    "label": 0
                },
                {
                    "sent": "We have house size and price later and it's not really noticeable relationship.",
                    "label": 0
                },
                {
                    "sent": "So it goes kind of like this and if you want to if you go try to fit it with the line it kind of fits but not really.",
                    "label": 0
                },
                {
                    "sent": "She tried to put a rubber tree kind of looks better already if you fit a polynomial of degree 6 St we can hit each point exactly but I think looking at this time everybody would agree that it's probably.",
                    "label": 0
                },
                {
                    "sent": "It doesn't generalize building other data, and this is what we call overthinking, and we do that.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Geometric interpretation of classifier.",
                    "label": 0
                },
                {
                    "sent": "It's basically the W vector would be a normal of these hyperplanes.",
                    "label": 0
                },
                {
                    "sent": "That is dividing the positive and negative straight.",
                    "label": 0
                },
                {
                    "sent": "This would be.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Their position is that we have a support each feature to get away.",
                    "label": 0
                },
                {
                    "sent": "Positive features vote for a positive plus negative features.",
                    "label": 1
                },
                {
                    "sent": "Features for negative class.",
                    "label": 0
                },
                {
                    "sent": "We sent them altogether remove to platter features from them up together and we see the final both conclusion.",
                    "label": 0
                },
                {
                    "sent": "Larger debates, typically stronger divorce, also depending on the picture size, but that's kind of the interpretation and we will see later in the hands of 1 computers entities.",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "How can we increase the?",
                    "label": 0
                },
                {
                    "sent": "How can we get more fixed?",
                    "label": 0
                },
                {
                    "sent": "With a bit more complex data, so we can't really do believe that model for efficient approaches, one would be kernel methods, so there is a bunch of algorithms where that can be written in a way that you only interact with the data points throughout the DOT product.",
                    "label": 0
                },
                {
                    "sent": "And these dogs properties, typically called our kernel and the story behind it goes the following.",
                    "label": 0
                },
                {
                    "sent": "So have a some mapping.",
                    "label": 0
                },
                {
                    "sent": "It takes data from other input space in Maps into some high dimensional space, can be high in a sense of loss of dimension, number of dimension.",
                    "label": 0
                },
                {
                    "sent": "And if you can, you can compute dot product in there.",
                    "label": 1
                },
                {
                    "sent": "Without explicitly mapping the data for this other space and then this will be called.",
                    "label": 0
                },
                {
                    "sent": "And the intuition behind his death.",
                    "label": 0
                },
                {
                    "sent": "In one way we are doing our learning problem in a much higher dimensional space.",
                    "label": 0
                },
                {
                    "sent": "So what's linear Del sooner up there is not linear.",
                    "label": 0
                },
                {
                    "sent": "Once we projected the decision now.",
                    "label": 0
                },
                {
                    "sent": "Thank you some examples.",
                    "label": 0
                },
                {
                    "sent": "So let's say we have a.",
                    "label": 0
                },
                {
                    "sent": "Well this would be negative positive class.",
                    "label": 0
                },
                {
                    "sent": "I believe that model would go like this.",
                    "label": 0
                },
                {
                    "sent": "Now if you use a polynomial kernel.",
                    "label": 0
                },
                {
                    "sent": "So this is what you are drinking the example before the 2nd degree we got this kind of problem.",
                    "label": 0
                },
                {
                    "sent": "Use degree treat regarding a more complex so the higher the degree, the more complicated the water can be and basically this line here is a.",
                    "label": 0
                },
                {
                    "sent": "Actually are.",
                    "label": 0
                },
                {
                    "sent": "The state line, but in some higher dimensional space or not to do dimensionally, but in some foreign Nationals.",
                    "label": 0
                },
                {
                    "sent": "If you look if you try to write it down.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this would be there.",
                    "label": 0
                },
                {
                    "sent": "So what we do is take the.",
                    "label": 0
                },
                {
                    "sent": "We have two elements X&Y and we want to compete with the DOT product between them so we still do the DOT product between them, but we.",
                    "label": 0
                },
                {
                    "sent": "Would that be greedy?",
                    "label": 0
                },
                {
                    "sent": "And if you go down and help, right, right, right it out.",
                    "label": 0
                },
                {
                    "sent": "So let's say we have a our feature space just so we have two dimensions.",
                    "label": 0
                },
                {
                    "sent": "Our degree of the polynomial kernel is 2 and C would be once this constant factor.",
                    "label": 0
                },
                {
                    "sent": "So what happens?",
                    "label": 0
                },
                {
                    "sent": "So we have these two vectors.",
                    "label": 0
                },
                {
                    "sent": "We write them down, so we have a basically.",
                    "label": 0
                },
                {
                    "sent": "Exactly, so the dot product plus one.",
                    "label": 0
                },
                {
                    "sent": "Now this is an equation data and then we go down.",
                    "label": 0
                },
                {
                    "sent": "We modified.",
                    "label": 0
                },
                {
                    "sent": "We get this wrong thing here and we can try to break it apart and write it again as a two individual vectors.",
                    "label": 0
                },
                {
                    "sent": "But one has only elements from XML.",
                    "label": 0
                },
                {
                    "sent": "He's only elements provide.",
                    "label": 0
                },
                {
                    "sent": "We can see that.",
                    "label": 0
                },
                {
                    "sent": "Actually this corresponds to.",
                    "label": 0
                },
                {
                    "sent": "Don't product enough 123456 dimensional space.",
                    "label": 0
                },
                {
                    "sent": "This not State Bank before.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this curve is actually projection of straight line from 6 dimensional space down here and that is nice.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "See that.",
                    "label": 0
                },
                {
                    "sent": "So that we have two pictures.",
                    "label": 0
                },
                {
                    "sent": "So linear model can't capture interaction, so it can always feature one is active or not.",
                    "label": 0
                },
                {
                    "sent": "Feature two is one or zero, for example as well.",
                    "label": 0
                },
                {
                    "sent": "But linear model can say is feature one or two 10?",
                    "label": 0
                },
                {
                    "sent": "Or is they're both positive?",
                    "label": 0
                },
                {
                    "sent": "For example there is.",
                    "label": 0
                },
                {
                    "sent": "Here you see we have a product X 1 * X Two.",
                    "label": 0
                },
                {
                    "sent": "So through just by going through this kernel, methods for this polynomial kernel, we are able to capture the signal.",
                    "label": 0
                },
                {
                    "sent": "So this interaction this file.",
                    "label": 0
                },
                {
                    "sent": "Paralyzing connections between features.",
                    "label": 0
                },
                {
                    "sent": "Now if we increase the degree then we get the interaction between 3 features variance one.",
                    "label": 0
                },
                {
                    "sent": "In the extreme.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We can go to the cabin Ocean kernel very basically mapped infinite dimensional space in the capture or possible interactions.",
                    "label": 1
                },
                {
                    "sent": "Describe complex.",
                    "label": 0
                },
                {
                    "sent": "Again here.",
                    "label": 0
                },
                {
                    "sent": "It's very easy to overfit now.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Another way of dealing with this will help increase the capacity would be going through supplying the artificial neural effort.",
                    "label": 0
                },
                {
                    "sent": "And, uh.",
                    "label": 0
                },
                {
                    "sent": "Or this is an example of neural network, but we're basically trying to do is an approximate the function, so like.",
                    "label": 0
                },
                {
                    "sent": "Other approaches, but we use network coding.",
                    "label": 0
                },
                {
                    "sent": "So here you have nodes.",
                    "label": 0
                },
                {
                    "sent": "Notes, notes, notes for everything in between, and.",
                    "label": 0
                },
                {
                    "sent": "These are called neurons.",
                    "label": 0
                },
                {
                    "sent": "So one note can depend on more.",
                    "label": 1
                },
                {
                    "sent": "One of the more inputs and they can send the signal outdoor one more outlets and each each architecture of the network would be how are basically this topology of the graph.",
                    "label": 0
                },
                {
                    "sent": "And then also there, but we've kept it specifies that activation, so lot of the functions.",
                    "label": 0
                },
                {
                    "sent": "And how does this note here?",
                    "label": 0
                },
                {
                    "sent": "How does it take that list to the inputs?",
                    "label": 0
                },
                {
                    "sent": "And how does it integrate them together?",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This would be with their project right?",
                    "label": 0
                },
                {
                    "sent": "So here we have a supervised approach, so the output will be presented, classes or aggression.",
                    "label": 0
                },
                {
                    "sent": "Must have at least three layers.",
                    "label": 0
                },
                {
                    "sent": "You could layer output layer at least one hidden layer.",
                    "label": 0
                },
                {
                    "sent": "Activation functions can be either linear, so after you take the outputs and you multiply them with a linear function, we get the value or it can be nonlinear optical.",
                    "label": 0
                },
                {
                    "sent": "Take that input and send it for some nonlinear function sigmoid or something like that.",
                    "label": 0
                },
                {
                    "sent": "And we can do because if you have to go to outlook, you can use something for the softmax, skip now.",
                    "label": 0
                },
                {
                    "sent": "Skip this, go to the demo.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This one is a playground.",
                    "label": 0
                },
                {
                    "sent": "Tensorflow don't work.",
                    "label": 0
                },
                {
                    "sent": "Want to play so once we do here we select the training data.",
                    "label": 0
                },
                {
                    "sent": "So let's start with something simple.",
                    "label": 0
                },
                {
                    "sent": "Then you select whether our features so features will be Hicks one and X2.",
                    "label": 0
                },
                {
                    "sent": "So basically we have two coordinates.",
                    "label": 0
                },
                {
                    "sent": "And we don't give any hidden layers for start and that means that output is just a linear combination of these two guys if we start.",
                    "label": 0
                },
                {
                    "sent": "We'll end up with that.",
                    "label": 0
                },
                {
                    "sent": "Now we go for something more complex.",
                    "label": 0
                },
                {
                    "sent": "Also this is.",
                    "label": 0
                },
                {
                    "sent": "Maybe it would be better.",
                    "label": 0
                },
                {
                    "sent": "Yes, you do not seem right.",
                    "label": 0
                },
                {
                    "sent": "Yeah, just.",
                    "label": 0
                },
                {
                    "sent": "It's more right.",
                    "label": 0
                },
                {
                    "sent": "So we see there are blue points.",
                    "label": 0
                },
                {
                    "sent": "It's kind of a check chess board like.",
                    "label": 0
                },
                {
                    "sent": "And if you try to pick the line for Secondry is everything's trying.",
                    "label": 0
                },
                {
                    "sent": "I mean the the model doesn't have the capacity to capture this now.",
                    "label": 0
                },
                {
                    "sent": "One simple thing would be you can increase the features so if you add a product feature so that at least some before that this polynomial of 2nd degree would already include.",
                    "label": 0
                },
                {
                    "sent": "So if we add one more feature so the product of fixed right.",
                    "label": 0
                },
                {
                    "sent": "Here we get up.",
                    "label": 0
                },
                {
                    "sent": "Get perfect terms classification.",
                    "label": 0
                },
                {
                    "sent": "But this is a this was a.",
                    "label": 0
                },
                {
                    "sent": "Basically you are messing up the inputs, so we're kind of in the future engineer.",
                    "label": 0
                },
                {
                    "sent": "And you know how to compensate this with a more structured ways.",
                    "label": 0
                },
                {
                    "sent": "Using for this kernel methods that we saw before, but another option since we have a neural network here.",
                    "label": 0
                },
                {
                    "sent": "Another way of dealing with the nonlinearities introduced this linear layers.",
                    "label": 0
                },
                {
                    "sent": "So now we have this goalkeeper features that get mapped into the intermediary values that then get mapped into the classification.",
                    "label": 0
                },
                {
                    "sent": "Now we feel like this.",
                    "label": 0
                },
                {
                    "sent": "We have only two neurons, limited trying.",
                    "label": 0
                },
                {
                    "sent": "It's doing something so I can see it before I get more complex, so most of the blue on blue most of the orange are orange.",
                    "label": 0
                },
                {
                    "sent": "Sacrificed.",
                    "label": 0
                },
                {
                    "sent": "Life increase the capacity.",
                    "label": 0
                },
                {
                    "sent": "Free.",
                    "label": 0
                },
                {
                    "sent": "Is not.",
                    "label": 0
                },
                {
                    "sent": "At 4:00 components kind of stock ticker.",
                    "label": 0
                },
                {
                    "sent": "Starting to bend.",
                    "label": 0
                },
                {
                    "sent": "It's struggling, but it's kind of something is happening at another layer.",
                    "label": 0
                },
                {
                    "sent": "Explain the learning curve so this is a.",
                    "label": 0
                },
                {
                    "sent": "Two parameters, so distortion training loss.",
                    "label": 0
                },
                {
                    "sent": "So we can you know that.",
                    "label": 0
                },
                {
                    "sent": "So the idea here is the.",
                    "label": 0
                },
                {
                    "sent": "Applying the model of this points and training last week, how well are we doing from the training data?",
                    "label": 0
                },
                {
                    "sent": "So if you're not doing that in the training data, then proposal under fell on the other data.",
                    "label": 0
                },
                {
                    "sent": "If you're doing well on the training data doesn't mean that we will do well on the other data 'cause we might be overheating.",
                    "label": 0
                },
                {
                    "sent": "Freeze.",
                    "label": 0
                },
                {
                    "sent": "Welcome home.",
                    "label": 0
                },
                {
                    "sent": "Good point if it starts to repeat.",
                    "label": 0
                },
                {
                    "sent": "Do you have an accent?",
                    "label": 0
                },
                {
                    "sent": "Do you have any information or what is happening happening in the Community players?",
                    "label": 0
                },
                {
                    "sent": "So this is the the if you just use this feature of the classifier, you will kind of.",
                    "label": 0
                },
                {
                    "sent": "It captures this kind of signal.",
                    "label": 0
                },
                {
                    "sent": "Then as you're learning you can see that this one basically now also added his serious kind of does.",
                    "label": 0
                },
                {
                    "sent": "He's doing this prediction.",
                    "label": 0
                },
                {
                    "sent": "This one is doing kind of complementary and then did not get refined here and then kind of summed up together, but it's.",
                    "label": 0
                },
                {
                    "sent": "There's lots of.",
                    "label": 0
                },
                {
                    "sent": "So this is these are simple examples here, so it's you know it's easy to experiment.",
                    "label": 0
                },
                {
                    "sent": "So when you get a bigger system, you really need to spend some time to get also the learning parameter, right and everything.",
                    "label": 0
                },
                {
                    "sent": "And is adding features, so adding the number of layers.",
                    "label": 0
                },
                {
                    "sent": "So now look like.",
                    "label": 0
                },
                {
                    "sent": "So how is the number of layers then?",
                    "label": 0
                },
                {
                    "sent": "I'm bout know that they didn't layers and the teachers is just trying to find out if I know.",
                    "label": 0
                },
                {
                    "sent": "I mean, you can see Kappa some.",
                    "label": 0
                },
                {
                    "sent": "For some problems you have a bad, understood architectures that you could even use.",
                    "label": 0
                },
                {
                    "sent": "So what is secure signing?",
                    "label": 0
                },
                {
                    "sent": "Something that is not?",
                    "label": 0
                },
                {
                    "sent": "It wasn't done with these dynamics, you're with lots of experimentation in your future, so it's not like this that you are doing it and then you are getting inside what is happening in this hidden layer.",
                    "label": 0
                },
                {
                    "sent": "So you get we will ever get an intuition of what we were.",
                    "label": 0
                },
                {
                    "sent": "For example, if you are.",
                    "label": 0
                },
                {
                    "sent": "Bismarck motor",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is a neural network for solving the problem we were doing in the motivation.",
                    "label": 1
                },
                {
                    "sent": "So this name entity recognition, for example, uses exactly so it has a.",
                    "label": 0
                },
                {
                    "sent": "It starts with the word on.",
                    "label": 0
                },
                {
                    "sent": "It takes its context and it first Maps them into.",
                    "label": 0
                },
                {
                    "sent": "Each word is mapped into 50 dimensional vector for example.",
                    "label": 0
                },
                {
                    "sent": "Then it is good transformation and then again the softmax to figure out the class.",
                    "label": 0
                },
                {
                    "sent": "Now for this, if you look at this later segment after you run documents for awhile, look at this vector.",
                    "label": 0
                },
                {
                    "sent": "Then it turns out that words that are similar by some connected similar class would have vectors that are closer together than words that are not in the same class.",
                    "label": 0
                },
                {
                    "sent": "But this is something that is very specific to this kind of architecture.",
                    "label": 0
                },
                {
                    "sent": "If you have some different things, there are some different wiring.",
                    "label": 0
                },
                {
                    "sent": "Then again, you would have to go down and check what exactly it means, whereas for this lower layers it's hard to.",
                    "label": 0
                },
                {
                    "sent": "Maybe with lots of handwaving there lots of effort you could figure out, maybe some meetings, but it's very hard to understand what's happening there.",
                    "label": 0
                },
                {
                    "sent": "Networks with dancer players and it gets more or less impossible.",
                    "label": 0
                },
                {
                    "sent": "We can do visualizations for example like this or before an outing, whether if you have an image problem then you can see how this image is broken into simple features and then each layer would kind of capture capture with more complex features.",
                    "label": 0
                },
                {
                    "sent": "But again, we see images.",
                    "label": 0
                },
                {
                    "sent": "You can visualize some degree crucifying reversing back to the image or text is a bit harder already cause.",
                    "label": 0
                },
                {
                    "sent": "It's hard to get from.",
                    "label": 0
                },
                {
                    "sent": "Metrics question text document, so it's.",
                    "label": 0
                },
                {
                    "sent": "It's a large degree to black folks.",
                    "label": 0
                },
                {
                    "sent": "And also it can be so can be also quite the month.",
                    "label": 0
                },
                {
                    "sent": "Side effects are very good performance other side and can help out everybody which classification we have.",
                    "label": 0
                },
                {
                    "sent": "Some examples when you take the image you just slightly distorted so you wouldn't even notice the difference and it will be classified in a completely different class.",
                    "label": 0
                },
                {
                    "sent": "And vice versa, I can give you some which looks more like like random noise to you and you would classify it in it.",
                    "label": 0
                },
                {
                    "sent": "Look like it was classified into some quick class just because this intermediary layers are hard to prove.",
                    "label": 0
                },
                {
                    "sent": "Is something going this is understanding during that time?",
                    "label": 0
                },
                {
                    "sent": "Is 1 big coffee gonna just came from this CBD conference and flus topic, which is not really addressed, or it's unlocking here couple of races.",
                    "label": 0
                },
                {
                    "sent": "What time is the black box?",
                    "label": 0
                },
                {
                    "sent": "Which.",
                    "label": 0
                },
                {
                    "sent": "Intermediate euros right?",
                    "label": 0
                },
                {
                    "sent": "There are some kind of Lego pieces building blocks which.",
                    "label": 0
                },
                {
                    "sent": "Allow people to do this or could be like the solution in a better way, but the question is.",
                    "label": 0
                },
                {
                    "sent": "Alchemist and is building blocks.",
                    "label": 0
                },
                {
                    "sent": "This label pieces so this is on here.",
                    "label": 0
                },
                {
                    "sent": "And I'm sorry.",
                    "label": 0
                },
                {
                    "sent": "Oh 13 case of images.",
                    "label": 0
                },
                {
                    "sent": "Somehow we can see this some elements with text, some kind of compare things may be less clear, but.",
                    "label": 0
                },
                {
                    "sent": "General instructions, and really there's no solution will.",
                    "label": 0
                },
                {
                    "sent": "Community doesn't have any proprietary.",
                    "label": 0
                },
                {
                    "sent": "Yes, please question.",
                    "label": 0
                },
                {
                    "sent": "Canada.",
                    "label": 0
                },
                {
                    "sent": "Hello.",
                    "label": 0
                },
                {
                    "sent": "You can include the regulations or controlling your criteria so you want before in the examples.",
                    "label": 0
                },
                {
                    "sent": "Here we had a good support at one or after regularization model or we have this early stopping for something that fits their things.",
                    "label": 0
                },
                {
                    "sent": "Yeah, it's not not definition.",
                    "label": 0
                },
                {
                    "sent": "I just wanted to check, for example using features exponent extremely revealing some variable values.",
                    "label": 0
                },
                {
                    "sent": "Can you just show in one year what is the equation that represents one of the like probably the first Hinrichs.",
                    "label": 0
                },
                {
                    "sent": "So just want to visualize it like Mathematica.",
                    "label": 0
                },
                {
                    "sent": "Like instead of having so many features, if I just have two features, for example, it's an experience.",
                    "label": 0
                },
                {
                    "sent": "These are just make up related to each feature or something, so can you just represent once mathematical?",
                    "label": 0
                },
                {
                    "sent": "He wasn't one of those like running for student there here.",
                    "label": 0
                },
                {
                    "sent": "Yes, so here.",
                    "label": 0
                },
                {
                    "sent": "It could be.",
                    "label": 0
                },
                {
                    "sent": "This is just.",
                    "label": 0
                },
                {
                    "sent": "So linear function with some weights times X1 plus wait times X2 that extends to downloads capabilities.",
                    "label": 0
                },
                {
                    "sent": "So this is kind of activations functions, so that would be.",
                    "label": 0
                },
                {
                    "sent": "Example of like we have like maybe 1 hidden layer can be limited to hidden there just so gross when we.",
                    "label": 0
                },
                {
                    "sent": "Each year we learn something and then we go to the next layer, right?",
                    "label": 0
                },
                {
                    "sent": "What is the I mean, just one simple decoration?",
                    "label": 0
                },
                {
                    "sent": "Probably that takes from the features in the sense that to the to the next leader.",
                    "label": 0
                },
                {
                    "sent": "So just want to let the.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For example.",
                    "label": 0
                },
                {
                    "sent": "Let's say we have a one possible step from input to the hidden person.",
                    "label": 0
                },
                {
                    "sent": "There would be have a metrics that takes this three element and outputs for element.",
                    "label": 0
                },
                {
                    "sent": "So 3 by 4 matrix.",
                    "label": 0
                },
                {
                    "sent": "While computing it, we need the weights of each of the training will give you.",
                    "label": 0
                },
                {
                    "sent": "Is the Matrix A in this case for example.",
                    "label": 0
                },
                {
                    "sent": "So this is what you're optimizing over.",
                    "label": 0
                },
                {
                    "sent": "Well, this is fixed.",
                    "label": 0
                },
                {
                    "sent": "The output is fixed.",
                    "label": 0
                },
                {
                    "sent": "But you're optimizing.",
                    "label": 0
                },
                {
                    "sent": "These are figure out out either the piece metrics A.",
                    "label": 0
                },
                {
                    "sent": "Either that's it, yeah.",
                    "label": 0
                },
                {
                    "sent": "They are random and then they are changed.",
                    "label": 0
                },
                {
                    "sent": "Reminder.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "You can understand why random or you can have some.",
                    "label": 0
                },
                {
                    "sent": "We have different different.",
                    "label": 0
                },
                {
                    "sent": "These guys.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You cannot.",
                    "label": 0
                },
                {
                    "sent": "So it can hear we are solving limited recognition.",
                    "label": 0
                },
                {
                    "sent": "We can solve a similar problem or similar problem problem for example this.",
                    "label": 0
                },
                {
                    "sent": "Word two vec very does this, and then the task is to predict which work will be in the middle, and you can use the this layer for correct and plug it in here and use that as the starting point, and then you're already forward to back.",
                    "label": 0
                },
                {
                    "sent": "It's much easier to generate lots of training data and from entities, and this is one way of how we can boost the performance, so not starting from random from something.",
                    "label": 0
                },
                {
                    "sent": "Maybe could you explain the principle of black backdrop?",
                    "label": 0
                },
                {
                    "sent": "This might be sort of.",
                    "label": 0
                },
                {
                    "sent": "The loss.",
                    "label": 0
                },
                {
                    "sent": "Maybe just one, maybe since you're short answer for already, can you show the evil example spiral?",
                    "label": 0
                },
                {
                    "sent": "So here we want to separate threads thoughts from blocks, right?",
                    "label": 0
                },
                {
                    "sent": "So you see, it's pretty unpleasant.",
                    "label": 0
                },
                {
                    "sent": "With.",
                    "label": 0
                },
                {
                    "sent": "These settings you won't be able to do much better.",
                    "label": 0
                },
                {
                    "sent": "Could be stronger in prison.",
                    "label": 0
                },
                {
                    "sent": "Still longer.",
                    "label": 0
                },
                {
                    "sent": "At other features.",
                    "label": 0
                },
                {
                    "sent": "The nondeterministic difference.",
                    "label": 0
                },
                {
                    "sent": "And a few more layers actually is very.",
                    "label": 0
                },
                {
                    "sent": "Very generous.",
                    "label": 0
                },
                {
                    "sent": "So doesn't mean that when you do something on this you really do like this.",
                    "label": 0
                },
                {
                    "sent": "You have feature your layers and then yeah, this is black magic.",
                    "label": 0
                },
                {
                    "sent": "Well these people do.",
                    "label": 0
                },
                {
                    "sent": "Puppy.",
                    "label": 0
                },
                {
                    "sent": "Anyway.",
                    "label": 0
                },
                {
                    "sent": "Which.",
                    "label": 0
                },
                {
                    "sent": "Same here.",
                    "label": 0
                },
                {
                    "sent": "It could be.",
                    "label": 0
                },
                {
                    "sent": "I mean, there's very some you there or something.",
                    "label": 0
                },
                {
                    "sent": "Busy.",
                    "label": 0
                },
                {
                    "sent": "Then you get some feeling, but there's lots of craft in training.",
                    "label": 0
                },
                {
                    "sent": "Switch back now.",
                    "label": 0
                },
                {
                    "sent": "So I think I think here the problem is the debt is how you how you nonlinear, so you need hundreds of layers to order two previous necessarily at your stuff enough there.",
                    "label": 0
                },
                {
                    "sent": "So the question was how many monkey are you try and so we can we can you can you can approximate any function with the neural network.",
                    "label": 0
                },
                {
                    "sent": "Just question is how many letters from any?",
                    "label": 0
                },
                {
                    "sent": "But also definitely trading deficit in order to function in this area.",
                    "label": 0
                },
                {
                    "sent": "We need to look at this neural networks and not not something outside whatever blush was saying before.",
                    "label": 0
                },
                {
                    "sent": "So whenever is just another function approximator.",
                    "label": 0
                },
                {
                    "sent": "So fancy now, however, it does everything.",
                    "label": 0
                },
                {
                    "sent": "Well, let's forget what we used to do and now this will solve at least once.",
                    "label": 0
                },
                {
                    "sent": "I mean all the participants around your metrics are exactly the same.",
                    "label": 0
                },
                {
                    "sent": "I mean, who had training testing an error?",
                    "label": 0
                },
                {
                    "sent": "Little great, I mean all these terms are still there, right?",
                    "label": 0
                },
                {
                    "sent": "We just we have different functional groups.",
                    "label": 0
                },
                {
                    "sent": "So this may be both in line with your question.",
                    "label": 0
                },
                {
                    "sent": "So how do we actually?",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now that we decided our model is this.",
                    "label": 0
                },
                {
                    "sent": "Metrics are this vector or something.",
                    "label": 0
                },
                {
                    "sent": "How do you find the best one?",
                    "label": 1
                },
                {
                    "sent": "Another question first is what do you mean by fast?",
                    "label": 1
                },
                {
                    "sent": "So we have kind of two parts.",
                    "label": 0
                },
                {
                    "sent": "One, we would want the model to work put value on the training set so even some loss function measuring the error or something on the training set.",
                    "label": 1
                },
                {
                    "sent": "We want to be as better good as possible and the other sense case we also found another way side both on the model to generalize well to unseen data.",
                    "label": 1
                },
                {
                    "sent": "So if you have something that was not in the training set.",
                    "label": 0
                },
                {
                    "sent": "The whole point was that we would also work well on that, and this is kind of two competing parts.",
                    "label": 0
                },
                {
                    "sent": "Now they go through each of them.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So first question is how to measure loss and with the general principle is we compare the model.",
                    "label": 1
                },
                {
                    "sent": "With the expected outputs.",
                    "label": 0
                },
                {
                    "sent": "So in our in the tensor flow before here this also, this points are expected outputs.",
                    "label": 0
                },
                {
                    "sent": "The color debate is our output and now we want to describe this relationship.",
                    "label": 0
                },
                {
                    "sent": "You want to describe this relationship.",
                    "label": 0
                },
                {
                    "sent": "With some function that we can optimize over though.",
                    "label": 0
                },
                {
                    "sent": "Preferably easily optimized and what your networks are doing is already is back propagation, so you can write all the equation down and do the stochastic gradient descent.",
                    "label": 0
                },
                {
                    "sent": "And this is one of my other purchasing check from work here.",
                    "label": 0
                },
                {
                    "sent": "So if you're doing this week.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And how do we measure loss?",
                    "label": 0
                },
                {
                    "sent": "So one straightforward, straightforward will say that.",
                    "label": 0
                },
                {
                    "sent": "If our prediction is the same as the training data prediction, then we say it's good, so there's no.",
                    "label": 0
                },
                {
                    "sent": "It's zero if the prediction is.",
                    "label": 0
                },
                {
                    "sent": "If the if the difference of declassification says.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Recover predictions is different than the training data size.",
                    "label": 0
                },
                {
                    "sent": "Then you count 1.",
                    "label": 0
                },
                {
                    "sent": "Now if we do that on the whole training data, we can write down into the equation.",
                    "label": 0
                },
                {
                    "sent": "And then this is something that we can go down and putting some optimization software in the figure and it would spit out the best F for this loss.",
                    "label": 0
                },
                {
                    "sent": "Another way of looking at this sheet so this hinge loss.",
                    "label": 1
                },
                {
                    "sent": "So here we say either our.",
                    "label": 0
                },
                {
                    "sent": "Our classifier is good and if it says if we take the output, it must be quite confident in the prediction as well as soon as it's not confident saying that it's not with the design of the function, but it has to be actually bigger than money for the confidence as soon as it's outside lower than this, we start applying penalty and the penalty linearly increase.",
                    "label": 0
                },
                {
                    "sent": "The bigger the misclassification is.",
                    "label": 0
                },
                {
                    "sent": "So this is called conditionals.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Another way of looking at it is maximum likelihood, so we are given a training data.",
                    "label": 1
                },
                {
                    "sent": "We have our model and then we can consider because ask ourself what's the likelihood of this data given this model?",
                    "label": 0
                },
                {
                    "sent": "OK, so for our output for our training data, but is there a likelihood of disease classification with a flexible to the outputs?",
                    "label": 0
                },
                {
                    "sent": "And the closer it is to the this is the training output, training input and the higher the likelihood of this is the happier we are.",
                    "label": 0
                },
                {
                    "sent": "Again, we can write it down as a function.",
                    "label": 0
                },
                {
                    "sent": "We can derive optimizing and so on so.",
                    "label": 0
                },
                {
                    "sent": "For today.",
                    "label": 0
                },
                {
                    "sent": "That's the general idea we want to capture the loss we want to capture the.",
                    "label": 0
                },
                {
                    "sent": "Property of the model to work well on the training data, as some optimizable function.",
                    "label": 1
                },
                {
                    "sent": "Then we optimize it by finding the most.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now the other problem is how do we ensure that we generalize well?",
                    "label": 1
                },
                {
                    "sent": "So let's say we are.",
                    "label": 0
                },
                {
                    "sent": "So before, so we likely to course.",
                    "label": 0
                },
                {
                    "sent": "Might be good.",
                    "label": 0
                },
                {
                    "sent": "Movie 6 is already obviously overheating and now with stand.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Be kind of welcome razors so we would like to find the simplest model possible that still produces good result.",
                    "label": 0
                },
                {
                    "sent": "Now the question is how to?",
                    "label": 0
                },
                {
                    "sent": "How do we define a simple?",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is we do usually by regularization, and regularization can be either.",
                    "label": 0
                },
                {
                    "sent": "Not directly included in the optimization function.",
                    "label": 0
                },
                {
                    "sent": "So in our case linear model, the norm of the vector, typically of the normal vector typically corresponds to the margin.",
                    "label": 0
                },
                {
                    "sent": "So how it's positioned over with respect to the training data and the smaller the smaller the the normal, the larger the margin.",
                    "label": 0
                },
                {
                    "sent": "So that's one way of shooting it.",
                    "label": 0
                },
                {
                    "sent": "Your networks you also do.",
                    "label": 0
                },
                {
                    "sent": "You will take your training data, take out a bit of a small set that you call validation, set and value optimizing on the training data and error will go down as we're getting more than one, we're approximately better and better.",
                    "label": 0
                },
                {
                    "sent": "At some point the validation set, so the one that is.",
                    "label": 0
                },
                {
                    "sent": "Part of the training set that is not used in the optimization.",
                    "label": 0
                },
                {
                    "sent": "The error there will start to increase.",
                    "label": 0
                },
                {
                    "sent": "Its OK if you got it here then maybe we have a very generalizable model.",
                    "label": 0
                },
                {
                    "sent": "For example.",
                    "label": 0
                },
                {
                    "sent": "Decision tree and then prune the branches to get a simpler model.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Enough.",
                    "label": 0
                },
                {
                    "sent": "Support vector machines, so because it's nicely German metric interpretation, so let's say we have a. Positives and negatives.",
                    "label": 1
                },
                {
                    "sent": "There are many possible models we can lines that we can drop them between them now, which one will be preferred and one approach is to say we want the one that produces maximum margin.",
                    "label": 0
                },
                {
                    "sent": "Now if you would put this link here then the margin so between the line and the nearest negative index positive example is quite small versus if you put the line like this it's quite the decryption.",
                    "label": 0
                },
                {
                    "sent": "Now the task comes down to we want to find the plane that.",
                    "label": 0
                },
                {
                    "sent": "First, it separates plus in using the maximum margin.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Write this down.",
                    "label": 0
                },
                {
                    "sent": "We get down to want to minimize the North of the model.",
                    "label": 0
                },
                {
                    "sent": "Given that we are classifying correctly, but this is not typically not possible because we have noise.",
                    "label": 0
                },
                {
                    "sent": "Assumes perfect supportability.",
                    "label": 0
                },
                {
                    "sent": "And then you can say OK, relax.",
                    "label": 0
                },
                {
                    "sent": "So we still want small normal, but we also small ones.",
                    "label": 0
                },
                {
                    "sent": "One small loss.",
                    "label": 0
                },
                {
                    "sent": "So this is this hinge loss before.",
                    "label": 0
                },
                {
                    "sent": "If you put these two together you basically get.",
                    "label": 0
                },
                {
                    "sent": "So much from the mother.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now the last part is how do we know we say?",
                    "label": 0
                },
                {
                    "sent": "Be.",
                    "label": 0
                },
                {
                    "sent": "But the data we representatives and how we train the model on it?",
                    "label": 0
                },
                {
                    "sent": "How good are we doing so?",
                    "label": 0
                },
                {
                    "sent": "There are three questions, kind of major questions we want to ask yourself.",
                    "label": 0
                },
                {
                    "sent": "So what is?",
                    "label": 0
                },
                {
                    "sent": "How do even tell?",
                    "label": 0
                },
                {
                    "sent": "How would we drink?",
                    "label": 0
                },
                {
                    "sent": "How can you be?",
                    "label": 0
                },
                {
                    "sent": "But we will measure.",
                    "label": 0
                },
                {
                    "sent": "Second question, how well do we have the model generalized?",
                    "label": 1
                },
                {
                    "sent": "The last one is is it better than other models?",
                    "label": 1
                },
                {
                    "sent": "So the last time goes in line with Canvas presented today.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Or how to quantify model performance?",
                    "label": 1
                },
                {
                    "sent": "So typically they would.",
                    "label": 1
                },
                {
                    "sent": "If you kept up bunch of evaluation metrics for different types of problems.",
                    "label": 0
                },
                {
                    "sent": "Depends on the problem.",
                    "label": 0
                },
                {
                    "sent": "Also, transportation be measured differently than regression.",
                    "label": 1
                },
                {
                    "sent": "And also depends a lot on the domain and what is actually cause.",
                    "label": 1
                },
                {
                    "sent": "There have been some domains.",
                    "label": 0
                },
                {
                    "sent": "We don't care if if we find more like positive examples, but really don't want to miss anybody some other domain.",
                    "label": 0
                },
                {
                    "sent": "So different types of wrong answers called different amount of cost plus cost, different amount of money and maybe we would factor related according to this or how much money we are losing that we're making even the mother.",
                    "label": 0
                },
                {
                    "sent": "So this is really specific and it's easy for a supervised it's easier models.",
                    "label": 0
                },
                {
                    "sent": "Account created, nothing else where we are given explicit outputs that we want.",
                    "label": 0
                },
                {
                    "sent": "Which might be noisy as soon as they're kind of high quality and it gets quite hard for unsupervised problems 'cause it's given to different clusterings.",
                    "label": 0
                },
                {
                    "sent": "Traffic televisions better without some good.",
                    "label": 0
                },
                {
                    "sent": "They're coming of age to qualify better.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "An example for binary classification, but we typically measure, so we have a prediction.",
                    "label": 1
                },
                {
                    "sent": "We have the truth table and then we can each instance.",
                    "label": 0
                },
                {
                    "sent": "Can be positioned into rolling stuff with the test set, which probably several 100, except it has to be simple.",
                    "label": 0
                },
                {
                    "sent": "We check for each element from the test set, which are the prediction.",
                    "label": 1
                },
                {
                    "sent": "We check the actual label and we see 2 positive means that they are.",
                    "label": 0
                },
                {
                    "sent": "They both agree to negative means they go for grip on the negative class.",
                    "label": 1
                },
                {
                    "sent": "Then you have false negative false positive which is kind of.",
                    "label": 0
                },
                {
                    "sent": "The different types of mistake, and from this we can get to the kind of basic classification measure.",
                    "label": 0
                },
                {
                    "sent": "So one is precision.",
                    "label": 1
                },
                {
                    "sent": "Precision tells you from all the positive ones how T. Or are they.",
                    "label": 0
                },
                {
                    "sent": "So how many of the massive positives are actually positives?",
                    "label": 0
                },
                {
                    "sent": "Another one is very cold, so from all the positives, how many degree dentify?",
                    "label": 0
                },
                {
                    "sent": "So these are kind of usually you get high precision but just classifying everything was negative was that it didn't make any any.",
                    "label": 0
                },
                {
                    "sent": "Mistake, we just be very Conservative and Liberal.",
                    "label": 0
                },
                {
                    "sent": "Few positive, but then it gets very lonely cold and vice versa.",
                    "label": 0
                },
                {
                    "sent": "You can always label everything positive, having terrible precision and a very good report.",
                    "label": 0
                },
                {
                    "sent": "And then one way of combining this is called F1 measure which is geometric mean.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Another way of looking at the model models is this RC cards.",
                    "label": 0
                },
                {
                    "sent": "So the idea here is that we computed two characteristics for each model, so one is this true positive rate which is a.",
                    "label": 1
                },
                {
                    "sent": "So I know how many.",
                    "label": 1
                },
                {
                    "sent": "So many positives to be fined and false positive rates is how many false negatives?",
                    "label": 0
                },
                {
                    "sent": "How many negatives to be put in the politics classes very well?",
                    "label": 0
                },
                {
                    "sent": "We did them.",
                    "label": 0
                },
                {
                    "sent": "And if you.",
                    "label": 0
                },
                {
                    "sent": "Optimal position would be here, and the random would be kind of District 2.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And what is nice is if you have some lots of models and we have some confidence.",
                    "label": 0
                },
                {
                    "sent": "Suppose we could take the predictions sorted by the office and scores and then slowly as we increase the threshold.",
                    "label": 0
                },
                {
                    "sent": "Threshold for where we say something is positive.",
                    "label": 0
                },
                {
                    "sent": "So we start here everything being zero, and so we jump up and go up there.",
                    "label": 0
                },
                {
                    "sent": "And the better the model, the most deep discoveries.",
                    "label": 0
                },
                {
                    "sent": "You cannot do this if your mother doesn't have the confidence right.",
                    "label": 0
                },
                {
                    "sent": "Mother fucker.",
                    "label": 0
                },
                {
                    "sent": "You just need to get some samples.",
                    "label": 0
                },
                {
                    "sent": "Existing next weekend, something modern.",
                    "label": 0
                },
                {
                    "sent": "Season 3",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Progression.",
                    "label": 0
                },
                {
                    "sent": "See, these are the measurements.",
                    "label": 0
                },
                {
                    "sent": "This is the model rule.",
                    "label": 0
                },
                {
                    "sent": "Check how far the much measurement is and then we have other means.",
                    "label": 0
                },
                {
                    "sent": "Carrera should be some dispense with the user receivables control, confidence and determination which we do.",
                    "label": 0
                },
                {
                    "sent": "That and it ends on which tells us how well they behaves.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now the question two was how well do we generalize?",
                    "label": 0
                },
                {
                    "sent": "So for generalization, so one rule so that we have to be always very careful about never test from trimmings training data.",
                    "label": 0
                },
                {
                    "sent": "This is conducive.",
                    "label": 0
                },
                {
                    "sent": "It gives full sense, false sense of performance and the model.",
                    "label": 0
                },
                {
                    "sent": "It doesn't tell you much, so it's always good to.",
                    "label": 0
                },
                {
                    "sent": "Split if you have the training.",
                    "label": 1
                },
                {
                    "sent": "A lot of Liberator disputed existing turning data in training and test parts.",
                    "label": 0
                },
                {
                    "sent": "We train on the training part and then compute the valuation measures of the test part.",
                    "label": 1
                },
                {
                    "sent": "And it's kind of sounds straightforward, but it's always.",
                    "label": 0
                },
                {
                    "sent": "Holistic and always very easy.",
                    "label": 1
                },
                {
                    "sent": "There's some information on the training data.",
                    "label": 0
                },
                {
                    "sent": "Would look into the test.",
                    "label": 0
                },
                {
                    "sent": "Set one up if you have a.",
                    "label": 0
                },
                {
                    "sent": "Stream of particles newsarticles in time.",
                    "label": 0
                },
                {
                    "sent": "And you would randomly split in training and test and then do topic classification of those.",
                    "label": 0
                },
                {
                    "sent": "Then it's a bit unfair.",
                    "label": 0
                },
                {
                    "sent": "It was maybe artikkel.",
                    "label": 0
                },
                {
                    "sent": "We will use the model.",
                    "label": 0
                },
                {
                    "sent": "In reality is you have the past data you train on and then you apply it in the future articles.",
                    "label": 0
                },
                {
                    "sent": "So you have to do this time wise place of your entity or curse in the future.",
                    "label": 0
                },
                {
                    "sent": "If you want to handle it fell around as well and this kind of random script will not work well.",
                    "label": 0
                },
                {
                    "sent": "Also feature extraction is running, so you're doing the TF IDF for some weighting scheme on the documents.",
                    "label": 0
                },
                {
                    "sent": "Do you want to do it only on the training set, not from the combination of everything, because it's so again here.",
                    "label": 0
                },
                {
                    "sent": "So it's always good to another difficult rule of thumb.",
                    "label": 0
                },
                {
                    "sent": "If you run your algorithm, you test it.",
                    "label": 0
                },
                {
                    "sent": "You get a very good result.",
                    "label": 0
                },
                {
                    "sent": "The first question should always be but very in-depth training data linking to the testing for the test data leading to the training process, so this is.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And how do we get confidence about it so when easy way of obtaining multiple metrics from the same training data is to do something called cross validation?",
                    "label": 1
                },
                {
                    "sent": "And the idea here is that we instead of doing last month train Pass Street, you can do many tenfold cost reductions on standard thing.",
                    "label": 0
                },
                {
                    "sent": "And that's where you get more number of metrics is and then you can start doing some statistical tests and therefore significance significance and one extreme of that would be leave one out very quickly, take all the training data, remove an example training and test it on the one piece.",
                    "label": 0
                },
                {
                    "sent": "One example.",
                    "label": 0
                },
                {
                    "sent": "And you do this for each individual example for this can be quite possible.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And now the last question is, is a trained model?",
                    "label": 0
                },
                {
                    "sent": "Is it better than what the literature says about this type of problems?",
                    "label": 1
                },
                {
                    "sent": "And typical approach would be so this goes in line against with statistics from before we have to models F1F2.",
                    "label": 0
                },
                {
                    "sent": "Can you tell which is better?",
                    "label": 1
                },
                {
                    "sent": "We compute valuation metrics on a different speeds of train test.",
                    "label": 1
                },
                {
                    "sent": "And because the Hippocrates, do they have the same mean?",
                    "label": 0
                },
                {
                    "sent": "This would be an example of the test.",
                    "label": 0
                },
                {
                    "sent": "This permutation test channel showing before the thing would be, but the two sets drawn from the same distribution or not so.",
                    "label": 1
                },
                {
                    "sent": "They have tested that and this is something that we can then say to models are statistically different.",
                    "label": 0
                },
                {
                    "sent": "They produced super different output and one is better because it has a higher need for examples.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's it.",
                    "label": 0
                }
            ]
        }
    }
}