{
    "id": "e64mbdindb4aobloft23dmkpcyzq2dzl",
    "title": "Improving Multi-label Learning with Missing Labels by Structured Semantic Correlations",
    "info": {
        "author": [
            "Hao Yang, Nanyang Technological University"
        ],
        "published": "Oct. 24, 2016",
        "recorded": "October 2016",
        "category": [
            "Top->Computer Science->Computer Vision"
        ]
    },
    "url": "http://videolectures.net/eccv2016_yang_semantic_correlations/",
    "segmentation": [
        [
            "Hello everyone, my name is how young today I'm going to introduce our work on multi label learning.",
            "The title is improving multi label learning with missing labels by structural similarity, semantic correlation."
        ],
        [
            "Nowadays multilabel images are actually everywhere.",
            "Technically, all images can be assigned with multiple labels or tags.",
            "This will give us several metrics or just simple labels.",
            "For example, it gives us better understanding for the image.",
            "Here for this image we can."
        ],
        [
            "Just give a single label such as talk or we can."
        ],
        [
            "Give multiple labels.",
            "Such as talk chair, carpet, indoor Hifi, pad, funny, etc.",
            "Clearly the letter one will give us a more comprehensive description of the image."
        ],
        [
            "Secondly, multiple labels will always provide us more conveniency for possible natural language related applications."
        ],
        [
            "Such as image captioning or visual question answering.",
            "An early oh sorry.",
            "ILY."
        ],
        [
            "Cause us to achieve actually achieve images more more efficiently."
        ],
        [
            "This is moistly.",
            "It is actually."
        ],
        [
            "People already can use.",
            "Flicker, like Freak out, already implemented the assistant with this kind of multi label learning.",
            "Sorry, there's something wrong with her, I think.",
            "So as I shown here, multi label learning provides us many possibilities, but it also poses many challenges.",
            "These challenges can be casting in two folds first."
        ],
        [
            "And this is feature extraction.",
            "Unlike single image classification, where we can use a global kind of image feature for multi label images will usually have multiple objects in multiple locations, category and sizes in the image.",
            "So both global and local level features are important.",
            "This is discussing our CPR paper, but more importantly the challenges are related to labels required for large label space.",
            "That we that would cause troubles for large scale chaining an inferring.",
            "And we also could have noisy labels and missing label problems.",
            "In this paper we mainly deal with the missing label problems."
        ],
        [
            "This problem actually is inevitable for multi label recognition problem as the label space could be large and there exists ambiguity among labels.",
            "Take this image example.",
            "Users or label us can assign this tax or label."
        ],
        [
            "As to this image, like animal Clouds, Plantlife, Sky and water.",
            "But we could easily like add more labels today."
        ],
        [
            "Image for example like Grass, Green Lake, landscape, reindeer etc.",
            "So as the missing label problem."
        ],
        [
            "It's very essential to multi label learning problem.",
            "Many works has been proposed to deal with this problem.",
            "There are many free kinds of correlations can be used to solve this problem.",
            "The first correlation is instant label correlation.",
            "Actually, this is essential for all kind of classification problem.",
            "Of course, the second and third correlations are label label correlation.",
            "An instance instance instance correlation.",
            "These two correlations are especially important for missing label problem as exploit deeper knowledge of the data.",
            "But most exciting existing words either only consider linear correlation.",
            "All is inefficient for large scale label matrix.",
            "In fact, this code."
        ],
        [
            "Nations are all structure."
        ],
        [
            "And we should take into take this structure correlate."
        ],
        [
            "Translations into account to in solving the problem.",
            "For example, for the label label correlations we could use knowledge graph or hierarchical tree graph to model the structure correlation.",
            "Actually the EC 2014 best paper done just paper already showed that this kind of correlation can be helpful for multiclass classification and for instance."
        ],
        [
            "Distance correlation nearest neighbor graph can be used to model the structural correlations, and this is also shown to be very useful.",
            "As this."
        ],
        [
            "Structural correlations are essential and important in the multi label learning multi label learning problem we want to formulate the problem so that we can exploit this structure correlations, especially in our case instance instance correlation if in an efficient way."
        ],
        [
            "Our simple intuition here is to make use of semantic correlations between images so that we can capture the structure, instance, instance correlation.",
            "Our assumption is that semantically similar images should share similar labels.",
            "If we can capture the similarity in semantic space, then we should we should be able to model and capture the structural correlations well now, but they have two problems.",
            "How can I?",
            "How can we define a good semantic representation and how can we construct a graph and incorporate it efficiently and effectively?"
        ],
        [
            "For solving the first problem, we propose semantic feature extraction pipeline, which consists of two parts.",
            "The first part is a global semantic feature and the second part is a local semantic feature.",
            "For the globe."
        ],
        [
            "Feature it is extracted.",
            "It is extracted from relevant visual concepts of large scale datasets, such as SVC or places data set.",
            "So basically we use the classification scores from this data sets and use a simple unsupervised feature selection techniques to filter out all the noisy visual concepts.",
            "Discuss descriptor."
        ],
        [
            "Essentially describe what is the image in general according to a large number of visual concepts developed in the general large scale data set.",
            "The second part of our semantic descriptor."
        ],
        [
            "It's a local semantic descriptor which are generating from Parrish Eric, pulling all the labels of its visual neighbors.",
            "As you can see from this example here.",
            "Of the other region neighbors share kind of overlapping similar labels with with our query image.",
            "So this kind of."
        ],
        [
            "Local semantic descriptor give."
        ],
        [
            "Thus, a description of what does the image look like specifically?",
            "By combining these two descriptors, we can effectively project the images into a semantic space."
        ],
        [
            "An we can construct a nearest neighbor graph as I shown before of the semantic representations.",
            "Then we can incorporate structure instance, instance, correlation with Laplacian regularization as shown in many related works.",
            "Sorry for the mess up of the equation is basically a trace trace norm of the cost model of the class model, the training instances and graph Laplacian.",
            "And in this frame, well, actually we can easily add in label label correlation if suitable graph is given.",
            "For example, maybe the knowledge maybe knowledge graph.",
            "Maybe some learn graph of label label correlation.",
            "Inca."
        ],
        [
            "Conclusion This is our system architect.",
            "For all the images, for the if we are given images, training images with missing labels, we project him into two space.",
            "The first space is a standard feature space we can use CN CN, such as VG 16 to book written in the feature space and use it use this feature to model low rank regularization.",
            "An classification loss.",
            "The second string of our architecture is to protect these images into a semantic space.",
            "By the semantic feature we just discuss and this is used to model the semantic structure correlations.",
            "By effectively combining these two parts, we can achieve satisfactory results."
        ],
        [
            "Actually, when the observed labor rate is very low.",
            "And one important aspect of our formulation is that since we are, we optimizing on the class classification model M instead of just simply optimizing on the label matrix Y.",
            "Our system is actually very effective and can be applied to large scale applications.",
            "We test our system in four standard multi label learning data set, Flickr 25 K Pascal VLC 2007 SP game and the IP RTC 12.",
            "We also we compare with four baseline methods."
        ],
        [
            "Basically they are one.",
            "One method that is proposing I say Mail 2013.",
            "One method is the system without."
        ],
        [
            "Without the semantic space path and one method."
        ],
        [
            "Is.",
            "Just fine tuning about that.",
            "Well, we've available labels and the other method is also finding in network with the least square loss.",
            "We have shown that our method actually achieve best results across different observe race as shown here, the X axis is the observe label Ray.",
            "Especially when the observer rates very low like 10%."
        ],
        [
            "We achieve a significant performance boosts there that's all for my presentation.",
            "Welcome to our poster an I can answer your question in detail, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hello everyone, my name is how young today I'm going to introduce our work on multi label learning.",
                    "label": 0
                },
                {
                    "sent": "The title is improving multi label learning with missing labels by structural similarity, semantic correlation.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Nowadays multilabel images are actually everywhere.",
                    "label": 0
                },
                {
                    "sent": "Technically, all images can be assigned with multiple labels or tags.",
                    "label": 1
                },
                {
                    "sent": "This will give us several metrics or just simple labels.",
                    "label": 1
                },
                {
                    "sent": "For example, it gives us better understanding for the image.",
                    "label": 0
                },
                {
                    "sent": "Here for this image we can.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just give a single label such as talk or we can.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Give multiple labels.",
                    "label": 0
                },
                {
                    "sent": "Such as talk chair, carpet, indoor Hifi, pad, funny, etc.",
                    "label": 1
                },
                {
                    "sent": "Clearly the letter one will give us a more comprehensive description of the image.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Secondly, multiple labels will always provide us more conveniency for possible natural language related applications.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Such as image captioning or visual question answering.",
                    "label": 1
                },
                {
                    "sent": "An early oh sorry.",
                    "label": 0
                },
                {
                    "sent": "ILY.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Cause us to achieve actually achieve images more more efficiently.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is moistly.",
                    "label": 0
                },
                {
                    "sent": "It is actually.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "People already can use.",
                    "label": 0
                },
                {
                    "sent": "Flicker, like Freak out, already implemented the assistant with this kind of multi label learning.",
                    "label": 0
                },
                {
                    "sent": "Sorry, there's something wrong with her, I think.",
                    "label": 0
                },
                {
                    "sent": "So as I shown here, multi label learning provides us many possibilities, but it also poses many challenges.",
                    "label": 1
                },
                {
                    "sent": "These challenges can be casting in two folds first.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And this is feature extraction.",
                    "label": 0
                },
                {
                    "sent": "Unlike single image classification, where we can use a global kind of image feature for multi label images will usually have multiple objects in multiple locations, category and sizes in the image.",
                    "label": 0
                },
                {
                    "sent": "So both global and local level features are important.",
                    "label": 1
                },
                {
                    "sent": "This is discussing our CPR paper, but more importantly the challenges are related to labels required for large label space.",
                    "label": 0
                },
                {
                    "sent": "That we that would cause troubles for large scale chaining an inferring.",
                    "label": 0
                },
                {
                    "sent": "And we also could have noisy labels and missing label problems.",
                    "label": 0
                },
                {
                    "sent": "In this paper we mainly deal with the missing label problems.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This problem actually is inevitable for multi label recognition problem as the label space could be large and there exists ambiguity among labels.",
                    "label": 1
                },
                {
                    "sent": "Take this image example.",
                    "label": 0
                },
                {
                    "sent": "Users or label us can assign this tax or label.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As to this image, like animal Clouds, Plantlife, Sky and water.",
                    "label": 0
                },
                {
                    "sent": "But we could easily like add more labels today.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Image for example like Grass, Green Lake, landscape, reindeer etc.",
                    "label": 0
                },
                {
                    "sent": "So as the missing label problem.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It's very essential to multi label learning problem.",
                    "label": 0
                },
                {
                    "sent": "Many works has been proposed to deal with this problem.",
                    "label": 1
                },
                {
                    "sent": "There are many free kinds of correlations can be used to solve this problem.",
                    "label": 0
                },
                {
                    "sent": "The first correlation is instant label correlation.",
                    "label": 0
                },
                {
                    "sent": "Actually, this is essential for all kind of classification problem.",
                    "label": 0
                },
                {
                    "sent": "Of course, the second and third correlations are label label correlation.",
                    "label": 1
                },
                {
                    "sent": "An instance instance instance correlation.",
                    "label": 1
                },
                {
                    "sent": "These two correlations are especially important for missing label problem as exploit deeper knowledge of the data.",
                    "label": 0
                },
                {
                    "sent": "But most exciting existing words either only consider linear correlation.",
                    "label": 0
                },
                {
                    "sent": "All is inefficient for large scale label matrix.",
                    "label": 1
                },
                {
                    "sent": "In fact, this code.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Nations are all structure.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we should take into take this structure correlate.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Translations into account to in solving the problem.",
                    "label": 0
                },
                {
                    "sent": "For example, for the label label correlations we could use knowledge graph or hierarchical tree graph to model the structure correlation.",
                    "label": 1
                },
                {
                    "sent": "Actually the EC 2014 best paper done just paper already showed that this kind of correlation can be helpful for multiclass classification and for instance.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Distance correlation nearest neighbor graph can be used to model the structural correlations, and this is also shown to be very useful.",
                    "label": 0
                },
                {
                    "sent": "As this.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Structural correlations are essential and important in the multi label learning multi label learning problem we want to formulate the problem so that we can exploit this structure correlations, especially in our case instance instance correlation if in an efficient way.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Our simple intuition here is to make use of semantic correlations between images so that we can capture the structure, instance, instance correlation.",
                    "label": 1
                },
                {
                    "sent": "Our assumption is that semantically similar images should share similar labels.",
                    "label": 1
                },
                {
                    "sent": "If we can capture the similarity in semantic space, then we should we should be able to model and capture the structural correlations well now, but they have two problems.",
                    "label": 0
                },
                {
                    "sent": "How can I?",
                    "label": 0
                },
                {
                    "sent": "How can we define a good semantic representation and how can we construct a graph and incorporate it efficiently and effectively?",
                    "label": 1
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For solving the first problem, we propose semantic feature extraction pipeline, which consists of two parts.",
                    "label": 0
                },
                {
                    "sent": "The first part is a global semantic feature and the second part is a local semantic feature.",
                    "label": 1
                },
                {
                    "sent": "For the globe.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Feature it is extracted.",
                    "label": 0
                },
                {
                    "sent": "It is extracted from relevant visual concepts of large scale datasets, such as SVC or places data set.",
                    "label": 1
                },
                {
                    "sent": "So basically we use the classification scores from this data sets and use a simple unsupervised feature selection techniques to filter out all the noisy visual concepts.",
                    "label": 0
                },
                {
                    "sent": "Discuss descriptor.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Essentially describe what is the image in general according to a large number of visual concepts developed in the general large scale data set.",
                    "label": 0
                },
                {
                    "sent": "The second part of our semantic descriptor.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's a local semantic descriptor which are generating from Parrish Eric, pulling all the labels of its visual neighbors.",
                    "label": 0
                },
                {
                    "sent": "As you can see from this example here.",
                    "label": 0
                },
                {
                    "sent": "Of the other region neighbors share kind of overlapping similar labels with with our query image.",
                    "label": 0
                },
                {
                    "sent": "So this kind of.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Local semantic descriptor give.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thus, a description of what does the image look like specifically?",
                    "label": 0
                },
                {
                    "sent": "By combining these two descriptors, we can effectively project the images into a semantic space.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "An we can construct a nearest neighbor graph as I shown before of the semantic representations.",
                    "label": 0
                },
                {
                    "sent": "Then we can incorporate structure instance, instance, correlation with Laplacian regularization as shown in many related works.",
                    "label": 1
                },
                {
                    "sent": "Sorry for the mess up of the equation is basically a trace trace norm of the cost model of the class model, the training instances and graph Laplacian.",
                    "label": 0
                },
                {
                    "sent": "And in this frame, well, actually we can easily add in label label correlation if suitable graph is given.",
                    "label": 1
                },
                {
                    "sent": "For example, maybe the knowledge maybe knowledge graph.",
                    "label": 0
                },
                {
                    "sent": "Maybe some learn graph of label label correlation.",
                    "label": 0
                },
                {
                    "sent": "Inca.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Conclusion This is our system architect.",
                    "label": 0
                },
                {
                    "sent": "For all the images, for the if we are given images, training images with missing labels, we project him into two space.",
                    "label": 1
                },
                {
                    "sent": "The first space is a standard feature space we can use CN CN, such as VG 16 to book written in the feature space and use it use this feature to model low rank regularization.",
                    "label": 0
                },
                {
                    "sent": "An classification loss.",
                    "label": 0
                },
                {
                    "sent": "The second string of our architecture is to protect these images into a semantic space.",
                    "label": 1
                },
                {
                    "sent": "By the semantic feature we just discuss and this is used to model the semantic structure correlations.",
                    "label": 0
                },
                {
                    "sent": "By effectively combining these two parts, we can achieve satisfactory results.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Actually, when the observed labor rate is very low.",
                    "label": 0
                },
                {
                    "sent": "And one important aspect of our formulation is that since we are, we optimizing on the class classification model M instead of just simply optimizing on the label matrix Y.",
                    "label": 0
                },
                {
                    "sent": "Our system is actually very effective and can be applied to large scale applications.",
                    "label": 0
                },
                {
                    "sent": "We test our system in four standard multi label learning data set, Flickr 25 K Pascal VLC 2007 SP game and the IP RTC 12.",
                    "label": 0
                },
                {
                    "sent": "We also we compare with four baseline methods.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Basically they are one.",
                    "label": 0
                },
                {
                    "sent": "One method that is proposing I say Mail 2013.",
                    "label": 0
                },
                {
                    "sent": "One method is the system without.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Without the semantic space path and one method.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is.",
                    "label": 0
                },
                {
                    "sent": "Just fine tuning about that.",
                    "label": 0
                },
                {
                    "sent": "Well, we've available labels and the other method is also finding in network with the least square loss.",
                    "label": 0
                },
                {
                    "sent": "We have shown that our method actually achieve best results across different observe race as shown here, the X axis is the observe label Ray.",
                    "label": 0
                },
                {
                    "sent": "Especially when the observer rates very low like 10%.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We achieve a significant performance boosts there that's all for my presentation.",
                    "label": 0
                },
                {
                    "sent": "Welcome to our poster an I can answer your question in detail, thank you.",
                    "label": 0
                }
            ]
        }
    }
}