{
    "id": "4vtnyjui7sgvmeg7rnbvspgqmtgtf65s",
    "title": "A Systematic Investigation of Explicit and Implicit Schema Information on the Linked Open Data Cloud",
    "info": {
        "introducer": [
            "Olaf Hartig, Hasso-Plattner-Institute, University of Potsdam"
        ],
        "author": [
            "Thomas Gottron, Institute for Web Science and Technologies (WeST), University of Koblenz-Landau"
        ],
        "published": "July 8, 2013",
        "recorded": "May 2013",
        "category": [
            "Top->Computer Science->Semantic Web",
            "Top->Computer Science->Big Data"
        ]
    },
    "url": "http://videolectures.net/eswc2013_gottron_cloud/",
    "segmentation": [
        [
            "So what we did was this systematic investigation of explicit and implicit schema information on the linked open Data Cloud, which probably explains also why I had the question related to schema information of the previous talk.",
            "But before I start going into the analysis, I think I might have to tell you what we consider explicit and implicit schema information, because we have heard so much about it in the last days saying that well, actually there is not really a schema in linked data or in semantic data, and it should be flexible.",
            "So what do we mean with schema information in this case?"
        ],
        [
            "Um, basically catching up with my previous presenter was talking about we consider explicit schema information.",
            "If you're assigning a type class to some resource, some entity that you're modeling in linked data 'cause they explicitly say this is something of a certain type.",
            "On the other hand, you have linked data.",
            "You have the option that you can just.",
            "Model things by their attributes.",
            "You don't have to provide a type, so you implicitly describe the entities, but just saying which attributes they have, which properties.",
            "Now the world is not black and white.",
            "You don't have either or and typically you will find both of these things together, so you will model entities, giving them both set of types and a set of properties.",
            "So in the example that I have put up here, we've got something that is a document of type document of type in proceedings and we also have something that some properties to tell us about the creator linking it to another UI and attaching a literal wire DC title property.",
            "So of course these things are not entirely independent.",
            "You can say it's quite obvious, or you could expect that if you have a document that this document has an author, it has a creator or it has a title, and vice versa.",
            "If you see something that has a title and it has a creator, you could also expect that this is very likely.",
            "A document might even be something that of the type in proceedings.",
            "So what we have here is we have some kind of redundancy in this explicit and implicit schema information, and that is something that is quite interesting.",
            "Because in the few that I am currently working on that is, schema extraction from linked data and we're building a schema level index that allows you to efficiently and very fast look up data based on the schema information in an index.",
            "So as these indexes based on schema information from you, I was wondering well if there is so much redundancy.",
            "Or maybe I can use that to compress the schema information and in that way also compress my index.",
            "There are also some other people that are actually curious about the results here.",
            "Got some colleagues that are working on supporting linked data engineers that are modeling their data and if they start describing the data attaching some types they might want to get some recommendations of what would be good properties to attach to and not just properties coming out of an ontology, but just properties.",
            "Also, how are they actually used in which combination on the link data cloud?",
            "Because that is vocabulary use.",
            "Reuse in a very good way.",
            "So there are several people that were interested in this and that led us to the question, well, to which degree do we have redundancy among this schema information?",
            "And effectively we ended up actually even wondering.",
            "Well, how can we measure that?",
            "How can we measure the redundancy between these two things?",
            "And that led us to formulate four question."
        ],
        [
            "That I'm going to present you hear.",
            "The first question was really, how much information is actually encoded in a type set or a property set of these attached to a single resource?",
            "And if you don't take it one step further, that is the next question.",
            "Well, assume that I already know of which type of resources.",
            "How much does that tell me about the properties or vice versa?",
            "That is the third question.",
            "If I tell you what are the properties, how much does that tell me about the types?",
            "And finally, that is really the question about redundancy.",
            "To which degree can one information one schema information?",
            "Either the types or the properties explain the respective other.",
            "So with these four questions in mind, I'm going."
        ],
        [
            "To take you through this talk, starting from these questions, the first thing that I will tell you now about how we arrived in or how we did our analysis is actually to see how did we model schema information in a suitable way so that we could analyze it towards the questions that we wanted to answer.",
            "And the second thing then is I'm going to tell you about information measures and 3D information theoretic measures that we are applying here and why they are suitable.",
            "Actually, to answer these questions, once we have developed them, we apply them on some linked open data later sets, and I'm coming out of there and hopefully can give you some answers that are going to satisfy you as we have several questions now in the talk.",
            "Actually, the last part I will go through it repeatedly, answering each of these questions.",
            "Alright."
        ],
        [
            "So let's start how do we model the data?",
            "The Information schema information data I already told you what are explicit and implicit schema information that we are really referring to.",
            "So what we did is we modeled this as a joint distribution of the typesets on of the property sets that you observe together with the resources.",
            "So this probability PTR is the probability of a resource having a particular set of class types.",
            "That's the tea, and it can be many or several.",
            "Types and at the same time to have a certain set of properties.",
            "As this is a bit abstract and the dinner yesterday was late and now it is shortly before lunch, I will give you a toy and mock up example to explain what I'm talking about.",
            "So this is a very very small.",
            "As I said, made up joint distribution of type and property sets.",
            "So if I take a look in one of these cells here, I have picked up one.",
            "This means that I have a probability of 8% that one of the resources in the data set that I am analyzing is actually having.",
            "A typeset T1 which, as I said, can be several types.",
            "It's a set, so picking up the example of before, maybe that is really just the in proceedings and the document and at the same time whoops wrong direction.",
            "It has a set of properties, so here maybe the Creator and the title.",
            "The other thing that you see here at the side, these are the marginal distribution, so this is the aggregation over the two dimensions and one of them gives us then just the distribution of the type sets and the other one is the distribution of the property sets and we will make use of these as well.",
            "OK, so this is a probability model, the question is."
        ],
        [
            "How do we estimate these probabilities?",
            "So what we actually have to do, and as we want to do it also for linked data and linked open data, we actually have to determine schema use as I have presented it to you.",
            "And then we also have to aggregate over all the individual resources that we have observed and so that can be quite a data in sentense if task.",
            "Now if you have paid attention or if you have come to my demo session then you might remember from the beginning of the talk that I actually I'm working on schema level indexes and we've got a schema level index.",
            "That is quite easy and quite efficient to compute on large datasets.",
            "So what we did here for estimating probabilities will simply run our construct.",
            "Our schema index, run it over the datasets that we're working with, and then we just query the index and ask well how many instances do we find in these datasets that have a certain type set in a certain property set.",
            "Which datasets did we use?",
            "We re used the billion triple Challenge data set from last year for a particular reason, because this data set is subdivided in segments that correspond to specific parts of the crawl that were used to collect data from the linked data cloud.",
            "So here we have different areas of the link data cloud covered to different extent and these datasets also have different characteristics.",
            "For example, you can see that the sizes varying between 20,000,000 triples and 900 million triples, and when it comes to the typesets and.",
            "Property sets that we are interested in here.",
            "You also have quite a wide range between for the smallest rest data set.",
            "800 Type sets an hour, roughly 800 and roughly 8000 property sets up to more than a million typesets for DB pedia and 400,000 property sets that we observed here.",
            "OK so.",
            "Now we are able to handle the data to create this joint distribution.",
            "To estimate this joint distribution that we are interested in.",
            "Let's address."
        ],
        [
            "Question question A was how much information is encoded in a type set or the property set of a resource.",
            "Now I already told you we are interested in information, so we're going into information theoretic measures and in that case you're automatically end up with entropy.",
            "Now as we have let's say.",
            "Different dimensions, not different dimension, different size of observations that we can make their very different numbers for the types into property sets and we want to be able to compare these things of it.",
            "That's why we went for a normalized version of entropy.",
            "And we're here considering first the entropy of the marginal distributions, because we're just interested in the types and the properties so far not in the joint distribution and how they appear together again, as this is a bit very dry and I'm trying to give you an example.",
            "Starting again with toy examples, so this is the marginal distribution of the property sets that I had made up, and you see here that the probabilities are relatively equally distributed.",
            "There is just one property centered in speaking a bit out, and this leads to a relatively high normalized entropy closed one, which means that there is in the property sets quite some information encoded.",
            "If you have a different behavior where one or in this case just or a few if you have more than the toy example just one property set that is dominating, it is basically collecting all the resources, then you get a very low normalized entropy close to 0.",
            "And just to show you really, what is the extreme case if everything is equally likely, then we would get a normalized entropy of 1 zero.",
            "This is the toy example.",
            "How does it look on the actual data that we analyzed?"
        ],
        [
            "I have summarized here.",
            "You can see for our five segments of the Building Triple Challenge data set.",
            "What is the normalized entropy over the type sets, and what is the normalized entropy over the property sets?",
            "Now there's some tendencies that we can observe in here.",
            "The first one is that.",
            "In most of these cases, we are actually observing that the entropy of the proper set property sets is higher than the one of the typesets, which means that the property sets actually tell us more about the resources.",
            "There are more suitable to identify them if you want to say it like this, we just had one case that is the day to have part of the building.",
            "Triple Challenge data set there it was the other way around, which might be due to the fact that this is really a collection of many many many different datasets.",
            "Furthermore, we had no really high values, so things are not equally distributed.",
            "Neither.",
            "We had values that are really close to 0, so neither we have just a very few combinations of properties and types that are, let's say, dominating everything else in the data.",
            "Alright."
        ],
        [
            "The next questions that we had.",
            "So here we were wondering how much information is still encoded in the properties once that we know the types of resource and vice versa.",
            "So as I already indicated here, we have some given knowledge and that takes us to conditional probabilities.",
            "Now there is also things such as conditional entropy and the one measure that we identified here to be really what we wanted is the expected conditional entropy.",
            "If you take a look at the last part of the formula, this is the entropy formula for a given type set in this case, and the entropy that then remains in the properties and this is aggregated and weighted by.",
            "Actually the probabilities of observing the type set that we have assumed as given.",
            "So.",
            "In a way of speaking, we can say this is the entropy that gives us the entropy we can expect if we know the types.",
            "Let me take you again through my toy exam."
        ],
        [
            "So, so that you might get that idea again.",
            "What are high values?",
            "What do they mean?",
            "What could they reflect, and what are low values?",
            "So this was the joint distribution that I have shown you before.",
            "How do we actually calculate this expected conditional entropy?",
            "What you do is for each of the type sets that you have, you take a look at the distribution over the property sets.",
            "That gives you an entropy.",
            "This entropy you're weighing it with the probability of actually observing this typeset, which gives you the final value that then you're working with.",
            "You do this for.",
            "All of the type sets that you have, you aggregate the whole thing and that gives you one number.",
            "In this toy example, the number would be 1.5, so Please note that this is not a normalized version.",
            "There is as far as we are aware, no commonly agreed, normalized, normalized version for the expected conditional entropy.",
            "This is the way how you would do it given the type.",
            "What is the conditional entropy that you can expect?",
            "And if you just aggregate in the other direction, that is what you would.",
            "How you would get the condition entropy for given property sets.",
            "So you have seen in this mock up example where these things are quite equally distributed, just a few things pointing out.",
            "We get quite high values.",
            "If instead you would have a behavior."
        ],
        [
            "Like I have again made up in this example, you would observe that actually the entropy is much lower becausw as soon as I know the type.",
            "In this case it tells me already a lot about the resource about the properties.",
            "An if I have the properties, it tells me a lot about the types.",
            "Again, just a made up example, so let's take a look at the real data."
        ],
        [
            "So what we have here again, our five segments from the billing Triple Challenge data set and the conditional expected entropies once given the properties.",
            "That is the first one and once given the type sets, now what we observe here again just tendencies?",
            "Anyway, this is just some data samples that we have taken.",
            "It seems again that actually the properties tell us more about the types, so if I have the types given, I know more about if I have the properties given.",
            "I know more about the types because the entropy is lower than afterwards, so there's not that much information that remains in the types.",
            "Then if you have it the other way around.",
            "So if I just tell you what it types attached to a resource that doesn't tell you that much about the properties, again there was just one example data, at least it is consistent for that.",
            "Another thing that we actually observed is if you compare that to the marginal entropy of typesets and property sets, so not the not normalized versions to be able to compare that.",
            "In general the corresponding values are really decreasing, so is giving you some information, does all your to tell you something and leverage but telling you about the properties actually gives you more information.",
            "So."
        ],
        [
            "Last question.",
            "To which degree can one information explain the respective other?",
            "Now, the information theoretic measure that we chose here is mutual information and actually a normalized version of mutual information which you might find in the literature even under the specific term redundancy, and this is really what we were interested in.",
            "So again, to toy around a bit with the data to show you what this could look like and how it is actually expressing, I'm using again."
        ],
        [
            "My mock up example the same thing that I have said here.",
            "The things are equally distributed.",
            "There is not very strong correlation that I have put into this example an you get a relatively low normalized mutual information of 0.23 for that example and that means that these things they don't really correlate very strong.",
            "They don't encode each others information.",
            "If you want to say like this instead."
        ],
        [
            "If you have a stronger correlation between the data, then you get higher values an again here for another.",
            "This made up example.",
            "You get a value that is closer to 1.",
            "So let's look again at the bill and Triple Check."
        ],
        [
            "This data.",
            "Now here I have no values that I can compare to each other, but I can take a look at the individual segments to see if this redundancy is consistent with what the data actually provides and if it is what we expected.",
            "So I'm just going through them, basically starting from the highest value of redundancy that we observed, which in this case was the rest segment.",
            "Maybe just to tell you briefly what that segment is.",
            "The building Triple Challenge data set, as far as I remember, they started with some seed, your eyes and.",
            "He crawled from that and the seed you arise for.",
            "Rest was all the old owl.",
            "Same as links coming out of DB Pedia that did not refer to any of the other datasets that they are here specifically referring to.",
            "I have looked into this data and you really find a lot of very, very structured data sources.",
            "Actually, roughly 90 to 95% of the data of the your eyes that you observe are provided by data that really form a very very strict, nearly strict, consistent schema where you always have the same types associated with the same.",
            "Properties so a redundancy of 88%.",
            "That is actually quite good word of and representative for what we would have expected for that data set.",
            "If I go through Freebase, also quite high level of redundancy which we explained simply by the fact that Freebase has, let's say, a kind of quiet weekly agreed schema.",
            "The people have modeled it and if you add new resources then you probably adapt and you reuse the same properties for that resource also in Freebase.",
            "The timber data set was a crawl for the billion triple charged.",
            "It started from the 4th profile of Tim Berners.",
            "Lee Ann is covering lots of both profiles now schema wise.",
            "Also both profiles.",
            "They always look pretty much the same, so that explains it.",
            "We have always people that have friends, maybe depiction, maybe a mailbox, but the schema is also pretty consistent there and that also leads to high redundancy for data.",
            "We're already going down.",
            "DB Pedia has the lowest redundancy which we can explain by the fact that it is extracted from Wikipedia.",
            "And it is finally up to human users and what they provide as information in the infoboxes.",
            "And so this is really matter also of how actually human users across all the articles make use of this information and what they provide.",
            "So that is not really enforced to be very consistent.",
            "OK, so.",
            "Based on these things, we can say that in general we also have a quite high level of redundancy, but it actually depends really on which part of the link data cloud you're looking at.",
            "So you really will have to analyze if you want to work with these metrics.",
            "If you want to make use of redundancy that you've observed, you really will have to analyze the data set.",
            "There is not one general thing that we can state globally to be true for everything."
        ],
        [
            "Coming for the summary of the talk, what I have presented you is, first of all the method.",
            "Actually how you can check redundancy in schema information on linked open data and also in large datasets for linked open data, the observations that we matches to quickly summarize, we said that the scheme information is not dominated really, just a few types of property sets.",
            "The attributes or properties actually provide more information than the types, and they're also more indicative in the sense of take if you're more.",
            "Idea of what are detached types of resource ones that you know the properties than the other way around.",
            "And the last thing is I just said is that we observed relatively high level of redundancy future work.",
            "So what are we doing next?",
            "What we're actually doing is we wanted to go bit in more detail now with these building triple challenge datasets it was quite aggregated over several data providers.",
            "So also here we are going down on data provider level and we have already done some of the analysis there and you see also there are quite interesting wide range of.",
            "Which data providers have a more consistent schema in which one have more a wild schema as you would say, that is what the semantic Web applications actually would.",
            "Based on an the second thing, and that I'm really going to have a chat with trivias, I think now in the next break is the temporal evolution of this redundancy.",
            "Is it something that.",
            "In particular, let's say for the those data sources that are curated by humans, do they maybe start to agree on some screamer information, or is it at the same level of redundancy and overtime?",
            "So this is the temporal evolution is definitely one of the things that we want to take a look at.",
            "So I'm going to make use of that data set as well, and that's everything from ice."
        ],
        [
            "Right, thanks a lot and now it's up to you if you want to have lunch or ask me questions.",
            "So very interesting talk.",
            "We did kind of a similar analysis of the BTC 2011 data set and what I was wondering in your talk, how did you actually derive or retrieve the schema information?",
            "Because we found that there are actually many additions to existing schemas even in the BTC data set.",
            "So four person the schema is extended within this large data set.",
            "So I was wondering if there is any analysis you did there of you just stuck with the original schema information.",
            "We really just used all the schema information that was available in the building.",
            "Triple Challenge data set.",
            "So under this aspect we didn't add anything else or any external resources.",
            "If this is what you meant.",
            "I mean and then if there.",
            "If there were extensions that are contained in the data, then of course we're considering them yes.",
            "Then we really make use of everything that is available.",
            "Very very good presentation.",
            "I have some questions though.",
            "The first is what do you kind of see as the main applicability of these metrics?",
            "Like in what way could they inform application development or whatever and the other is?",
            "Can you make some comment a little bit about the influence of like for instance in Bio TF?",
            "We now have started mapping to an upper level ontology, hence you can expect that for some properties the original ones we would expect them to be tightly correlated to the data.",
            "It would be very strongly informative, but when we do the mapping to the upper level then those relations will certainly because they're reused amongst many types, they will become much less informative in some sense, so can you, did you?",
            "Did you consider or did you do any kind of reasoning or entailment to studies?",
            "Let me answer the second question first.",
            "We did not do any reasoning and we didn't do any entailment.",
            "Also, this is one of the things that we're actually considering for what we want to do in the future.",
            "We could simply materialize or the information that you could just reason that you could just entail from vocabulary descriptions and see if this has an effect, but so far we haven't done it.",
            "Coming back to the first question of.",
            "What are applications?",
            "I mean one thing as I said.",
            "Personally I'm simply interested in how much I can compress my schema index.",
            "On the other hand.",
            "An application I haven't mentioned yet is that there are some people also in our group that are working on programming interfaces towards link data and they are of course really interested in what are stable patterns in the data, so they really interested in what are typical combinations of types and of properties that always Co occur together and so for them it might even make sense to apply such metrics on a data provider level to see.",
            "Is this a data source which is very consistent.",
            "Makes it easier to program against that, so this is one additional thing.",
            "The other I have mentioned briefly was the colleague that is working on support tool for link data engineering and he really wants to make use of this.",
            "To propose you properties or types when modeling the data and there you can say OK if I have some properties which are always used together, very consistent in a certain way, then that might make a very strong recommendation.",
            "So it can be used for a ranking.",
            "Two to apply to these recommendations.",
            "Can you use this to find solve instances that are so funny in a way that they are so different and then maybe they are they have errors or they are soft, particularly interesting.",
            "That's a good question.",
            "I'm just trying to figure out.",
            "I mean how would they look like they would be?",
            "A very unusual combination so that if you would go down to really the resource level would be something, but it would have really high information encoded in a certain way.",
            "So I've never done that.",
            "I could imagine that you could actually use it too.",
            "Observe Singleton strange things that are really outliers.",
            "But I would have to think about it more carefully now.",
            "Coming back to the inference question, because that's something that.",
            "Bothered me during you talk?",
            "Very interesting by the way, but you mentioned the idea of materializing or inferences and then it makes sense to me.",
            "But on the other hand, the redundancy would grow as inferences actually add information that is predictable by definition.",
            "So maybe another another idea would be to materialize or inferences and then.",
            "Uh.",
            "Remove everything that.",
            "That is redundant because of because of.",
            "Because of the inference, just so just keep the most specific subclasses.",
            "For example, in the type sets and.",
            "So you would maybe you would measure something that's more inherent to the data rather than some artificial redundancy coming from the inference.",
            "Just an idea.",
            "Interesting, I mean because in a certain way then you could use that again to say.",
            "Using this redundancy, you can actually compress the data itself because you remove everything that you can influence that is interesting.",
            "On the other hand.",
            "This is link data from the web, so it's pretty dirty and pretty noisy.",
            "Don't remember where someone stop by during the demo session and we found instances that were, I think it was a movie that was described using a fold name property.",
            "So if you really would use inferencing and taking a look domain and range things then you would end up making that movie a person so.",
            "I'm not entirely sure if you really would decrease her down.",
            "It's something that we would have to take a look at.",
            "Yeah, but it is.",
            "I like also the idea of just influencing 1st and that or the other way around.",
            "Remove everything that can be influenced.",
            "Yeah.",
            "So if you have no questions anymore, then let's think.",
            "Speak again, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what we did was this systematic investigation of explicit and implicit schema information on the linked open Data Cloud, which probably explains also why I had the question related to schema information of the previous talk.",
                    "label": 1
                },
                {
                    "sent": "But before I start going into the analysis, I think I might have to tell you what we consider explicit and implicit schema information, because we have heard so much about it in the last days saying that well, actually there is not really a schema in linked data or in semantic data, and it should be flexible.",
                    "label": 0
                },
                {
                    "sent": "So what do we mean with schema information in this case?",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um, basically catching up with my previous presenter was talking about we consider explicit schema information.",
                    "label": 0
                },
                {
                    "sent": "If you're assigning a type class to some resource, some entity that you're modeling in linked data 'cause they explicitly say this is something of a certain type.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, you have linked data.",
                    "label": 0
                },
                {
                    "sent": "You have the option that you can just.",
                    "label": 0
                },
                {
                    "sent": "Model things by their attributes.",
                    "label": 0
                },
                {
                    "sent": "You don't have to provide a type, so you implicitly describe the entities, but just saying which attributes they have, which properties.",
                    "label": 0
                },
                {
                    "sent": "Now the world is not black and white.",
                    "label": 0
                },
                {
                    "sent": "You don't have either or and typically you will find both of these things together, so you will model entities, giving them both set of types and a set of properties.",
                    "label": 0
                },
                {
                    "sent": "So in the example that I have put up here, we've got something that is a document of type document of type in proceedings and we also have something that some properties to tell us about the creator linking it to another UI and attaching a literal wire DC title property.",
                    "label": 0
                },
                {
                    "sent": "So of course these things are not entirely independent.",
                    "label": 0
                },
                {
                    "sent": "You can say it's quite obvious, or you could expect that if you have a document that this document has an author, it has a creator or it has a title, and vice versa.",
                    "label": 0
                },
                {
                    "sent": "If you see something that has a title and it has a creator, you could also expect that this is very likely.",
                    "label": 0
                },
                {
                    "sent": "A document might even be something that of the type in proceedings.",
                    "label": 0
                },
                {
                    "sent": "So what we have here is we have some kind of redundancy in this explicit and implicit schema information, and that is something that is quite interesting.",
                    "label": 0
                },
                {
                    "sent": "Because in the few that I am currently working on that is, schema extraction from linked data and we're building a schema level index that allows you to efficiently and very fast look up data based on the schema information in an index.",
                    "label": 1
                },
                {
                    "sent": "So as these indexes based on schema information from you, I was wondering well if there is so much redundancy.",
                    "label": 0
                },
                {
                    "sent": "Or maybe I can use that to compress the schema information and in that way also compress my index.",
                    "label": 0
                },
                {
                    "sent": "There are also some other people that are actually curious about the results here.",
                    "label": 0
                },
                {
                    "sent": "Got some colleagues that are working on supporting linked data engineers that are modeling their data and if they start describing the data attaching some types they might want to get some recommendations of what would be good properties to attach to and not just properties coming out of an ontology, but just properties.",
                    "label": 0
                },
                {
                    "sent": "Also, how are they actually used in which combination on the link data cloud?",
                    "label": 0
                },
                {
                    "sent": "Because that is vocabulary use.",
                    "label": 0
                },
                {
                    "sent": "Reuse in a very good way.",
                    "label": 0
                },
                {
                    "sent": "So there are several people that were interested in this and that led us to the question, well, to which degree do we have redundancy among this schema information?",
                    "label": 0
                },
                {
                    "sent": "And effectively we ended up actually even wondering.",
                    "label": 0
                },
                {
                    "sent": "Well, how can we measure that?",
                    "label": 0
                },
                {
                    "sent": "How can we measure the redundancy between these two things?",
                    "label": 0
                },
                {
                    "sent": "And that led us to formulate four question.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That I'm going to present you hear.",
                    "label": 0
                },
                {
                    "sent": "The first question was really, how much information is actually encoded in a type set or a property set of these attached to a single resource?",
                    "label": 1
                },
                {
                    "sent": "And if you don't take it one step further, that is the next question.",
                    "label": 0
                },
                {
                    "sent": "Well, assume that I already know of which type of resources.",
                    "label": 1
                },
                {
                    "sent": "How much does that tell me about the properties or vice versa?",
                    "label": 0
                },
                {
                    "sent": "That is the third question.",
                    "label": 0
                },
                {
                    "sent": "If I tell you what are the properties, how much does that tell me about the types?",
                    "label": 0
                },
                {
                    "sent": "And finally, that is really the question about redundancy.",
                    "label": 1
                },
                {
                    "sent": "To which degree can one information one schema information?",
                    "label": 0
                },
                {
                    "sent": "Either the types or the properties explain the respective other.",
                    "label": 0
                },
                {
                    "sent": "So with these four questions in mind, I'm going.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To take you through this talk, starting from these questions, the first thing that I will tell you now about how we arrived in or how we did our analysis is actually to see how did we model schema information in a suitable way so that we could analyze it towards the questions that we wanted to answer.",
                    "label": 1
                },
                {
                    "sent": "And the second thing then is I'm going to tell you about information measures and 3D information theoretic measures that we are applying here and why they are suitable.",
                    "label": 0
                },
                {
                    "sent": "Actually, to answer these questions, once we have developed them, we apply them on some linked open data later sets, and I'm coming out of there and hopefully can give you some answers that are going to satisfy you as we have several questions now in the talk.",
                    "label": 0
                },
                {
                    "sent": "Actually, the last part I will go through it repeatedly, answering each of these questions.",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's start how do we model the data?",
                    "label": 0
                },
                {
                    "sent": "The Information schema information data I already told you what are explicit and implicit schema information that we are really referring to.",
                    "label": 0
                },
                {
                    "sent": "So what we did is we modeled this as a joint distribution of the typesets on of the property sets that you observe together with the resources.",
                    "label": 0
                },
                {
                    "sent": "So this probability PTR is the probability of a resource having a particular set of class types.",
                    "label": 1
                },
                {
                    "sent": "That's the tea, and it can be many or several.",
                    "label": 1
                },
                {
                    "sent": "Types and at the same time to have a certain set of properties.",
                    "label": 0
                },
                {
                    "sent": "As this is a bit abstract and the dinner yesterday was late and now it is shortly before lunch, I will give you a toy and mock up example to explain what I'm talking about.",
                    "label": 0
                },
                {
                    "sent": "So this is a very very small.",
                    "label": 1
                },
                {
                    "sent": "As I said, made up joint distribution of type and property sets.",
                    "label": 0
                },
                {
                    "sent": "So if I take a look in one of these cells here, I have picked up one.",
                    "label": 0
                },
                {
                    "sent": "This means that I have a probability of 8% that one of the resources in the data set that I am analyzing is actually having.",
                    "label": 0
                },
                {
                    "sent": "A typeset T1 which, as I said, can be several types.",
                    "label": 0
                },
                {
                    "sent": "It's a set, so picking up the example of before, maybe that is really just the in proceedings and the document and at the same time whoops wrong direction.",
                    "label": 0
                },
                {
                    "sent": "It has a set of properties, so here maybe the Creator and the title.",
                    "label": 0
                },
                {
                    "sent": "The other thing that you see here at the side, these are the marginal distribution, so this is the aggregation over the two dimensions and one of them gives us then just the distribution of the type sets and the other one is the distribution of the property sets and we will make use of these as well.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is a probability model, the question is.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "How do we estimate these probabilities?",
                    "label": 0
                },
                {
                    "sent": "So what we actually have to do, and as we want to do it also for linked data and linked open data, we actually have to determine schema use as I have presented it to you.",
                    "label": 1
                },
                {
                    "sent": "And then we also have to aggregate over all the individual resources that we have observed and so that can be quite a data in sentense if task.",
                    "label": 0
                },
                {
                    "sent": "Now if you have paid attention or if you have come to my demo session then you might remember from the beginning of the talk that I actually I'm working on schema level indexes and we've got a schema level index.",
                    "label": 0
                },
                {
                    "sent": "That is quite easy and quite efficient to compute on large datasets.",
                    "label": 0
                },
                {
                    "sent": "So what we did here for estimating probabilities will simply run our construct.",
                    "label": 0
                },
                {
                    "sent": "Our schema index, run it over the datasets that we're working with, and then we just query the index and ask well how many instances do we find in these datasets that have a certain type set in a certain property set.",
                    "label": 0
                },
                {
                    "sent": "Which datasets did we use?",
                    "label": 0
                },
                {
                    "sent": "We re used the billion triple Challenge data set from last year for a particular reason, because this data set is subdivided in segments that correspond to specific parts of the crawl that were used to collect data from the linked data cloud.",
                    "label": 0
                },
                {
                    "sent": "So here we have different areas of the link data cloud covered to different extent and these datasets also have different characteristics.",
                    "label": 0
                },
                {
                    "sent": "For example, you can see that the sizes varying between 20,000,000 triples and 900 million triples, and when it comes to the typesets and.",
                    "label": 0
                },
                {
                    "sent": "Property sets that we are interested in here.",
                    "label": 1
                },
                {
                    "sent": "You also have quite a wide range between for the smallest rest data set.",
                    "label": 0
                },
                {
                    "sent": "800 Type sets an hour, roughly 800 and roughly 8000 property sets up to more than a million typesets for DB pedia and 400,000 property sets that we observed here.",
                    "label": 0
                },
                {
                    "sent": "OK so.",
                    "label": 0
                },
                {
                    "sent": "Now we are able to handle the data to create this joint distribution.",
                    "label": 0
                },
                {
                    "sent": "To estimate this joint distribution that we are interested in.",
                    "label": 0
                },
                {
                    "sent": "Let's address.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Question question A was how much information is encoded in a type set or the property set of a resource.",
                    "label": 1
                },
                {
                    "sent": "Now I already told you we are interested in information, so we're going into information theoretic measures and in that case you're automatically end up with entropy.",
                    "label": 0
                },
                {
                    "sent": "Now as we have let's say.",
                    "label": 0
                },
                {
                    "sent": "Different dimensions, not different dimension, different size of observations that we can make their very different numbers for the types into property sets and we want to be able to compare these things of it.",
                    "label": 0
                },
                {
                    "sent": "That's why we went for a normalized version of entropy.",
                    "label": 0
                },
                {
                    "sent": "And we're here considering first the entropy of the marginal distributions, because we're just interested in the types and the properties so far not in the joint distribution and how they appear together again, as this is a bit very dry and I'm trying to give you an example.",
                    "label": 0
                },
                {
                    "sent": "Starting again with toy examples, so this is the marginal distribution of the property sets that I had made up, and you see here that the probabilities are relatively equally distributed.",
                    "label": 0
                },
                {
                    "sent": "There is just one property centered in speaking a bit out, and this leads to a relatively high normalized entropy closed one, which means that there is in the property sets quite some information encoded.",
                    "label": 0
                },
                {
                    "sent": "If you have a different behavior where one or in this case just or a few if you have more than the toy example just one property set that is dominating, it is basically collecting all the resources, then you get a very low normalized entropy close to 0.",
                    "label": 0
                },
                {
                    "sent": "And just to show you really, what is the extreme case if everything is equally likely, then we would get a normalized entropy of 1 zero.",
                    "label": 0
                },
                {
                    "sent": "This is the toy example.",
                    "label": 0
                },
                {
                    "sent": "How does it look on the actual data that we analyzed?",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I have summarized here.",
                    "label": 0
                },
                {
                    "sent": "You can see for our five segments of the Building Triple Challenge data set.",
                    "label": 1
                },
                {
                    "sent": "What is the normalized entropy over the type sets, and what is the normalized entropy over the property sets?",
                    "label": 0
                },
                {
                    "sent": "Now there's some tendencies that we can observe in here.",
                    "label": 0
                },
                {
                    "sent": "The first one is that.",
                    "label": 0
                },
                {
                    "sent": "In most of these cases, we are actually observing that the entropy of the proper set property sets is higher than the one of the typesets, which means that the property sets actually tell us more about the resources.",
                    "label": 1
                },
                {
                    "sent": "There are more suitable to identify them if you want to say it like this, we just had one case that is the day to have part of the building.",
                    "label": 0
                },
                {
                    "sent": "Triple Challenge data set there it was the other way around, which might be due to the fact that this is really a collection of many many many different datasets.",
                    "label": 1
                },
                {
                    "sent": "Furthermore, we had no really high values, so things are not equally distributed.",
                    "label": 0
                },
                {
                    "sent": "Neither.",
                    "label": 0
                },
                {
                    "sent": "We had values that are really close to 0, so neither we have just a very few combinations of properties and types that are, let's say, dominating everything else in the data.",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The next questions that we had.",
                    "label": 0
                },
                {
                    "sent": "So here we were wondering how much information is still encoded in the properties once that we know the types of resource and vice versa.",
                    "label": 1
                },
                {
                    "sent": "So as I already indicated here, we have some given knowledge and that takes us to conditional probabilities.",
                    "label": 0
                },
                {
                    "sent": "Now there is also things such as conditional entropy and the one measure that we identified here to be really what we wanted is the expected conditional entropy.",
                    "label": 0
                },
                {
                    "sent": "If you take a look at the last part of the formula, this is the entropy formula for a given type set in this case, and the entropy that then remains in the properties and this is aggregated and weighted by.",
                    "label": 0
                },
                {
                    "sent": "Actually the probabilities of observing the type set that we have assumed as given.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 1
                },
                {
                    "sent": "In a way of speaking, we can say this is the entropy that gives us the entropy we can expect if we know the types.",
                    "label": 0
                },
                {
                    "sent": "Let me take you again through my toy exam.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So, so that you might get that idea again.",
                    "label": 0
                },
                {
                    "sent": "What are high values?",
                    "label": 0
                },
                {
                    "sent": "What do they mean?",
                    "label": 0
                },
                {
                    "sent": "What could they reflect, and what are low values?",
                    "label": 0
                },
                {
                    "sent": "So this was the joint distribution that I have shown you before.",
                    "label": 0
                },
                {
                    "sent": "How do we actually calculate this expected conditional entropy?",
                    "label": 0
                },
                {
                    "sent": "What you do is for each of the type sets that you have, you take a look at the distribution over the property sets.",
                    "label": 0
                },
                {
                    "sent": "That gives you an entropy.",
                    "label": 0
                },
                {
                    "sent": "This entropy you're weighing it with the probability of actually observing this typeset, which gives you the final value that then you're working with.",
                    "label": 0
                },
                {
                    "sent": "You do this for.",
                    "label": 0
                },
                {
                    "sent": "All of the type sets that you have, you aggregate the whole thing and that gives you one number.",
                    "label": 0
                },
                {
                    "sent": "In this toy example, the number would be 1.5, so Please note that this is not a normalized version.",
                    "label": 0
                },
                {
                    "sent": "There is as far as we are aware, no commonly agreed, normalized, normalized version for the expected conditional entropy.",
                    "label": 0
                },
                {
                    "sent": "This is the way how you would do it given the type.",
                    "label": 0
                },
                {
                    "sent": "What is the conditional entropy that you can expect?",
                    "label": 0
                },
                {
                    "sent": "And if you just aggregate in the other direction, that is what you would.",
                    "label": 0
                },
                {
                    "sent": "How you would get the condition entropy for given property sets.",
                    "label": 0
                },
                {
                    "sent": "So you have seen in this mock up example where these things are quite equally distributed, just a few things pointing out.",
                    "label": 0
                },
                {
                    "sent": "We get quite high values.",
                    "label": 0
                },
                {
                    "sent": "If instead you would have a behavior.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Like I have again made up in this example, you would observe that actually the entropy is much lower becausw as soon as I know the type.",
                    "label": 0
                },
                {
                    "sent": "In this case it tells me already a lot about the resource about the properties.",
                    "label": 0
                },
                {
                    "sent": "An if I have the properties, it tells me a lot about the types.",
                    "label": 0
                },
                {
                    "sent": "Again, just a made up example, so let's take a look at the real data.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what we have here again, our five segments from the billing Triple Challenge data set and the conditional expected entropies once given the properties.",
                    "label": 0
                },
                {
                    "sent": "That is the first one and once given the type sets, now what we observe here again just tendencies?",
                    "label": 0
                },
                {
                    "sent": "Anyway, this is just some data samples that we have taken.",
                    "label": 0
                },
                {
                    "sent": "It seems again that actually the properties tell us more about the types, so if I have the types given, I know more about if I have the properties given.",
                    "label": 1
                },
                {
                    "sent": "I know more about the types because the entropy is lower than afterwards, so there's not that much information that remains in the types.",
                    "label": 0
                },
                {
                    "sent": "Then if you have it the other way around.",
                    "label": 0
                },
                {
                    "sent": "So if I just tell you what it types attached to a resource that doesn't tell you that much about the properties, again there was just one example data, at least it is consistent for that.",
                    "label": 0
                },
                {
                    "sent": "Another thing that we actually observed is if you compare that to the marginal entropy of typesets and property sets, so not the not normalized versions to be able to compare that.",
                    "label": 0
                },
                {
                    "sent": "In general the corresponding values are really decreasing, so is giving you some information, does all your to tell you something and leverage but telling you about the properties actually gives you more information.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Last question.",
                    "label": 0
                },
                {
                    "sent": "To which degree can one information explain the respective other?",
                    "label": 1
                },
                {
                    "sent": "Now, the information theoretic measure that we chose here is mutual information and actually a normalized version of mutual information which you might find in the literature even under the specific term redundancy, and this is really what we were interested in.",
                    "label": 0
                },
                {
                    "sent": "So again, to toy around a bit with the data to show you what this could look like and how it is actually expressing, I'm using again.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "My mock up example the same thing that I have said here.",
                    "label": 0
                },
                {
                    "sent": "The things are equally distributed.",
                    "label": 0
                },
                {
                    "sent": "There is not very strong correlation that I have put into this example an you get a relatively low normalized mutual information of 0.23 for that example and that means that these things they don't really correlate very strong.",
                    "label": 0
                },
                {
                    "sent": "They don't encode each others information.",
                    "label": 0
                },
                {
                    "sent": "If you want to say like this instead.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you have a stronger correlation between the data, then you get higher values an again here for another.",
                    "label": 0
                },
                {
                    "sent": "This made up example.",
                    "label": 0
                },
                {
                    "sent": "You get a value that is closer to 1.",
                    "label": 0
                },
                {
                    "sent": "So let's look again at the bill and Triple Check.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This data.",
                    "label": 0
                },
                {
                    "sent": "Now here I have no values that I can compare to each other, but I can take a look at the individual segments to see if this redundancy is consistent with what the data actually provides and if it is what we expected.",
                    "label": 0
                },
                {
                    "sent": "So I'm just going through them, basically starting from the highest value of redundancy that we observed, which in this case was the rest segment.",
                    "label": 0
                },
                {
                    "sent": "Maybe just to tell you briefly what that segment is.",
                    "label": 0
                },
                {
                    "sent": "The building Triple Challenge data set, as far as I remember, they started with some seed, your eyes and.",
                    "label": 0
                },
                {
                    "sent": "He crawled from that and the seed you arise for.",
                    "label": 0
                },
                {
                    "sent": "Rest was all the old owl.",
                    "label": 0
                },
                {
                    "sent": "Same as links coming out of DB Pedia that did not refer to any of the other datasets that they are here specifically referring to.",
                    "label": 0
                },
                {
                    "sent": "I have looked into this data and you really find a lot of very, very structured data sources.",
                    "label": 0
                },
                {
                    "sent": "Actually, roughly 90 to 95% of the data of the your eyes that you observe are provided by data that really form a very very strict, nearly strict, consistent schema where you always have the same types associated with the same.",
                    "label": 0
                },
                {
                    "sent": "Properties so a redundancy of 88%.",
                    "label": 0
                },
                {
                    "sent": "That is actually quite good word of and representative for what we would have expected for that data set.",
                    "label": 0
                },
                {
                    "sent": "If I go through Freebase, also quite high level of redundancy which we explained simply by the fact that Freebase has, let's say, a kind of quiet weekly agreed schema.",
                    "label": 0
                },
                {
                    "sent": "The people have modeled it and if you add new resources then you probably adapt and you reuse the same properties for that resource also in Freebase.",
                    "label": 0
                },
                {
                    "sent": "The timber data set was a crawl for the billion triple charged.",
                    "label": 0
                },
                {
                    "sent": "It started from the 4th profile of Tim Berners.",
                    "label": 0
                },
                {
                    "sent": "Lee Ann is covering lots of both profiles now schema wise.",
                    "label": 0
                },
                {
                    "sent": "Also both profiles.",
                    "label": 0
                },
                {
                    "sent": "They always look pretty much the same, so that explains it.",
                    "label": 0
                },
                {
                    "sent": "We have always people that have friends, maybe depiction, maybe a mailbox, but the schema is also pretty consistent there and that also leads to high redundancy for data.",
                    "label": 0
                },
                {
                    "sent": "We're already going down.",
                    "label": 0
                },
                {
                    "sent": "DB Pedia has the lowest redundancy which we can explain by the fact that it is extracted from Wikipedia.",
                    "label": 0
                },
                {
                    "sent": "And it is finally up to human users and what they provide as information in the infoboxes.",
                    "label": 0
                },
                {
                    "sent": "And so this is really matter also of how actually human users across all the articles make use of this information and what they provide.",
                    "label": 0
                },
                {
                    "sent": "So that is not really enforced to be very consistent.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Based on these things, we can say that in general we also have a quite high level of redundancy, but it actually depends really on which part of the link data cloud you're looking at.",
                    "label": 0
                },
                {
                    "sent": "So you really will have to analyze if you want to work with these metrics.",
                    "label": 0
                },
                {
                    "sent": "If you want to make use of redundancy that you've observed, you really will have to analyze the data set.",
                    "label": 0
                },
                {
                    "sent": "There is not one general thing that we can state globally to be true for everything.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Coming for the summary of the talk, what I have presented you is, first of all the method.",
                    "label": 0
                },
                {
                    "sent": "Actually how you can check redundancy in schema information on linked open data and also in large datasets for linked open data, the observations that we matches to quickly summarize, we said that the scheme information is not dominated really, just a few types of property sets.",
                    "label": 1
                },
                {
                    "sent": "The attributes or properties actually provide more information than the types, and they're also more indicative in the sense of take if you're more.",
                    "label": 1
                },
                {
                    "sent": "Idea of what are detached types of resource ones that you know the properties than the other way around.",
                    "label": 0
                },
                {
                    "sent": "And the last thing is I just said is that we observed relatively high level of redundancy future work.",
                    "label": 0
                },
                {
                    "sent": "So what are we doing next?",
                    "label": 0
                },
                {
                    "sent": "What we're actually doing is we wanted to go bit in more detail now with these building triple challenge datasets it was quite aggregated over several data providers.",
                    "label": 0
                },
                {
                    "sent": "So also here we are going down on data provider level and we have already done some of the analysis there and you see also there are quite interesting wide range of.",
                    "label": 1
                },
                {
                    "sent": "Which data providers have a more consistent schema in which one have more a wild schema as you would say, that is what the semantic Web applications actually would.",
                    "label": 0
                },
                {
                    "sent": "Based on an the second thing, and that I'm really going to have a chat with trivias, I think now in the next break is the temporal evolution of this redundancy.",
                    "label": 0
                },
                {
                    "sent": "Is it something that.",
                    "label": 0
                },
                {
                    "sent": "In particular, let's say for the those data sources that are curated by humans, do they maybe start to agree on some screamer information, or is it at the same level of redundancy and overtime?",
                    "label": 0
                },
                {
                    "sent": "So this is the temporal evolution is definitely one of the things that we want to take a look at.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to make use of that data set as well, and that's everything from ice.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right, thanks a lot and now it's up to you if you want to have lunch or ask me questions.",
                    "label": 0
                },
                {
                    "sent": "So very interesting talk.",
                    "label": 0
                },
                {
                    "sent": "We did kind of a similar analysis of the BTC 2011 data set and what I was wondering in your talk, how did you actually derive or retrieve the schema information?",
                    "label": 0
                },
                {
                    "sent": "Because we found that there are actually many additions to existing schemas even in the BTC data set.",
                    "label": 0
                },
                {
                    "sent": "So four person the schema is extended within this large data set.",
                    "label": 0
                },
                {
                    "sent": "So I was wondering if there is any analysis you did there of you just stuck with the original schema information.",
                    "label": 0
                },
                {
                    "sent": "We really just used all the schema information that was available in the building.",
                    "label": 1
                },
                {
                    "sent": "Triple Challenge data set.",
                    "label": 0
                },
                {
                    "sent": "So under this aspect we didn't add anything else or any external resources.",
                    "label": 0
                },
                {
                    "sent": "If this is what you meant.",
                    "label": 0
                },
                {
                    "sent": "I mean and then if there.",
                    "label": 0
                },
                {
                    "sent": "If there were extensions that are contained in the data, then of course we're considering them yes.",
                    "label": 0
                },
                {
                    "sent": "Then we really make use of everything that is available.",
                    "label": 0
                },
                {
                    "sent": "Very very good presentation.",
                    "label": 0
                },
                {
                    "sent": "I have some questions though.",
                    "label": 0
                },
                {
                    "sent": "The first is what do you kind of see as the main applicability of these metrics?",
                    "label": 0
                },
                {
                    "sent": "Like in what way could they inform application development or whatever and the other is?",
                    "label": 0
                },
                {
                    "sent": "Can you make some comment a little bit about the influence of like for instance in Bio TF?",
                    "label": 0
                },
                {
                    "sent": "We now have started mapping to an upper level ontology, hence you can expect that for some properties the original ones we would expect them to be tightly correlated to the data.",
                    "label": 0
                },
                {
                    "sent": "It would be very strongly informative, but when we do the mapping to the upper level then those relations will certainly because they're reused amongst many types, they will become much less informative in some sense, so can you, did you?",
                    "label": 0
                },
                {
                    "sent": "Did you consider or did you do any kind of reasoning or entailment to studies?",
                    "label": 0
                },
                {
                    "sent": "Let me answer the second question first.",
                    "label": 0
                },
                {
                    "sent": "We did not do any reasoning and we didn't do any entailment.",
                    "label": 0
                },
                {
                    "sent": "Also, this is one of the things that we're actually considering for what we want to do in the future.",
                    "label": 0
                },
                {
                    "sent": "We could simply materialize or the information that you could just reason that you could just entail from vocabulary descriptions and see if this has an effect, but so far we haven't done it.",
                    "label": 0
                },
                {
                    "sent": "Coming back to the first question of.",
                    "label": 0
                },
                {
                    "sent": "What are applications?",
                    "label": 0
                },
                {
                    "sent": "I mean one thing as I said.",
                    "label": 0
                },
                {
                    "sent": "Personally I'm simply interested in how much I can compress my schema index.",
                    "label": 0
                },
                {
                    "sent": "On the other hand.",
                    "label": 0
                },
                {
                    "sent": "An application I haven't mentioned yet is that there are some people also in our group that are working on programming interfaces towards link data and they are of course really interested in what are stable patterns in the data, so they really interested in what are typical combinations of types and of properties that always Co occur together and so for them it might even make sense to apply such metrics on a data provider level to see.",
                    "label": 0
                },
                {
                    "sent": "Is this a data source which is very consistent.",
                    "label": 0
                },
                {
                    "sent": "Makes it easier to program against that, so this is one additional thing.",
                    "label": 0
                },
                {
                    "sent": "The other I have mentioned briefly was the colleague that is working on support tool for link data engineering and he really wants to make use of this.",
                    "label": 0
                },
                {
                    "sent": "To propose you properties or types when modeling the data and there you can say OK if I have some properties which are always used together, very consistent in a certain way, then that might make a very strong recommendation.",
                    "label": 0
                },
                {
                    "sent": "So it can be used for a ranking.",
                    "label": 0
                },
                {
                    "sent": "Two to apply to these recommendations.",
                    "label": 0
                },
                {
                    "sent": "Can you use this to find solve instances that are so funny in a way that they are so different and then maybe they are they have errors or they are soft, particularly interesting.",
                    "label": 0
                },
                {
                    "sent": "That's a good question.",
                    "label": 0
                },
                {
                    "sent": "I'm just trying to figure out.",
                    "label": 0
                },
                {
                    "sent": "I mean how would they look like they would be?",
                    "label": 0
                },
                {
                    "sent": "A very unusual combination so that if you would go down to really the resource level would be something, but it would have really high information encoded in a certain way.",
                    "label": 0
                },
                {
                    "sent": "So I've never done that.",
                    "label": 0
                },
                {
                    "sent": "I could imagine that you could actually use it too.",
                    "label": 0
                },
                {
                    "sent": "Observe Singleton strange things that are really outliers.",
                    "label": 0
                },
                {
                    "sent": "But I would have to think about it more carefully now.",
                    "label": 0
                },
                {
                    "sent": "Coming back to the inference question, because that's something that.",
                    "label": 0
                },
                {
                    "sent": "Bothered me during you talk?",
                    "label": 0
                },
                {
                    "sent": "Very interesting by the way, but you mentioned the idea of materializing or inferences and then it makes sense to me.",
                    "label": 1
                },
                {
                    "sent": "But on the other hand, the redundancy would grow as inferences actually add information that is predictable by definition.",
                    "label": 0
                },
                {
                    "sent": "So maybe another another idea would be to materialize or inferences and then.",
                    "label": 0
                },
                {
                    "sent": "Uh.",
                    "label": 0
                },
                {
                    "sent": "Remove everything that.",
                    "label": 0
                },
                {
                    "sent": "That is redundant because of because of.",
                    "label": 0
                },
                {
                    "sent": "Because of the inference, just so just keep the most specific subclasses.",
                    "label": 0
                },
                {
                    "sent": "For example, in the type sets and.",
                    "label": 0
                },
                {
                    "sent": "So you would maybe you would measure something that's more inherent to the data rather than some artificial redundancy coming from the inference.",
                    "label": 0
                },
                {
                    "sent": "Just an idea.",
                    "label": 0
                },
                {
                    "sent": "Interesting, I mean because in a certain way then you could use that again to say.",
                    "label": 0
                },
                {
                    "sent": "Using this redundancy, you can actually compress the data itself because you remove everything that you can influence that is interesting.",
                    "label": 0
                },
                {
                    "sent": "On the other hand.",
                    "label": 0
                },
                {
                    "sent": "This is link data from the web, so it's pretty dirty and pretty noisy.",
                    "label": 0
                },
                {
                    "sent": "Don't remember where someone stop by during the demo session and we found instances that were, I think it was a movie that was described using a fold name property.",
                    "label": 0
                },
                {
                    "sent": "So if you really would use inferencing and taking a look domain and range things then you would end up making that movie a person so.",
                    "label": 0
                },
                {
                    "sent": "I'm not entirely sure if you really would decrease her down.",
                    "label": 0
                },
                {
                    "sent": "It's something that we would have to take a look at.",
                    "label": 0
                },
                {
                    "sent": "Yeah, but it is.",
                    "label": 0
                },
                {
                    "sent": "I like also the idea of just influencing 1st and that or the other way around.",
                    "label": 0
                },
                {
                    "sent": "Remove everything that can be influenced.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "So if you have no questions anymore, then let's think.",
                    "label": 0
                },
                {
                    "sent": "Speak again, thank you.",
                    "label": 0
                }
            ]
        }
    }
}