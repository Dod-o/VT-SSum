{
    "id": "6wvyimcrdlzbzyuyhywpjnm7zg3i5yrx",
    "title": "Incrementally learning an Incremental parser",
    "info": {
        "author": [
            "Yoav Seginer, Institute for Logic, Language & Computation, Dept. of Social Science Informatics, University of Amsterdam"
        ],
        "published": "Oct. 31, 2007",
        "recorded": "June 2007",
        "category": [
            "Top->Computer Science->Text Mining"
        ]
    },
    "url": "http://videolectures.net/mlcs07_seginer_ili/",
    "segmentation": [
        [
            "Morning.",
            "So this talk will certainly be about 1 penalty, but first and foremost it's about."
        ],
        [
            "On Sundays, so when will understand that we can ask yourself the question what is actually the relation between the language surface statistics and the hidden syntactic structure of the language?",
            "So one way to explore this question is to construct an unsupervised party that's in algorithm.",
            "That is exactly that it takes or less statistics from the language surface structure and converts these positive.",
            "That is, this covers the syntactic structure of the language now.",
            "Of course, when I say variation, I'm a bit misleading you, because of course the related might be different relations depending on our choice of syntactical presentation.",
            "On the one hand, and the statistics on the other hand.",
            "So put on whatever they should children means if they do, might be just one of many possibilities.",
            "So in this talk I would do both.",
            "First of all I will present.",
            "A syntactic representation.",
            "Then I represented possible this inactivation.",
            "And finally I would present the learning algorithm collection of statistics for this class.",
            "Um?",
            "So while even if one is not really concerned with cognitive modeling, it's only good to look at what humans do with language, simply because language is, after all, the very human thing.",
            "So I would try to use the following.",
            "I think generally well accepted policies of language, both reconstructing my syntactic representation and in collecting the statistics, and the hope is that if the syntactic representation is well constructed in, the statistics are collected.",
            "But the relation between them should be relatively simple.",
            "This relation is coded by the unsupervised class, so the first probe to properties would be used in constructing the syntactic.",
            "Representation, so first of all, the syntactic structures of language are skewed trees.",
            "That is basically in every subtree of the structure there would be a short branch.",
            "I would code this property into the syntactic representation for this order.",
            "A small version of the Universal graph.",
            "The default is doing so is that if this is indeed a universal open field language, there's no need for the learning algorithm to discover.",
            "This makes learning easier.",
            "The second property I would use is the incrementality of human processing of language, so I would have a incremental parser.",
            "The advantage of this is this is it per mentality.",
            "Considering restricts the possibilities the parcel has considered every step.",
            "This also means that learning it becomes easier because the range of possibilities is small.",
            "Now if indeed the.",
            "Anne.",
            "My incremental parser must be represented incrementality of human processing.",
            "It should remain accurate despite this restriction of the range of possibilities.",
            "So this has to do with representation, so the representation would be well suited for incremental parsing.",
            "The other side of of these, through the syntactic relation and the statistics reduce the following two properties.",
            "First of all, residual distribution reports, so that roughly means that the few words which are very frequent and lots of words which are extremely in free.",
            "Now.",
            "Usually this is very often this is seen as a problem because it's very difficult to predict statistics for all those many words which are extremely infrequent, but I will try to see the glass is half full.",
            "That is, say OK, we have this very small set of words which appear almost everywhere.",
            "Now we try to use those words in in my learning, these words would be used to fasting and learning in a way this is similar to what people do when they induce part of speech.",
            "Then finally another property of language learning is that it's incremental, that is, children tone.",
            "Like to sit in the corner for three years, listen, observe, and then suddenly one day that can speak fluently, but rather they completely used and language while learning the way I will use this in my algorithm is basically that the collection of statistic won't be just directly on the sentences, but on parses of these services.",
            "So my parse I collect statistics are used to improve the parser and so on."
        ],
        [
            "So this was the introduction and now to the details.",
            "So my syntactic representation would be based on what I call former companies.",
            "Basically, these are.",
            "This is a link representation of language in a way similar to dependencies, but it is constructed based on in bracketing and the idea is that from the links one can go back to the practical.",
            "And basically I have a link between world view.",
            "And the words V with the depth D if the other with the smallest bracket covering these two words.",
            "I know how deep is you under this packet.",
            "If it's of minimal depth under that bracket, that is, no word is less deep under the bracket.",
            "I can write a link from you to be an hour."
        ],
        [
            "So let's look at this bracket.",
            "The only two words there there, both of minimal depth under this packet.",
            "This step to 0.",
            "So there is a link from why to center from center."
        ],
        [
            "Five of them zero the next record.",
            "The only word of minimum depth there is X.",
            "The depth to 0.",
            "This is the smallest bracket covering X&Y&XZ that are falling, so that's zero from X to the two."
        ],
        [
            "Other words, and finally the top bracket here.",
            "WF South minimum depth.",
            "This depth is already one.",
            "It's not anymore 0 because there's initial additional bracket between the two and then disconnect those version for which this is."
        ],
        [
            "The minimum back of covering those first, so this is the common cover link representation for this, right?"
        ],
        [
            "So let's look at some of more linguistic example.",
            "So here we have, we can talk.",
            "We have different verb phrase in the bottom of a very simple sentence structure.",
            "I think the first reaction when one sees this say, well, that's the whole lot of links, right?",
            "Maybe we can get rid of some of them and remember, the idea is that I want to get back from the links to the bracket."
        ],
        [
            "So some of these things might be redundant.",
            "For example, the same brackets might have several generators, so it will words from which wich ultimate definitely leaves right.",
            "So for example in the bottom example with work or the determiner or denial of the subject or generators of them correctly.",
            "So I can choose just things."
        ],
        [
            "Of one of those.",
            "A second redundancy is this consecutive links for next to wine.",
            "From what he said, there will always be a link from XZX.",
            "Moreover, the depth of this new can be used from the death of the shoulders."
        ],
        [
            "So therefore I can drop the longer leg speech communities in this truck loadings and therefore this is no representation I would use, and I thought the shortest common coupling sense because it was the shortest lease possible to this right now."
        ],
        [
            "So now by now you're probably wondering what is direction to bring this representation and dependencies.",
            "So here is a simple example.",
            "So first of all, you can see that in weights the structure is similar.",
            "The sum of more links in the shortest form covering setting.",
            "A structure.",
            "But there are three important differences between these two representations, all of which can be seen in this system, for example.",
            "First difference is eccentric constructions, like here the boy so.",
            "The representation I have here learnings from the board and back again in dependencies entirely impossible.",
            "Now.",
            "Why is this would be used?",
            "For example, linguists really have a problem deciding which which of these two is the head of the noun phrase.",
            "My learning algorithm doesn't have to make that decision, so it makes less like a bit simple.",
            "The second thing is that links have deaths, that means.",
            "This, for example.",
            "This allows us to distinguish between the subject which is external to the VP, and this argument, which is internal to the ability 1, means to external argument zooming in internal.",
            "Moreover, to describe any sort of bracketing, one need any unlimited days, but I use only depth zero and one this codes fewness of syntactic structure which I was talking about in the beginning.",
            "Finally, the property of adjacency.",
            "This means that I have here they both representations heavily from node to sleeps, but.",
            "In the shortest, covering it is also a link path to any of the two words between those two words.",
            "This again restricts the range of possibilities that have to be considered by the parser.",
            "Because there are strong relations between the sort of links which help you to the end, so you can't add a link unless it satisfies this problem property."
        ],
        [
            "So.",
            "What is an incremental pass for this representation?",
            "Basically parses the function, which given utterance reduces the shoulders coming covering set for that.",
            "For that reason, and if mentality means that words are being read one by one and at each step links may only be added to or from the last word.",
            "So if I have this sentence at first past this practice up to here now, I've decided to read the next word.",
            "I read it, I'm no longer allowed to change any of the links here, neither add or remove.",
            "Now.",
            "This one interesting formal property of this is that.",
            "The prefix of any mosque isn't itself also shoulders coming coming soon."
        ],
        [
            "So the quick example, this is sort of very known example from the cycling mystical literature.",
            "So here I give other references to some papers which dealt with this issue in somewhat similar way.",
            "So the question is you have two sentences, one of which is the preference of the other and But the problem if I try to parse this incrementally with the dependency files are after.",
            "I've seen this graphics I have to make a different decision.",
            "Joy want this thing or not?",
            "In one sentence, this is correct, the other it's wrong if I'm not allowed to change my decision.",
            "After reading the following word.",
            "I'm not going to make a mistake, but it's known that people have no problem talking this incrementally, but here with the shoulders, covering their representation.",
            "The links for the prefixes of these two sentences are exactly the same, so there is no problem."
        ],
        [
            "So what is the parsing algorithm?",
            "Again, it is very simple.",
            "Ever since certain prefix.",
            "The.",
            "Shortcoming set determines certain things which may be added.",
            "Not everything may be added.",
            "For example, the postage agency property.",
            "Now out of these set of links we have to choose one or none using a wave function.",
            "If we've chosen one, we added to the past and try again.",
            "If we've chosen none, then that means read the next word.",
            "And so it goes on.",
            "So the wave function, that is what the learning algorithm has to estimate has to be able to learn to distinguish between different possible links which may be added by this monster.",
            "And specific way function I've described here is Lexicon, others.",
            "You actually have to learn is the lexicon."
        ],
        [
            "No, now the incrementality of course, is basically what is created is a sequence of next things.",
            "So we start from Lexicon which complained how information.",
            "Then let's you can add I is used to parsing utterance.",
            "Statistics are collected over the sparse.",
            "And these statistics are used to update the next time.",
            "Then this gives a new lexicon and the process can continue with the next packets.",
            "So this happens while parsing.",
            "So basically part learning can be a continuous process which can go on and on and on.",
            "After awhile you would hope that it converges more or less, so it doesn't change."
        ],
        [
            "Much.",
            "So what's index?",
            "And so this is a typical lexical entry, so it has something like argument positions for NC, for example, descriptions where we have arguments with arrives in arguments to the left eye problem, adjacency points.",
            "Because of this adjacency property, and for each such adjacency point.",
            "Dot labels and properties which have a wife and the learning algorithm updates these ways.",
            "So let's first look at the labels labels based on the world.",
            "It can be either class label.",
            "For example, here is the Earth is a faster.",
            "Roughly they say on this side.",
            "Then there are the same or surprising.",
            "There are the same sort of their field, similar problems.",
            "Agency neighbor says.",
            "On this side, this difficulty appears after this sort of word, or something of the same class."
        ],
        [
            "So let's see how these tables are calculated.",
            "Remember that statistics are collected on top of the parts, so let's say I have ever passed.",
            "Now I'm looking at the second argument, position adjacency position on Saturday.",
            "So I looked at the 2nd.",
            "Word which appears in the second potential argument position on 3rd Ave in example noted that this depends on all kinds of things, but it doesn't depend on the day or whether there is an interview today or not.",
            "And now I think I think the statistics collected for the world be on the right and use it to update this.",
            "This is pulled back on the first of all and you can make the strength of the word V being in this position adjacent, and I think each of these labels with its relative weight and update the opposite David.",
            "So if this is a class label feed, this means an adjacency.",
            "If it's exercise B, then W is.",
            "Next to something like X.",
            "So this is a simple update.",
            "It might be that the adjacent support right here to divide with W. Then are you committed to stop?"
        ],
        [
            "And now I want to use these statistics to update the.",
            "Linking problems so basically I probably again in the lexical like to stop property, would say.",
            "Is there an inbounding for outbound and for this certain adjacency position?",
            "Basically this needs to be done only for the first, against imposition of the death of the wife.",
            "For reasons I will show in the Minutes.",
            "So how can I reduce these from the labels?",
            "So basically the idea is to say.",
            "I looked at the statistics say here.",
            "There is no label which is stronger than this doctor on.",
            "So on the right side of.",
            "Sorry, that's I would be with you in Vehicle simulator is it's likely that there is a link from you too.",
            "You probably not because the stock means offering there's nothing there.",
            "And I use this to update the inbound property of you on the right.",
            "So if.",
            "If the property codes and I say no, not actively involved, and if the property does not hold but hold on the other side, I say yes, it is likely to be an impounding.",
            "Use this property so as to these two Council, so random noise.",
            "And this gives me a search first, sort of.",
            "Indication is there inbounding.",
            "To a certain words U on the right.",
            "But now in bounding for one word is an album for the algorithm, so I just do a bit of bootstrapping.",
            "So I update the outbound incorporated for you on the base of the inbounding for V and again the other one.",
            "Other way around.",
            "4IN base from Alex."
        ],
        [
            "This is the learning algorithm that's that's all that's already done.",
            "Now what I have to do is I have to use these in and out properties to deduce things while passing.",
            "So remember what I have to do is I have to decide even 2 towards X&Y, which may possibly be linked.",
            "I have to decide.",
            "What is the weight I'm going to sign for this thing?",
            "So what I do is I could use the in and out properties of X&Y, but this causes certain problem, so instead I know that these two words and I say.",
            "What is this for mismatch of the labels here.",
            "So here for example, this word and this their match.",
            "This is like there and there's typically appears next to something right here, so this is the strongest match and I use the properties of that word to decide on the link.",
            "What is this good first of all?",
            "It solves the problem with whether I want to use the properties of X.",
            "2nd in Heaven as well.",
            "Low frequency words.",
            "So for example, if I have Mr Antenna name, the name is likely to be very low frequency, But the best metric review would be Mr.",
            "So if we use the properties of Mr to link the two words, it might happen that the best matching label is actually none of the tools, but it almost always is treatment for which my solutions are good.",
            "And finally, you can actually have it also do because best mentioned they would depend on your words.",
            "So this when it says determiner I'd get matching table is the term, but when this is used as a pronoun, actually the best country label would be preferred."
        ],
        [
            "And finally, as to having this best mention later, I need to convert it into a way.",
            "And now I have several numbers I might use to do that.",
            "What is the strength of the metric set if strength is low?",
            "I certainly don't want the way to be higher, so the strength would be an upper bound for this.",
            "Now it depends on what sort of Labor was match left.",
            "The match was a class label of X.",
            "Then, basically, since we're looking at the link from X to Y, we want to look at the outbound properties of W on the right side of the building.",
            "So basically, if the outbound properties larger than zero, this is would be the weight.",
            "If the best matching label most across the table, why?",
            "When the link from X to Y is an inbound link on the left side of the video?",
            "So basically I use the in property on the left side of the W. And now there's some sub cases.",
            "For example, here I would if the in an install properties do not agree, let's determines whether it's.",
            "It's a 0 depth or one or the one ending in our cases where the in and out properties do not tell us much about the deck and then I use the match strength."
        ],
        [
            "To determine the weight.",
            "OK, so this describes.",
            "This is basically the relation.",
            "Between the parsing and the statistics.",
            "So the question of course is does this work?",
            "So.",
            "You know it gives the result through several experiments that we compare this with previous work.",
            "So hard work by client money and violence Squad.",
            "Which will I think will be presented here in the session and.",
            "So.",
            "Before the 100 mile presented works from playing cats, it's actually has to work from plain text because it uses a different distribution.",
            "This is not something that's part of speech is this is a popular plain text.",
            "Typically, these solar systems are more often than not evaluated in part of speech sequences, so there's a certain difficulty comparing the results, but more or less one can see that there are on there are more or less the same level operating accuracy."
        ],
        [
            "And.",
            "Something similar can be said about.",
            "German.",
            "Another point is that this actually conditions very fast partial, so this works as well.",
            "Breaking something like 4000 words a second.",
            "And that's just passing.",
            "But when one turns on the learning, it doesn't become it's over, because it's basically just doing business pause.",
            "So 20%.",
            "So this really means if one can leave the learning model form which is used."
        ],
        [
            "OK, So what I had today is a syntactic representation with one hand in a learning algorithm or the other.",
            "The main properties is possible.",
            "This syntactic representation has skewness of the trees built into it.",
            "Why should it for implementing this mentality makes learning parsing simpler and finally passing decisions are made only pointed towards in the sense that I defined before.",
            "Again, this break is simplifies the decision process.",
            "On the other side, on the learning side and these tables, this is in a way they replaced part of speech.",
            "If you look at those lips they very much resemble which one would think of as part of speech tagging in a way, but one doesn't need to cluster anything because basically one just connected, simplistic and then later uses them on the fly on the part.",
            "Different distribution those tables would almost always be high frequency words.",
            "And the statistics are collected from the past is not complaining, it's correctly.",
            "And the best metric label.",
            "Method of determining the election wave solves many problems because usually the best matching labels by how high frequency.",
            "Finally, the result is rather fascinating, also simple."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Morning.",
                    "label": 0
                },
                {
                    "sent": "So this talk will certainly be about 1 penalty, but first and foremost it's about.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "On Sundays, so when will understand that we can ask yourself the question what is actually the relation between the language surface statistics and the hidden syntactic structure of the language?",
                    "label": 1
                },
                {
                    "sent": "So one way to explore this question is to construct an unsupervised party that's in algorithm.",
                    "label": 0
                },
                {
                    "sent": "That is exactly that it takes or less statistics from the language surface structure and converts these positive.",
                    "label": 0
                },
                {
                    "sent": "That is, this covers the syntactic structure of the language now.",
                    "label": 0
                },
                {
                    "sent": "Of course, when I say variation, I'm a bit misleading you, because of course the related might be different relations depending on our choice of syntactical presentation.",
                    "label": 0
                },
                {
                    "sent": "On the one hand, and the statistics on the other hand.",
                    "label": 0
                },
                {
                    "sent": "So put on whatever they should children means if they do, might be just one of many possibilities.",
                    "label": 0
                },
                {
                    "sent": "So in this talk I would do both.",
                    "label": 1
                },
                {
                    "sent": "First of all I will present.",
                    "label": 0
                },
                {
                    "sent": "A syntactic representation.",
                    "label": 0
                },
                {
                    "sent": "Then I represented possible this inactivation.",
                    "label": 0
                },
                {
                    "sent": "And finally I would present the learning algorithm collection of statistics for this class.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So while even if one is not really concerned with cognitive modeling, it's only good to look at what humans do with language, simply because language is, after all, the very human thing.",
                    "label": 0
                },
                {
                    "sent": "So I would try to use the following.",
                    "label": 0
                },
                {
                    "sent": "I think generally well accepted policies of language, both reconstructing my syntactic representation and in collecting the statistics, and the hope is that if the syntactic representation is well constructed in, the statistics are collected.",
                    "label": 0
                },
                {
                    "sent": "But the relation between them should be relatively simple.",
                    "label": 0
                },
                {
                    "sent": "This relation is coded by the unsupervised class, so the first probe to properties would be used in constructing the syntactic.",
                    "label": 0
                },
                {
                    "sent": "Representation, so first of all, the syntactic structures of language are skewed trees.",
                    "label": 0
                },
                {
                    "sent": "That is basically in every subtree of the structure there would be a short branch.",
                    "label": 0
                },
                {
                    "sent": "I would code this property into the syntactic representation for this order.",
                    "label": 0
                },
                {
                    "sent": "A small version of the Universal graph.",
                    "label": 0
                },
                {
                    "sent": "The default is doing so is that if this is indeed a universal open field language, there's no need for the learning algorithm to discover.",
                    "label": 0
                },
                {
                    "sent": "This makes learning easier.",
                    "label": 0
                },
                {
                    "sent": "The second property I would use is the incrementality of human processing of language, so I would have a incremental parser.",
                    "label": 0
                },
                {
                    "sent": "The advantage of this is this is it per mentality.",
                    "label": 0
                },
                {
                    "sent": "Considering restricts the possibilities the parcel has considered every step.",
                    "label": 0
                },
                {
                    "sent": "This also means that learning it becomes easier because the range of possibilities is small.",
                    "label": 0
                },
                {
                    "sent": "Now if indeed the.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "My incremental parser must be represented incrementality of human processing.",
                    "label": 0
                },
                {
                    "sent": "It should remain accurate despite this restriction of the range of possibilities.",
                    "label": 0
                },
                {
                    "sent": "So this has to do with representation, so the representation would be well suited for incremental parsing.",
                    "label": 0
                },
                {
                    "sent": "The other side of of these, through the syntactic relation and the statistics reduce the following two properties.",
                    "label": 0
                },
                {
                    "sent": "First of all, residual distribution reports, so that roughly means that the few words which are very frequent and lots of words which are extremely in free.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "Usually this is very often this is seen as a problem because it's very difficult to predict statistics for all those many words which are extremely infrequent, but I will try to see the glass is half full.",
                    "label": 0
                },
                {
                    "sent": "That is, say OK, we have this very small set of words which appear almost everywhere.",
                    "label": 0
                },
                {
                    "sent": "Now we try to use those words in in my learning, these words would be used to fasting and learning in a way this is similar to what people do when they induce part of speech.",
                    "label": 0
                },
                {
                    "sent": "Then finally another property of language learning is that it's incremental, that is, children tone.",
                    "label": 0
                },
                {
                    "sent": "Like to sit in the corner for three years, listen, observe, and then suddenly one day that can speak fluently, but rather they completely used and language while learning the way I will use this in my algorithm is basically that the collection of statistic won't be just directly on the sentences, but on parses of these services.",
                    "label": 0
                },
                {
                    "sent": "So my parse I collect statistics are used to improve the parser and so on.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this was the introduction and now to the details.",
                    "label": 0
                },
                {
                    "sent": "So my syntactic representation would be based on what I call former companies.",
                    "label": 0
                },
                {
                    "sent": "Basically, these are.",
                    "label": 0
                },
                {
                    "sent": "This is a link representation of language in a way similar to dependencies, but it is constructed based on in bracketing and the idea is that from the links one can go back to the practical.",
                    "label": 0
                },
                {
                    "sent": "And basically I have a link between world view.",
                    "label": 0
                },
                {
                    "sent": "And the words V with the depth D if the other with the smallest bracket covering these two words.",
                    "label": 1
                },
                {
                    "sent": "I know how deep is you under this packet.",
                    "label": 0
                },
                {
                    "sent": "If it's of minimal depth under that bracket, that is, no word is less deep under the bracket.",
                    "label": 1
                },
                {
                    "sent": "I can write a link from you to be an hour.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's look at this bracket.",
                    "label": 0
                },
                {
                    "sent": "The only two words there there, both of minimal depth under this packet.",
                    "label": 1
                },
                {
                    "sent": "This step to 0.",
                    "label": 1
                },
                {
                    "sent": "So there is a link from why to center from center.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Five of them zero the next record.",
                    "label": 0
                },
                {
                    "sent": "The only word of minimum depth there is X.",
                    "label": 1
                },
                {
                    "sent": "The depth to 0.",
                    "label": 0
                },
                {
                    "sent": "This is the smallest bracket covering X&Y&XZ that are falling, so that's zero from X to the two.",
                    "label": 1
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Other words, and finally the top bracket here.",
                    "label": 0
                },
                {
                    "sent": "WF South minimum depth.",
                    "label": 0
                },
                {
                    "sent": "This depth is already one.",
                    "label": 0
                },
                {
                    "sent": "It's not anymore 0 because there's initial additional bracket between the two and then disconnect those version for which this is.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The minimum back of covering those first, so this is the common cover link representation for this, right?",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's look at some of more linguistic example.",
                    "label": 0
                },
                {
                    "sent": "So here we have, we can talk.",
                    "label": 0
                },
                {
                    "sent": "We have different verb phrase in the bottom of a very simple sentence structure.",
                    "label": 0
                },
                {
                    "sent": "I think the first reaction when one sees this say, well, that's the whole lot of links, right?",
                    "label": 0
                },
                {
                    "sent": "Maybe we can get rid of some of them and remember, the idea is that I want to get back from the links to the bracket.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So some of these things might be redundant.",
                    "label": 0
                },
                {
                    "sent": "For example, the same brackets might have several generators, so it will words from which wich ultimate definitely leaves right.",
                    "label": 0
                },
                {
                    "sent": "So for example in the bottom example with work or the determiner or denial of the subject or generators of them correctly.",
                    "label": 0
                },
                {
                    "sent": "So I can choose just things.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of one of those.",
                    "label": 0
                },
                {
                    "sent": "A second redundancy is this consecutive links for next to wine.",
                    "label": 0
                },
                {
                    "sent": "From what he said, there will always be a link from XZX.",
                    "label": 0
                },
                {
                    "sent": "Moreover, the depth of this new can be used from the death of the shoulders.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So therefore I can drop the longer leg speech communities in this truck loadings and therefore this is no representation I would use, and I thought the shortest common coupling sense because it was the shortest lease possible to this right now.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now by now you're probably wondering what is direction to bring this representation and dependencies.",
                    "label": 0
                },
                {
                    "sent": "So here is a simple example.",
                    "label": 0
                },
                {
                    "sent": "So first of all, you can see that in weights the structure is similar.",
                    "label": 0
                },
                {
                    "sent": "The sum of more links in the shortest form covering setting.",
                    "label": 0
                },
                {
                    "sent": "A structure.",
                    "label": 0
                },
                {
                    "sent": "But there are three important differences between these two representations, all of which can be seen in this system, for example.",
                    "label": 0
                },
                {
                    "sent": "First difference is eccentric constructions, like here the boy so.",
                    "label": 1
                },
                {
                    "sent": "The representation I have here learnings from the board and back again in dependencies entirely impossible.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "Why is this would be used?",
                    "label": 0
                },
                {
                    "sent": "For example, linguists really have a problem deciding which which of these two is the head of the noun phrase.",
                    "label": 1
                },
                {
                    "sent": "My learning algorithm doesn't have to make that decision, so it makes less like a bit simple.",
                    "label": 0
                },
                {
                    "sent": "The second thing is that links have deaths, that means.",
                    "label": 0
                },
                {
                    "sent": "This, for example.",
                    "label": 0
                },
                {
                    "sent": "This allows us to distinguish between the subject which is external to the VP, and this argument, which is internal to the ability 1, means to external argument zooming in internal.",
                    "label": 0
                },
                {
                    "sent": "Moreover, to describe any sort of bracketing, one need any unlimited days, but I use only depth zero and one this codes fewness of syntactic structure which I was talking about in the beginning.",
                    "label": 0
                },
                {
                    "sent": "Finally, the property of adjacency.",
                    "label": 1
                },
                {
                    "sent": "This means that I have here they both representations heavily from node to sleeps, but.",
                    "label": 1
                },
                {
                    "sent": "In the shortest, covering it is also a link path to any of the two words between those two words.",
                    "label": 0
                },
                {
                    "sent": "This again restricts the range of possibilities that have to be considered by the parser.",
                    "label": 0
                },
                {
                    "sent": "Because there are strong relations between the sort of links which help you to the end, so you can't add a link unless it satisfies this problem property.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "What is an incremental pass for this representation?",
                    "label": 0
                },
                {
                    "sent": "Basically parses the function, which given utterance reduces the shoulders coming covering set for that.",
                    "label": 0
                },
                {
                    "sent": "For that reason, and if mentality means that words are being read one by one and at each step links may only be added to or from the last word.",
                    "label": 1
                },
                {
                    "sent": "So if I have this sentence at first past this practice up to here now, I've decided to read the next word.",
                    "label": 0
                },
                {
                    "sent": "I read it, I'm no longer allowed to change any of the links here, neither add or remove.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "This one interesting formal property of this is that.",
                    "label": 0
                },
                {
                    "sent": "The prefix of any mosque isn't itself also shoulders coming coming soon.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the quick example, this is sort of very known example from the cycling mystical literature.",
                    "label": 0
                },
                {
                    "sent": "So here I give other references to some papers which dealt with this issue in somewhat similar way.",
                    "label": 0
                },
                {
                    "sent": "So the question is you have two sentences, one of which is the preference of the other and But the problem if I try to parse this incrementally with the dependency files are after.",
                    "label": 0
                },
                {
                    "sent": "I've seen this graphics I have to make a different decision.",
                    "label": 0
                },
                {
                    "sent": "Joy want this thing or not?",
                    "label": 0
                },
                {
                    "sent": "In one sentence, this is correct, the other it's wrong if I'm not allowed to change my decision.",
                    "label": 0
                },
                {
                    "sent": "After reading the following word.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to make a mistake, but it's known that people have no problem talking this incrementally, but here with the shoulders, covering their representation.",
                    "label": 0
                },
                {
                    "sent": "The links for the prefixes of these two sentences are exactly the same, so there is no problem.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what is the parsing algorithm?",
                    "label": 1
                },
                {
                    "sent": "Again, it is very simple.",
                    "label": 0
                },
                {
                    "sent": "Ever since certain prefix.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "Shortcoming set determines certain things which may be added.",
                    "label": 0
                },
                {
                    "sent": "Not everything may be added.",
                    "label": 0
                },
                {
                    "sent": "For example, the postage agency property.",
                    "label": 0
                },
                {
                    "sent": "Now out of these set of links we have to choose one or none using a wave function.",
                    "label": 0
                },
                {
                    "sent": "If we've chosen one, we added to the past and try again.",
                    "label": 1
                },
                {
                    "sent": "If we've chosen none, then that means read the next word.",
                    "label": 0
                },
                {
                    "sent": "And so it goes on.",
                    "label": 0
                },
                {
                    "sent": "So the wave function, that is what the learning algorithm has to estimate has to be able to learn to distinguish between different possible links which may be added by this monster.",
                    "label": 1
                },
                {
                    "sent": "And specific way function I've described here is Lexicon, others.",
                    "label": 0
                },
                {
                    "sent": "You actually have to learn is the lexicon.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "No, now the incrementality of course, is basically what is created is a sequence of next things.",
                    "label": 1
                },
                {
                    "sent": "So we start from Lexicon which complained how information.",
                    "label": 0
                },
                {
                    "sent": "Then let's you can add I is used to parsing utterance.",
                    "label": 0
                },
                {
                    "sent": "Statistics are collected over the sparse.",
                    "label": 0
                },
                {
                    "sent": "And these statistics are used to update the next time.",
                    "label": 0
                },
                {
                    "sent": "Then this gives a new lexicon and the process can continue with the next packets.",
                    "label": 0
                },
                {
                    "sent": "So this happens while parsing.",
                    "label": 1
                },
                {
                    "sent": "So basically part learning can be a continuous process which can go on and on and on.",
                    "label": 0
                },
                {
                    "sent": "After awhile you would hope that it converges more or less, so it doesn't change.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Much.",
                    "label": 0
                },
                {
                    "sent": "So what's index?",
                    "label": 0
                },
                {
                    "sent": "And so this is a typical lexical entry, so it has something like argument positions for NC, for example, descriptions where we have arguments with arrives in arguments to the left eye problem, adjacency points.",
                    "label": 0
                },
                {
                    "sent": "Because of this adjacency property, and for each such adjacency point.",
                    "label": 1
                },
                {
                    "sent": "Dot labels and properties which have a wife and the learning algorithm updates these ways.",
                    "label": 1
                },
                {
                    "sent": "So let's first look at the labels labels based on the world.",
                    "label": 0
                },
                {
                    "sent": "It can be either class label.",
                    "label": 1
                },
                {
                    "sent": "For example, here is the Earth is a faster.",
                    "label": 0
                },
                {
                    "sent": "Roughly they say on this side.",
                    "label": 0
                },
                {
                    "sent": "Then there are the same or surprising.",
                    "label": 0
                },
                {
                    "sent": "There are the same sort of their field, similar problems.",
                    "label": 0
                },
                {
                    "sent": "Agency neighbor says.",
                    "label": 0
                },
                {
                    "sent": "On this side, this difficulty appears after this sort of word, or something of the same class.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's see how these tables are calculated.",
                    "label": 0
                },
                {
                    "sent": "Remember that statistics are collected on top of the parts, so let's say I have ever passed.",
                    "label": 0
                },
                {
                    "sent": "Now I'm looking at the second argument, position adjacency position on Saturday.",
                    "label": 0
                },
                {
                    "sent": "So I looked at the 2nd.",
                    "label": 0
                },
                {
                    "sent": "Word which appears in the second potential argument position on 3rd Ave in example noted that this depends on all kinds of things, but it doesn't depend on the day or whether there is an interview today or not.",
                    "label": 0
                },
                {
                    "sent": "And now I think I think the statistics collected for the world be on the right and use it to update this.",
                    "label": 0
                },
                {
                    "sent": "This is pulled back on the first of all and you can make the strength of the word V being in this position adjacent, and I think each of these labels with its relative weight and update the opposite David.",
                    "label": 0
                },
                {
                    "sent": "So if this is a class label feed, this means an adjacency.",
                    "label": 0
                },
                {
                    "sent": "If it's exercise B, then W is.",
                    "label": 0
                },
                {
                    "sent": "Next to something like X.",
                    "label": 0
                },
                {
                    "sent": "So this is a simple update.",
                    "label": 0
                },
                {
                    "sent": "It might be that the adjacent support right here to divide with W. Then are you committed to stop?",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And now I want to use these statistics to update the.",
                    "label": 0
                },
                {
                    "sent": "Linking problems so basically I probably again in the lexical like to stop property, would say.",
                    "label": 0
                },
                {
                    "sent": "Is there an inbounding for outbound and for this certain adjacency position?",
                    "label": 0
                },
                {
                    "sent": "Basically this needs to be done only for the first, against imposition of the death of the wife.",
                    "label": 0
                },
                {
                    "sent": "For reasons I will show in the Minutes.",
                    "label": 0
                },
                {
                    "sent": "So how can I reduce these from the labels?",
                    "label": 0
                },
                {
                    "sent": "So basically the idea is to say.",
                    "label": 0
                },
                {
                    "sent": "I looked at the statistics say here.",
                    "label": 0
                },
                {
                    "sent": "There is no label which is stronger than this doctor on.",
                    "label": 1
                },
                {
                    "sent": "So on the right side of.",
                    "label": 1
                },
                {
                    "sent": "Sorry, that's I would be with you in Vehicle simulator is it's likely that there is a link from you too.",
                    "label": 0
                },
                {
                    "sent": "You probably not because the stock means offering there's nothing there.",
                    "label": 0
                },
                {
                    "sent": "And I use this to update the inbound property of you on the right.",
                    "label": 0
                },
                {
                    "sent": "So if.",
                    "label": 0
                },
                {
                    "sent": "If the property codes and I say no, not actively involved, and if the property does not hold but hold on the other side, I say yes, it is likely to be an impounding.",
                    "label": 0
                },
                {
                    "sent": "Use this property so as to these two Council, so random noise.",
                    "label": 0
                },
                {
                    "sent": "And this gives me a search first, sort of.",
                    "label": 1
                },
                {
                    "sent": "Indication is there inbounding.",
                    "label": 0
                },
                {
                    "sent": "To a certain words U on the right.",
                    "label": 0
                },
                {
                    "sent": "But now in bounding for one word is an album for the algorithm, so I just do a bit of bootstrapping.",
                    "label": 0
                },
                {
                    "sent": "So I update the outbound incorporated for you on the base of the inbounding for V and again the other one.",
                    "label": 0
                },
                {
                    "sent": "Other way around.",
                    "label": 0
                },
                {
                    "sent": "4IN base from Alex.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is the learning algorithm that's that's all that's already done.",
                    "label": 0
                },
                {
                    "sent": "Now what I have to do is I have to use these in and out properties to deduce things while passing.",
                    "label": 0
                },
                {
                    "sent": "So remember what I have to do is I have to decide even 2 towards X&Y, which may possibly be linked.",
                    "label": 0
                },
                {
                    "sent": "I have to decide.",
                    "label": 0
                },
                {
                    "sent": "What is the weight I'm going to sign for this thing?",
                    "label": 0
                },
                {
                    "sent": "So what I do is I could use the in and out properties of X&Y, but this causes certain problem, so instead I know that these two words and I say.",
                    "label": 0
                },
                {
                    "sent": "What is this for mismatch of the labels here.",
                    "label": 0
                },
                {
                    "sent": "So here for example, this word and this their match.",
                    "label": 0
                },
                {
                    "sent": "This is like there and there's typically appears next to something right here, so this is the strongest match and I use the properties of that word to decide on the link.",
                    "label": 1
                },
                {
                    "sent": "What is this good first of all?",
                    "label": 1
                },
                {
                    "sent": "It solves the problem with whether I want to use the properties of X.",
                    "label": 0
                },
                {
                    "sent": "2nd in Heaven as well.",
                    "label": 0
                },
                {
                    "sent": "Low frequency words.",
                    "label": 1
                },
                {
                    "sent": "So for example, if I have Mr Antenna name, the name is likely to be very low frequency, But the best metric review would be Mr.",
                    "label": 0
                },
                {
                    "sent": "So if we use the properties of Mr to link the two words, it might happen that the best matching label is actually none of the tools, but it almost always is treatment for which my solutions are good.",
                    "label": 1
                },
                {
                    "sent": "And finally, you can actually have it also do because best mentioned they would depend on your words.",
                    "label": 0
                },
                {
                    "sent": "So this when it says determiner I'd get matching table is the term, but when this is used as a pronoun, actually the best country label would be preferred.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And finally, as to having this best mention later, I need to convert it into a way.",
                    "label": 0
                },
                {
                    "sent": "And now I have several numbers I might use to do that.",
                    "label": 0
                },
                {
                    "sent": "What is the strength of the metric set if strength is low?",
                    "label": 0
                },
                {
                    "sent": "I certainly don't want the way to be higher, so the strength would be an upper bound for this.",
                    "label": 0
                },
                {
                    "sent": "Now it depends on what sort of Labor was match left.",
                    "label": 0
                },
                {
                    "sent": "The match was a class label of X.",
                    "label": 0
                },
                {
                    "sent": "Then, basically, since we're looking at the link from X to Y, we want to look at the outbound properties of W on the right side of the building.",
                    "label": 0
                },
                {
                    "sent": "So basically, if the outbound properties larger than zero, this is would be the weight.",
                    "label": 0
                },
                {
                    "sent": "If the best matching label most across the table, why?",
                    "label": 0
                },
                {
                    "sent": "When the link from X to Y is an inbound link on the left side of the video?",
                    "label": 0
                },
                {
                    "sent": "So basically I use the in property on the left side of the W. And now there's some sub cases.",
                    "label": 0
                },
                {
                    "sent": "For example, here I would if the in an install properties do not agree, let's determines whether it's.",
                    "label": 0
                },
                {
                    "sent": "It's a 0 depth or one or the one ending in our cases where the in and out properties do not tell us much about the deck and then I use the match strength.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To determine the weight.",
                    "label": 0
                },
                {
                    "sent": "OK, so this describes.",
                    "label": 0
                },
                {
                    "sent": "This is basically the relation.",
                    "label": 0
                },
                {
                    "sent": "Between the parsing and the statistics.",
                    "label": 0
                },
                {
                    "sent": "So the question of course is does this work?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "You know it gives the result through several experiments that we compare this with previous work.",
                    "label": 0
                },
                {
                    "sent": "So hard work by client money and violence Squad.",
                    "label": 0
                },
                {
                    "sent": "Which will I think will be presented here in the session and.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Before the 100 mile presented works from playing cats, it's actually has to work from plain text because it uses a different distribution.",
                    "label": 0
                },
                {
                    "sent": "This is not something that's part of speech is this is a popular plain text.",
                    "label": 0
                },
                {
                    "sent": "Typically, these solar systems are more often than not evaluated in part of speech sequences, so there's a certain difficulty comparing the results, but more or less one can see that there are on there are more or less the same level operating accuracy.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Something similar can be said about.",
                    "label": 0
                },
                {
                    "sent": "German.",
                    "label": 0
                },
                {
                    "sent": "Another point is that this actually conditions very fast partial, so this works as well.",
                    "label": 0
                },
                {
                    "sent": "Breaking something like 4000 words a second.",
                    "label": 0
                },
                {
                    "sent": "And that's just passing.",
                    "label": 0
                },
                {
                    "sent": "But when one turns on the learning, it doesn't become it's over, because it's basically just doing business pause.",
                    "label": 0
                },
                {
                    "sent": "So 20%.",
                    "label": 0
                },
                {
                    "sent": "So this really means if one can leave the learning model form which is used.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, So what I had today is a syntactic representation with one hand in a learning algorithm or the other.",
                    "label": 0
                },
                {
                    "sent": "The main properties is possible.",
                    "label": 0
                },
                {
                    "sent": "This syntactic representation has skewness of the trees built into it.",
                    "label": 1
                },
                {
                    "sent": "Why should it for implementing this mentality makes learning parsing simpler and finally passing decisions are made only pointed towards in the sense that I defined before.",
                    "label": 0
                },
                {
                    "sent": "Again, this break is simplifies the decision process.",
                    "label": 0
                },
                {
                    "sent": "On the other side, on the learning side and these tables, this is in a way they replaced part of speech.",
                    "label": 0
                },
                {
                    "sent": "If you look at those lips they very much resemble which one would think of as part of speech tagging in a way, but one doesn't need to cluster anything because basically one just connected, simplistic and then later uses them on the fly on the part.",
                    "label": 0
                },
                {
                    "sent": "Different distribution those tables would almost always be high frequency words.",
                    "label": 1
                },
                {
                    "sent": "And the statistics are collected from the past is not complaining, it's correctly.",
                    "label": 1
                },
                {
                    "sent": "And the best metric label.",
                    "label": 0
                },
                {
                    "sent": "Method of determining the election wave solves many problems because usually the best matching labels by how high frequency.",
                    "label": 0
                },
                {
                    "sent": "Finally, the result is rather fascinating, also simple.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": []
        }
    }
}