{
    "id": "m5d3asmcoukrt63e2ortvsnvnfzkxaha",
    "title": "Libra",
    "info": {
        "author": [
            "Daniel Lowd, Department of Computer and Information Science, University of Oregon"
        ],
        "published": "July 20, 2010",
        "recorded": "June 2010",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/icml2010_lowd_libra/",
    "segmentation": [
        [
            "Hi, my name is Daniel Loud and I'm going to be talking about the Libra."
        ],
        [
            "Book it.",
            "So, in a nutshell, Libra is a command line tool kit for learning and inference in Bayesian networks, random fields and arithmetic circuits.",
            "Hence the acronym Libra.",
            "Although I should mention that random fields aren't entirely supported yet, they're coming very, very soon, bit by bit.",
            "And some of that is already available in the source repository."
        ],
        [
            "So the functionality is focused on structure learning and weight learning, mainly structured learning and also on exact approximate inference and on ways of combining learning with inference.",
            "And the levers real strength relative to all of the other toolkits and libraries out there is on using arithmetic circuits and local structure to perform efficient exact inference.",
            "Even in models that have high treewidth and would otherwise be intractable for exact inference.",
            "Libra is written in O Caml because O Caml.",
            "Is fast and fun and I'll go into that a little bit more later and we use a modified BSD license because we want to allow industry to take up these ideas and reuse them.",
            "So for the purpose of.",
            "Technology transfer to industry.",
            "No good news is good news."
        ],
        [
            "So it's basically the GNU GNU BSD license, so that you don't have the.",
            "Yeah.",
            "So you don't have to credit Berkeley, that's the original busy right this right?",
            "I didn't say that you have to create a berkeleyan changed.",
            "Replace birthday by yourself.",
            "So in the remainder of the talk, I'll give you a little bit of background in graphical models and local structure in them and arithmetic circuits.",
            "I'll talk about the algorithms we have implemented currently and a little bit about the implementation.",
            "Give a demo and conclude with some lessons learned."
        ],
        [
            "So probabilistic graphical models are a way of compactly representing a probability distribution over some set of variables.",
            "In Libra, we currently assume a fixed set of variables, so no relational models and that all of the variables are discrete, so no continuous variables.",
            "And the two popular ways of doing this are Bayesian networks and Markov networks, and they mainly differ in how they factor a probability distribution into a product of these functions over fewer variables.",
            "So in a Bayesian network, each of these factors have to be a conditional probability distribution in a Markov network.",
            "It's less constrained, but the price you pay is there's a normalization constant that can make certain things harder, like weight learning, and you get a slightly different representation.",
            "In Markham Networks, you're allowed to have cycles.",
            "In Bayesian networks you avoid cycles."
        ],
        [
            "Another way of looking at probabilistic graphical models is if you were to represent all possible.",
            "Configurations and their corresponding probabilities.",
            "Buy new running them in a table.",
            "It would take exponential amount of space, but if you can represent it as a product of smaller tables that you can save A lot of space, which leads to more compact representation, faster inference, better learning etc etc.",
            "So sometime."
        ],
        [
            "You can do better than tables as well, so here's an example of a table where this is representing the conditional probability of C given A&B, and it's maybe one of the factors I want to use in a Bayesian network.",
            "And when a is true, the probability of C given a is .1 independent of what B is.",
            "So I'd like to capture this context specific independence and I can do that with a decision tree here.",
            "So when a is true, the probability of C is .1, otherwise we need to check the value of B.",
            "And at this scale it's not a huge win, but you can now imagine that you could have a factor with over 100 variables he wanted, because as long as the number of leaves is small, the representation is."
        ],
        [
            "Impact another popular way of representing local structure is to have some feature functions, so here's one potential in a Markov random field.",
            "This is just again a table representing one of the factors that you would multiply together to get this probability distribution.",
            "And we can represent more compactly as this sort of test.",
            "It has a value of 4.48.",
            "If this feature A and not B is true in.",
            "Otherwise it has the value one.",
            "People represent these as features.",
            "Attach weights and you can form a log linear model like this where you have arbitrary features and now all that matters is that you have a small number of features.",
            "It doesn't matter if some of these are very, very long conjunctions, you don't have to worry about exponentially sized tables.",
            "And these are the things that Libra is good at supporting and representing.",
            "Instead of using the full table."
        ],
        [
            "So finally arithmetic circuits.",
            "So this is an inference representation, sort of proposed an popularized by adding Darwish at UCLA and the basic idea is if you're going to do inference in a graphical model.",
            "There's typically a bunch of additions and multiplications.",
            "You would have to perform in order to some out variables or do conditioning or whatnot and the arithmetic circuit is going to represent all of those operations in a directed acyclic graph.",
            "So each of these interior nodes is the times or plus and the leaf nodes are input.",
            "So we have these thetas here that represent model parameters.",
            "So those are some numerical values and we have these indicator functions that will be.",
            "These lambdas will be zero or one, and by setting them through the right values you want, you can effectively some out any variable or or condition on any variable to get fast computations, and so the arithmetic circuit could be very big exponential in size, but inference is linear in the size of this circuit.",
            "So if you can find a compact arithmetic circuit.",
            "Then you have efficient inference, even potentially if you have a high tree with model.",
            "And arithmetic circuits are very good at exploiting local structures, so if there's a single computation that you would have to perform multiple times in the arithmetic circuit, you can reference that one computation many times by a bunch of different parents.",
            "So that's how arithmetic circuits can make things fast."
        ],
        [
            "And lever builds on that.",
            "So now let me talk about the algorithm."
        ],
        [
            "So we have implemented so for structure learning we have child who algorithm.",
            "It's a simple classic standard way of learning a tree distribution.",
            "Bayesian network or Markov network?",
            "It's a nice benchmark to have and then we have methods for learning Bayesian networks and dependency networks with where the where the conditional probability distributions are represented as these decision trees that I showed you before so that potentially gives us much more compact representation and these are algorithms developed by Max Chickering.",
            "David Heckerman, Chris Meek and other people at Microsoft Research.",
            "So now we can learn models with say over 100 parents for single node which is nice to be able to do and then the final algorithm here which is sort of one of the reasons why the whole toolkit was developed and is by far the most complex algorithm is where we actually learn an arithmetic circuit or learn a Bayesian network but guide its structure.",
            "Learning by the size of the corresponding arithmetic circuit.",
            "So think of it as learning a model and its influence representation at the same time.",
            "So you always get fast inference out.",
            "Even if you have a really complex model that you learn, you only learn models that give you fast inference.",
            "And so now we can learn models that maybe have over 100 parents for some nodes, but still give you exact inference in like 100 milliseconds.",
            "So that's a nice thing to have.",
            "Of course, your mileage may vary.",
            "You are paying some penalty in terms of constraining yourself to models that have efficient inference.",
            "Everything varies with the data set, but this is the sort of thing that you can get with these algorithms."
        ],
        [
            "Max loading local structure like that.",
            "For exact inference we have implemented this AC verbal elimination method by Chevere and Darwish, which is a method of taking a Bayesian network and compiling into an arithmetic circuit and it's very good at exploiting local structure even in the table.",
            "So if the same value appears a bunch of times in the table, it's able to exploit that and it basically runs variable elimination and instead of throwing away the factors that creates it.",
            "It sums up variables.",
            "It sort of grows in arithmetic circuit representing all those operations.",
            "And then once you have an arithmetic circuit, either from learning it or compiling it, we can do exact inference in linear time and we have just a utility that does that."
        ],
        [
            "We also have some approximate inference benchmarks for comparison, and that's Gibbs sampling, loopy belief propagation and mean field, and all of these are implemented to be aware of tree distributions or other kinds of local structure, so that if you have.",
            "A very complex tree you're running time depends on number of leaves in that tree, not the total number of variables that appear in that."
        ],
        [
            "Free.",
            "So some things we don't have, we don't really have Markov network in CRF support yet.",
            "It's sort of in the process.",
            "Some of the code is written.",
            "Some of the code is still being written.",
            "We don't have time series or relational models.",
            "There's other toolkits that do handle that, and there's a lot of advance approximate inference methods that we don't have that you can find another toolkits, and there's even other structure learning methods we don't have, but our emphasis really is on local structure in arithmetic circuits, and we'd like to have as many other baselines and alternatives as possible in the toolkit.",
            "Because that's more useful and friendly and fun, but we're really focused on what can you do by exploiting local structure for representation and inference."
        ],
        [
            "And learning.",
            "So."
        ],
        [
            "A little bit about the implementation.",
            "So Libra is a toolkit.",
            "It would be nice if library as well, but for now things are changing fast enough that it's best to just use it as a tool kit.",
            "We have this collection of standalone command line executables representing the different algorithms and they are all designed to take similar command line parameters.",
            "So Dash I in one program corresponds to Dash I in another program for the most part.",
            "Yes, you want that."
        ],
        [
            "I think it's obvious and shared code is wrapped into libraries as much as possible.",
            "I won't suggest that these libraries be used outside the context of the toolkit, but they're very useful within the context of the toolkit for having multiple little programs that all build on the same basic functionality.",
            "So we have some common definition that utility methods basically extension of the standard library we have input and output of data, and we have a couple C libraries that were.",
            "Wrapped for use with O Caml, LB, FGS and X path for XML parsing and then we have Bayesian network in circuit representations and everything is subject to renaming, refactoring because as new implementation continues to be added, things need to change."
        ],
        [
            "So I feel the need to defend O Caml because it's not a very popular language for implementing things, especially if you want other people to participate in your project.",
            "And most people don't know Camel.",
            "So while I think Ocaml is worth the effort to learn and use is because it's almost as fast as C++, and I think almost as fun as Python.",
            "So this can lead to faster development, refactoring and execution times.",
            "So the language has a lot of features it supports, both functional and procedural programming.",
            "Functional programming is nice for writing code quickly.",
            "Procedural programming is nice for those cases when something doesn't really make sense as a big recursion, or when you really want something to run fast.",
            "Sometimes you just want to iterate over an array, and O Caml makes it easy to sort of switch between those two different ways of doing things as you want.",
            "Garbage collection is nice if you've.",
            "Spend enough time dealing with C++.",
            "You really start to appreciate that strong static typing is nice, so that means that the compiler catches a whole lot of errors.",
            "So once your code compiles, it will probably run and you probably won't get too many errors and crashes.",
            "Unlike something like Python which is dynamically typed, you could have it run along and then get halfway through and then find an error and crash.",
            "And in O Caml that happens less.",
            "Has automatic type inference, so you don't spend all your time writing things like a CD:: list, open Racket, list, [might data type, star star Foo.",
            "And it has native code compilation that supports Linux, OSX and other things, and it's easy to link to C code."
        ],
        [
            "So let me just briefly show you an example.",
            "Suppose you want to do something simple like just test to see if a list of conditions is satisfied by an instance.",
            "So there might be some Markov network feature that you want to test.",
            "This is actually real example from the code, and if you were to do this in C++ then you probably define some sort of class that represented one of these conditions and then have some sort of list of them, maybe using STL and test each one of these in turn, and that would be OK.",
            "It would be, you know, readable code.",
            "But you're spending a lot of energy on defining this class and that kind of overhead even without any getters or setters, or copy constructors or destructors.",
            "And O Caml, it's much more compact to write.",
            "You just sort of saying for each element in this list applied this anonymous function that test to see if a variable matches a particular value in the instance.",
            "And since allows you to distinguish between equality and inequality.",
            "So when things are this compact to write, they also get much more compact to rewrite and to read and to refactor.",
            "And if you are.",
            "Working on developing new algorithms and you need to re develop new algorithms when your ideas don't work or you get new ideas then being able to change things around quickly is a big benefit."
        ],
        [
            "So a brief demo.",
            "Instead of typing in all these commands myself.",
            "I put them in a script.",
            "So let's start by learning a chow lutry.",
            "We give it some input data, which is basically a comma separated file format schema, so it knows the dimension of each variable and tell it to output this dot X MoD file, which is the same file format used by the Wind Toolkit.",
            "And you can set a prior.",
            "It runs, figured out the schema.",
            "Few seconds there and now it's created the.",
            "Asian Network you desire?",
            "Why does it print out so many things?",
            "Oh OK, so so this is the schema, so this is a data set that has 294 Boolean variables in it.",
            "So each of these.",
            "So this is the schema for the data set.",
            "Arguably I need to revise what gets outputted to make it make more sense.",
            "Or be more discreet about what it chooses to print out or not, but all these.",
            "So each of these Two's is the dimension of one of the variables, so that's a complete variable schema.",
            "And if you were to run the Chao Lu command without any arguments, then it gives you a helpful usage message.",
            "These arguments here log file volts output and enabled.",
            "Debugging output are standardized across all of the commands, so all commands support those options.",
            "So now let's take this Bayesian network and use the AC verbal elimination algorithm to compile it into an arithmetic circuit.",
            "So that's pretty fast to run because it's a tree and trees are small and easy.",
            "Enough, let's alternately generate next circuit by learning it directly from the data.",
            "So again, we specify the input schema and output arithmetic circuit and output Beijing network.",
            "So we can run this and.",
            "I accidentally commented outline and didn't really comment.",
            "The fix that we will show that later it prints out a lot of stuff and generates a vision network and everything circuit.",
            "Honest, really.",
            "So then you can score these models with simple log likelihood scoring.",
            "To get average log likelihood of.",
            "Test data or something for arithmetic circuit and we see that one of the models learned a little bit better than on the test data.",
            "And then we can issue queries to get, say all marginal all single variable marginals.",
            "And there's 294 of them, so this.",
            "Ends up being.",
            "A lot.",
            "If you have particular queries you like, you want to know the probability of A&B and not C&D.",
            "Then you can represent these in a query file and it will give you the probability of that conjunction, so this isn't just marginal inference, this is the probability of a particular configuration.",
            "So it gives you the log probability of each of those configurations, as well as an average if you care about that sort of thing.",
            "And you can also run mean field in a Bayesian network to get similarly bunch of marginals.",
            "Or with a query.",
            "Or you can also specify some evidence.",
            "And now you're getting conditional probabilities.",
            "You can specify Dash V for verbose and get a little bit more information about timing information and the whole command string that you typed, which is useful for experiments and the total time things like that, and similarly you can do the same with belief propagation."
        ],
        [
            "So lessons learned.",
            "I found that research code requires frequent refactoring, at least in the early stages of an algorithm, and some languages are better at this than others, and I've had great fun with O Caml.",
            "It may not be the best for every project, but it's worked well here and automated tests are awesome, so I only started actually having automated tests fairly recently, but it's really nice to have that extra bit of.",
            "So I won't say it's not complete security, but you feel a little bit safer when you know that your code is giving the same answers that it gave yesterday, at least on a bunch of really complex test problems."
        ],
        [
            "Especially.",
            "Yes, especially for refactoring.",
            "Currently I just have smoke tests where I test I have the output of what this complete algorithm would generate.",
            "Given this data set and then I do this to see if they differ at all, and if they don't then I take that to be a good sign.",
            "Unit tests would be nice as well or integration tests, but even just smoke tests are very good.",
            "For finding errors more quickly and knowing that most things are still working the same.",
            "So we have fast implementations of both classic and cutting edge learning and inference algorithms, and the key strength of this toolkit is really excluding content specific independence for efficient representation learning and inference, and using arithmetic circuits.",
            "And more functionality is coming soon, probably in the next few weeks, and then even more later on this summer.",
            "And so on.",
            "And you can find it all at libra.cs.org.edu.",
            "Thanks.",
            "You mentioned this a paramedic service.",
            "Could you do something example of?",
            "Inference problems it can actually speed up.",
            "You mentioned that you support some gifts distributions.",
            "Let's say that you have only submachine structure and you would like normally would.",
            "So the inference by some dynamic programming.",
            "But if you say use your arithmetic circuit, you said that you can do it in linear time.",
            "Programming requires quadratic.",
            "It's linear in the size of the arithmetic circuit.",
            "So.",
            "Yeah, that's the catch, here's a."
        ],
        [
            "Sort of an explanation of how arithmetic circuits work and what they're really doing.",
            "If you have some Bayesian network, this factored representation, any Bayesian network you can represent as sort of this network polynomial.",
            "Where you have a product of a bunch of these indicator functions and parameters.",
            "So this is basically adding up the probability of all configurations and the arithmetic circuit is a factored way to represent that more compactly, and so you could translate a junction tree into an arithmetic circuit easilly, and if there's a bunch of of context specific in dependencies or repeated values or determinism probabilities that one or zero, then potentially in the junction tree you'll be doing many computations that are unnecessary.",
            "Or doing them multiple times unnecessarily, and the arithmetic circuit is better at.",
            "Getting rid of unnecessary computations and redundancy compared to what you do and say junction tree or variable elimination.",
            "So when you're this is this lever takes advantage of repeated values by putting them in a tree.",
            "But any real set of data you will never get rarely get.",
            "A repeated value, doesn't do some coercing or approximation to, so you can say the same thing about any Bayesian network structure.",
            "Learning in real data you very rarely get true conditional independence, but you can learn it anyway, so it's a matter of.",
            "You could say you could argue that what the vision network is doing by learning these conditional Independencies is a kind of regularization, or that it's just convenient for representation.",
            "Different ways of looking at it, but it's the same argument for local structure and content specific independence.",
            "Does the problem really?",
            "So is this helping it does it?",
            "I mean, what is it?",
            "What is it doing to encourage repeated values?",
            "So for for the structure learning it is doing this by learning a tree distribution at each node.",
            "So if you think about learning a probabilistic decision tree.",
            "You split on one value at a time and you will naturally get usually most of the time you'll get a final decision tree that is not equivalent to a full table.",
            "Typically we're not learning a full table and then trying to find a matching decision tree.",
            "We're learning the decision tree to begin with, which means we always end up with.",
            "Typically some kind of.",
            "Context with independence.",
            "Fixing to speak again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi, my name is Daniel Loud and I'm going to be talking about the Libra.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Book it.",
                    "label": 0
                },
                {
                    "sent": "So, in a nutshell, Libra is a command line tool kit for learning and inference in Bayesian networks, random fields and arithmetic circuits.",
                    "label": 1
                },
                {
                    "sent": "Hence the acronym Libra.",
                    "label": 0
                },
                {
                    "sent": "Although I should mention that random fields aren't entirely supported yet, they're coming very, very soon, bit by bit.",
                    "label": 0
                },
                {
                    "sent": "And some of that is already available in the source repository.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the functionality is focused on structure learning and weight learning, mainly structured learning and also on exact approximate inference and on ways of combining learning with inference.",
                    "label": 0
                },
                {
                    "sent": "And the levers real strength relative to all of the other toolkits and libraries out there is on using arithmetic circuits and local structure to perform efficient exact inference.",
                    "label": 1
                },
                {
                    "sent": "Even in models that have high treewidth and would otherwise be intractable for exact inference.",
                    "label": 0
                },
                {
                    "sent": "Libra is written in O Caml because O Caml.",
                    "label": 0
                },
                {
                    "sent": "Is fast and fun and I'll go into that a little bit more later and we use a modified BSD license because we want to allow industry to take up these ideas and reuse them.",
                    "label": 0
                },
                {
                    "sent": "So for the purpose of.",
                    "label": 0
                },
                {
                    "sent": "Technology transfer to industry.",
                    "label": 0
                },
                {
                    "sent": "No good news is good news.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So it's basically the GNU GNU BSD license, so that you don't have the.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "So you don't have to credit Berkeley, that's the original busy right this right?",
                    "label": 0
                },
                {
                    "sent": "I didn't say that you have to create a berkeleyan changed.",
                    "label": 0
                },
                {
                    "sent": "Replace birthday by yourself.",
                    "label": 0
                },
                {
                    "sent": "So in the remainder of the talk, I'll give you a little bit of background in graphical models and local structure in them and arithmetic circuits.",
                    "label": 1
                },
                {
                    "sent": "I'll talk about the algorithms we have implemented currently and a little bit about the implementation.",
                    "label": 0
                },
                {
                    "sent": "Give a demo and conclude with some lessons learned.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So probabilistic graphical models are a way of compactly representing a probability distribution over some set of variables.",
                    "label": 1
                },
                {
                    "sent": "In Libra, we currently assume a fixed set of variables, so no relational models and that all of the variables are discrete, so no continuous variables.",
                    "label": 0
                },
                {
                    "sent": "And the two popular ways of doing this are Bayesian networks and Markov networks, and they mainly differ in how they factor a probability distribution into a product of these functions over fewer variables.",
                    "label": 0
                },
                {
                    "sent": "So in a Bayesian network, each of these factors have to be a conditional probability distribution in a Markov network.",
                    "label": 0
                },
                {
                    "sent": "It's less constrained, but the price you pay is there's a normalization constant that can make certain things harder, like weight learning, and you get a slightly different representation.",
                    "label": 0
                },
                {
                    "sent": "In Markham Networks, you're allowed to have cycles.",
                    "label": 1
                },
                {
                    "sent": "In Bayesian networks you avoid cycles.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another way of looking at probabilistic graphical models is if you were to represent all possible.",
                    "label": 0
                },
                {
                    "sent": "Configurations and their corresponding probabilities.",
                    "label": 0
                },
                {
                    "sent": "Buy new running them in a table.",
                    "label": 0
                },
                {
                    "sent": "It would take exponential amount of space, but if you can represent it as a product of smaller tables that you can save A lot of space, which leads to more compact representation, faster inference, better learning etc etc.",
                    "label": 0
                },
                {
                    "sent": "So sometime.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You can do better than tables as well, so here's an example of a table where this is representing the conditional probability of C given A&B, and it's maybe one of the factors I want to use in a Bayesian network.",
                    "label": 0
                },
                {
                    "sent": "And when a is true, the probability of C given a is .1 independent of what B is.",
                    "label": 0
                },
                {
                    "sent": "So I'd like to capture this context specific independence and I can do that with a decision tree here.",
                    "label": 0
                },
                {
                    "sent": "So when a is true, the probability of C is .1, otherwise we need to check the value of B.",
                    "label": 0
                },
                {
                    "sent": "And at this scale it's not a huge win, but you can now imagine that you could have a factor with over 100 variables he wanted, because as long as the number of leaves is small, the representation is.",
                    "label": 1
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Impact another popular way of representing local structure is to have some feature functions, so here's one potential in a Markov random field.",
                    "label": 0
                },
                {
                    "sent": "This is just again a table representing one of the factors that you would multiply together to get this probability distribution.",
                    "label": 0
                },
                {
                    "sent": "And we can represent more compactly as this sort of test.",
                    "label": 0
                },
                {
                    "sent": "It has a value of 4.48.",
                    "label": 0
                },
                {
                    "sent": "If this feature A and not B is true in.",
                    "label": 0
                },
                {
                    "sent": "Otherwise it has the value one.",
                    "label": 0
                },
                {
                    "sent": "People represent these as features.",
                    "label": 0
                },
                {
                    "sent": "Attach weights and you can form a log linear model like this where you have arbitrary features and now all that matters is that you have a small number of features.",
                    "label": 0
                },
                {
                    "sent": "It doesn't matter if some of these are very, very long conjunctions, you don't have to worry about exponentially sized tables.",
                    "label": 0
                },
                {
                    "sent": "And these are the things that Libra is good at supporting and representing.",
                    "label": 0
                },
                {
                    "sent": "Instead of using the full table.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So finally arithmetic circuits.",
                    "label": 0
                },
                {
                    "sent": "So this is an inference representation, sort of proposed an popularized by adding Darwish at UCLA and the basic idea is if you're going to do inference in a graphical model.",
                    "label": 0
                },
                {
                    "sent": "There's typically a bunch of additions and multiplications.",
                    "label": 0
                },
                {
                    "sent": "You would have to perform in order to some out variables or do conditioning or whatnot and the arithmetic circuit is going to represent all of those operations in a directed acyclic graph.",
                    "label": 1
                },
                {
                    "sent": "So each of these interior nodes is the times or plus and the leaf nodes are input.",
                    "label": 1
                },
                {
                    "sent": "So we have these thetas here that represent model parameters.",
                    "label": 0
                },
                {
                    "sent": "So those are some numerical values and we have these indicator functions that will be.",
                    "label": 0
                },
                {
                    "sent": "These lambdas will be zero or one, and by setting them through the right values you want, you can effectively some out any variable or or condition on any variable to get fast computations, and so the arithmetic circuit could be very big exponential in size, but inference is linear in the size of this circuit.",
                    "label": 0
                },
                {
                    "sent": "So if you can find a compact arithmetic circuit.",
                    "label": 0
                },
                {
                    "sent": "Then you have efficient inference, even potentially if you have a high tree with model.",
                    "label": 0
                },
                {
                    "sent": "And arithmetic circuits are very good at exploiting local structures, so if there's a single computation that you would have to perform multiple times in the arithmetic circuit, you can reference that one computation many times by a bunch of different parents.",
                    "label": 1
                },
                {
                    "sent": "So that's how arithmetic circuits can make things fast.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And lever builds on that.",
                    "label": 0
                },
                {
                    "sent": "So now let me talk about the algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we have implemented so for structure learning we have child who algorithm.",
                    "label": 1
                },
                {
                    "sent": "It's a simple classic standard way of learning a tree distribution.",
                    "label": 0
                },
                {
                    "sent": "Bayesian network or Markov network?",
                    "label": 0
                },
                {
                    "sent": "It's a nice benchmark to have and then we have methods for learning Bayesian networks and dependency networks with where the where the conditional probability distributions are represented as these decision trees that I showed you before so that potentially gives us much more compact representation and these are algorithms developed by Max Chickering.",
                    "label": 0
                },
                {
                    "sent": "David Heckerman, Chris Meek and other people at Microsoft Research.",
                    "label": 0
                },
                {
                    "sent": "So now we can learn models with say over 100 parents for single node which is nice to be able to do and then the final algorithm here which is sort of one of the reasons why the whole toolkit was developed and is by far the most complex algorithm is where we actually learn an arithmetic circuit or learn a Bayesian network but guide its structure.",
                    "label": 0
                },
                {
                    "sent": "Learning by the size of the corresponding arithmetic circuit.",
                    "label": 0
                },
                {
                    "sent": "So think of it as learning a model and its influence representation at the same time.",
                    "label": 0
                },
                {
                    "sent": "So you always get fast inference out.",
                    "label": 0
                },
                {
                    "sent": "Even if you have a really complex model that you learn, you only learn models that give you fast inference.",
                    "label": 0
                },
                {
                    "sent": "And so now we can learn models that maybe have over 100 parents for some nodes, but still give you exact inference in like 100 milliseconds.",
                    "label": 1
                },
                {
                    "sent": "So that's a nice thing to have.",
                    "label": 0
                },
                {
                    "sent": "Of course, your mileage may vary.",
                    "label": 0
                },
                {
                    "sent": "You are paying some penalty in terms of constraining yourself to models that have efficient inference.",
                    "label": 0
                },
                {
                    "sent": "Everything varies with the data set, but this is the sort of thing that you can get with these algorithms.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Max loading local structure like that.",
                    "label": 0
                },
                {
                    "sent": "For exact inference we have implemented this AC verbal elimination method by Chevere and Darwish, which is a method of taking a Bayesian network and compiling into an arithmetic circuit and it's very good at exploiting local structure even in the table.",
                    "label": 1
                },
                {
                    "sent": "So if the same value appears a bunch of times in the table, it's able to exploit that and it basically runs variable elimination and instead of throwing away the factors that creates it.",
                    "label": 0
                },
                {
                    "sent": "It sums up variables.",
                    "label": 0
                },
                {
                    "sent": "It sort of grows in arithmetic circuit representing all those operations.",
                    "label": 0
                },
                {
                    "sent": "And then once you have an arithmetic circuit, either from learning it or compiling it, we can do exact inference in linear time and we have just a utility that does that.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We also have some approximate inference benchmarks for comparison, and that's Gibbs sampling, loopy belief propagation and mean field, and all of these are implemented to be aware of tree distributions or other kinds of local structure, so that if you have.",
                    "label": 0
                },
                {
                    "sent": "A very complex tree you're running time depends on number of leaves in that tree, not the total number of variables that appear in that.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Free.",
                    "label": 0
                },
                {
                    "sent": "So some things we don't have, we don't really have Markov network in CRF support yet.",
                    "label": 1
                },
                {
                    "sent": "It's sort of in the process.",
                    "label": 0
                },
                {
                    "sent": "Some of the code is written.",
                    "label": 0
                },
                {
                    "sent": "Some of the code is still being written.",
                    "label": 0
                },
                {
                    "sent": "We don't have time series or relational models.",
                    "label": 1
                },
                {
                    "sent": "There's other toolkits that do handle that, and there's a lot of advance approximate inference methods that we don't have that you can find another toolkits, and there's even other structure learning methods we don't have, but our emphasis really is on local structure in arithmetic circuits, and we'd like to have as many other baselines and alternatives as possible in the toolkit.",
                    "label": 1
                },
                {
                    "sent": "Because that's more useful and friendly and fun, but we're really focused on what can you do by exploiting local structure for representation and inference.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And learning.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A little bit about the implementation.",
                    "label": 0
                },
                {
                    "sent": "So Libra is a toolkit.",
                    "label": 0
                },
                {
                    "sent": "It would be nice if library as well, but for now things are changing fast enough that it's best to just use it as a tool kit.",
                    "label": 0
                },
                {
                    "sent": "We have this collection of standalone command line executables representing the different algorithms and they are all designed to take similar command line parameters.",
                    "label": 1
                },
                {
                    "sent": "So Dash I in one program corresponds to Dash I in another program for the most part.",
                    "label": 0
                },
                {
                    "sent": "Yes, you want that.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I think it's obvious and shared code is wrapped into libraries as much as possible.",
                    "label": 0
                },
                {
                    "sent": "I won't suggest that these libraries be used outside the context of the toolkit, but they're very useful within the context of the toolkit for having multiple little programs that all build on the same basic functionality.",
                    "label": 0
                },
                {
                    "sent": "So we have some common definition that utility methods basically extension of the standard library we have input and output of data, and we have a couple C libraries that were.",
                    "label": 0
                },
                {
                    "sent": "Wrapped for use with O Caml, LB, FGS and X path for XML parsing and then we have Bayesian network in circuit representations and everything is subject to renaming, refactoring because as new implementation continues to be added, things need to change.",
                    "label": 1
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I feel the need to defend O Caml because it's not a very popular language for implementing things, especially if you want other people to participate in your project.",
                    "label": 0
                },
                {
                    "sent": "And most people don't know Camel.",
                    "label": 0
                },
                {
                    "sent": "So while I think Ocaml is worth the effort to learn and use is because it's almost as fast as C++, and I think almost as fun as Python.",
                    "label": 1
                },
                {
                    "sent": "So this can lead to faster development, refactoring and execution times.",
                    "label": 0
                },
                {
                    "sent": "So the language has a lot of features it supports, both functional and procedural programming.",
                    "label": 0
                },
                {
                    "sent": "Functional programming is nice for writing code quickly.",
                    "label": 0
                },
                {
                    "sent": "Procedural programming is nice for those cases when something doesn't really make sense as a big recursion, or when you really want something to run fast.",
                    "label": 0
                },
                {
                    "sent": "Sometimes you just want to iterate over an array, and O Caml makes it easy to sort of switch between those two different ways of doing things as you want.",
                    "label": 0
                },
                {
                    "sent": "Garbage collection is nice if you've.",
                    "label": 0
                },
                {
                    "sent": "Spend enough time dealing with C++.",
                    "label": 0
                },
                {
                    "sent": "You really start to appreciate that strong static typing is nice, so that means that the compiler catches a whole lot of errors.",
                    "label": 0
                },
                {
                    "sent": "So once your code compiles, it will probably run and you probably won't get too many errors and crashes.",
                    "label": 0
                },
                {
                    "sent": "Unlike something like Python which is dynamically typed, you could have it run along and then get halfway through and then find an error and crash.",
                    "label": 0
                },
                {
                    "sent": "And in O Caml that happens less.",
                    "label": 0
                },
                {
                    "sent": "Has automatic type inference, so you don't spend all your time writing things like a CD:: list, open Racket, list, [might data type, star star Foo.",
                    "label": 0
                },
                {
                    "sent": "And it has native code compilation that supports Linux, OSX and other things, and it's easy to link to C code.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let me just briefly show you an example.",
                    "label": 0
                },
                {
                    "sent": "Suppose you want to do something simple like just test to see if a list of conditions is satisfied by an instance.",
                    "label": 1
                },
                {
                    "sent": "So there might be some Markov network feature that you want to test.",
                    "label": 0
                },
                {
                    "sent": "This is actually real example from the code, and if you were to do this in C++ then you probably define some sort of class that represented one of these conditions and then have some sort of list of them, maybe using STL and test each one of these in turn, and that would be OK.",
                    "label": 0
                },
                {
                    "sent": "It would be, you know, readable code.",
                    "label": 0
                },
                {
                    "sent": "But you're spending a lot of energy on defining this class and that kind of overhead even without any getters or setters, or copy constructors or destructors.",
                    "label": 0
                },
                {
                    "sent": "And O Caml, it's much more compact to write.",
                    "label": 0
                },
                {
                    "sent": "You just sort of saying for each element in this list applied this anonymous function that test to see if a variable matches a particular value in the instance.",
                    "label": 0
                },
                {
                    "sent": "And since allows you to distinguish between equality and inequality.",
                    "label": 0
                },
                {
                    "sent": "So when things are this compact to write, they also get much more compact to rewrite and to read and to refactor.",
                    "label": 0
                },
                {
                    "sent": "And if you are.",
                    "label": 0
                },
                {
                    "sent": "Working on developing new algorithms and you need to re develop new algorithms when your ideas don't work or you get new ideas then being able to change things around quickly is a big benefit.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So a brief demo.",
                    "label": 0
                },
                {
                    "sent": "Instead of typing in all these commands myself.",
                    "label": 0
                },
                {
                    "sent": "I put them in a script.",
                    "label": 0
                },
                {
                    "sent": "So let's start by learning a chow lutry.",
                    "label": 0
                },
                {
                    "sent": "We give it some input data, which is basically a comma separated file format schema, so it knows the dimension of each variable and tell it to output this dot X MoD file, which is the same file format used by the Wind Toolkit.",
                    "label": 0
                },
                {
                    "sent": "And you can set a prior.",
                    "label": 0
                },
                {
                    "sent": "It runs, figured out the schema.",
                    "label": 0
                },
                {
                    "sent": "Few seconds there and now it's created the.",
                    "label": 0
                },
                {
                    "sent": "Asian Network you desire?",
                    "label": 0
                },
                {
                    "sent": "Why does it print out so many things?",
                    "label": 0
                },
                {
                    "sent": "Oh OK, so so this is the schema, so this is a data set that has 294 Boolean variables in it.",
                    "label": 0
                },
                {
                    "sent": "So each of these.",
                    "label": 0
                },
                {
                    "sent": "So this is the schema for the data set.",
                    "label": 0
                },
                {
                    "sent": "Arguably I need to revise what gets outputted to make it make more sense.",
                    "label": 0
                },
                {
                    "sent": "Or be more discreet about what it chooses to print out or not, but all these.",
                    "label": 0
                },
                {
                    "sent": "So each of these Two's is the dimension of one of the variables, so that's a complete variable schema.",
                    "label": 0
                },
                {
                    "sent": "And if you were to run the Chao Lu command without any arguments, then it gives you a helpful usage message.",
                    "label": 0
                },
                {
                    "sent": "These arguments here log file volts output and enabled.",
                    "label": 0
                },
                {
                    "sent": "Debugging output are standardized across all of the commands, so all commands support those options.",
                    "label": 0
                },
                {
                    "sent": "So now let's take this Bayesian network and use the AC verbal elimination algorithm to compile it into an arithmetic circuit.",
                    "label": 0
                },
                {
                    "sent": "So that's pretty fast to run because it's a tree and trees are small and easy.",
                    "label": 0
                },
                {
                    "sent": "Enough, let's alternately generate next circuit by learning it directly from the data.",
                    "label": 0
                },
                {
                    "sent": "So again, we specify the input schema and output arithmetic circuit and output Beijing network.",
                    "label": 0
                },
                {
                    "sent": "So we can run this and.",
                    "label": 0
                },
                {
                    "sent": "I accidentally commented outline and didn't really comment.",
                    "label": 0
                },
                {
                    "sent": "The fix that we will show that later it prints out a lot of stuff and generates a vision network and everything circuit.",
                    "label": 0
                },
                {
                    "sent": "Honest, really.",
                    "label": 0
                },
                {
                    "sent": "So then you can score these models with simple log likelihood scoring.",
                    "label": 0
                },
                {
                    "sent": "To get average log likelihood of.",
                    "label": 0
                },
                {
                    "sent": "Test data or something for arithmetic circuit and we see that one of the models learned a little bit better than on the test data.",
                    "label": 0
                },
                {
                    "sent": "And then we can issue queries to get, say all marginal all single variable marginals.",
                    "label": 0
                },
                {
                    "sent": "And there's 294 of them, so this.",
                    "label": 0
                },
                {
                    "sent": "Ends up being.",
                    "label": 0
                },
                {
                    "sent": "A lot.",
                    "label": 0
                },
                {
                    "sent": "If you have particular queries you like, you want to know the probability of A&B and not C&D.",
                    "label": 0
                },
                {
                    "sent": "Then you can represent these in a query file and it will give you the probability of that conjunction, so this isn't just marginal inference, this is the probability of a particular configuration.",
                    "label": 0
                },
                {
                    "sent": "So it gives you the log probability of each of those configurations, as well as an average if you care about that sort of thing.",
                    "label": 0
                },
                {
                    "sent": "And you can also run mean field in a Bayesian network to get similarly bunch of marginals.",
                    "label": 0
                },
                {
                    "sent": "Or with a query.",
                    "label": 0
                },
                {
                    "sent": "Or you can also specify some evidence.",
                    "label": 0
                },
                {
                    "sent": "And now you're getting conditional probabilities.",
                    "label": 0
                },
                {
                    "sent": "You can specify Dash V for verbose and get a little bit more information about timing information and the whole command string that you typed, which is useful for experiments and the total time things like that, and similarly you can do the same with belief propagation.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So lessons learned.",
                    "label": 0
                },
                {
                    "sent": "I found that research code requires frequent refactoring, at least in the early stages of an algorithm, and some languages are better at this than others, and I've had great fun with O Caml.",
                    "label": 1
                },
                {
                    "sent": "It may not be the best for every project, but it's worked well here and automated tests are awesome, so I only started actually having automated tests fairly recently, but it's really nice to have that extra bit of.",
                    "label": 0
                },
                {
                    "sent": "So I won't say it's not complete security, but you feel a little bit safer when you know that your code is giving the same answers that it gave yesterday, at least on a bunch of really complex test problems.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Especially.",
                    "label": 0
                },
                {
                    "sent": "Yes, especially for refactoring.",
                    "label": 0
                },
                {
                    "sent": "Currently I just have smoke tests where I test I have the output of what this complete algorithm would generate.",
                    "label": 0
                },
                {
                    "sent": "Given this data set and then I do this to see if they differ at all, and if they don't then I take that to be a good sign.",
                    "label": 0
                },
                {
                    "sent": "Unit tests would be nice as well or integration tests, but even just smoke tests are very good.",
                    "label": 0
                },
                {
                    "sent": "For finding errors more quickly and knowing that most things are still working the same.",
                    "label": 0
                },
                {
                    "sent": "So we have fast implementations of both classic and cutting edge learning and inference algorithms, and the key strength of this toolkit is really excluding content specific independence for efficient representation learning and inference, and using arithmetic circuits.",
                    "label": 1
                },
                {
                    "sent": "And more functionality is coming soon, probably in the next few weeks, and then even more later on this summer.",
                    "label": 0
                },
                {
                    "sent": "And so on.",
                    "label": 0
                },
                {
                    "sent": "And you can find it all at libra.cs.org.edu.",
                    "label": 0
                },
                {
                    "sent": "Thanks.",
                    "label": 0
                },
                {
                    "sent": "You mentioned this a paramedic service.",
                    "label": 0
                },
                {
                    "sent": "Could you do something example of?",
                    "label": 0
                },
                {
                    "sent": "Inference problems it can actually speed up.",
                    "label": 0
                },
                {
                    "sent": "You mentioned that you support some gifts distributions.",
                    "label": 0
                },
                {
                    "sent": "Let's say that you have only submachine structure and you would like normally would.",
                    "label": 0
                },
                {
                    "sent": "So the inference by some dynamic programming.",
                    "label": 0
                },
                {
                    "sent": "But if you say use your arithmetic circuit, you said that you can do it in linear time.",
                    "label": 0
                },
                {
                    "sent": "Programming requires quadratic.",
                    "label": 0
                },
                {
                    "sent": "It's linear in the size of the arithmetic circuit.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that's the catch, here's a.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sort of an explanation of how arithmetic circuits work and what they're really doing.",
                    "label": 0
                },
                {
                    "sent": "If you have some Bayesian network, this factored representation, any Bayesian network you can represent as sort of this network polynomial.",
                    "label": 1
                },
                {
                    "sent": "Where you have a product of a bunch of these indicator functions and parameters.",
                    "label": 0
                },
                {
                    "sent": "So this is basically adding up the probability of all configurations and the arithmetic circuit is a factored way to represent that more compactly, and so you could translate a junction tree into an arithmetic circuit easilly, and if there's a bunch of of context specific in dependencies or repeated values or determinism probabilities that one or zero, then potentially in the junction tree you'll be doing many computations that are unnecessary.",
                    "label": 0
                },
                {
                    "sent": "Or doing them multiple times unnecessarily, and the arithmetic circuit is better at.",
                    "label": 0
                },
                {
                    "sent": "Getting rid of unnecessary computations and redundancy compared to what you do and say junction tree or variable elimination.",
                    "label": 0
                },
                {
                    "sent": "So when you're this is this lever takes advantage of repeated values by putting them in a tree.",
                    "label": 0
                },
                {
                    "sent": "But any real set of data you will never get rarely get.",
                    "label": 0
                },
                {
                    "sent": "A repeated value, doesn't do some coercing or approximation to, so you can say the same thing about any Bayesian network structure.",
                    "label": 0
                },
                {
                    "sent": "Learning in real data you very rarely get true conditional independence, but you can learn it anyway, so it's a matter of.",
                    "label": 0
                },
                {
                    "sent": "You could say you could argue that what the vision network is doing by learning these conditional Independencies is a kind of regularization, or that it's just convenient for representation.",
                    "label": 0
                },
                {
                    "sent": "Different ways of looking at it, but it's the same argument for local structure and content specific independence.",
                    "label": 0
                },
                {
                    "sent": "Does the problem really?",
                    "label": 0
                },
                {
                    "sent": "So is this helping it does it?",
                    "label": 0
                },
                {
                    "sent": "I mean, what is it?",
                    "label": 0
                },
                {
                    "sent": "What is it doing to encourage repeated values?",
                    "label": 0
                },
                {
                    "sent": "So for for the structure learning it is doing this by learning a tree distribution at each node.",
                    "label": 0
                },
                {
                    "sent": "So if you think about learning a probabilistic decision tree.",
                    "label": 0
                },
                {
                    "sent": "You split on one value at a time and you will naturally get usually most of the time you'll get a final decision tree that is not equivalent to a full table.",
                    "label": 0
                },
                {
                    "sent": "Typically we're not learning a full table and then trying to find a matching decision tree.",
                    "label": 0
                },
                {
                    "sent": "We're learning the decision tree to begin with, which means we always end up with.",
                    "label": 0
                },
                {
                    "sent": "Typically some kind of.",
                    "label": 0
                },
                {
                    "sent": "Context with independence.",
                    "label": 0
                },
                {
                    "sent": "Fixing to speak again.",
                    "label": 0
                }
            ]
        }
    }
}