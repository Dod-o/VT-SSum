{
    "id": "ogfm6psrgp7fn3hkttdekyuu3yia53dt",
    "title": "Learning to Classify Spatiotextual Entities in Maps",
    "info": {
        "author": [
            "Giorgos Giannopoulos, National Technical University of Athens"
        ],
        "published": "July 28, 2016",
        "recorded": "June 2016",
        "category": [
            "Top->Computer Science->Big Data",
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/eswc2016_giannopoulus_enteties_maps/",
    "segmentation": [
        [
            "Hi so I will present you our work on classifying space shuttle spatial textual entities in Maps work done enough in our service center and supported by John Owen City Risk projects.",
            "So what is?"
        ],
        [
            "The problem we are handling why?",
            "What's the motivation of this work the last years?",
            "There have been a lot of crowdsourcing initiatives and there have also been a convergence between Special Temple Run and the semantic communities.",
            "So as a result we have large amount of just partial data sets that need to be annotated.",
            "A representative example of these data sets is Openstreetmap.",
            "A very large community of millions of users of.",
            "Containing hundreds of millions of geospatial entities.",
            "A that needs to be annotated.",
            "So that they can be exploited by other applications for navigation from social media applications, etc.",
            "So Openstreetmap offers a very extensive ontology of more than 1400 categories.",
            "Which organ organized in the key value pairs?",
            "For example, amenity, restaurant, shop toys.",
            "It also offers a lot of tools.",
            "For example Johnson Tool which is an editing tool that allows the user to download the specific geographic area and add, delete, edit just partial entities.",
            "Geometry is essentially on the map and also of course annotated annotate them.",
            "So what is the specific problem with this approach of call?",
            "Of course you have a very high precision.",
            "This has to be done manually also."
        ],
        [
            "The crowdsourcing of this of this effort facilitates the efficiency of the efforts becausw.",
            "A lot of users contribute on the same time to to add new geometries and annotations in Openstreetmap, however.",
            "There are some issues, one of them is that the the offered ontology.",
            "The categories offered by Openstreetmap is very large is as I said, the more more than 1400 categories, so users might find it difficult to browse the whole list and find the exact categories that fit the specific special tensional entity that they annotate.",
            "So as a result, they might add one category of their own.",
            "Which might be wrong, might might be out of context, or it might be a synonym of an already existing category.",
            "On the other hand, if we do not allow the users to add new categories, essentially we cancel the whole crowd sourcing concept, and of course we're not.",
            "We can't be sure that even with this number of categories that these categories cover every aspect, every concept that.",
            "Needs to exist in the ontology.",
            "So was the solution we exploit the already existing annotated entities within Open Street Map and we recommend users categories that we believe that that fit the specific celebrities and let the users decide what to do."
        ],
        [
            "So our method is very simple.",
            "We train the classifiers on the already existing annotated.",
            "It's a just past specifics on entities.",
            "To do so, we have to analyze these entities into meaningful training features that captures latent relations between these entities and the categories that characterize them.",
            "And also of course we use these these existing or some categories that characterize this training entities as training labels.",
            "And of course, the second step is to exploit these trained models.",
            "And to use them for multi label classification of new entities of new specific textual entities.",
            "So our final output of the method is a rank list of some categories that we believe that best characterize a new specifics specific cell entity.",
            "So first."
        ],
        [
            "The training features that we define.",
            "The first category is the spatial properties, so.",
            "We have several features there, a for example geometry type, which is whether the geometry is a linestring, Polygon, circle etc.",
            "The number of points and the area that is covered by a geometry.",
            "And the main maenads length of the geometry and the variance of the edge of the length of the geometry.",
            "So the last two features gives us some implicit information about the shape of the geometry.",
            "So depending on the algorithm we we apply, these features might be Boolean values that represent different ranges.",
            "For example, we defined several ranges for the number of points and a Boolean feature essentially is one in one of the races and zero in all the other ranges.",
            "And the same applies for the rest of the features.",
            "So."
        ],
        [
            "So the second category of features are textual features.",
            "Essentially we create TF vectors.",
            "A for the short textual representations of the special entities.",
            "And finally, we'll also consider semantic features, which essentially is a is a vector containing all available or some categories, and for its entity it has one only on the categories that characterizes it.",
            "I should note here that the the last category of features is only used on on the tool that we have implemented.",
            "In the experiments.",
            "We also we only consider textual and special features."
        ],
        [
            "So.",
            "We apply for a classification algorithms.",
            "A the 1st two are representatives widely used to representatives of model based and the memory based approaches.",
            "So SVM Maps the training entities into a multi dimensional feature space and tries to find optimal hyperplanes that discriminate entities belonging to different categories.",
            "The output is a model that can map a new a new entity into a ranked list of recommended categories.",
            "So again, an algorithm compares its new entity with all training entities and depending on the matching similarity between test and train entity, recommends the most fitting categories."
        ],
        [
            "And we have also implemented the two hybrid solutions.",
            "Both of them contain a first step, which is clustering.",
            "So class and SVM.",
            "We first cluster the training entities using the features I presented you before.",
            "And then for its cluster of entities, we train a separate SVM model.",
            "And at the final states where Sensorly fuse, the ranked list of recommendations that has been produced by its SVM model, depending on the matching of a test entity on the training entities.",
            "Similarly with class in Canon, we cluster again, train 90s, this time for each cluster we we construct a centroid representative entity of the cluster.",
            "And again we compare its test entity with the centroids and depending on the matching and the similarity, we recommend categories belonging to the matching clusters."
        ],
        [
            "So for our evaluation you we essentially used those tool we downloaded to a random data sets from Athens and London.",
            "We made sure that we keep we kept from both of them around 20,000.",
            "Entities.",
            "Anne and.",
            "We perform 5 fold cross validation, that is we separated the data sets in five subsets and we serve the training, validation and test sets.",
            "A couple of interesting features from these two data sets.",
            "So.",
            "We have the same number of entities, However the London data sets has much more distinct classes characterizing these entities.",
            "A the average class per entity is around the same.",
            "Here we present the numbers that were numbers of majority classes and the these two last numbers essentially show outlier categories in the data set.",
            "So esentially this this last one here means that 38% in London and 33% in Athens, 33% of the categories appear only twice, so this categories essentially shared the whole process becausw.",
            "You cannot expect to find them very often, so if you train your classifier then you cannot use it on the test set."
        ],
        [
            "So for the assay evaluation measure, we defined this precision, which is essentially the number of correct category recommendations divided to total category recommendations, so."
        ],
        [
            "How what we define as correct category accommodation.",
            "We have three variations that.",
            "Variety, strictness of this definition at P1.",
            "We consider a correct category recommendation if the first the highest rank category that we recommend is actually a category that characterizes the test entity.",
            "So in P5 we lose this restriction.",
            "We say that we have a correct record category commendation if one of the five first recommendations that we make actually characterizes the entity, and similarly for the pit 10 measure.",
            "So as we said, we compare the four class classification algorithms.",
            "For each of them, we selected the best configurations.",
            "After the experiments we performed, and also we consider the majority class recommendation.",
            "A naive baseline.",
            "Which always recommends the majority class of the data set for annotation.",
            "So as we can see in the results, SVM SVM performs better.",
            "For the strict metric, the P1 measure which demands that the highest category is a successful recommendation.",
            "We can see here that Canon comes very close to SVM.",
            "However, as we move to more loose measures, SVM maintains a higher precision, while Cannon loses in precision.",
            "So as we move from P1 to P-10 we can see that clustering KNN performs better than every method, especially for pyhton metric, which has the best performance for all.",
            "So class in an SVM cost the worst performance and it is probably be cause.",
            "In this case we didn't consider cluster centroids and we must East it's test entity with with each trainer entity.",
            "As you can see, all methods are higher, perform higher than the naive majority class method baseline, and especially the the highest performing algorithms, SVM and class and KNN perform much better."
        ],
        [
            "As far as the training features we saw from the experiments that special properties are much more meaningful and useful.",
            "Dan, the texture properties.",
            "This is probably due to the sparseness of the textual properties Becausw.",
            "We have very short descriptions for the for the test entity for the entities in general in OSM.",
            "Yeah, but we also saw that the plane type features that is only feature that that say that this is a linestring or this is a Polygon.",
            "Often perform very well on their own.",
            "So specifically for SVM and KNN.",
            "The best combination is usually most of the times is all special properties plus textual features.",
            "The essentially all the features that we use well for clustering and KNN, either plain type features or only special properties usually give their best.",
            "Precision.",
            "Finally."
        ],
        [
            "Comparison on the data sets so Athens is better city than London.",
            "Why?",
            "As we said, the.",
            "London has more more distinct classes, so.",
            "That increases the heterogeneity of the data set of the London deficits, so this might be one factor.",
            "And the other factor is the outlier classes.",
            "London has a bit more outlier classes, so this might be another reason for the lower consistently lower precision numbers in London than Athens.",
            "So moving."
        ],
        [
            "The experiments let's see a real world example to to also see that what we have implemented actually works on real data.",
            "So this is the judgment tool and this little panel.",
            "Here is our plug-in within this tool.",
            "So here we have the already existing.",
            "A category categories of this geometry here, which is an asserts in Vienna.",
            "So the existing annotations, among other, which are a bit irrelevant, are amenity place of worship, Catholic and Christian.",
            "So what our recommendation algorithm gives for this?",
            "So it also gives, among others, again a bit irrelevant.",
            "It gives amenity worship again.",
            "It also gives building sets which might be the most relevant.",
            "A category two assigned to this to this tells.",
            "And also gives an annotation monument, so this last annotation here monument might apply.",
            "Might not apply.",
            "We do not know whether this is a monument or just a search, but this here.",
            "Introduces a bit diversity in the annotation, so it's on the hand of the user whether he he selects to to use this annotation or not."
        ],
        [
            "So as a conclusion.",
            "With this work, we filled the gap.",
            "We searched for other methods doing such a similar task.",
            "We didn't find nothing, especially in the in the OSM plugins.",
            "So we define some meaningful training features.",
            "We evaluated them with four algorithms we so we showed that we can have a high precision results.",
            "And of course we showed that we can exploit the millions of already annotated entities within OSM.",
            "And also we implemented all this into a just plug in.",
            "So as a future work we had started working on neighborhood features.",
            "So the promising results by, but we didn't have the time to conclude the whole set of experiments and also introducing a bit more of diversification in the recommendations would also be a good idea."
        ],
        [
            "So these are some references where you can find this work in GitHub in the those plugins pages and a couple of previous papers.",
            "Thank you.",
            "Thank you very much.",
            "You're gross."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi so I will present you our work on classifying space shuttle spatial textual entities in Maps work done enough in our service center and supported by John Owen City Risk projects.",
                    "label": 0
                },
                {
                    "sent": "So what is?",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The problem we are handling why?",
                    "label": 0
                },
                {
                    "sent": "What's the motivation of this work the last years?",
                    "label": 0
                },
                {
                    "sent": "There have been a lot of crowdsourcing initiatives and there have also been a convergence between Special Temple Run and the semantic communities.",
                    "label": 0
                },
                {
                    "sent": "So as a result we have large amount of just partial data sets that need to be annotated.",
                    "label": 0
                },
                {
                    "sent": "A representative example of these data sets is Openstreetmap.",
                    "label": 0
                },
                {
                    "sent": "A very large community of millions of users of.",
                    "label": 0
                },
                {
                    "sent": "Containing hundreds of millions of geospatial entities.",
                    "label": 1
                },
                {
                    "sent": "A that needs to be annotated.",
                    "label": 0
                },
                {
                    "sent": "So that they can be exploited by other applications for navigation from social media applications, etc.",
                    "label": 1
                },
                {
                    "sent": "So Openstreetmap offers a very extensive ontology of more than 1400 categories.",
                    "label": 0
                },
                {
                    "sent": "Which organ organized in the key value pairs?",
                    "label": 1
                },
                {
                    "sent": "For example, amenity, restaurant, shop toys.",
                    "label": 0
                },
                {
                    "sent": "It also offers a lot of tools.",
                    "label": 0
                },
                {
                    "sent": "For example Johnson Tool which is an editing tool that allows the user to download the specific geographic area and add, delete, edit just partial entities.",
                    "label": 0
                },
                {
                    "sent": "Geometry is essentially on the map and also of course annotated annotate them.",
                    "label": 0
                },
                {
                    "sent": "So what is the specific problem with this approach of call?",
                    "label": 0
                },
                {
                    "sent": "Of course you have a very high precision.",
                    "label": 0
                },
                {
                    "sent": "This has to be done manually also.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The crowdsourcing of this of this effort facilitates the efficiency of the efforts becausw.",
                    "label": 0
                },
                {
                    "sent": "A lot of users contribute on the same time to to add new geometries and annotations in Openstreetmap, however.",
                    "label": 0
                },
                {
                    "sent": "There are some issues, one of them is that the the offered ontology.",
                    "label": 0
                },
                {
                    "sent": "The categories offered by Openstreetmap is very large is as I said, the more more than 1400 categories, so users might find it difficult to browse the whole list and find the exact categories that fit the specific special tensional entity that they annotate.",
                    "label": 0
                },
                {
                    "sent": "So as a result, they might add one category of their own.",
                    "label": 0
                },
                {
                    "sent": "Which might be wrong, might might be out of context, or it might be a synonym of an already existing category.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, if we do not allow the users to add new categories, essentially we cancel the whole crowd sourcing concept, and of course we're not.",
                    "label": 1
                },
                {
                    "sent": "We can't be sure that even with this number of categories that these categories cover every aspect, every concept that.",
                    "label": 1
                },
                {
                    "sent": "Needs to exist in the ontology.",
                    "label": 1
                },
                {
                    "sent": "So was the solution we exploit the already existing annotated entities within Open Street Map and we recommend users categories that we believe that that fit the specific celebrities and let the users decide what to do.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So our method is very simple.",
                    "label": 0
                },
                {
                    "sent": "We train the classifiers on the already existing annotated.",
                    "label": 0
                },
                {
                    "sent": "It's a just past specifics on entities.",
                    "label": 0
                },
                {
                    "sent": "To do so, we have to analyze these entities into meaningful training features that captures latent relations between these entities and the categories that characterize them.",
                    "label": 1
                },
                {
                    "sent": "And also of course we use these these existing or some categories that characterize this training entities as training labels.",
                    "label": 1
                },
                {
                    "sent": "And of course, the second step is to exploit these trained models.",
                    "label": 1
                },
                {
                    "sent": "And to use them for multi label classification of new entities of new specific textual entities.",
                    "label": 0
                },
                {
                    "sent": "So our final output of the method is a rank list of some categories that we believe that best characterize a new specifics specific cell entity.",
                    "label": 0
                },
                {
                    "sent": "So first.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The training features that we define.",
                    "label": 0
                },
                {
                    "sent": "The first category is the spatial properties, so.",
                    "label": 0
                },
                {
                    "sent": "We have several features there, a for example geometry type, which is whether the geometry is a linestring, Polygon, circle etc.",
                    "label": 1
                },
                {
                    "sent": "The number of points and the area that is covered by a geometry.",
                    "label": 0
                },
                {
                    "sent": "And the main maenads length of the geometry and the variance of the edge of the length of the geometry.",
                    "label": 0
                },
                {
                    "sent": "So the last two features gives us some implicit information about the shape of the geometry.",
                    "label": 0
                },
                {
                    "sent": "So depending on the algorithm we we apply, these features might be Boolean values that represent different ranges.",
                    "label": 0
                },
                {
                    "sent": "For example, we defined several ranges for the number of points and a Boolean feature essentially is one in one of the races and zero in all the other ranges.",
                    "label": 0
                },
                {
                    "sent": "And the same applies for the rest of the features.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the second category of features are textual features.",
                    "label": 0
                },
                {
                    "sent": "Essentially we create TF vectors.",
                    "label": 0
                },
                {
                    "sent": "A for the short textual representations of the special entities.",
                    "label": 0
                },
                {
                    "sent": "And finally, we'll also consider semantic features, which essentially is a is a vector containing all available or some categories, and for its entity it has one only on the categories that characterizes it.",
                    "label": 0
                },
                {
                    "sent": "I should note here that the the last category of features is only used on on the tool that we have implemented.",
                    "label": 0
                },
                {
                    "sent": "In the experiments.",
                    "label": 0
                },
                {
                    "sent": "We also we only consider textual and special features.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We apply for a classification algorithms.",
                    "label": 1
                },
                {
                    "sent": "A the 1st two are representatives widely used to representatives of model based and the memory based approaches.",
                    "label": 0
                },
                {
                    "sent": "So SVM Maps the training entities into a multi dimensional feature space and tries to find optimal hyperplanes that discriminate entities belonging to different categories.",
                    "label": 1
                },
                {
                    "sent": "The output is a model that can map a new a new entity into a ranked list of recommended categories.",
                    "label": 0
                },
                {
                    "sent": "So again, an algorithm compares its new entity with all training entities and depending on the matching similarity between test and train entity, recommends the most fitting categories.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we have also implemented the two hybrid solutions.",
                    "label": 0
                },
                {
                    "sent": "Both of them contain a first step, which is clustering.",
                    "label": 0
                },
                {
                    "sent": "So class and SVM.",
                    "label": 0
                },
                {
                    "sent": "We first cluster the training entities using the features I presented you before.",
                    "label": 0
                },
                {
                    "sent": "And then for its cluster of entities, we train a separate SVM model.",
                    "label": 0
                },
                {
                    "sent": "And at the final states where Sensorly fuse, the ranked list of recommendations that has been produced by its SVM model, depending on the matching of a test entity on the training entities.",
                    "label": 1
                },
                {
                    "sent": "Similarly with class in Canon, we cluster again, train 90s, this time for each cluster we we construct a centroid representative entity of the cluster.",
                    "label": 1
                },
                {
                    "sent": "And again we compare its test entity with the centroids and depending on the matching and the similarity, we recommend categories belonging to the matching clusters.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for our evaluation you we essentially used those tool we downloaded to a random data sets from Athens and London.",
                    "label": 1
                },
                {
                    "sent": "We made sure that we keep we kept from both of them around 20,000.",
                    "label": 0
                },
                {
                    "sent": "Entities.",
                    "label": 0
                },
                {
                    "sent": "Anne and.",
                    "label": 0
                },
                {
                    "sent": "We perform 5 fold cross validation, that is we separated the data sets in five subsets and we serve the training, validation and test sets.",
                    "label": 0
                },
                {
                    "sent": "A couple of interesting features from these two data sets.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We have the same number of entities, However the London data sets has much more distinct classes characterizing these entities.",
                    "label": 0
                },
                {
                    "sent": "A the average class per entity is around the same.",
                    "label": 0
                },
                {
                    "sent": "Here we present the numbers that were numbers of majority classes and the these two last numbers essentially show outlier categories in the data set.",
                    "label": 0
                },
                {
                    "sent": "So esentially this this last one here means that 38% in London and 33% in Athens, 33% of the categories appear only twice, so this categories essentially shared the whole process becausw.",
                    "label": 0
                },
                {
                    "sent": "You cannot expect to find them very often, so if you train your classifier then you cannot use it on the test set.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for the assay evaluation measure, we defined this precision, which is essentially the number of correct category recommendations divided to total category recommendations, so.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "How what we define as correct category accommodation.",
                    "label": 0
                },
                {
                    "sent": "We have three variations that.",
                    "label": 0
                },
                {
                    "sent": "Variety, strictness of this definition at P1.",
                    "label": 0
                },
                {
                    "sent": "We consider a correct category recommendation if the first the highest rank category that we recommend is actually a category that characterizes the test entity.",
                    "label": 0
                },
                {
                    "sent": "So in P5 we lose this restriction.",
                    "label": 0
                },
                {
                    "sent": "We say that we have a correct record category commendation if one of the five first recommendations that we make actually characterizes the entity, and similarly for the pit 10 measure.",
                    "label": 0
                },
                {
                    "sent": "So as we said, we compare the four class classification algorithms.",
                    "label": 1
                },
                {
                    "sent": "For each of them, we selected the best configurations.",
                    "label": 1
                },
                {
                    "sent": "After the experiments we performed, and also we consider the majority class recommendation.",
                    "label": 1
                },
                {
                    "sent": "A naive baseline.",
                    "label": 0
                },
                {
                    "sent": "Which always recommends the majority class of the data set for annotation.",
                    "label": 0
                },
                {
                    "sent": "So as we can see in the results, SVM SVM performs better.",
                    "label": 0
                },
                {
                    "sent": "For the strict metric, the P1 measure which demands that the highest category is a successful recommendation.",
                    "label": 0
                },
                {
                    "sent": "We can see here that Canon comes very close to SVM.",
                    "label": 0
                },
                {
                    "sent": "However, as we move to more loose measures, SVM maintains a higher precision, while Cannon loses in precision.",
                    "label": 0
                },
                {
                    "sent": "So as we move from P1 to P-10 we can see that clustering KNN performs better than every method, especially for pyhton metric, which has the best performance for all.",
                    "label": 0
                },
                {
                    "sent": "So class in an SVM cost the worst performance and it is probably be cause.",
                    "label": 0
                },
                {
                    "sent": "In this case we didn't consider cluster centroids and we must East it's test entity with with each trainer entity.",
                    "label": 0
                },
                {
                    "sent": "As you can see, all methods are higher, perform higher than the naive majority class method baseline, and especially the the highest performing algorithms, SVM and class and KNN perform much better.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As far as the training features we saw from the experiments that special properties are much more meaningful and useful.",
                    "label": 0
                },
                {
                    "sent": "Dan, the texture properties.",
                    "label": 0
                },
                {
                    "sent": "This is probably due to the sparseness of the textual properties Becausw.",
                    "label": 0
                },
                {
                    "sent": "We have very short descriptions for the for the test entity for the entities in general in OSM.",
                    "label": 0
                },
                {
                    "sent": "Yeah, but we also saw that the plane type features that is only feature that that say that this is a linestring or this is a Polygon.",
                    "label": 0
                },
                {
                    "sent": "Often perform very well on their own.",
                    "label": 1
                },
                {
                    "sent": "So specifically for SVM and KNN.",
                    "label": 0
                },
                {
                    "sent": "The best combination is usually most of the times is all special properties plus textual features.",
                    "label": 0
                },
                {
                    "sent": "The essentially all the features that we use well for clustering and KNN, either plain type features or only special properties usually give their best.",
                    "label": 0
                },
                {
                    "sent": "Precision.",
                    "label": 0
                },
                {
                    "sent": "Finally.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Comparison on the data sets so Athens is better city than London.",
                    "label": 1
                },
                {
                    "sent": "Why?",
                    "label": 0
                },
                {
                    "sent": "As we said, the.",
                    "label": 0
                },
                {
                    "sent": "London has more more distinct classes, so.",
                    "label": 1
                },
                {
                    "sent": "That increases the heterogeneity of the data set of the London deficits, so this might be one factor.",
                    "label": 1
                },
                {
                    "sent": "And the other factor is the outlier classes.",
                    "label": 0
                },
                {
                    "sent": "London has a bit more outlier classes, so this might be another reason for the lower consistently lower precision numbers in London than Athens.",
                    "label": 0
                },
                {
                    "sent": "So moving.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The experiments let's see a real world example to to also see that what we have implemented actually works on real data.",
                    "label": 0
                },
                {
                    "sent": "So this is the judgment tool and this little panel.",
                    "label": 0
                },
                {
                    "sent": "Here is our plug-in within this tool.",
                    "label": 0
                },
                {
                    "sent": "So here we have the already existing.",
                    "label": 0
                },
                {
                    "sent": "A category categories of this geometry here, which is an asserts in Vienna.",
                    "label": 0
                },
                {
                    "sent": "So the existing annotations, among other, which are a bit irrelevant, are amenity place of worship, Catholic and Christian.",
                    "label": 1
                },
                {
                    "sent": "So what our recommendation algorithm gives for this?",
                    "label": 0
                },
                {
                    "sent": "So it also gives, among others, again a bit irrelevant.",
                    "label": 0
                },
                {
                    "sent": "It gives amenity worship again.",
                    "label": 0
                },
                {
                    "sent": "It also gives building sets which might be the most relevant.",
                    "label": 0
                },
                {
                    "sent": "A category two assigned to this to this tells.",
                    "label": 0
                },
                {
                    "sent": "And also gives an annotation monument, so this last annotation here monument might apply.",
                    "label": 0
                },
                {
                    "sent": "Might not apply.",
                    "label": 0
                },
                {
                    "sent": "We do not know whether this is a monument or just a search, but this here.",
                    "label": 0
                },
                {
                    "sent": "Introduces a bit diversity in the annotation, so it's on the hand of the user whether he he selects to to use this annotation or not.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So as a conclusion.",
                    "label": 0
                },
                {
                    "sent": "With this work, we filled the gap.",
                    "label": 0
                },
                {
                    "sent": "We searched for other methods doing such a similar task.",
                    "label": 0
                },
                {
                    "sent": "We didn't find nothing, especially in the in the OSM plugins.",
                    "label": 0
                },
                {
                    "sent": "So we define some meaningful training features.",
                    "label": 1
                },
                {
                    "sent": "We evaluated them with four algorithms we so we showed that we can have a high precision results.",
                    "label": 0
                },
                {
                    "sent": "And of course we showed that we can exploit the millions of already annotated entities within OSM.",
                    "label": 1
                },
                {
                    "sent": "And also we implemented all this into a just plug in.",
                    "label": 0
                },
                {
                    "sent": "So as a future work we had started working on neighborhood features.",
                    "label": 1
                },
                {
                    "sent": "So the promising results by, but we didn't have the time to conclude the whole set of experiments and also introducing a bit more of diversification in the recommendations would also be a good idea.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So these are some references where you can find this work in GitHub in the those plugins pages and a couple of previous papers.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                },
                {
                    "sent": "You're gross.",
                    "label": 0
                }
            ]
        }
    }
}