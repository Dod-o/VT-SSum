{
    "id": "edkrrn3yechyjk2wsljsagljhauktqni",
    "title": "A Videography Analysis Framework for Video Retrieval and Summarization",
    "info": {
        "author": [
            "Yun Fu, Northeastern University"
        ],
        "published": "Oct. 9, 2012",
        "recorded": "September 2012",
        "category": [
            "Top->Computer Science->Computer Vision->Video Analysis"
        ]
    },
    "url": "http://videolectures.net/bmvc2012_fu_video_retrieval/",
    "segmentation": [
        [
            "So I'm the last presenter for today and.",
            "I try to hide the old of mathematical equations so that no one will fall asleep before the banquet.",
            "So by the way, I'm not currently colleagues my student, I'm the last one.",
            "I'm reminded full from Northeastern University at Boston today, we're going to talk about videography analysis framework for video retrieval and summarization.",
            "So this worker is a joint work with the summing oh Mr Pereira from Kate where.",
            "A company in New York, so we were we started this program when we were in State University of New York at Buffalo.",
            "We just recently moved to Northeastern University.",
            "OK, behind this program this is the US government supported."
        ],
        [
            "Program there is a public evaluation project.",
            "Then motivate our paper so this is the track with multimedia event detection 2011.",
            "In this evaluation, there is a fairly large amount of a collection of web videos, so those videos are could be from YouTube, so you can imagine that it's large scale and complex event.",
            "A lot of variety diversity is showing up in the video, so it's very complicated.",
            "So there are many challenges to dealing with those video.",
            "So first our goal is to do a high level inference, understanding and summarization of the of those video in the world so the events could be human center.",
            "So we mainly look into human centered events such as interacting human, human and human interaction with objects.",
            "In this evaluation there are two subsets, so first lines are called training and 2nd is the test.",
            "A major challenge is the positive and negative.",
            "Videos actually very unevenly distributed in the two datasets in the training set, you can see that there are only three to 5% positive samples, so majority of them are negative samples, so this is very unevenly distributed.",
            "In the testing data we have even worse situation we have less than 1% positive video clips for events.",
            "OK, the events here can be anything related to human interactions, such as.",
            "Interactions.",
            "Also, action activities and the any of the combined.",
            "The densely sparsely data have any semantic relationship with the overall arcane events as well, so it could be a combination of different action activities, not just one action.",
            "Activities like the lab collect data data.",
            "Now let me show some."
        ],
        [
            "Example from this data set.",
            "So for now, this is a board shake.",
            "So what is boring?",
            "So there are many different samples.",
            "For example, we have a board trick Oblek.",
            "They could have a snowboard, right?",
            "They could have served, or they could have a roller skate and tricks as well.",
            "And we have outdoor activity.",
            "We have indoor activity.",
            "We have activity at night activity at daytime and also in terms of a camera.",
            "So we have camera motions such as stationary pan, tilt, zoom in, zoom out.",
            "And also we see animals.",
            "They see human, we see objects.",
            "So you can get a sense of how difficult it is in this video corpus.",
            "OK, this is a second example line."
        ],
        [
            "Of fish so these are mainly outdoor activities, but we do see some text in the video and we see a underwater saying and also about water activities.",
            "We see single person multiple person.",
            "And a group of people working together.",
            "And the cameras can be shaken.",
            "Two men zoom out, Pan tilt as well.",
            "The third one."
        ],
        [
            "I'm going to show is a flash more.",
            "It's a crowd of people.",
            "Run into a place, then do some action activities, then disappear OK. You see that we have text innovative as well, and a lot of Ocado fading in fading out.",
            "Zoom in, zoom out.",
            "Pan tilt.",
            "A lot of details showing up as well, so you have to browse the whole thing and find out what's going on there.",
            "It's pretty complicated as well."
        ],
        [
            "OK, to deal with such kind of data.",
            "So we propose a framework becausw videography analysis framework.",
            "We have a couple of layers so different modules followed one by one, so the first one is the video graphy feature extraction.",
            "We develop a hierarchy scheme to extract features for videography.",
            "So we first look into the short boundary detection and I'm going to talk about details how to do that.",
            "Might be a separate video into shorts.",
            "Then we try to segment them further so we can capture camera operations so those operations could be static.",
            "Zoom in, zoom out, Pan, tilt as I just mentioned there are a lot of that operation showing up in the video and when we have those camera operations we do a separation of the foreground and background the frame by frame based on their motion.",
            "So we mainly use KLT trackers to extract.",
            "Cues and when we separate the foreground background, we can extract features so those features we define here could be full ground motion style, foreground scale motion into intention, which is a correlation between foreground and background.",
            "And then we have the camera motion type.",
            "When we have those feature attracted, we can build a record videography dictionary, so this dictionary you can imagine that it's mainly a combination of different words, videography words.",
            "So each word is a combination of a quantized value of those features.",
            "So we do do a quantization on these four particular features, and when we do that, we have a statistical analysis on that.",
            "I'm going to show details for this dictionary.",
            "Theoretical if you have a 288 dimensions.",
            "But actually in reality we found that only 40% of them can be observable from this data set.",
            "So that means we have a large space to improve in the near future.",
            "When we build this dictionary, we can actually project all these videos under this dictionary.",
            "So each video will be eventually represented by a sequence of quantized.",
            "Videography words so that you can do retrieval and summarization task.",
            "So now I'm going to talk about the details about this free."
        ],
        [
            "Work, especially the feature extraction and also dictionary and another."
        ],
        [
            "So as I just mentioned, we do a hierarchy of feature extraction like course to find style we mainly use KLT as a basic trackers when we have that we have a clip to shorts.",
            "Partition, so when we do that, we consider the boundary shot boundary detection based on cut fade in fade out of the videos and when we achieve those shorts we do sub signals.",
            "So to subsegments as we defined it could be a camera motion estimation, static until zoom in, zoom out."
        ],
        [
            "OK, camera motion estimation.",
            "So when we separate the foreground background based on clustering result of the emotion based on the trackers, then we can also use the background motion to estimate the camera parameters so those camera parameters is based on a global linear model that that can model the camera motion.",
            "So this is highly correlated with the background motion, so that's why we use that features.",
            "So here in the image is the red color rubs on the background motion.",
            "An accordion represent the foreground motion, and the yellow is actually the corrected foreground motion.",
            "After we use the background or camera motion to compress it.",
            "So because background and foreground and the camera they are there.",
            "No more moving, so we have to use the camera motion to compensate.",
            "So now let me show a video.",
            "To give you a sense, what we?"
        ],
        [
            "Doing here, so this is a event.",
            "It's called getting vehicle and stock.",
            "And you can see, especially on the left bottom corner we have a white errors.",
            "So those errors represent the camera motion.",
            "So you can try to observe that those wider errors has a high correlation with the background motion.",
            "As we just mentioned, the background motion is actually used to estimate the camera motion.",
            "So foreground is still green, red is representing the background.",
            "And the arrows represent the camera motion.",
            "This is."
        ],
        [
            "Another example I like it so much because this is so complicated parcul, so this activity is very complicated and the cameras has to follow the players.",
            "And it's very fast and a lot of motion blur shaking.",
            "Cutting of the thing.",
            "It's like a combination of a.",
            "Many complex elements.",
            "Again, we have those.",
            "White arrows represent the camera motion which is highly correlated with.",
            "The rapid motion, the background motion.",
            "OK."
        ],
        [
            "As I mentioned just now actually define the 4th kind of features to be eventually used to build our dictionary.",
            "So the four features are background motion, foreground motion, foreground background correlation and also the scale.",
            "So the scale here we use phase because in our video we mainly consider human centered videos and we try to contact them when they contact them.",
            "We use a histogram to do a statistiques.",
            "On account of the segments.",
            "And when we do, the statistique eventually quantized them in this way.",
            "So in the background and foreground we have 3 levels.",
            "Red, Green, blue represents small, medium and large motion, and the foreground background correlation we eventually defined in two ways, though no correlation or correlation in the phase scale is a again red, green, blue, medium, large.",
            "So these are the quantization of the features."
        ],
        [
            "Now we have the content of the features.",
            "We can use those feature quantization results for the dictionary."
        ],
        [
            "Under analysis.",
            "So we have 4 features quantized and we consider different combination of them that we have.",
            "We can build the videography dictionary.",
            "Now let me show some examples of those dictionary for each word we have a different combinations, so this first one is zoom in small phase.",
            "So this is the event of a birthday party or wedding event.",
            "Anna basically the camera bill move and zoom into the face of someone who is.",
            "In a birthday, try to blow a candle and with the cake on the table and something like that.",
            "And also we have the wedding event as well and the next example is Penn left with a large foreground motion.",
            "So this is a board trick as well.",
            "Now I can also show the video to give you the idea."
        ],
        [
            "So this is the panel left.",
            "Large foreground emotion.",
            "Again, the white arrow indicate the camera motion and the green represent the foreground."
        ],
        [
            "OK, this is another example.",
            "Zoom in to the face.",
            "For wedding band and for birthday event.",
            "So the oranges face bounding box indicate the size scale of the foreground.",
            "OK, well we build that."
        ],
        [
            "Missionary straightforwardly we can project the video into this dictionary number.",
            "You achieve the quantized video clip with a sequence of words.",
            "That's the final representation."
        ],
        [
            "So when they have those representation, we can actually find their correlations with those visual words and this is a map indicate different events.",
            "The correlation between different events and words.",
            "So we use the mutual information to indicate their magnitude of the correlation.",
            "So this map actually shows that different events really have some unique patterns.",
            "That's why they can be discriminative for the later applications, for example."
        ],
        [
            "Here I show a particular example.",
            "Of.",
            "For the board check is highly related to track moving object an for the birthday party.",
            "Which is in purple color.",
            "He's often shows face close up and the wedding ceremony, which is in green, often frequently shows zoom in.",
            "So this makes sense if we revisit the video and show the visual words that correlated to the event."
        ],
        [
            "Now I'm going to show the applications."
        ],
        [
            "The first application is a video retrieval.",
            "We still work on this."
        ],
        [
            "This data set we test on both subsets on the left.",
            "Figure on the right figure.",
            "Different method here represent a different version of our method and as well as the chance which is a random guess.",
            "We also compare with a stiff chart as well, so the PZT here only represent we only use camera motions.",
            "And Jay here means joint Model B is a background average of foreground of C is a correlation, as is a scale.",
            "So the conclusion from this figure.",
            "Is that the joint model is the best, especially when we consider for features at the same time and when they fuse with Steve Stars such as at least we got improvement as well.",
            "So sad."
        ],
        [
            "The application is video summarization, so we try to detect Salem."
        ],
        [
            "Contents and summarize a video clip as a key frame collection.",
            "The computer score to each segment in the left figure.",
            "Actually, the magnitude indicate the color in the previous map, so that's the same thing here, and a different color here represent the different camera motions as well.",
            "We do have a heuristic here, because when we decide which frame to extract for segment, it's actually different for different camera motion.",
            "For example, if it's kind of left.",
            "We picked keyframe in the center of the segment.",
            "If it's zoom in then we actually picked the last frame in that segment.",
            "So it really depends on the scenario.",
            "Depends on the camera motion.",
            "OK, now I show."
        ],
        [
            "Results we do have a baseline with just used global features such as color histogram or other features.",
            "Is Steve's art method on this?",
            "Complex data set.",
            "We do have a lot of missing frames, which is actually is not a keyframe because we missed the player in this video.",
            "And also for the birthday party, which is more like a static static video, we also miss some keeper, especially Mr Subjects and miss the object."
        ],
        [
            "Well, so parkour is more difficult.",
            "And for those dynamic events, some highlight moments are extracted, and for static events such as birthday party key, things with those key objects are extracted by our framework.",
            "OK, now come."
        ],
        [
            "Lauren, we come up with a videography framework for video retrieval and summarization, especially when the video has a lot of variety and diversity and variation showing up in the video and especially with the complex showing up in the video.",
            "We deal with video retrieval and summarization, so this project is just started recently and we hope in the near future we can do a better job, especially when more events.",
            "Consider, in addition to the 15 that we are considered right now.",
            "And also the feature we extracted can be also improved based on the camera motion that we can consider."
        ],
        [
            "OK, that's all, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I'm the last presenter for today and.",
                    "label": 0
                },
                {
                    "sent": "I try to hide the old of mathematical equations so that no one will fall asleep before the banquet.",
                    "label": 0
                },
                {
                    "sent": "So by the way, I'm not currently colleagues my student, I'm the last one.",
                    "label": 0
                },
                {
                    "sent": "I'm reminded full from Northeastern University at Boston today, we're going to talk about videography analysis framework for video retrieval and summarization.",
                    "label": 1
                },
                {
                    "sent": "So this worker is a joint work with the summing oh Mr Pereira from Kate where.",
                    "label": 0
                },
                {
                    "sent": "A company in New York, so we were we started this program when we were in State University of New York at Buffalo.",
                    "label": 0
                },
                {
                    "sent": "We just recently moved to Northeastern University.",
                    "label": 0
                },
                {
                    "sent": "OK, behind this program this is the US government supported.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Program there is a public evaluation project.",
                    "label": 0
                },
                {
                    "sent": "Then motivate our paper so this is the track with multimedia event detection 2011.",
                    "label": 1
                },
                {
                    "sent": "In this evaluation, there is a fairly large amount of a collection of web videos, so those videos are could be from YouTube, so you can imagine that it's large scale and complex event.",
                    "label": 0
                },
                {
                    "sent": "A lot of variety diversity is showing up in the video, so it's very complicated.",
                    "label": 0
                },
                {
                    "sent": "So there are many challenges to dealing with those video.",
                    "label": 0
                },
                {
                    "sent": "So first our goal is to do a high level inference, understanding and summarization of the of those video in the world so the events could be human center.",
                    "label": 0
                },
                {
                    "sent": "So we mainly look into human centered events such as interacting human, human and human interaction with objects.",
                    "label": 0
                },
                {
                    "sent": "In this evaluation there are two subsets, so first lines are called training and 2nd is the test.",
                    "label": 0
                },
                {
                    "sent": "A major challenge is the positive and negative.",
                    "label": 0
                },
                {
                    "sent": "Videos actually very unevenly distributed in the two datasets in the training set, you can see that there are only three to 5% positive samples, so majority of them are negative samples, so this is very unevenly distributed.",
                    "label": 0
                },
                {
                    "sent": "In the testing data we have even worse situation we have less than 1% positive video clips for events.",
                    "label": 0
                },
                {
                    "sent": "OK, the events here can be anything related to human interactions, such as.",
                    "label": 0
                },
                {
                    "sent": "Interactions.",
                    "label": 0
                },
                {
                    "sent": "Also, action activities and the any of the combined.",
                    "label": 0
                },
                {
                    "sent": "The densely sparsely data have any semantic relationship with the overall arcane events as well, so it could be a combination of different action activities, not just one action.",
                    "label": 0
                },
                {
                    "sent": "Activities like the lab collect data data.",
                    "label": 0
                },
                {
                    "sent": "Now let me show some.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Example from this data set.",
                    "label": 0
                },
                {
                    "sent": "So for now, this is a board shake.",
                    "label": 0
                },
                {
                    "sent": "So what is boring?",
                    "label": 0
                },
                {
                    "sent": "So there are many different samples.",
                    "label": 0
                },
                {
                    "sent": "For example, we have a board trick Oblek.",
                    "label": 1
                },
                {
                    "sent": "They could have a snowboard, right?",
                    "label": 0
                },
                {
                    "sent": "They could have served, or they could have a roller skate and tricks as well.",
                    "label": 0
                },
                {
                    "sent": "And we have outdoor activity.",
                    "label": 0
                },
                {
                    "sent": "We have indoor activity.",
                    "label": 0
                },
                {
                    "sent": "We have activity at night activity at daytime and also in terms of a camera.",
                    "label": 0
                },
                {
                    "sent": "So we have camera motions such as stationary pan, tilt, zoom in, zoom out.",
                    "label": 0
                },
                {
                    "sent": "And also we see animals.",
                    "label": 0
                },
                {
                    "sent": "They see human, we see objects.",
                    "label": 0
                },
                {
                    "sent": "So you can get a sense of how difficult it is in this video corpus.",
                    "label": 0
                },
                {
                    "sent": "OK, this is a second example line.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of fish so these are mainly outdoor activities, but we do see some text in the video and we see a underwater saying and also about water activities.",
                    "label": 0
                },
                {
                    "sent": "We see single person multiple person.",
                    "label": 0
                },
                {
                    "sent": "And a group of people working together.",
                    "label": 0
                },
                {
                    "sent": "And the cameras can be shaken.",
                    "label": 0
                },
                {
                    "sent": "Two men zoom out, Pan tilt as well.",
                    "label": 0
                },
                {
                    "sent": "The third one.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm going to show is a flash more.",
                    "label": 0
                },
                {
                    "sent": "It's a crowd of people.",
                    "label": 0
                },
                {
                    "sent": "Run into a place, then do some action activities, then disappear OK. You see that we have text innovative as well, and a lot of Ocado fading in fading out.",
                    "label": 0
                },
                {
                    "sent": "Zoom in, zoom out.",
                    "label": 0
                },
                {
                    "sent": "Pan tilt.",
                    "label": 0
                },
                {
                    "sent": "A lot of details showing up as well, so you have to browse the whole thing and find out what's going on there.",
                    "label": 0
                },
                {
                    "sent": "It's pretty complicated as well.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, to deal with such kind of data.",
                    "label": 0
                },
                {
                    "sent": "So we propose a framework becausw videography analysis framework.",
                    "label": 1
                },
                {
                    "sent": "We have a couple of layers so different modules followed one by one, so the first one is the video graphy feature extraction.",
                    "label": 0
                },
                {
                    "sent": "We develop a hierarchy scheme to extract features for videography.",
                    "label": 1
                },
                {
                    "sent": "So we first look into the short boundary detection and I'm going to talk about details how to do that.",
                    "label": 0
                },
                {
                    "sent": "Might be a separate video into shorts.",
                    "label": 0
                },
                {
                    "sent": "Then we try to segment them further so we can capture camera operations so those operations could be static.",
                    "label": 0
                },
                {
                    "sent": "Zoom in, zoom out, Pan, tilt as I just mentioned there are a lot of that operation showing up in the video and when we have those camera operations we do a separation of the foreground and background the frame by frame based on their motion.",
                    "label": 0
                },
                {
                    "sent": "So we mainly use KLT trackers to extract.",
                    "label": 0
                },
                {
                    "sent": "Cues and when we separate the foreground background, we can extract features so those features we define here could be full ground motion style, foreground scale motion into intention, which is a correlation between foreground and background.",
                    "label": 1
                },
                {
                    "sent": "And then we have the camera motion type.",
                    "label": 1
                },
                {
                    "sent": "When we have those feature attracted, we can build a record videography dictionary, so this dictionary you can imagine that it's mainly a combination of different words, videography words.",
                    "label": 0
                },
                {
                    "sent": "So each word is a combination of a quantized value of those features.",
                    "label": 0
                },
                {
                    "sent": "So we do do a quantization on these four particular features, and when we do that, we have a statistical analysis on that.",
                    "label": 0
                },
                {
                    "sent": "I'm going to show details for this dictionary.",
                    "label": 0
                },
                {
                    "sent": "Theoretical if you have a 288 dimensions.",
                    "label": 0
                },
                {
                    "sent": "But actually in reality we found that only 40% of them can be observable from this data set.",
                    "label": 0
                },
                {
                    "sent": "So that means we have a large space to improve in the near future.",
                    "label": 0
                },
                {
                    "sent": "When we build this dictionary, we can actually project all these videos under this dictionary.",
                    "label": 0
                },
                {
                    "sent": "So each video will be eventually represented by a sequence of quantized.",
                    "label": 0
                },
                {
                    "sent": "Videography words so that you can do retrieval and summarization task.",
                    "label": 0
                },
                {
                    "sent": "So now I'm going to talk about the details about this free.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Work, especially the feature extraction and also dictionary and another.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So as I just mentioned, we do a hierarchy of feature extraction like course to find style we mainly use KLT as a basic trackers when we have that we have a clip to shorts.",
                    "label": 0
                },
                {
                    "sent": "Partition, so when we do that, we consider the boundary shot boundary detection based on cut fade in fade out of the videos and when we achieve those shorts we do sub signals.",
                    "label": 1
                },
                {
                    "sent": "So to subsegments as we defined it could be a camera motion estimation, static until zoom in, zoom out.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, camera motion estimation.",
                    "label": 0
                },
                {
                    "sent": "So when we separate the foreground background based on clustering result of the emotion based on the trackers, then we can also use the background motion to estimate the camera parameters so those camera parameters is based on a global linear model that that can model the camera motion.",
                    "label": 1
                },
                {
                    "sent": "So this is highly correlated with the background motion, so that's why we use that features.",
                    "label": 0
                },
                {
                    "sent": "So here in the image is the red color rubs on the background motion.",
                    "label": 0
                },
                {
                    "sent": "An accordion represent the foreground motion, and the yellow is actually the corrected foreground motion.",
                    "label": 1
                },
                {
                    "sent": "After we use the background or camera motion to compress it.",
                    "label": 0
                },
                {
                    "sent": "So because background and foreground and the camera they are there.",
                    "label": 0
                },
                {
                    "sent": "No more moving, so we have to use the camera motion to compensate.",
                    "label": 0
                },
                {
                    "sent": "So now let me show a video.",
                    "label": 0
                },
                {
                    "sent": "To give you a sense, what we?",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Doing here, so this is a event.",
                    "label": 0
                },
                {
                    "sent": "It's called getting vehicle and stock.",
                    "label": 1
                },
                {
                    "sent": "And you can see, especially on the left bottom corner we have a white errors.",
                    "label": 1
                },
                {
                    "sent": "So those errors represent the camera motion.",
                    "label": 0
                },
                {
                    "sent": "So you can try to observe that those wider errors has a high correlation with the background motion.",
                    "label": 0
                },
                {
                    "sent": "As we just mentioned, the background motion is actually used to estimate the camera motion.",
                    "label": 0
                },
                {
                    "sent": "So foreground is still green, red is representing the background.",
                    "label": 0
                },
                {
                    "sent": "And the arrows represent the camera motion.",
                    "label": 0
                },
                {
                    "sent": "This is.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Another example I like it so much because this is so complicated parcul, so this activity is very complicated and the cameras has to follow the players.",
                    "label": 0
                },
                {
                    "sent": "And it's very fast and a lot of motion blur shaking.",
                    "label": 0
                },
                {
                    "sent": "Cutting of the thing.",
                    "label": 0
                },
                {
                    "sent": "It's like a combination of a.",
                    "label": 0
                },
                {
                    "sent": "Many complex elements.",
                    "label": 0
                },
                {
                    "sent": "Again, we have those.",
                    "label": 0
                },
                {
                    "sent": "White arrows represent the camera motion which is highly correlated with.",
                    "label": 1
                },
                {
                    "sent": "The rapid motion, the background motion.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As I mentioned just now actually define the 4th kind of features to be eventually used to build our dictionary.",
                    "label": 0
                },
                {
                    "sent": "So the four features are background motion, foreground motion, foreground background correlation and also the scale.",
                    "label": 0
                },
                {
                    "sent": "So the scale here we use phase because in our video we mainly consider human centered videos and we try to contact them when they contact them.",
                    "label": 0
                },
                {
                    "sent": "We use a histogram to do a statistiques.",
                    "label": 0
                },
                {
                    "sent": "On account of the segments.",
                    "label": 0
                },
                {
                    "sent": "And when we do, the statistique eventually quantized them in this way.",
                    "label": 0
                },
                {
                    "sent": "So in the background and foreground we have 3 levels.",
                    "label": 0
                },
                {
                    "sent": "Red, Green, blue represents small, medium and large motion, and the foreground background correlation we eventually defined in two ways, though no correlation or correlation in the phase scale is a again red, green, blue, medium, large.",
                    "label": 0
                },
                {
                    "sent": "So these are the quantization of the features.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now we have the content of the features.",
                    "label": 0
                },
                {
                    "sent": "We can use those feature quantization results for the dictionary.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Under analysis.",
                    "label": 0
                },
                {
                    "sent": "So we have 4 features quantized and we consider different combination of them that we have.",
                    "label": 0
                },
                {
                    "sent": "We can build the videography dictionary.",
                    "label": 1
                },
                {
                    "sent": "Now let me show some examples of those dictionary for each word we have a different combinations, so this first one is zoom in small phase.",
                    "label": 0
                },
                {
                    "sent": "So this is the event of a birthday party or wedding event.",
                    "label": 0
                },
                {
                    "sent": "Anna basically the camera bill move and zoom into the face of someone who is.",
                    "label": 0
                },
                {
                    "sent": "In a birthday, try to blow a candle and with the cake on the table and something like that.",
                    "label": 1
                },
                {
                    "sent": "And also we have the wedding event as well and the next example is Penn left with a large foreground motion.",
                    "label": 0
                },
                {
                    "sent": "So this is a board trick as well.",
                    "label": 0
                },
                {
                    "sent": "Now I can also show the video to give you the idea.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is the panel left.",
                    "label": 0
                },
                {
                    "sent": "Large foreground emotion.",
                    "label": 0
                },
                {
                    "sent": "Again, the white arrow indicate the camera motion and the green represent the foreground.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, this is another example.",
                    "label": 0
                },
                {
                    "sent": "Zoom in to the face.",
                    "label": 0
                },
                {
                    "sent": "For wedding band and for birthday event.",
                    "label": 0
                },
                {
                    "sent": "So the oranges face bounding box indicate the size scale of the foreground.",
                    "label": 1
                },
                {
                    "sent": "OK, well we build that.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Missionary straightforwardly we can project the video into this dictionary number.",
                    "label": 0
                },
                {
                    "sent": "You achieve the quantized video clip with a sequence of words.",
                    "label": 0
                },
                {
                    "sent": "That's the final representation.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So when they have those representation, we can actually find their correlations with those visual words and this is a map indicate different events.",
                    "label": 0
                },
                {
                    "sent": "The correlation between different events and words.",
                    "label": 1
                },
                {
                    "sent": "So we use the mutual information to indicate their magnitude of the correlation.",
                    "label": 0
                },
                {
                    "sent": "So this map actually shows that different events really have some unique patterns.",
                    "label": 0
                },
                {
                    "sent": "That's why they can be discriminative for the later applications, for example.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here I show a particular example.",
                    "label": 0
                },
                {
                    "sent": "Of.",
                    "label": 0
                },
                {
                    "sent": "For the board check is highly related to track moving object an for the birthday party.",
                    "label": 0
                },
                {
                    "sent": "Which is in purple color.",
                    "label": 0
                },
                {
                    "sent": "He's often shows face close up and the wedding ceremony, which is in green, often frequently shows zoom in.",
                    "label": 0
                },
                {
                    "sent": "So this makes sense if we revisit the video and show the visual words that correlated to the event.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now I'm going to show the applications.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The first application is a video retrieval.",
                    "label": 0
                },
                {
                    "sent": "We still work on this.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This data set we test on both subsets on the left.",
                    "label": 0
                },
                {
                    "sent": "Figure on the right figure.",
                    "label": 0
                },
                {
                    "sent": "Different method here represent a different version of our method and as well as the chance which is a random guess.",
                    "label": 0
                },
                {
                    "sent": "We also compare with a stiff chart as well, so the PZT here only represent we only use camera motions.",
                    "label": 0
                },
                {
                    "sent": "And Jay here means joint Model B is a background average of foreground of C is a correlation, as is a scale.",
                    "label": 0
                },
                {
                    "sent": "So the conclusion from this figure.",
                    "label": 0
                },
                {
                    "sent": "Is that the joint model is the best, especially when we consider for features at the same time and when they fuse with Steve Stars such as at least we got improvement as well.",
                    "label": 0
                },
                {
                    "sent": "So sad.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The application is video summarization, so we try to detect Salem.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Contents and summarize a video clip as a key frame collection.",
                    "label": 1
                },
                {
                    "sent": "The computer score to each segment in the left figure.",
                    "label": 0
                },
                {
                    "sent": "Actually, the magnitude indicate the color in the previous map, so that's the same thing here, and a different color here represent the different camera motions as well.",
                    "label": 0
                },
                {
                    "sent": "We do have a heuristic here, because when we decide which frame to extract for segment, it's actually different for different camera motion.",
                    "label": 0
                },
                {
                    "sent": "For example, if it's kind of left.",
                    "label": 0
                },
                {
                    "sent": "We picked keyframe in the center of the segment.",
                    "label": 0
                },
                {
                    "sent": "If it's zoom in then we actually picked the last frame in that segment.",
                    "label": 0
                },
                {
                    "sent": "So it really depends on the scenario.",
                    "label": 0
                },
                {
                    "sent": "Depends on the camera motion.",
                    "label": 0
                },
                {
                    "sent": "OK, now I show.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Results we do have a baseline with just used global features such as color histogram or other features.",
                    "label": 0
                },
                {
                    "sent": "Is Steve's art method on this?",
                    "label": 0
                },
                {
                    "sent": "Complex data set.",
                    "label": 0
                },
                {
                    "sent": "We do have a lot of missing frames, which is actually is not a keyframe because we missed the player in this video.",
                    "label": 0
                },
                {
                    "sent": "And also for the birthday party, which is more like a static static video, we also miss some keeper, especially Mr Subjects and miss the object.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well, so parkour is more difficult.",
                    "label": 0
                },
                {
                    "sent": "And for those dynamic events, some highlight moments are extracted, and for static events such as birthday party key, things with those key objects are extracted by our framework.",
                    "label": 1
                },
                {
                    "sent": "OK, now come.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Lauren, we come up with a videography framework for video retrieval and summarization, especially when the video has a lot of variety and diversity and variation showing up in the video and especially with the complex showing up in the video.",
                    "label": 0
                },
                {
                    "sent": "We deal with video retrieval and summarization, so this project is just started recently and we hope in the near future we can do a better job, especially when more events.",
                    "label": 0
                },
                {
                    "sent": "Consider, in addition to the 15 that we are considered right now.",
                    "label": 0
                },
                {
                    "sent": "And also the feature we extracted can be also improved based on the camera motion that we can consider.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, that's all, thank you.",
                    "label": 0
                }
            ]
        }
    }
}