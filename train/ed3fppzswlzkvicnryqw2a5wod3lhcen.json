{
    "id": "ed3fppzswlzkvicnryqw2a5wod3lhcen",
    "title": "Statistical learning theory",
    "info": {
        "author": [
            "Olivier Bousquet, Google, Inc."
        ],
        "published": "Aug. 27, 2007",
        "recorded": "August 2007",
        "category": [
            "Top->Computer Science->Machine Learning->Statistical Learning"
        ]
    },
    "url": "http://videolectures.net/mlss07_bousquet_slt/",
    "segmentation": [
        [
            "And then start on the 2nd.",
            "We have some loss.",
            "I see of people.",
            "It's a pleasure for me to welcome Olivier Busquet.",
            "He is French, so and he studied at all these bigger cults in Paris.",
            "In 2002, he got his PhD from the Ecole Polytechnique on concentration, inequality's and empirical process theory for machine learning.",
            "His thesis was awarded the best thesis of the Equality equality technique and he also earned the best paper award at the Conference on Learning Theory during his PhD time.",
            "After his PhD, he moved shortly to the US and then came to the MPI here, where he worked for three years as a senior postdoc.",
            "And that was before he turned to the dark side and went to industry back to France.",
            "In Paris he worked at party notes as a research manager and recently moved to Google in Zurich.",
            "In his research career, he was mostly interested in learning theory, but he also contributed to more applied things.",
            "So I heard you are coauthor on semi supervised learning paper of any.",
            "So he also knows what theory is good for.",
            "Before I give the word to Olivia, just let me mention that he was also the organizer of the last machine Learning Summer School in Tubingen, so I guess it's a nice for him to speak here again, OK?",
            "Morning everyone, thank you very much for this introduction and I wish to sing the organizer for inviting me first of all and also explore inside.",
            "It's kind of important moment for me because four years ago I was in this room and I was introducing the other speakers.",
            "And I know it's a lot of work and it's I mean it's very difficult to organize such an event and to make it successful.",
            "And this one seems very successful so far.",
            "So I won't be here at the end, but I hope you will all give them a lot of applause at the end to congratulate the organizer for this nice Seven.",
            "Um?",
            "OK, so I know he was a bit.",
            "I mean this was a very nice dinner yesterday and lots of rings.",
            "So probably you will not be completely awake for the entire duration duration of this talk so I will try to give you a very slow start this morning.",
            "And aspirin say that I have turned to the dark side.",
            "Which means that.",
            "I started thinking, but you know what is this all for this theory?",
            "How does it help in practice?",
            "And does it really make a difference in the real world?",
            "I mean, when you're in a company and someone ask you to design A learning algorithm.",
            "Does it really help to have proven theorem before?",
            "And So what?",
            "I will try to attempt in this lecture is to show you that you know all the details, the mathematical details you can figure them out right.",
            "You look at the papers you mean.",
            "Once you know enough of you, know what are the definitions and that's you can more or less figure out the details and understand the proofs of the papers.",
            "What is harder though, is to understand the meaning behind those proof, or really what you can infer from these theorems and what you can do in practice and how does it help you or guide you towards building the right algorithm.",
            "And so this really be really the goal of these lectures.",
            "There will be 3 parts, so today we will.",
            "Look into."
        ],
        [
            "Who?",
            "So when I called the what and why.",
            "Which is you know what is learning theory and why are we studying it?",
            "An what are the foundations?",
            "And we in the second part of this lecture will discuss about the North free lunch theorem, which is I think, an important piece of it.",
            "And tomorrow will go into the bounds and show I will show you how to prove some bounds and how to play around with the different techniques that exists and they after tomorrow I will discuss it with the implication and the consequences and how to interpret this things.",
            "So again.",
            "The goal of this course is not really to.",
            "He's not really to, you know, give you a lot of results and a lot of proof, but more talk about the foundations.",
            "Keep saying simples and really give insights.",
            "That's what I try to do most of the day.",
            "I mean most of the lecture."
        ],
        [
            "And that will of course not cover things like the history of the domain or general results and advanced topics."
        ],
        [
            "So let's start."
        ],
        [
            "So before.",
            "Telling you what is learning theory, I have to tell you what is a theory and what is the goal of defining a theory about learning.",
            "So this is I mean definition of what is a theory and I have emphasized the important words here.",
            "Important is that we are looking at the phenomenon and we try to explain this phenomenon and we want to explain it in a repeatable way.",
            "And also.",
            "This explanation should help us make prediction about these phenomena.",
            "That's the important point."
        ],
        [
            "So in a way you can think of a theory as a model, something that kind of represents over describ, stomp, elemental."
        ],
        [
            "Anne.",
            "That model helps us understand the, you know the various things that happen when you absorb this permanent.",
            "In this case, it would be the phenomenon of learning of course."
        ],
        [
            "And of course, predict what's going to happen later."
        ],
        [
            "Are two more definitions that will be useful.",
            "During this lecture.",
            "Deduction in induction.",
            "These are often opposed, and actually they are opposed.",
            "If you look at the definitions, so deduction is really you go from the general axioms, the general rules and you try to derive consequences.",
            "So you go from the general to the specific and specific is, say, a theorem.",
            "So you go from the action and you derive your theorem, you prove yourself.",
            "So this is really what mathematics is all about.",
            "Induction is more what physics is all about, which is.",
            "You look at specific examples.",
            "You make observations about nature and then you try to infer the general principles that the actions of nature if you want.",
            "This is how you create series, usually from observing nature I mean there is also something in between which is called transduction, which will probably heard of which is going from specific to specific without even mentioning a model.",
            "But these are two important things from general to specific or from specific to general."
        ],
        [
            "So what is a good theory?",
            "Good theory is one that is, you know, intuitively makes sense, of course, and which is simple and concise.",
            "So you have a lot of observation.",
            "You can look outside and observe a lot of natural phenomena.",
            "And if you can explain all these phenomena with very small sets of actions of our principles, then you are happy in a way."
        ],
        [
            "So you want to explain many things with few things."
        ],
        [
            "And these principles, or these actions or postulates they?",
            "I mean they can be called assumptions, axioms, postulates or any.",
            "I mean there are various denominations.",
            "An example of them is the following one.",
            "So principle of relativity, the laws of physics are the same in all inertial frames of reference.",
            "So this is really something that you can't really prove.",
            "You just say, OK, let's assume this is true, and if this is true, what can we derive from that and what are the consequences?"
        ],
        [
            "So that's the important point here.",
            "These assumptions you can never prove them, you can only you know.",
            "Kind of figure out what are the consequences of these assumptions and then go in the nature an try these things and test whether they are true or not.",
            "Test the consequences."
        ],
        [
            "And of course, a good theory should have few of them."
        ],
        [
            "So we have defined what is serial it now let's define what is learning.",
            "So learning, I mean, you all have pretty good efficient what is learning, but let's make things precise.",
            "Learning definition you can find in dictionary is to gain knowledge, comprehension of mastery or mastery of through experience or study.",
            "Study is kind of the easy case.",
            "You study something, you know it.",
            "So we will not focus on this part of it, but more on learning through experience.",
            "So you do something, and as you do it, you kind of gain knowledge comprehension like understanding.",
            "So in a way you build your own mental model.",
            "Right, so Interestingly, is the interesting part is when you don't just accumulate observations, but you really create your own representation of the world and you have some internal model that allows you not only to account for what you have observed, but also allows you to make predictions about the future.",
            "Um?",
            "So I mean all these words.",
            "You can consider them as meaning the same thing in the context of this lecture."
        ],
        [
            "So this leads us to an interesting.",
            "I mean, if we look at the definition of learning and definition of a theory, we get some kind of weird circularity here.",
            "So we have said what is a theory and what it how it should be constructed.",
            "Siri is really.",
            "Making observation and constructing a model of these observations."
        ],
        [
            "End.",
            "The question is.",
            "Why did I tell you all that, right?"
        ],
        [
            "Actually, building a theory is really the same as induction, which is the same as I said before, as learning learning is your observe things learning from experience at least you're observing and you make a kind of internal model of these things.",
            "And building a series the same so.",
            "You know it's kind of.",
            "See."
        ],
        [
            "Cooler here, I'm I'm telling you that learning is building series an I want to build a theory on building series.",
            "So let me rephrase that."
        ],
        [
            "A bit so induction is the process of building series."
        ],
        [
            "Learning theory, the main focus of learning theory is the phenomenon of induction, so."
        ],
        [
            "How can we?",
            "Build a theory about building series."
        ],
        [
            "OK, so I mean I won't go more into the details of that, but it's just to emphasize that.",
            "This whole thing is involving a lot of philosophical issues and I will touch upon some of them.",
            "Some of them later on.",
            "But let's"
        ],
        [
            "Try to go a bit further now.",
            "So OK, now you have a rough idea of what is it that we are trying to do with learning theory now.",
            "Why is it that we are trying to do that?",
            "Um?",
            "I like this quote.",
            "I mean, you can find it in that next book.",
            "And I think it it doesn't.",
            "It doesn't say that it's from currently divine.",
            "Well, I mean I don't know why I look on the Internet and that's the kind of reference that is given most often, but maybe it was reduced by many people.",
            "Um?",
            "So.",
            "I mean, yeah.",
            "What else can I say?",
            "No, I mean more seriously.",
            "These are the things that I think are important.",
            "First of all, we want to understand what's going on when we do learning right?",
            "And we want to study the properties of different learning algorithm and be able to say OK this is better.",
            "Why in this context this is better and this other algorithm is better than?",
            "And not just by, you know, trying it on various kinds of data, but by being able to say I mean to make some general statements.",
            "Um?",
            "Anne.",
            "Ideally that should lead us to, you know.",
            "A way to design better algorithm for certain tasks."
        ],
        [
            "So again.",
            "This induction versus deduction.",
            "I mean, I'm kind of repeating the same thing over and over again in various flavors, hoping that you will get the main message here.",
            "So.",
            "If you compare induction induction, that's really what is kind of most frustrating.",
            "Both studying induction is that deduction is can be easily justified.",
            "I mean, once you have agreed upon the actions, then you kind of derive and the rules for combining these actions, then you derive the consequences you proved your serum and nobody can disagree.",
            "I mean, this theorem is correct, provided that everyone agrees on the action.",
            "For induction is exactly the opposite.",
            "You can't really justify anything.",
            "You know someone comes up with one action about some observations.",
            "You can only test the consequences of these actions.",
            "So make deduction from that and then check that it's true.",
            "I mean check that it corresponds to correlate, Stew your observation, but you can't really prove or disprove an action and.",
            "You can't really argue, but the truth of some induction in a way."
        ],
        [
            "So.",
            "Let's see I mean, let's make these now a bit more concrete and I will give you some examples too.",
            "You know force you to reason about these things.",
            "Here is an example.",
            "So let's say we observe the sun every morning, and we see that it's rising every morning.",
            "I mean, the usual example is your weather certainly is running from the East or from the West.",
            "But let's just say we observe that the sun is rising every morning.",
            "For a number of the dates OK and the question I'm asking you is OK given that you observe that 40 days, what is your estimate of the probability that the sun will rise again tomorrow?",
            "I have not defined what is probably T yet you have already.",
            "I'm sure you have already used that and you already know what it is, but I will go into the details later.",
            "But let's say you have some intuitive notion of what is the probability.",
            "And let's say I'm asking you.",
            "What is your best estimate at this probability given these observations?",
            "Um?",
            "There are many ways in which you can answer this."
        ],
        [
            "And the first one you can say, well, they cannot be the P cannot be defined, right?",
            "Tomorrow is not identical to yesterday, is just.",
            "Another day is not a repetition of the same experiments, right?",
            "You can't really compare two different days, so I don't want to define this probability because this is just.",
            "A single events that cannot be compared to any other event.",
            "OK, that's kind of the pessimist answer."
        ],
        [
            "The optimist answer would be the opposite.",
            "Say Oh well, it's always Rose so far, so tomorrow I'm sure it will rise.",
            "So P = 1.",
            "Then you have the beige and answer."
        ],
        [
            "Which is.",
            "Well, let's assume that's P. This is probability.",
            "Pi put a prior on this probability unit from prior on.",
            "This probability between zero and one, and then I workout the details.",
            "I apply Bayes rule and I get this value here Z + 1 / D + 2.",
            "OK, so as the increases this probability will converge to one.",
            "But in the beginning it's kind of more towards the help.",
            "And then there is the physics."
        ],
        [
            "Physicist answer.",
            "Which is, you know you can workout the details so the sun is a star.",
            "We know how many stars explode per day.",
            "An we can compare the sun to other stars with the same property.",
            "Take into account the age of the sun and so on, and we can workout the probability that the sun will explode tomorrow and not rise again.",
            "So OK, what?",
            "What do we gain from this example?",
            "Basically all these results just converge towards saying that there is a high probability of the sun rising again tomorrow, and they all have different justification and these different justification.",
            "Really, the point is that they differ in how they consider similar situation, like in this case.",
            "It's like every day is the same.",
            "Here.",
            "You have some kind of probabilistic notion of a day, plus you know the prior on the probability P. And here the similarity is not over days but over the.",
            "Kind of elements that were considering the sun and the stars.",
            "It's really up to how you kind of relates the current situation or the OR the future situation to what you have observed in the past."
        ],
        [
            "Let me give you another example.",
            "OK, so let's assume we observe this sequence of numbers 1247.",
            "And the question is what comes next, any idea?",
            "OK, that's one answer, but actually there is not just one."
        ],
        [
            "Answer There are so far.",
            "I mean it keeps going there 599.",
            "This encyclopedia of integer sequences, so you go in the Internet, you type 1247 and it gives you all the sequences that are known and start with 1247 and all are very good justification.",
            "So 11 could be one but."
        ],
        [
            "Let's see what are the other one so elephant would correspond to this one, or at least could correspond to this one, which is the maximum number of pieces formed when you slice a pancake with end cuts.",
            "Keep cutting your pancake and every cuts you add NPC's.",
            "So you have 1247 elements, 16 and so on, and this sequence is called a 124.",
            "OK.",
            "But"
        ],
        [
            "You could just think in another way and say oh, this is just this recursion.",
            "Here I take the previous two numbers.",
            "I add them.",
            "I had one and I get 1247 and then I continue like 12 and 20.",
            "This is perfectly fine, right?",
            "It fits with what we have observed.",
            "It's a natural.",
            "I mean, it's a relatively reasonable equation here, and we can carry on."
        ],
        [
            "Another one is what I call the triple matching numbers.",
            "OK, yet another pretty simple recursion."
        ],
        [
            "And you can have some kind of different approach if you're bit original, you can say, well, let's look at the binary expansion of the sequence.",
            "So one is, this two is 10 in binary for is, 107 is 111.",
            "And if you count number of ones, you have the you have an odd number of ones in all these numbers.",
            "So you can say, well, let's carry on.",
            "Let's keep looking at bigger and bigger binary numbers and just keep the ones that have an odd number of ones.",
            "And this gives you 1247, eight 1113 so.",
            "It said."
        ],
        [
            "Just a simple right?",
            "Or, well, you can be even more.",
            "Tortured in away and look at Pi, an E interleaved.",
            "So here is I removed the three right so 314159 that would be \u03c0 and 2718 that would be E. And then you say, well, OK 1247.",
            "So the next one is 1."
        ],
        [
            "Why not?",
            "And well, you can say, well, I'm observing 1247, but I think later on it will keep at 7 and this is my explanation for it.",
            "OK, so basically you see that you can come up with as many possible expansion of that sequence as you wish, and it's you know a matter of which one.",
            "Do you consider the simplest is there is no notion of simplest thing like an absolute because some people would argue that the binary expansion is natural.",
            "Like computers would argue that.",
            "Um?",
            "Reasonable people might argue that this one is.",
            "Simpler.",
            "I don't know.",
            "I mean, it's really up to you.",
            "Well, some other example in the same thing.",
            "If you look at."
        ],
        [
            "Sequence.",
            "You think, well, OK, with so many numbers there is only one way to continue this sequence, right?",
            "You can be sure that.",
            "I mean these are all primes, so the next one is a prime well.",
            "Again, if you look into this insect."
        ],
        [
            "Encyclopedia you can see 2 answers.",
            "One is the next prime."
        ],
        [
            "And one is another which is the order of the next simple group.",
            "OK, so you probably don't know what it is.",
            "Simple group."
        ],
        [
            "Or maybe you know.",
            "But doesn't matter.",
            "My point is, you know.",
            "It's a matter of what you're most familiar with, and you know people are more familiar with Prime, so maybe we can say OK, a natural continuation of the sequence is 61, But again, there is no, we cannot prove it right.",
            "We cannot say for sure.",
            "This sequence will continue with 61 and there is no other way."
        ],
        [
            "Um?",
            "Another example which gives a little twist on that the the following.",
            "So we observe this sequence of numbers.",
            "Maybe it's familiar to you."
        ],
        [
            "But it looks random, no.",
            "It's just a bunch of numbers.",
            "Yeah.",
            "But you know, if you don't know the specific number that is very popular.",
            "Like if I had given you another less popular number, you would have said, OK, that seems to not have any pattern."
        ],
        [
            "So an if you look actually at the frequencies right?",
            "If you.",
            "Kind of count how many times each individual number.",
            "Ockers and you kind of.",
            "Assume that the probability of the next digit.",
            "Being I is proportional to how many times jobs you have observed this I divided by number.",
            "Digital observed then?",
            "This probability you can see that it will converge to 110's, so you can say, well, this is kind of random in the sense that every number can occur with the same probability."
        ],
        [
            "But as you said.",
            "Now you notice.",
            "Uh.",
            "I mean, this really looks like the expansion of fine, right so?"
        ],
        [
            "OK.",
            "So why do we prefer this answer?",
            "The last answer?",
            "Well, because we obviously notice that there is a structure.",
            "Even though it's not, you know you can formalize it by some kind of recursion, like you cannot say UN is equal to U N -- 1 plus something.",
            "But still we managed to notice that this is something that contains structure and actually there is.",
            "There is an algorithm that would produce these sequence and continue it, so which so this algorithm you can think of it as a model for that sequence.",
            "It's corresponds to this observation and it gives you.",
            "An expansion.",
            "So."
        ],
        [
            "OK, now let's wrap up.",
            "Is there a general principle for providing a good answer to these riddles, right?",
            "These questions of continuing sequences?"
        ],
        [
            "Well, unfortunately.",
            "I mean there is one approach that seems to be satisfactory which is called.",
            "This all comes razor.",
            "You try to find an explanation which is consistent with what you observe and which is the simplest possible.",
            "But the problem is."
        ],
        [
            "Can't really define.",
            "This simplicity.",
            "So first of all, you cannot really justify that this is.",
            "This will give you the best answer.",
            "As again as I said before, you can justify this.",
            "Postulates, right there is no proof that the simplest answer is the correct one.",
            "And second of all.",
            "You can't define simplicity because it's not objective.",
            "There are many ways in which you can measure it, and everyone would have a different notion.",
            "I mean, some people tend to say that the right notion of simplicity is what is called Kolmogorov complexity, which is a measure of the length of the shortest program that can generate some sequence, or that can do some.",
            "Implement some function, but even that is not completely objective, because when you define the length of the shortest program, you first have to define in which programming language you write your program.",
            "An which means that every programming language would give rise to a different notion of lengths.",
            "So even though you can prove that asymptotically they are all equivalent.",
            "At least if their languages completes during completes.",
            "In practice, on finite sequences, each programming language would give you a different notion of simplicity.",
            "So if you observe a finite sequence as we did before, there is again no no reason to choose one or another."
        ],
        [
            "So.",
            "Seems that we are doomed, right?",
            "I'm just saying I keep saying, OK, we can't do anything, so what's the point?",
            "Well, let's see, maybe we can do something, but it means we first have to kind of lower our expectations.",
            "We want to prove that something is the right thing to do.",
            "Or I mean, we want to prove that there is an optimal way of doing induction.",
            "But we can at least try to get some more understanding."
        ],
        [
            "So let me now define probability and discuss a bit about what probability means, because you've heard a lot probably before in the previous lectures about probabilities.",
            "Maybe you also use that a lot.",
            "But I want to make you think again about what is probability and what it means.",
            "So probability mean to me is just a way to formalize reasoning under uncertainty.",
            "So it's a convenient way to define to assign numbers to events, right?",
            "An it relies on these simple actions that probability of an event is non negative probability of the certain events is 1.",
            "And then you have this additivity like disjoint events are probability that sum up and if there is some intersection you can just subtract it.",
            "And well, optionally you can introduce this.",
            "Kind of Sigma additivity of the probability, but it's not really relevant to understand what it means.",
            "OK, so that's pretty simple.",
            "Pretty convenient.",
            "You can make easy computation with these things, But the question is what does it all mean?",
            "And more precisely how you can measure these numbers?",
            "Or you decide which is the right number for an event."
        ],
        [
            "So.",
            "There are a number of ways to interpret these numbers, and interpretation here means assigning meaning to a given number.",
            "Uh.",
            "One of the simplest one is the so called frequentist interpretation.",
            "So in the frequencies interpretation probabilities are relative frequencies.",
            "So you know how many times a certain event occurs divided by how many times you tried this?"
        ],
        [
            "And I will get into details.",
            "Objectivism is.",
            "More or less the same.",
            "I mean you you can say.",
            "The probability is still a frequency, but now this frequency is not observed as infrequent ISM, but it's kind of postulated that something that exists."
        ],
        [
            "And you have the Subjectivist POV which says that well, probabilities are just beliefs is just something that we think is true, but there is no way to prove that it's true."
        ],
        [
            "OK, so probabilities as frequencies.",
            "So what you do is, I said as I said, and as is natural, you repeat a given experiment N times and if the events of interest occurs K times, then K / N is your estimate of the probability and you can even define the probability of these events as the limits.",
            "Right so.",
            "You can say, well, if I were to repeat this experiment and Infinity infinite number of times.",
            "Eventually these limits might convert to some number and this is how I define probability.",
            "OK, that's kind of clear and easy, but the problem is you can't always repeat experiments and also you rarely can repeat infinitely experiments, so you cannot really have a measure of these numbers by experimenting, because you can't really reach that limit and you know probability of sunrising tomorrow.",
            "How can?"
        ],
        [
            "I repeat.",
            "So there are some limitations.",
            "So these Objectivists interpretation?",
            "It's kind of, you know.",
            "It's kind of a leap of face, you say?",
            "Well, I can measure.",
            "I mean, I can try to measure these probabilities, but I'm assuming that they exist and this is some kind of intrinsic property of the word that there is.",
            "Like the right, just sorry the sun has attached to him or attached to it.",
            "Some probability of rising tomorrow an.",
            "This is kind of a property of the nature, and I can only observe it.",
            "It's like the mass, right?",
            "The sun has some mass, but it also has some probability of rising and I just want to measure that.",
            "So these probabilities preexists."
        ],
        [
            "And the last interpretation.",
            "So, for the subjectivist interpretation, these probabilities they are just numbers that people given person would assign to some events, and that correspond to how like or I mean our strong is belief is that this event will occur and there is a. I mean, you can naturally define.",
            "I mean naturally assign these beliefs.",
            "I mean assigned numbers to these beliefs.",
            "Real numbers to these beliefs and then you know you can come up with the natural or intuitively natural rules for combining these beliefs when you have, when you believe in one event and you have ability for one event or another events how you combine these beliefs and so on and you can show that if you use these natural rules then it will lead you to.",
            "Something that has the same properties as probabilities so.",
            "Essentially.",
            "Probabilities are the right way to formalize.",
            "The natural notion of belief in something.",
            "And then once you have kind of chosen, one of these interpretations.",
            "I mean you don't have to choose it.",
            "Basically you can just run your calculation without even.",
            "Thinking about how to interpret these numbers.",
            "And one way in which you can.",
            "Combining these numbers, besides the action, I mean, you can derive that from the actions is what?"
        ],
        [
            "Called the Bayes rule and what it is is just a way to update your probabilities when you make observation, so you have prior beliefs in some hypothesis P of H. You have some way to measure how like what is called the conditional probability of observing some data given the hypothesis that's against some belief that you define so or some number and the natural way too.",
            "Derive from that how much you believe in your hypothesis.",
            "After you have seen the data is to apply this rule, and this is kind of if you want to be consistent with your actions.",
            "That's the only way you should do it.",
            "Um?",
            "But again, you can't really measure all these numbers, but you know once you have agreed that this is the right thing to do, you can just work that workout the details."
        ],
        [
            "So again, my point here is.",
            "What can we gain using probabilities is is this the right way of doing inference or?",
            "Induction, well, I mean it's a natural way to do it, or it's a convenient way to do it.",
            "You get these nice formulas and you get these nice.",
            "Numbers that you can combine, but we don't gain anything right?",
            "We still cannot prove that what we are saying is true because.",
            "You know we don't get any guarantee the probabilities, they just help us rezoning.",
            "But if we did not set these numbers right in the 1st place, but even if we set them right?",
            "I mean because there are so many ways to interpret them.",
            "You can't really prove that the probability of something is some number because you know you can come up with all sorts of interpretations.",
            "You can be a frequencies or an objective or subjective istan.",
            "None of these people would agree, right?",
            "Um?",
            "So again, it's kind of disappointing.",
            "But even though you are using probabilities, it doesn't mean that you are doing the right thing or that you're justifying anything.",
            "I'm.",
            "So we."
        ],
        [
            "The problem is that we need these assumptions and there is no way we can escape these assumptions.",
            "And.",
            "So what can we do?",
            "What we can do is.",
            "You know?",
            "Implicitly assume something like the future looks like the best.",
            "This is kind of reasonable and you know everyone would agree with that some degree.",
            "Or what we have not seen yet?",
            "Looks like what we have seen.",
            "And it's clear that if we don't make such assumptions, then there is no point in doing any.",
            "You know, working in learning theory or even working in machine learning at all, because if you don't assume that there is some regularity in the world, there is no hope that you can uncover it with these algorithms."
        ],
        [
            "No.",
            "But still we want to make these assumptions, you know, as limited as possible.",
            "We don't want to assume too much.",
            "And we want to keep them to a minimum, which means that.",
            "Maybe we can even completely get rid of this assumption.",
            "Actually you can in a certain sense if you don't say much, proving that some algorithm is optimal.",
            "But if you want to compare algorithms like if you don't.",
            "Want to predict, but too I mean to predict well, but you want to predict as well as some other algorithms.",
            "So if you want to imitate the behavior of an algorithm independent of how good that algorithm is, then you can you know somehow get rid of these assumptions.",
            "So it's a matter of, you know.",
            "Can we match some others performance?",
            "And like and when we are willing to go with assumptions, then the question is.",
            "And the question that the series should answer is given these assumptions, what can we do at best right?",
            "What is the optimal algorithm with respect to these assumptions?",
            "That's something we can answer."
        ],
        [
            "OK. Now I want to kind of slowly go towards more formal things.",
            "Hope it's not too slow for you.",
            "I fixed myself 1/4 of 5% of people that should be asleep by the end of the lecture.",
            "So far it seems to be OK. Maybe 3% yes.",
            "Um?",
            "OK, so.",
            "Maybe I need to be a bit faster?",
            "So let me introduce now.",
            "I mean I, I'll try to describe a picture of the things.",
            "Let's see.",
            "You know how to distinguish between different assumptions or frameworks?",
            "Because you probably have heard about you know online learning or semi supervised learning, or beige and inference and all these things, you know I want to kind of draw a chart where you can place these things and relate them to each other and understand what is an assumption and what is just a matter of setting the problem and so on and trying not to confuse all these things.",
            "So here are some examples of settings that are commonly used, so the so called offline supervised learning.",
            "You have training pairs that are given to you, and the goal is to produce a model that predicts well on future instances."
        ],
        [
            "Semi supervised learning.",
            "You have both training pairs like XY and also unlabeled data and you want to produce a model that predicts well, so you want to produce function that assigns a label to every future instance."
        ],
        [
            "Transductive is slightly different.",
            "You have the same inputs, training pairs and unlabeled data, but the goal is to predict well on unlabeled example."
        ],
        [
            "2X and you want to predict the Y and the the you, so you have to predict the performance at each step whenever you get a new example."
        ],
        [
            "And I mean there are some variants that you probably have heard of like reinforcement learning, where instead of predicting some label, you want to take some action and then you get some reward, possibly not immediately but later on.",
            "So these are what I call settings.",
            "That's the way you set up the problem and like what you ask your algorithm to do.",
            "Now."
        ],
        [
            "You should not confuse these settings with the assumptions that you put on top of that, usually the assumptions are about how the data is generated.",
            "In this case is like if I go back."
        ],
        [
            "You know?",
            "How do I assume that these data is generated?",
            "This training pairs or these instances that come one at a time, so you know you.",
            "Probably I mean a natural weight is to say OK, they are generated by some probabilistic mechanism, some random number generator or something like this.",
            "Or maybe they are generated by some natural phenomenon.",
            "You know observing nature and so."
        ],
        [
            "And these assumptions, as I said before, they are only used if you want to prove anything, but otherwise you know they don't really make sense and you can't really justify any of those, so you know who cares."
        ],
        [
            "The protocol is more, you know how you set the scene, the stage of your learning problem, and how the instances are coming to you and what you get to see of these instances, and so on.",
            "And this is really the relevant part when you want to create algorithm because your algorithm has to have two fits with this protocol."
        ],
        [
            "Then there is this notion of success measure, which is how you would be measuring success, or when would you say I'm satisfied with this algorithm and.",
            "Sometimes they are.",
            "The success measures are abstract, like for example the reward in infinite in finite horizon, like how much you will or the number of errors you will make if you add infinitely many data points.",
            "This kind of thing.",
            "So these are target criteria, but you can't really measure them, you never will have infinitely many data points.",
            "But did they help you or they guide you towards the deriving the right Al Gore?"
        ],
        [
            "Then there is what type of analysis you are doing in this given this setting.",
            "Given the success measured given you algorithm how you will analyze it and what kind of statements you are expecting to prove about this algorithm.",
            "And again, that's relevant one that's only relevant within a certain.",
            "Data generation generation mechanism."
        ],
        [
            "And sometimes you also add further restrictive assumption.",
            "So you kind of, you know, assume some regularity about the data or.",
            "You know, you may assume that you're only looking at certain kinds of functions for this kind of things.",
            "And this again is not.",
            "Really.",
            "I mean, it's useful for designing algorithm because then you can restrict your algorithm, But then your algorithm would only work or would only probably work under this."
        ],
        [
            "These conditions.",
            "The point here is that if you have an algorithm that has been designed under certain set of, you know for certain protocol with certain limited limiting assumption.",
            "The this algorithm may perform well under some circumstances, so my point here is that you know people would tell you OK. Algorithms that are based on Bayesian inference, for example working better OK Baby.",
            "But you know?",
            "The thing is that you can prove that within this restrictive framework and within the right assumptions, these can be proved to be optimal fine, but then beyond that you don't know you cannot prove anything but still they can work well, so you can't really use the fact that an algorithm is proven to be optimal in a certain context to derive the fact that it will be good in another context, but it may just be good just because it is good.",
            "Because it happens to fit with this assumption of these other contexts.",
            "Um?",
            "And another point is that you know algorithm often.",
            "Have a proxy that they are trying to optimize, which is not the real success measure, but some some.",
            "So measure that, hopefully will converse with success measure for example."
        ],
        [
            "OK, some examples of all these things.",
            "Um?",
            "Data generation mechanism.",
            "You can have several ways in which you assume the data comes to you in the kind of Bayes interpretation.",
            "You can assume that the underlying function describing your phenomenon is sampled from some distribution and that the data also is sampled from some other distribution.",
            "So you put probabilistic assumption or probabilistic generation assumption on both the function and the data.",
            "In the IID setting.",
            "IID stands for independent, identically distributed.",
            "You don't assume that the function is sampled.",
            "Kind of randomly, but you assume that the data is sampled.",
            "IID so independently and.",
            "With the same distribution from some unknown unknown distribution P in the transaction framework, you assume that the data is completely fixed.",
            "But what is random is how you split these data into labeled and unlabeled principle.",
            "And then, well, you can just read that.",
            "So the point is, this data generation assumption tell you how you assume that the data comes to you."
        ],
        [
            "Now the protocols.",
            "I mean mainly it's you know whether the data comes all at a time like you get all the examples once for all, that's the offline case or online.",
            "You get one example at the time.",
            "And along with how the example come, you have some other things that define the protocol, which is how you define the error.",
            "If you algorithm or whether you.",
            "Whether you are available to you, the error or the value of the error.",
            "Sorry, the error function or the value of the value of the error or the error of other related algorithms.",
            "I mean, this will be clear probably when when you see equals lecture online learning.",
            "And I won't get into that."
        ],
        [
            "Details here.",
            "Just to give you an idea, success measures.",
            "I mean there are various ways also to define the success, like one classical one is the expected error in the offline setting where you take the average error under this unknown distribution.",
            "The accumulated error is like the sum of the errors that you make at every step in the online learning case.",
            "And you can have.",
            "A combination of both.",
            "If you have an underlying probabilistic assumption.",
            "So if you assume that the example from one at a time and they are sampled from some distribution, you can compute the expected value of this error."
        ],
        [
            "Now the type of analysis.",
            "This is what you kind of aim for or how you want to define what is a good algorithm or bad algorithm.",
            "And you can study.",
            "You know the worst case.",
            "Performance or the average case?",
            "So worst case, being like you consider the worst possible data generation mechanism within the ones that you have chosen or average cases like you define some kind of probability on the data generation mechanism and you take the average over them.",
            "So it requires some weighting, like choosing how what is the probability of each data generation or probability distribution.",
            "Or this case, which is like you are interested in the case that you observe.",
            "OK, and then you can prove several different things given I mean, for each of each type of an ally."
        ],
        [
            "So.",
            "OK, so one example that we can detail a bit more is this Bayesian inference and I'm using that in the kind of very general way, and I mean many people would have different definitions or would only consider the protocol but not the data generation mechanism and so on.",
            "So I'm trying to go through all these things that have defined an tell you what would be the way.",
            "Kind of.",
            "People would do it innovation framework.",
            "So as I said before, the data generation mechanism for Bayesian inference is usually that you assume that your function is sampled from some prior and the data is sampled IID from this distribution, right?",
            "So from the prior distribution and labeled by this function depends on whether you consider function or distribution here.",
            "The protocol is often you have offline.",
            "You see all the examples at once.",
            "And the last measure is the expected error under.",
            "This data generation mechanism.",
            "And the type of analysis is again you average things under the prior.",
            "So it's kind of fun.",
            "Average case analysis.",
            "Ann, usually you also have a restrictive assumptions like you assume that the noises of this specific form, like in the regulation based on regression, you would assume that the noise is Gaussian or this kind of thing.",
            "Well, I mean, usually you assume that each instance is sampled independently from some distribution.",
            "So I mean, there are two ways, right?",
            "Yeah, well yeah, maybe it's not very clear so yeah, usually have a different prior from the data for sampling the data.",
            "But there are two ways, so either.",
            "You consider a function.",
            "You sample your data and then you label these data with the function.",
            "Or you consider a distribution here.",
            "So distribution on XY.",
            "And then the data is just sample from XY, so it's not labeled by the function.",
            "Sure, yeah, I mean OK. Yeah, maybe this is a special case.",
            "I added the special case.",
            "That's true because like some people would just say, OK, I get this data and it's sample from distribution which needs, not the ID.",
            "And yeah, sure all these assumptions you only need if you want to prove things right, but otherwise you can.",
            "Well, also if you want to apply Bayes rules right, you have to choose whether you want to write the probability of the observation as a product of probabilities of individual observations which correspond to the ID.",
            "Or you define this otherwise."
        ],
        [
            "OK, so in our case we will consider more of the worst case analysis and we try to avoid assumptions as much as we can.",
            "And look for algorithm that do do best under these few assumptions.",
            "And the kind of quantity that that kind of is interesting to us is the following.",
            "We're looking at the loss of a given algorithm.",
            "Or some problem?",
            "And we look at the worst case.",
            "Value of this loss for the worst problem in a certain class maybe.",
            "And hopefully we try to find the algorithm that is best with respect to this worst case loss.",
            "So The thing is, we will show that this value, which is kind of the optimal loss, that we can expect under this worst case scenario, we will show that this actually does not need always to be small."
        ],
        [
            "So sometimes there is no way to escape and that's the no free lunch theorem.",
            "Sometimes you cannot hope to make this small, so you can't really have a good algorithm.",
            "And there are several ways in which you can make these non small I."
        ],
        [
            "Show you how.",
            "I'm.",
            "There is a, I mean, the distinction to understand which is a bit subtle here is that you can put restrictions.",
            "On the problem class and what does this mean?",
            "So that's the classical minimax approach.",
            "What you consider is.",
            "Just what I wrote before, but you consider that the problem is within a certain class.",
            "So for example, problem means the probability distribution, for example.",
            "So you assume that the probability distribution at certain regularity's say.",
            "And.",
            "You can either considered the loss or the loss with respect to the best algorithm for that problem.",
            "2 two cases occur.",
            "Um?",
            "The problem is like if you get the statement so if you prove that this quantity or this quantity has some value or is within certain range, the only thing you can say is that.",
            "If my problem so sorry I should have said problem in a class here.",
            "So you have also this restriction on the problem.",
            "So the only thing you can derive from that is that if your problem is indeed within that class.",
            "So if your probability distribution indeed as these regularity's, then you can say something about the loss of your algorithm.",
            "Or of the best algorithm?",
            "But if it doesn't satisfy these conditions, then you cannot say anything, right?",
            "So this is important.",
            "You have to.",
            "I understand that whatever restriction you put here would restrict the applicability of your results.",
            "Yeah, well, I mean.",
            "Yeah, I have not specified what is the class, but what I mean by this is.",
            "If you have a class of problems then you can define the Max over this class.",
            "Oh OK, OK, sorry.",
            "So if you if you don't have this restriction.",
            "Then I mean the the.",
            "What I mean by problem in this case is for example, all probability distributions say.",
            "So yes, yeah, it's OK. You always have a class for sure, but the class would be.",
            "Less restricted.",
            "I mean, for example in the online case you would have the maximum over all sequences of data points of all pairs, all sequences of pairs.",
            "No.",
            "OK. Maybe I'll skip that.",
            "So if we if we go the other instead of the minimax approach with the competitive approach.",
            "Here the difference and OK here is where the difference occurs is that instead of.",
            "Imposing restriction on your class of problems.",
            "What you impose is.",
            "That you don't want to compare your performance to kind of the best possible performance, but the best possible performance in a certain class of predictors so.",
            "You're looking at your loss, the loss of your algorithm on the problem, and you compare it to the loss of some reference algorithm on the problem and the reference algorithm.",
            "You take the best within a certain class, so here I mean again, it's not.",
            "I should have said references.",
            "Some elements of a small class of.",
            "Of algorithms and problem is.",
            "Some probability distribution, for example, among a large class, possibly all probability distributions, or all sequences of data or something so you.",
            "Put a lot less restrictions on the problems, but now you introduce restriction on what you are comparing your algorithm to.",
            "So in a way, you're trying to do as best as good as some algorithm within the class for all possible problems.",
            "So this way you no longer add assumption and you no longer have to, kind of.",
            "Make sure that your problem satisfies the restrictions that you put before.",
            "I mean, you don't have restrictions anymore.",
            "An OK.",
            "So once we are, I mean studying these quantities means proving what we call upper bounds or lower bounds on these numbers.",
            "So we want to an upper bound would be something saying that I mean the statement saying that this is less than some quantity and the lower bound would be something saying that this is larger than some quantity.",
            "And some proven upper bound.",
            "It's the only thing that we have to do is to show an algorithm.",
            "I mean, come up with an algorithm for which we can prove that the error is not larger than some value, and to prove a lower bound we have to prove that for any possible algorithm.",
            "Because we have here for any possible algorithm, there is some distribution for which there is large enough."
        ],
        [
            "An OK, finally I'll get to some notation.",
            "Which is kind of simple here, but we consider this this pairwise prediction, so we have an input SpaceX.",
            "An open space that we can consider as binary so we can restrict to binary classification for now and will be the sample size number of examples that we observe.",
            "So I I I'm not in the online setting here and more in the offline.",
            "So I observe pairs XY.",
            "I'm considering again the supervised learning framework, so I don't assume that I have unlabeled data.",
            "So we have a loss function, which often is whether the two instance two labels are the same or not.",
            "So that's the misclassification error."
        ],
        [
            "And.",
            "We look at.",
            "Either the cumulative loss for a given function, so the number of times it makes a mistake at predicting Y from X.",
            "Or the expected loss which is.",
            "The expectation of this value under some distribution.",
            "Some unknown distribution.",
            "That's the IID setting.",
            "We will consider we will call GN the function that we that we construct after observing NN pairs.",
            "Anne, this talk will be the optimal function in the sense that it minimizes the loss, the expected loss.",
            "OK. And.",
            "The problem is that we I mean kind of quantities that we can be interested in our.",
            "Like this minimax loss.",
            "So we compare the loss of a given algorithm to.",
            "The last of the best in the class.",
            "So for probabilities belonging to some class P of probabilities.",
            "Or the regret approach where we compared to a reference belonging to some class G of functions, and we take the Max overall probabilities distribution.",
            "So these are.",
            "Slightly more formalized goals.",
            "Um?",
            "Maybe I'll stop here and we can start again in.",
            "Well, it's in 10 minutes."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then start on the 2nd.",
                    "label": 0
                },
                {
                    "sent": "We have some loss.",
                    "label": 0
                },
                {
                    "sent": "I see of people.",
                    "label": 0
                },
                {
                    "sent": "It's a pleasure for me to welcome Olivier Busquet.",
                    "label": 0
                },
                {
                    "sent": "He is French, so and he studied at all these bigger cults in Paris.",
                    "label": 0
                },
                {
                    "sent": "In 2002, he got his PhD from the Ecole Polytechnique on concentration, inequality's and empirical process theory for machine learning.",
                    "label": 0
                },
                {
                    "sent": "His thesis was awarded the best thesis of the Equality equality technique and he also earned the best paper award at the Conference on Learning Theory during his PhD time.",
                    "label": 0
                },
                {
                    "sent": "After his PhD, he moved shortly to the US and then came to the MPI here, where he worked for three years as a senior postdoc.",
                    "label": 0
                },
                {
                    "sent": "And that was before he turned to the dark side and went to industry back to France.",
                    "label": 0
                },
                {
                    "sent": "In Paris he worked at party notes as a research manager and recently moved to Google in Zurich.",
                    "label": 0
                },
                {
                    "sent": "In his research career, he was mostly interested in learning theory, but he also contributed to more applied things.",
                    "label": 0
                },
                {
                    "sent": "So I heard you are coauthor on semi supervised learning paper of any.",
                    "label": 0
                },
                {
                    "sent": "So he also knows what theory is good for.",
                    "label": 0
                },
                {
                    "sent": "Before I give the word to Olivia, just let me mention that he was also the organizer of the last machine Learning Summer School in Tubingen, so I guess it's a nice for him to speak here again, OK?",
                    "label": 0
                },
                {
                    "sent": "Morning everyone, thank you very much for this introduction and I wish to sing the organizer for inviting me first of all and also explore inside.",
                    "label": 0
                },
                {
                    "sent": "It's kind of important moment for me because four years ago I was in this room and I was introducing the other speakers.",
                    "label": 0
                },
                {
                    "sent": "And I know it's a lot of work and it's I mean it's very difficult to organize such an event and to make it successful.",
                    "label": 0
                },
                {
                    "sent": "And this one seems very successful so far.",
                    "label": 0
                },
                {
                    "sent": "So I won't be here at the end, but I hope you will all give them a lot of applause at the end to congratulate the organizer for this nice Seven.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "OK, so I know he was a bit.",
                    "label": 0
                },
                {
                    "sent": "I mean this was a very nice dinner yesterday and lots of rings.",
                    "label": 0
                },
                {
                    "sent": "So probably you will not be completely awake for the entire duration duration of this talk so I will try to give you a very slow start this morning.",
                    "label": 0
                },
                {
                    "sent": "And aspirin say that I have turned to the dark side.",
                    "label": 0
                },
                {
                    "sent": "Which means that.",
                    "label": 0
                },
                {
                    "sent": "I started thinking, but you know what is this all for this theory?",
                    "label": 0
                },
                {
                    "sent": "How does it help in practice?",
                    "label": 0
                },
                {
                    "sent": "And does it really make a difference in the real world?",
                    "label": 0
                },
                {
                    "sent": "I mean, when you're in a company and someone ask you to design A learning algorithm.",
                    "label": 0
                },
                {
                    "sent": "Does it really help to have proven theorem before?",
                    "label": 0
                },
                {
                    "sent": "And So what?",
                    "label": 0
                },
                {
                    "sent": "I will try to attempt in this lecture is to show you that you know all the details, the mathematical details you can figure them out right.",
                    "label": 0
                },
                {
                    "sent": "You look at the papers you mean.",
                    "label": 0
                },
                {
                    "sent": "Once you know enough of you, know what are the definitions and that's you can more or less figure out the details and understand the proofs of the papers.",
                    "label": 0
                },
                {
                    "sent": "What is harder though, is to understand the meaning behind those proof, or really what you can infer from these theorems and what you can do in practice and how does it help you or guide you towards building the right algorithm.",
                    "label": 0
                },
                {
                    "sent": "And so this really be really the goal of these lectures.",
                    "label": 0
                },
                {
                    "sent": "There will be 3 parts, so today we will.",
                    "label": 0
                },
                {
                    "sent": "Look into.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Who?",
                    "label": 0
                },
                {
                    "sent": "So when I called the what and why.",
                    "label": 1
                },
                {
                    "sent": "Which is you know what is learning theory and why are we studying it?",
                    "label": 0
                },
                {
                    "sent": "An what are the foundations?",
                    "label": 0
                },
                {
                    "sent": "And we in the second part of this lecture will discuss about the North free lunch theorem, which is I think, an important piece of it.",
                    "label": 0
                },
                {
                    "sent": "And tomorrow will go into the bounds and show I will show you how to prove some bounds and how to play around with the different techniques that exists and they after tomorrow I will discuss it with the implication and the consequences and how to interpret this things.",
                    "label": 0
                },
                {
                    "sent": "So again.",
                    "label": 0
                },
                {
                    "sent": "The goal of this course is not really to.",
                    "label": 1
                },
                {
                    "sent": "He's not really to, you know, give you a lot of results and a lot of proof, but more talk about the foundations.",
                    "label": 0
                },
                {
                    "sent": "Keep saying simples and really give insights.",
                    "label": 1
                },
                {
                    "sent": "That's what I try to do most of the day.",
                    "label": 0
                },
                {
                    "sent": "I mean most of the lecture.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And that will of course not cover things like the history of the domain or general results and advanced topics.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's start.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So before.",
                    "label": 0
                },
                {
                    "sent": "Telling you what is learning theory, I have to tell you what is a theory and what is the goal of defining a theory about learning.",
                    "label": 1
                },
                {
                    "sent": "So this is I mean definition of what is a theory and I have emphasized the important words here.",
                    "label": 0
                },
                {
                    "sent": "Important is that we are looking at the phenomenon and we try to explain this phenomenon and we want to explain it in a repeatable way.",
                    "label": 0
                },
                {
                    "sent": "And also.",
                    "label": 0
                },
                {
                    "sent": "This explanation should help us make prediction about these phenomena.",
                    "label": 0
                },
                {
                    "sent": "That's the important point.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in a way you can think of a theory as a model, something that kind of represents over describ, stomp, elemental.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "That model helps us understand the, you know the various things that happen when you absorb this permanent.",
                    "label": 0
                },
                {
                    "sent": "In this case, it would be the phenomenon of learning of course.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And of course, predict what's going to happen later.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Are two more definitions that will be useful.",
                    "label": 1
                },
                {
                    "sent": "During this lecture.",
                    "label": 0
                },
                {
                    "sent": "Deduction in induction.",
                    "label": 0
                },
                {
                    "sent": "These are often opposed, and actually they are opposed.",
                    "label": 0
                },
                {
                    "sent": "If you look at the definitions, so deduction is really you go from the general axioms, the general rules and you try to derive consequences.",
                    "label": 0
                },
                {
                    "sent": "So you go from the general to the specific and specific is, say, a theorem.",
                    "label": 1
                },
                {
                    "sent": "So you go from the action and you derive your theorem, you prove yourself.",
                    "label": 0
                },
                {
                    "sent": "So this is really what mathematics is all about.",
                    "label": 0
                },
                {
                    "sent": "Induction is more what physics is all about, which is.",
                    "label": 0
                },
                {
                    "sent": "You look at specific examples.",
                    "label": 0
                },
                {
                    "sent": "You make observations about nature and then you try to infer the general principles that the actions of nature if you want.",
                    "label": 0
                },
                {
                    "sent": "This is how you create series, usually from observing nature I mean there is also something in between which is called transduction, which will probably heard of which is going from specific to specific without even mentioning a model.",
                    "label": 1
                },
                {
                    "sent": "But these are two important things from general to specific or from specific to general.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what is a good theory?",
                    "label": 1
                },
                {
                    "sent": "Good theory is one that is, you know, intuitively makes sense, of course, and which is simple and concise.",
                    "label": 0
                },
                {
                    "sent": "So you have a lot of observation.",
                    "label": 0
                },
                {
                    "sent": "You can look outside and observe a lot of natural phenomena.",
                    "label": 0
                },
                {
                    "sent": "And if you can explain all these phenomena with very small sets of actions of our principles, then you are happy in a way.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So you want to explain many things with few things.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And these principles, or these actions or postulates they?",
                    "label": 0
                },
                {
                    "sent": "I mean they can be called assumptions, axioms, postulates or any.",
                    "label": 0
                },
                {
                    "sent": "I mean there are various denominations.",
                    "label": 0
                },
                {
                    "sent": "An example of them is the following one.",
                    "label": 0
                },
                {
                    "sent": "So principle of relativity, the laws of physics are the same in all inertial frames of reference.",
                    "label": 1
                },
                {
                    "sent": "So this is really something that you can't really prove.",
                    "label": 0
                },
                {
                    "sent": "You just say, OK, let's assume this is true, and if this is true, what can we derive from that and what are the consequences?",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that's the important point here.",
                    "label": 0
                },
                {
                    "sent": "These assumptions you can never prove them, you can only you know.",
                    "label": 0
                },
                {
                    "sent": "Kind of figure out what are the consequences of these assumptions and then go in the nature an try these things and test whether they are true or not.",
                    "label": 0
                },
                {
                    "sent": "Test the consequences.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And of course, a good theory should have few of them.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we have defined what is serial it now let's define what is learning.",
                    "label": 1
                },
                {
                    "sent": "So learning, I mean, you all have pretty good efficient what is learning, but let's make things precise.",
                    "label": 0
                },
                {
                    "sent": "Learning definition you can find in dictionary is to gain knowledge, comprehension of mastery or mastery of through experience or study.",
                    "label": 1
                },
                {
                    "sent": "Study is kind of the easy case.",
                    "label": 1
                },
                {
                    "sent": "You study something, you know it.",
                    "label": 0
                },
                {
                    "sent": "So we will not focus on this part of it, but more on learning through experience.",
                    "label": 0
                },
                {
                    "sent": "So you do something, and as you do it, you kind of gain knowledge comprehension like understanding.",
                    "label": 0
                },
                {
                    "sent": "So in a way you build your own mental model.",
                    "label": 0
                },
                {
                    "sent": "Right, so Interestingly, is the interesting part is when you don't just accumulate observations, but you really create your own representation of the world and you have some internal model that allows you not only to account for what you have observed, but also allows you to make predictions about the future.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So I mean all these words.",
                    "label": 0
                },
                {
                    "sent": "You can consider them as meaning the same thing in the context of this lecture.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this leads us to an interesting.",
                    "label": 0
                },
                {
                    "sent": "I mean, if we look at the definition of learning and definition of a theory, we get some kind of weird circularity here.",
                    "label": 0
                },
                {
                    "sent": "So we have said what is a theory and what it how it should be constructed.",
                    "label": 1
                },
                {
                    "sent": "Siri is really.",
                    "label": 0
                },
                {
                    "sent": "Making observation and constructing a model of these observations.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "End.",
                    "label": 0
                },
                {
                    "sent": "The question is.",
                    "label": 0
                },
                {
                    "sent": "Why did I tell you all that, right?",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Actually, building a theory is really the same as induction, which is the same as I said before, as learning learning is your observe things learning from experience at least you're observing and you make a kind of internal model of these things.",
                    "label": 1
                },
                {
                    "sent": "And building a series the same so.",
                    "label": 0
                },
                {
                    "sent": "You know it's kind of.",
                    "label": 0
                },
                {
                    "sent": "See.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Cooler here, I'm I'm telling you that learning is building series an I want to build a theory on building series.",
                    "label": 0
                },
                {
                    "sent": "So let me rephrase that.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A bit so induction is the process of building series.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Learning theory, the main focus of learning theory is the phenomenon of induction, so.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How can we?",
                    "label": 0
                },
                {
                    "sent": "Build a theory about building series.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so I mean I won't go more into the details of that, but it's just to emphasize that.",
                    "label": 0
                },
                {
                    "sent": "This whole thing is involving a lot of philosophical issues and I will touch upon some of them.",
                    "label": 1
                },
                {
                    "sent": "Some of them later on.",
                    "label": 0
                },
                {
                    "sent": "But let's",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Try to go a bit further now.",
                    "label": 0
                },
                {
                    "sent": "So OK, now you have a rough idea of what is it that we are trying to do with learning theory now.",
                    "label": 0
                },
                {
                    "sent": "Why is it that we are trying to do that?",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "I like this quote.",
                    "label": 0
                },
                {
                    "sent": "I mean, you can find it in that next book.",
                    "label": 0
                },
                {
                    "sent": "And I think it it doesn't.",
                    "label": 0
                },
                {
                    "sent": "It doesn't say that it's from currently divine.",
                    "label": 0
                },
                {
                    "sent": "Well, I mean I don't know why I look on the Internet and that's the kind of reference that is given most often, but maybe it was reduced by many people.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "I mean, yeah.",
                    "label": 0
                },
                {
                    "sent": "What else can I say?",
                    "label": 0
                },
                {
                    "sent": "No, I mean more seriously.",
                    "label": 0
                },
                {
                    "sent": "These are the things that I think are important.",
                    "label": 0
                },
                {
                    "sent": "First of all, we want to understand what's going on when we do learning right?",
                    "label": 0
                },
                {
                    "sent": "And we want to study the properties of different learning algorithm and be able to say OK this is better.",
                    "label": 0
                },
                {
                    "sent": "Why in this context this is better and this other algorithm is better than?",
                    "label": 0
                },
                {
                    "sent": "And not just by, you know, trying it on various kinds of data, but by being able to say I mean to make some general statements.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "Ideally that should lead us to, you know.",
                    "label": 0
                },
                {
                    "sent": "A way to design better algorithm for certain tasks.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So again.",
                    "label": 0
                },
                {
                    "sent": "This induction versus deduction.",
                    "label": 0
                },
                {
                    "sent": "I mean, I'm kind of repeating the same thing over and over again in various flavors, hoping that you will get the main message here.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "If you compare induction induction, that's really what is kind of most frustrating.",
                    "label": 0
                },
                {
                    "sent": "Both studying induction is that deduction is can be easily justified.",
                    "label": 1
                },
                {
                    "sent": "I mean, once you have agreed upon the actions, then you kind of derive and the rules for combining these actions, then you derive the consequences you proved your serum and nobody can disagree.",
                    "label": 0
                },
                {
                    "sent": "I mean, this theorem is correct, provided that everyone agrees on the action.",
                    "label": 0
                },
                {
                    "sent": "For induction is exactly the opposite.",
                    "label": 0
                },
                {
                    "sent": "You can't really justify anything.",
                    "label": 0
                },
                {
                    "sent": "You know someone comes up with one action about some observations.",
                    "label": 1
                },
                {
                    "sent": "You can only test the consequences of these actions.",
                    "label": 0
                },
                {
                    "sent": "So make deduction from that and then check that it's true.",
                    "label": 0
                },
                {
                    "sent": "I mean check that it corresponds to correlate, Stew your observation, but you can't really prove or disprove an action and.",
                    "label": 0
                },
                {
                    "sent": "You can't really argue, but the truth of some induction in a way.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Let's see I mean, let's make these now a bit more concrete and I will give you some examples too.",
                    "label": 0
                },
                {
                    "sent": "You know force you to reason about these things.",
                    "label": 0
                },
                {
                    "sent": "Here is an example.",
                    "label": 0
                },
                {
                    "sent": "So let's say we observe the sun every morning, and we see that it's rising every morning.",
                    "label": 0
                },
                {
                    "sent": "I mean, the usual example is your weather certainly is running from the East or from the West.",
                    "label": 0
                },
                {
                    "sent": "But let's just say we observe that the sun is rising every morning.",
                    "label": 0
                },
                {
                    "sent": "For a number of the dates OK and the question I'm asking you is OK given that you observe that 40 days, what is your estimate of the probability that the sun will rise again tomorrow?",
                    "label": 1
                },
                {
                    "sent": "I have not defined what is probably T yet you have already.",
                    "label": 0
                },
                {
                    "sent": "I'm sure you have already used that and you already know what it is, but I will go into the details later.",
                    "label": 0
                },
                {
                    "sent": "But let's say you have some intuitive notion of what is the probability.",
                    "label": 0
                },
                {
                    "sent": "And let's say I'm asking you.",
                    "label": 1
                },
                {
                    "sent": "What is your best estimate at this probability given these observations?",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "There are many ways in which you can answer this.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the first one you can say, well, they cannot be the P cannot be defined, right?",
                    "label": 1
                },
                {
                    "sent": "Tomorrow is not identical to yesterday, is just.",
                    "label": 1
                },
                {
                    "sent": "Another day is not a repetition of the same experiments, right?",
                    "label": 0
                },
                {
                    "sent": "You can't really compare two different days, so I don't want to define this probability because this is just.",
                    "label": 0
                },
                {
                    "sent": "A single events that cannot be compared to any other event.",
                    "label": 0
                },
                {
                    "sent": "OK, that's kind of the pessimist answer.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The optimist answer would be the opposite.",
                    "label": 0
                },
                {
                    "sent": "Say Oh well, it's always Rose so far, so tomorrow I'm sure it will rise.",
                    "label": 0
                },
                {
                    "sent": "So P = 1.",
                    "label": 0
                },
                {
                    "sent": "Then you have the beige and answer.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which is.",
                    "label": 0
                },
                {
                    "sent": "Well, let's assume that's P. This is probability.",
                    "label": 0
                },
                {
                    "sent": "Pi put a prior on this probability unit from prior on.",
                    "label": 0
                },
                {
                    "sent": "This probability between zero and one, and then I workout the details.",
                    "label": 0
                },
                {
                    "sent": "I apply Bayes rule and I get this value here Z + 1 / D + 2.",
                    "label": 0
                },
                {
                    "sent": "OK, so as the increases this probability will converge to one.",
                    "label": 0
                },
                {
                    "sent": "But in the beginning it's kind of more towards the help.",
                    "label": 0
                },
                {
                    "sent": "And then there is the physics.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Physicist answer.",
                    "label": 0
                },
                {
                    "sent": "Which is, you know you can workout the details so the sun is a star.",
                    "label": 0
                },
                {
                    "sent": "We know how many stars explode per day.",
                    "label": 1
                },
                {
                    "sent": "An we can compare the sun to other stars with the same property.",
                    "label": 1
                },
                {
                    "sent": "Take into account the age of the sun and so on, and we can workout the probability that the sun will explode tomorrow and not rise again.",
                    "label": 1
                },
                {
                    "sent": "So OK, what?",
                    "label": 1
                },
                {
                    "sent": "What do we gain from this example?",
                    "label": 0
                },
                {
                    "sent": "Basically all these results just converge towards saying that there is a high probability of the sun rising again tomorrow, and they all have different justification and these different justification.",
                    "label": 0
                },
                {
                    "sent": "Really, the point is that they differ in how they consider similar situation, like in this case.",
                    "label": 0
                },
                {
                    "sent": "It's like every day is the same.",
                    "label": 0
                },
                {
                    "sent": "Here.",
                    "label": 0
                },
                {
                    "sent": "You have some kind of probabilistic notion of a day, plus you know the prior on the probability P. And here the similarity is not over days but over the.",
                    "label": 0
                },
                {
                    "sent": "Kind of elements that were considering the sun and the stars.",
                    "label": 0
                },
                {
                    "sent": "It's really up to how you kind of relates the current situation or the OR the future situation to what you have observed in the past.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let me give you another example.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's assume we observe this sequence of numbers 1247.",
                    "label": 1
                },
                {
                    "sent": "And the question is what comes next, any idea?",
                    "label": 1
                },
                {
                    "sent": "OK, that's one answer, but actually there is not just one.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Answer There are so far.",
                    "label": 0
                },
                {
                    "sent": "I mean it keeps going there 599.",
                    "label": 0
                },
                {
                    "sent": "This encyclopedia of integer sequences, so you go in the Internet, you type 1247 and it gives you all the sequences that are known and start with 1247 and all are very good justification.",
                    "label": 0
                },
                {
                    "sent": "So 11 could be one but.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let's see what are the other one so elephant would correspond to this one, or at least could correspond to this one, which is the maximum number of pieces formed when you slice a pancake with end cuts.",
                    "label": 1
                },
                {
                    "sent": "Keep cutting your pancake and every cuts you add NPC's.",
                    "label": 0
                },
                {
                    "sent": "So you have 1247 elements, 16 and so on, and this sequence is called a 124.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "But",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You could just think in another way and say oh, this is just this recursion.",
                    "label": 0
                },
                {
                    "sent": "Here I take the previous two numbers.",
                    "label": 0
                },
                {
                    "sent": "I add them.",
                    "label": 0
                },
                {
                    "sent": "I had one and I get 1247 and then I continue like 12 and 20.",
                    "label": 0
                },
                {
                    "sent": "This is perfectly fine, right?",
                    "label": 0
                },
                {
                    "sent": "It fits with what we have observed.",
                    "label": 0
                },
                {
                    "sent": "It's a natural.",
                    "label": 0
                },
                {
                    "sent": "I mean, it's a relatively reasonable equation here, and we can carry on.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another one is what I call the triple matching numbers.",
                    "label": 0
                },
                {
                    "sent": "OK, yet another pretty simple recursion.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And you can have some kind of different approach if you're bit original, you can say, well, let's look at the binary expansion of the sequence.",
                    "label": 1
                },
                {
                    "sent": "So one is, this two is 10 in binary for is, 107 is 111.",
                    "label": 1
                },
                {
                    "sent": "And if you count number of ones, you have the you have an odd number of ones in all these numbers.",
                    "label": 1
                },
                {
                    "sent": "So you can say, well, let's carry on.",
                    "label": 0
                },
                {
                    "sent": "Let's keep looking at bigger and bigger binary numbers and just keep the ones that have an odd number of ones.",
                    "label": 0
                },
                {
                    "sent": "And this gives you 1247, eight 1113 so.",
                    "label": 0
                },
                {
                    "sent": "It said.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just a simple right?",
                    "label": 0
                },
                {
                    "sent": "Or, well, you can be even more.",
                    "label": 0
                },
                {
                    "sent": "Tortured in away and look at Pi, an E interleaved.",
                    "label": 0
                },
                {
                    "sent": "So here is I removed the three right so 314159 that would be \u03c0 and 2718 that would be E. And then you say, well, OK 1247.",
                    "label": 0
                },
                {
                    "sent": "So the next one is 1.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Why not?",
                    "label": 0
                },
                {
                    "sent": "And well, you can say, well, I'm observing 1247, but I think later on it will keep at 7 and this is my explanation for it.",
                    "label": 0
                },
                {
                    "sent": "OK, so basically you see that you can come up with as many possible expansion of that sequence as you wish, and it's you know a matter of which one.",
                    "label": 1
                },
                {
                    "sent": "Do you consider the simplest is there is no notion of simplest thing like an absolute because some people would argue that the binary expansion is natural.",
                    "label": 1
                },
                {
                    "sent": "Like computers would argue that.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 1
                },
                {
                    "sent": "Reasonable people might argue that this one is.",
                    "label": 0
                },
                {
                    "sent": "Simpler.",
                    "label": 0
                },
                {
                    "sent": "I don't know.",
                    "label": 0
                },
                {
                    "sent": "I mean, it's really up to you.",
                    "label": 0
                },
                {
                    "sent": "Well, some other example in the same thing.",
                    "label": 0
                },
                {
                    "sent": "If you look at.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sequence.",
                    "label": 0
                },
                {
                    "sent": "You think, well, OK, with so many numbers there is only one way to continue this sequence, right?",
                    "label": 0
                },
                {
                    "sent": "You can be sure that.",
                    "label": 0
                },
                {
                    "sent": "I mean these are all primes, so the next one is a prime well.",
                    "label": 0
                },
                {
                    "sent": "Again, if you look into this insect.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Encyclopedia you can see 2 answers.",
                    "label": 0
                },
                {
                    "sent": "One is the next prime.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And one is another which is the order of the next simple group.",
                    "label": 1
                },
                {
                    "sent": "OK, so you probably don't know what it is.",
                    "label": 0
                },
                {
                    "sent": "Simple group.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or maybe you know.",
                    "label": 0
                },
                {
                    "sent": "But doesn't matter.",
                    "label": 0
                },
                {
                    "sent": "My point is, you know.",
                    "label": 0
                },
                {
                    "sent": "It's a matter of what you're most familiar with, and you know people are more familiar with Prime, so maybe we can say OK, a natural continuation of the sequence is 61, But again, there is no, we cannot prove it right.",
                    "label": 0
                },
                {
                    "sent": "We cannot say for sure.",
                    "label": 0
                },
                {
                    "sent": "This sequence will continue with 61 and there is no other way.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Another example which gives a little twist on that the the following.",
                    "label": 0
                },
                {
                    "sent": "So we observe this sequence of numbers.",
                    "label": 0
                },
                {
                    "sent": "Maybe it's familiar to you.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But it looks random, no.",
                    "label": 1
                },
                {
                    "sent": "It's just a bunch of numbers.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "But you know, if you don't know the specific number that is very popular.",
                    "label": 0
                },
                {
                    "sent": "Like if I had given you another less popular number, you would have said, OK, that seems to not have any pattern.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So an if you look actually at the frequencies right?",
                    "label": 0
                },
                {
                    "sent": "If you.",
                    "label": 0
                },
                {
                    "sent": "Kind of count how many times each individual number.",
                    "label": 0
                },
                {
                    "sent": "Ockers and you kind of.",
                    "label": 0
                },
                {
                    "sent": "Assume that the probability of the next digit.",
                    "label": 1
                },
                {
                    "sent": "Being I is proportional to how many times jobs you have observed this I divided by number.",
                    "label": 0
                },
                {
                    "sent": "Digital observed then?",
                    "label": 0
                },
                {
                    "sent": "This probability you can see that it will converge to 110's, so you can say, well, this is kind of random in the sense that every number can occur with the same probability.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But as you said.",
                    "label": 0
                },
                {
                    "sent": "Now you notice.",
                    "label": 0
                },
                {
                    "sent": "Uh.",
                    "label": 0
                },
                {
                    "sent": "I mean, this really looks like the expansion of fine, right so?",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So why do we prefer this answer?",
                    "label": 0
                },
                {
                    "sent": "The last answer?",
                    "label": 0
                },
                {
                    "sent": "Well, because we obviously notice that there is a structure.",
                    "label": 0
                },
                {
                    "sent": "Even though it's not, you know you can formalize it by some kind of recursion, like you cannot say UN is equal to U N -- 1 plus something.",
                    "label": 0
                },
                {
                    "sent": "But still we managed to notice that this is something that contains structure and actually there is.",
                    "label": 0
                },
                {
                    "sent": "There is an algorithm that would produce these sequence and continue it, so which so this algorithm you can think of it as a model for that sequence.",
                    "label": 0
                },
                {
                    "sent": "It's corresponds to this observation and it gives you.",
                    "label": 0
                },
                {
                    "sent": "An expansion.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, now let's wrap up.",
                    "label": 0
                },
                {
                    "sent": "Is there a general principle for providing a good answer to these riddles, right?",
                    "label": 0
                },
                {
                    "sent": "These questions of continuing sequences?",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well, unfortunately.",
                    "label": 0
                },
                {
                    "sent": "I mean there is one approach that seems to be satisfactory which is called.",
                    "label": 0
                },
                {
                    "sent": "This all comes razor.",
                    "label": 0
                },
                {
                    "sent": "You try to find an explanation which is consistent with what you observe and which is the simplest possible.",
                    "label": 1
                },
                {
                    "sent": "But the problem is.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Can't really define.",
                    "label": 0
                },
                {
                    "sent": "This simplicity.",
                    "label": 0
                },
                {
                    "sent": "So first of all, you cannot really justify that this is.",
                    "label": 0
                },
                {
                    "sent": "This will give you the best answer.",
                    "label": 0
                },
                {
                    "sent": "As again as I said before, you can justify this.",
                    "label": 0
                },
                {
                    "sent": "Postulates, right there is no proof that the simplest answer is the correct one.",
                    "label": 1
                },
                {
                    "sent": "And second of all.",
                    "label": 0
                },
                {
                    "sent": "You can't define simplicity because it's not objective.",
                    "label": 0
                },
                {
                    "sent": "There are many ways in which you can measure it, and everyone would have a different notion.",
                    "label": 1
                },
                {
                    "sent": "I mean, some people tend to say that the right notion of simplicity is what is called Kolmogorov complexity, which is a measure of the length of the shortest program that can generate some sequence, or that can do some.",
                    "label": 1
                },
                {
                    "sent": "Implement some function, but even that is not completely objective, because when you define the length of the shortest program, you first have to define in which programming language you write your program.",
                    "label": 0
                },
                {
                    "sent": "An which means that every programming language would give rise to a different notion of lengths.",
                    "label": 0
                },
                {
                    "sent": "So even though you can prove that asymptotically they are all equivalent.",
                    "label": 0
                },
                {
                    "sent": "At least if their languages completes during completes.",
                    "label": 0
                },
                {
                    "sent": "In practice, on finite sequences, each programming language would give you a different notion of simplicity.",
                    "label": 0
                },
                {
                    "sent": "So if you observe a finite sequence as we did before, there is again no no reason to choose one or another.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Seems that we are doomed, right?",
                    "label": 0
                },
                {
                    "sent": "I'm just saying I keep saying, OK, we can't do anything, so what's the point?",
                    "label": 0
                },
                {
                    "sent": "Well, let's see, maybe we can do something, but it means we first have to kind of lower our expectations.",
                    "label": 0
                },
                {
                    "sent": "We want to prove that something is the right thing to do.",
                    "label": 0
                },
                {
                    "sent": "Or I mean, we want to prove that there is an optimal way of doing induction.",
                    "label": 0
                },
                {
                    "sent": "But we can at least try to get some more understanding.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let me now define probability and discuss a bit about what probability means, because you've heard a lot probably before in the previous lectures about probabilities.",
                    "label": 0
                },
                {
                    "sent": "Maybe you also use that a lot.",
                    "label": 0
                },
                {
                    "sent": "But I want to make you think again about what is probability and what it means.",
                    "label": 0
                },
                {
                    "sent": "So probability mean to me is just a way to formalize reasoning under uncertainty.",
                    "label": 1
                },
                {
                    "sent": "So it's a convenient way to define to assign numbers to events, right?",
                    "label": 0
                },
                {
                    "sent": "An it relies on these simple actions that probability of an event is non negative probability of the certain events is 1.",
                    "label": 0
                },
                {
                    "sent": "And then you have this additivity like disjoint events are probability that sum up and if there is some intersection you can just subtract it.",
                    "label": 0
                },
                {
                    "sent": "And well, optionally you can introduce this.",
                    "label": 0
                },
                {
                    "sent": "Kind of Sigma additivity of the probability, but it's not really relevant to understand what it means.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's pretty simple.",
                    "label": 0
                },
                {
                    "sent": "Pretty convenient.",
                    "label": 0
                },
                {
                    "sent": "You can make easy computation with these things, But the question is what does it all mean?",
                    "label": 0
                },
                {
                    "sent": "And more precisely how you can measure these numbers?",
                    "label": 0
                },
                {
                    "sent": "Or you decide which is the right number for an event.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "There are a number of ways to interpret these numbers, and interpretation here means assigning meaning to a given number.",
                    "label": 0
                },
                {
                    "sent": "Uh.",
                    "label": 0
                },
                {
                    "sent": "One of the simplest one is the so called frequentist interpretation.",
                    "label": 0
                },
                {
                    "sent": "So in the frequencies interpretation probabilities are relative frequencies.",
                    "label": 1
                },
                {
                    "sent": "So you know how many times a certain event occurs divided by how many times you tried this?",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And I will get into details.",
                    "label": 0
                },
                {
                    "sent": "Objectivism is.",
                    "label": 0
                },
                {
                    "sent": "More or less the same.",
                    "label": 0
                },
                {
                    "sent": "I mean you you can say.",
                    "label": 0
                },
                {
                    "sent": "The probability is still a frequency, but now this frequency is not observed as infrequent ISM, but it's kind of postulated that something that exists.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And you have the Subjectivist POV which says that well, probabilities are just beliefs is just something that we think is true, but there is no way to prove that it's true.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so probabilities as frequencies.",
                    "label": 0
                },
                {
                    "sent": "So what you do is, I said as I said, and as is natural, you repeat a given experiment N times and if the events of interest occurs K times, then K / N is your estimate of the probability and you can even define the probability of these events as the limits.",
                    "label": 1
                },
                {
                    "sent": "Right so.",
                    "label": 0
                },
                {
                    "sent": "You can say, well, if I were to repeat this experiment and Infinity infinite number of times.",
                    "label": 0
                },
                {
                    "sent": "Eventually these limits might convert to some number and this is how I define probability.",
                    "label": 0
                },
                {
                    "sent": "OK, that's kind of clear and easy, but the problem is you can't always repeat experiments and also you rarely can repeat infinitely experiments, so you cannot really have a measure of these numbers by experimenting, because you can't really reach that limit and you know probability of sunrising tomorrow.",
                    "label": 0
                },
                {
                    "sent": "How can?",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I repeat.",
                    "label": 0
                },
                {
                    "sent": "So there are some limitations.",
                    "label": 0
                },
                {
                    "sent": "So these Objectivists interpretation?",
                    "label": 0
                },
                {
                    "sent": "It's kind of, you know.",
                    "label": 0
                },
                {
                    "sent": "It's kind of a leap of face, you say?",
                    "label": 0
                },
                {
                    "sent": "Well, I can measure.",
                    "label": 0
                },
                {
                    "sent": "I mean, I can try to measure these probabilities, but I'm assuming that they exist and this is some kind of intrinsic property of the word that there is.",
                    "label": 0
                },
                {
                    "sent": "Like the right, just sorry the sun has attached to him or attached to it.",
                    "label": 0
                },
                {
                    "sent": "Some probability of rising tomorrow an.",
                    "label": 0
                },
                {
                    "sent": "This is kind of a property of the nature, and I can only observe it.",
                    "label": 0
                },
                {
                    "sent": "It's like the mass, right?",
                    "label": 0
                },
                {
                    "sent": "The sun has some mass, but it also has some probability of rising and I just want to measure that.",
                    "label": 0
                },
                {
                    "sent": "So these probabilities preexists.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the last interpretation.",
                    "label": 0
                },
                {
                    "sent": "So, for the subjectivist interpretation, these probabilities they are just numbers that people given person would assign to some events, and that correspond to how like or I mean our strong is belief is that this event will occur and there is a. I mean, you can naturally define.",
                    "label": 1
                },
                {
                    "sent": "I mean naturally assign these beliefs.",
                    "label": 0
                },
                {
                    "sent": "I mean assigned numbers to these beliefs.",
                    "label": 0
                },
                {
                    "sent": "Real numbers to these beliefs and then you know you can come up with the natural or intuitively natural rules for combining these beliefs when you have, when you believe in one event and you have ability for one event or another events how you combine these beliefs and so on and you can show that if you use these natural rules then it will lead you to.",
                    "label": 0
                },
                {
                    "sent": "Something that has the same properties as probabilities so.",
                    "label": 1
                },
                {
                    "sent": "Essentially.",
                    "label": 0
                },
                {
                    "sent": "Probabilities are the right way to formalize.",
                    "label": 1
                },
                {
                    "sent": "The natural notion of belief in something.",
                    "label": 0
                },
                {
                    "sent": "And then once you have kind of chosen, one of these interpretations.",
                    "label": 0
                },
                {
                    "sent": "I mean you don't have to choose it.",
                    "label": 0
                },
                {
                    "sent": "Basically you can just run your calculation without even.",
                    "label": 0
                },
                {
                    "sent": "Thinking about how to interpret these numbers.",
                    "label": 0
                },
                {
                    "sent": "And one way in which you can.",
                    "label": 0
                },
                {
                    "sent": "Combining these numbers, besides the action, I mean, you can derive that from the actions is what?",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Called the Bayes rule and what it is is just a way to update your probabilities when you make observation, so you have prior beliefs in some hypothesis P of H. You have some way to measure how like what is called the conditional probability of observing some data given the hypothesis that's against some belief that you define so or some number and the natural way too.",
                    "label": 1
                },
                {
                    "sent": "Derive from that how much you believe in your hypothesis.",
                    "label": 0
                },
                {
                    "sent": "After you have seen the data is to apply this rule, and this is kind of if you want to be consistent with your actions.",
                    "label": 0
                },
                {
                    "sent": "That's the only way you should do it.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "But again, you can't really measure all these numbers, but you know once you have agreed that this is the right thing to do, you can just work that workout the details.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So again, my point here is.",
                    "label": 0
                },
                {
                    "sent": "What can we gain using probabilities is is this the right way of doing inference or?",
                    "label": 0
                },
                {
                    "sent": "Induction, well, I mean it's a natural way to do it, or it's a convenient way to do it.",
                    "label": 0
                },
                {
                    "sent": "You get these nice formulas and you get these nice.",
                    "label": 0
                },
                {
                    "sent": "Numbers that you can combine, but we don't gain anything right?",
                    "label": 0
                },
                {
                    "sent": "We still cannot prove that what we are saying is true because.",
                    "label": 0
                },
                {
                    "sent": "You know we don't get any guarantee the probabilities, they just help us rezoning.",
                    "label": 0
                },
                {
                    "sent": "But if we did not set these numbers right in the 1st place, but even if we set them right?",
                    "label": 0
                },
                {
                    "sent": "I mean because there are so many ways to interpret them.",
                    "label": 0
                },
                {
                    "sent": "You can't really prove that the probability of something is some number because you know you can come up with all sorts of interpretations.",
                    "label": 0
                },
                {
                    "sent": "You can be a frequencies or an objective or subjective istan.",
                    "label": 0
                },
                {
                    "sent": "None of these people would agree, right?",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So again, it's kind of disappointing.",
                    "label": 0
                },
                {
                    "sent": "But even though you are using probabilities, it doesn't mean that you are doing the right thing or that you're justifying anything.",
                    "label": 0
                },
                {
                    "sent": "I'm.",
                    "label": 0
                },
                {
                    "sent": "So we.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The problem is that we need these assumptions and there is no way we can escape these assumptions.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "So what can we do?",
                    "label": 0
                },
                {
                    "sent": "What we can do is.",
                    "label": 0
                },
                {
                    "sent": "You know?",
                    "label": 0
                },
                {
                    "sent": "Implicitly assume something like the future looks like the best.",
                    "label": 1
                },
                {
                    "sent": "This is kind of reasonable and you know everyone would agree with that some degree.",
                    "label": 0
                },
                {
                    "sent": "Or what we have not seen yet?",
                    "label": 1
                },
                {
                    "sent": "Looks like what we have seen.",
                    "label": 0
                },
                {
                    "sent": "And it's clear that if we don't make such assumptions, then there is no point in doing any.",
                    "label": 0
                },
                {
                    "sent": "You know, working in learning theory or even working in machine learning at all, because if you don't assume that there is some regularity in the world, there is no hope that you can uncover it with these algorithms.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "But still we want to make these assumptions, you know, as limited as possible.",
                    "label": 0
                },
                {
                    "sent": "We don't want to assume too much.",
                    "label": 0
                },
                {
                    "sent": "And we want to keep them to a minimum, which means that.",
                    "label": 1
                },
                {
                    "sent": "Maybe we can even completely get rid of this assumption.",
                    "label": 0
                },
                {
                    "sent": "Actually you can in a certain sense if you don't say much, proving that some algorithm is optimal.",
                    "label": 0
                },
                {
                    "sent": "But if you want to compare algorithms like if you don't.",
                    "label": 1
                },
                {
                    "sent": "Want to predict, but too I mean to predict well, but you want to predict as well as some other algorithms.",
                    "label": 0
                },
                {
                    "sent": "So if you want to imitate the behavior of an algorithm independent of how good that algorithm is, then you can you know somehow get rid of these assumptions.",
                    "label": 0
                },
                {
                    "sent": "So it's a matter of, you know.",
                    "label": 0
                },
                {
                    "sent": "Can we match some others performance?",
                    "label": 1
                },
                {
                    "sent": "And like and when we are willing to go with assumptions, then the question is.",
                    "label": 0
                },
                {
                    "sent": "And the question that the series should answer is given these assumptions, what can we do at best right?",
                    "label": 1
                },
                {
                    "sent": "What is the optimal algorithm with respect to these assumptions?",
                    "label": 0
                },
                {
                    "sent": "That's something we can answer.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK. Now I want to kind of slowly go towards more formal things.",
                    "label": 0
                },
                {
                    "sent": "Hope it's not too slow for you.",
                    "label": 0
                },
                {
                    "sent": "I fixed myself 1/4 of 5% of people that should be asleep by the end of the lecture.",
                    "label": 0
                },
                {
                    "sent": "So far it seems to be OK. Maybe 3% yes.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Maybe I need to be a bit faster?",
                    "label": 0
                },
                {
                    "sent": "So let me introduce now.",
                    "label": 0
                },
                {
                    "sent": "I mean I, I'll try to describe a picture of the things.",
                    "label": 0
                },
                {
                    "sent": "Let's see.",
                    "label": 0
                },
                {
                    "sent": "You know how to distinguish between different assumptions or frameworks?",
                    "label": 0
                },
                {
                    "sent": "Because you probably have heard about you know online learning or semi supervised learning, or beige and inference and all these things, you know I want to kind of draw a chart where you can place these things and relate them to each other and understand what is an assumption and what is just a matter of setting the problem and so on and trying not to confuse all these things.",
                    "label": 0
                },
                {
                    "sent": "So here are some examples of settings that are commonly used, so the so called offline supervised learning.",
                    "label": 0
                },
                {
                    "sent": "You have training pairs that are given to you, and the goal is to produce a model that predicts well on future instances.",
                    "label": 1
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Semi supervised learning.",
                    "label": 0
                },
                {
                    "sent": "You have both training pairs like XY and also unlabeled data and you want to produce a model that predicts well, so you want to produce function that assigns a label to every future instance.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Transductive is slightly different.",
                    "label": 0
                },
                {
                    "sent": "You have the same inputs, training pairs and unlabeled data, but the goal is to predict well on unlabeled example.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "2X and you want to predict the Y and the the you, so you have to predict the performance at each step whenever you get a new example.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And I mean there are some variants that you probably have heard of like reinforcement learning, where instead of predicting some label, you want to take some action and then you get some reward, possibly not immediately but later on.",
                    "label": 0
                },
                {
                    "sent": "So these are what I call settings.",
                    "label": 0
                },
                {
                    "sent": "That's the way you set up the problem and like what you ask your algorithm to do.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You should not confuse these settings with the assumptions that you put on top of that, usually the assumptions are about how the data is generated.",
                    "label": 0
                },
                {
                    "sent": "In this case is like if I go back.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You know?",
                    "label": 0
                },
                {
                    "sent": "How do I assume that these data is generated?",
                    "label": 0
                },
                {
                    "sent": "This training pairs or these instances that come one at a time, so you know you.",
                    "label": 1
                },
                {
                    "sent": "Probably I mean a natural weight is to say OK, they are generated by some probabilistic mechanism, some random number generator or something like this.",
                    "label": 0
                },
                {
                    "sent": "Or maybe they are generated by some natural phenomenon.",
                    "label": 0
                },
                {
                    "sent": "You know observing nature and so.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And these assumptions, as I said before, they are only used if you want to prove anything, but otherwise you know they don't really make sense and you can't really justify any of those, so you know who cares.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The protocol is more, you know how you set the scene, the stage of your learning problem, and how the instances are coming to you and what you get to see of these instances, and so on.",
                    "label": 0
                },
                {
                    "sent": "And this is really the relevant part when you want to create algorithm because your algorithm has to have two fits with this protocol.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then there is this notion of success measure, which is how you would be measuring success, or when would you say I'm satisfied with this algorithm and.",
                    "label": 0
                },
                {
                    "sent": "Sometimes they are.",
                    "label": 0
                },
                {
                    "sent": "The success measures are abstract, like for example the reward in infinite in finite horizon, like how much you will or the number of errors you will make if you add infinitely many data points.",
                    "label": 0
                },
                {
                    "sent": "This kind of thing.",
                    "label": 0
                },
                {
                    "sent": "So these are target criteria, but you can't really measure them, you never will have infinitely many data points.",
                    "label": 0
                },
                {
                    "sent": "But did they help you or they guide you towards the deriving the right Al Gore?",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then there is what type of analysis you are doing in this given this setting.",
                    "label": 1
                },
                {
                    "sent": "Given the success measured given you algorithm how you will analyze it and what kind of statements you are expecting to prove about this algorithm.",
                    "label": 1
                },
                {
                    "sent": "And again, that's relevant one that's only relevant within a certain.",
                    "label": 0
                },
                {
                    "sent": "Data generation generation mechanism.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And sometimes you also add further restrictive assumption.",
                    "label": 0
                },
                {
                    "sent": "So you kind of, you know, assume some regularity about the data or.",
                    "label": 0
                },
                {
                    "sent": "You know, you may assume that you're only looking at certain kinds of functions for this kind of things.",
                    "label": 0
                },
                {
                    "sent": "And this again is not.",
                    "label": 0
                },
                {
                    "sent": "Really.",
                    "label": 0
                },
                {
                    "sent": "I mean, it's useful for designing algorithm because then you can restrict your algorithm, But then your algorithm would only work or would only probably work under this.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "These conditions.",
                    "label": 0
                },
                {
                    "sent": "The point here is that if you have an algorithm that has been designed under certain set of, you know for certain protocol with certain limited limiting assumption.",
                    "label": 0
                },
                {
                    "sent": "The this algorithm may perform well under some circumstances, so my point here is that you know people would tell you OK. Algorithms that are based on Bayesian inference, for example working better OK Baby.",
                    "label": 1
                },
                {
                    "sent": "But you know?",
                    "label": 0
                },
                {
                    "sent": "The thing is that you can prove that within this restrictive framework and within the right assumptions, these can be proved to be optimal fine, but then beyond that you don't know you cannot prove anything but still they can work well, so you can't really use the fact that an algorithm is proven to be optimal in a certain context to derive the fact that it will be good in another context, but it may just be good just because it is good.",
                    "label": 0
                },
                {
                    "sent": "Because it happens to fit with this assumption of these other contexts.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And another point is that you know algorithm often.",
                    "label": 0
                },
                {
                    "sent": "Have a proxy that they are trying to optimize, which is not the real success measure, but some some.",
                    "label": 0
                },
                {
                    "sent": "So measure that, hopefully will converse with success measure for example.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, some examples of all these things.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Data generation mechanism.",
                    "label": 0
                },
                {
                    "sent": "You can have several ways in which you assume the data comes to you in the kind of Bayes interpretation.",
                    "label": 0
                },
                {
                    "sent": "You can assume that the underlying function describing your phenomenon is sampled from some distribution and that the data also is sampled from some other distribution.",
                    "label": 1
                },
                {
                    "sent": "So you put probabilistic assumption or probabilistic generation assumption on both the function and the data.",
                    "label": 1
                },
                {
                    "sent": "In the IID setting.",
                    "label": 0
                },
                {
                    "sent": "IID stands for independent, identically distributed.",
                    "label": 1
                },
                {
                    "sent": "You don't assume that the function is sampled.",
                    "label": 0
                },
                {
                    "sent": "Kind of randomly, but you assume that the data is sampled.",
                    "label": 0
                },
                {
                    "sent": "IID so independently and.",
                    "label": 0
                },
                {
                    "sent": "With the same distribution from some unknown unknown distribution P in the transaction framework, you assume that the data is completely fixed.",
                    "label": 0
                },
                {
                    "sent": "But what is random is how you split these data into labeled and unlabeled principle.",
                    "label": 0
                },
                {
                    "sent": "And then, well, you can just read that.",
                    "label": 0
                },
                {
                    "sent": "So the point is, this data generation assumption tell you how you assume that the data comes to you.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now the protocols.",
                    "label": 0
                },
                {
                    "sent": "I mean mainly it's you know whether the data comes all at a time like you get all the examples once for all, that's the offline case or online.",
                    "label": 1
                },
                {
                    "sent": "You get one example at the time.",
                    "label": 0
                },
                {
                    "sent": "And along with how the example come, you have some other things that define the protocol, which is how you define the error.",
                    "label": 0
                },
                {
                    "sent": "If you algorithm or whether you.",
                    "label": 1
                },
                {
                    "sent": "Whether you are available to you, the error or the value of the error.",
                    "label": 0
                },
                {
                    "sent": "Sorry, the error function or the value of the value of the error or the error of other related algorithms.",
                    "label": 1
                },
                {
                    "sent": "I mean, this will be clear probably when when you see equals lecture online learning.",
                    "label": 0
                },
                {
                    "sent": "And I won't get into that.",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Details here.",
                    "label": 0
                },
                {
                    "sent": "Just to give you an idea, success measures.",
                    "label": 1
                },
                {
                    "sent": "I mean there are various ways also to define the success, like one classical one is the expected error in the offline setting where you take the average error under this unknown distribution.",
                    "label": 1
                },
                {
                    "sent": "The accumulated error is like the sum of the errors that you make at every step in the online learning case.",
                    "label": 1
                },
                {
                    "sent": "And you can have.",
                    "label": 0
                },
                {
                    "sent": "A combination of both.",
                    "label": 0
                },
                {
                    "sent": "If you have an underlying probabilistic assumption.",
                    "label": 0
                },
                {
                    "sent": "So if you assume that the example from one at a time and they are sampled from some distribution, you can compute the expected value of this error.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now the type of analysis.",
                    "label": 1
                },
                {
                    "sent": "This is what you kind of aim for or how you want to define what is a good algorithm or bad algorithm.",
                    "label": 0
                },
                {
                    "sent": "And you can study.",
                    "label": 0
                },
                {
                    "sent": "You know the worst case.",
                    "label": 0
                },
                {
                    "sent": "Performance or the average case?",
                    "label": 1
                },
                {
                    "sent": "So worst case, being like you consider the worst possible data generation mechanism within the ones that you have chosen or average cases like you define some kind of probability on the data generation mechanism and you take the average over them.",
                    "label": 1
                },
                {
                    "sent": "So it requires some weighting, like choosing how what is the probability of each data generation or probability distribution.",
                    "label": 0
                },
                {
                    "sent": "Or this case, which is like you are interested in the case that you observe.",
                    "label": 0
                },
                {
                    "sent": "OK, and then you can prove several different things given I mean, for each of each type of an ally.",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "OK, so one example that we can detail a bit more is this Bayesian inference and I'm using that in the kind of very general way, and I mean many people would have different definitions or would only consider the protocol but not the data generation mechanism and so on.",
                    "label": 0
                },
                {
                    "sent": "So I'm trying to go through all these things that have defined an tell you what would be the way.",
                    "label": 0
                },
                {
                    "sent": "Kind of.",
                    "label": 0
                },
                {
                    "sent": "People would do it innovation framework.",
                    "label": 0
                },
                {
                    "sent": "So as I said before, the data generation mechanism for Bayesian inference is usually that you assume that your function is sampled from some prior and the data is sampled IID from this distribution, right?",
                    "label": 1
                },
                {
                    "sent": "So from the prior distribution and labeled by this function depends on whether you consider function or distribution here.",
                    "label": 1
                },
                {
                    "sent": "The protocol is often you have offline.",
                    "label": 1
                },
                {
                    "sent": "You see all the examples at once.",
                    "label": 0
                },
                {
                    "sent": "And the last measure is the expected error under.",
                    "label": 0
                },
                {
                    "sent": "This data generation mechanism.",
                    "label": 1
                },
                {
                    "sent": "And the type of analysis is again you average things under the prior.",
                    "label": 0
                },
                {
                    "sent": "So it's kind of fun.",
                    "label": 0
                },
                {
                    "sent": "Average case analysis.",
                    "label": 0
                },
                {
                    "sent": "Ann, usually you also have a restrictive assumptions like you assume that the noises of this specific form, like in the regulation based on regression, you would assume that the noise is Gaussian or this kind of thing.",
                    "label": 0
                },
                {
                    "sent": "Well, I mean, usually you assume that each instance is sampled independently from some distribution.",
                    "label": 0
                },
                {
                    "sent": "So I mean, there are two ways, right?",
                    "label": 0
                },
                {
                    "sent": "Yeah, well yeah, maybe it's not very clear so yeah, usually have a different prior from the data for sampling the data.",
                    "label": 0
                },
                {
                    "sent": "But there are two ways, so either.",
                    "label": 0
                },
                {
                    "sent": "You consider a function.",
                    "label": 0
                },
                {
                    "sent": "You sample your data and then you label these data with the function.",
                    "label": 0
                },
                {
                    "sent": "Or you consider a distribution here.",
                    "label": 0
                },
                {
                    "sent": "So distribution on XY.",
                    "label": 0
                },
                {
                    "sent": "And then the data is just sample from XY, so it's not labeled by the function.",
                    "label": 0
                },
                {
                    "sent": "Sure, yeah, I mean OK. Yeah, maybe this is a special case.",
                    "label": 0
                },
                {
                    "sent": "I added the special case.",
                    "label": 0
                },
                {
                    "sent": "That's true because like some people would just say, OK, I get this data and it's sample from distribution which needs, not the ID.",
                    "label": 0
                },
                {
                    "sent": "And yeah, sure all these assumptions you only need if you want to prove things right, but otherwise you can.",
                    "label": 0
                },
                {
                    "sent": "Well, also if you want to apply Bayes rules right, you have to choose whether you want to write the probability of the observation as a product of probabilities of individual observations which correspond to the ID.",
                    "label": 0
                },
                {
                    "sent": "Or you define this otherwise.",
                    "label": 0
                }
            ]
        },
        "clip_80": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so in our case we will consider more of the worst case analysis and we try to avoid assumptions as much as we can.",
                    "label": 1
                },
                {
                    "sent": "And look for algorithm that do do best under these few assumptions.",
                    "label": 0
                },
                {
                    "sent": "And the kind of quantity that that kind of is interesting to us is the following.",
                    "label": 0
                },
                {
                    "sent": "We're looking at the loss of a given algorithm.",
                    "label": 0
                },
                {
                    "sent": "Or some problem?",
                    "label": 0
                },
                {
                    "sent": "And we look at the worst case.",
                    "label": 0
                },
                {
                    "sent": "Value of this loss for the worst problem in a certain class maybe.",
                    "label": 0
                },
                {
                    "sent": "And hopefully we try to find the algorithm that is best with respect to this worst case loss.",
                    "label": 0
                },
                {
                    "sent": "So The thing is, we will show that this value, which is kind of the optimal loss, that we can expect under this worst case scenario, we will show that this actually does not need always to be small.",
                    "label": 0
                }
            ]
        },
        "clip_81": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So sometimes there is no way to escape and that's the no free lunch theorem.",
                    "label": 0
                },
                {
                    "sent": "Sometimes you cannot hope to make this small, so you can't really have a good algorithm.",
                    "label": 0
                },
                {
                    "sent": "And there are several ways in which you can make these non small I.",
                    "label": 1
                }
            ]
        },
        "clip_82": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Show you how.",
                    "label": 0
                },
                {
                    "sent": "I'm.",
                    "label": 0
                },
                {
                    "sent": "There is a, I mean, the distinction to understand which is a bit subtle here is that you can put restrictions.",
                    "label": 0
                },
                {
                    "sent": "On the problem class and what does this mean?",
                    "label": 0
                },
                {
                    "sent": "So that's the classical minimax approach.",
                    "label": 1
                },
                {
                    "sent": "What you consider is.",
                    "label": 0
                },
                {
                    "sent": "Just what I wrote before, but you consider that the problem is within a certain class.",
                    "label": 0
                },
                {
                    "sent": "So for example, problem means the probability distribution, for example.",
                    "label": 0
                },
                {
                    "sent": "So you assume that the probability distribution at certain regularity's say.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "You can either considered the loss or the loss with respect to the best algorithm for that problem.",
                    "label": 0
                },
                {
                    "sent": "2 two cases occur.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "The problem is like if you get the statement so if you prove that this quantity or this quantity has some value or is within certain range, the only thing you can say is that.",
                    "label": 1
                },
                {
                    "sent": "If my problem so sorry I should have said problem in a class here.",
                    "label": 0
                },
                {
                    "sent": "So you have also this restriction on the problem.",
                    "label": 0
                },
                {
                    "sent": "So the only thing you can derive from that is that if your problem is indeed within that class.",
                    "label": 0
                },
                {
                    "sent": "So if your probability distribution indeed as these regularity's, then you can say something about the loss of your algorithm.",
                    "label": 0
                },
                {
                    "sent": "Or of the best algorithm?",
                    "label": 0
                },
                {
                    "sent": "But if it doesn't satisfy these conditions, then you cannot say anything, right?",
                    "label": 0
                },
                {
                    "sent": "So this is important.",
                    "label": 0
                },
                {
                    "sent": "You have to.",
                    "label": 0
                },
                {
                    "sent": "I understand that whatever restriction you put here would restrict the applicability of your results.",
                    "label": 0
                },
                {
                    "sent": "Yeah, well, I mean.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I have not specified what is the class, but what I mean by this is.",
                    "label": 0
                },
                {
                    "sent": "If you have a class of problems then you can define the Max over this class.",
                    "label": 0
                },
                {
                    "sent": "Oh OK, OK, sorry.",
                    "label": 0
                },
                {
                    "sent": "So if you if you don't have this restriction.",
                    "label": 0
                },
                {
                    "sent": "Then I mean the the.",
                    "label": 0
                },
                {
                    "sent": "What I mean by problem in this case is for example, all probability distributions say.",
                    "label": 0
                },
                {
                    "sent": "So yes, yeah, it's OK. You always have a class for sure, but the class would be.",
                    "label": 0
                },
                {
                    "sent": "Less restricted.",
                    "label": 0
                },
                {
                    "sent": "I mean, for example in the online case you would have the maximum over all sequences of data points of all pairs, all sequences of pairs.",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 1
                },
                {
                    "sent": "OK. Maybe I'll skip that.",
                    "label": 0
                },
                {
                    "sent": "So if we if we go the other instead of the minimax approach with the competitive approach.",
                    "label": 0
                },
                {
                    "sent": "Here the difference and OK here is where the difference occurs is that instead of.",
                    "label": 0
                },
                {
                    "sent": "Imposing restriction on your class of problems.",
                    "label": 0
                },
                {
                    "sent": "What you impose is.",
                    "label": 0
                },
                {
                    "sent": "That you don't want to compare your performance to kind of the best possible performance, but the best possible performance in a certain class of predictors so.",
                    "label": 0
                },
                {
                    "sent": "You're looking at your loss, the loss of your algorithm on the problem, and you compare it to the loss of some reference algorithm on the problem and the reference algorithm.",
                    "label": 0
                },
                {
                    "sent": "You take the best within a certain class, so here I mean again, it's not.",
                    "label": 0
                },
                {
                    "sent": "I should have said references.",
                    "label": 0
                },
                {
                    "sent": "Some elements of a small class of.",
                    "label": 0
                },
                {
                    "sent": "Of algorithms and problem is.",
                    "label": 0
                },
                {
                    "sent": "Some probability distribution, for example, among a large class, possibly all probability distributions, or all sequences of data or something so you.",
                    "label": 0
                },
                {
                    "sent": "Put a lot less restrictions on the problems, but now you introduce restriction on what you are comparing your algorithm to.",
                    "label": 0
                },
                {
                    "sent": "So in a way, you're trying to do as best as good as some algorithm within the class for all possible problems.",
                    "label": 0
                },
                {
                    "sent": "So this way you no longer add assumption and you no longer have to, kind of.",
                    "label": 0
                },
                {
                    "sent": "Make sure that your problem satisfies the restrictions that you put before.",
                    "label": 0
                },
                {
                    "sent": "I mean, you don't have restrictions anymore.",
                    "label": 0
                },
                {
                    "sent": "An OK.",
                    "label": 0
                },
                {
                    "sent": "So once we are, I mean studying these quantities means proving what we call upper bounds or lower bounds on these numbers.",
                    "label": 0
                },
                {
                    "sent": "So we want to an upper bound would be something saying that I mean the statement saying that this is less than some quantity and the lower bound would be something saying that this is larger than some quantity.",
                    "label": 1
                },
                {
                    "sent": "And some proven upper bound.",
                    "label": 0
                },
                {
                    "sent": "It's the only thing that we have to do is to show an algorithm.",
                    "label": 0
                },
                {
                    "sent": "I mean, come up with an algorithm for which we can prove that the error is not larger than some value, and to prove a lower bound we have to prove that for any possible algorithm.",
                    "label": 0
                },
                {
                    "sent": "Because we have here for any possible algorithm, there is some distribution for which there is large enough.",
                    "label": 0
                }
            ]
        },
        "clip_83": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "An OK, finally I'll get to some notation.",
                    "label": 1
                },
                {
                    "sent": "Which is kind of simple here, but we consider this this pairwise prediction, so we have an input SpaceX.",
                    "label": 0
                },
                {
                    "sent": "An open space that we can consider as binary so we can restrict to binary classification for now and will be the sample size number of examples that we observe.",
                    "label": 1
                },
                {
                    "sent": "So I I I'm not in the online setting here and more in the offline.",
                    "label": 0
                },
                {
                    "sent": "So I observe pairs XY.",
                    "label": 1
                },
                {
                    "sent": "I'm considering again the supervised learning framework, so I don't assume that I have unlabeled data.",
                    "label": 0
                },
                {
                    "sent": "So we have a loss function, which often is whether the two instance two labels are the same or not.",
                    "label": 0
                },
                {
                    "sent": "So that's the misclassification error.",
                    "label": 0
                }
            ]
        },
        "clip_84": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "We look at.",
                    "label": 0
                },
                {
                    "sent": "Either the cumulative loss for a given function, so the number of times it makes a mistake at predicting Y from X.",
                    "label": 1
                },
                {
                    "sent": "Or the expected loss which is.",
                    "label": 0
                },
                {
                    "sent": "The expectation of this value under some distribution.",
                    "label": 0
                },
                {
                    "sent": "Some unknown distribution.",
                    "label": 0
                },
                {
                    "sent": "That's the IID setting.",
                    "label": 0
                },
                {
                    "sent": "We will consider we will call GN the function that we that we construct after observing NN pairs.",
                    "label": 0
                },
                {
                    "sent": "Anne, this talk will be the optimal function in the sense that it minimizes the loss, the expected loss.",
                    "label": 1
                },
                {
                    "sent": "OK. And.",
                    "label": 0
                },
                {
                    "sent": "The problem is that we I mean kind of quantities that we can be interested in our.",
                    "label": 0
                },
                {
                    "sent": "Like this minimax loss.",
                    "label": 0
                },
                {
                    "sent": "So we compare the loss of a given algorithm to.",
                    "label": 0
                },
                {
                    "sent": "The last of the best in the class.",
                    "label": 0
                },
                {
                    "sent": "So for probabilities belonging to some class P of probabilities.",
                    "label": 0
                },
                {
                    "sent": "Or the regret approach where we compared to a reference belonging to some class G of functions, and we take the Max overall probabilities distribution.",
                    "label": 0
                },
                {
                    "sent": "So these are.",
                    "label": 0
                },
                {
                    "sent": "Slightly more formalized goals.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Maybe I'll stop here and we can start again in.",
                    "label": 0
                },
                {
                    "sent": "Well, it's in 10 minutes.",
                    "label": 0
                }
            ]
        }
    }
}