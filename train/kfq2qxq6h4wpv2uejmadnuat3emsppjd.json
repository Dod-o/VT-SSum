{
    "id": "kfq2qxq6h4wpv2uejmadnuat3emsppjd",
    "title": "Feature Selection in Land-Cover Classification using EO-learn",
    "info": {
        "author": [
            "Klemen Kenda, Artificial Intelligence Laboratory, Jo\u017eef Stefan Institute"
        ],
        "published": "Nov. 14, 2019",
        "recorded": "October 2019",
        "category": [
            "Top->Computer Science->Data Mining",
            "Top->Computer Science->Artificial Intelligence"
        ]
    },
    "url": "http://videolectures.net/sikdd2019_kenda_feature_selection/",
    "segmentation": [
        [
            "So hello, I am Clement.",
            "I will be presenting joint work with Philip Private Santiago Peternel and the work is.",
            "Opens another topic in the conference, which will appear three more times today and it's the topic of how to use satellite imagery for different tasks.",
            "A lot of work has been done in this Department over the last three years, and what we are focusing on in our Department is how to do common things that we usually do.",
            "For example, land cover classification in an efficient way, and we attacked in this paper.",
            "We take the feature selection process."
        ],
        [
            "So the basic idea is that we have a multi spectral image that we get from the satellites and this image is come from the European Space Agency from the Sentinel to program and what we want to do in the end we want to use that image to prepare this kind of map and this is the land cover classification map where each color represents a different thing that grows in the field.",
            "So these are fields.",
            "This is some populated area urban area.",
            "This is Forrest and so on."
        ],
        [
            "Today I will give a brief introduction on the satellite imagery and how we attack this problems.",
            "Then I will present your learn library, which is a library that we developed within Perceptive Sentinel Project and Automatised the process.",
            "How you deal with this data and it saves you a lot of times.",
            "Then I will talk a little bit about feature generation, feature selection and then I will conclude in the end.",
            "So basically this is symbolic image of the Sentinel.",
            "To mention we have satellites, a couple of them that orbit the Earth.",
            "From the pole to pole and around and basically what they do is they take a picture of each point on the earth surface once every five days.",
            "If you are near to the pole.",
            "This is more often cause the districts overlap, but if you are at the equator, this happens every five days and this images are multispectral.",
            "We have from infrared to ultraviolet and of course everything in between."
        ],
        [
            "So that you learn library that we have developed makes your work much easier in the past you had to download the correct image.",
            "You had to be careful about the coordinates you had to do the preprocessing yourself, but today these things are pretty much automated.",
            "European Space Agency makes a lot of work already when they retrieve the data.",
            "So for example they do atmospheric correction and then they upload this to the cloud and once it's in the cloud we have the service.",
            "It's called Sentinel hub.",
            "That indices this images and it is able to retrieve them quite fast and once we have this our component our library you learn comes into play.",
            "So basically we have a lot of these components which are here depicted in blue.",
            "They're called your task Earth observation tasks which we can just put in chain one after another.",
            "The nice thing is that the data structure which is called a Patch is able to transfer any data from any tasks to any other task so.",
            "Whatever we can put together, it will basically work almost immediately, so this is the process that we used for our experiments.",
            "Here.",
            "We first load the data from the cloud, then we do some cloud detection, some sampling which is needed to have balanced classes for our task and so on.",
            "We do feature engineering, feature selection, train the models and so on.",
            "So the library itself is available.",
            "Here.",
            "You can check it, it's being updated as we speak, actually.",
            "And it's it also has some supporting software where you can play with the data and see what's inside."
        ],
        [
            "So the first thing that we need to do when we acquire the data we get to calculate some very nice features out of it.",
            "A lot of work has been done in this area in the past.",
            "It's from the pre machine learning Kira.",
            "I think I have read that a lot of classification models have been already done in the 80s and what they did then is they looked actually at the data and try to find simple relations that would extract something out of it.",
            "For example, we have an index that's called normal differential vegetation index and.",
            "When they observe these data, they have seen it.",
            "For example, when we have green vegetation, the reflectance in the infrared band is 50% and indivisible Red Band is only 8%.",
            "If they took the plants after a draft, they have seen the reflectance in the infrared is a little bit smaller, but in the visible red spectrum it's much higher.",
            "So when you put this into this index and calculate it, you see that when you have green vegetation, this is a high index.",
            "And when you don't have green vegetation needs a small index.",
            "So it's a very useful value to do immediate classification.",
            "We still use this indices today, although we combine them together, put them into machine learning methods, and usually they eat much better results OK?"
        ],
        [
            "So.",
            "As the satellites revisit the surface every five days, we don't work just with single images, but we work with the time series of images.",
            "So for example, it's not seen very nicely, but so we have this stack of images that represent the whole year and some are missing in between.",
            "There missing of course, because we have cloudy weather and so on.",
            "And what we do after that we do some sort of interpolation.",
            "So here for example we have values of some parameter from the image.",
            "On the time scale of 1 year and what we do, we interpolate it in between.",
            "Once we have this interpolation, we can do so."
        ],
        [
            "Some pretty nice things out of it.",
            "Here is an example how they calculate it features for classifying Christ fields.",
            "And once you have this interpolation you can extract things like.",
            "I don't know the maximum of that index.",
            "How long is this period of the maximum?",
            "How long is the period of growth, how fast the things are growing, and so on?",
            "And it shows after experiments that these features are very informative and you get very good classification results.",
            "Out of it."
        ],
        [
            "So here are some examples how these features look like.",
            "You can see that every feature extracts some something else from the image and this can be useful for classification and this is sort of state of the art in the area at this point."
        ],
        [
            "OK, we did all that and we came up with 108 different features and you would need to consider that there is a lot of data.",
            "A lot of processing power is needed to calculate interpolations, extract features and so on.",
            "What we wanted to do in our work is how to reduce this number of features significantly but still get good results.",
            "So this means that we need to search through this vast space and find the best combinations, but of course we want to do this in an efficient way.",
            "What we used was a genetic algorithm which is POS algorithm which we modified slightly.",
            "And how does this work?",
            "Basically, we are dealing with a multi objective optimization problem.",
            "On one hand we want to use as little features as possible and which are depicted here on this graph and on the other hand we want to get as good result as possible.",
            "So let's consider our algorithm.",
            "For example, let's say that we are that these points actually represent results of a particular candidate for our solution, which has a number of features.",
            "For example, we select this candidate, it has 10 features, and then of course in genetic algorithm we want to mutate this sample little bit.",
            "So we will add some features or remove some features depends on the algorithm and then we will test the new candidate.",
            "If the new candidate decades.",
            "Behaves better or equally good as the candidate before.",
            "Then we will take that one, otherwise we will throw it away and we repeat the process for awhile and so here the results of all of all this of our experiments.",
            "We have tested three different things, three different methods, logistic regression, random forest and gradient boosting's.",
            "We see that gradient boosting is dealing with the best with this problems, but also with good choice of the features.",
            "Logistic regression is not this bad.",
            "We need to consider that in the beginning we had 108 features and we see from this graph that, for example, after somehow 10 or a little bit more features, these results get quite stable.",
            "So we don't need to use 108 features.",
            "We can reduce these to 10:15 and we will already get good results.",
            "What's nice to see is not so much visible because the scale is not good, but for example for random forest we got the best results with 13 features.",
            "If we used, more results were slightly worse, so that's also a good thing to consider.",
            "And of course, when you have calculate, calculate less features.",
            "This takes less time, and when you use this for learning Kit, also takes much less than these pictures here, they picked as the candidates for different number of features.",
            "So this is the index of the feature.",
            "This is the number of the features this is gradient boosting, random forest and logistic regression.",
            "For example, if you check logistic regression.",
            "If we take just one feature, it will choose that one that is.",
            "That gives us the best result is the most informative, and if you check these features here with logistic regression, we see that some of the features are quite stable.",
            "They're very informative.",
            "The algorithm will take them always, and the rest it will perturbate a little bit."
        ],
        [
            "OK.",
            "So it's not just this affects the accuracy of the algorithm, but it also affects the computational demand.",
            "So in this graph, especially for logistic regression, for gradient boosting, which is depicted in blue, you can see that this is so.",
            "This graph depicts number of features and memory consumption in megabytes, and we see that the more features we use which we expect, the more memory we need.",
            "The only this is some sort of anomaly of the implementation of the random forest.",
            "But basically we save memory, we save, we save time and we would be able to calculate the same, almost the same result with much less resources.",
            "So we don't have to do so much preprocessing of the data."
        ],
        [
            "OK, basically this is all I wanted to say, so we use the state of the art feature extractors.",
            "We did the genetic algorithm to optimize feature selection and we're also dealing with other things.",
            "How to optimize this work so one is to use for example faster algorithms for learning and some early results have shown promising promising times.",
            "So if we put all these things together that we do, perhaps we are in the reach of making the computations maybe 100 times faster than they are now.",
            "But they will be maybe a few percent worse than the state of the art.",
            "The state of the art in the area is still deep learning, of course, but deep learning takes especially with this kind of features.",
            "It takes a lot of time, so thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So hello, I am Clement.",
                    "label": 0
                },
                {
                    "sent": "I will be presenting joint work with Philip Private Santiago Peternel and the work is.",
                    "label": 0
                },
                {
                    "sent": "Opens another topic in the conference, which will appear three more times today and it's the topic of how to use satellite imagery for different tasks.",
                    "label": 0
                },
                {
                    "sent": "A lot of work has been done in this Department over the last three years, and what we are focusing on in our Department is how to do common things that we usually do.",
                    "label": 0
                },
                {
                    "sent": "For example, land cover classification in an efficient way, and we attacked in this paper.",
                    "label": 0
                },
                {
                    "sent": "We take the feature selection process.",
                    "label": 1
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the basic idea is that we have a multi spectral image that we get from the satellites and this image is come from the European Space Agency from the Sentinel to program and what we want to do in the end we want to use that image to prepare this kind of map and this is the land cover classification map where each color represents a different thing that grows in the field.",
                    "label": 0
                },
                {
                    "sent": "So these are fields.",
                    "label": 0
                },
                {
                    "sent": "This is some populated area urban area.",
                    "label": 0
                },
                {
                    "sent": "This is Forrest and so on.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Today I will give a brief introduction on the satellite imagery and how we attack this problems.",
                    "label": 0
                },
                {
                    "sent": "Then I will present your learn library, which is a library that we developed within Perceptive Sentinel Project and Automatised the process.",
                    "label": 0
                },
                {
                    "sent": "How you deal with this data and it saves you a lot of times.",
                    "label": 0
                },
                {
                    "sent": "Then I will talk a little bit about feature generation, feature selection and then I will conclude in the end.",
                    "label": 1
                },
                {
                    "sent": "So basically this is symbolic image of the Sentinel.",
                    "label": 0
                },
                {
                    "sent": "To mention we have satellites, a couple of them that orbit the Earth.",
                    "label": 0
                },
                {
                    "sent": "From the pole to pole and around and basically what they do is they take a picture of each point on the earth surface once every five days.",
                    "label": 0
                },
                {
                    "sent": "If you are near to the pole.",
                    "label": 0
                },
                {
                    "sent": "This is more often cause the districts overlap, but if you are at the equator, this happens every five days and this images are multispectral.",
                    "label": 0
                },
                {
                    "sent": "We have from infrared to ultraviolet and of course everything in between.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So that you learn library that we have developed makes your work much easier in the past you had to download the correct image.",
                    "label": 0
                },
                {
                    "sent": "You had to be careful about the coordinates you had to do the preprocessing yourself, but today these things are pretty much automated.",
                    "label": 0
                },
                {
                    "sent": "European Space Agency makes a lot of work already when they retrieve the data.",
                    "label": 0
                },
                {
                    "sent": "So for example they do atmospheric correction and then they upload this to the cloud and once it's in the cloud we have the service.",
                    "label": 0
                },
                {
                    "sent": "It's called Sentinel hub.",
                    "label": 0
                },
                {
                    "sent": "That indices this images and it is able to retrieve them quite fast and once we have this our component our library you learn comes into play.",
                    "label": 0
                },
                {
                    "sent": "So basically we have a lot of these components which are here depicted in blue.",
                    "label": 0
                },
                {
                    "sent": "They're called your task Earth observation tasks which we can just put in chain one after another.",
                    "label": 1
                },
                {
                    "sent": "The nice thing is that the data structure which is called a Patch is able to transfer any data from any tasks to any other task so.",
                    "label": 0
                },
                {
                    "sent": "Whatever we can put together, it will basically work almost immediately, so this is the process that we used for our experiments.",
                    "label": 0
                },
                {
                    "sent": "Here.",
                    "label": 0
                },
                {
                    "sent": "We first load the data from the cloud, then we do some cloud detection, some sampling which is needed to have balanced classes for our task and so on.",
                    "label": 0
                },
                {
                    "sent": "We do feature engineering, feature selection, train the models and so on.",
                    "label": 1
                },
                {
                    "sent": "So the library itself is available.",
                    "label": 0
                },
                {
                    "sent": "Here.",
                    "label": 0
                },
                {
                    "sent": "You can check it, it's being updated as we speak, actually.",
                    "label": 0
                },
                {
                    "sent": "And it's it also has some supporting software where you can play with the data and see what's inside.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the first thing that we need to do when we acquire the data we get to calculate some very nice features out of it.",
                    "label": 0
                },
                {
                    "sent": "A lot of work has been done in this area in the past.",
                    "label": 0
                },
                {
                    "sent": "It's from the pre machine learning Kira.",
                    "label": 0
                },
                {
                    "sent": "I think I have read that a lot of classification models have been already done in the 80s and what they did then is they looked actually at the data and try to find simple relations that would extract something out of it.",
                    "label": 0
                },
                {
                    "sent": "For example, we have an index that's called normal differential vegetation index and.",
                    "label": 1
                },
                {
                    "sent": "When they observe these data, they have seen it.",
                    "label": 0
                },
                {
                    "sent": "For example, when we have green vegetation, the reflectance in the infrared band is 50% and indivisible Red Band is only 8%.",
                    "label": 0
                },
                {
                    "sent": "If they took the plants after a draft, they have seen the reflectance in the infrared is a little bit smaller, but in the visible red spectrum it's much higher.",
                    "label": 0
                },
                {
                    "sent": "So when you put this into this index and calculate it, you see that when you have green vegetation, this is a high index.",
                    "label": 0
                },
                {
                    "sent": "And when you don't have green vegetation needs a small index.",
                    "label": 0
                },
                {
                    "sent": "So it's a very useful value to do immediate classification.",
                    "label": 0
                },
                {
                    "sent": "We still use this indices today, although we combine them together, put them into machine learning methods, and usually they eat much better results OK?",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "As the satellites revisit the surface every five days, we don't work just with single images, but we work with the time series of images.",
                    "label": 0
                },
                {
                    "sent": "So for example, it's not seen very nicely, but so we have this stack of images that represent the whole year and some are missing in between.",
                    "label": 0
                },
                {
                    "sent": "There missing of course, because we have cloudy weather and so on.",
                    "label": 0
                },
                {
                    "sent": "And what we do after that we do some sort of interpolation.",
                    "label": 0
                },
                {
                    "sent": "So here for example we have values of some parameter from the image.",
                    "label": 0
                },
                {
                    "sent": "On the time scale of 1 year and what we do, we interpolate it in between.",
                    "label": 0
                },
                {
                    "sent": "Once we have this interpolation, we can do so.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some pretty nice things out of it.",
                    "label": 0
                },
                {
                    "sent": "Here is an example how they calculate it features for classifying Christ fields.",
                    "label": 0
                },
                {
                    "sent": "And once you have this interpolation you can extract things like.",
                    "label": 0
                },
                {
                    "sent": "I don't know the maximum of that index.",
                    "label": 0
                },
                {
                    "sent": "How long is this period of the maximum?",
                    "label": 0
                },
                {
                    "sent": "How long is the period of growth, how fast the things are growing, and so on?",
                    "label": 0
                },
                {
                    "sent": "And it shows after experiments that these features are very informative and you get very good classification results.",
                    "label": 0
                },
                {
                    "sent": "Out of it.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here are some examples how these features look like.",
                    "label": 0
                },
                {
                    "sent": "You can see that every feature extracts some something else from the image and this can be useful for classification and this is sort of state of the art in the area at this point.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, we did all that and we came up with 108 different features and you would need to consider that there is a lot of data.",
                    "label": 0
                },
                {
                    "sent": "A lot of processing power is needed to calculate interpolations, extract features and so on.",
                    "label": 0
                },
                {
                    "sent": "What we wanted to do in our work is how to reduce this number of features significantly but still get good results.",
                    "label": 0
                },
                {
                    "sent": "So this means that we need to search through this vast space and find the best combinations, but of course we want to do this in an efficient way.",
                    "label": 0
                },
                {
                    "sent": "What we used was a genetic algorithm which is POS algorithm which we modified slightly.",
                    "label": 0
                },
                {
                    "sent": "And how does this work?",
                    "label": 0
                },
                {
                    "sent": "Basically, we are dealing with a multi objective optimization problem.",
                    "label": 0
                },
                {
                    "sent": "On one hand we want to use as little features as possible and which are depicted here on this graph and on the other hand we want to get as good result as possible.",
                    "label": 0
                },
                {
                    "sent": "So let's consider our algorithm.",
                    "label": 0
                },
                {
                    "sent": "For example, let's say that we are that these points actually represent results of a particular candidate for our solution, which has a number of features.",
                    "label": 0
                },
                {
                    "sent": "For example, we select this candidate, it has 10 features, and then of course in genetic algorithm we want to mutate this sample little bit.",
                    "label": 0
                },
                {
                    "sent": "So we will add some features or remove some features depends on the algorithm and then we will test the new candidate.",
                    "label": 0
                },
                {
                    "sent": "If the new candidate decades.",
                    "label": 0
                },
                {
                    "sent": "Behaves better or equally good as the candidate before.",
                    "label": 0
                },
                {
                    "sent": "Then we will take that one, otherwise we will throw it away and we repeat the process for awhile and so here the results of all of all this of our experiments.",
                    "label": 0
                },
                {
                    "sent": "We have tested three different things, three different methods, logistic regression, random forest and gradient boosting's.",
                    "label": 0
                },
                {
                    "sent": "We see that gradient boosting is dealing with the best with this problems, but also with good choice of the features.",
                    "label": 0
                },
                {
                    "sent": "Logistic regression is not this bad.",
                    "label": 0
                },
                {
                    "sent": "We need to consider that in the beginning we had 108 features and we see from this graph that, for example, after somehow 10 or a little bit more features, these results get quite stable.",
                    "label": 0
                },
                {
                    "sent": "So we don't need to use 108 features.",
                    "label": 0
                },
                {
                    "sent": "We can reduce these to 10:15 and we will already get good results.",
                    "label": 0
                },
                {
                    "sent": "What's nice to see is not so much visible because the scale is not good, but for example for random forest we got the best results with 13 features.",
                    "label": 0
                },
                {
                    "sent": "If we used, more results were slightly worse, so that's also a good thing to consider.",
                    "label": 0
                },
                {
                    "sent": "And of course, when you have calculate, calculate less features.",
                    "label": 0
                },
                {
                    "sent": "This takes less time, and when you use this for learning Kit, also takes much less than these pictures here, they picked as the candidates for different number of features.",
                    "label": 0
                },
                {
                    "sent": "So this is the index of the feature.",
                    "label": 0
                },
                {
                    "sent": "This is the number of the features this is gradient boosting, random forest and logistic regression.",
                    "label": 1
                },
                {
                    "sent": "For example, if you check logistic regression.",
                    "label": 0
                },
                {
                    "sent": "If we take just one feature, it will choose that one that is.",
                    "label": 0
                },
                {
                    "sent": "That gives us the best result is the most informative, and if you check these features here with logistic regression, we see that some of the features are quite stable.",
                    "label": 0
                },
                {
                    "sent": "They're very informative.",
                    "label": 0
                },
                {
                    "sent": "The algorithm will take them always, and the rest it will perturbate a little bit.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So it's not just this affects the accuracy of the algorithm, but it also affects the computational demand.",
                    "label": 0
                },
                {
                    "sent": "So in this graph, especially for logistic regression, for gradient boosting, which is depicted in blue, you can see that this is so.",
                    "label": 0
                },
                {
                    "sent": "This graph depicts number of features and memory consumption in megabytes, and we see that the more features we use which we expect, the more memory we need.",
                    "label": 0
                },
                {
                    "sent": "The only this is some sort of anomaly of the implementation of the random forest.",
                    "label": 0
                },
                {
                    "sent": "But basically we save memory, we save, we save time and we would be able to calculate the same, almost the same result with much less resources.",
                    "label": 0
                },
                {
                    "sent": "So we don't have to do so much preprocessing of the data.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, basically this is all I wanted to say, so we use the state of the art feature extractors.",
                    "label": 1
                },
                {
                    "sent": "We did the genetic algorithm to optimize feature selection and we're also dealing with other things.",
                    "label": 1
                },
                {
                    "sent": "How to optimize this work so one is to use for example faster algorithms for learning and some early results have shown promising promising times.",
                    "label": 0
                },
                {
                    "sent": "So if we put all these things together that we do, perhaps we are in the reach of making the computations maybe 100 times faster than they are now.",
                    "label": 0
                },
                {
                    "sent": "But they will be maybe a few percent worse than the state of the art.",
                    "label": 0
                },
                {
                    "sent": "The state of the art in the area is still deep learning, of course, but deep learning takes especially with this kind of features.",
                    "label": 0
                },
                {
                    "sent": "It takes a lot of time, so thank you.",
                    "label": 0
                }
            ]
        }
    }
}